<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:01:09Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|87001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04094</identifier>
 <datestamp>2016-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Do Global Audiences Take Shape? The Role of Institutions and Culture
  in Patterns of Web Use</dc:title>
 <dc:creator>Taneja, Harsh</dc:creator>
 <dc:creator>Webster, James</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This study investigates the role of both cultural and technological factors
in determining audience formation on a global scale. It integrates theories of
media choice with theories of global cultural consumption and tests them by
analyzing shared audience traffic between the world's 1000 most popular
Websites. We find that language and geographic similarities are more powerful
predictors of audience overlap than hyperlinks and genre similarity,
highlighting the role of cultural structures in shaping global media use.
</dc:description>
 <dc:description>Comment: Suggested Citation: Taneja. H &amp; Webster. J.G. (In Press). How Do
  Global Audiences Take Shape? The Role of Institutions and Culture in Shaping
  Patterns of Web Use. Journal of Communication</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04094</dc:identifier>
 <dc:identifier>doi:10.1111/jcom.12200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04103</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Basic Level Categorization Facilitates Visual Object Recognition</dc:title>
 <dc:creator>Wang, Panqu</dc:creator>
 <dc:creator>Cottrell, Garrison W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in deep learning have led to significant progress in the
computer vision field, especially for visual object recognition tasks. The
features useful for object classification are learned by feed-forward deep
convolutional neural networks (CNNs) automatically, and they are shown to be
able to predict and decode neural representations in the ventral visual pathway
of humans and monkeys. However, despite the huge amount of work on optimizing
CNNs, there has not been much research focused on linking CNNs with guiding
principles from the human visual cortex. In this work, we propose a network
optimization strategy inspired by both of the developmental trajectory of
children's visual object recognition capabilities, and Bar (2003), who
hypothesized that basic level information is carried in the fast magnocellular
pathway through the prefrontal cortex (PFC) and then projected back to inferior
temporal cortex (IT), where subordinate level categorization is achieved. We
instantiate this idea by training a deep CNN to perform basic level object
categorization first, and then train it on subordinate level categorization. We
apply this idea to training AlexNet (Krizhevsky et al., 2012) on the ILSVRC
2012 dataset and show that the top-5 accuracy increases from 80.13% to 82.14%,
demonstrating the effectiveness of the method. We also show that subsequent
transfer learning on smaller datasets gives superior results.
</dc:description>
 <dc:description>Comment: ICLR 2016 submission R1</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04108</identifier>
 <datestamp>2016-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM-based Deep Learning Models for Non-factoid Answer Selection</dc:title>
 <dc:creator>Tan, Ming</dc:creator>
 <dc:creator>Santos, Cicero dos</dc:creator>
 <dc:creator>Xiang, Bing</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we apply a general deep learning (DL) framework for the answer
selection task, which does not depend on manually defined features or
linguistic tools. The basic framework is to build the embeddings of questions
and answers based on bidirectional long short-term memory (biLSTM) models, and
measure their closeness by cosine similarity. We further extend this basic
model in two directions. One direction is to define a more composite
representation for questions and answers by combining convolutional neural
network with the basic framework. The other direction is to utilize a simple
but efficient attention mechanism in order to generate the answer
representation according to the question context. Several variations of models
are provided. The models are examined by two datasets, including TREC-QA and
InsuranceQA. Experimental results demonstrate that the proposed models
substantially outperform several strong baselines.
</dc:description>
 <dc:description>Comment: added new experiments on TREC-QA</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04109</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Analytics to Software Domains: A Systematic Literature Review</dc:title>
 <dc:creator>Abdelltif, Tamer Mohamed</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Ho, Danny</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Software Analytics (SA) is a new branch of big data analytics that has
recently emerged (2011). What distinguishes SA from direct software analysis is
that it links data mined from many different software artifacts to obtain
valuable insights. These insights are useful for the decision-making process
throughout the different phases of the software lifecycle. Since SA is
currently a hot and promising topic, we have conducted a systematic literature
review, presented in this paper, to identify gaps in knowledge and open
research areas in SA. Because many researchers are still confused about the
true potential of SA, we had to filter out available research papers to obtain
the most SA-relevant work for our review. This filtration yielded 19 studies
out of 135. We have based our systematic review on four main factors: which
software practitioners SA targets, which domains are covered by SA, which
artifacts are extracted by SA, and whether these artifacts are linked or not.
The results of our review have shown that much of the available SA research
only serves the needs of developers. Also, much of the available research uses
only one artifact which, in turn, means fewer links between artifacts and fewer
insights. This shows that the available SA research work is still embryonic
leaving plenty of room for future research in the SA field.
</dc:description>
 <dc:description>Comment: pp. 30-36</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04109</dc:identifier>
 <dc:identifier>37th IEEE International Conference on Software Engineering -
  Workshop on BIGDSE, 2015</dc:identifier>
 <dc:identifier>doi:10.1109/BIGDSE.2015.14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04110</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Going Deeper in Facial Expression Recognition using Deep Neural Networks</dc:title>
 <dc:creator>Mollahosseini, Ali</dc:creator>
 <dc:creator>Chan, David</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated Facial Expression Recognition (FER) has remained a challenging and
interesting problem. Despite efforts made in developing various methods for
FER, existing approaches traditionally lack generalizability when applied to
unseen images or those that are captured in wild setting. Most of the existing
approaches are based on engineered features (e.g. HOG, LBPH, and Gabor) where
the classifier's hyperparameters are tuned to give best recognition accuracies
across a single database, or a small collection of similar databases.
Nevertheless, the results are not significant when they are applied to novel
data. This paper proposes a deep neural network architecture to address the FER
problem across multiple well-known standard face datasets. Specifically, our
network consists of two convolutional layers each followed by max pooling and
then four Inception layers. The network is a single component architecture that
takes registered facial images as the input and classifies them into either of
the six basic or the neutral expressions. We conducted comprehensive
experiments on seven publically available facial expression databases, viz.
MultiPIE, MMI, CK+, DISFA, FERA, SFEW, and FER2013. The results of proposed
architecture are comparable to or better than the state-of-the-art methods and
better than traditional convolutional neural networks and in both accuracy and
training time.
</dc:description>
 <dc:description>Comment: To be appear in IEEE Winter Conference on Applications of Computer
  Vision (WACV), 2016 {Accepted in first round submission}</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04110</dc:identifier>
 <dc:identifier>IEEE Winter Conference on Applications of Computer Vision (WACV),
  2016</dc:identifier>
 <dc:identifier>doi:10.1109/WACV.2016.7477450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04115</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Spectrum Sensing and Resource Allocation for OFDM-based
  Transmission with a Cognitive Relay</dc:title>
 <dc:creator>Mahmoodi, S. Eman</dc:creator>
 <dc:creator>Subbalakshmi, K. P.</dc:creator>
 <dc:creator>Chandramouli, R.</dc:creator>
 <dc:creator>Abolhassani, Bahman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the joint spectrum sensing and resource
allocation problem to maximize throughput capacity of an OFDM-based cognitive
radio link with a cognitive relay. By applying a cognitive relay that uses
decode and forward (D&amp;F), we achieve more reliable communications, generating
less interference (by needing less transmit power) and more diversity gain. In
order to account for imperfections in spectrum sensing, the proposed schemes
jointly modify energy detector thresholds and allocates transmit powers to all
cognitive radio (CR) subcarriers, while simultaneously assigning subcarrier
pairs for secondary users (SU) and the cognitive relay. This problem is cast as
a constrained optimization problem with constraints on (1) interference
introduced by the SU and the cognitive relay to the PUs; (2) miss-detection and
false alarm probabilities and (3) subcarrier pairing for transmission on the SU
transmitter and the cognitive relay and (4) minimum Quality of Service (QoS)
for each CR subcarrier. We propose one optimal and two sub-optimal schemes all
of which are compared to other schemes in the literature. Simulation results
show that the proposed schemes achieve significantly higher throughput than
other schemes in the literature for different relay situations.
</dc:description>
 <dc:description>Comment: EAI Endorsed Transactions on Wireless Spectrum 14(1): e4 Published
  13th Apr 2014</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04119</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Action Recognition using Visual Attention</dc:title>
 <dc:creator>Sharma, Shikhar</dc:creator>
 <dc:creator>Kiros, Ryan</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a soft attention based model for the task of action recognition in
videos. We use multi-layered Recurrent Neural Networks (RNNs) with Long
Short-Term Memory (LSTM) units which are deep both spatially and temporally.
Our model learns to focus selectively on parts of the video frames and
classifies videos after taking a few glimpses. The model essentially learns
which parts in the frames are relevant for the task at hand and attaches higher
importance to them. We evaluate the model on UCF-11 (YouTube Action), HMDB-51
and Hollywood2 datasets and analyze how the model focuses its attention
depending on the scene and the action being performed.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04120</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Change Patterns for Model Creation: Investigating the Role of Nesting
  Depth</dc:title>
 <dc:creator>Weber, Barbara</dc:creator>
 <dc:creator>Pinggera, Jakob</dc:creator>
 <dc:creator>Torres, Victoria</dc:creator>
 <dc:creator>Reichert, Manfred</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Process model quality has been an area of considerable research efforts. In
this context, the correctness-by-construction principle of change patterns
offers a promising perspective. However, using change patterns for model
creation imposes a more structured way of modeling. While the process of
process modeling (PPM) based on change primitives has been investigated, little
is known about this process based on change patterns and factors that impact
the cognitive complexity of pattern usage. Insights from the field of cognitive
psychology as well as observations from a pilot study suggest that the nesting
depth of the model to be created has a significant impact on cognitive
complexity. This paper proposes a research design to test the impact of nesting
depth on the cognitive complexity of change pattern usage in an experiment.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1511.04059</dc:description>
 <dc:date>2015-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04120</dc:identifier>
 <dc:identifier>Proc. Cognise'13, pp. 198-204, 2013</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-38490-5_19</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04121</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Process of Process Modeling with Eye Movement Analysis</dc:title>
 <dc:creator>Pinggera, Jakob</dc:creator>
 <dc:creator>Furtner, Marco</dc:creator>
 <dc:creator>Martini, Markus</dc:creator>
 <dc:creator>Sachse, Pierre</dc:creator>
 <dc:creator>Reiter, Katharina</dc:creator>
 <dc:creator>Zugal, Stefan</dc:creator>
 <dc:creator>Weber, Barbara</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Research on quality issues of business process models has recently begun to
explore the process of creating process models by analyzing the modeler's
interactions with the modeling environment. In this paper we aim to complement
previous insights on the modeler's modeling behavior with data gathered by
tracking the modeler's eye movements when engaged in the act of modeling. We
present preliminary results and outline directions for future research to
triangulate toward a more comprehensive understanding of the process of process
modeling. We believe that combining different views on the process of process
modeling constitutes another building block in understanding this process that
will ultimately enable us to support modelers in creating better process
models.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1511.04057</dc:description>
 <dc:date>2015-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04121</dc:identifier>
 <dc:identifier>Proc. ER-BPM'12, pp. 438-450, 2013</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-36285-9_46</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04123</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weight Balancing on Boundaries and Skeletons</dc:title>
 <dc:creator>Barba, Luis</dc:creator>
 <dc:creator>Cheong, Otfried</dc:creator>
 <dc:creator>De Carufel, Jean Lou</dc:creator>
 <dc:creator>Dobbins, Michael Gene</dc:creator>
 <dc:creator>Fleischer, Rudolf</dc:creator>
 <dc:creator>Kawamura, Akitoshi</dc:creator>
 <dc:creator>Korman, Matias</dc:creator>
 <dc:creator>Okamoto, Yoshio</dc:creator>
 <dc:creator>Pach, Janos</dc:creator>
 <dc:creator>Tang, Yuan</dc:creator>
 <dc:creator>Tokuyama, Takeshi</dc:creator>
 <dc:creator>Verdonschot, Sander</dc:creator>
 <dc:creator>Wang, Tianhao</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a polygonal region containing a target point (which we assume is the
origin), it is not hard to see that there are two points on the perimeter that
are antipodal, i.e., whose midpoint is the origin. We prove three
generalizations of this fact. (1) For any polygon (or any bounded closed region
with connected boundary) containing the origin, it is possible to place a given
set of weights on the boundary so that their barycenter (center of mass)
coincides with the origin, provided that the largest weight does not exceed the
sum of the other weights. (2) On the boundary of any $3$-dimensional bounded
polyhedron containing the origin, there exist three points that form an
equilateral triangle centered at the origin. (3) On the $1$-skeleton of any
$3$-dimensional bounded convex polyhedron containing the origin, there exist
three points whose center of mass coincides with the origin.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2015-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04126</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Alignment-Aided Base Station Clustering using Coalition
  Formation</dc:title>
 <dc:creator>Brandt, Rasmus</dc:creator>
 <dc:creator>Mochaourab, Rami</dc:creator>
 <dc:creator>Bengtsson, Mats</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Base station clustering is necessary in large interference networks, where
the channel state information (CSI) acquisition overhead otherwise would be
overwhelming. In this paper, we propose a novel long-term throughput model for
the clustered users which addresses the balance between interference mitigation
capability and CSI acquisition overhead. The model only depends on statistical
CSI, thus enabling long-term clustering. Based on notions from coalitional game
theory, we propose a low-complexity distributed clustering method. The
algorithm converges in a couple of iterations, and only requires limited
communication between base stations. Numerical simulations show the viability
of the proposed approach.
</dc:description>
 <dc:description>Comment: 2nd Prize, Student Paper Contest. Copyright 2015 SS&amp;C. Published in
  the Proceedings of the 49th Asilomar Conference on Signals, Systems and
  Computers, Nov 8-11, 2015, Pacific Grove, CA, USA</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04126</dc:identifier>
 <dc:identifier>doi:10.1109/ACSSC.2015.7421307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04134</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Whom Should We Sense in &quot;Social Sensing&quot; -- Analyzing Which Users Work
  Best for Social Media Now-Casting</dc:title>
 <dc:creator>An, Jisun</dc:creator>
 <dc:creator>Weber, Ingmar</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Given the ever increasing amount of publicly available social media data,
there is growing interest in using online data to study and quantify phenomena
in the offline &quot;real&quot; world. As social media data can be obtained in near
real-time and at low cost, it is often used for &quot;now-casting&quot; indices such as
levels of flu activity or unemployment. The term &quot;social sensing&quot; is often used
in this context to describe the idea that users act as &quot;sensors&quot;, publicly
reporting their health status or job losses. Sensor activity during a time
period is then typically aggregated in a &quot;one tweet, one vote&quot; fashion by
simply counting. At the same time, researchers readily admit that social media
users are not a perfect representation of the actual population. Additionally,
users differ in the amount of details of their personal lives that they reveal.
Intuitively, it should be possible to improve now-casting by assigning
different weights to different user groups.
  In this paper, we ask &quot;How does social sensing actually work?&quot; or, more
precisely, &quot;Whom should we sense--and whom not--for optimal results?&quot;. We
investigate how different sampling strategies affect the performance of
now-casting of two common offline indices: flu activity and unemployment rate.
We show that now-casting can be improved by 1) applying user filtering
techniques and 2) selecting users with complete profiles. We also find that,
using the right type of user groups, now-casting performance does not degrade,
even when drastically reducing the size of the dataset. More fundamentally, we
describe which type of users contribute most to the accuracy by asking if
&quot;babblers are better&quot;. We conclude the paper by providing guidance on how to
select better user groups for more accurate now-casting.
</dc:description>
 <dc:description>Comment: This is a pre-print of a forthcoming EPJ Data Science paper</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04136</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and
  Tracking</dc:title>
 <dc:creator>Wen, Longyin</dc:creator>
 <dc:creator>Du, Dawei</dc:creator>
 <dc:creator>Cai, Zhaowei</dc:creator>
 <dc:creator>Lei, Zhen</dc:creator>
 <dc:creator>Chang, Ming-Ching</dc:creator>
 <dc:creator>Qi, Honggang</dc:creator>
 <dc:creator>Lim, Jongwoo</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:creator>Lyu, Siwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, numerous effective multi-object tracking (MOT) methods are
developed because of the wide range of applications. Existing performance
evaluations of MOT methods usually separate the object tracking step from the
object detection step by using the same fixed object detection results for
comparisons. In this work, we perform a comprehensive quantitative study on the
effects of object detection accuracy to the overall MOT performance, using the
new large-scale University at Albany DETection and tRACking (UA-DETRAC)
benchmark dataset. The UA-DETRAC benchmark dataset consists of 100 challenging
video sequences captured from real-world traffic scenes (over 140,000 frames
with rich annotations, including occlusion, weather, vehicle category,
truncation, and vehicle bounding boxes) for object detection, object tracking
and MOT system. We evaluate complete MOT systems constructed from combinations
of state-of-the-art object detection and object tracking methods. Our analysis
shows the complex effects of object detection accuracy on MOT system
performance. Based on these observations, we propose new evaluation tools and
metrics for MOT systems that consider both object detection and object tracking
for comprehensive analysis.
</dc:description>
 <dc:description>Comment: 18 pages, 11 figures</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04137</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seeing the Unseen Network: Inferring Hidden Social Ties from
  Respondent-Driven Sampling</dc:title>
 <dc:creator>Chen, Lin</dc:creator>
 <dc:creator>Crawford, Forrest W.</dc:creator>
 <dc:creator>Karbasi, Amin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning about the social structure of hidden and hard-to-reach populations
--- such as drug users and sex workers --- is a major goal of epidemiological
and public health research on risk behaviors and disease prevention.
Respondent-driven sampling (RDS) is a peer-referral process widely used by many
health organizations, where research subjects recruit other subjects from their
social network. In such surveys, researchers observe who recruited whom, along
with the time of recruitment and the total number of acquaintances (network
degree) of respondents. However, due to privacy concerns, the identities of
acquaintances are not disclosed. In this work, we show how to reconstruct the
underlying network structure through which the subjects are recruited. We
formulate the dynamics of RDS as a continuous-time diffusion process over the
underlying graph and derive the likelihood for the recruitment time series
under an arbitrary recruitment time distribution. We develop an efficient
stochastic optimization algorithm called RENDER (REspoNdent-Driven nEtwork
Reconstruction) that finds the network that best explains the collected data.
We support our analytical results through an exhaustive set of experiments on
both synthetic and real data.
</dc:description>
 <dc:description>Comment: A full version with technical proofs. Accepted by AAAI-16</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04143</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning in Parameterized Action Space</dc:title>
 <dc:creator>Hausknecht, Matthew</dc:creator>
 <dc:creator>Stone, Peter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent work has shown that deep neural networks are capable of approximating
both value functions and policies in reinforcement learning domains featuring
continuous state and action spaces. However, to the best of our knowledge no
previous work has succeeded at using deep neural networks in structured
(parameterized) continuous action spaces. To fill this gap, this paper focuses
on learning within the domain of simulated RoboCup soccer, which features a
small set of discrete action types, each of which is parameterized with
continuous variables. The best learned agent can score goals more reliably than
the 2012 RoboCup champion agent. As such, this paper represents a successful
extension of deep reinforcement learning to the class of parameterized action
space MDPs.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04145</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Continuous-time Mutually-Exciting Point Process Framework for
  Prioritizing Events in Social Media</dc:title>
 <dc:creator>Farajtabar, Mehrdad</dc:creator>
 <dc:creator>Yousefi, Safoora</dc:creator>
 <dc:creator>Tran, Long Q.</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The overwhelming amount and rate of information update in online social media
is making it increasingly difficult for users to allocate their attention to
their topics of interest, thus there is a strong need for prioritizing news
feeds. The attractiveness of a post to a user depends on many complex
contextual and temporal features of the post. For instance, the contents of the
post, the responsiveness of a third user, and the age of the post may all have
impact. So far, these static and dynamic features has not been incorporated in
a unified framework to tackle the post prioritization problem. In this paper,
we propose a novel approach for prioritizing posts based on a feature modulated
multi-dimensional point process. Our model is able to simultaneously capture
textual and sentiment features, and temporal features such as self-excitation,
mutual-excitation and bursty nature of social interaction. As an evaluation, we
also curated a real-world conversational benchmark dataset crawled from
Facebook. In our experiments, we demonstrate that our algorithm is able to
achieve the-state-of-the-art performance in terms of analyzing, predicting, and
prioritizing events. In terms of interpretability of our method, we observe
that features indicating individual user profile and linguistic characteristics
of the events work best for prediction and prioritization of new events.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04145</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04150</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Mean Maps</dc:title>
 <dc:creator>Oliva, Junier B.</dc:creator>
 <dc:creator>Sutherland, Dougal J.</dc:creator>
 <dc:creator>P&#xf3;czos, Barnab&#xe1;s</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The use of distributions and high-level features from deep architecture has
become commonplace in modern computer vision. Both of these methodologies have
separately achieved a great deal of success in many computer vision tasks.
However, there has been little work attempting to leverage the power of these
to methodologies jointly. To this end, this paper presents the Deep Mean Maps
(DMMs) framework, a novel family of methods to non-parametrically represent
distributions of features in convolutional neural network models.
  DMMs are able to both classify images using the distribution of top-level
features, and to tune the top-level features for performing this task. We show
how to implement DMMs using a special mean map layer composed of typical CNN
operations, making both forward and backward propagation simple.
  We illustrate the efficacy of DMMs at analyzing distributional patterns in
image data in a synthetic data experiment. We also show that we extending
existing deep architectures with DMMs improves the performance of existing CNNs
on several challenging real-world datasets.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04153</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Affinity Matrix for Unsupervised Metric Learning</dc:title>
 <dc:creator>Li, Yaoyi</dc:creator>
 <dc:creator>Chen, Junxuan</dc:creator>
 <dc:creator>Lu, Hongtao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Spectral clustering is one of the most popular clustering approaches with the
capability to handle some challenging clustering problems. Most spectral
clustering methods provide a nonlinear map from the data manifold to a
subspace. Only a little work focuses on the explicit linear map which can be
viewed as the unsupervised distance metric learning. In practice, the selection
of the affinity matrix exhibits a tremendous impact on the unsupervised
learning. While much success of affinity learning has been achieved in recent
years, some issues such as noise reduction remain to be addressed. In this
paper, we propose a novel method, dubbed Adaptive Affinity Matrix (AdaAM), to
learn an adaptive affinity matrix and derive a distance metric from the
affinity. We assume the affinity matrix to be positive semidefinite with
ability to quantify the pairwise dissimilarity. Our method is based on posing
the optimization of objective function as a spectral decomposition problem. We
yield the affinity from both the original data distribution and the widely-used
heat kernel. The provided matrix can be regarded as the optimal representation
of pairwise relationship on the manifold. Extensive experiments on a number of
real-world data sets show the effectiveness and efficiency of AdaAM.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04153</dc:identifier>
 <dc:identifier>doi:10.1109/ICME.2016.7552887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04156</identifier>
 <datestamp>2016-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neuroprosthetic decoder training as imitation learning</dc:title>
 <dc:creator>Merel, Josh</dc:creator>
 <dc:creator>Carlson, David</dc:creator>
 <dc:creator>Paninski, Liam</dc:creator>
 <dc:creator>Cunningham, John P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Neuroprosthetic brain-computer interfaces function via an algorithm which
decodes neural activity of the user into movements of an end effector, such as
a cursor or robotic arm. In practice, the decoder is often learned by updating
its parameters while the user performs a task. When the user's intention is not
directly observable, recent methods have demonstrated value in training the
decoder against a surrogate for the user's intended movement. We describe how
training a decoder in this way is a novel variant of an imitation learning
problem, where an oracle or expert is employed for supervised training in lieu
of direct observations, which are not available. Specifically, we describe how
a generic imitation learning meta-algorithm, dataset aggregation (DAgger, [1]),
can be adapted to train a generic brain-computer interface. By deriving
existing learning algorithms for brain-computer interfaces in this framework,
we provide a novel analysis of regret (an important metric of learning
efficacy) for brain-computer interfaces. This analysis allows us to
characterize the space of algorithmic variants and bounds on their regret
rates. Existing approaches for decoder learning have been performed in the
cursor control setting, but the available design principles for these decoders
are such that it has been impossible to scale them to naturalistic settings.
Leveraging our findings, we then offer an algorithm that combines imitation
learning with optimal control, which should allow for training of arbitrary
effectors for which optimal control can generate goal-oriented control. We
demonstrate this novel and general BCI algorithm with simulated neuroprosthetic
control of a 26 degree-of-freedom model of an arm, a sophisticated and
realistic end effector.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04156</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pcbi.1004948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04158</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aadhaar-Based Unified Payment Solution</dc:title>
 <dc:creator>Bagaria, Sankalp</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In this paper, we propose to build an Aadhaar Based Unified Payment Solution.
The key idea is that a virtual wallet will be linked to the Aadhaar card number
of the customer. After that, any identification unique to the person and linked
with the Aadhaar card, be it something the person knows like secret
Internet-banking password, be it something s/he carries like debit card/ credit
card, something s/he owns like fingerprints, voice, email-id or somewhere s/he
is like house or office address, can be used for money transfer from the
sender's Aadhaar card linked virtual wallet to the receiver's Aadhaar card
linked virtual wallet, whose any unique ID is known to the sender. If the
sender knows the receiver's email-id, s/he can transfer money to his/ her
Aadhaar card linked virtual wallet using the email-id. And, if the sender knows
receiver's mobile number but not email-id, s/he can use the mobile number to
transfer the money to his/ her Aadhaar card linked virtual wallet. And so on.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04160</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voter Models and External Influence</dc:title>
 <dc:creator>Majmudar, Jimit</dc:creator>
 <dc:creator>Krone, Stephen M.</dc:creator>
 <dc:creator>Baumgaertner, Bert O.</dc:creator>
 <dc:creator>Tyson, Rebecca C.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  In this paper, we extend the voter model (VM) and the threshold voter model
(TVM) to include external influences modelled as a jump process. We study the
newly-formulated models both analytically and computationally, employing
diffusion approximations and mean field approximations. We derive results
pertaining to the probability of reaching consensus on a particular opinion and
also the expected consensus time. We find that although including an external
influence leads to a faster consensus in general, this effect is more
pronounced in the VM as compared to the TVM. Our findings suggest the potential
importance of &quot;macro-level&quot; phenomena such as the external influences as
compared to &quot;micro-level&quot; local interactions.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, preprint</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04164</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Object Retrieval</dc:title>
 <dc:creator>Hu, Ronghang</dc:creator>
 <dc:creator>Xu, Huazhe</dc:creator>
 <dc:creator>Rohrbach, Marcus</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we address the task of natural language object retrieval, to
localize a target object within a given image based on a natural language query
of the object. Natural language object retrieval differs from text-based image
retrieval task as it involves spatial information about objects within the
scene and global scene context. To address this issue, we propose a novel
Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate
boxes for object retrieval, integrating spatial configurations and global
scene-level contextual information into the network. Our model processes query
text, local image descriptors, spatial configurations and global context
features through a recurrent network, outputs the probability of the query text
conditioned on each candidate box as a score for the box, and can transfer
visual-linguistic knowledge from image captioning domain to our task.
Experimental results demonstrate that our method effectively utilizes both
local and global information, outperforming previous baseline methods
significantly on different datasets and scenarios, and can exploit large scale
vision and language datasets for knowledge transfer.
</dc:description>
 <dc:description>Comment: Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition, 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04166</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Edges</dc:title>
 <dc:creator>Li, Yin</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:creator>Rehg, James M.</dc:creator>
 <dc:creator>Doll&#xe1;r, Piotr</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Data-driven approaches for edge detection have proven effective and achieve
top results on modern benchmarks. However, all current data-driven edge
detectors require manual supervision for training in the form of hand-labeled
region segments or object boundaries. Specifically, human annotators mark
semantically meaningful edges which are subsequently used for training. Is this
form of strong, high-level supervision actually necessary to learn to
accurately detect edges? In this work we present a simple yet effective
approach for training edge detectors without human supervision. To this end we
utilize motion, and more specifically, the only input to our method is noisy
semi-dense matches between frames. We begin with only a rudimentary knowledge
of edges (in the form of image gradients), and alternate between improving
motion estimation and edge detection in turn. Using a large corpus of video
data, we show that edge detectors trained using our unsupervised scheme
approach the performance of the same methods trained with full supervision
(within 3-5%). Finally, we show that when using a deep network for the edge
detector, our approach provides a novel pre-training scheme for object
detection.
</dc:description>
 <dc:description>Comment: Camera ready version for CVPR 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04169</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Specifying a Realistic File System</dc:title>
 <dc:creator>Amani, Sidney</dc:creator>
 <dc:creator>Murray, Toby</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  We present the most interesting elements of the correctness specification of
BilbyFs, a performant Linux flash file system. The BilbyFs specification
supports asynchronous writes, a feature that has been overlooked by several
file system verification projects, and has been used to verify the correctness
of BilbyFs's fsync() C implementation. It makes use of nondeterminism to be
concise and is shallowly-embedded in higher-order logic.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04169</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 1-9</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04170</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlled Owicki-Gries Concurrency: Reasoning about the Preemptible
  eChronos Embedded Operating System</dc:title>
 <dc:creator>Andronick, June</dc:creator>
 <dc:creator>Lewis, Corey</dc:creator>
 <dc:creator>Morgan, Carroll</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  We introduce a controlled concurrency framework, derived from the
Owicki-Gries method, for describing a hardware interface in detail sufficient
to support the modelling and verification of small, embedded operating systems
(OS's) whose run-time responsiveness is paramount. Such real-time systems run
with interrupts mostly enabled, including during scheduling. That differs from
many other successfully modelled and verified OS's that typically reduce the
complexity of concurrency by running on uniprocessor platforms and by switching
interrupts off as much as possible. Our framework builds on the traditional
Owicki-Gries method, for its fine-grained concurrency is needed for
high-performance system code. We adapt it to support explicit concurrency
control, by providing a simple, faithful representation of the hardware
interface that allows software to control the degree of interleaving between
user code, OS code, interrupt handlers and a scheduler that controls context
switching. We then apply this framework to model the interleaving behavior of
the eChronos OS, a preemptible real-time OS for embedded micro-controllers. We
discuss the accuracy and usability of our approach when instantiated to model
the eChronos OS. Both our framework and the eChronos model are formalised in
the Isabelle/HOL theorem prover, taking advantage of the high level of
automation in modern reasoning tools.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04170</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 10-24</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04171</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Control of Self-Balancing Unicycles</dc:title>
 <dc:creator>Freiberger, Felix</dc:creator>
 <dc:creator>Hermanns, Holger</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper discusses the problem of designing a self-balancing unicycle where
pedals are used for both power generation and speed control. After developing
the principal physical aspects (in the longitudinal dimension), we describe an
abstract model in the form of a collection of hybrid automata, together with
design requirements to be met by an ideal controller. We discuss
simplifications and assumptions that make this model amenable to verification
and validation tools such as SpaceEx. To enable experimentation with different
prototypical controllers and user behaviours in concrete scenarios, we also
develop a simple simulation framework using digital time.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04171</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 25-36</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04172</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timed Automata for Modelling Caches and Pipelines</dc:title>
 <dc:creator>Cassez, Franck</dc:creator>
 <dc:creator>Marug&#xe1;n, Pablo Gonz&#xe1;lez de Aledo</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In this paper, we focus on modelling the timing aspects of binary programs
running on architectures featuring caches and pipelines. The objective is to
obtain a timed automaton model to compute tight bounds for the worst-case
execution time (WCET) of the programs using model-checking techniques.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04172</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 37-45</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04173</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Verification of the Bitcoin Protocol</dc:title>
 <dc:creator>Chaudhary, Kaylash</dc:creator>
 <dc:creator>Fehnker, Ansgar</dc:creator>
 <dc:creator>van de Pol, Jaco</dc:creator>
 <dc:creator>Stoelinga, Marielle</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Bitcoin is a popular digital currency for online payments, realized as a
decentralized peer-to-peer electronic cash system. Bitcoin keeps a ledger of
all transactions; the majority of the participants decides on the correct
ledger. Since there is no trusted third party to guard against double spending,
and inspired by its popularity, we would like to investigate the correctness of
the Bitcoin protocol. Double spending is an important threat to electronic
payment systems. Double spending would happen if one user could force a
majority to believe that a ledger without his previous payment is the correct
one. We are interested in the probability of success of such a double spending
attack, which is linked to the computational power of the attacker. This paper
examines the Bitcoin protocol and provides its formalization as an UPPAAL
model. The model will be used to show how double spending can be done if the
parties in the Bitcoin protocol behave maliciously, and with what probability
double spending occurs.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04173</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 46-60</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04174</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Specification and Verification of Fully Asynchronous
  Implementations of the Data Encryption Standard</dc:title>
 <dc:creator>Serwe, Wendelin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents two formal models of the Data Encryption Standard (DES),
a first using the international standard LOTOS, and a second using the more
recent process calculus LNT. Both models encode the DES in the style of
asynchronous circuits, i.e., the data-flow blocks of the DES algorithm are
represented by processes communicating via rendezvous. To ensure correctness of
the models, several techniques have been applied, including model checking,
equivalence checking, and comparing the results produced by a prototype
automatically generated from the formal model with those of existing
implementations of the DES. The complete code of the models is provided as
appendices and also available on the website of the CADP verification toolbox.
</dc:description>
 <dc:description>Comment: In Proceedings MARS 2015, arXiv:1511.02528</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04174</dc:identifier>
 <dc:identifier>EPTCS 196, 2015, pp. 61-147</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.196.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04176</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence to Sequence Learning for Optical Character Recognition</dc:title>
 <dc:creator>Sahu, Devendra Kumar</dc:creator>
 <dc:creator>Sukhwani, Mohak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an end-to-end recurrent encoder-decoder based sequence learning
approach for printed text Optical Character Recognition (OCR). In contrast to
present day existing state-of-art OCR solution which uses connectionist
temporal classification (CTC) output layer, our approach makes minimalistic
assumptions on the structure and length of the sequence. We use a two step
encoder-decoder approach -- (a) A recurrent encoder reads a variable length
printed text word image and encodes it to a fixed dimensional embedding. (b)
This fixed dimensional embedding is subsequently comprehended by decoder
structure which converts it into a variable length text output. Our
architecture gives competitive performance relative to connectionist temporal
classification (CTC) output layer while being executed in more natural
settings. The learnt deep word image embedding from encoder can be used for
printed text based retrieval systems. The expressive fixed dimensional
embedding for any variable length input expedites the task of retrieval and
makes it more efficient which is not possible with other recurrent neural
network architectures. We empirically investigate the expressiveness and the
learnability of long short term memory (LSTMs) in the sequence to sequence
learning regime by training our network for prediction tasks in segmentation
free printed text OCR. The utility of the proposed architecture for printed
text is demonstrated by quantitative and qualitative evaluation of two tasks --
word prediction and retrieval.
</dc:description>
 <dc:description>Comment: 9 pages (including reference), 6 figures (including subfigures), 5
  tables</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2015-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04177</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Automated Generation of Focused Proof Systems</dc:title>
 <dc:creator>Nigam, Vivek</dc:creator>
 <dc:creator>Reis, Giselle</dc:creator>
 <dc:creator>Lima, Leonardo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This paper tackles the problem of formulating and proving the completeness of
focused-like proof systems in an automated fashion. Focusing is a discipline on
proofs which structures them into phases in order to reduce proof search
non-determinism. We demonstrate that it is possible to construct a complete
focused proof system from a given un-focused proof system if it satisfies some
conditions. Our key idea is to generalize the completeness proof based on
permutation lemmas given by Miller and Saurin for the focused linear logic
proof system. This is done by building a graph from the rule permutation
relation of a proof system, called permutation graph. We then show that from
the permutation graph of a given proof system, it is possible to construct a
complete focused proof system, and additionally infer for which formulas
contraction is admissible. An implementation for building the permutation graph
of a system is provided. We apply our technique to generate the focused proof
systems MALLF, LJF and LKF for linear, intuitionistic and classical logics,
respectively.
</dc:description>
 <dc:description>Comment: In Proceedings WoF'15, arXiv:1511.02529</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04177</dc:identifier>
 <dc:identifier>EPTCS 197, 2015, pp. 1-6</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.197.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04178</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proof Outlines as Proof Certificates: A System Description</dc:title>
 <dc:creator>Blanco, Roberto</dc:creator>
 <dc:creator>Miller, Dale</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We apply the foundational proof certificate (FPC) framework to the problem of
designing high-level outlines of proofs. The FPC framework provides a means to
formally define and check a wide range of proof evidence. A focused proof
system is central to this framework and such a proof system provides an
interesting approach to proof reconstruction during the process of proof
checking (relying on an underlying logic programming implementation). Here, we
illustrate how the FPC framework can be used to design proof outlines and then
to exploit proof checkers as a means for expanding outlines into fully detailed
proofs. In order to validate this approach to proof outlines, we have built the
ACheck system that allows us to take a sequence of theorems and apply the proof
outline &quot;do the obvious induction and close the proof using previously proved
lemmas&quot;.
</dc:description>
 <dc:description>Comment: In Proceedings WoF'15, arXiv:1511.02529</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04178</dc:identifier>
 <dc:identifier>EPTCS 197, 2015, pp. 7-14</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.197.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04179</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realisability semantics of abstract focussing, formalised</dc:title>
 <dc:creator>Graham-Lengrand, St&#xe9;phane</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a sequent calculus for abstract focussing, equipped with
proof-terms: in the tradition of Zeilberger's work, logical connectives and
their introduction rules are left as a parameter of the system, which collapses
the synchronous and asynchronous phases of focussing as macro rules. We go
further by leaving as a parameter the operation that extends a context of
hypotheses with new ones, which allows us to capture both classical and
intuitionistic focussed sequent calculi. We then define the realisability
semantics of (the proofs of) the system, on the basis of Munch-Maccagnoni's
orthogonality models for the classical focussed sequent calculus, but now
operating at the higher level of abstraction mentioned above. We prove, at that
level, the Adequacy Lemma, namely that if a term is of type A, then in the
model its denotation is in the (set-theoretic) interpretation of A. This
exhibits the fact that the universal quantification involved when taking the
orthogonal of a set, reflects in the semantics Zeilberger's universal
quantification in the macro rule for the asynchronous phase. The system and its
semantics are all formalised in Coq.
</dc:description>
 <dc:description>Comment: In Proceedings WoF'15, arXiv:1511.02529</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04179</dc:identifier>
 <dc:identifier>EPTCS 197, 2015, pp. 15-28</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.197.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04180</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiplicative-Additive Focusing for Parsing as Deduction</dc:title>
 <dc:creator>Morrill, Glyn</dc:creator>
 <dc:creator>Valent&#xed;n, Oriol</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Spurious ambiguity is the phenomenon whereby distinct derivations in grammar
may assign the same structural reading, resulting in redundancy in the parse
search space and inefficiency in parsing. Understanding the problem depends on
identifying the essential mathematical structure of derivations. This is
trivial in the case of context free grammar, where the parse structures are
ordered trees; in the case of categorial grammar, the parse structures are
proof nets. However, with respect to multiplicatives intrinsic proof nets have
not yet been given for displacement calculus, and proof nets for additives,
which have applications to polymorphism, are involved. Here we approach
multiplicative-additive spurious ambiguity by means of the proof-theoretic
technique of focalisation.
</dc:description>
 <dc:description>Comment: In Proceedings WoF'15, arXiv:1511.02529</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04180</dc:identifier>
 <dc:identifier>EPTCS 197, 2015, pp. 29-54</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.197.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04190</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Choosing Committees Based on Approval Votes in the Presence of
  Outliers</dc:title>
 <dc:creator>Dey, Palash</dc:creator>
 <dc:creator>Misra, Neeldhara</dc:creator>
 <dc:creator>Narahari, Y.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the computational complexity of committee selection problem for
several approval-based voting rules in the presence of outliers. Our first
result shows that outlier consideration makes committee selection problem
intractable for approval, net approval, and minisum approval voting rules. We
then study parameterized complexity of this problem with five natural
parameters, namely the target score, the size of the committee (and its dual
parameter, the number of candidates outside the committee), the number of
outliers (and its dual parameter, the number of non-outliers). For net approval
and minisum approval voting rules, we provide a dichotomous result, resolving
the parameterized complexity of this problem for all subsets of five natural
parameters considered (by showing either FPT or W[1]-hardness for all subsets
of parameters). For the approval voting rule, we resolve the parameterized
complexity of this problem for all subsets of parameters except one.
  We also study approximation algorithms for this problem. We show that there
does not exist any alpha(.) factor approximation algorithm for approval and net
approval voting rules, for any computable function alpha(.), unless P=NP. For
the minisum voting rule, we provide a pseudopolynomial (1+eps) factor
approximation algorithm.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04191</identifier>
 <datestamp>2016-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Monotone Measure of Correlation</dc:title>
 <dc:creator>Etesami, Omid</dc:creator>
 <dc:creator>Gohari, Amin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Based on the notion of maximal correlation, Kimeldorf, May and Sampson (1980)
introduce a measure of correlation between two random variables, called the
&quot;concordant monotone correlation&quot; (CMC). We revisit, generalize and prove new
properties of this measure of correlation. It is shown that CMC captures
various types of correlation detected in measures of rank correlation like the
Kendall tau correlation. We show that the CMC satisfies the data processing and
tensorization properties (that make ordinary maximal correlation applicable to
problems in information theory). Furthermore, CMC is shown to be intimately
related to the FKG inequality. Furthermore, a combinatorical application of CMC
is given for which we do not know of another method to derive its result.
Finally, we study the problem of the complexity of the computation of the CMC,
which is a non-convex optimization problem with local maximas. We give a simple
but exponential-time algorithm that is guaranteed to output the exact value of
the generalized CMC.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-06-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04191</dc:identifier>
 <dc:identifier>IEEE Communication Letters, 2015, Volume 20, Issue 1, Pages 17-20</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2015.2501287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04192</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DISC: Deep Image Saliency Computing via Progressive Representation
  Learning</dc:title>
 <dc:creator>Chen, Tianshui</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Liu, Lingbo</dc:creator>
 <dc:creator>Luo, Xiaonan</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Salient object detection increasingly receives attention as an important
component or step in several pattern recognition and image processing tasks.
Although a variety of powerful saliency models have been intensively proposed,
they usually involve heavy feature (or model) engineering based on priors (or
assumptions) about the properties of objects and backgrounds. Inspired by the
effectiveness of recently developed feature learning, we provide a novel Deep
Image Saliency Computing (DISC) framework for fine-grained image saliency
computing. In particular, we model the image saliency from both the coarse- and
fine-level observations, and utilize the deep convolutional neural network
(CNN) to learn the saliency representation in a progressive manner.
Specifically, our saliency model is built upon two stacked CNNs. The first CNN
generates a coarse-level saliency map by taking the overall image as the input,
roughly identifying saliency regions in the global context. Furthermore, we
integrate superpixel-based local context information in the first CNN to refine
the coarse-level saliency map. Guided by the coarse saliency map, the second
CNN focuses on the local context to produce fine-grained and accurate saliency
map while preserving object details. For a testing image, the two CNNs
collaboratively conduct the saliency computing in one shot. Our DISC framework
is capable of uniformly highlighting the objects-of-interest from complex
background while preserving well object details. Extensive experiments on
several standard benchmarks suggest that DISC outperforms other
state-of-the-art methods and it also generalizes well across datasets without
additional training. The executable version of DISC is available online:
http://vision.sysu.edu.cn/projects/DISC.
</dc:description>
 <dc:description>Comment: This manuscript is the accepted version for IEEE Transactions on
  Neural Networks and Learning Systems (T-NNLS), 2015</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2015-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04192</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2015.2506664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04196</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure Inference Machines: Recurrent Neural Networks for Analyzing
  Relations in Group Activity Recognition</dc:title>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Vahdat, Arash</dc:creator>
 <dc:creator>Hu, Hexiang</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Rich semantic relations are important in a variety of visual recognition
problems. As a concrete example, group activity recognition involves the
interactions and relative spatial relations of a set of people in a scene.
State of the art recognition methods center on deep learning approaches for
training highly effective, complex classifiers for interpreting images.
However, bridging the relatively low-level concepts output by these methods to
interpret higher-level compositional scenes remains a challenge. Graphical
models are a standard tool for this task. In this paper, we propose a method to
integrate graphical models and deep neural networks into a joint framework.
Instead of using a traditional inference method, we use a sequential inference
modeled by a recurrent neural network. Beyond this, the appropriate structure
for inference can be learned by imposing gates on edges between nodes.
Empirical results on group activity recognition demonstrate the potential of
this model to handle highly structured learning tasks.
</dc:description>
 <dc:description>Comment: CVPR 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04197</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaboration Framework in the EViE-m Platform</dc:title>
 <dc:creator>Kapetanakis, Kostas</dc:creator>
 <dc:creator>Andrioti, Haroula</dc:creator>
 <dc:creator>Vonorta, Helen</dc:creator>
 <dc:creator>Zotos, Marios</dc:creator>
 <dc:creator>Tsigkos, Nikolaos</dc:creator>
 <dc:creator>Pachoulakis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.5.1</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:subject>I.3.8</dc:subject>
 <dc:description>  Within the context of a 3D interactive strategy game, the EViE platform
allows participants to unlock game features using their knowledge and skills in
various thematic areas such as physics, mathematics, etc. By answering
questions organized by Educational Objective in stratified levels of
difficulty, users gather points which grant them access to desired world
elements. Richer world components become increasingly more difficult to access,
so that a players' individual (or cumulative if in a group) knowledge, ability
and / or dexterity is directly reflected by the level of complication of their
virtual world. In the present article we report on the communication
architecture of the platform and focus on framework components that allow group
activities such as cooperation (within the group to facilitate e.g.,
collaboration on more difficult problems), (inter-group) competition as well as
practice and skill honing activities (in single or in multi-player mode).
</dc:description>
 <dc:description>Comment: 6 pages, 10 figures</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04197</dc:identifier>
 <dc:identifier>Proceedings of the 24th EAEEIE Annual Conference (EAEEIE'13),
  Chania, Greece, 30 - 31 of May, 2013 pgs 178-183</dc:identifier>
 <dc:identifier>doi:10.1109/EAEEIE.2013.6576525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04203</identifier>
 <datestamp>2016-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPEC, a real-time capable Tokamak equilibrium code</dc:title>
 <dc:creator>Rampp, Markus</dc:creator>
 <dc:creator>Preuss, Roland</dc:creator>
 <dc:creator>Fischer, Rainer</dc:creator>
 <dc:creator>Team, the ASDEX Upgrade</dc:creator>
 <dc:subject>Physics - Plasma Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  A new parallel equilibrium reconstruction code for tokamak plasmas is
presented. GPEC allows to compute equilibrium flux distributions sufficiently
accurate to derive parameters for plasma control within 1 ms of runtime which
enables real-time applications at the ASDEX Upgrade experiment (AUG) and other
machines with a control cycle of at least this size. The underlying algorithms
are based on the well-established offline-analysis code CLISTE, following the
classical concept of iteratively solving the Grad-Shafranov equation and
feeding in diagnostic signals from the experiment. The new code adopts a hybrid
parallelization scheme for computing the equilibrium flux distribution and
extends the fast, shared-memory-parallel Poisson solver which we have described
previously by a distributed computation of the individual Poisson problems
corresponding to different basis functions. The code is based entirely on
open-source software components and runs on standard server hardware and
software environments. The real-time capability of GPEC is demonstrated by
performing an offline-computation of a sequence of 1000 flux distributions
which are taken from one second of operation of a typical AUG discharge and
deriving the relevant control parameters with a time resolution of a
millisecond. On current server hardware the new code allows employing a grid
size of 32x64 zones for the spatial discretization and up to 15 basis
functions. It takes into account about 90 diagnostic signals while using up to
4 equilibrium iterations and computing more than 20 plasma-control parameters,
including the computationally expensive safety-factor q on at least 4 different
levels of the normalized flux.
</dc:description>
 <dc:description>Comment: minor typos corrected and reference updated, matches published
  version</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04203</dc:identifier>
 <dc:identifier>Fusion Science and Technology 70(1), 2016, 1-13</dc:identifier>
 <dc:identifier>doi:10.13182/FST15-154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04207</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acyclic colourings of graphs with bounded degree</dc:title>
 <dc:creator>Fiedorowicz, Anna</dc:creator>
 <dc:creator>Sidorowicz, El&#x17c;bieta</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C15</dc:subject>
 <dc:description>  A $k$-colouring (not necessarily proper) of vertices of a graph is called
{\it acyclic}, if for every pair of distinct colours $i$ and $j$ the subgraph
induced by the edges whose endpoints have colours $i$ and $j$ is acyclic. In
the paper we consider some generalised acyclic $k$-colourings, namely, we
require that each colour class induces an acyclic or bounded degree graph.
Mainly we focus on graphs with maximum degree 5. We prove that any such graph
has an acyclic $5$-colouring such that each colour class induces an acyclic
graph with maximum degree at most 4. We prove that the problem of deciding
whether a graph $G$ has an acyclic 2-colouring in which each colour class
induces a graph with maximum degree at most 3 is NP-complete, even for graphs
with maximum degree 5. We also give a linear-time algorithm for an acyclic
$t$-improper colouring of any graph with maximum degree $d$ assuming that the
number of colors is large enough.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04207</dc:identifier>
 <dc:identifier>doi:10.1007/s11425-016-5126-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04210</identifier>
 <datestamp>2016-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Quality of the Initial Basin in Overspecified Neural Networks</dc:title>
 <dc:creator>Safran, Itay</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning, in the form of artificial neural networks, has achieved
remarkable practical success in recent years, for a variety of difficult
machine learning applications. However, a theoretical explanation for this
remains a major open problem, since training neural networks involves
optimizing a highly non-convex objective function, and is known to be
computationally hard in the worst case. In this work, we study the
\emph{geometric} structure of the associated non-convex objective function, in
the context of ReLU networks and starting from a random initialization of the
network parameters. We identify some conditions under which it becomes more
favorable to optimization, in the sense of (i) High probability of initializing
at a point from which there is a monotonically decreasing path to a global
minimum; and (ii) High probability of initializing at a basin (suitably
defined) with a small minimal objective value. A common theme in our results is
that such properties are more likely to hold for larger (&quot;overspecified&quot;)
networks, which accords with some recent empirical and theoretical
observations.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04211</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Contextual Entropy Search</dc:title>
 <dc:creator>Metzen, Jan Hendrik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Contextual policy search allows adapting robotic movement primitives to
different situations. For instance, a locomotion primitive might be adapted to
different terrain inclinations or desired walking speeds. Such an adaptation is
often achievable by modifying a small number of hyperparameters. However,
learning, when performed on real robotic systems, is typically restricted to a
small number of trials. Bayesian optimization has recently been proposed as a
sample-efficient means for contextual policy search that is well suited under
these conditions. In this work, we extend entropy search, a variant of Bayesian
optimization, such that it can be used for active contextual policy search
where the agent selects those tasks during training in which it expects to
learn the most. Empirical results in simulation suggest that this allows
learning successful behavior with less trials.
</dc:description>
 <dc:description>Comment: Corrected title of reference #19</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04217</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Reproducibility in Parallel Computing</dc:title>
 <dc:creator>Hunold, Sascha</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We summarize the results of a survey on reproducibility in parallel
computing, which was conducted during the Euro-Par conference in August 2015.
The survey form was handed out to all participants of the conference and the
workshops. The questionnaire, which specifically targeted the parallel
computing community, contained questions in four different categories: general
questions on reproducibility, the current state of reproducibility, the
reproducibility of the participants' own papers, and questions about the
participants' familiarity with tools, software, or open-source software
licenses used for reproducible research.
</dc:description>
 <dc:description>Comment: 15 pages, 24 figures</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04224</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Procedural wood textures</dc:title>
 <dc:creator>Liu, Albert J.</dc:creator>
 <dc:creator>Marschner, Stephen R.</dc:creator>
 <dc:creator>Dye, Victoria E.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  Existing bidirectional reflectance distribution function (BRDF) models are
capable of capturing the distinctive highlights produced by the fibrous nature
of wood. However, capturing parameter textures for even a single specimen
remains a laborious process requiring specialized equipment. In this paper we
take a procedural approach to generating parameters for the wood BSDF. We
characterize the elements of trees that are important for the appearance of
wood, discuss techniques appropriate for representing those features, and
present a complete procedural wood shader capable of reproducing the growth
patterns responsible for the distinctive appearance of highly prized
``figured'' wood. Our procedural wood shader is random-access, 3D, modular, and
is fast enough to generate a preview for design.
</dc:description>
 <dc:description>Comment: This version: Increased resolution of images and added YouTube link
  to video</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04240</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Adaptive Data Representation for Robust Point-Set Registration and
  Merging</dc:title>
 <dc:creator>Campbell, Dylan</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a framework for rigid point-set registration and merging
using a robust continuous data representation. Our point-set representation is
constructed by training a one-class support vector machine with a Gaussian
radial basis function kernel and subsequently approximating the output function
with a Gaussian mixture model. We leverage the representation's sparse
parametrisation and robustness to noise, outliers and occlusions in an
efficient registration algorithm that minimises the L2 distance between our
support vector--parametrised Gaussian mixtures. In contrast, existing
techniques, such as Iterative Closest Point and Gaussian mixture approaches,
manifest a narrower region of convergence and are less robust to occlusions and
missing data, as demonstrated in the evaluation on a range of 2D and 3D
datasets. Finally, we present a novel algorithm, GMMerge, that parsimoniously
and equitably merges aligned mixture models, allowing the framework to be used
for reconstruction and mapping.
</dc:description>
 <dc:description>Comment: Manuscript in press 2015 IEEE International Conference on Computer
  Vision</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04240</dc:identifier>
 <dc:identifier>doi:10.1109/ICCV.2015.488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04242</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volume-based Semantic Labeling with Signed Distance Functions</dc:title>
 <dc:creator>Cavallari, Tommaso</dc:creator>
 <dc:creator>Di Stefano, Luigi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research works on the two topics of Semantic Segmentation and SLAM
(Simultaneous Localization and Mapping) have been following separate tracks.
Here, we link them quite tightly by delineating a category label fusion
technique that allows for embedding semantic information into the dense map
created by a volume-based SLAM algorithm such as KinectFusion. Accordingly, our
approach is the first to provide a semantically labeled dense reconstruction of
the environment from a stream of RGB-D images. We validate our proposal using a
publicly available semantically annotated RGB-D dataset and a) employing ground
truth labels, b) corrupting such annotations with synthetic noise, c) deploying
a state of the art semantic segmentation algorithm based on Convolutional
Neural Networks.
</dc:description>
 <dc:description>Comment: Submitted to PSIVT2015</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04244</identifier>
 <datestamp>2016-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Design for MISO Physical-Layer Multicasting over Line-of-Sight
  Channels</dc:title>
 <dc:creator>Yue, Man-Chung</dc:creator>
 <dc:creator>Wu, Sissi Xiaoxiao</dc:creator>
 <dc:creator>So, Anthony Man-Cho</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies a robust design problem for far-field line-of-sight (LOS)
channels where phase errors are present. Compared with the commonly used
additive error model, the phase error model is more suitable for capturing the
uncertainty in an LOS channel, as the dominant source of uncertainty lies in
the phase. We consider a multiple-input single-output (MISO) multicast
scenario, in which our goal is to design a beamformer that minimizes the
transmit power while satisfying probabilistic signal-to-noise ratio (SNR)
constraints. The probabilistic constraints give rise to a new computational
challenge, as they involve random trigonometric forms. In this work, we propose
to first approximate the random trigonometric form by its second-order Taylor
expansion and then tackle the resulting random quadratic form using a
Bernstein-type inequality. The advantage of such an approach is that an
approximately optimal beamformer can be obtained using the standard
semidefinite relaxation technique. In the simulations, we first show that if a
non-robust design (i.e., one that does not take phase errors into account) is
used, then the whole system may collapse. We then show that our proposed method
is less conservative than the existing robust design based on Gaussian
approximation and thus requires a lower power budget.
</dc:description>
 <dc:description>Comment: This manuscript is submitted for possible journal publication on
  13-Nov-2015</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04244</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2569600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04245</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Cooperation by Carrier Aggregation in Heterogeneous Networks: A
  Hierarchical Game Approach</dc:title>
 <dc:creator>Yuan, Pu</dc:creator>
 <dc:creator>Xiao, Yong</dc:creator>
 <dc:creator>Bi, Guoan</dc:creator>
 <dc:creator>Zhang, Liren</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper studies the resource allocation problem for a heterogeneous
network (HetNet) in which the spectrum owned by a macro-cell operator (MCO) can
be shared by both unlicensed users (UUs) and licensed users (LUs). We formulate
a novel hierarchical game theoretic framework to jointly optimize the transmit
powers and sub-band allocations of the UUs as well as the pricing strategies of
the MCO. In our framework, an overlapping coalition formation (OCF) game has
been introduced to model the cooperative behaviors of the UUs. We then
integrate this OCF game into a Stackelberg game-based hierarchical framework.
We prove that the core of our proposed OCF game is non-empty and introduce an
optimal sub-band allocation scheme for UUs. A simple distributed algorithm is
proposed for UUs to autonomously form optimal coalition formation structure.
The Stackelberg Equilibrium (SE) of the proposed hierarchical game is derived
and its uniqueness and optimality have been proved. A distributed joint
optimization algorithm is also proposed to approach the SE of the game with
limited information exchanges between the MCO and the UU.
</dc:description>
 <dc:description>Comment: 13 pages journal papaer</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04271</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canonicity and Relativized Canonicity via Pseudo-Correspondence: an
  Application of ALBA</dc:title>
 <dc:creator>Conradie, Willem</dc:creator>
 <dc:creator>Palmigiano, Alessandra</dc:creator>
 <dc:creator>Sourabh, Sumit</dc:creator>
 <dc:creator>Zhao, Zhiguang</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03B45, 06D50, 06D10, 03G10, 06E15</dc:subject>
 <dc:description>  We generalize Venema's result on the canonicity of the additivity of positive
terms, from classical modal logic to a vast class of logics the algebraic
semantics of which is given by varieties of normal distributive lattice
expansions (normal DLEs), aka `distributive lattices with operators'. We
provide two contrasting proofs for this result: the first is along the lines of
Venema's pseudo-correspondence argument but using the insights and tools of
unified correspondence theory, and in particular the algorithm ALBA; the second
closer to the style of J\'onsson. Using insights gleaned from the second proof,
we define a suitable enhancement of the algorithm ALBA, which we use prove the
canonicity of certain syntactically defined classes of DLE-inequalities (called
the meta-inductive inequalities), relative to the structures in which the
formulas asserting the additivity of some given terms are valid.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04273</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Assign Orientations to Feature Points</dc:title>
 <dc:creator>Yi, Kwang Moo</dc:creator>
 <dc:creator>Verdie, Yannick</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:creator>Lepetit, Vincent</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We show how to train a Convolutional Neural Network to assign a canonical
orientation to feature points given an image patch centered on the feature
point. Our method improves feature point matching upon the state-of-the art and
can be used in conjunction with any existing rotation sensitive descriptors. To
avoid the tedious and almost impossible task of finding a target orientation to
learn, we propose to use Siamese networks which implicitly find the optimal
orientations during training. We also propose a new type of activation function
for Neural Networks that generalizes the popular ReLU, maxout, and PReLU
activation functions. This novel activation performs better for our task. We
validate the effectiveness of our method extensively with four existing
datasets, including two non-planar datasets, as well as our own dataset. We
show that we outperform the state-of-the-art without the need of retraining for
each dataset.
</dc:description>
 <dc:description>Comment: Accepted as Oral presentation in Computer Vision and Pattern
  Recognition, 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04275</identifier>
 <datestamp>2015-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Index for SSRN Downloads</dc:title>
 <dc:creator>Kakushadze, Zura</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We propose a new index to quantify SSRN downloads. Unlike the SSRN downloads
rank, which is based on the total number of an author's SSRN downloads, our
index also reflects the author's productivity by taking into account the
download numbers for the papers. Our index is inspired by - but is not the same
as - Hirsch's h-index for citations, which cannot be directly applied to SSRN
downloads. We analyze data for about 30,000 authors and 367,000 papers. We find
a simple empirical formula for the SSRN author rank via a Gaussian function of
the log of the number of downloads.
</dc:description>
 <dc:description>Comment: 41 pages; minor misprints corrected, hyperlinks fixed; to appear in
  Journal of Informetrics</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2015-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04275</dc:identifier>
 <dc:identifier>Journal of Informetrics 10(1) (2016) 9-28</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04278</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Accuracy Real-Time Whole-Body Human Motion Tracking Based on
  Constrained Nonlinear Kalman Filtering</dc:title>
 <dc:creator>Steinbring, Jannik</dc:creator>
 <dc:creator>Mandery, Christian</dc:creator>
 <dc:creator>Vahrenkamp, Nikolaus</dc:creator>
 <dc:creator>Asfour, Tamim</dc:creator>
 <dc:creator>Hanebeck, Uwe D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a new online approach to track human whole-body motion from motion
capture data, i.e., positions of labeled markers attached to the human body.
Tracking in noisy data can be effectively performed with the aid of
well-established recursive state estimation techniques. This allows us to
systematically take noise of the marker measurements into account. However, as
joint limits imposed by the human body have to be satisfied during estimation,
first we transform this constrained estimation problem into an unconstrained
one by using periodic functions. Then, we apply the Smart Sampling Kalman
Filter to solve this unconstrained estimation problem. The proposed recursive
state estimation approach makes the human motion tracking very robust to
partial occlusion of markers and avoids any special treatment or reconstruction
of the missed markers. A concrete implementation built on the kinematic human
reference model of the Master Motor Map framework and a Vicon motion capture
system is evaluated. Different captured motions show that our implementation
can accurately estimate whole-body human motion in real-time and outperforms
existing gradient-based approaches. In addition, we demonstrate its ability to
smoothly handle incomplete marker data.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04285</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kilombo: a Kilobot simulator to enable effective research in swarm
  robotics</dc:title>
 <dc:creator>Jansson, Fredrik</dc:creator>
 <dc:creator>Hartley, Matthew</dc:creator>
 <dc:creator>Hinsch, Martin</dc:creator>
 <dc:creator>Slavkov, Ivica</dc:creator>
 <dc:creator>Carranza, Noem&#xed;</dc:creator>
 <dc:creator>Olsson, Tjelvar S. G.</dc:creator>
 <dc:creator>Dries, Roland M.</dc:creator>
 <dc:creator>Gr&#xf6;nqvist, Johanna H.</dc:creator>
 <dc:creator>Mar&#xe9;e, Athanasius F. M.</dc:creator>
 <dc:creator>Sharpe, James</dc:creator>
 <dc:creator>Kaandorp, Jaap A.</dc:creator>
 <dc:creator>Grieneisen, Ver&#xf4;nica A.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The Kilobot is a widely used platform for investigation of swarm robotics.
Physical Kilobots are slow moving and require frequent recalibration and
charging, which significantly slows down the development cycle. Simulators can
speed up the process of testing, exploring and hypothesis generation, but
usually require time consuming and error-prone translation of code between
simulator and robot. Moreover, code of different nature often obfuscates direct
comparison, as well as determination of the cause of deviation, between
simulator and actual robot swarm behaviour. To tackle these issues we have
developed a C-based simulator that allows those working with Kilobots to use
the same programme code in both the simulator and the physical robots. Use of
our simulator, coined Kilombo, significantly simplifies and speeds up
development, given that a simulation of 1000 robots can be run at a speed 100
times faster than real time on a desktop computer, making high-throughput
pre-screening possible of potential algorithms that could lead to desired
emergent behaviour. We argue that this strategy, here specifically developed
for Kilobots, is of general importance for effective robot swarm research. The
source code is freely available under the MIT license.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04303</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Evaluation of Distributed Node Coloring Algorithms for
  Wireless Networks</dc:title>
 <dc:creator>Fuchs, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we evaluate distributed node coloring algorithms for wireless
networks using the network simulator Sinalgo [by DCG@ETHZ]. All considered
algorithms operate in the realistic signal-to-interference-and-noise-ratio
(SINR) model of interference. We evaluate two recent coloring algorithms,
Rand4DColor and ColorReduction (in the following ColorRed), proposed by Fuchs
and Prutkin in [SIROCCO'15], the MW-Coloring algorithm introduced by Moscibroda
and Wattenhofer [DC'08] and transferred to the SINR model by Derbel and Talbi
[ICDCS'10], and a variant of the coloring algorithm of Yu et al. [TCS'14]. We
additionally consider several practical improvements to the algorithms and
evaluate their performance in both static and dynamic scenarios. Our
experiments show that Rand4DColor is very fast, computing a valid
(4Degree)-coloring in less than one third of the time slots required for local
broadcasting, where Degree is the maximum node degree in the network. Regarding
other O(Degree)-coloring algorithms Rand4DColor is at least 4 to 5 times
faster. Additionally, the algorithm is robust even in networks with mobile
nodes and an additional listening phase at the start of the algorithm makes
Rand4DColor robust against the late wake-up of large parts of the network.
Regarding (Degree+1)-coloring algorithms, we observe that ColorRed it is
significantly faster than the considered variant of the Yu et al. coloring
algorithm, which is the only other (Degree+1)-coloring algorithm for the SINR
model. Further improvement can be made with an error-correcting variant that
increases the runtime by allowing some uncertainty in the communication and
afterwards correcting the introduced conflicts.
</dc:description>
 <dc:description>Comment: Full version of paper accepted to ALENEX'16; 19 pages plus 12 pages
  appendix,</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04306</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Feature Learning for EEG Recordings</dc:title>
 <dc:creator>Stober, Sebastian</dc:creator>
 <dc:creator>Sternin, Avital</dc:creator>
 <dc:creator>Owen, Adrian M.</dc:creator>
 <dc:creator>Grahn, Jessica A.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce and compare several strategies for learning discriminative
features from electroencephalography (EEG) recordings using deep learning
techniques. EEG data are generally only available in small quantities, they are
high-dimensional with a poor signal-to-noise ratio, and there is considerable
variability between individual subjects and recording sessions. Our proposed
techniques specifically address these challenges for feature learning.
Cross-trial encoding forces auto-encoders to focus on features that are stable
across trials. Similarity-constraint encoders learn features that allow to
distinguish between classes by demanding that two trials from the same class
are more similar to each other than to trials from other classes. This
tuple-based training approach is especially suitable for small datasets.
Hydra-nets allow for separate processing pathways adapting to subsets of a
dataset and thus combine the advantages of individual feature learning (better
adaptation of early, low-level processing) with group model training (better
generalization of higher-level processing in deeper layers). This way, models
can, for instance, adapt to each subject individually to compensate for
differences in spatial patterns due to anatomical differences or variance in
electrode positions. The different techniques are evaluated using the publicly
available OpenMIIR dataset of EEG recordings taken while participants listened
to and imagined music.
</dc:description>
 <dc:description>Comment: submitted as conference paper for ICLR 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04308</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Cost Eye-Trackers: Useful for Information Systems Research?</dc:title>
 <dc:creator>Zugal, Stefan</dc:creator>
 <dc:creator>Pinggera, Jakob</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Research investigating cognitive aspects of information systems is often
dependent on detail-rich data. Eye-trackers promise to provide respective data,
but the associated costs are often beyond the researchers' budget. Recently,
eye-trackers have entered the market that promise eye-tracking support at a
reasonable price. In this work, we explore whether such eye-trackers are of use
for information systems research and explore the accuracy of a low-cost
eye-tracker (Gazepoint GP3) in an empirical study. The results show that
Gazepoint GP3 is well suited for respective research, given that experimental
material acknowledges the limits of the eye-tracker. To foster replication and
comparison of results, all data, experimental material as well as the source
code developed for this study are made available online.
</dc:description>
 <dc:date>2015-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04308</dc:identifier>
 <dc:identifier>S. Zugal and J. Pinggera: Low-Cost Eye-Trackers: Useful for
  Information Systems Research? In: Proc. Cognise'14, pp. 159-170, 2014</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-07869-4_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04317</identifier>
 <datestamp>2016-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel Feature Extraction, Selection and Fusion for Effective Malware
  Family Classification</dc:title>
 <dc:creator>Ahmadi, Mansour</dc:creator>
 <dc:creator>Ulyanov, Dmitry</dc:creator>
 <dc:creator>Semenov, Stanislav</dc:creator>
 <dc:creator>Trofimov, Mikhail</dc:creator>
 <dc:creator>Giacinto, Giorgio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Modern malware is designed with mutation characteristics, namely polymorphism
and metamorphism, which causes an enormous growth in the number of variants of
malware samples. Categorization of malware samples on the basis of their
behaviors is essential for the computer security community, because they
receive huge number of malware everyday, and the signature extraction process
is usually based on malicious parts characterizing malware families. Microsoft
released a malware classification challenge in 2015 with a huge dataset of near
0.5 terabytes of data, containing more than 20K malware samples. The analysis
of this dataset inspired the development of a novel paradigm that is effective
in categorizing malware variants into their actual family groups. This paradigm
is presented and discussed in the present paper, where emphasis has been given
to the phases related to the extraction, and selection of a set of novel
features for the effective representation of malware samples. Features can be
grouped according to different characteristics of malware behavior, and their
fusion is performed according to a per-class weighting paradigm. The proposed
method achieved a very high accuracy ($\approx$ 0.998) on the Microsoft Malware
Challenge dataset.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04320</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Standard methods for inexpensive pollen loads authentication by means of
  computer vision and machine learning</dc:title>
 <dc:creator>Chica, Manuel</dc:creator>
 <dc:creator>Campoy, Pascual</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a complete methodology for authenticating local bee pollen against
fraudulent samples using image processing and machine learning techniques. The
proposed standard methods do not need expensive equipment such as advanced
microscopes and can be used for a preliminary fast rejection of unknown pollen
types. The system is able to rapidly reject the non-local pollen samples with
inexpensive hardware and without the need to send the product to the
laboratory. Methods are based on the color properties of bee pollen loads
images and the use of one-class classifiers which are appropriate to reject
unknown pollen samples when there is limited data about them. The validation of
the method is carried out by authenticating Spanish bee pollen types.
Experimentation shows that the proposed methods can obtain an overall
authentication accuracy of 94%. We finally illustrate the user interaction with
the software in some practical cases by showing the developed application
prototype.
</dc:description>
 <dc:description>Comment: 24 pages. Book chapter to appear</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04326</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ICON Challenge on Algorithm Selection</dc:title>
 <dc:creator>Kotthoff, Lars</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We present the results of the ICON Challenge on Algorithm Selection.
</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04348</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Scale Artificial Neural Network Training Using Multi-GPUs</dc:title>
 <dc:creator>Wang, Linnan</dc:creator>
 <dc:creator>Wu, Wei</dc:creator>
 <dc:creator>Xiao, Jianxiong</dc:creator>
 <dc:creator>Yi, Yang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper describes a method for accelerating large scale Artificial Neural
Networks (ANN) training using multi-GPUs by reducing the forward and backward
passes to matrix multiplication. We propose an out-of-core multi-GPU matrix
multiplication and integrate the algorithm with the ANN training. The
experiments demonstrate that our matrix multiplication algorithm achieves
linear speedup on multiple inhomogeneous GPUs. The full paper of this project
can be found at [1].
</dc:description>
 <dc:description>Comment: SC 15 Poster</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04352</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduzione all'Intelligenza Artificiale</dc:title>
 <dc:creator>Riguzzi, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The paper presents an introduction to Artificial Intelligence (AI) in an
accessible and informal but precise form. The paper focuses on the algorithmic
aspects of the discipline, presenting the main techniques used in AI systems
groped in symbolic and subsymbolic. The last part of the paper is devoted to
the discussion ongoing among experts in the field and the public at large about
on the advantages and disadvantages of AI and in particular on the possible
dangers. The personal opinion of the author on this subject concludes the
paper.
  -----
  L'articolo presenta un'introduzione all'Intelligenza Artificiale (IA) in
forma divulgativa e informale ma precisa. L'articolo affronta prevalentemente
gli aspetti informatici della disciplina, presentando le principali tecniche
usate nei sistemi di IA divise in simboliche e subsimboliche. L'ultima parte
dell'articolo presenta il dibattito in corso tra gli esperi e il pubblico su
vantaggi e svantaggi dell'IA e in particolare sui possibili pericoli.
L'articolo termina con l'opinione dell'autore al riguardo.
</dc:description>
 <dc:description>Comment: 27 pages, in Italian</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04352</dc:identifier>
 <dc:identifier>Terre di Confine, 2(1), January 2006</dc:identifier>
 <dc:language>it</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04359</identifier>
 <datestamp>2016-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On cyclotomic cosets and code constructions</dc:title>
 <dc:creator>La Guardia, Giuliano Gadioli</dc:creator>
 <dc:creator>Alves, Marcelo Muniz Silva</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  New properties of $q$-ary cyclotomic cosets modulo $n = q^{m} - 1$, where $q
\geq 3$ is a prime power, are investigated in this paper. Based on these
properties, the dimension as well as bounds for the designed distance of some
families of classical cyclic codes can be computed. As an application, new
families of nonbinary Calderbank-Shor-Steane (CSS) quantum codes as well as new
families of convolutional codes are constructed in this work. These new CSS
codes have parameters better than the ones available in the literature. The
convolutional codes constructed here have free distance greater than the ones
available in the literature.
</dc:description>
 <dc:description>Comment: Accepted for publication in Linear Algebra and its Applications</dc:description>
 <dc:date>2015-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04359</dc:identifier>
 <dc:identifier>Linear Algebra and its Applications, v. 488, p. 302-319, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04376</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Defined Optical Networks (SDONs): A Comprehensive Survey</dc:title>
 <dc:creator>Thyagaturu, Akhilesh</dc:creator>
 <dc:creator>Mercian, Anu</dc:creator>
 <dc:creator>McGarry, Michael P.</dc:creator>
 <dc:creator>Reisslein, Martin</dc:creator>
 <dc:creator>Kellerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The emerging Software Defined Networking (SDN) paradigm separates the data
plane from the control plane and centralizes network control in an SDN
controller. Applications interact with controllers to implement network
services, such as network transport with Quality of Service (QoS). SDN
facilitates the virtualization of network functions so that multiple virtual
networks can operate over a given installed physical network infrastructure.
Due to the specific characteristics of optical (photonic) communication
components and the high optical transmission capacities, SDN based optical
networking poses particular challenges, but holds also great potential. In this
article, we comprehensively survey studies that examine the SDN paradigm in
optical networks; in brief, we survey the area of Software Defined Optical
Networks (SDONs). We mainly organize the SDON studies into studies focused on
the infrastructure layer, the control layer, and the application layer.
Moreover, we cover SDON studies focused on network virtualization, as well as
SDON studies focused on the orchestration of multilayer and multidomain
networking. Based on the survey, we identify open challenges for SDONs and
outline future directions.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04376</dc:identifier>
 <dc:identifier>IEEE Communications Surveys &amp; Tutorials, vol. 18, no. 4, pp.
  2738-2786, 4th Qu. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/COMST.2016.2586999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04377</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Dense Convolutional Embeddings for Semantic Segmentation</dc:title>
 <dc:creator>Harley, Adam W.</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new deep convolutional neural network (DCNN)
architecture that learns pixel embeddings, such that pairwise distances between
the embeddings can be used to infer whether or not the pixels lie on the same
region. That is, for any two pixels on the same object, the embeddings are
trained to be similar; for any pair that straddles an object boundary, the
embeddings are trained to be dissimilar. Experimental results show that when
this embedding network is used in conjunction with a DCNN trained on semantic
segmentation, there is a systematic improvement in per-pixel classification
accuracy. Our contributions are integrated in the popular Caffe deep learning
framework, and consist in straightforward modifications to convolution
routines. As such, they can be exploited for any task involving convolution
layers.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04383</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handling Class Imbalance in Link Prediction using Learning to Rank
  Techniques</dc:title>
 <dc:creator>Li, Bopeng</dc:creator>
 <dc:creator>Chaudhuri, Sougata</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider the link prediction problem in a partially observed network,
where the objective is to make predictions in the unobserved portion of the
network. Many existing methods reduce link prediction to binary classification
problem. However, the dominance of absent links in real world networks makes
misclassification error a poor performance metric. Instead, researchers have
argued for using ranking performance measures, like AUC, AP and NDCG, for
evaluation. Our main contribution is to recast the link prediction problem as a
learning to rank problem and use effective learning to rank techniques directly
during training. This is in contrast to existing work that uses ranking
measures only during evaluation. Our approach is able to deal with the class
imbalance problem by using effective, scalable learning to rank techniques
during training. Furthermore, our approach allows us to combine network
topology and node features. As a demonstration of our general approach, we
develop a link prediction method by optimizing the cross-entropy surrogate,
originally used in the popular ListNet ranking algorithm. We conduct extensive
experiments on publicly available co-authorship, citation and metabolic
networks to demonstrate the merits of our method.
</dc:description>
 <dc:description>Comment: The paper has been withdrawn due to a baseline implementation error
  in experiments</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04384</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reflectance Maps</dc:title>
 <dc:creator>Rematas, Konstantinos</dc:creator>
 <dc:creator>Ritschel, Tobias</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:creator>Gavves, Efstratios</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Undoing the image formation process and therefore decomposing appearance into
its intrinsic properties is a challenging task due to the under-constraint
nature of this inverse problem. While significant progress has been made on
inferring shape, materials and illumination from images only, progress in an
unconstrained setting is still limited. We propose a convolutional neural
architecture to estimate reflectance maps of specular materials in natural
lighting conditions. We achieve this in an end-to-end learning formulation that
directly predicts a reflectance map from the image itself. We show how to
improve estimates by facilitating additional supervision in an indirect scheme
that first predicts surface orientation and afterwards predicts the reflectance
map by a learning-based sparse data interpolation.
  In order to analyze performance on this difficult task, we propose a new
challenge of Specular MAterials on SHapes with complex IllumiNation (SMASHINg)
using both synthetic and real images. Furthermore, we show the application of
our method to a range of image-based editing tasks on real images.
</dc:description>
 <dc:description>Comment: project page: http://homes.esat.kuleuven.be/~krematas/DRM/</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04385</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factoring Safe Semiprimes with a Single Quantum Query</dc:title>
 <dc:creator>Grosshans, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>Lawson, Thomas</dc:creator>
 <dc:creator>Morain, Fran&#xe7;ois</dc:creator>
 <dc:creator>Smith, Benjamin</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q12</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  Shor's factoring algorithm (SFA), by its ability to efficiently factor large
numbers, has the potential to undermine contemporary encryption. At its heart
is a process called order finding, which quantum mechanics lets us perform
efficiently. SFA thus consists of a \emph{quantum order finding algorithm}
(QOFA), bookended by classical routines which, given the order, return the
factors. But, with probability up to $1/2$, these classical routines fail, and
QOFA must be rerun. We modify these routines using elementary results in number
theory, improving the likelihood that they return the factors.
  The resulting quantum factoring algorithm is better than SFA at factoring
safe semiprimes, an important class of numbers used in cryptography. With just
one call to QOFA, our algorithm almost always factors safe semiprimes. As well
as a speed-up, improving efficiency gives our algorithm other, practical
advantages: unlike SFA, it does not need a randomly picked input, making it
simpler to construct in the lab; and in the (unlikely) case of failure, the
same circuit can be rerun, without modification.
  We consider generalizing this result to other cases, although we do not find
a simple extension, and conclude that SFA is still the best algorithm for
general numbers (non safe semiprimes, in other words). Even so, we present some
simple number theoretic tricks for improving SFA in this case.
</dc:description>
 <dc:description>Comment: v2 : Typo correction and rewriting for improved clarity v3 : Slight
  expansion, for improved clarity</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04386</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Performance Computing with Quantum Processing Units</dc:title>
 <dc:creator>Britt, Keith A.</dc:creator>
 <dc:creator>Humble, Travis S.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The prospects of quantum computing have driven efforts to realize fully
functional quantum processing units (QPUs). Recent success in developing
proof-of-principle QPUs has prompted the question of how to integrate these
emerging processors into modern high-performance computing (HPC) systems. We
examine how QPUs can be integrated into current and future HPC system
architectures by accounting for functional and physical design requirements. We
identify two integration pathways that are differentiated by infrastructure
constraints on the QPU and the use cases expected for the HPC system. This
includes a tight integration that assumes infrastructure bottlenecks can be
overcome as well as a loose integration that assumes they cannot. We find that
the performance of both approaches is likely to depend on the quantum
interconnect that serves to entangle multiple QPUs. We also identify several
challenges in assessing QPU performance for HPC, and we consider new metrics
that capture the interplay between system architecture and the quantum
parallelism underlying computational performance.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04387</identifier>
 <datestamp>2016-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Monte-Carlo and Hyper-heuristic methods for the Multi-mode
  Resource-constrained Multi-project Scheduling Problem</dc:title>
 <dc:creator>Asta, Shahriar</dc:creator>
 <dc:creator>Karapetyan, Daniel</dc:creator>
 <dc:creator>Kheiri, Ahmed</dc:creator>
 <dc:creator>&#xd6;zcan, Ender</dc:creator>
 <dc:creator>Parkes, Andrew J.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Multi-mode resource and precedence-constrained project scheduling is a
well-known challenging real-world optimisation problem. An important variant of
the problem requires scheduling of activities for multiple projects considering
availability of local and global resources while respecting a range of
constraints. A critical aspect of the benchmarks addressed in this paper is
that the primary objective is to minimise the sum of the project completion
times, with the usual makespan minimisation as a secondary objective. We
observe that this leads to an expected different overall structure of good
solutions and discuss the effects this has on the algorithm design. This paper
presents a carefully designed hybrid of Monte-Carlo tree search, novel
neighbourhood moves, memetic algorithms, and hyper-heuristic methods. The
implementation is also engineered to increase the speed with which iterations
are performed, and to exploit the computing power of multicore machines.
Empirical evaluation shows that the resulting information-sharing
multi-component algorithm significantly outperforms other solvers on a set of
&quot;hidden&quot; instances, i.e. instances not available at the algorithm design phase.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04387</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04389</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HackAttack: Game-Theoretic Analysis of Realistic Cyber Conflicts</dc:title>
 <dc:creator>Ferragut, Erik M.</dc:creator>
 <dc:creator>Brady, Andrew C.</dc:creator>
 <dc:creator>Brady, Ethan J.</dc:creator>
 <dc:creator>Ferragut, Jacob M.</dc:creator>
 <dc:creator>Ferragut, Nathan M.</dc:creator>
 <dc:creator>Wildgruber, Max C.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Game theory is appropriate for studying cyber conflict because it allows for
an intelligent and goal-driven adversary. Applications of game theory have led
to a number of results regarding optimal attack and defense strategies.
However, the overwhelming majority of applications explore overly simplistic
games, often ones in which each participant's actions are visible to every
other participant. These simplifications strip away the fundamental properties
of real cyber conflicts: probabilistic alerting, hidden actions, unknown
opponent capabilities.
  In this paper, we demonstrate that it is possible to analyze a more realistic
game, one in which different resources have different weaknesses, players have
different exploits, and moves occur in secrecy, but they can be detected.
Certainly, more advanced and complex games are possible, but the game presented
here is more realistic than any other game we know of in the scientific
literature. While optimal strategies can be found for simpler games using
calculus, case-by-case analysis, or, for stochastic games, Q-learning, our more
complex game is more naturally analyzed using the same methods used to study
other complex games, such as checkers and chess. We define a simple evaluation
function and ploy multi-step searches to create strategies. We show that such
scenarios can be analyzed, and find that in cases of extreme uncertainty, it is
often better to ignore one's opponent's possible moves. Furthermore, we show
that a simple evaluation function in a complex game can lead to interesting and
nuanced strategies.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04397</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Similarity-based Text Recognition by Deeply Supervised Siamese Network</dc:title>
 <dc:creator>Hosseini-Asl, Ehsan</dc:creator>
 <dc:creator>Guha, Angshuman</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose a new text recognition model based on measuring the
visual similarity of text and predicting the content of unlabeled texts. First
a Siamese convolutional network is trained with deep supervision on a labeled
training dataset. This network projects texts into a similarity manifold. The
Deeply Supervised Siamese network learns visual similarity of texts. Then a
K-nearest neighbor classifier is used to predict unlabeled text based on
similarity distance to labeled texts. The performance of the model is evaluated
on three datasets of machine-print and hand-written text combined. We
demonstrate that the model reduces the cost of human estimation by $50\%-85\%$.
The error of the system is less than $0.5\%$. The proposed model outperform
conventional Siamese network by finding visually-similar barely-readable and
readable text, e.g. machine-printed, handwritten, due to deep supervision. The
results also demonstrate that the predicted labels are sometimes better than
human labels e.g. spelling correction.
</dc:description>
 <dc:description>Comment: Accepted for presenting at Future Technologies Conference - (FTC
  2016) San Francisco, December 6-7, 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04401</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbol Grounding Association in Multimodal Sequences with Missing
  Elements</dc:title>
 <dc:creator>Raue, Federico</dc:creator>
 <dc:creator>Dengel, Andreas</dc:creator>
 <dc:creator>Breuel, Thomas M.</dc:creator>
 <dc:creator>Liwicki, Marcus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we extend a symbolic association framework for being able to
handle missing elements in multimodal sequences. The general scope of the work
is the symbolic associations of object-word mappings as it happens in language
development in infants. In other words, two different representations of the
same abstract concepts can associate in both directions. This scenario has been
long interested in Artificial Intelligence, Psychology, and Neuroscience. In
this work, we extend a recent approach for multimodal sequences (visual and
audio) to also cope with missing elements in one or both modalities. Our method
uses two parallel Long Short-Term Memories (LSTMs) with a learning rule based
on EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We
propose to include an extra step for the combination with the max operation for
exploiting the common elements between both sequences. The motivation behind is
that the combination acts as a condition selector for choosing the best
representation from both LSTMs. We evaluated the proposed extension in the
following scenarios: missing elements in one modality (visual or audio) and
missing elements in both modalities (visual and sound). The performance of our
extension reaches better results than the original model and similar results to
individual LSTM trained in each modality.
</dc:description>
 <dc:description>Comment: Under review on Journal of Artificial Intelligence Research (JAIR) --
  Special Track on Deep Learning, Knowledge Representation, and Reasoning</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2017-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04404</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Face Alignment Using a Mixture of Invariant Experts</dc:title>
 <dc:creator>Tuzel, Oncel</dc:creator>
 <dc:creator>Marks, Tim K.</dc:creator>
 <dc:creator>Tambe, Salil</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face alignment, which is the task of finding the locations of a set of facial
landmark points in an image of a face, is useful in widespread application
areas. Face alignment is particularly challenging when there are large
variations in pose (in-plane and out-of-plane rotations) and facial expression.
To address this issue, we propose a cascade in which each stage consists of a
mixture of regression experts. Each expert learns a customized regression model
that is specialized to a different subset of the joint space of pose and
expressions. The system is invariant to a predefined class of transformations
(e.g., affine), because the input is transformed to match each expert's
prototype shape before the regression is applied. We also present a method to
include deformation constraints within the discriminative alignment framework,
which makes our algorithm more robust. Our algorithm significantly outperforms
previous methods on publicly available face alignment datasets.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04404</dc:identifier>
 <dc:identifier>Proceedings of 14th European Conference on Computer Vision (ECCV),
  Amsterdam, The Netherlands, October 11-14, 2016, pp 825-841</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-46454-1_50</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04411</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personality Profiles of Software Engineers and Their Software Quality
  Preferences</dc:title>
 <dc:creator>Raza, Arif</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>ul-Mustafa, Zaka</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Studies related to human aspects in software engineering (SE) have been
performed from different perspectives. These perspectives include the study of
human factors in different phases of software life cycle, effect of team
performance in software development, how can a personality trait suit a
particular task, and about some other miscellaneous issues. This research work
aims to establish personality profiles of Pakistani software engineers using
the Myers-Briggs Type Indicator (MBTI) instrument. In this survey, we have
collected personality profiles of 110 software engineers. Moreover, their
preferences of software quality attributes have also been collected. Analysis
of the study shows that the most prominent personality type is a combination of
introversion, sensing, thinking and judging. Investigative results indicate
that most of the software engineers consider usability and functionality as the
most important software quality attributes.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04411</dc:identifier>
 <dc:identifier>International Journal of Information Systems and Social Changes
  (IJISSC), 5(3):74-84, 2014</dc:identifier>
 <dc:identifier>doi:10.4018/ijissc.2014070106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04412</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Sum Product Networks for Tractable Inference on Sequence Data
  (Extended Version)</dc:title>
 <dc:creator>Melibari, Mazen</dc:creator>
 <dc:creator>Poupart, Pascal</dc:creator>
 <dc:creator>Doshi, Prashant</dc:creator>
 <dc:creator>Trimponias, George</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sum-Product Networks (SPN) have recently emerged as a new class of tractable
probabilistic graphical models. Unlike Bayesian networks and Markov networks
where inference may be exponential in the size of the network, inference in
SPNs is in time linear in the size of the network. Since SPNs represent
distributions over a fixed set of variables only, we propose dynamic sum
product networks (DSPNs) as a generalization of SPNs for sequence data of
varying length. A DSPN consists of a template network that is repeated as many
times as needed to model data sequences of any length. We present a local
search technique to learn the structure of the template network. In contrast to
dynamic Bayesian networks for which inference is generally exponential in the
number of variables per time slice, DSPNs inherit the linear inference
complexity of SPNs. We demonstrate the advantages of DSPNs over DBNs and other
models on several datasets of sequence data.
</dc:description>
 <dc:description>Comment: Published in the Proceedings of the International Conference on
  Probabilistic Graphical Models (PGM), 2016</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04417</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Systematic Literature Review of the Critical Factors for Success of
  Mobile Learning in Higher Education (University Students' Perspective)</dc:title>
 <dc:creator>Alrasheedi, Muasaad</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Raza, Arif</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The phenomenon of the use of a mobile learning (m-Learning) platform in
educational institutions is slowly gaining momentum. While this can be taken as
an encouraging sign, the perplexing part is that the fervor with which mobile
phones have been welcomed into every aspect of our lives does not seem to be
evident in the educational sector. In order to understand the reason, it is
important to understand user expectations of the system. This paper documents a
systematic review of various research studies seeking to find the success
factors for effective m-Learning. A total of 30 studies were included in the
research, which combined would give a true picture of user perceptions of the
factors they consider important for effective m-Learning implementation. Our
systematic review collates results from 30 studies conducted in 17 countries,
where 13 critical success factors (CSFs) were found to strongly impact
m-Learning.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04417</dc:identifier>
 <dc:identifier>Journal of Educational Computing Research, 52(2):257-276, 2015</dc:identifier>
 <dc:identifier>doi:10.1177/0735633115571928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04422</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Investigation of Key Business Factors for Digital Game
  Performance</dc:title>
 <dc:creator>Aleem, Saiqa</dc:creator>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Ahmed, Faheem</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Game development is an interdisciplinary concept that embraces software
engineering, business, management, and artistic disciplines. This research
facilitates a better understanding of the business dimension of digital games.
The main objective of this research is to investigate empirically the effect of
business factors on the performance of digital games in the market and to
answer the research questions asked in this study. Game development
organizations are facing high pressure and competition in the digital game
industry. Business has become a crucial dimension, especially for game
development organizations. The main contribution of this paper is to
investigate empirically the influence of key business factors on the business
performance of games. This is the first study in the domain of game development
that demonstrates the interrelationship between key business factors and game
performance in the market. The results of the study provide evidence that game
development organizations must deal with multiple business key factors to
remain competitive and handle the high pressure in the digital game industry.
Furthermore, the results of the study support the theoretical assertion that
key business factors play an important role in game business performance.
</dc:description>
 <dc:description>Comment: in Entertainment Computing, 2014</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04422</dc:identifier>
 <dc:identifier>doi:10.1016/j.entcom.2015.09.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04424</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Influence of Personality Types in Software Tasks Choices</dc:title>
 <dc:creator>Capretz, Luiz Fernando</dc:creator>
 <dc:creator>Varona, Daniel</dc:creator>
 <dc:creator>Raza, Arif</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  According to psychology, not everybody can excel at all kinds of tasks. Thus,
chances of a successful outcome of software development increase if people with
particular personality types are assigned to their preferred tasks in the
project. Likewise, software development depends significantly on how software
practitioners perform their tasks. This empirical study surveys 100 Cuban
software developers, who also teach or study at the University of Informatics
Sciences in Havana, Cuba. This work aims to find possible patterns that link
personality types to role preferences in a software life cycle. Among the
various roles, system analyst, software designer, and programmer are found to
be the most preferred among the participants. In contrast, software tester and
software maintainer happen to be the least popular roles among software
engineers.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04424</dc:identifier>
 <dc:identifier>Computers in Human Behavior, 52:373-378, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.chb.2015.05.050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04428</identifier>
 <datestamp>2016-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Asymptotic Bias of the Diffusion-Based Distributed Pareto
  Optimization</dc:title>
 <dc:creator>Arablouei, Reza</dc:creator>
 <dc:creator>Do&#x11f;an&#xe7;ay, Kutluy&#x131;l</dc:creator>
 <dc:creator>Werner, Stefan</dc:creator>
 <dc:creator>Huang, Yih-Fang</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We revisit the asymptotic bias analysis of the distributed Pareto
optimization algorithm developed based on the diffusion strategies. We propose
an alternative way to analyze the asymptotic bias of this algorithm at small
step-sizes and show that the asymptotic bias descends to zero with a linear
dependence on the largest step-size parameter when this parameter is
sufficiently small. In addition, through the proposed analytic approach, we
provide an expression for the small-step-size asymptotic bias when a condition
assumed jointly on the combination matrices and the step-sizes does not
strictly hold. This is a likely scenario in practice, which has not been
considered in the original paper that introduced the algorithm. Our methodology
provides new insights into the inner workings of the diffusion Pareto
optimization algorithm while being considerably less involved than the
small-step-size asymptotic bias analysis presented in the original work. This
is because we take advantage of the special eigenstructure of the composite
combination matrix used in the algorithm without calling for any eigenspace
decomposition or matrix inversion.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04433</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Assignment of Drainage Direction Over Flat Surfaces in
  Raster Digital Elevation Models</dc:title>
 <dc:creator>Barnes, Richard</dc:creator>
 <dc:creator>Lehman, Clarence</dc:creator>
 <dc:creator>Mulla, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In processing raster digital elevation models (DEMs) it is often necessary to
assign drainage directions over flats---that is, over regions with no local
elevation gradient. This paper presents an approach to drainage direction
assignment which is not restricted by a flat's shape, number of outlets, or
surrounding topography. Flow is modeled by superimposing a gradient away from
higher terrain with a gradient towards lower terrain resulting in a drainage
field exhibiting flow convergence, an improvement over methods which produce
regions of parallel flow. This approach builds on previous work by Garbrecht
and Martz (1997), but presents several important improvements. The improved
algorithm guarantees that flats are only resolved if they have outlets. The
algorithm does not require iterative application; a single pass is sufficient
to resolve all flats. The algorithm presents a clear strategy for identifying
flats and their boundaries. The algorithm is not susceptible to loss of
floating-point precision. Furthermore, the algorithm is efficient, operating in
O( N ) time whereas the older algorithm operates in O( N^(3/2) ) time. In
testing, the improved algorithm ran 6.5 times faster than the old for a 100 x
100 cell flat and 69 times faster for a 700 x 700 cell flat. In tests on actual
DEMs, the improved algorithm finished its processing 38--110 times sooner while
running on a single processor than a parallel implementation of the old
algorithm did while running on 16 processors. The improved algorithm is an
optimal, accurate, easy-to-implement drop-in replacement for the original.
Pseudocode is provided in the paper and working source code is provided in the
Supplemental Materials.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, 8 subalgorithms</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04433</dc:identifier>
 <dc:identifier>Computers &amp; Geosciences. Vol 62, Jan 2014, pp 12--135</dc:identifier>
 <dc:identifier>doi:10.1016/j.cageo.2013.01.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04435</identifier>
 <datestamp>2016-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Dynamic Analysis of the Costas Loop</dc:title>
 <dc:creator>Best, R. E.</dc:creator>
 <dc:creator>Kuznetsov, N. V.</dc:creator>
 <dc:creator>Leonov, G. A.</dc:creator>
 <dc:creator>Yuldashev, M. V.</dc:creator>
 <dc:creator>Yuldashev, R. V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  This survey is devoted to the dynamic analysis of the Costas loop. In
particular the acquisition process is analyzed in great detail. Acquision is
most conventiently described by a number of frequency and time parameters such
as lock-in range, lock-in time, pull-in range, pull-in time, and hold-in range.
While for the classical PLL equations for all these parameters have been
derived (many of them are approximations, some even crude approximations), this
has not yet been carried out for the Costas loop. It is the aim of this
analysis to close this gap. The paper starts with an overview on mathematical
and physical models (exact and simplified) of the different variants of the
Costas loop, cf. Section~1. In Sections 2--5 equations for the above mentioned
key parameters are derived. Finally, the hold-in range of the Costas loop for
the case where a lead-lag filter is used for the loop filter is analyzed, cf.
Appendix.
</dc:description>
 <dc:date>2015-11-11</dc:date>
 <dc:date>2016-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04435</dc:identifier>
 <dc:identifier>Annual Reviews in Control, Volume 42, 2016, Pages 27-49</dc:identifier>
 <dc:identifier>doi:10.1016/j.arcontrol.2016.08.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04437</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Ranking Problem of Alternatives as a Cooperative Game</dc:title>
 <dc:creator>Kondratev, Aleksei</dc:creator>
 <dc:creator>Mazalov, Vladimir</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper considers the ranking problem of candidates for a certain position
based on ballot papers filled by voters. We suggest a ranking procedure of
alternatives using cooperative game theory methods. For this, it is necessary
to construct a characteristic function via the filled ballot paper profile of
voters. The Shapley value serves as the ranking method. The winner is the
candidate having the maximum Shapley value. And finally, we explore the
properties of the designed ranking procedure.
</dc:description>
 <dc:date>2015-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04440</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mathematical model stabilization control of a robot due to the delay of
  the control signal</dc:title>
 <dc:creator>Legchekova, Elena</dc:creator>
 <dc:creator>Titov, Oleg</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Consider the question of building a system of commands remotely controlled
robot that can perform motion stabilization in the presence of a constant delay
of the control signal.
</dc:description>
 <dc:description>Comment: 4 pages, in Russian</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04440</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04458</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transductive Zero-Shot Action Recognition by Word-Vector Embedding</dc:title>
 <dc:creator>Xu, Xun</dc:creator>
 <dc:creator>Hospedales, Timothy</dc:creator>
 <dc:creator>Gong, Shaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The number of categories for action recognition is growing rapidly and it has
become increasingly hard to label sufficient training data for learning
conventional models for all categories. Instead of collecting ever more data
and labelling them exhaustively for all categories, an attractive alternative
approach is zero-shot learning&quot; (ZSL). To that end, in this study we construct
a mapping between visual features and a semantic descriptor of each action
category, allowing new categories to be recognised in the absence of any visual
training data. Existing ZSL studies focus primarily on still images, and
attribute-based semantic representations. In this work, we explore word-vectors
as the shared semantic space to embed videos and category labels for ZSL action
recognition. This is a more challenging problem than existing ZSL of still
images and/or attributes, because the mapping between video spacetime features
of actions and the semantic space is more complex and harder to learn for the
purpose of generalising over any cross-category domain shift. To solve this
generalisation problem in ZSL action recognition, we investigate a series of
synergistic strategies to improve upon the standard ZSL pipeline. Most of these
strategies are transductive in nature which means access to testing data in the
training phase.
</dc:description>
 <dc:description>Comment: Accepted by IJCV</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04463</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Priority-Flood: An Optimal Depression-Filling and Watershed-Labeling
  Algorithm for Digital Elevation Models</dc:title>
 <dc:creator>Barnes, Richard</dc:creator>
 <dc:creator>Lehman, Clarence</dc:creator>
 <dc:creator>Mulla, David</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Depressions (or pits) are low areas within a digital elevation model that are
surrounded by higher terrain, with no outlet to lower areas. Filling them so
they are level, as fluid would fill them if the terrain were impermeable, is
often necessary in preprocessing DEMs. The depression-filling algorithm
presented here---called Priority-Flood---unifies and improves on the work of a
number of previous authors who have published similar algorithms. The algorithm
operates by flooding DEMs inwards from their edges using a priority queue to
determine the next cell to be flooded. The resultant DEM has no depressions or
digital dams: every cell is guaranteed to drain. The algorithm is optimal for
both integer and floating-point data, working in O(n) and O(n lg n) time,
respectively. It is shown that by using a plain queue to fill depressions once
they have been found, an O(m lg m) time-complexity can be achieved, where m
does not exceed the number of cells n. This is the lowest time complexity of
any known floating-point depression-filling algorithm. In testing, this
improved variation of the algorithm performed up to 37% faster than the
original. Additionally, a parallel version of an older, but widely-used
depression-filling algorithm required six parallel processors to achieve a
run-time on par with what the newer algorithm's improved variation took on a
single processor. The Priority-Flood Algorithm is simple to understand and
implement: the included pseudocode is only 20 lines and the included C++
reference implementation is under a hundred lines. The algorithm can work on
irregular meshes as well as 4-, 6-, 8-, and n-connected grids. It can also be
adapted to label watersheds and determine flow directions through either
incremental elevation changes or depression carving. In the case of incremental
elevation changes, the algorithm includes safety checks not present in prior
works.
</dc:description>
 <dc:description>Comment: 17 pages, 4 figures, 5 algorithms</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04463</dc:identifier>
 <dc:identifier>Computers &amp; Geosciences. Vol 62, Jan 2014, pp 117--127</dc:identifier>
 <dc:identifier>doi:10.1016/j.cageo.2013.04.024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04466</identifier>
 <datestamp>2016-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Star-Convex Functions</dc:title>
 <dc:creator>Lee, Jasper C. H.</dc:creator>
 <dc:creator>Valiant, Paul</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce a polynomial time algorithm for optimizing the class of
star-convex functions, under no restrictions except boundedness on a region
about the origin, and Lebesgue measurability. The algorithm's performance is
polynomial in the requested number of digits of accuracy, contrasting with the
previous best known algorithm of Nesterov and Polyak that has exponential
dependence, and that further requires Lipschitz second differentiability of the
function, but has milder dependence on the dimension of the domain. Star-convex
functions constitute a rich class of functions generalizing convex functions to
new parameter regimes, and which confound standard variants of gradient
descent; more generally, we construct a family of star-convex functions where
gradient-based algorithms provably give no information about the location of
the global optimum.
  We introduce a new randomized algorithm for finding cutting planes based only
on function evaluations, where, counterintuitively, the algorithm must look
outside the feasible region to discover the structure of the star-convex
function that lets it compute the next cut of the feasible region. We emphasize
that the class of star-convex functions we consider is as unrestricted as
possible: the class of Lebesgue measurable star-convex functions has
theoretical appeal, introducing to the domain of polynomial-time algorithms a
huge class with many interesting pathologies. We view our results as a step
forward in understanding the scope of optimization techniques beyond the garden
of convex optimization and local gradient-based methods.
</dc:description>
 <dc:description>Comment: 30 pages (including appendices)</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04467</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of multiple and overlapping bidirectional communities within
  large, directed and weighted networks of neurons</dc:title>
 <dc:creator>Esposito, Umberto</dc:creator>
 <dc:creator>Vasilaki, Eleni</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  With the recent explosion of publicly available biological data, the analysis
of networks has gained significant interest. In particular, recent promising
results in Neuroscience show that the way neurons and areas of the brain are
connected to each other plays a fundamental role in cognitive functions and
behaviour. Revealing pattern and structures within such an intricate volume of
connections is a hard problem that has its roots in Graph and Network Theory.
Since many real world situations can be modelled through networks, structures
detection algorithms find application in almost every field of Science. These
are NP-complete problems; therefore the generally used approach is through
heuristic algorithms. Here, we formulate the problem of finding structures in
networks of neurons in terms of a community detection problem. We introduce a
definition of community and we construct a statistics-based heuristic algorithm
for directed and weighted networks aiming at identifying overlapping
bidirectional communities in large networks. We carry out a systematic analysis
of the algorithm's performance, showing excellent results over a wide range of
parameters (successful detection percentages almost $100\%$ all the time).
Also, we show results on the computational time needed and we suggest future
directions on how to improve computational performance.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04472</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Jigsaw Puzzles with Linear Programming</dc:title>
 <dc:creator>Yu, Rui</dc:creator>
 <dc:creator>Russell, Chris</dc:creator>
 <dc:creator>Agapito, Lourdes</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel Linear Program (LP) based formula- tion for solving jigsaw
puzzles. We formulate jigsaw solving as a set of successive global convex
relaxations of the stan- dard NP-hard formulation, that can describe both
jigsaws with pieces of unknown position and puzzles of unknown po- sition and
orientation. The main contribution and strength of our approach comes from the
LP assembly strategy. In contrast to existing greedy methods, our LP solver
exploits all the pairwise matches simultaneously, and computes the position of
each piece/component globally. The main ad- vantages of our LP approach
include: (i) a reduced sensi- tivity to local minima compared to greedy
approaches, since our successive approximations are global and convex and (ii)
an increased robustness to the presence of mismatches in the pairwise matches
due to the use of a weighted L1 penalty. To demonstrate the effectiveness of
our approach, we test our algorithm on public jigsaw datasets and show that it
outperforms state-of-the-art methods.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04478</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Backward/Forward Recovery Approach for the Preconditioned Conjugate
  Gradient Method</dc:title>
 <dc:creator>Fasi, Massimiliano</dc:creator>
 <dc:creator>Langou, Julien</dc:creator>
 <dc:creator>Robert, Yves</dc:creator>
 <dc:creator>Ucar, Bora</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Several recent papers have introduced a periodic verification mechanism to
detect silent errors in iterative solvers. Chen [PPoPP'13, pp. 167--176] has
shown how to combine such a verification mechanism (a stability test checking
the orthogonality of two vectors and recomputing the residual) with
checkpointing: the idea is to verify every $d$ iterations, and to checkpoint
every $c \times d$ iterations. When a silent error is detected by the
verification mechanism, one can rollback to and re-execute from the last
checkpoint. In this paper, we also propose to combine checkpointing and
verification, but we use algorithm-based fault tolerance (ABFT) rather than
stability tests. ABFT can be used for error detection, but also for error
detection and correction, allowing a forward recovery (and no rollback nor
re-execution) when a single error is detected. We introduce an abstract
performance model to compute the performance of all schemes, and we instantiate
it using the preconditioned conjugate gradient algorithm. Finally, we validate
our new approach through a set of simulations.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04479</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Clique-Width</dc:title>
 <dc:creator>F&#xfc;rer, Martin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Multi-clique-width is obtained by a simple modification in the definition of
clique-width. It has the advantage of providing a natural extension of
tree-width. Unlike clique-width, it does not explode exponentially compared to
tree-width. Efficient algorithms based on multi-clique-width are still possible
for interesting tasks like computing the independent set polynomial or testing
$c$-colorability. In particular, $c$-colorability can be tested in time linear
in $n$ and singly exponential in $c$ and the width $k$ of a given
multi-$k$-expression. For these tasks, the running time as a function of the
multi-clique-width is the same as the running time of the fastest known
algorithm as a function of the clique-width. This results in an exponential
speed-up for some graphs, if the corresponding graph generating expressions are
given. The reason is that the multi-clique-width is never bigger, but is
exponentially smaller than the clique-width for many graphs. This gap shows up
when the tree-width is basically equal to the multi-clique width as well as
when the tree-width is not bounded by any function of the clique-width.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04484</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Synapses Enable Efficient Brain-Inspired Learning Machines</dc:title>
 <dc:creator>Neftci, Emre O.</dc:creator>
 <dc:creator>Pedroni, Bruno U.</dc:creator>
 <dc:creator>Joshi, Siddharth</dc:creator>
 <dc:creator>Al-Shedivat, Maruan</dc:creator>
 <dc:creator>Cauwenberghs, Gert</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent studies have shown that synaptic unreliability is a robust and
sufficient mechanism for inducing the stochasticity observed in cortex. Here,
we introduce Synaptic Sampling Machines, a class of neural network models that
uses synaptic stochasticity as a means to Monte Carlo sampling and unsupervised
learning. Similar to the original formulation of Boltzmann machines, these
models can be viewed as a stochastic counterpart of Hopfield networks, but
where stochasticity is induced by a random mask over the connections. Synaptic
stochasticity plays the dual role of an efficient mechanism for sampling, and a
regularizer during learning akin to DropConnect. A local synaptic plasticity
rule implementing an event-driven form of contrastive divergence enables the
learning of generative models in an on-line fashion. Synaptic sampling machines
perform equally well using discrete-timed artificial units (as in Hopfield
networks) or continuous-timed leaky integrate &amp; fire neurons. The learned
representations are remarkably sparse and robust to reductions in bit precision
and synapse pruning: removal of more than 75% of the weakest connections
followed by cursory re-learning causes a negligible performance loss on
benchmark classification tasks. The spiking neuron-based synaptic sampling
machines outperform existing spike-based unsupervised learners, while
potentially offering substantial advantages in terms of power and complexity,
and are thus promising models for on-line learning in brain-inspired hardware.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04484</dc:identifier>
 <dc:identifier>Frontiers in Neuroscience 10 (2016): 241</dc:identifier>
 <dc:identifier>doi:10.3389/fnins.2016.00241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04491</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeply-Recursive Convolutional Network for Image Super-Resolution</dc:title>
 <dc:creator>Kim, Jiwon</dc:creator>
 <dc:creator>Lee, Jung Kwon</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose an image super-resolution method (SR) using a deeply-recursive
convolutional network (DRCN). Our network has a very deep recursive layer (up
to 16 recursions). Increasing recursion depth can improve performance without
introducing new parameters for additional convolutions. Albeit advantages,
learning a DRCN is very hard with a standard gradient descent method due to
exploding/vanishing gradients. To ease the difficulty of training, we propose
two extensions: recursive-supervision and skip-connection. Our method
outperforms previous methods by a large margin.
</dc:description>
 <dc:description>Comment: CVPR 2016 Oral</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04493</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Client-Side Web Proxy Detection from Unprivileged Mobile Devices</dc:title>
 <dc:creator>Zhang, Huijing</dc:creator>
 <dc:creator>Choffnes, David</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Mobile devices that connect to the Internet via cellular networks are rapidly
becoming the primary medium for accessing Web content. Cellular service
providers (CSPs) commonly deploy Web proxies and other middleboxes for
security, performance optimization and traffic engineering reasons. However,
the prevalence and policies of these Web proxies are generally opaque to users
and difficult to measure without privileged access to devices and servers. In
this paper, we present a methodology to detect the presence of Web proxies
without requiring access to low-level packet traces on a device, nor access to
servers being contacted. We demonstrate the viability of this technique using
controlled experiments, and present the results of running our approach on
several production networks and popular Web sites. Next, we characterize the
behaviors of these Web proxies, including caching, redirecting, and content
rewriting. Our analysis can identify how Web proxies impact network
performance, and inform policies for future deployments. Last, we release an
Android app called Proxy Detector on the Google Play Store, allowing average
users with unprivileged (non-rooted) devices to understand Web proxy
deployments and contribute to our IRB-approved study. We report on results of
using this app on 11 popular carriers from the US, Canada, Austria, and China.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04494</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructing Permutation Arrays from Groups</dc:title>
 <dc:creator>Bereg, Sergey</dc:creator>
 <dc:creator>Levy, Avi</dc:creator>
 <dc:creator>Sudborough, I. Hal</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let M(n, d) be the maximum size of a permutation array on n symbols with
pairwise Hamming distance at least d. We use various combinatorial, algebraic,
and computational methods to improve lower bounds for M(n, d). We compute the
Hamming distances of affine semilinear groups and projective semilinear groups,
and unions of cosets of AGL(1,q) and PGL(2,q) with Frobenius maps to obtain
new, improved lower bounds for M(n,d). We give new randomized algorithms. We
give better lower bounds for M(n,d) also using new theorems concerning the
contraction operation. For example, we prove a quadratic lower bound for
M(n,n-2) for all n=2 (mod 3) such that n+1 is a prime power.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04508</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distillation as a Defense to Adversarial Perturbations against Deep
  Neural Networks</dc:title>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:creator>Wu, Xi</dc:creator>
 <dc:creator>Jha, Somesh</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning algorithms have been shown to perform extremely well on many
classical machine learning problems. However, recent studies have shown that
deep learning, like other machine learning techniques, is vulnerable to
adversarial samples: inputs crafted to force a deep neural network (DNN) to
provide adversary-selected outputs. Such attacks can seriously undermine the
security of the system supported by the DNN, sometimes with devastating
consequences. For example, autonomous vehicles can be crashed, illicit or
illegal content can bypass content filters, or biometric authentication systems
can be manipulated to allow improper access. In this work, we introduce a
defensive mechanism called defensive distillation to reduce the effectiveness
of adversarial samples on DNNs. We analytically investigate the
generalizability and robustness properties granted by the use of defensive
distillation when training DNNs. We also empirically study the effectiveness of
our defense mechanisms on two DNNs placed in adversarial settings. The study
shows that defensive distillation can reduce effectiveness of sample creation
from 95% to less than 0.5% on a studied DNN. Such dramatic gains can be
explained by the fact that distillation leads gradients used in adversarial
sample creation to be reduced by a factor of 10^30. We also find that
distillation increases the average minimum number of features that need to be
modified to create adversarial samples by about 800% on one of the DNNs we
tested.
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04510</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Object Parsing with Local-Global Long Short-Term Memory</dc:title>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Xiang, Donglai</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic object parsing is a fundamental task for understanding objects in
detail in computer vision community, where incorporating multi-level contextual
information is critical for achieving such fine-grained pixel-level
recognition. Prior methods often leverage the contextual information through
post-processing predicted confidence maps. In this work, we propose a novel
deep Local-Global Long Short-Term Memory (LG-LSTM) architecture to seamlessly
incorporate short-distance and long-distance spatial dependencies into the
feature learning over all pixel positions. In each LG-LSTM layer, local
guidance from neighboring positions and global guidance from the whole image
are imposed on each position to better exploit complex local and global
contextual information. Individual LSTMs for distinct spatial dimensions are
also utilized to intrinsically capture various spatial layouts of semantic
parts in the images, yielding distinct hidden and memory cells of each position
for each dimension. In our parsing approach, several LG-LSTM layers are stacked
and appended to the intermediate convolutional layers to directly enhance
visual features, allowing network parameters to be learned in an end-to-end
way. The long chains of sequential computation by stacked LG-LSTM layers also
enable each pixel to sense a much larger region for inference benefiting from
the memorization of previous dependencies in all positions along all
dimensions. Comprehensive evaluations on three public datasets well demonstrate
the significant superiority of our LG-LSTM over other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04511</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Optimization for Efficient High-Quality Object Proposal
  Generation</dc:title>
 <dc:creator>Zhang, Ziming</dc:creator>
 <dc:creator>Liu, Yun</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Zhu, Yanjun</dc:creator>
 <dc:creator>Cheng, Ming-Ming</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We are motivated by the need for a generic object proposal generation
algorithm which achieves good balance between object detection recall, proposal
localization quality and computational efficiency. We propose a novel object
proposal algorithm, BING++, which inherits the virtue of good computational
efficiency of BING but significantly improves its proposal localization
quality. At high level we formulate the problem of object proposal generation
from a novel probabilistic perspective, based on which our BING++ manages to
improve the localization quality by employing edges and segments to estimate
object boundaries and update the proposals sequentially. We propose learning
the parameters efficiently by searching for approximate solutions in a
quantized parameter space for complexity reduction. We demonstrate the
generalization of BING++ with the same fixed parameters across different object
classes and datasets. Empirically our BING++ can run at half speed of BING on
CPU, but significantly improve the localization quality by 18.5% and 16.7% on
both VOC2007 and Microhsoft COCO datasets, respectively. Compared with other
state-of-the-art approaches, BING++ can achieve comparable performance, but run
significantly faster.
</dc:description>
 <dc:description>Comment: Accepted by TPAMI</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04512</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Shot Learning via Joint Latent Similarity Embedding</dc:title>
 <dc:creator>Zhang, Ziming</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Zero-shot recognition (ZSR) deals with the problem of predicting class labels
for target domain instances based on source domain side information (e.g.
attributes) of unseen classes. We formulate ZSR as a binary prediction problem.
Our resulting classifier is class-independent. It takes an arbitrary pair of
source and target domain instances as input and predicts whether or not they
come from the same class, i.e. whether there is a match. We model the posterior
probability of a match since it is a sufficient statistic and propose a latent
probabilistic model in this context. We develop a joint discriminative learning
framework based on dictionary learning to jointly learn the parameters of our
model for both domains, which ultimately leads to our class-independent
classifier. Many of the existing embedding methods can be viewed as special
cases of our probabilistic model. On ZSR our method shows 4.90\% improvement
over the state-of-the-art in accuracy averaged across four benchmark datasets.
We also adapt ZSR method for zero-shot retrieval and show 22.45\% improvement
accordingly in mean average precision (mAP).
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04514</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Nonlinear Regression: Parameter Estimation and Asymptotic
  Inference</dc:title>
 <dc:creator>Yang, Zhuoran</dc:creator>
 <dc:creator>Wang, Zhaoran</dc:creator>
 <dc:creator>Liu, Han</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study parameter estimation and asymptotic inference for sparse nonlinear
regression. More specifically, we assume the data are given by $y = f( x^\top
\beta^* ) + \epsilon$, where $f$ is nonlinear. To recover $\beta^*$, we propose
an $\ell_1$-regularized least-squares estimator. Unlike classical linear
regression, the corresponding optimization problem is nonconvex because of the
nonlinearity of $f$. In spite of the nonconvexity, we prove that under mild
conditions, every stationary point of the objective enjoys an optimal
statistical rate of convergence. In addition, we provide an efficient algorithm
that provably converges to a stationary point. We also access the uncertainty
of the obtained estimator. Specifically, based on any stationary point of the
objective, we construct valid hypothesis tests and confidence intervals for the
low dimensional components of the high-dimensional parameter $\beta^*$.
Detailed numerical results are provided to back up our theory.
</dc:description>
 <dc:description>Comment: 32 pages, 2 figures, 1 table</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04515</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algorithmic Framework for Efficient Large-Scale Circuit Simulation
  Using Exponential Integrators</dc:title>
 <dc:creator>Zhuang, Hao</dc:creator>
 <dc:creator>Yu, Wenjian</dc:creator>
 <dc:creator>Kang, Ilgweon</dc:creator>
 <dc:creator>Wang, Xinan</dc:creator>
 <dc:creator>Cheng, Chung-Kuan</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We propose an efficient algorithmic framework for time domain circuit
simulation using exponential integrator. This work addresses several critical
issues exposed by previous matrix exponential based circuit simulation
research, and makes it capable of simulating stiff nonlinear circuit system at
a large scale. In this framework, the system's nonlinearity is treated with
exponential Rosenbrock-Euler formulation. The matrix exponential and vector
product is computed using invert Krylov subspace method. Our proposed method
has several distinguished advantages over conventional formulations (e.g., the
well-known backward Euler with Newton-Raphson method). The matrix factorization
is performed only for the conductance/resistance matrix G, without being
performed for the combinations of the capacitance/inductance matrix C and
matrix G, which are used in traditional implicit formulations. Furthermore, due
to the explicit nature of our formulation, we do not need to repeat LU
decompositions when adjusting the length of time steps for error controls. Our
algorithm is better suited to solving tightly coupled post-layout circuits in
the pursuit for full-chip simulation. Our experimental results validate the
advantages of our framework.
</dc:description>
 <dc:description>Comment: 6 pages; ACM/IEEE DAC 2015</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04515</dc:identifier>
 <dc:identifier>doi:10.1145/2744769.2744793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04517</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible Recursive Instance-level Object Segmentation</dc:title>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Wei, Yunchao</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Jie, Zequn</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Lin, Liang</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose a novel Reversible Recursive Instance-level Object
Segmentation (R2-IOS) framework to address the challenging instance-level
object segmentation task. R2-IOS consists of a reversible proposal refinement
sub-network that predicts bounding box offsets for refining the object proposal
locations, and an instance-level segmentation sub-network that generates the
foreground mask of the dominant object instance in each proposal. By being
recursive, R2-IOS iteratively optimizes the two sub-networks during joint
training, in which the refined object proposals and improved segmentation
predictions are alternately fed into each other to progressively increase the
network capabilities. By being reversible, the proposal refinement sub-network
adaptively determines an optimal number of refinement iterations required for
each proposal during both training and testing. Furthermore, to handle multiple
overlapped instances within a proposal, an instance-aware denoising autoencoder
is introduced into the segmentation sub-network to distinguish the dominant
object from other distracting instances. Extensive experiments on the
challenging PASCAL VOC 2012 benchmark well demonstrate the superiority of
R2-IOS over other state-of-the-art methods. In particular, the $\text{AP}^r$
over $20$ classes at $0.5$ IoU achieves $66.7\%$, which significantly
outperforms the results of $58.7\%$ by PFN~\cite{PFN} and $46.3\%$
by~\cite{liu2015multi}.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04519</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MATEX: A Distributed Framework for Transient Simulation of Power
  Distribution Networks</dc:title>
 <dc:creator>Zhuang, Hao</dc:creator>
 <dc:creator>Weng, Shih-Hung</dc:creator>
 <dc:creator>Lin, Jeng-Hau</dc:creator>
 <dc:creator>Cheng, Chung-Kuan</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We proposed MATEX, a distributed framework for transient simulation of power
distribution networks (PDNs). MATEX utilizes matrix exponential kernel with
Krylov subspace approximations to solve differential equations of linear
circuit. First, the whole simulation task is divided into subtasks based on
decompositions of current sources, in order to reduce the computational
overheads. Then these subtasks are distributed to different computing nodes and
processed in parallel. Within each node, after the matrix factorization at the
beginning of simulation, the adaptive time stepping solver is performed without
extra matrix re-factorizations. MATEX overcomes the stiff-ness hinder of
previous matrix exponential-based circuit simulator by rational Krylov subspace
method, which leads to larger step sizes with smaller dimensions of Krylov
subspace bases and highly accelerates the whole computation. MATEX outperforms
both traditional fixed and adaptive time stepping methods, e.g., achieving
around 13X over the trapezoidal framework with fixed time step for the IBM
power grid benchmarks.
</dc:description>
 <dc:description>Comment: ACM/IEEE DAC 2014. arXiv admin note: substantial text overlap with
  arXiv:1505.06699</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04519</dc:identifier>
 <dc:identifier>doi:10.1145/2593069.2593160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04524</identifier>
 <datestamp>2016-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Training of Very Deep Neural Networks for Supervised Hashing</dc:title>
 <dc:creator>Zhang, Ziming</dc:creator>
 <dc:creator>Chen, Yuting</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose training very deep neural networks (DNNs) for
supervised learning of hash codes. Existing methods in this context train
relatively &quot;shallow&quot; networks limited by the issues arising in back propagation
(e.e. vanishing gradients) as well as computational efficiency. We propose a
novel and efficient training algorithm inspired by alternating direction method
of multipliers (ADMM) that overcomes some of these limitations. Our method
decomposes the training process into independent layer-wise local updates
through auxiliary variables. Empirically we observe that our training algorithm
always converges and its computational complexity is linearly proportional to
the number of edges in the networks. Empirically we manage to train DNNs with
64 hidden layers and 1024 nodes per layer for supervised hashing in about 3
hours using a single GPU. Our proposed very deep supervised hashing (VDSH)
method significantly outperforms the state-of-the-art on several benchmark
datasets.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04534</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Fine-grained Features via a CNN Tree for Large-scale
  Classification</dc:title>
 <dc:creator>Wang, Zhenhua</dc:creator>
 <dc:creator>Wang, Xingxing</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel approach to enhance the discriminability of Convolutional
Neural Networks (CNN). The key idea is to build a tree structure that could
progressively learn fine-grained features to distinguish a subset of classes,
by learning features only among these classes. Such features are expected to be
more discriminative, compared to features learned for all the classes. We
develop a new algorithm to effectively learn the tree structure from a large
number of classes. Experiments on large-scale image classification tasks
demonstrate that our method could boost the performance of a given basic CNN
model. Our method is quite general, hence it can potentially be used in
combination with many other deep learning models.
</dc:description>
 <dc:description>Comment: Neurocomputing 2017</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04536</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coefficient of Restitution based Cross Layer Interference Aware Routing
  Protocol in Wireless Mesh Networks</dc:title>
 <dc:creator>V, Sarasvathi</dc:creator>
 <dc:creator>Saha, Snehanshu</dc:creator>
 <dc:creator>Iyengar, N. Ch. S. N.</dc:creator>
 <dc:creator>Koti, Mahalaxmi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In Multi-Radio Multi-Channel (MRMC) Wireless Mesh Networks (WMN), Partially
Overlapped Channels (POC) has been used to increase the parallel transmission.
But adjacent channel interference is very severe in MRMC environment; it
decreases the network throughput very badly. In this paper, we propose a
Coefficient of Restitution based Cross layer Interference aware Routing
protocol (CoRCiaR) to improve TCP performance in Wireless Mesh Networks. This
approach comprises of two-steps: Initially, the interference detection
algorithm is developed at MAC layer by enhancing the RTS/CTS method. Based on
the channel interference, congestion is identified by Round Trip Time (RTT)
measurements, and subsequently the route discovery module selects the
alternative path to send the data packet. The packets are transmitted to the
congestion free path seamlessly by the source. The performance of the proposed
CoRCiaR protocol is measured by Coefficient of Restitution (COR) parameter. The
impact of the rerouting is experienced on the network throughput performance.
The simulation results show that the proposed cross layer interference aware
dynamic routing enhances the TCP performance on WMN.
  Keywords: Coefficient of Restitution, Wireless Mesh Networks, Partially
Overlapped Channels, Round Trip Time, Multi-Radio, Multi-Channel.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04541</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Trust Domains Taxonomy for Securely Sharing Information: A Preliminary
  Investigation</dc:title>
 <dc:creator>Arachchilage, Nalin Asanka Gamagedara</dc:creator>
 <dc:creator>Martin, Andrew</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Information sharing has become a vital part in our day-to-day life due to the
pervasiveness of Internet technology. In any given collaboration, information
needs to flow from one participant to another. While participants may be
interested in sharing information with one another, it is often necessary for
them to establish the impact of sharing certain kinds of information. This is
because certain information could have detrimental effects when it ends up in
wrong hands. For this reason, any would-be participant in a given collaboration
may need to establish the guarantees that the collaboration provides, in terms
of protecting sensitive information, before joining the collaboration as well
as evaluating the impact of sharing a given piece of information with a given
set of entities. In order to address this issue, earlier work introduced a
trust domains taxonomy that aims at managing trust-related issues in
information sharing. This paper attempts to empirically investigate the
proposed taxonomy through a possible scenario (e.g. the ConfiChair system). The
study results determined that Role, Policy, Action, Control, Evidence and Asset
elements should be incorporated into the taxonomy for securely sharing
information among others. Additionally, the study results showed that the
ConfiChair, a novel cloud-based conference management system, offers strong
privacy and confidentiality guarantees.
</dc:description>
 <dc:description>Comment: 16, Eighth International Symposium on Human Aspects of Information
  Security &amp; Assurance (HAISA 2014)</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04557</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Four-dimensional signalling schemes - Application to satellite
  communications</dc:title>
 <dc:creator>Arend, Lionel</dc:creator>
 <dc:creator>Krause, Jens</dc:creator>
 <dc:creator>Marso, Michel</dc:creator>
 <dc:creator>Sperber, Ray</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A14</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  In satellite communications both polarizations of an electromagnetic wave are
used to transmit two separate signals. These two independent signals can be
merged to form one dual-polarization, four-dimensional signal.
  The present article pursues this idea and proposes different signal
constellations to be used for four-dimensional signalling in satellite links.
Analytical methods and simulations predict an increased power efficiency of
these constellations with respect to currently used transmission methods. The
cost of this advantage is evaluated considering the limited applicability in
non-linear channels.
  Four-dimensional signalling also implies simultaneous reception on both
polarizations. Such a combined reception allows the precision of timing and
carrier recovery loops to be doubled. This claim is derived analytically and
illustrated by simulating an example case.
  An experimental transmitter/receiver pair was implemented and used to
demonstrate a satellite transmission using a four-dimensional, bi-orthogonal
signal in the dual-polarization channel. The experimental verification confirms
the presented simulation results.
</dc:description>
 <dc:description>Comment: 14 pages, 9 figures</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04561</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>8-Bit Approximations for Parallelism in Deep Learning</dc:title>
 <dc:creator>Dettmers, Tim</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The creation of practical deep learning data-products often requires
parallelization across processors and computers to make deep learning feasible
on large data sets, but bottlenecks in communication bandwidth make it
difficult to attain good speedups through parallelism. Here we develop and test
8-bit approximation algorithms which make better use of the available bandwidth
by compressing 32-bit gradients and nonlinear activations to 8-bit
approximations. We show that these approximations do not decrease predictive
performance on MNIST, CIFAR10, and ImageNet for both model and data parallelism
and provide a data transfer speedup of 2x relative to 32-bit parallelism. We
build a predictive model for speedups based on our experimental data, verify
its validity on known speedup data, and show that we can obtain a speedup of
50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We
compare our data types with other methods and show that 8-bit approximations
achieve state-of-the-art speedups for model parallelism. Thus 8-bit
approximation is an efficient method to parallelize convolutional networks on
very large systems of GPUs.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04581</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Test of Relative Similarity For Model Selection in Generative Models</dc:title>
 <dc:creator>Bounliphone, Wacha</dc:creator>
 <dc:creator>Belilovsky, Eugene</dc:creator>
 <dc:creator>Blaschko, Matthew B.</dc:creator>
 <dc:creator>Antonoglou, Ioannis</dc:creator>
 <dc:creator>Gretton, Arthur</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Probabilistic generative models provide a powerful framework for representing
data that avoids the expense of manual annotation typically needed by
discriminative approaches. Model selection in this generative setting can be
challenging, however, particularly when likelihoods are not easily accessible.
To address this issue, we introduce a statistical test of relative similarity,
which is used to determine which of two models generates samples that are
significantly closer to a real-world reference dataset of interest. We use as
our test statistic the difference in maximum mean discrepancies (MMDs) between
the reference dataset and each model dataset, and derive a powerful,
low-variance test based on the joint asymptotic distribution of the MMDs
between each reference-model pair. In experiments on deep generative models,
including the variational auto-encoder and generative moment matching network,
the tests provide a meaningful ranking of model performance as a function of
parameter and training settings.
</dc:description>
 <dc:description>Comment: International Conference on Learning Representations 2016</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04582</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive Sensing of Sparse Signals in the Hermite Transform Basis:
  Analysis and Algorithm for Signal Reconstruction</dc:title>
 <dc:creator>Brajovic, Milo&#x161;</dc:creator>
 <dc:creator>Orovic, Irena</dc:creator>
 <dc:creator>Dakovic, Milos</dc:creator>
 <dc:creator>Stankovic, Srdjan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An analysis of the influence of missing samples in signals exhibiting
sparsity in the Hermite transform domain is provided. Based on the statistical
properties derived for the Hermite coefficients of randomly undersampled
signal, the probability of success in detection of signal components support is
determined. Based on the probabilistic analysis, a threshold for the detection
of signal components is provided. It is a crucial step in the definition of a
simple non-iterative algorithm for compressive sensing signal reconstruction.
The derived theoretical concepts are proved on several examples using different
statistical tests.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04583</identifier>
 <datestamp>2016-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demand-Driven Incremental Object Queries</dc:title>
 <dc:creator>Liu, Yanhong A.</dc:creator>
 <dc:creator>Brandvein, Jon</dc:creator>
 <dc:creator>Stoller, Scott D.</dc:creator>
 <dc:creator>Lin, Bo</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Object queries are essential in information seeking and decision making in
vast areas of applications. However, a query may involve complex conditions on
objects and sets, which can be arbitrarily nested and aliased. The objects and
sets involved as well as the demand---the given parameter values of
interest---can change arbitrarily. How to implement object queries efficiently
under all possible updates, and furthermore to provide complexity guarantees?
  This paper describes an automatic method. The method allows powerful queries
to be written completely declaratively. It transforms demand as well as all
objects and sets into relations. Most importantly, it defines invariants for
not only the query results, but also all auxiliary values about the objects and
sets involved, including those for propagating demand, and incrementally
maintains all of them. Implementation and experiments with problems from a
variety of application areas, including distributed algorithms and
probabilistic queries, confirm the analyzed complexities, trade-offs, and
significant improvements over prior work.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04585</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A System for Compressive Sensing Signal Reconstruction</dc:title>
 <dc:creator>Orovic, Irena</dc:creator>
 <dc:creator>Draganic, Andjela</dc:creator>
 <dc:creator>Lekic, Nedjeljko</dc:creator>
 <dc:creator>Stankovic, Srdjan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An architecture for hardware realization of a system for sparse signal
reconstruction is presented. The threshold based reconstruction method is
considered, which is further modified in this paper to reduce the system
complexity in order to provide easier hardware realization. Instead of using
the partial random Fourier transform matrix, the minimization problem is
reformulated using only the triangular R matrix from the QR decomposition. The
triangular R matrix can be efficiently implemented in hardware without
calculating the orthogonal Q matrix. A flexible and scalable realization of
matrix R is proposed, such that the size of R changes with the number of
available samples and sparsity level.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04586</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Character-based Neural Machine Translation</dc:title>
 <dc:creator>Ling, Wang</dc:creator>
 <dc:creator>Trancoso, Isabel</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Black, Alan W</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a neural machine translation model that views the input and
output sentences as sequences of characters rather than words. Since word-level
information provides a crucial source of bias, our input model composes
representations of character sequences into representations of words (as
determined by whitespace boundaries), and then these are translated using a
joint attention/translation model. In the target language, the translation is
modeled as a sequence of word vectors, but each word is generated one character
at a time, conditional on the previous character generations in each word. As
the representation and generation of words is performed at the character level,
our model is capable of interpreting and generating unseen word forms. A
secondary benefit of this approach is that it alleviates much of the challenges
associated with preprocessing/tokenization of the source and target languages.
We show that our model can achieve translation results that are on par with
conventional word-based models.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04587</identifier>
 <datestamp>2016-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accurate Image Super-Resolution Using Very Deep Convolutional Networks</dc:title>
 <dc:creator>Kim, Jiwon</dc:creator>
 <dc:creator>Lee, Jung Kwon</dc:creator>
 <dc:creator>Lee, Kyoung Mu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a highly accurate single-image super-resolution (SR) method. Our
method uses a very deep convolutional network inspired by VGG-net used for
ImageNet classification \cite{simonyan2015very}. We find increasing our network
depth shows a significant improvement in accuracy. Our final model uses 20
weight layers. By cascading small filters many times in a deep network
structure, contextual information over large image regions is exploited in an
efficient way. With very deep networks, however, convergence speed becomes a
critical issue during training. We propose a simple yet effective training
procedure. We learn residuals only and use extremely high learning rates
($10^4$ times higher than SRCNN \cite{dong2015image}) enabled by adjustable
gradient clipping. Our proposed method performs better than existing methods in
accuracy and visual improvements in our results are easily noticeable.
</dc:description>
 <dc:description>Comment: CVPR 2016 Oral</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-11-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04590</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oracle performance for visual captioning</dc:title>
 <dc:creator>Yao, Li</dc:creator>
 <dc:creator>Ballas, Nicolas</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Smith, John R.</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The task of associating images and videos with a natural language description
has attracted a great amount of attention recently. Rapid progress has been
made in terms of both developing novel algorithms and releasing new datasets.
Indeed, the state-of-the-art results on some of the standard datasets have been
pushed into the regime where it has become more and more difficult to make
significant improvements. Instead of proposing new models, this work
investigates the possibility of empirically establishing performance upper
bounds on various visual captioning datasets without extra data labelling
effort or human evaluation. In particular, it is assumed that visual captioning
is decomposed into two steps: from visual inputs to visual concepts, and from
visual concepts to natural language descriptions. One would be able to obtain
an upper bound when assuming the first step is perfect and only requiring
training a conditional language model for the second step. We demonstrate the
construction of such bounds on MS-COCO, YouTube2Text and LSMDC (a combination
of M-VAD and MPII-MD). Surprisingly, despite of the imperfect process we used
for visual concept extraction in the first step and the simplicity of the
language model for the second step, we show that current state-of-the-art
models fall short when being compared with the learned upper bounds.
Furthermore, with such a bound, we quantify several important factors
concerning image and video captioning: the number of visual concepts captured
by different models, the trade-off between the amount of visual elements
captured and their accuracy, and the intrinsic difficulty and blessing of
different datasets.
</dc:description>
 <dc:description>Comment: BMVC2016 (Oral paper)</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04594</identifier>
 <datestamp>2016-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flush+Flush: A Fast and Stealthy Cache Attack</dc:title>
 <dc:creator>Gruss, Daniel</dc:creator>
 <dc:creator>Maurice, Cl&#xe9;mentine</dc:creator>
 <dc:creator>Wagner, Klaus</dc:creator>
 <dc:creator>Mangard, Stefan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Research on cache attacks has shown that CPU caches leak significant
information. Proposed detection mechanisms assume that all cache attacks cause
more cache hits and cache misses than benign applications and use hardware
performance counters for detection.
  In this article, we show that this assumption does not hold by developing a
novel attack technique: the Flush+Flush attack. The Flush+Flush attack only
relies on the execution time of the flush instruction, which depends on whether
data is cached or not. Flush+Flush does not make any memory accesses, contrary
to any other cache attack. Thus, it causes no cache misses at all and the
number of cache hits is reduced to a minimum due to the constant cache flushes.
Therefore, Flush+Flush attacks are stealthy, i.e., the spy process cannot be
detected based on cache hits and misses, or state-of-the-art detection
mechanisms. The Flush+Flush attack runs in a higher frequency and thus is
faster than any existing cache attack. With 496 KB/s in a cross-core covert
channel it is 6.7 times faster than any previously published cache covert
channel.
</dc:description>
 <dc:description>Comment: This paper has been accepted at the 13th Conference on Detection of
  Intrusions and Malware &amp; Vulnerability Assessment (DIMVA) 2016. The final
  publication is available at link.springer.com</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04599</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepFool: a simple and accurate method to fool deep neural networks</dc:title>
 <dc:creator>Moosavi-Dezfooli, Seyed-Mohsen</dc:creator>
 <dc:creator>Fawzi, Alhussein</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art deep neural networks have achieved impressive results on
many image classification tasks. However, these same architectures have been
shown to be unstable to small, well sought, perturbations of the images.
Despite the importance of this phenomenon, no effective methods have been
proposed to accurately compute the robustness of state-of-the-art deep
classifiers to such perturbations on large-scale datasets. In this paper, we
fill this gap and propose the DeepFool algorithm to efficiently compute
perturbations that fool deep networks, and thus reliably quantify the
robustness of these classifiers. Extensive experimental results show that our
approach outperforms recent methods in the task of computing adversarial
perturbations and making classifiers more robust.
</dc:description>
 <dc:description>Comment: In Proceedings of IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR), 2016</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04601</identifier>
 <datestamp>2016-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jointly Learning Non-negative Projection and Dictionary with
  Discriminative Graph Constraints for Classification</dc:title>
 <dc:creator>Liu, Weiyang</dc:creator>
 <dc:creator>Yu, Zhiding</dc:creator>
 <dc:creator>Wen, Yandong</dc:creator>
 <dc:creator>Lin, Rongmei</dc:creator>
 <dc:creator>Yang, Meng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse coding with dictionary learning (DL) has shown excellent
classification performance. Despite the considerable number of existing works,
how to obtain features on top of which dictionaries can be better learned
remains an open and interesting question. Many current prevailing DL methods
directly adopt well-performing crafted features. While such strategy may
empirically work well, it ignores certain intrinsic relationship between
dictionaries and features. We propose a framework where features and
dictionaries are jointly learned and optimized. The framework, named joint
non-negative projection and dictionary learning (JNPDL), enables interaction
between the input features and the dictionaries. The non-negative projection
leads to discriminative parts-based object features while DL seeks a more
suitable representation. Discriminative graph constraints are further imposed
to simultaneously maximize intra-class compactness and inter-class
separability. Experiments on both image and image set classification show the
excellent performance of JNPDL by outperforming several state-of-the-art
approaches.
</dc:description>
 <dc:description>Comment: To appear in BMVC 2016</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04623</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Represent Words in Context with Multilingual Supervision</dc:title>
 <dc:creator>Kawakami, Kazuya</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a neural network architecture based on bidirectional LSTMs to
compute representations of words in the sentential contexts. These
context-sensitive word representations are suitable for, e.g., distinguishing
different word senses and other context-modulated variations in meaning. To
learn the parameters of our model, we use cross-lingual supervision,
hypothesizing that a good representation of a word in context will be one that
is sufficient for selecting the correct translation into a second language. We
evaluate the quality of our representations as features in three downstream
tasks: prediction of semantic supersenses (which assign nouns and verbs into a
few dozen semantic classes), low resource machine translation, and a lexical
substitution task, and obtain state-of-the-art results on all of these.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04628</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Planning and Controlling Non-Periodic Bipedal Locomotion</dc:title>
 <dc:creator>Zhao, Ye</dc:creator>
 <dc:creator>Fernandez, Benito R.</dc:creator>
 <dc:creator>Sentis, Luis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This study presents a theoretical framework for planning and controlling
agile bipedal locomotion based on robustly tracking a set of non-periodic apex
states. Based on the prismatic inverted pendulum model, we formulate a hybrid
phase-space planning and control framework which includes the following key
components: (1) a step transition solver that enables dynamically tracking
non-periodic apex or keyframe states over various types of terrains, (2) a
robust hybrid automaton to effectively formulate planning and control
algorithms, (3) a phase-space metric to measure distance to the planned
locomotion manifolds, and (4) a hybrid control method based on the previous
distance metric to produce robust dynamic locomotion under external
disturbances. Compared to other locomotion frameworks, we have a larger focus
on non-periodic gait generation and robustness metrics to deal with
disturbances. Such focus enables the proposed control framework to robustly
track non-periodic apex states over various challenging terrains and under
external disturbances as illustrated through several simulations. Additionally,
it allows a bipedal robot to perform non-periodic bouncing maneuvers over
disjointed terrains.
</dc:description>
 <dc:description>Comment: 33 pages, 18 figures, journal</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04629</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coding in the Finite-Blocklength Regime: Bounds based on Laplace
  Integrals and their Asymptotic Approximations</dc:title>
 <dc:creator>Erseghe, Tomaso</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we provide new compact integral expressions and associated
simple asymptotic approximations for converse and achievability bounds in the
finite blocklength regime. The chosen converse and random coding union bounds
were taken from the recent work of Polyanskyi-Poor-Verdu, and are investigated
under parallel AWGN channels, the AWGN channels, the BI-AWGN channel, and the
BSC. The technique we use, which is a generalization of some recent results
available from the literature, is to map the probabilities of interest into a
Laplace integral, and then solve (or approximate) the integral by use of a
steepest descent technique. The proposed results are particularly useful for
short packet lengths, where the normal approximation may provide unreliable
results.
</dc:description>
 <dc:description>Comment: 29 pages, 10 figures. Submitted to IEEE Trans. on Information Theory.
  Matlab code available from http://dgt.dei.unipd.it section Download-&gt;Finite
  Blocklength Regime</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04629</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2616900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04631</identifier>
 <datestamp>2016-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shortest Paths and Distances with Differential Privacy</dc:title>
 <dc:creator>Sealfon, Adam</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We introduce a model for differentially private analysis of weighted graphs
in which the graph topology $(V,E)$ is assumed to be public and the private
information consists only of the edge weights $w:E\to\mathbb{R}^+$. This can
express hiding congestion patterns in a known system of roads. Differential
privacy requires that the output of an algorithm provides little advantage,
measured by privacy parameters $\epsilon$ and $\delta$, for distinguishing
between neighboring inputs, which are thought of as inputs that differ on the
contribution of one individual. In our model, two weight functions $w,w'$ are
considered to be neighboring if they have $\ell_1$ distance at most one.
  We study the problems of privately releasing a short path between a pair of
vertices and of privately releasing approximate distances between all pairs of
vertices. We are concerned with the approximation error, the difference between
the length of the released path or released distance and the length of the
shortest path or actual distance.
  For privately releasing a short path between a pair of vertices, we prove a
lower bound of $\Omega(|V|)$ on the additive approximation error for fixed
$\epsilon,\delta$. We provide a differentially private algorithm that matches
this error bound up to a logarithmic factor and releases paths between all
pairs of vertices. The approximation error of our algorithm can be bounded by
the number of edges on the shortest path, so we achieve better accuracy than
the worst-case bound for vertex pairs that are connected by a low-weight path
with $o(|V|)$ vertices.
  For privately releasing all-pairs distances, we show that for trees we can
release all distances with approximation error $O(\log^{2.5}|V|)$ for fixed
privacy parameters. For arbitrary bounded-weight graphs with edge weights in
$[0,M]$ we can release all distances with approximation error
$\tilde{O}(\sqrt{|V|M})$.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04634</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion Planning for Global Localization in Non-Gaussian Belief Spaces</dc:title>
 <dc:creator>Agarwal, Saurav</dc:creator>
 <dc:creator>Tamjidi, Amirhossein</dc:creator>
 <dc:creator>Chakravorty, Suman</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a method for motion planning under uncertainty to deal
with situations where ambiguous data associations result in a multimodal
hypothesis on the robot state. In the global localization problem, sometimes
referred to as the &quot;lost or kidnapped robot problem&quot;, given little to no a
priori pose information, the localization algorithm should recover the correct
pose of a mobile robot with respect to a global reference frame. We present a
Receding Horizon approach, to plan actions that sequentially disambiguate a
multimodal belief to achieve tight localization on the correct pose in finite
time, i.e., converge to a unimodal belief. Experimental results are presented
using a physical ground robot operating in an artificial maze-like environment.
We demonstrate two runs wherein the robot is given no a priori information
about its initial pose and the planner is tasked to localize the robot.
</dc:description>
 <dc:description>Comment: extends previous submission with updated figures, analysis and
  justifications. arXiv admin note: text overlap with arXiv:1506.01780</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04636</identifier>
 <datestamp>2016-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Reinforcement Learning with a Natural Language Action Space</dc:title>
 <dc:creator>He, Ji</dc:creator>
 <dc:creator>Chen, Jianshu</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:creator>Ostendorf, Mari</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces a novel architecture for reinforcement learning with
deep neural networks designed to handle state and action spaces characterized
by natural language, as found in text-based games. Termed a deep reinforcement
relevance network (DRRN), the architecture represents action and state spaces
with separate embedding vectors, which are combined with an interaction
function to approximate the Q-function in reinforcement learning. We evaluate
the DRRN on two popular text games, showing superior performance over other
deep Q-learning architectures. Experiments with paraphrased action descriptions
show that the model is extracting meaning rather than simply memorizing strings
of text.
</dc:description>
 <dc:description>Comment: accepted by ACL 2016</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04646</identifier>
 <datestamp>2017-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Word Embedding based Correlation Model for Question/Answer Matching</dc:title>
 <dc:creator>Shen, Yikang</dc:creator>
 <dc:creator>Rong, Wenge</dc:creator>
 <dc:creator>Jiang, Nan</dc:creator>
 <dc:creator>Peng, Baolin</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:creator>Xiong, Zhang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  With the development of community based question answering (Q&amp;A) services, a
large scale of Q&amp;A archives have been accumulated and are an important
information and knowledge resource on the web. Question and answer matching has
been attached much importance to for its ability to reuse knowledge stored in
these systems: it can be useful in enhancing user experience with recurrent
questions. In this paper, we try to improve the matching accuracy by overcoming
the lexical gap between question and answer pairs. A Word Embedding based
Correlation (WEC) model is proposed by integrating advantages of both the
translation model and word embedding, given a random pair of words, WEC can
score their co-occurrence probability in Q&amp;A pairs and it can also leverage the
continuity and smoothness of continuous space word representation to deal with
new pairs of words that are rare in the training parallel text. An experimental
study on Yahoo! Answers dataset and Baidu Zhidao dataset shows this new
method's promising potential.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04646</dc:identifier>
 <dc:identifier>AAAI (2017) 3511--3517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04651</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigations into Elasticity in Cloud Computing</dc:title>
 <dc:creator>Han, Rui</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The pay-as-you-go model supported by existing cloud infrastructure providers
is appealing to most application service providers to deliver their
applications in the cloud. Within this context, elasticity of applications has
become one of the most important features in cloud computing. This elasticity
enables real-time acquisition/release of compute resources to meet application
performance demands. In this thesis we investigate the problem of delivering
cost-effective elasticity services for cloud applications.
  Traditionally, the application level elasticity addresses the question of how
to scale applications up and down to meet their performance requirements, but
does not adequately address issues relating to minimising the costs of using
the service. With this current limitation in mind, we propose a scaling
approach that makes use of cost-aware criteria to detect the bottlenecks within
multi-tier cloud applications, and scale these applications only at bottleneck
tiers to reduce the costs incurred by consuming cloud infrastructure resources.
Our approach is generic for a wide class of multi-tier applications, and we
demonstrate its effectiveness by studying the behaviour of an example
electronic commerce site application.
  Furthermore, we consider the characteristics of the algorithm for
implementing the business logic of cloud applications, and investigate the
elasticity at the algorithm level: when dealing with large-scale data under
resource and time constraints, the algorithm's output should be elastic with
respect to the resource consumed. We propose a novel framework to guide the
development of elastic algorithms that adapt to the available budget while
guaranteeing the quality of output result, e.g. prediction accuracy for
classification tasks, improves monotonically with the used budget.
</dc:description>
 <dc:description>Comment: 211 pages, 27 tables, 75 figures</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04657</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Model Approximations and Asymptotic Optimality of Quantized
  Policies in Decentralized Stochastic Control</dc:title>
 <dc:creator>Saldi, Naci</dc:creator>
 <dc:creator>Y&#xfc;ksel, Serdar</dc:creator>
 <dc:creator>Linder, Tam&#xe1;s</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we consider finite model approximations of a large class of
static and dynamic team problems where these models are constructed through
uniform quantization of the observation and action spaces of the agents. The
strategies obtained from these finite models are shown to approximate the
optimal cost with arbitrary precision under mild technical assumptions. In
particular, quantized team policies are asymptotically optimal. This result is
then applied to Witsenhausen's celebrated counterexample and the Gaussian relay
channel problem. For the Witsenhausen's counterexample, our approximation
approach provides, to our knowledge, the first rigorously established result
that one can construct an $\varepsilon$-optimal strategy for any $\varepsilon &gt;
0$ through a solution of a simpler problem.
</dc:description>
 <dc:description>Comment: 13 pages, double column</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04659</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implementation and comparative quantitative assessment of different
  multispectral image pansharpening approches</dc:title>
 <dc:creator>Panchal, Shailesh</dc:creator>
 <dc:creator>Thakker, Rajesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In remote sensing, images acquired by various earth observation satellites
tend to have either a high spatial and low spectral resolution or vice versa.
Pansharpening is a technique which aims to improve spatial resolution of
multispectral image. The challenges involve in the pansharpening are not only
to improve the spatial resolution but also to preserve spectral quality of the
multispectral image. In this paper, various pansharpening algorithms are
discussed and classified based on approaches they have adopted. Using MATLAB
image processing toolbox, several state-of-art pan-sharpening algorithms are
implemented. Quality of pansharpened images are assessed visually and
quantitatively. Correlation coefficient (CC), Root mean square error (RMSE),
Relative average spectral error (RASE) and Universal quality index (Q) indices
are used to easure spectral quality while to spatial-CC (SCC) quantitative
parameter is used for spatial quality measurement. Finally, the paper is
concluded with useful remarks.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04659</dc:identifier>
 <dc:identifier>doi:10.5121/sipij.2015.6503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04661</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A System for Extracting Sentiment from Large-Scale Arabic Social Data</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Bommireddipalli, Vijay R.</dc:creator>
 <dc:creator>Hanafy, Ayman</dc:creator>
 <dc:creator>Bahgat, Mohamed</dc:creator>
 <dc:creator>Noeman, Sara</dc:creator>
 <dc:creator>Emam, Ossama S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Social media data in Arabic language is becoming more and more abundant. It
is a consensus that valuable information lies in social media data. Mining this
data and making the process easier are gaining momentum in the industries. This
paper describes an enterprise system we developed for extracting sentiment from
large volumes of social data in Arabic dialects. First, we give an overview of
the Big Data system for information extraction from multilingual social data
from a variety of sources. Then, we focus on the Arabic sentiment analysis
capability that was built on top of the system including normalizing written
Arabic dialects, building sentiment lexicons, sentiment classification, and
performance evaluation. Lastly, we demonstrate the value of enriching sentiment
results with user profiles in understanding sentiments of a specific user
group.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04664</identifier>
 <datestamp>2016-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Activity Recognition Models with Triaxial Accelerometers</dc:title>
 <dc:creator>Alsheikh, Mohammad Abu</dc:creator>
 <dc:creator>Selim, Ahmed</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Doyle, Linda</dc:creator>
 <dc:creator>Lin, Shaowei</dc:creator>
 <dc:creator>Tan, Hwee-Pink</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Despite the widespread installation of accelerometers in almost all mobile
phones and wearable devices, activity recognition using accelerometers is still
immature due to the poor recognition accuracy of existing recognition methods
and the scarcity of labeled training data. We consider the problem of human
activity recognition using triaxial accelerometers and deep learning paradigms.
This paper shows that deep activity recognition models (a) provide better
recognition accuracy of human activities, (b) avoid the expensive design of
handcrafted features in existing systems, and (c) utilize the massive unlabeled
acceleration samples for unsupervised feature extraction. Moreover, a hybrid
approach of deep learning and hidden Markov models (DL-HMM) is presented for
sequential activity recognition. This hybrid approach integrates the
hierarchical representations of deep activity recognition models with the
stochastic modeling of temporal sequences in the hidden Markov models. We show
substantial recognition improvement on real world datasets over
state-of-the-art methods of human activity recognition using triaxial
accelerometers.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04668</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Neural Network for Real-Time Autonomous Indoor Navigation</dc:title>
 <dc:creator>Kim, Dong Ki</dc:creator>
 <dc:creator>Chen, Tsuhan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many
challenges. One main reason is that GPS has limited precision in indoor
environments. The additional fact that MAVs are not able to carry heavy weight
or power consuming sensors, such as range finders, makes indoor autonomous
navigation a challenging task. In this paper, we propose a practical system in
which a quadcopter autonomously navigates indoors and finds a specific target,
i.e., a book bag, by using a single camera. A deep learning model,
Convolutional Neural Network (ConvNet), is used to learn a controller strategy
that mimics an expert pilot's choice of action. We show our system's
performance through real-time experiments in diverse indoor locations. To
understand more about our trained network, we use several visualization
techniques.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04670</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering Temporal Context for Video Question and Answering</dc:title>
 <dc:creator>Zhu, Linchao</dc:creator>
 <dc:creator>Xu, Zhongwen</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:creator>Hauptmann, Alexander G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we introduce Video Question Answering in temporal domain to
infer the past, describe the present and predict the future. We present an
encoder-decoder approach using Recurrent Neural Networks to learn temporal
structures of videos and introduce a dual-channel ranking loss to answer
multiple-choice questions. We explore approaches for finer understanding of
video content using question form of &quot;fill-in-the-blank&quot;, and managed to
collect 109,895 video clips with duration over 1,000 hours from TACoS, MPII-MD,
MEDTest 14 datasets, while the corresponding 390,744 questions are generated
from annotations. Extensive experiments demonstrate that our approach
significantly outperforms the compared baselines.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04674</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Text Mining To Analyze Real Estate Classifieds</dc:title>
 <dc:creator>Abdallah, Sherief</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many brokers have adapted their operation to exploit the potential of the
web. Despite the importance of the real estate classifieds, there has been
little work in analyzing such data. In this paper we propose a two-stage
regression model that exploits the textual data in real estate classifieds. We
show how our model can be used to predict the price of a real estate
classified. We also show how our model can be used to highlight keywords that
affect the price positively or negatively. To assess our contributions, we
analyze four real world data sets, which we gathered from three different
property websites. The analysis shows that our model (which exploits textual
features) achieves significantly lower root mean squared error across the
different data sets and against variety of regression models.
</dc:description>
 <dc:description>Comment: 18 pages, 3 figures, and 9 tables</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04685</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-Inner-Products for Convex Functionals and Their Use in Image
  Decomposition</dc:title>
 <dc:creator>Gilboa, Guy</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:description>  Semi-inner-products in the sense of Lumer are extended to convex functionals.
This yields a Hilbert-space like structure to convex functionals in Banach
spaces. In particular, a general expression for semi-inner-products with
respect to one homogeneous functionals is given. Thus one can use the new
operator for the analysis of total variation and higher order functionals like
total-generalized-variation (TGV). Having a semi-inner-product, an angle
between functions can be defined in a straightforward manner. It is shown that
in the one homogeneous case the Bregman distance can be expressed in terms of
this newly defined angle. In addition, properties of the semi-inner-product of
nonlinear eigenfunctions induced by the functional are derived. We use this
construction to state a sufficient condition for a perfect decomposition of two
signals and suggest numerical measures which indicate when those conditions are
approximately met.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04687</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separation Surfaces in the Spectral TV Domain for Texture Decomposition</dc:title>
 <dc:creator>Horesh, Dikla</dc:creator>
 <dc:creator>Gilboa, Guy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:description>  In this paper we introduce a novel notion of separation surfaces for image
decomposition. A surface is embedded in the spectral total-variation (TV) three
dimensional domain and encodes a spatially-varying separation scale. The method
allows good separation of textures with gradually varying pattern-size,
pattern-contrast or illumination. The recently proposed total variation
spectral framework is used to decompose the image into a continuum of textural
scales. A desired texture, within a scale range, is found by fitting a surface
to the local maximal responses in the spectral domain. A band above and below
the surface, referred to as the \textit{Texture Stratum}, defines for each
pixel the adaptive scale-range of the texture. Based on the decomposition an
application is proposed which can attenuate or enhance textures in the image in
a very natural and visually convincing manner.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04687</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2587121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04690</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Elastic Net Regression</dc:title>
 <dc:creator>Liu, Weiyang</dc:creator>
 <dc:creator>Lin, Rongmei</dc:creator>
 <dc:creator>Yang, Meng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a robust elastic net (REN) model for high-dimensional sparse
regression and give its performance guarantees (both the statistical error
bound and the optimization bound). A simple idea of trimming the inner product
is applied to the elastic net model. Specifically, we robustify the covariance
matrix by trimming the inner product based on the intuition that the trimmed
inner product can not be significant affected by a bounded number of
arbitrarily corrupted points (outliers). The REN model can also derive two
interesting special cases: robust Lasso and robust soft thresholding.
Comprehensive experimental results show that the robustness of the proposed
model consistently outperforms the original elastic net and matches the
performance guarantees nicely.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04691</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of the Block-level Bit Allocation in Perceptual Video
  Coding based on MINMAX</dc:title>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Mou, Xuanqin</dc:creator>
 <dc:creator>Zhang, Lei</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>I.4.2</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:description>  In video coding, it is expected that the encoder could adaptively select the
encoding parameters (e.g., quantization parameter) to optimize the bit
allocation to different sources under the given constraint. However, in hybrid
video coding, the dependency between sources brings high complexity for the bit
allocation optimization, especially in the block-level, and existing
optimization methods mostly focus on frame-level bit allocation. In this paper,
we propose a macroblock (MB) level bit allocation method based on the minimum
maximum (MINMAX) criterion, which has acceptable encoding complexity for
offline applications. An iterative-based algorithm, namely maximum distortion
descend (MDD), is developed to reduce quality fluctuation among MBs within a
frame, where the Structure SIMilarity (SSIM) index is used to measure the
perceptual distortion of MBs. Our extensive experimental results on benchmark
video sequences show that the proposed method can greatly enhance the encoding
performance in terms of both bits saving and perceptual quality improvement.
</dc:description>
 <dc:description>Comment: 11 pages, 17 figures</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04695</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Reweighted Method for Tucker Decomposition of Incomplete
  Multiway Tensors</dc:title>
 <dc:creator>Yang, Linxiao</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Li, Hongbin</dc:creator>
 <dc:creator>Zeng, Bing</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of low-rank decomposition of incomplete multiway
tensors. Since many real-world data lie on an intrinsically low dimensional
subspace, tensor low-rank decomposition with missing entries has applications
in many data analysis problems such as recommender systems and image
inpainting. In this paper, we focus on Tucker decomposition which represents an
Nth-order tensor in terms of N factor matrices and a core tensor via
multilinear operations. To exploit the underlying multilinear low-rank
structure in high-dimensional datasets, we propose a group-based log-sum
penalty functional to place structural sparsity over the core tensor, which
leads to a compact representation with smallest core tensor. The method for
Tucker decomposition is developed by iteratively minimizing a surrogate
function that majorizes the original objective function, which results in an
iterative reweighted process. In addition, to reduce the computational
complexity, an over-relaxed monotone fast iterative shrinkage-thresholding
technique is adapted and embedded in the iterative reweighted process. The
proposed method is able to determine the model complexity (i.e. multilinear
rank) in an automatic way. Simulation results show that the proposed algorithm
offers competitive performance compared with other existing algorithms.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04695</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2572047</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04698</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-centric Multilayer Networking: improving performance through
  an ICN/WDM architecture</dc:title>
 <dc:creator>AL-Naday, Mays F.</dc:creator>
 <dc:creator>Thomos, Nikolaos</dc:creator>
 <dc:creator>Reed, Martin J.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Information-centric networking (ICN) facilitates content identification in
networks and offers parametric representation of content semantics. This work,
proposes an ICN/WDM network architecture that uses these features to offer
superior network utilization, in terms of performance and power consumption.
The architecture introduces an ICN publish/subscribe communication approach to
the wavelength layer, whereby, content is aggregated according to its
popularity rank into wavelength-size groups that can be published and
&quot;subscribed to&quot; by multiple nodes. Consequently, routing and wavelength
assignment (RWA) algorithms benefit from anycast to identify multiple sources
of aggregate content and allow optimization of the source selection of
light-paths. A power-aware algorithm, Maximum Degree of connectivity (MaxDeg),
has been developed with the objective of exploiting this flexibility to address
the trade-off between power consumption and network performance. The algorithm
is also applicable to IP architectures, albeit with less flexibility.
Evaluation results indicate the superiority of the proposed ICN architecture,
even when utilizing conventional routing methods, compared to its IP
counterpart. The results further highlight the performance improvement achieved
by the proposed algorithm, compared to conventional RWA methods such as
Shortest-path First Fit (SFF).
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04700</identifier>
 <datestamp>2016-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Optimal Control with Adjustable Uncertainty Sets</dc:title>
 <dc:creator>Zhang, Xiaojing</dc:creator>
 <dc:creator>Kamgarpour, Maryam</dc:creator>
 <dc:creator>Georghiou, Angelos</dc:creator>
 <dc:creator>Goulart, Paul</dc:creator>
 <dc:creator>Lygeros, John</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we develop a unified framework for studying constrained robust
optimal control problems with adjustable uncertainty sets. In contrast to
standard constrained robust optimal control problems with known uncertainty
sets, we treat the uncertainty sets in our problems as additional decision
variables. In particular, given a finite prediction horizon and a metric for
adjusting the uncertainty sets, we address the question of determining the
optimal size and shape of the uncertainty sets, while simultaneously ensuring
the existence of a control policy that will keep the system within its
constraints for all possible disturbance realizations inside the adjusted
uncertainty set. Since our problem subsumes the classical constrained robust
optimal control design problem, it is computationally intractable in general.
We demonstrate that by restricting the families of admissible uncertainty sets
and control policies, the problem can be formulated as a tractable convex
optimization problem. We show that our framework captures several families of
(convex) uncertainty sets of practical interest, and illustrate our approach on
a demand response problem of providing control reserves for a power system.
</dc:description>
 <dc:description>Comment: Pre-print submitted to Automatica</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04707</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Linear Discriminant Analysis</dc:title>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:creator>Kelz, Rainer</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns
linearly separable latent representations in an end-to-end fashion. Classic LDA
extracts features which preserve class separability and is used for
dimensionality reduction for many classification problems. The central idea of
this paper is to put LDA on top of a deep neural network. This can be seen as a
non-linear extension of classic LDA. Instead of maximizing the likelihood of
target labels for individual samples, we propose an objective function that
pushes the network to produce feature distributions which: (a) have low
variance within the same class and (b) high variance between different classes.
Our objective is derived from the general LDA eigenvalue problem and still
allows to train with stochastic gradient descent and back-propagation. For
evaluation we test our approach on three different benchmark datasets (MNIST,
CIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and
CIFAR-10 and outperforms a network trained with categorical cross entropy (same
architecture) on a supervised setting of STL-10.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04717</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Semantic Web Technologies for Improving the Visibility of
  Tourism Data</dc:title>
 <dc:creator>Soualah-Alila, Fayrouz</dc:creator>
 <dc:creator>Faucher, Cyril</dc:creator>
 <dc:creator>Bertrand, Fr&#xe9;d&#xe9;ric</dc:creator>
 <dc:creator>Coustaty, Micka&#xeb;l</dc:creator>
 <dc:creator>Doucet, Antoine</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Tourism industry is an extremely information-intensive, complex and dynamic
activity. It can benefit from semantic Web technologies, due to the significant
heterogeneity of information sources and the high volume of on-line data. The
management of semantically diverse annotated tourism data is facilitated by
ontologies that provide methods and standards, which allow flexibility and more
intelligent access to on-line data. This paper provides a description of some
of the early results of the Tourinflux project which aims to apply semantic Web
technologies to support tourist actors in effectively finding and publishing
information on the Web.
</dc:description>
 <dc:description>Comment: ESAIR: Exploiting Semantic Annotations in Information Retrieval, Oct
  2015, Melbourne, Austria. 2015</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04717</dc:identifier>
 <dc:identifier>doi:10.1145/2810133.2810137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04731</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hardness of RNA Folding Problem with Four Symbols</dc:title>
 <dc:creator>Chang, Yi-Jun</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An RNA sequence is a string composed of four types of nucleotides, $A, C, G$,
and $U$. Given an RNA sequence, the goal of the RNA folding problem is to find
a maximum cardinality set of crossing-free pairs of the form $\{A,U\}$ or
$\{C,G\}$. The problem is central in bioinformatics and has received much
attention over the years. However, the current best algorithm for the problem
still takes $\mathcal{O}\left(\frac{n^3}{\log^2 (n)}\right)$ time, which is
only a slight improvement over the classic $\mathcal{O}(n^3)$ dynamic
programming algorithm. Whether the RNA folding problem can be solved in
$\mathcal{O}(n^{3-\epsilon})$ time remains an open problem. Recently, Abboud,
Backurs, and Williams (FOCS'15) made the first progress by showing a
conditional lower bound for a generalized version of the RNA folding problem
based on a conjectured hardness of the $k$-clique problem. A drawback of their
work is that they require the RNA sequence to have at least 36 types of
letters, making their result biologically irrelevant. In this paper, we show
that by constructing the gadgets using a lemma of Bringmann and K\&quot;{u}nnemann
(FOCS'15) and surrounding them with some carefully designed sequences, the
framework of Abboud et al. can be improved upon to work for the case where the
alphabet size is 4, yielding a conditional lower bound for the RNA folding
problem.
  We also investigate the Dyck edit distance problem. We demonstrate a
reduction from RNA folding problem to Dyck edit distance problem of alphabet
size 10, establishing a connection between the two fundamental string problems.
This leads to a much simpler proof of the conditional lower bound for Dyck edit
distance problem given by Abboud et al. and lowers the required alphabet size
for the lower bound to work.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04741</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Computational Complexity of Optimal Simple Mechanisms</dc:title>
 <dc:creator>Rubinstein, Aviad</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider a monopolist seller facing a single buyer with additive
valuations over n heterogeneous, independent items. It is known that in this
important setting optimal mechanisms may require randomization [HR12], use
menus of infinite size [DDT15], and may be computationally intractable [DDT14].
This has sparked recent interest in finding simple mechanisms that obtain
reasonable approximations to the optimal revenue [HN12, LY13, BILW14]. In this
work we attempt to find the optimal simple mechanism.
  There are many ways to define simple mechanisms. Here we restrict our search
to partition mechanisms, where the seller partitions the items into disjoint
bundles and posts a price for each bundle; the buyer is allowed to buy any
number of bundles.
  We give a PTAS for the problem of finding a revenue-maximizing partition
mechanism, and prove that the problem is strongly NP-hard. En route, we prove
structural properties of near-optimal partition mechanisms which may be of
independent interest: for example, there always exists a near-optimal partition
mechanism that uses only a constant number of non-trivial bundles (i.e. bundles
with more than one item).
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04747</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Representations of Affect from Speech</dc:title>
 <dc:creator>Ghosh, Sayan</dc:creator>
 <dc:creator>Laksana, Eugene</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:creator>Scherer, Stefan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  There has been a lot of prior work on representation learning for speech
recognition applications, but not much emphasis has been given to an
investigation of effective representations of affect from speech, where the
paralinguistic elements of speech are separated out from the verbal content. In
this paper, we explore denoising autoencoders for learning paralinguistic
attributes i.e. categorical and dimensional affective traits from speech. We
show that the representations learnt by the bottleneck layer of the autoencoder
are highly discriminative of activation intensity and at separating out
negative valence (sadness and anger) from positive valence (happiness). We
experiment with different input speech features (such as FFT and log-mel
spectrograms with temporal context windows), and different autoencoder
architectures (such as stacked and deep autoencoders). We also learn utterance
specific representations by a combination of denoising autoencoders and BLSTM
based recurrent autoencoders. Emotion classification is performed with the
learnt temporal/dynamic representations to evaluate the quality of the
representations. Experiments on a well-established real-life speech dataset
(IEMOCAP) show that the learnt representations are comparable to state of the
art feature extractors (such as voice quality features and MFCCs) and are
competitive with state-of-the-art approaches at emotion and dimensional affect
recognition.
</dc:description>
 <dc:description>Comment: This is a submission for the ICLR (International Conference on
  Learning Representations) Workshop 2016</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04750</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchical Aggregation Framework for Efficient Multilevel Visual
  Exploration and Analysis</dc:title>
 <dc:creator>Bikakis, Nikos</dc:creator>
 <dc:creator>Papastefanatos, George</dc:creator>
 <dc:creator>Skourla, Melina</dc:creator>
 <dc:creator>Sellis, Timos</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>97R50, 68P05, 68P15</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>H.4</dc:subject>
 <dc:description>  Data exploration and visualization systems are of great importance in the Big
Data era, in which the volume and heterogeneity of available information make
it difficult for humans to manually explore and analyse data. Most traditional
systems operate in an offline way, limited to accessing preprocessed (static)
sets of data. They also restrict themselves to dealing with small dataset
sizes, which can be easily handled with conventional techniques. However, the
Big Data era has realized the availability of a great amount and variety of big
datasets that are dynamic in nature; most of them offer API or query endpoints
for online access, or the data is received in a stream fashion. Therefore,
modern systems must address the challenge of on-the-fly scalable visualizations
over large dynamic sets of data, offering efficient exploration techniques, as
well as mechanisms for information abstraction and summarization. In this work,
we present a generic model for personalized multilevel exploration and analysis
over large dynamic sets of numeric and temporal data. Our model is built on top
of a lightweight tree-based structure which can be efficiently constructed
on-the-fly for a given set of data. This tree structure aggregates input
objects into a hierarchical multiscale model. Considering different exploration
scenarios over large datasets, the proposed model enables efficient multilevel
exploration, offering incremental construction and prefetching via user
interaction, and dynamic adaptation of the hierarchies based on user
preferences. A thorough theoretical analysis is presented, illustrating the
efficiency of the proposed model. The proposed model is realized in a web-based
prototype tool, called SynopsViz that offers multilevel visual exploration and
analysis over Linked Data datasets.
</dc:description>
 <dc:description>Comment: Semantic Web Journal 2016 (to appear)</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04754</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Distribution of Device-to-Device Communications in Underlaid
  Cellular Networks</dc:title>
 <dc:creator>Banagar, Morteza</dc:creator>
 <dc:creator>Maham, Behrouz</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:creator>Pantisano, Francesco</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Device-to-device (D2D) communications have recently emerged as a novel
transmission paradigm in wireless cellular networks. D2D transmissions take
place concurrently with the usual cellular connections, and thus, controlling
the interference brought to the macro-cellular user equipment (UE) is of vital
importance. In this paper, we consider the uplink transmission of a tier of D2D
users that operates as an underlay for the traditional cellular network. Using
network model based on stochastic geometry, we derive the equilibrium
cumulative distribution function (CDF) of the D2D transmit power. Considering
interference-limited and relatively lossy environment cases, closed form
equations are derived for the power CDF. Finally, a tight closed-form
upper-bound for the derived power distribution is proposed, and the analytical
results are validated via simulation.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04762</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bin Packing with Multiple Colors</dc:title>
 <dc:creator>Alsarhan, Hamza</dc:creator>
 <dc:creator>Chia, Davin</dc:creator>
 <dc:creator>Christman, Ananya</dc:creator>
 <dc:creator>Fu, Shannia</dc:creator>
 <dc:creator>Jin, Yanfeng</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the Colored Bin Packing problem a set of items with varying weights and
colors must be packed into bins of uniform weight limit such that no two items
of the same color may be packed adjacently within a bin. We solve this problem
for the case where there are two or more colors when the items have zero weight
and when the items have unit weight. Our algorithms are optimal and run in
linear time. Since our algorithms apply for two or more colors, they
demonstrate that the problem does not get harder as the number of colors
increases. We also provide closed-form expressions for the optimal number of
bins.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04763</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Channel Assignment Performance Prediction Techniques in
  Random Wireless Mesh Networks</dc:title>
 <dc:creator>Reddy, M Pavan Kumar</dc:creator>
 <dc:creator>Kala, Srikant Manas</dc:creator>
 <dc:creator>Tamma, Bheemarjuna Reddy</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Performance of wireless mesh networks (WMNs) in terms of network capacity,
end-to-end latency, and network resilience depends upon the prevalent levels of
interference. Thus, interference alleviation is a fundamental design concern in
multi-radio multi-channel (MRMC) WMNs, and is achieved through a judicious
channel assignment (CA) to the radios in a WMN. In our earlier works we have
tried to address the problem of estimating the intensity of interference in a
wireless network and predicting the performance of CA schemes based on the
measure of the interference estimate. We have proposed reliable CA performance
prediction approaches which have proven effective in grid WMNs. In this work,
we further assess the reliability of these CA performance prediction techniques
in a large MRMC WMN which comprises of randomly placed mesh routers. We perform
exhaustive simulations on an ns-3 802.11n environment. We obtain conclusive
results to demonstrate the efficacy of proposed schemes in random WMNs as well.
</dc:description>
 <dc:description>Comment: Accepted in 2015 International Conference on Computing and Network
  Communications (CoCoNet'15) (IEEE)</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04763</dc:identifier>
 <dc:identifier>doi:10.1109/CoCoNet.2015.7411298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04773</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Approximate Kernel Canonical Correlation Analysis</dc:title>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view
representation learning technique with broad applicability in statistics and
machine learning. Although there is a closed-form solution for the KCCA
objective, it involves solving an $N\times N$ eigenvalue system where $N$ is
the training set size, making its computational requirements in both memory and
time prohibitive for large-scale problems. Various approximation techniques
have been developed for KCCA. A commonly used approach is to first transform
the original inputs to an $M$-dimensional random feature space so that inner
products in the feature space approximate kernel evaluations, and then apply
linear CCA to the transformed inputs. In many applications, however, the
dimensionality $M$ of the random feature space may need to be very large in
order to obtain a sufficiently good approximation; it then becomes challenging
to perform the linear CCA step on the resulting very high-dimensional data
matrices. We show how to use a stochastic optimization algorithm, recently
proposed for linear CCA and its neural-network extension, to further alleviate
the computation requirements of approximate KCCA. This approach allows us to
run approximate KCCA on a speech dataset with $1.4$ million training samples
and a random feature space of dimensionality $M=100000$ on a typical
workstation.
</dc:description>
 <dc:description>Comment: Published as a conference paper at International Conference on
  Learning Representations (ICLR) 2016</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04775</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressive recommender systems through normalized nonnegative models</dc:title>
 <dc:creator>Stark, Cyril</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce normalized nonnegative models (NNM) for explorative data
analysis. NNMs are partial convexifications of models from probability theory.
We demonstrate their value at the example of item recommendation. We show that
NNM-based recommender systems satisfy three criteria that all recommender
systems should ideally satisfy: high predictive power, computational
tractability, and expressive representations of users and items. Expressive
user and item representations are important in practice to succinctly summarize
the pool of customers and the pool of items. In NNMs, user representations are
expressive because each user's preference can be regarded as normalized mixture
of preferences of stereotypical users. The interpretability of item and user
representations allow us to arrange properties of items (e.g., genres of movies
or topics of documents) or users (e.g., personality traits) hierarchically.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04776</identifier>
 <datestamp>2016-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixtures of Sparse Autoregressive Networks</dc:title>
 <dc:creator>Goessling, Marc</dc:creator>
 <dc:creator>Amit, Yali</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider high-dimensional distribution estimation through autoregressive
networks. By combining the concepts of sparsity, mixtures and parameter sharing
we obtain a simple model which is fast to train and which achieves
state-of-the-art or better results on several standard benchmark datasets.
Specifically, we use an L1-penalty to regularize the conditional distributions
and introduce a procedure for automatic parameter sharing between mixture
components. Moreover, we propose a simple distributed representation which
permits exact likelihood evaluations since the latent variables are interleaved
with the observable variables and can be easily integrated out. Our model
achieves excellent generalization performance and scales well to extremely high
dimensions.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04777</identifier>
 <datestamp>2017-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete Dictionary Recovery over the Sphere II: Recovery by Riemannian
  Trust-region Method</dc:title>
 <dc:creator>Sun, Ju</dc:creator>
 <dc:creator>Qu, Qing</dc:creator>
 <dc:creator>Wright, John</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of recovering a complete (i.e., square and
invertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb{R}^{n \times p}$
with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ is
sufficiently sparse. This recovery problem is central to theoretical
understanding of dictionary learning, which seeks a sparse representation for a
collection of input signals and finds numerous applications in modern signal
processing and machine learning. We give the first efficient algorithm that
provably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros per
column, under suitable probability model for $\mathbf X_0$.
  Our algorithmic pipeline centers around solving a certain nonconvex
optimization problem with a spherical constraint, and hence is naturally
phrased in the language of manifold optimization. In a companion paper
(arXiv:1511.03607), we have showed that with high probability our nonconvex
formulation has no &quot;spurious&quot; local minimizers and around any saddle point the
objective function has a negative directional curvature. In this paper, we take
advantage of the particular geometric structure, and describe a Riemannian
trust region algorithm that provably converges to a local minimizer with from
arbitrary initializations. Such minimizers give excellent approximations to
rows of $\mathbf X_0$. The rows are then recovered by linear programming
rounding and deflation.
</dc:description>
 <dc:description>Comment: The second of two papers based on the report arXiv:1504.06785.
  Accepted by IEEE Transaction on Information Theory; revised according to the
  reviewers' comments</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04777</dc:identifier>
 <dc:identifier>IEEE Trans. Information Theory, 63(2): 885 - 914 (2017)</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2632149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04780</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal interpretation rules for encoding and decoding models in
  neuroimaging</dc:title>
 <dc:creator>Weichwald, Sebastian</dc:creator>
 <dc:creator>Meyer, Timm</dc:creator>
 <dc:creator>&#xd6;zdenizci, Ozan</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:creator>Ball, Tonio</dc:creator>
 <dc:creator>Grosse-Wentrup, Moritz</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Causal terminology is often introduced in the interpretation of encoding and
decoding models trained on neuroimaging data. In this article, we investigate
which causal statements are warranted and which ones are not supported by
empirical evidence. We argue that the distinction between encoding and decoding
models is not sufficient for this purpose: relevant features in encoding and
decoding models carry a different meaning in stimulus- and in response-based
experimental paradigms. We show that only encoding models in the stimulus-based
setting support unambiguous causal interpretations. By combining encoding and
decoding models trained on the same data, however, we obtain insights into
causal relations beyond those that are implied by each individual model type.
We illustrate the empirical relevance of our theoretical findings on EEG data
recorded during a visuo-motor learning task.
</dc:description>
 <dc:description>Comment: accepted manuscript</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04780</dc:identifier>
 <dc:identifier>NeuroImage, 110:48-59, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.neuroimage.2015.01.036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04785</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Theory Applications in Network Security</dc:title>
 <dc:creator>Webb, Jonathan</dc:creator>
 <dc:creator>Docemmilli, Fernando</dc:creator>
 <dc:creator>Bonin, Mikhail</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Graph theory has become a very critical component in many applications in the
computing field including networking and security. Unfortunately, it is also
amongst the most complex topics to understand and apply.
  In this paper, we review some of the key applications of graph theory in
network security. We first cover some algorithmic aspects, then present network
coding and its relation to routing.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04792</identifier>
 <datestamp>2016-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensor Scheduling in Variance Based Event Triggered Estimation with
  Packet Drops</dc:title>
 <dc:creator>Leong, Alex S.</dc:creator>
 <dc:creator>Dey, Subhrakanti</dc:creator>
 <dc:creator>Quevedo, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper considers a remote state estimation problem with multiple sensors
observing a dynamical process, where sensors transmit local state estimates
over an independent and identically distributed (i.i.d.) packet dropping
channel to a remote estimator. At every discrete time instant, the remote
estimator decides whether each sensor should transmit or not, with each sensor
transmission incurring a fixed energy cost. The channel is shared such that
collisions will occur if more than one sensor transmits at a time. Performance
is quantified via an optimization problem that minimizes a convex combination
of the expected estimation error covariance at the remote estimator and
expected energy usage across the sensors. For transmission schedules dependent
only on the estimation error covariance at the remote estimator, this work
establishes structural results on the optimal scheduling which show that 1) for
unstable systems, if the error covariance is large then a sensor will always be
scheduled to transmit, and 2) there is a threshold-type behaviour in switching
from one sensor transmitting to another. Specializing to the single sensor
case, these structural results demonstrate that a threshold policy (i.e.
transmit if the error covariance exceeds a certain threshold and don't transmit
otherwise) is optimal. We also consider the situation where sensors transmit
measurements instead of state estimates, and establish structural results
including the optimality of threshold policies for the single sensor, scalar
case. These results provide a theoretical justification for the use of such
threshold policies in variance based event triggered estimation. Numerical
studies confirm the qualitative behaviour predicted by our structural results.
An extension of the structural results to Markovian packet drops is also
outlined.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04794</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superimposed Signaling Inspired Channel Estimation in Full-Duplex
  Systems</dc:title>
 <dc:creator>Koohian, Abbas</dc:creator>
 <dc:creator>Mehrpouyan, Hani</dc:creator>
 <dc:creator>Nasir, Ali A.</dc:creator>
 <dc:creator>Durrani, Salman</dc:creator>
 <dc:creator>Azarbad, Mohammad</dc:creator>
 <dc:creator>Blostein, Steven D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Residual self-interference (SI) cancellation in the digital baseband is an
important problem in full-duplex (FD) communication systems. In this paper, we
propose a new technique for estimating the SI and communication channels in a
FD communication system, which is inspired from superimposed signalling. In our
proposed technique, we add a constant real number to each constellation point
of a conventional modulation constellation to yield asymmetric shifted
modulation constellations with respect to the origin. We show mathematically
that such constellations can be used for bandwidth efficient channel estimation
without ambiguity. We propose an expectation maximization (EM) estimator for
use with the asymmetric shifted modulation constellations. We derive a
closed-form lower bound for the mean square error (MSE) of the channel
estimation error, which allows us to find the minimum shift energy needed for
accurate channel estimation in a given FD communication system. The simulation
results show that the proposed technique outperforms the data-aided channel
estimation method, under the condition that the pilots use the same extra
energy as the shift, both in terms of MSE of channel estimation error and bit
error rate. The proposed technique is also robust to an increasing power of the
SI signal.
</dc:description>
 <dc:description>Comment: submitted for possible journal publication</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04798</identifier>
 <datestamp>2016-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous Knowledge Transfer in Video Emotion Recognition,
  Attribution and Summarization</dc:title>
 <dc:creator>Xu, Baohan</dc:creator>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Jiang, Yu-Gang</dc:creator>
 <dc:creator>Li, Boyang</dc:creator>
 <dc:creator>Sigal, Leonid</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Emotional content is a key element in user-generated videos. However, it is
difficult to understand emotions conveyed in such videos due to the complex and
unstructured nature of user-generated content and the sparsity of video frames
that express emotion. In this paper, for the first time, we study the problem
of transferring knowledge from heterogeneous external sources, including image
and textual data, to facilitate three related tasks in video emotion
understanding: emotion recognition, emotion attribution and emotion-oriented
summarization. Specifically, our framework (1) learns a video encoding from an
auxiliary emotional image dataset in order to improve supervised video emotion
recognition, and (2) transfers knowledge from an auxiliary textual corpus for
zero-shot \pl{recognition} of emotion classes unseen during training. The
proposed technique for knowledge transfer facilitates novel applications of
emotion attribution and emotion-oriented summarization. A comprehensive set of
experiments on multiple datasets demonstrate the effectiveness of our
framework.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04805</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Job-related discourse on social media</dc:title>
 <dc:creator>Liu, Tong</dc:creator>
 <dc:creator>Homan, Christopher M.</dc:creator>
 <dc:creator>Alm, Cecilia Ovesdotter</dc:creator>
 <dc:creator>White, Ann Marie</dc:creator>
 <dc:creator>Lytle-Flint, Megan C.</dc:creator>
 <dc:creator>Kautz, Henry A.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Working adults spend nearly one third of their daily time at their jobs. In
this paper, we study job-related social media discourse from a community of
users. We use both crowdsourcing and local expertise to train a classifier to
detect job-related messages on Twitter. Additionally, we analyze the linguistic
differences in a job-related corpus of tweets between individual users vs.
commercial accounts. The volumes of job-related tweets from individual users
indicate that people use Twitter with distinct monthly, daily, and hourly
patterns. We further show that the moods associated with jobs, positive and
negative, have unique diurnal rhythms.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures, 7 tables</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04808</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Mid-level Words on Riemannian Manifold for Action Recognition</dc:title>
 <dc:creator>Liu, Mengyi</dc:creator>
 <dc:creator>Wang, Ruiping</dc:creator>
 <dc:creator>Shan, Shiguang</dc:creator>
 <dc:creator>Chen, Xilin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human action recognition remains a challenging task due to the various
sources of video data and large intra-class variations. It thus becomes one of
the key issues in recent research to explore effective and robust
representation to handle such challenges. In this paper, we propose a novel
representation approach by constructing mid-level words in videos and encoding
them on Riemannian manifold. Specifically, we first conduct a global alignment
on the densely extracted low-level features to build a bank of corresponding
feature groups, each of which can be statistically modeled as a mid-level word
lying on some specific Riemannian manifold. Based on these mid-level words, we
construct intrinsic Riemannian codebooks by employing K-Karcher-means
clustering and Riemannian Gaussian Mixture Model, and consequently extend the
Riemannian manifold version of three well studied encoding methods in Euclidean
space, i.e. Bag of Visual Words (BoVW), Vector of Locally Aggregated
Descriptors (VLAD), and Fisher Vector (FV), to obtain the final action video
representations. Our method is evaluated in two tasks on four popular realistic
datasets: action recognition on YouTube, UCF50, HMDB51 databases, and action
similarity labeling on ASLAN database. In all cases, the reported results
achieve very competitive performance with those most recent state-of-the-art
works.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04810</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsimonious shooting heuristic for trajectory control of connected
  automated traffic part I: Theoretical analysis with generalized time
  geography</dc:title>
 <dc:creator>Zhou, Fang</dc:creator>
 <dc:creator>Li, Xiaopeng</dc:creator>
 <dc:creator>Ma, Jiaqi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies a problem of controlling trajectories of a platoon of
vehicles on a highway segment with connected and automated vehicles. This
problem is complex because each vehicle trajectory is an infinite-dimensional
object and neighboring trajectories have complex interactions (e.g.,
car-following behavior). A parsimonious shooting heuristic algorithm is
proposed to construct vehicle trajectories on a signalized highway segment that
comply with boundary conditions for vehicle arrivals, vehicle mechanical
limits, traffic lights and vehicle following safety. This algorithm breaks each
vehicle trajectory into a few sections and each is analytically solvable. This
decomposes the original hard trajectory control problem to a simple
constructive heuristic. Then we slightly adapt this shooting heuristic
algorithm to efficiently solve a leading vehicle problem on an uninterrupted
freeway. To study theoretical properties of the proposed algorithms, the time
geography theory is generalized by considering finite accelerations. With this
generalized theory, it is found that under mild conditions, these algorithms
can always obtain a feasible solution to the original complex trajectory
control problem. Further, we discover that the shooting heuristic solution is a
generalization of the solution to the classic kinematic wave theory by
incorporating finite accelerations. We identify the theoretical bounds to the
difference between the shooting heuristic solution and the kinematic wave
solution. Numerical experiments are conducted to verify the theoretical results
and to draw additional insights into the potential of trajectory control in
improving traffic performance. Building upon this foundation, an optimization
framework will be presented in a following paper as Part II of this study.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04813</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Budget Online Multiple Kernel Learning</dc:title>
 <dc:creator>Lu, Jing</dc:creator>
 <dc:creator>Hoi, Steven C. H.</dc:creator>
 <dc:creator>Sahoo, Doyen</dc:creator>
 <dc:creator>Zhao, Peilin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Online learning with multiple kernels has gained increasing interests in
recent years and found many applications. For classification tasks, Online
Multiple Kernel Classification (OMKC), which learns a kernel based classifier
by seeking the optimal linear combination of a pool of single kernel
classifiers in an online fashion, achieves superior accuracy and enjoys great
flexibility compared with traditional single-kernel classifiers. Despite being
studied extensively, existing OMKC algorithms suffer from high computational
cost due to their unbounded numbers of support vectors. To overcome this
drawback, we present a novel framework of Budget Online Multiple Kernel
Learning (BOMKL) and propose a new Sparse Passive Aggressive learning to
perform effective budget online learning. Specifically, we adopt a simple yet
effective Bernoulli sampling to decide if an incoming instance should be added
to the current set of support vectors. By limiting the number of support
vectors, our method can significantly accelerate OMKC while maintaining
satisfactory accuracy that is comparable to that of the existing OMKC
algorithms. We theoretically prove that our new method achieves an optimal
regret bound in expectation, and empirically found that the proposed algorithm
outperforms various OMKC algorithms and can easily scale up to large-scale
datasets.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04814</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application-Aware Resource Block and Power Allocation for LTE</dc:title>
 <dc:creator>Erpek, Tugba</dc:creator>
 <dc:creator>Abdelhadi, Ahmed</dc:creator>
 <dc:creator>Clancy, T. Charles</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we implement an application-aware scheduler that
differentiates users running real-time applications and delay-tolerant
applications while allocating resources. This approach ensures that the
priority is given to real-time applications over delay-tolerant applications.
In our system model, we include realistic channel effects of Long Term
Evolution (LTE) system. Our application-aware scheduler runs in two stages, the
first stage is resource block allocation and the second stage is power
allocation. In the optimal solution of resource block allocation problem, each
user is inherently guaranteed a minimum Quality of Experience (QoE) while
ensuring priority given to users with real-time applications. In the power
allocation problem, a new power allocation method is proposed which utilizes
the optimal solution of the application-aware resource block scheduling
problem. As a proof of concept, we run a simulation comparison between a
conventional proportional fairness scheduler and the application-aware
scheduler. The simulation results show better QoE with the application-aware
scheduler.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04834</identifier>
 <datestamp>2016-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Programmer: Inducing Latent Programs with Gradient Descent</dc:title>
 <dc:creator>Neelakantan, Arvind</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks have achieved impressive supervised classification
performance in many tasks including image recognition, speech recognition, and
sequence to sequence learning. However, this success has not been translated to
applications like question answering that may involve complex arithmetic and
logic reasoning. A major limitation of these models is in their inability to
learn even simple arithmetic and logic operations. For example, it has been
shown that neural networks fail to learn to add two binary numbers reliably. In
this work, we propose Neural Programmer, an end-to-end differentiable neural
network augmented with a small set of basic arithmetic and logic operations.
Neural Programmer can call these augmented operations over several steps,
thereby inducing compositional programs that are more complex than the built-in
operations. The model learns from a weak supervision signal which is the result
of execution of the correct program, hence it does not require expensive
annotation of the correct program itself. The decisions of what operations to
call, and what data segments to apply to are inferred by Neural Programmer.
Such decisions, during training, are done in a differentiable fashion so that
the entire network can be trained jointly by gradient descent. We find that
training the model is difficult, but it can be greatly improved by adding
random noise to the gradient. On a fairly complex synthetic table-comprehension
dataset, traditional recurrent networks and attentional models perform poorly
while Neural Programmer typically obtains nearly perfect accuracy.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICLR 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04836</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DUDE-Seq: Fast, Flexible, and Robust Denoising for Targeted Amplicon
  Sequencing</dc:title>
 <dc:creator>Lee, Byunghan</dc:creator>
 <dc:creator>Moon, Taesup</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:creator>Weissman, Tsachy</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the correction of errors from nucleotide sequences produced by
next-generation targeted amplicon sequencing. The next-generation sequencing
(NGS) platforms can provide a great deal of sequencing data thanks to their
high throughput, but the associated error rates often tend to be high.
Denoising in high-throughput sequencing has thus become a crucial process for
boosting the reliability of downstream analyses. Our methodology, named
DUDE-Seq, is derived from a general setting of reconstructing finite-valued
source data corrupted by a discrete memoryless channel and effectively corrects
substitution and homopolymer indel errors, the two major types of sequencing
errors in most high-throughput targeted amplicon sequencing platforms. Our
experimental studies with real and simulated datasets suggest that the proposed
DUDE-Seq not only outperforms existing alternatives in terms of
error-correction capability and time efficiency, but also boosts the
reliability of downstream analyses. Further, the flexibility of DUDE-Seq
enables its robust application to different sequencing platforms and analysis
pipelines by simple updates of the noise model. DUDE-Seq is available at
http://data.snu.ac.kr/pub/dude-seq.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04838</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Origin of Polar Coding</dc:title>
 <dc:creator>Ar&#x131;kan, Erdal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar coding was conceived originally as a technique for boosting the cutoff
rate of sequential decoding, along the lines of earlier schemes of Pinsker and
Massey. The key idea in boosting the cutoff rate is to take a vector channel
(either given or artificially built), split it into multiple correlated
subchannels, and employ a separate sequential decoder on each subchannel. Polar
coding was originally designed to be a low-complexity recursive channel
combining and splitting operation of this type, to be used as the inner code in
a concatenated scheme with outer convolutional coding and sequential decoding.
However, the polar inner code turned out to be so effective that no outer code
was actually needed to achieve the original aim of boosting the cutoff rate to
channel capacity. This paper explains the cutoff rate considerations that
motivated the development of polar coding.
</dc:description>
 <dc:description>Comment: To appear in IEEE Journal on Selected Areas in Communications,
  Special Issue on Recent Advances on Capacity-Approaching Codes</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04839</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric Canonical Correlation Analysis</dc:title>
 <dc:creator>Michaeli, Tomer</dc:creator>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Canonical correlation analysis (CCA) is a classical representation learning
technique for finding correlated variables in multi-view data. Several
nonlinear extensions of the original linear CCA have been proposed, including
kernel and deep neural network methods. These approaches seek maximally
correlated projections among families of functions, which the user specifies
(by choosing a kernel or neural network structure), and are computationally
demanding. Interestingly, the theory of nonlinear CCA, without functional
restrictions, had been studied in the population setting by Lancaster already
in the 1950s, but these results have not inspired practical algorithms. We
revisit Lancaster's theory to devise a practical algorithm for nonparametric
CCA (NCCA). Specifically, we show that the solution can be expressed in terms
of the singular value decomposition of a certain operator associated with the
joint density of the views. Thus, by estimating the population density from
data, NCCA reduces to solving an eigenvalue system, superficially like kernel
CCA but, importantly, without requiring the inversion of any kernel matrix. We
also derive a partially linear CCA (PLCCA) variant in which one of the views
undergoes a linear projection while the other is nonparametric. Using a kernel
density estimate based on a small number of nearest neighbors, our NCCA and
PLCCA algorithms are memory-efficient, often run much faster, and perform
better than kernel CCA and comparable to deep CCA.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04841</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple DFT-aided Spatial Basis Expansion Model and Channel Estimation
  Strategy for TDD/FDD Massive MIMO Systems</dc:title>
 <dc:creator>Xie, Hongxiang</dc:creator>
 <dc:creator>Gao, Feifei</dc:creator>
 <dc:creator>Zhang, Shun</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a new transmission strategy for the multiuser massive
multiple-input multiple-output (MIMO) systems, including uplink/downlink
channel estimation and user scheduling for data transmission. A discrete
Fourier transform (DFT) aided spatial basis expansion model (SBEM) is first
introduced to represent the uplink/downlink channels with much few parameter
dimensions by exploiting angle reciprocity and the physical characteristics of
the uniform linear array (ULA). With SBEM, both uplink and downlink channel
estimation of multiuser can be carried out with very few amount of training
resources, which significantly reduces the training overhead and feedback cost.
Meanwhile, the pilot contamination problem in the uplink raining is immediately
relieved by exploiting the spatial information of users. To enhance the
spectral efficiency and to fully utilize the spatial resources, we also design
a greedy user scheduling scheme during the data transmission period. Compared
to existing low-rank models, the newly proposed SBEM offers an alternative for
channel acquisition without need of channel statistics for both TDD and FDD
systems based on the angle reciprocity. Moreover, the proposed method can be
efficiently deployed by the fast Fourier transform (FFT). Various numerical
results are provided to corroborate the proposed studies.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04846</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Short-Circuiting Validation of Data Structure Invariants</dc:title>
 <dc:creator>Tsai, Yi-Fan</dc:creator>
 <dc:creator>Coughlin, Devin</dc:creator>
 <dc:creator>Chang, Bor-Yuh Evan</dc:creator>
 <dc:creator>Rival, Xavier</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:description>  This paper presents incremental verification-validation, a novel approach for
checking rich data structure invariants expressed as separation logic
assertions. Incremental verification-validation combines static verification of
separation properties with efficient, short-circuiting dynamic validation of
arbitrarily rich data constraints. A data structure invariant checker is an
inductive predicate in separation logic with an executable interpretation; a
short-circuiting checker is an invariant checker that stops checking whenever
it detects at run time that an assertion for some sub-structure has been fully
proven statically. At a high level, our approach does two things: it statically
proves the separation properties of data structure invariants using a static
shape analysis in a standard way but then leverages this proof in a novel
manner to synthesize short-circuiting dynamic validation of the data
properties. As a consequence, we enable dynamic validation to make up for
imprecision in sound static analysis while simultaneously leveraging the static
verification to make the remaining dynamic validation efficient. We show
empirically that short-circuiting can yield asymptotic improvements in dynamic
validation, with low overhead over no validation, even in cases where static
verification is incomplete.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04854</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Heterogeneous Information Network Analysis</dc:title>
 <dc:creator>Shi, Chuan</dc:creator>
 <dc:creator>Li, Yitong</dc:creator>
 <dc:creator>Zhang, Jiawei</dc:creator>
 <dc:creator>Sun, Yizhou</dc:creator>
 <dc:creator>Yu, Philip S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Most real systems consist of a large number of interacting, multi-typed
components, while most contemporary researches model them as homogeneous
networks, without distinguishing different types of objects and links in the
networks. Recently, more and more researchers begin to consider these
interconnected, multi-typed data as heterogeneous information networks, and
develop structural analysis approaches by leveraging the rich semantic meaning
of structural types of objects and links in the networks. Compared to widely
studied homogeneous network, the heterogeneous information network contains
richer structure and semantic information, which provides plenty of
opportunities as well as a lot of challenges for data mining. In this paper, we
provide a survey of heterogeneous information network analysis. We will
introduce basic concepts of heterogeneous information network analysis, examine
its developments on different data mining tasks, discuss some advanced topics,
and point out some future research directions.
</dc:description>
 <dc:description>Comment: 45 pages, 12 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04855</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep learning is a good steganalysis tool when embedding key is reused
  for different images, even if there is a cover source-mismatch</dc:title>
 <dc:creator>Pibre, Lionel</dc:creator>
 <dc:creator>J&#xe9;r&#xf4;me, Pasquet</dc:creator>
 <dc:creator>Ienco, Dino</dc:creator>
 <dc:creator>Chaumont, Marc</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Since the BOSS competition, in 2010, most steganalysis approaches use a
learning methodology involving two steps: feature extraction, such as the Rich
Models (RM), for the image representation, and use of the Ensemble Classifier
(EC) for the learning step. In 2015, Qian et al. have shown that the use of a
deep learning approach that jointly learns and computes the features, is very
promising for the steganalysis. In this paper, we follow-up the study of Qian
et al., and show that, due to intrinsic joint minimization, the results
obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural
Network (FNN), if well parameterized, surpass the conventional use of a RM with
an EC. First, numerous experiments were conducted in order to find the best &quot;
shape &quot; of the CNN. Second, experiments were carried out in the clairvoyant
scenario in order to compare the CNN and FNN to an RM with an EC. The results
show more than 16% reduction in the classification error with our CNN or FNN.
Third, experiments were also performed in a cover-source mismatch setting. The
results show that the CNN and FNN are naturally robust to the mismatch problem.
In Addition to the experiments, we provide discussions on the internal
mechanisms of a CNN, and weave links with some previously stated ideas, in
order to understand the impressive results we obtained.
</dc:description>
 <dc:description>Comment: IS&amp;T. Media Watermarking, Security, and Forensics, Part of IS&amp;T
  International Symposium on Electronic Imaging, EI'2016, Feb 2015, San
  Fransisco, United States</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04861</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hadoop Mapreduce Performance Enhancement Using In-node Combiners</dc:title>
 <dc:creator>Lee, Woo-Hyun</dc:creator>
 <dc:creator>Jun, Hee-Gook</dc:creator>
 <dc:creator>Kim, Hyoung-Joo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  While advanced analysis of large dataset is in high demand, data sizes have
surpassed capabilities of conventional software and hardware. Hadoop framework
distributes large datasets over multiple commodity servers and performs
parallel computations. We discuss the I/O bottlenecks of Hadoop framework and
propose methods for enhancing I/O performance. A proven approach is to cache
data to maximize memory-locality of all map tasks. We introduce an approach to
optimize I/O, the in-node combining design which extends the traditional
combiner to a node level. The in-node combiner reduces the total number of
intermediate results and curtail network traffic between mappers and reducers.
</dc:description>
 <dc:description>Comment: International Journal of Computer Science &amp; Information Technology,
  2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04861</dc:identifier>
 <dc:identifier>doi:10.5121/ijcsit.2015.7501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04867</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quality assessment of voice converted speech using articulatory features</dc:title>
 <dc:creator>Rajpal, Avni</dc:creator>
 <dc:creator>Shah, Nirmesh J.</dc:creator>
 <dc:creator>Zaki, Mohammadi</dc:creator>
 <dc:creator>Patil, Hemant A.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We propose a novel application based on acoustic-to-articulatory inversion
towards quality assessment of voice converted speech. The ability of humans to
speak effortlessly requires coordinated movements of various articulators,
muscles, etc. This effortless movement contributes towards naturalness,
intelligibility and speakers identity which is partially present in voice
converted speech. Hence, during voice conversion, the information related to
speech production is lost. In this paper, this loss is quantified for male
voice, by showing increase in RMSE error for voice converted speech followed by
showing decrease in mutual information. Similar results are obtained in case of
female voice. This observation is extended by showing that articulatory
features can be used as an objective measure. The effectiveness of proposed
measure over MCD is illustrated by comparing their correlation with Mean
Opinion Score.
</dc:description>
 <dc:description>Comment: The paper is withdrawn from the arxiv. Author doesnot want
  circulation of unpublished unverified results</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04868</identifier>
 <datestamp>2016-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Transducer</dc:title>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:creator>Sussillo, David</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Sequence-to-sequence models have achieved impressive results on various
tasks. However, they are unsuitable for tasks that require incremental
predictions to be made as more data arrives or tasks that have long input
sequences and output sequences. This is because they generate an output
sequence conditioned on an entire input sequence. In this paper, we present a
Neural Transducer that can make incremental predictions as more input arrives,
without redoing the entire computation. Unlike sequence-to-sequence models, the
Neural Transducer computes the next-step distribution conditioned on the
partially observed input sequence and the partially generated sequence. At each
time step, the transducer can decide to emit zero to many output symbols. The
data can be processed using an encoder and presented as input to the
transducer. The discrete decision to emit a symbol at every time step makes it
difficult to learn with conventional backpropagation. It is however possible to
train the transducer by using a dynamic programming algorithm to generate
target discrete decisions. Our experiments show that the Neural Transducer
works well in settings where it is required to produce output predictions as
data come in. We also find that the Neural Transducer performs well for long
sequences even when attention mechanisms are not used.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-08-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04870</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isogeometric Boundary Element Analysis with elasto-plastic inclusions.
  Part 1: Plane problems</dc:title>
 <dc:creator>Beer, Gernot</dc:creator>
 <dc:creator>Marussig, Benjamin</dc:creator>
 <dc:creator>Zechner, J&#xfc;rgen</dc:creator>
 <dc:creator>D&#xfc;nser, Christian</dc:creator>
 <dc:creator>Fries, Thomas-Peter</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  In this work a novel approach is presented for the isogeometric Boundary
Element analysis of domains that contain inclusions with different elastic
properties than the ones used for computing the fundamental solutions. In
addition the inclusion may exhibit inelastic material behavior. In this paper
only plane stress/strain problems are considered.
  In our approach the geometry of the inclusion is described using NURBS basis
functions. The advantage over currently used methods is that no discretization
into cells is required in order to evaluate the arising volume integrals. The
other difference to current approaches is that Kernels of lower singularity are
used in the domain term. The implementation is verified on simple finite and
infinite domain examples with various boundary conditions. Finally a practical
application in geomechanics is presented.
</dc:description>
 <dc:description>Comment: 21 pages, 16 figures, 1 table</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04870</dc:identifier>
 <dc:identifier>doi:10.1016/j.cma.2016.03.035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04874</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operational Interpretation of Renyi Information Measures via Composite
  Hypothesis Testing Against Product and Markov Distributions</dc:title>
 <dc:creator>Tomamichel, Marco</dc:creator>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We revisit the problem of asymmetric binary hypothesis testing against a
composite alternative hypothesis. We introduce a general framework to treat
such problems when the alternative hypothesis adheres to certain axioms. In
this case we find the threshold rate, the optimal error and strong converse
exponents (at large deviations from the threshold) and the second order
asymptotics (at small deviations from the threshold). We apply our results to
find operational interpretations of various Renyi information measures. In case
the alternative hypothesis is comprised of bipartite product distributions, we
find that the optimal error and strong converse exponents are determined by
variations of Renyi mutual information. In case the alternative hypothesis
consists of tripartite distributions satisfying the Markov property, we find
that the optimal exponents are determined by variations of Renyi conditional
mutual information. In either case the relevant notion of Renyi mutual
information depends on the precise choice of the alternative hypothesis. As
such, our work also strengthens the view that different definitions of Renyi
mutual information, conditional entropy and conditional mutual information are
adequate depending on the context in which the measures are used.
</dc:description>
 <dc:description>Comment: published version</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04874</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2776900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04891</identifier>
 <datestamp>2016-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sherlock: Scalable Fact Learning in Images</dc:title>
 <dc:creator>Elhoseiny, Mohamed</dc:creator>
 <dc:creator>Cohen, Scott</dc:creator>
 <dc:creator>Chang, Walter</dc:creator>
 <dc:creator>Price, Brian</dc:creator>
 <dc:creator>Elgammal, Ahmed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study scalable and uniform understanding of facts in images. Existing
visual recognition systems are typically modeled differently for each fact type
such as objects, actions, and interactions. We propose a setting where all
these facts can be modeled simultaneously with a capacity to understand
unbounded number of facts in a structured way. The training data comes as
structured facts in images, including (1) objects (e.g., $&lt;$boy$&gt;$), (2)
attributes (e.g., $&lt;$boy, tall$&gt;$), (3) actions (e.g., $&lt;$boy, playing$&gt;$), and
(4) interactions (e.g., $&lt;$boy, riding, a horse $&gt;$). Each fact has a semantic
language view (e.g., $&lt;$ boy, playing$&gt;$) and a visual view (an image with this
fact). We show that learning visual facts in a structured way enables not only
a uniform but also generalizable visual understanding. We propose and
investigate recent and strong approaches from the multiview learning literature
and also introduce two learning representation models as potential baselines.
We applied the investigated methods on several datasets that we augmented with
structured facts and a large scale dataset of more than 202,000 facts and
814,000 images. Our experiments show the advantage of relating facts by the
structure by the proposed models compared to the designed baselines on
bidirectional fact retrieval.
</dc:description>
 <dc:description>Comment: Jan 7 Update</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04892</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A discontinuous Galerkin Method for the EEG Forward Problem using the
  Subtraction Approach</dc:title>
 <dc:creator>Engwer, Christian</dc:creator>
 <dc:creator>Vorwerk, Johannes</dc:creator>
 <dc:creator>Ludewig, Jakob</dc:creator>
 <dc:creator>Wolters, Carsten H.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>35J25, 35J75, 35Q90, 65N12, 65N30, 68U20, 92C50</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.1.10</dc:subject>
 <dc:subject>I.6.0</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  In order to perform electroencephalography (EEG) source reconstruction, i.e.,
to localize the sources underlying a measured EEG, the electric potential
distribution at the electrodes generated by a dipolar current source in the
brain has to be simulated, which is the so-called EEG forward problem. To solve
it accurately, it is necessary to apply numerical methods that are able to take
the individual geometry and conductivity distribution of the subject's head
into account. In this context, the finite element method (FEM) has shown high
numerical accuracy with the possibility to model complex geometries and
conductive features, e.g., white matter conductivity anisotropy. In this
article, we introduce and analyze the application of a discontinuous Galerkin
(DG) method, a finite element method that includes features of the finite
volume framework, to the EEG forward problem. The DG-FEM approach fulfills the
conservation property of electric charge also in the discrete case, making it
attractive for a variety of applications. Furthermore, as we show, this
approach can alleviate modeling inaccuracies that might occur in head
geometries when using classical FE methods, e.g., so-called &quot;skull leakage
effects&quot;, which may occur in areas where the thickness of the skull is in the
range of the mesh resolution. Therefore, we derive a DG formulation of the FEM
subtraction approach for the EEG forward problem and present numerical results
that highlight the advantageous features and the potential benefits of the
proposed approach.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04893</identifier>
 <datestamp>2016-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Free Commutative Grammars with Integer Counters and Resets</dc:title>
 <dc:creator>Chistikov, Dmitry</dc:creator>
 <dc:creator>Haase, Christoph</dc:creator>
 <dc:creator>Halfon, Simon</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  We study the computational complexity of reachability, coverability and
inclusion for extensions of context-free commutative grammars with integer
counters and reset operations on them. Those grammars can alternatively be
viewed as an extension of communication-free Petri nets. Our main results are
that reachability and coverability are inter-reducible and both NP-complete. In
particular, this class of commutative grammars enjoys semi-linear reachability
sets. We also show that the inclusion problem is, in general, coNEXP-complete
and already $\Pi_2^\text{P}$-complete for grammars with only one non-terminal
symbol. Showing the lower bound for the latter result requires us to develop a
novel $\Pi_2^\text{P}$-complete variant of the classic subset sum problem.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04897</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ARMageddon: Cache Attacks on Mobile Devices</dc:title>
 <dc:creator>Lipp, Moritz</dc:creator>
 <dc:creator>Gruss, Daniel</dc:creator>
 <dc:creator>Spreitzer, Raphael</dc:creator>
 <dc:creator>Maurice, Cl&#xe9;mentine</dc:creator>
 <dc:creator>Mangard, Stefan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the last 10 years, cache attacks on Intel x86 CPUs have gained increasing
attention among the scientific community and powerful techniques to exploit
cache side channels have been developed. However, modern smartphones use one or
more multi-core ARM CPUs that have a different cache organization and
instruction set than Intel x86 CPUs. So far, no cross-core cache attacks have
been demonstrated on non-rooted Android smartphones. In this work, we
demonstrate how to solve key challenges to perform the most powerful cross-core
cache attacks Prime+Probe, Flush+Reload, Evict+Reload, and Flush+Flush on
non-rooted ARM-based devices without any privileges. Based on our techniques,
we demonstrate covert channels that outperform state-of-the-art covert channels
on Android by several orders of magnitude. Moreover, we present attacks to
monitor tap and swipe events as well as keystrokes, and even derive the lengths
of words entered on the touchscreen. Eventually, we are the first to attack
cryptographic primitives implemented in Java. Our attacks work across CPUs and
can even monitor cache activity in the ARM TrustZone from the normal world. The
techniques we present can be used to attack hundreds of millions of Android
devices.
</dc:description>
 <dc:description>Comment: Original publication in the Proceedings of the 25th Annual USENIX
  Security Symposium (USENIX Security 2016).
  https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04898</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast clustering for scalable statistical analysis on structured images</dc:title>
 <dc:creator>Thirion, Bertrand</dc:creator>
 <dc:creator>Hoyos-Idrobo, Andr&#xe9;s</dc:creator>
 <dc:creator>Kahn, Jonas</dc:creator>
 <dc:creator>Varoquaux, Gael</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The use of brain images as markers for diseases or behavioral differences is
challenged by the small effects size and the ensuing lack of power, an issue
that has incited researchers to rely more systematically on large cohorts.
Coupled with resolution increases, this leads to very large datasets. A
striking example in the case of brain imaging is that of the Human Connectome
Project: 20 Terabytes of data and growing. The resulting data deluge poses
severe challenges regarding the tractability of some processing steps
(discriminant analysis, multivariate models) due to the memory demands posed by
these data. In this work, we revisit dimension reduction approaches, such as
random projections, with the aim of replacing costly function evaluations by
cheaper ones while decreasing the memory requirements. Specifically, we
investigate the use of alternate schemes, based on fast clustering, that are
well suited for signals exhibiting a strong spatial structure, such as
anatomical and functional brain images. Our contribution is twofold: i) we
propose a linear-time clustering scheme that bypasses the percolation issues
inherent in these algorithms and thus provides compressions nearly as good as
traditional quadratic-complexity variance-minimizing clustering schemes, ii) we
show that cluster-based compression can have the virtuous effect of removing
high-frequency noise, actually improving subsequent estimations steps. As a
consequence, the proposed approach yields very accurate models on several
large-scale problems yet with impressive gains in computational efficiency,
making it possible to analyze large datasets.
</dc:description>
 <dc:description>Comment: ICML Workshop on Statistics, Machine Learning and Neuroscience
  (Stamlins 2015), Jul 2015, Lille, France</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04901</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse-to-fine Face Alignment with Multi-Scale Local Patch Regression</dc:title>
 <dc:creator>Huang, Zhiao</dc:creator>
 <dc:creator>Zhou, Erjin</dc:creator>
 <dc:creator>Cao, Zhimin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial landmark localization plays an important role in face recognition and
analysis applications. In this paper, we give a brief introduction to a
coarse-to-fine pipeline with neural networks and sequential regression. First,
a global convolutional network is applied to the holistic facial image to give
an initial landmark prediction. A pyramid of multi-scale local image patches is
then cropped to feed to a new network for each landmark to refine the
prediction. As the refinement network outputs a more accurate position
estimation than the input, such procedure could be repeated several times until
the estimation converges. We evaluate our system on the 300-W dataset [11] and
it outperforms the recent state-of-the-arts.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04902</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based denoising for time-varying point clouds</dc:title>
 <dc:creator>Schoenenberger, Yann</dc:creator>
 <dc:creator>Paratte, Johan</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Noisy 3D point clouds arise in many applications. They may be due to errors
when constructing a 3D model from images or simply to imprecise depth sensors.
Point clouds can be given geometrical structure using graphs created from the
similarity information between points. This paper introduces a technique that
uses this graph structure and convex optimization methods to denoise 3D point
clouds. A short discussion presents how those methods naturally generalize to
time-varying inputs such as 3D point cloud time series.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 3DTV-Con 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04902</dc:identifier>
 <dc:identifier>3DTV-Conference: The True Vision - Capture, Transmission and
  Display of 3D Video (3DTV-CON) (2015) 1-4</dc:identifier>
 <dc:identifier>doi:10.1109/3DTV.2015.7169366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04906</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performing Highly Accurate Predictions Through Convolutional Networks
  for Actual Telecommunication Challenges</dc:title>
 <dc:creator>Zaratiegui, Jaime</dc:creator>
 <dc:creator>Montoro, Ana</dc:creator>
 <dc:creator>Castanedo, Federico</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We investigated how the application of deep learning, specifically the use of
convolutional networks trained with GPUs, can help to build better predictive
models in telecommunication business environments, and fill this gap. In
particular, we focus on the non-trivial problem of predicting customer churn in
telecommunication operators. Our model, called WiseNet, consists of a
convolutional network and a novel encoding method that transforms customer
activity data and Call Detail Records (CDRs) into images. Experimental
evaluation with several machine learning classifiers supports the ability of
WiseNet for learning features when using structured input data. For this type
of telecommunication business problems, we found that WiseNet outperforms
machine learning models with hand-crafted features, and does not require the
labor-intensive step of feature engineering. Furthermore, the same model has
been applied without retraining to a different market, achieving consistent
results. This confirms the generalization property of WiseNet and the ability
to extract useful representations.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, accepted by IJCAI-16 Workshop on Deep Learning
  for Artificial Intelligence (DLAI)</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04919</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tales told by coloured tangles</dc:title>
 <dc:creator>Moskovich, Daniel</dc:creator>
 <dc:creator>Carmi, Avishy Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Geometric Topology</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>94A15, 81P68, 57M99</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>F.0</dc:subject>
 <dc:description>  Tangle machines are a topologically inspired diagrammatic formalism to
describe information flow in networks. This paper begins with an expository
account of tangle machines motivated by the problem of describing `covariance
intersection' fusion of Gaussian estimators in networks. It then gives two
examples in which tangle machines tell stories of adiabatic quantum
computations, and discusses learning tangle machines from data.
</dc:description>
 <dc:description>Comment: 29 pages, 28 figures. Revised to be more self-contained</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04919</dc:identifier>
 <dc:identifier>Int. J. Unconv. Comput. 12(1) 71-105 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04925</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PageRank in undirected random graphs</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Kadavankandy, Arun</dc:creator>
 <dc:creator>Ostroumova, Liudmila</dc:creator>
 <dc:creator>Raigorodskii, Andrei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  PageRank has numerous applications in information retrieval, reputation
systems, machine learning, and graph partitioning.In this paper, we study
PageRank in undirected random graphs with expansion property. The Chung-Lu
random graph representsan example of such graphs. We show that in the limit, as
the size of the graph goes to infinity, PageRank can be represented by a
mixture of the restart distribution and the vertex degree distribution.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04925</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-26784-5_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04926</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A framework for deadlock detection in core ABS</dc:title>
 <dc:creator>Giachino, Elena</dc:creator>
 <dc:creator>Laneve, Cosimo</dc:creator>
 <dc:creator>Lienhardt, Michael</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a framework for statically detecting deadlocks in a concurrent
object-oriented language with asynchronous method calls and cooperative
scheduling of method activations. Since this language features recursion and
dynamic resource creation, deadlock detection is extremely complex and
state-of-the-art solutions either give imprecise answers or do not scale. In
order to augment precision and scalability we propose a modular framework that
allows several techniques to be combined. The basic component of the framework
is a front-end inference algorithm that extracts abstract behavioural
descriptions of methods, called contracts, which retain resource dependency
information. This component is integrated with a number of possible different
back-ends that analyse contracts and derive deadlock information. As a
proof-of-concept, we discuss two such back-ends: (i) an evaluator that computes
a fixpoint semantics and (ii) an evaluator using abstract model checking.
</dc:description>
 <dc:description>Comment: Software and Systems Modeling, Springer Verlag, 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04926</dc:identifier>
 <dc:identifier>doi:10.1007/s10270-014-0444-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04930</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Access for Machine-Type Communication based on Bloom Filtering</dc:title>
 <dc:creator>Pratas, Nuno K.</dc:creator>
 <dc:creator>Stefanovic, Cedomir</dc:creator>
 <dc:creator>Madueno, German Corrales</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present a random access method inspired on Bloom filters that is suited
for Machine-Type Communications (MTC). Each accessing device sends a
\emph{signature} during the contention process. A signature is constructed
using the Bloom filtering method and contains information on the device
identity and the connection establishment cause. We instantiate the proposed
method over the current LTE-A access protocol. However, the method is
applicable to a more general class of random access protocols that use
preambles or other reservation sequences, as expected to be the case in 5G
systems. We show that our method utilizes the system resources more efficiently
and achieves significantly lower connection establishment latency in case of
synchronous arrivals, compared to the variant of the LTE-A access protocol that
is optimized for MTC traffic. A dividend of the proposed method is that it
allows the base station (BS) to acquire the device identity and the connection
establishment cause already in the initial phase of the connection
establishment, thereby enabling their differentiated treatment by the BS.
</dc:description>
 <dc:description>Comment: Accepted for presentation on IEEE Globecom 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04934</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification and Counting White Blood Cells and Red Blood Cells using
  Image Processing Case Study of Leukemia</dc:title>
 <dc:creator>Suryani, Esti</dc:creator>
 <dc:creator>Wiharto, Wiharto</dc:creator>
 <dc:creator>Polvonov, Nizomjon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Leukemia is diagnosed with complete blood counts which is by calculating all
blood cells and compare the number of white blood cells (White Blood Cells /
WBC) and red blood cells (Red Blood Cells / RBC). Information obtained from a
complete blood count, has become a cornerstone in the hematology laboratory for
diagnostic purposes and monitoring of hematological disorders. However, the
traditional procedure for counting blood cells manually requires effort and a
long time, therefore this method is one of the most expensive routine tests in
laboratory hematology clinic. Solution for such kind of time consuming task and
necessity of data tracability can be found in image processing techniques based
on blood cell morphology . This study aims to identify Acute Lymphocytic
Leukemia (ALL) and Acute Myeloid Leukemia type M3 (AML M3) using Fuzzy Rule
Based System based on morphology of white blood cells. Characteristic
parameters witch extractedare WBC Area, Nucleus and Granule Ratio of white
blood cells. Image processing algorithms such as thresholding, Canny edge
detection and color identification filters are used.Then for identification of
ALL, AML M3 and Healthy cells used Fuzzy Rule Based System with Sugeno method.
In the testing process used 104 images out of which 29 ALL - Positive, 50 AML
M3 - Positive and 25 Healthy cells. Test results showed 83.65 % accuracy .
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04944</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NASCUP: Nucleic Acid Sequence Classification by Universal Probability</dc:title>
 <dc:creator>Kwon, Sunyoung</dc:creator>
 <dc:creator>Kim, Gyuwan</dc:creator>
 <dc:creator>Lee, Byunghan</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:creator>Kim, Young-Han</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by the need for fast and accurate classification of unlabeled
nucleotide sequences on a large scale, we propose a new classification method
that captures the probabilistic structure of a sequence family as a compact
context-tree model and uses it efficiently to test proximity and membership of
a query sequence. The proposed nucleic acid sequence classification by
universal probability (NASCUP) method crucially utilizes the notion of
universal probability from information theory in model-building and
classification processes, delivering BLAST-like accuracy in orders-of-magnitude
reduced runtime for large-scale databases. A comprehensive experimental study
involving seven public databases for functional non-coding RNA classification
and microbial taxonomy classification demonstrates the advantages of NASCUP
over widely-used alternatives in efficiency, accuracy, and scalability across
all datasets considered. [availability: http://data.snu.ac.kr/nascup]
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04946</identifier>
 <datestamp>2016-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context Sensitive Article Ranking with Citation Context Analysis</dc:title>
 <dc:creator>Doslu, Metin</dc:creator>
 <dc:creator>Bingol, Haluk O.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:description>  It is hard to detect important articles in a specific context. Information
retrieval techniques based on full text search can be inaccurate to identify
main topics and they are not able to provide an indication about the importance
of the article. Generating a citation network is a good way to find most
popular articles but this approach is not context aware.
  The text around a citation mark is generally a good summary of the referred
article. So citation context analysis presents an opportunity to use the wisdom
of crowd for detecting important articles in a context sensitive way. In this
work, we analyze citation contexts to rank articles properly for a given topic.
The model proposed uses citation contexts in order to create a directed and
weighted citation network based on the target topic. We create a directed and
weighted edge between two articles if citation context contains terms related
with the target topic. Then we apply common ranking algorithms in order to find
important articles in this newly created network. We showed that this method
successfully detects a good subset of most prominent articles in a given topic.
The biggest contribution of this approach is that we are able to identify
important articles for a given search term even though these articles do not
contain this search term. This technique can be used in other linked documents
including web pages, legal documents, and patents.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04946</dc:identifier>
 <dc:identifier>Scientometrics (2016) 108:653-671</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-016-1982-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04952</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planar Disjoint-Paths Completion</dc:title>
 <dc:creator>Adler, Isolde</dc:creator>
 <dc:creator>Kolliopoulos, Stavros G.</dc:creator>
 <dc:creator>Thilikos, Dimitrios M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C10</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  introduce {\sc Planar Disjoint Paths Completion}, a completion counterpart of
the Disjoint Paths problem, and study its parameterized complexity. The problem
can be stated as follows: given a, not necessarily connected, plane graph $G,$
$k$ pairs of terminals, and a face $F$ of $G,$ find a minimum-size set of
edges, if one exists, to be added inside $F$ so that the embedding remains
planar and the pairs become connected by $k$ disjoint paths in the augmented
network. Our results are twofold: first, we give an upper bound on the number
of necessary additional edges when a solution exists. This bound is a function
of $k$, independent of the size of $G.$ Second, we show that the problem is
fixed-parameter tractable, in particular, it can be solved in time $f(k)\cdot
n^{2}.$
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04960</identifier>
 <datestamp>2016-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample and Filter: Nonparametric Scene Parsing via Efficient Filtering</dc:title>
 <dc:creator>Najafi, Mohammad</dc:creator>
 <dc:creator>Namin, Sarah Taghavi</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>Petersson, Lars</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene parsing has attracted a lot of attention in computer vision. While
parametric models have proven effective for this task, they cannot easily
incorporate new training data. By contrast, nonparametric approaches, which
bypass any learning phase and directly transfer the labels from the training
data to the query images, can readily exploit new labeled samples as they
become available. Unfortunately, because of the computational cost of their
label transfer procedures, state-of-the-art nonparametric methods typically
filter out most training images to only keep a few relevant ones to label the
query. As such, these methods throw away many images that still contain
valuable information and generally obtain an unbalanced set of labeled samples.
In this paper, we introduce a nonparametric approach to scene parsing that
follows a sample-and-filter strategy. More specifically, we propose to sample
labeled superpixels according to an image similarity score, which allows us to
obtain a balanced set of samples. We then formulate label transfer as an
efficient filtering procedure, which lets us exploit more labeled samples than
existing techniques. Our experiments evidence the benefits of our approach over
state-of-the-art nonparametric methods on two benchmark datasets.
</dc:description>
 <dc:description>Comment: Please refer to the CVPR-2016 version of this manuscript</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04970</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning about Spanish dialects through Twitter</dc:title>
 <dc:creator>Gon&#xe7;alves, Bruno</dc:creator>
 <dc:creator>S&#xe1;nchez, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  This paper maps the large-scale variation of the Spanish language by
employing a corpus based on geographically tagged Twitter messages. Lexical
dialects are extracted from an analysis of variants of tens of concepts. The
resulting maps show linguistic variation on an unprecedented scale across the
globe. We discuss the properties of the main dialects within a machine learning
approach and find that varieties spoken in urban areas have an international
character in contrast to country areas where dialects show a more regional
uniformity.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, 1 table</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04970</dc:identifier>
 <dc:identifier>RILI, XVI 2 (28), 65-75 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04985</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Paxos Made Switch-y</dc:title>
 <dc:creator>Dang, Huynh Tu</dc:creator>
 <dc:creator>Canini, Marco</dc:creator>
 <dc:creator>Pedone, Fernando</dc:creator>
 <dc:creator>Soul&#xe9;, Robert</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper describes an implementation of the well-known consensus protocol,
Paxos, in the P4 programming language. P4 is a language for programming the
behavior of network forwarding devices (i.e., the network data plane). Moving
consensus logic into network devices could significantly improve the
performance of the core infrastructure and services in data centers. Moreover,
implementing Paxos in P4 provides a critical use case and set of requirements
for data plane language designers. In the long term, we imagine that consensus
could someday be offered as a network service, just as point-to-point
communication is provided today.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04986</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A genetic algorithm to discover flexible motifs with support</dc:title>
 <dc:creator>Serr&#xe0;, Joan</dc:creator>
 <dc:creator>Matic, Aleksandar</dc:creator>
 <dc:creator>Arcos, Josep Luis</dc:creator>
 <dc:creator>Karatzoglou, Alexandros</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Finding repeated patterns or motifs in a time series is an important
unsupervised task that has still a number of open issues, starting by the
definition of motif. In this paper, we revise the notion of motif support,
characterizing it as the number of patterns or repetitions that define a motif.
We then propose GENMOTIF, a genetic algorithm to discover motifs with support
which, at the same time, is flexible enough to accommodate other motif
specifications and task characteristics. GENMOTIF is an anytime algorithm that
easily adapts to many situations: searching in a range of segment lengths,
applying uniform scaling, dealing with multiple dimensions, using different
similarity and grouping criteria, etc. GENMOTIF is also parameter-friendly: it
has only two intuitive parameters which, if set within reasonable bounds, do
not substantially affect its performance. We demonstrate the value of our
approach in a number of synthetic and real-world settings, considering traffic
volume measurements, accelerometer signals, and telephone call records.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, code available at
  https://github.com/joansj/genmotif</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04996</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Hops or More: On Hop-Limited Search in Opportunistic Networks</dc:title>
 <dc:creator>Bayhan, Suzan</dc:creator>
 <dc:creator>Hyyti&#xe4;, Esa</dc:creator>
 <dc:creator>Kangasharju, Jussi</dc:creator>
 <dc:creator>Ott, J&#xf6;rg</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  While there is a drastic shift from host-centric networking to
content-centric networking, how to locate and retrieve the relevant content
efficiently, especially in a mobile network, is still an open question. Mobile
devices host increasing volume of data which could be shared with the nearby
nodes in a multi-hop fashion. However, searching for content in this
resource-restricted setting is not trivial due to the lack of a content index,
as well as, desire for keeping the search cost low. In this paper, we analyze a
lightweight search scheme, hop-limited search, that forwards the search
messages only till a maximum number of hops, and requires no prior knowledge
about the network. We highlight the effect of the hop limit on both search
performance (i.e., success ratio and delay) and associated cost along with the
interplay between content availability, tolerated waiting time, network
density, and mobility. Our analysis, using the real mobility traces, as well as
synthetic models, shows that the most substantial benefit is achieved at the
first few hops and that after several hops the extra gain diminishes as a
function of content availability and tolerated delay. We also observe that the
return path taken by a response is on average longer than the forward path of
the query and that the search cost increases only marginally after several hops
due to the small network diameter.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.04996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05006</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Quantum Noncompression</dc:title>
 <dc:creator>Epstein, Samuel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This article presents a quantum transmission problem, in which Alice is
trying to send a number of qbits to Bob. Alice has access to two channels, one
that sends classical bits and another that sends quantum bits. We show that
under certain error terms, Alice can optimize transmission, up to logarithmic
precision, by sending only a classical description of the qbits.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05009</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Graphs are 2-Dot Product Graphs?</dc:title>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Paulusma, Daniel</dc:creator>
 <dc:creator>van Leeuwen, Erik Jan</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $d \geq 1$ be an integer. From a set of $d$-dimensional vectors, we
obtain a $d$-dot product graph by letting each vector ${\bf a}^u$ correspond to
a vertex $u$ and by adding an edge between two vertices $u$ and $v$ if and only
if their dot product ${\bf a}^{u} \cdot {\bf a}^{v} \geq t$, for some fixed,
positive threshold~$t$. Dot product graphs can be used to model social
networks. Recognizing a $d$-dot product graph is known to be \NP-hard for all
fixed $d\geq 2$. To understand the position of $d$-dot product graphs in the
landscape of graph classes, we consider the case $d=2$, and investigate how
$2$-dot product graphs relate to a number of other known graph classes.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05010</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eventually Consistent Register Revisited</dc:title>
 <dc:creator>Zawirski, Marek</dc:creator>
 <dc:creator>Baquero, Carlos</dc:creator>
 <dc:creator>Bieniusa, Annette</dc:creator>
 <dc:creator>Pregui&#xe7;a, Nuno</dc:creator>
 <dc:creator>Shapiro, Marc</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In order to converge in the presence of concurrent updates, modern eventually
consistent replication systems rely on causality information and operation
semantics. It is relatively easy to use semantics of high-level operations on
replicated data structures, such as sets, lists, etc. However, it is difficult
to exploit semantics of operations on registers, which store opaque data. In
existing register designs, concurrent writes are resolved either by the
application, or by arbitrating them according to their timestamps. The former
is complex and may require user intervention, whereas the latter causes
arbitrary updates to be lost. In this work, we identify a register construction
that generalizes existing ones by combining runtime causality ordering, to
identify concurrent writes, with static data semantics, to resolve them. We
propose a simple conflict resolution template based on an
application-predefined order on the domain of values. It eliminates or reduces
the number of conflicts that need to be resolved by the user or by an explicit
application logic. We illustrate some variants of our approach with use cases,
and how it generalizes existing designs.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05012</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimum Transmission Through the Multiple-Antenna Gaussian Multiple
  Access Channel</dc:title>
 <dc:creator>Calabuig, Daniel</dc:creator>
 <dc:creator>Gohary, Ramy H.</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the optimal points in the capacity region of Gaussian
multiple access channels (GMACs) with constant fading, multiple antennas and
various power constraints. The points of interest maximize general rate
objectives that arise in practical communication scenarios. Achieving these
points constitutes the task of jointly optimizing the time-sharing parameters,
the input covariance matrices and the order of decoding used by the successive
interference cancellation receiver. To approach this problem, Carath\'eodory's
theorem is invoked to represent time-sharing and decoding orders jointly as a
finite-dimensional matrix variable. This variable enables us to use variational
inequalities to extend results pertaining to problems with linear rate
objectives to more general, potentially nonconvex, problems, and to obtain a
necessary and sufficient condition for the optimality of the transmission
parameters in a wide range of problems. Using the insights gained from this
condition, we develop and analyze the convergence of an algorithm for solving,
otherwise daunting, GMAC-based optimization problems.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Information Theory, 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05012</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, vol. 62, no. 1, pp.
  230-243, Jan. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2015.2502244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05023</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved bounds on the peak sidelobe level of binary sequences</dc:title>
 <dc:creator>Mercer, Idris</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Schmidt proved in 2014 that if $\varepsilon&gt;0$, almost all binary sequences
of length $n$ have peak sidelobe level between
$(\sqrt{2}-\varepsilon)\sqrt{n\log n}$ and $(\sqrt{2}+\varepsilon)\sqrt{n\log
n}$. Because of the small gap between his upper and lower bounds, it is
difficult to find improved upper bounds that hold for almost all binary
sequences. In this note, we prove that if $\varepsilon&gt;0$, then almost all
binary sequences of length $n$ have peak sidelobe level at most $\sqrt{2n(\log
n-(1-\varepsilon)\log\log n)}$, and we provide a slightly better upper bound
that holds for a positive proportion of binary sequences of length $n$.
</dc:description>
 <dc:description>Comment: Added Corollary 4 and its proof</dc:description>
 <dc:date>2015-11-04</dc:date>
 <dc:date>2015-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05027</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth, Highness and DNR degrees</dc:title>
 <dc:creator>Moser, Philippe</dc:creator>
 <dc:creator>Stephan, Frank</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study Bennett deep sequences in the context of recursion theory; in
particular we investigate the notions of O(1)-deepK, O(1)-deepC , order-deep K
and order-deep C sequences. Our main results are that Martin-Loef random sets
are not order-deepC , that every many-one degree contains a set which is not
O(1)-deepC , that O(1)-deepC sets and order-deepK sets have high or DNR Turing
degree and that no K-trival set is O(1)-deepK.
</dc:description>
 <dc:description>Comment: journal version, dmtcs</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05027</dc:identifier>
 <dc:identifier>Discrete Mathematics &amp; Theoretical Computer Science, vol 19 no. 4,
  FCT '15, special issue FCT'15 (October 26, 2017) dmtcs:4012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05042</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Exploration of Softmax Alternatives Belonging to the Spherical Loss
  Family</dc:title>
 <dc:creator>de Br&#xe9;bisson, Alexandre</dc:creator>
 <dc:creator>Vincent, Pascal</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In a multi-class classification problem, it is standard to model the output
of a neural network as a categorical distribution conditioned on the inputs.
The output must therefore be positive and sum to one, which is traditionally
enforced by a softmax. This probabilistic mapping allows to use the maximum
likelihood principle, which leads to the well-known log-softmax loss. However
the choice of the softmax function seems somehow arbitrary as there are many
other possible normalizing functions. It is thus unclear why the log-softmax
loss would perform better than other loss alternatives. In particular Vincent
et al. (2015) recently introduced a class of loss functions, called the
spherical family, for which there exists an efficient algorithm to compute the
updates of the output weights irrespective of the output size. In this paper,
we explore several loss functions from this family as possible alternatives to
the traditional log-softmax. In particular, we focus our investigation on
spherical bounds of the log-softmax loss and on two spherical log-likelihood
losses, namely the log-Spherical Softmax suggested by Vincent et al. (2015) and
the log-Taylor Softmax that we introduce. Although these alternatives do not
yield as good results as the log-softmax loss on two language modeling tasks,
they surprisingly outperform it in our experiments on MNIST and CIFAR-10,
suggesting that they might be relevant in a broad range of applications.
</dc:description>
 <dc:description>Comment: Published at ICLR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05045</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handcrafted Local Features are Convolutional Neural Networks</dc:title>
 <dc:creator>Lan, Zhenzhong</dc:creator>
 <dc:creator>Yu, Shoou-I</dc:creator>
 <dc:creator>Lin, Ming</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:creator>Hauptmann, Alexander G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image and video classification research has made great progress through the
development of handcrafted local features and learning based features. These
two architectures were proposed roughly at the same time and have flourished at
overlapping stages of history. However, they are typically viewed as distinct
approaches. In this paper, we emphasize their structural similarities and show
how such a unified view helps us in designing features that balance efficiency
and effectiveness. As an example, we study the problem of designing efficient
video feature learning algorithms for action recognition.
  We approach this problem by first showing that local handcrafted features and
Convolutional Neural Networks (CNNs) share the same convolution-pooling network
structure. We then propose a two-stream Convolutional ISA (ConvISA) that adopts
the convolution-pooling structure of the state-of-the-art handcrafted video
feature with greater modeling capacities and a cost-effective training
algorithm. Through custom designed network structures for pixels and optical
flow, our method also reflects distinctive characteristics of these two data
sources.
  Our experimental results on standard action recognition benchmarks show that
by focusing on the structure of CNNs, rather than end-to-end training methods,
we are able to design an efficient and powerful video feature learning
algorithm.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05049</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Study of Recent Face Alignment Methods</dc:title>
 <dc:creator>Yang, Heng</dc:creator>
 <dc:creator>Jia, Xuhui</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Robinson, Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of face alignment has been intensively studied in the past years.
A large number of novel methods have been proposed and reported very good
performance on benchmark dataset such as 300W. However, the differences in the
experimental setting and evaluation metric, missing details in the description
of the methods make it hard to reproduce the results reported and evaluate the
relative merits. For instance, most recent face alignment methods are built on
top of face detection but from different face detectors. In this paper, we
carry out a rigorous evaluation of these methods by making the following
contributions: 1) we proposes a new evaluation metric for face alignment on a
set of images, i.e., area under error distribution curve within a threshold,
AUC$_\alpha$, given the fact that the traditional evaluation measure (mean
error) is very sensitive to big alignment error. 2) we extend the 300W database
with more practical face detections to make fair comparison possible. 3) we
carry out face alignment sensitivity analysis w.r.t. face detection, on both
synthetic and real data, using both off-the-shelf and re-retrained models. 4)
we study factors that are particularly important to achieve good performance
and provide suggestions for practical applications. Most of the conclusions
drawn from our comparative analysis cannot be inferred from the original
publications.
</dc:description>
 <dc:description>Comment: under review of a conference. Project page:
  https://www.cl.cam.ac.uk/~hy306/FaceAlignment.html</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05053</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Polynomial Lower Bound for Testing Monotonicity</dc:title>
 <dc:creator>Belovs, Aleksandrs</dc:creator>
 <dc:creator>Blais, Eric</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that every algorithm for testing $n$-variate Boolean functions for
monotonicity must have query complexity $\tilde{\Omega}(n^{1/4})$. All previous
lower bounds for this problem were designed for non-adaptive algorithms and, as
a result, the best previous lower bound for general (possibly adaptive)
monotonicity testers was only $\Omega(\log n)$. Combined with the query
complexity of the non-adaptive monotonicity tester of Khot, Minzer, and Safra
(FOCS 2015), our lower bound shows that adaptivity can result in at most a
quadratic reduction in the query complexity for testing monotonicity.
  By contrast, we show that there is an exponential gap between the query
complexity of adaptive and non-adaptive algorithms for testing regular linear
threshold functions (LTFs) for monotonicity. Chen, De, Servedio, and Tan (STOC
2015) recently showed that non-adaptive algorithms require almost
$\Omega(n^{1/2})$ queries for this task. We introduce a new adaptive
monotonicity testing algorithm which has query complexity $O(\log n)$ when the
input is a regular LTF.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05060</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving the Forward Position Problem of an In-Parallel Planar
  Manipulator in the Gauss Plane</dc:title>
 <dc:creator>Sahin, Sureyya</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We study determining the posture of an in-parallel planar manipulator, which
has three connectors composed of revolute, prismatic and revolute joints, from
specified active joint variables. We construct an ideal in the field of complex
numbers, and we introduce self inversive polynomials. We provide results for an
in-parallel planar manipulator, which has a base and moving platform in right
triangular shape. Using Sage computer algebra system, we compute its Groebner
bases. We illustrate that the single variable polynomials obtained from the
Groebner bases are self reciprocal.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05065</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proposal Flow</dc:title>
 <dc:creator>Ham, Bumsub</dc:creator>
 <dc:creator>Cho, Minsu</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:creator>Ponce, Jean</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Finding image correspondences remains a challenging problem in the presence
of intra-class variations and large changes in scene layout.~Semantic flow
methods are designed to handle images depicting different instances of the same
object or scene category. We introduce a novel approach to semantic flow,
dubbed proposal flow, that establishes reliable correspondences using object
proposals. Unlike prevailing semantic flow approaches that operate on pixels or
regularly sampled local regions, proposal flow benefits from the
characteristics of modern object proposals, that exhibit high repeatability at
multiple scales, and can take advantage of both local and geometric consistency
constraints among proposals. We also show that proposal flow can effectively be
transformed into a conventional dense flow field. We introduce a new dataset
that can be used to evaluate both general semantic flow techniques and
region-based approaches such as proposal flow. We use this benchmark to compare
different matching algorithms, object proposals, and region features within
proposal flow, to the state of the art in semantic flow. This comparison, along
with experiments on standard datasets, demonstrates that proposal flow
significantly outperforms existing semantic flow methods in various settings.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05067</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Training of Generic CNN-CRF Models with Stochastic Optimization</dc:title>
 <dc:creator>Kirillov, Alexander</dc:creator>
 <dc:creator>Schlesinger, Dmitrij</dc:creator>
 <dc:creator>Zheng, Shuai</dc:creator>
 <dc:creator>Savchynskyy, Bogdan</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new CNN-CRF end-to-end learning framework, which is based on
joint stochastic optimization with respect to both Convolutional Neural Network
(CNN) and Conditional Random Field (CRF) parameters. While stochastic gradient
descent is a standard technique for CNN training, it was not used for joint
models so far. We show that our learning method is (i) general, i.e. it applies
to arbitrary CNN and CRF architectures and potential functions; (ii) scalable,
i.e. it has a low memory footprint and straightforwardly parallelizes on GPUs;
(iii) easy in implementation. Additionally, the unified CNN-CRF optimization
approach simplifies a potential hardware implementation. We empirically
evaluate our method on the task of semantic labeling of body parts in depth
images and show that it compares favorably to competing techniques.
</dc:description>
 <dc:description>Comment: ACCV2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05070</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joining Transition Systems of Records: Some Congruency and
  Language-Theoretic Results</dc:title>
 <dc:creator>Izadi, Mohammad</dc:creator>
 <dc:creator>Masoudian, Saeed</dc:creator>
 <dc:creator>Mozaffari, Sahand</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  B\&quot;uchi automaton of records (BAR) has been proposed as a basic operational
semantics for Reo coordination language. It is an extension of B\&quot;uchi
automaton by using a set of records as its alphabet or transition labels.
Records are used to express the synchrony between the externally visible
actions of coordinated components modeled by BARs. The main composition
operator on the set of BARs is called as join which is the semantics of its
counterpart in Reo. In this paper, we define the notion of labeled transition
systems of records as a generalization of the notion of BAR, abstracting away
from acceptance or rejection of strings. Then, we consider four equivalence
relations (semantics) over the set of labeled transition systems of records and
investigate their congruency with respect to the join composition operator. In
fact, we prove that the finite-traces-based, infinite-traces-based, and
nondeterministic finite automata (NFA)-based equivalence relations all are
congruence relations over the set of all labeled transition systems of records
with respect to the join operation. However, the equivalence relation using
B\&quot;uchi acceptance condition is not so. In addition, using these results, we
introduce the language-theoretic definitions of the join operation considering
both finite and infinite strings notions. Also, we show that there is no
language-based and structure-independent definition of the join operation on
B\&quot;uchi automata of records.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05073</identifier>
 <datestamp>2017-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Massive MIMO-Enabled Downlink Wireless Backhauling for
  Full-Duplex Small Cells</dc:title>
 <dc:creator>Tabassum, Hina</dc:creator>
 <dc:creator>Sakr, Ahmed Hamdi</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Using tools from stochastic geometry, we develop a framework to model the
downlink rate coverage probability of a user in a given small cell network
(SCN) with massive MIMO-enabled wireless backhauls. The considered SCN is
composed of a mixture of small cells that are configured in either in-band or
out-of-band backhaul modes with a certain probability. The performance of the
user in the considered hierarchical network is limited by several sources of
interference such as the backhaul interference, small cell base station
(SBS)-to-SBS interference and the SI. Moreover, due to the channel hardening
effect in massive MIMO, the backhaul links experience long term channel effects
only, whereas the access links experience both the long term and short term
channel effects. Consequently, the developed framework is flexible to
characterize different sources of interference while capturing the
heterogeneity of the access and backhaul channels. In specific scenarios, the
framework enables deriving closed-form coverage probability expressions. Under
perfect backhaul coverage, the simplified expressions are utilized to optimize
the proportion of in-band and out-of-band small cells in the SCN in
closed-form. Finally, few remedial solutions are proposed that can potentially
mitigate the backhaul interference and in turn improve the performance of
in-band FD wireless backhauling. Numerical results investigate the scenarios in
which in-band wireless backhauling is useful and demonstrate that maintaining a
correct proportion of in-band and out-of-band FD small cells is crucial in
wireless backhauled SCNs.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, IEEE Transactions on Communications</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05073</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2555908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05076</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Dirichlet Allocation Based Organisation of Broadcast Media
  Archives for Deep Neural Network Adaptation</dc:title>
 <dc:creator>Doulaty, Mortaza</dc:creator>
 <dc:creator>Saz, Oscar</dc:creator>
 <dc:creator>Ng, Raymond W. M.</dc:creator>
 <dc:creator>Hain, Thomas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper presents a new method for the discovery of latent domains in
diverse speech data, for the use of adaptation of Deep Neural Networks (DNNs)
for Automatic Speech Recognition. Our work focuses on transcription of
multi-genre broadcast media, which is often only categorised broadly in terms
of high level genres such as sports, news, documentary, etc. However, in terms
of acoustic modelling these categories are coarse. Instead, it is expected that
a mixture of latent domains can better represent the complex and diverse
behaviours within a TV show, and therefore lead to better and more robust
performance. We propose a new method, whereby these latent domains are
discovered with Latent Dirichlet Allocation, in an unsupervised manner. These
are used to adapt DNNs using the Unique Binary Code (UBIC) representation for
the LDA domains. Experiments conducted on a set of BBC TV broadcasts, with more
than 2,000 shows for training and 47 shows for testing, show that the use of
LDA-UBIC DNNs reduces the error up to 13% relative compared to the baseline
hybrid DNN models.
</dc:description>
 <dc:description>Comment: IEEE Automatic Speech Recognition and Understanding Workshop (ASRU
  2015), 13-17 Dec 2015, Scottsdale, Arizona, USA</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05076</dc:identifier>
 <dc:identifier>doi:10.1109/ASRU.2015.7404785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05077</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diversity Networks: Neural Network Compression Using Determinantal Point
  Processes</dc:title>
 <dc:creator>Mariet, Zelda</dc:creator>
 <dc:creator>Sra, Suvrit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce Divnet, a flexible technique for learning networks with diverse
neurons. Divnet models neuronal diversity by placing a Determinantal Point
Process (DPP) over neurons in a given layer. It uses this DPP to select a
subset of diverse neurons and subsequently fuses the redundant neurons into the
selected ones. Compared with previous approaches, Divnet offers a more
principled, flexible technique for capturing neuronal diversity and thus
implicitly enforcing regularization. This enables effective auto-tuning of
network architecture and leads to smaller network sizes without hurting
performance. Moreover, through its focus on diversity and neuron fusing, Divnet
remains compatible with other procedures that seek to reduce memory footprints
of networks. We present experimental results to corroborate our claims: for
pruning neural networks, Divnet is seen to be notably superior to competing
approaches.
</dc:description>
 <dc:description>Comment: This paper appeared under the shorter title Diversity Networks at
  ICLR 2016
  (http://www.iclr.cc/doku.php?id=iclr2016:main#accepted_papers_conference_track)</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05078</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which type of citation analysis generates the most accurate taxonomy of
  scientific and technical knowledge?</dc:title>
 <dc:creator>Klavans, Richard</dc:creator>
 <dc:creator>Boyack, Kevin W.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In 1965, Derek de Solla Price foresaw the day when a citation-based taxonomy
of science and technology would be delineated and correspondingly used for
science policy. A taxonomy needs to be comprehensive and accurate if it is to
be useful for policy making, especially now that policy makers are utilizing
citation-based indicators to evaluate people, institutions and laboratories.
Determining the accuracy of a taxonomy, however, remains a challenge. Previous
work on the accuracy of partition solutions is sparse, and the results of those
studies, while useful, have not been definitive. In this study we compare the
accuracies of topic-level taxonomies based on the clustering of documents using
direct citation, bibliographic coupling, and co-citation. Using a set of new
gold standards - articles with at least 100 references - we find that direct
citation is better at concentrating references than either bibliographic
coupling or co-citation. Using the assumption that higher concentrations of
references denote more accurate clusters, direct citation thus provides a more
accurate representation of the taxonomy of scientific and technical knowledge
than either bibliographic coupling or co-citation. We also find that
discipline-level taxonomies based on journal schema are highly inaccurate
compared to topic-level taxonomies, and recommend against their use.
</dc:description>
 <dc:description>Comment: 26 pages, 4 figures, 7 tables</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05078</dc:identifier>
 <dc:identifier>JASIST, 68(4), pp. 984-998 (2017)</dc:identifier>
 <dc:identifier>doi:10.1002/asi.23734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05081</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed Monotonicity of Partial First-In-First-Out Traffic Flow Models</dc:title>
 <dc:creator>Coogan, Samuel</dc:creator>
 <dc:creator>Arcak, Murat</dc:creator>
 <dc:creator>Kurzhanskiy, Alexander A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In vehicle traffic networks, congestion on one outgoing link of a diverging
junction often impedes flow to other outgoing links, a phenomenon known as the
first-in-first-out (FIFO) property. Simplified traffic models that do not
account for the FIFO property result in monotone dynamics for which powerful
analysis techniques exist. FIFO models are in general not monotone, but have
been shown to be mixed monotone - a generalization of monotonicity that enables
similarly powerful analysis techniques. In this paper, we study traffic flow
models for which the FIFO property is only partial, that is, flows at diverging
junctions exhibit a combination of FIFO and non-FIFO phenomena. We show that
mixed monotonicity extends to this wider class of models and establish
conditions that guarantee convergence to an equilibrium.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05082</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Modeling of Behavioral Modes Using Sensor Data</dc:title>
 <dc:creator>Resheff, Yehezkel S.</dc:creator>
 <dc:creator>Rotics, Shay</dc:creator>
 <dc:creator>Nathan, Ran</dc:creator>
 <dc:creator>Weinshall, Daphna</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The field of Movement Ecology, like so many other fields, is experiencing a
period of rapid growth in availability of data. As the volume rises,
traditional methods are giving way to machine learning and data science, which
are playing an increasingly large part it turning this data into
science-driving insights. One rich and interesting source is the bio-logger.
These small electronic wearable devices are attached to animals free to roam in
their natural habitats, and report back readings from multiple sensors,
including GPS and accelerometer bursts. A common use of accelerometer data is
for supervised learning of behavioral modes. However, we need unsupervised
analysis tools as well, in order to overcome the inherent difficulties of
obtaining a labeled dataset, which in some cases is either infeasible or does
not successfully encompass the full repertoire of behavioral modes of interest.
Here we present a matrix factorization based topic-model method for
accelerometer bursts, derived using a linear mixture property of patch
features. Our method is validated via comparison to a labeled dataset, and is
further compared to standard clustering algorithms.
</dc:description>
 <dc:description>Comment: Invited Extended version of a paper \cite{resheffmatrix} presented at
  the international conference \textit{Data Science and Advanced Analytics},
  Paris, France, 19-21 OCtober 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05082</dc:identifier>
 <dc:identifier>International Journal of Data Science and Analytics 1.1 (2016):
  51-60</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05084</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding learned CNN features through Filter Decoding with
  Substitution</dc:title>
 <dc:creator>Rafegas, Ivet</dc:creator>
 <dc:creator>Vanrell, Maria</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In parallel with the success of CNNs to solve vision problems, there is a
growing interest in developing methodologies to understand and visualize the
internal representations of these networks. How the responses of a trained CNN
encode the visual information is a fundamental question both for computer and
human vision research. Image representations provided by the first
convolutional layer as well as the resolution change provided by the
max-polling operation are easy to understand, however, as soon as a second and
further convolutional layers are added in the representation, any intuition is
lost. A usual way to deal with this problem has been to define deconvolutional
networks that somehow allow to explore the internal representations of the most
important activations towards the image space, where deconvolution is assumed
as a convolution with the transposed filter. However, this assumption is not
the best approximation of an inverse convolution. In this paper we propose a
new assumption based on filter substitution to reverse the encoding of a
convolutional layer. This provides us with a new tool to directly visualize any
CNN single neuron as a filter in the first layer, this is in terms of the image
space.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures (including supplementary material). Submitted for
  review for CVPR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05099</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Yin and Yang: Balancing and Answering Binary Visual Questions</dc:title>
 <dc:creator>Zhang, Peng</dc:creator>
 <dc:creator>Goyal, Yash</dc:creator>
 <dc:creator>Summers-Stay, Douglas</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The complex compositional structure of language makes problems at the
intersection of vision and language challenging. But language also provides a
strong prior that can result in good superficial performance, without the
underlying models truly understanding the visual content. This can hinder
progress in pushing state of art in the computer vision aspects of multi-modal
AI. In this paper, we address binary Visual Question Answering (VQA) on
abstract scenes. We formulate this problem as visual verification of concepts
inquired in the questions. Specifically, we convert the question to a tuple
that concisely summarizes the visual concept to be detected in the image. If
the concept can be found in the image, the answer to the question is &quot;yes&quot;, and
otherwise &quot;no&quot;. Abstract scenes play two roles (1) They allow us to focus on
the high-level semantics of the VQA task as opposed to the low-level
recognition problems, and perhaps more importantly, (2) They provide us the
modality to balance the dataset such that language priors are controlled, and
the role of vision is essential. In particular, we collect fine-grained pairs
of scenes for every question, such that the answer to the question is &quot;yes&quot; for
one scene, and &quot;no&quot; for the other for the exact same question. Indeed, language
priors alone do not perform better than chance on our balanced dataset.
Moreover, our proposed approach matches the performance of a state-of-the-art
VQA approach on the unbalanced dataset, and outperforms it on the balanced
dataset.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05101</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How (not) to Train your Generative Model: Scheduled Sampling,
  Likelihood, Adversary?</dc:title>
 <dc:creator>Husz&#xe1;r, Ferenc</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modern applications and progress in deep learning research have created
renewed interest for generative models of text and of images. However, even
today it is unclear what objective functions one should use to train and
evaluate these models. In this paper we present two contributions.
  Firstly, we present a critique of scheduled sampling, a state-of-the-art
training method that contributed to the winning entry to the MSCOCO image
captioning benchmark in 2015. Here we show that despite this impressive
empirical performance, the objective function underlying scheduled sampling is
improper and leads to an inconsistent learning algorithm.
  Secondly, we revisit the problems that scheduled sampling was meant to
address, and present an alternative interpretation. We argue that maximum
likelihood is an inappropriate training objective when the end-goal is to
generate natural-looking samples. We go on to derive an ideal objective
function to use in this situation instead. We introduce a generalisation of
adversarial training, and show how such method can interpolate between maximum
likelihood training and our ideal training objective. To our knowledge this is
the first theoretical analysis that explains why adversarial training tends to
produce samples with higher perceived quality.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05102</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resolving the Geometric Locus Dilemma for Support Vector Learning
  Machines</dc:title>
 <dc:creator>Reeves, Denise M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Capacity control, the bias/variance dilemma, and learning unknown functions
from data, are all concerned with identifying effective and consistent fits of
unknown geometric loci to random data points. A geometric locus is a curve or
surface formed by points, all of which possess some uniform property. A
geometric locus of an algebraic equation is the set of points whose coordinates
are solutions of the equation. Any given curve or surface must pass through
each point on a specified locus. This paper argues that it is impossible to fit
random data points to algebraic equations of partially configured geometric
loci that reference arbitrary Cartesian coordinate systems. It also argues that
the fundamental curve of a linear decision boundary is actually a principal
eigenaxis. It is shown that learning principal eigenaxes of linear decision
boundaries involves finding a point of statistical equilibrium for which
eigenenergies of principal eigenaxis components are symmetrically balanced with
each other. It is demonstrated that learning linear decision boundaries
involves strong duality relationships between a statistical eigenlocus of
principal eigenaxis components and its algebraic forms, in primal and dual,
correlated Hilbert spaces. Locus equations are introduced and developed that
describe principal eigen-coordinate systems for lines, planes, and hyperplanes.
These equations are used to introduce and develop primal and dual statistical
eigenlocus equations of principal eigenaxes of linear decision boundaries.
Important generalizations for linear decision boundaries are shown to be
encoded within a dual statistical eigenlocus of principal eigenaxis components.
Principal eigenaxes of linear decision boundaries are shown to encode Bayes'
likelihood ratio for common covariance data and a robust likelihood ratio for
all other data.
</dc:description>
 <dc:description>Comment: 170 pages, 33 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05104</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time complexity of concurrent programs</dc:title>
 <dc:creator>Giachino, Elena</dc:creator>
 <dc:creator>Johnsen, Einar Broch</dc:creator>
 <dc:creator>Laneve, Cosimo</dc:creator>
 <dc:creator>Pun, Ka I</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We study the problem of automatically computing the time complexity of
concurrent object-oriented programs. To determine this complexity we use
intermediate abstract descriptions that record relevant information for the
time analysis (cost of statements, creations of objects, and concurrent
operations), called behavioural types. Then, we define a translation function
that takes behavioural types and makes the parallelism explicit into so-called
cost equations, which are fed to an automatic off-the-shelf solver for
obtaining the time complexity.
</dc:description>
 <dc:description>Comment: FACS 2015, Oct 2015, Niter\'oi, Rio de Janeiro, Brazil</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05109</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Eccentricity Shortest Paths in some Structured Graph Classes</dc:title>
 <dc:creator>Dragan, Feodor F.</dc:creator>
 <dc:creator>Leitert, Arne</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We investigate the Minimum Eccentricity Shortest Path problem in some
structured graph classes. It asks for a given graph to find a shortest path
with minimum eccentricity. Although it is NP-hard in general graphs, we
demonstrate that a minimum eccentricity shortest path can be found in linear
time for distance-hereditary graphs (generalizing the previous result for
trees) and give a generalised approach which allows to solve the problem in
polynomial time for other graph classes. This includes chordal graphs, dually
chordal graphs, graphs with bounded tree-length, and graphs with bounded
hyperbolicity. Additionally, we give a simple algorithm to compute an additive
approximation for graphs with bounded tree-length and graphs with bounded
hyperbolicity.
</dc:description>
 <dc:description>Comment: Results of this paper were partially presented at WG 2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05118</identifier>
 <datestamp>2016-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random sampling of bandlimited signals on graphs</dc:title>
 <dc:creator>Puy, Gilles</dc:creator>
 <dc:creator>Tremblay, Nicolas</dc:creator>
 <dc:creator>Gribonval, R&#xe9;mi</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of sampling k-bandlimited signals on graphs. We propose
two sampling strategies that consist in selecting a small subset of nodes at
random. The first strategy is non-adaptive, i.e., independent of the graph
structure, and its performance depends on a parameter called the graph
coherence. On the contrary, the second strategy is adaptive but yields optimal
results. Indeed, no more than O(k log(k)) measurements are sufficient to ensure
an accurate and stable recovery of all k-bandlimited signals. This second
strategy is based on a careful choice of the sampling distribution, which can
be estimated quickly. Then, we propose a computationally efficient decoder to
reconstruct k-bandlimited signals from their samples. We prove that it yields
accurate reconstructions and that it is also stable to noise. Finally, we
conduct several experiments to test these techniques.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05121</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Kalman Filters</dc:title>
 <dc:creator>Krishnan, Rahul G.</dc:creator>
 <dc:creator>Shalit, Uri</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Kalman Filters are one of the most influential models of time-varying
phenomena. They admit an intuitive probabilistic interpretation, have a simple
functional form, and enjoy widespread adoption in a variety of disciplines.
Motivated by recent variational methods for learning deep generative models, we
introduce a unified algorithm to efficiently learn a broad spectrum of Kalman
filters. Of particular interest is the use of temporal generative models for
counterfactual inference. We investigate the efficacy of such models for
counterfactual inference, and to that end we introduce the &quot;Healing MNIST&quot;
dataset where long-term structure, noise and actions are applied to sequences
of digits. We show the efficacy of our method for modeling this dataset. We
further show how our model can be used for counterfactual inference for
patients, based on electronic health record data of 8,000 patients over 4.5
years.
</dc:description>
 <dc:description>Comment: 17 pages, 14 figures: Fixed typo in Fig. 1(b) and added reference</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05122</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Manipulation of Deep Representations</dc:title>
 <dc:creator>Sabour, Sara</dc:creator>
 <dc:creator>Cao, Yanshuai</dc:creator>
 <dc:creator>Faghri, Fartash</dc:creator>
 <dc:creator>Fleet, David J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We show that the representation of an image in a deep neural network (DNN)
can be manipulated to mimic those of other natural images, with only minor,
imperceptible perturbations to the original image. Previous methods for
generating adversarial images focused on image perturbations designed to
produce erroneous class labels, while we concentrate on the internal layers of
DNN representations. In this way our new class of adversarial images differs
qualitatively from others. While the adversary is perceptually similar to one
image, its internal representation appears remarkably similar to a different
image, one from a different class, bearing little if any apparent similarity to
the input; they appear generic and consistent with the space of natural images.
This phenomenon raises questions about DNN representations, as well as the
properties of natural images themselves.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05132</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Evolution of Microscopic Wet Cracking Noises</dc:title>
 <dc:creator>Ghaffari, H. O.</dc:creator>
 <dc:creator>Griffith, W. A.</dc:creator>
 <dc:creator>Benson, P. M.</dc:creator>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Characterizing the interaction between water and microscopic defects is one
of the long-standing challenges in understanding a broad range of cracking
processes. Different physical aspects of microscopic events, driven or
influenced by water, have been extensively discussed in atomistic calculations
but have not been accessible in microscale experiments. Through the analysis of
the emitted noises during the evolution of individual, dynamic microcracking
events, we show that the onset of a secondary instability known as hybrid
events occurs during the fast healing phase of microcracking, which leads to
(local) sudden increase of pore water pressure in the process zone, inducing a
secondary instability, which is followed by a fast-locking phase on the
microscopic faults (pulse-like rupture).
</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:date>2016-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05132</dc:identifier>
 <dc:identifier>doi:10.1038/srep40560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05133</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Proximal Linearized Alternating Direction Method of Multiplier with
  Parallel Splitting</dc:title>
 <dc:creator>Lu, Canyi</dc:creator>
 <dc:creator>Li, Huan</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The Augmented Lagragian Method (ALM) and Alternating Direction Method of
Multiplier (ADMM) have been powerful optimization methods for general convex
programming subject to linear constraint. We consider the convex problem whose
objective consists of a smooth part and a nonsmooth but simple part. We propose
the Fast Proximal Augmented Lagragian Method (Fast PALM) which achieves the
convergence rate $O(1/K^2)$, compared with $O(1/K)$ by the traditional PALM. In
order to further reduce the per-iteration complexity and handle the
multi-blocks problem, we propose the Fast Proximal ADMM with Parallel Splitting
(Fast PL-ADMM-PS) method. It also partially improves the rate related to the
smooth part of the objective function. Experimental results on both synthesized
and real world data demonstrate that our fast methods significantly improve the
previous PALM and ADMM.
</dc:description>
 <dc:description>Comment: AAAI 2016</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05169</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Local Metric Learning for Person Re-identification</dc:title>
 <dc:creator>Huang, Siyuan</dc:creator>
 <dc:creator>Lu, Jiwen</dc:creator>
 <dc:creator>Zhou, Jie</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification aims at matching pedestrians observed from
non-overlapping camera views. Feature descriptor and metric learning are two
significant problems in person re-identification. A discriminative metric
learning method should be capable of exploiting complex nonlinear
transformations due to the large variations in feature space. In this paper, we
propose a nonlinear local metric learning (NLML) method to improve the
state-of-the-art performance of person re-identification on public datasets.
Motivated by the fact that local metric learning has been introduced to handle
the data which varies locally and deep neural network has presented outstanding
capability in exploiting the nonlinearity of samples, we utilize the merits of
both local metric learning and deep neural network to learn multiple sets of
nonlinear transformations. By enforcing a margin between the distances of
positive pedestrian image pairs and distances of negative pairs in the
transformed feature subspace, discriminative information can be effectively
exploited in the developed neural networks. Our experiments show that the
proposed NLML method achieves the state-of-the-art results on the widely used
VIPeR, GRID, and CUHK 01 datasets.
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05174</identifier>
 <datestamp>2016-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-scale predictive dictionaries</dc:title>
 <dc:creator>Saragadam, Vishwanath</dc:creator>
 <dc:creator>Sankaranarayanan, Aswin</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel signal model, based on sparse representations, that
captures cross-scale features for visual signals. We show that cross-scale
predictive model enables faster solutions to sparse approximation problems.
This is achieved by first solving the sparse approximation problem for the
downsampled signal and using the support of the solution to constrain the
support at the original resolution. The speedups obtained are especially
compelling for high-dimensional signals that require large dictionaries to
provide precise sparse approximations. We demonstrate speedups in the order of
10-100x for denoising and up to 15x speedups for compressive sensing of images,
videos, hyperspectral images and light-field images.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05175</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Models for Joint Object Categorization and Pose Estimation</dc:title>
 <dc:creator>Elhoseiny, Mohamed</dc:creator>
 <dc:creator>El-Gaaly, Tarek</dc:creator>
 <dc:creator>Bakry, Amr</dc:creator>
 <dc:creator>Elgammal, Ahmed</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the task of Object Recognition, there exists a dichotomy between the
categorization of objects and estimating object pose, where the former
necessitates a view-invariant representation, while the latter requires a
representation capable of capturing pose information over different categories
of objects. With the rise of deep architectures, the prime focus has been on
object category recognition. Deep learning methods have achieved wide success
in this task. In contrast, object pose regression using these approaches has
received relatively much less attention. In this paper we show how deep
architectures, specifically Convolutional Neural Networks (CNN), can be adapted
to the task of simultaneous categorization and pose estimation of objects. We
investigate and analyze the layers of various CNN models and extensively
compare between them with the goal of discovering how the layers of distributed
representations of CNNs represent object pose information and how this
contradicts with object category representations. We extensively experiment on
two recent large and challenging multi-view datasets. Our models achieve better
than state-of-the-art performance on both datasets.
</dc:description>
 <dc:description>Comment: only for workshop presentation at ICLR</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05176</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MuProp: Unbiased Backpropagation for Stochastic Neural Networks</dc:title>
 <dc:creator>Gu, Shixiang</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Mnih, Andriy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks are powerful parametric models that can be trained
efficiently using the backpropagation algorithm. Stochastic neural networks
combine the power of large parametric functions with that of graphical models,
which makes it possible to learn very complex distributions. However, as
backpropagation is not directly applicable to stochastic networks that include
discrete sampling operations within their computational graph, training such
networks remains difficult. We present MuProp, an unbiased gradient estimator
for stochastic networks, designed to make this task easier. MuProp improves on
the likelihood-ratio estimator by reducing its variance using a control variate
based on the first-order Taylor expansion of a mean-field network. Crucially,
unlike prior attempts at using backpropagation for training stochastic
networks, the resulting estimator is unbiased and well behaved. Our experiments
on structured output prediction and discrete latent variable modeling
demonstrate that MuProp yields consistently good performance across a range of
difficult tasks.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05178</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Almost Perfect Probabilistically Checkable Proofs of Proximity</dc:title>
 <dc:creator>Jozeph, Shlomo</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Probabilistically checkable proofs of proximity (PCPP) are proof systems
where the verifier is given a 3SAT formula, but has only oracle access to an
assignment and a proof. The verifier accepts a satisfying assignment with a
valid proof, and rejects (with high enough probability) an assignment that is
far from all satisfying assignments (for any given proof).
  In this work, we focus on the type of computation the verifier is allowed to
make. Assuming P $\neq$ NP, there can be no PCPP when the verifier is only
allowed to answer according to constraints from a set that forms a CSP that is
solvable in P. Therefore, the notion of PCPP is relaxed to almost perfect
probabilistically checkable proofs of proximity (APPCPP), where the verifier is
allowed to reject a satisfying assignment with a valid proof, with arbitrary
small probability.
  We show, unconditionally, a dichotomy of sets of allowable computations: sets
that have APPCPPs (which actually follows because they have PCPPs) and sets
that do not. This dichotomy turns out to be the same as that of the Dichotomy
Theorem, which can be thought of as dividing sets of allowable verifier
computations into sets that give rise to NP-hard CSPs, and sets that give rise
to CSPs that are solvable in P.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05180</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HiFlash: A History Independent Flash Device</dc:title>
 <dc:creator>Chen, Bo</dc:creator>
 <dc:creator>Sion, Radu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Retention regulations require timely and irrecoverable disposal of data, a
challenging task, as data and its side effects are stored and maintained at all
layers of a computing system. Those side effects can be used as an oracle to
derive the past existence of deleted data.
  Fortunately, history independence can be utilized to eliminate such
history-related oracles. HIFS can provide history independence for file storage
over mechanical disk drives. However, HIFS cannot provide history independence
when deployed on top of flash devices, as flash memory manages its own internal
block placement, which is often inherently history dependent.
  In this work, we initiate research on history independent flash devices. We
design HiFlash, which achieves a strong notion of history independence by
defending against an adversary allowed access to the flash at multiple
different points in time. In addition, we design a simple, yet history
independence friendly wear-leveling mechanism that allows HiFlash to smartly
and advantageously trade off a tunable small amount of history leakage for a
significant increase in the device's lifetime. Our prototype built in an actual
flash device as well as extensive simulations validate the effectiveness of
HiFlash.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05186</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Motion Planning Under Non-Gaussian Uncertainty and Non-Convex
  State Constraints</dc:title>
 <dc:creator>Rafieisakhaei, Mohammadhussein</dc:creator>
 <dc:creator>Tamjidi, Amirhossein</dc:creator>
 <dc:creator>Chakravorty, Suman</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Planning under process and measurement uncertainties is a challenging
problem. In its most general form it can be modeled as a Partially Observed
Markov Decision Process (POMDP) problem. However POMDPs are generally difficult
to solve when the underlying spaces are continuous, particularly when beliefs
are non-Gaussian, and the difficulty is further exacerbated when there are also
non-convex constraints on states. Existing algorithms to address such
challenging POMDPs are expensive in terms of computation and memory. In this
paper, we provide a feedback policy in non-Gaussian belief space via solving a
convex program for common non-linear observation models. The solution involves
a Receding Horizon Control strategy using particle filters for the non-Gaussian
belief representation. We develop a way of capturing non-convex constraints in
the state space and adapt the optimization to incorporate such constraints, as
well. A key advantage of this method is that it does not introduce additional
variables in the optimization problem and is therefore more scalable than
existing constrained problems in belief space. We demonstrate the performance
of the method on different scenarios.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, Submitted to IEEE International Conference on
  Robotics and Automation (ICRA) 2016 on 9/15/2015</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05186</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2016.7487619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05191</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Classifier Calibration using an Ensemble of Near Isotonic
  Regression Models</dc:title>
 <dc:creator>Naeini, Mahdi Pakdaman</dc:creator>
 <dc:creator>Cooper, Gregory F.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning accurate probabilistic models from data is crucial in many practical
tasks in data mining. In this paper we present a new non-parametric calibration
method called \textit{ensemble of near isotonic regression} (ENIR). The method
can be considered as an extension of BBQ, a recently proposed calibration
method, as well as the commonly used calibration method based on isotonic
regression. ENIR is designed to address the key limitation of isotonic
regression which is the monotonicity assumption of the predictions. Similar to
BBQ, the method post-processes the output of a binary classifier to obtain
calibrated probabilities. Thus it can be combined with many existing
classification models. We demonstrate the performance of ENIR on synthetic and
real datasets for the commonly used binary classification models. Experimental
results show that the method outperforms several common binary classifier
calibration methods. In particular on the real data, ENIR commonly performs
statistically significantly better than the other methods, and never worse. It
is able to improve the calibration power of classifiers, while retaining their
discrimination power. The method is also computationally tractable for large
scale datasets, as it is $O(N \log N)$ time, where $N$ is the number of
samples.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05194</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse-promoting Full Waveform Inversion based on Online Orthonormal
  Dictionary Learning</dc:title>
 <dc:creator>Zhu, Lingchen</dc:creator>
 <dc:creator>Liu, Entao</dc:creator>
 <dc:creator>McClellan, James H.</dc:creator>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  Full waveform inversion (FWI) delivers high-resolution images of the
subsurface by minimizing iteratively the misfit between the recorded and
calculated seismic data. It has been attacked successfully with the
Gauss-Newton method and sparsity promoting regularization based on fixed
multiscale transforms that permit significant subsampling of the seismic data
when the model perturbation at each FWI data-fitting iteration can be
represented with sparse coefficients. Rather than using analytical transforms
with predefined dictionaries to achieve sparse representation, we introduce an
adaptive transform called the Sparse Orthonormal Transform (SOT) whose
dictionary is learned from many small training patches taken from the model
perturbations in previous iterations. The patch-based dictionary is constrained
to be orthonormal and trained with an online approach to provide the best
sparse representation of the complex features and variations of the entire
model perturbation. The complexity of the training method is proportional to
the cube of the number of samples in one small patch. By incorporating both
compressive subsampling and the adaptive SOT-based representation into the
Gauss-Newton least-squares problem for each FWI iteration, the model
perturbation can be recovered after an l1-norm sparsity constraint is applied
on the SOT coefficients. Numerical experiments on synthetic models demonstrate
that the SOT-based sparsity promoting regularization can provide robust FWI
results with reduced computation.
</dc:description>
 <dc:description>Comment: This paper has already been accepted by Geophysics</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05196</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic Network Formation with Attack and Immunization</dc:title>
 <dc:creator>Goyal, Sanjeev</dc:creator>
 <dc:creator>Jabbari, Shahin</dc:creator>
 <dc:creator>Kearns, Michael</dc:creator>
 <dc:creator>Khanna, Sanjeev</dc:creator>
 <dc:creator>Morgenstern, Jamie</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Strategic network formation arises where agents receive benefit from
connections to other agents, but also incur costs for forming links. We
consider a new network formation game that incorporates an adversarial attack,
as well as immunization against attack. An agent's benefit is the expected size
of her connected component post-attack, and agents may also choose to immunize
themselves from attack at some additional cost. Our framework is a stylized
model of settings where reachability rather than centrality is the primary
concern and vertices vulnerable to attacks may reduce risk via costly measures.
  In the reachability benefit model without attack or immunization, the set of
equilibria is the empty graph and any tree. The introduction of attack and
immunization changes the game dramatically; new equilibrium topologies emerge,
some more sparse and some more dense than trees. We show that, under a mild
assumption on the adversary, every equilibrium network with $n$ agents contains
at most $2n-4$ edges for $n\geq 4$. So despite permitting topologies denser
than trees, the amount of overbuilding is limited. We also show that attack and
immunization don't significantly erode social welfare: every non-trivial
equilibrium with respect to several adversaries has welfare at least as that of
any equilibrium in the attack-free model.
  We complement our theory with simulations demonstrating fast convergence of a
new bounded rationality dynamic which generalizes linkstable best response but
is considerably more powerful in our game. The simulations further elucidate
the wide variety of asymmetric equilibria and demonstrate topological
consequences of the dynamics e.g. heavy-tailed degree distributions. Finally,
we report on a behavioral experiment on our game with over 100 participants,
where despite the complexity of the game, the resulting network was
surprisingly close to equilibrium.
</dc:description>
 <dc:description>Comment: The short version of this paper appears in the proceedings of WINE-16</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05197</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing and Understanding Deep Texture Representations</dc:title>
 <dc:creator>Lin, Tsung-Yu</dc:creator>
 <dc:creator>Maji, Subhransu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A number of recent approaches have used deep convolutional neural networks
(CNNs) to build texture representations. Nevertheless, it is still unclear how
these models represent texture and invariances to categorical variations. This
work conducts a systematic evaluation of recent CNN-based texture descriptors
for recognition and attempts to understand the nature of invariances captured
by these representations. First we show that the recently proposed bilinear CNN
model [25] is an excellent general-purpose texture descriptor and compares
favorably to other CNN-based descriptors on various texture and scene
recognition benchmarks. The model is translationally invariant and obtains
better accuracy on the ImageNet dataset without requiring spatial jittering of
data compared to corresponding models trained with spatial jittering. Based on
recent work [13, 28] we propose a technique to visualize pre-images, providing
a means for understanding categorical properties that are captured by these
representations. Finally, we show preliminary results on how a unified
parametric model of texture analysis and synthesis can be used for
attribute-based image manipulation, e.g. to make an image more swirly,
honeycombed, or knitted. The source code and additional visualizations are
available at http://vis-www.cs.umass.edu/texture
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05201</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The capacity of Bernoulli nonadaptive group testing</dc:title>
 <dc:creator>Aldridge, Matthew</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider nonadaptive group testing with Bernoulli tests, where each item
is placed in each test independently with some fixed probability. We give a
tight threshold on the maximum number of tests required to find the defective
set under optimal Bernoulli testing. Achievability is given by a result of
Scarlett and Cevher; here we give a converse bound showing that this result is
best possible. Our new converse requires three parts: a typicality bound
generalising the trivial counting bound, a converse on the COMP algorithm of
Chan et al, and a bound on the SSS algorithm similar to that given by Aldridge,
Baldassini, and Johnson. Our result has a number of important corollaries, in
particular that, in denser cases, Bernoulli nonadaptive group testing is
strictly worse than the best adaptive strategies.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05201</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, 63:11, 7142-7148, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2748564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05202</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient AUC Optimization for Information Ranking Applications</dc:title>
 <dc:creator>Welleck, Sean J.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adequate evaluation of an information retrieval system to estimate future
performance is a crucial task. Area under the ROC curve (AUC) is widely used to
evaluate the generalization of a retrieval system. However, the objective
function optimized in many retrieval systems is the error rate and not the AUC
value. This paper provides an efficient and effective non-linear approach to
optimize AUC using additive regression trees, with a special emphasis on the
use of multi-class AUC (MAUC) because multiple relevance levels are widely used
in many ranking applications. Compared to a conventional linear approach, the
performance of the non-linear approach is comparable on binary-relevance
benchmark datasets and is better on multi-relevance benchmark datasets.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05202</dc:identifier>
 <dc:identifier>ECIR 2016, LNCS 9626, pp.159-170, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-30671-1_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05204</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Expressionlets via Universal Manifold Model for Dynamic Facial
  Expression Recognition</dc:title>
 <dc:creator>Liu, Mengyi</dc:creator>
 <dc:creator>Shan, Shiguang</dc:creator>
 <dc:creator>Wang, Ruiping</dc:creator>
 <dc:creator>Chen, Xilin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Facial expression is temporally dynamic event which can be decomposed into a
set of muscle motions occurring in different facial regions over various time
intervals. For dynamic expression recognition, two key issues, temporal
alignment and semantics-aware dynamic representation, must be taken into
account. In this paper, we attempt to solve both problems via manifold modeling
of videos based on a novel mid-level representation, i.e.
\textbf{expressionlet}. Specifically, our method contains three key stages: 1)
each expression video clip is characterized as a spatial-temporal manifold
(STM) formed by dense low-level features; 2) a Universal Manifold Model (UMM)
is learned over all low-level features and represented as a set of local modes
to statistically unify all the STMs. 3) the local modes on each STM can be
instantiated by fitting to UMM, and the corresponding expressionlet is
constructed by modeling the variations in each local mode. With above strategy,
expression videos are naturally aligned both spatially and temporally. To
enhance the discriminative power, the expressionlet-based STM representation is
further processed with discriminant embedding. Our method is evaluated on four
public expression databases, CK+, MMI, Oulu-CASIA, and FERA. In all cases, our
method outperforms the known state-of-the-art by a large margin.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05204</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2615424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05208</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HOID: Higher Order Interpolatory Decomposition for tensors based on
  Tucker representation</dc:title>
 <dc:creator>Saibaba, Arvind K.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We derive a CUR-type factorization for tensors in the Tucker format based on
interpolatory decomposition, which we will denote as Higher Order Interpolatory
Decomposition (HOID). Given a tensor $\mathcal{X}$, the algorithm provides a
set of column vectors $\{ \mathbf{C}_n\}_{n=1}^d$ which are columns extracted
from the mode-$n$ tensor unfolding, along with a core tensor $\mathcal{G}$ and
together, they satisfy some error bounds. Compared to the Higher Order SVD
(HOSVD) algorithm, the HOID provides a decomposition that preserves certain
important features of the original tensor such as sparsity, non-negativity,
integer values, etc. Error bounds along with detailed estimates of
computational costs are provided. The algorithms proposed in this paper have
been validated against carefully chosen numerical examples which highlight the
favorable properties of the algorithms. Related methods for subset selection
proposed for matrix CUR decomposition, such as Discrete Empirical Interpolation
method (DEIM) and leverage score sampling, have also been extended to tensors
and are compared against our proposed algorithms.
</dc:description>
 <dc:description>Comment: 28 pages, 9 figures, minor revisions</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05210</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting Ones Without Broadword Operations</dc:title>
 <dc:creator>Petersen, Holger</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  A lower time bound $\Omega(\min(\nu(x), n-\nu(x))$ for counting the number of
ones in a binary input word $x$ of length $n$ is presented, where $\nu(x)$ is
the number of ones. The operations available are increment, decrement, bit-wise
logical operations, and assignment. The only constant available is zero. An
almost matching upper bound is also obtained.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05212</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary embeddings with structured hashed projections</dc:title>
 <dc:creator>Choromanska, Anna</dc:creator>
 <dc:creator>Choromanski, Krzysztof</dc:creator>
 <dc:creator>Bojarski, Mariusz</dc:creator>
 <dc:creator>Jebara, Tony</dc:creator>
 <dc:creator>Kumar, Sanjiv</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the hashing mechanism for constructing binary embeddings, that
involves pseudo-random projections followed by nonlinear (sign function)
mappings. The pseudo-random projection is described by a matrix, where not all
entries are independent random variables but instead a fixed &quot;budget of
randomness&quot; is distributed across the matrix. Such matrices can be efficiently
stored in sub-quadratic or even linear space, provide reduction in randomness
usage (i.e. number of required random values), and very often lead to
computational speed ups. We prove several theoretical results showing that
projections via various structured matrices followed by nonlinear mappings
accurately preserve the angular distance between input high-dimensional
vectors. To the best of our knowledge, these results are the first that give
theoretical ground for the use of general structured matrices in the nonlinear
setting. In particular, they generalize previous extensions of the
Johnson-Lindenstrauss lemma and prove the plausibility of the approach that was
so far only heuristically confirmed for some special structured matrices.
Consequently, we show that many structured matrices can be used as an efficient
information compression mechanism. Our findings build a better understanding of
certain deep architectures, which contain randomly weighted and untrained
layers, and yet achieve high performance on different learning tasks. We
empirically verify our theoretical findings and show the dependence of learning
via structured hashed projections on the performance of neural network as well
as nearest neighbor classifier.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1505.03190</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05219</identifier>
 <datestamp>2016-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How much does your data exploration overfit? Controlling bias via
  information usage</dc:title>
 <dc:creator>Russo, Daniel</dc:creator>
 <dc:creator>Zou, James</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modern data is messy and high-dimensional, and it is often not clear a priori
what are the right questions to ask. Instead, the analyst typically needs to
use the data to search for interesting analyses to perform and hypotheses to
test. This is an adaptive process, where the choice of analysis to be performed
next depends on the results of the previous analyses on the same data.
Ultimately, which results are reported can be heavily influenced by the data.
It is widely recognized that this process, even if well-intentioned, can lead
to biases and false discoveries, contributing to the crisis of reproducibility
in science. But while %the adaptive nature of exploration any data-exploration
renders standard statistical theory invalid, experience suggests that different
types of exploratory analysis can lead to disparate levels of bias, and the
degree of bias also depends on the particulars of the data set. In this paper,
we propose a general information usage framework to quantify and provably bound
the bias and other error metrics of an arbitrary exploratory analysis. We prove
that our mutual information based bound is tight in natural settings, and then
use it to give rigorous insights into when commonly used procedures do or do
not lead to substantially biased estimation. Through the lens of information
usage, we analyze the bias of specific exploration procedures such as
filtering, rank selection and clustering. Our general framework also naturally
motivates randomization techniques that provably reduces exploration bias while
preserving the utility of the data analysis. We discuss the connections between
our approach and related ideas from differential privacy and blinded data
analysis, and supplement our results with illustrative simulations.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05223</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Event-based State Estimation</dc:title>
 <dc:creator>Trimpe, Sebastian</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An event-based state estimation approach for reducing communication in a
networked control system is proposed. Multiple distributed
sensor-actuator-agents observe a dynamic process and sporadically exchange
their measurements and inputs over a bus network. Based on these data, each
agent estimates the full state of the dynamic system, which may exhibit
arbitrary inter-agent couplings. Local event-based protocols ensure that data
is transmitted only when necessary to meet a desired estimation accuracy. This
event-based scheme is shown to mimic a centralized Luenberger observer design
up to guaranteed bounds, and stability is proven in the sense of bounded
estimation errors for bounded disturbances. The stability result extends to the
distributed control system that results when the local state estimates are used
for distributed feedback control. Simulation results highlight the benefit of
the event-based approach over classical periodic ones in reducing communication
requirements.
</dc:description>
 <dc:description>Comment: Technical report, 16 pages, 10 figures, minor updates</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05234</identifier>
 <datestamp>2016-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
  Visual Question Answering</dc:title>
 <dc:creator>Xu, Huijuan</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We address the problem of Visual Question Answering (VQA), which requires
joint image and language understanding to answer a question about a given
photograph. Recent approaches have applied deep image captioning methods based
on convolutional-recurrent networks to this problem, but have failed to model
spatial inference. To remedy this, we propose a model we call the Spatial
Memory Network and apply it to the VQA task. Memory networks are recurrent
neural networks with an explicit attention mechanism that selects certain parts
of the information stored in memory. Our Spatial Memory Network stores neuron
activations from different spatial regions of the image in its memory, and uses
the question to choose relevant regions for computing the answer, a process of
which constitutes a single &quot;hop&quot; in the network. We propose a novel spatial
attention architecture that aligns words with image patches in the first hop,
and obtain improved results by adding a second attention hop which considers
the whole question to choose visual evidence based on the results of the first
hop. To better understand the inference process learned by the network, we
design synthetic questions that specifically require spatial inference and
visualize the attention weights. We evaluate our model on two published visual
question answering datasets, DAQUAR [1] and VQA [2], and obtain improved
results compared to a strong deep baseline model (iBOWIMG) which concatenates
image and question features to predict the answer [3].
</dc:description>
 <dc:description>Comment: include test-standard result on VQA full release (V1.0) dataset</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05236</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets</dc:title>
 <dc:creator>Judd, Patrick</dc:creator>
 <dc:creator>Albericio, Jorge</dc:creator>
 <dc:creator>Hetherington, Tayler</dc:creator>
 <dc:creator>Aamodt, Tor</dc:creator>
 <dc:creator>Jerger, Natalie Enright</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:creator>Moshovos, Andreas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This work investigates how using reduced precision data in Convolutional
Neural Networks (CNNs) affects network accuracy during classification. More
specifically, this study considers networks where each layer may use different
precision data. Our key result is the observation that the tolerance of CNNs to
reduced precision data not only varies across networks, a well established
observation, but also within networks. Tuning precision per layer is appealing
as it could enable energy and performance improvements. In this paper we study
how error tolerance across layers varies and propose a method for finding a low
precision configuration for a network while maintaining high accuracy. A
diverse set of CNNs is analyzed showing that compared to a conventional
implementation using a 32-bit floating-point representation for all layers, and
with less than 1% loss in relative accuracy, the data footprint required by
these networks can be reduced by an average of 74% and up to 92%.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2016, 12 pages, 5 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05240</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An extension of McDiarmid's inequality</dc:title>
 <dc:creator>Combes, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We derive an extension of McDiarmid's inequality for functions $f$ with
bounded differences on a high probability set ${\cal Y}$ (instead of almost
surely). The behavior of $f$ outside ${\cal Y}$ may be arbitrary. The proof is
short and elementary, and relies on an extension argument similar to
Kirszbraun's theorem.
</dc:description>
 <dc:description>Comment: Note (4 pages)</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05252</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal $\mathcal{H}_{2}$ model approximation based on multiple
  input/output delays systems</dc:title>
 <dc:creator>Duff, Igor Pontes</dc:creator>
 <dc:creator>Poussot-Vassal, Charles</dc:creator>
 <dc:creator>Seren, C&#xe9;dric</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, the $\mathcal{H}_{2}$ optimal approximation of a
$n_{y}\times{n_{u}}$ transfer function $\mathbf{G}(s)$ by a finite dimensional
system $\hat{\mathbf{H}}_{d}(s)$ including input/output delays, is addressed.
The underlying $\mathcal{H}_{2}$ optimality conditions of the approximation
problem are firstly derived and established in the case of a poles/residues
decomposition. These latter form an extension of the tangential interpolatory
conditions, presented in~\cite{gugercin2008h_2,dooren2007} for the delay-free
case, which is the main contribution of this paper. Secondly, a two stage
algorithm is proposed in order to practically obtain such an approximation.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures, submitted to Automatica Journal</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05254</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Statistical Model for Motifs Detection</dc:title>
 <dc:creator>Javadi, Hamid</dc:creator>
 <dc:creator>Montanari, Andrea</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a statistical model for the problem of finding subgraphs with
specified topology in an otherwise random graph. This task plays an important
role in the analysis of social and biological networks. In these types of
networks, small subgraphs with a specific structure have important functional
roles, and they are referred to as `motifs.'
  Within this model, one or multiple copies of a subgraph is added (`planted')
in an Erd\H{o}s-Renyi random graph with $n$ vertices and edge probability
$q_0$. We ask whether the resulting graph can be distinguished reliably from a
pure Erd\H{o}s-Renyi random graph, and we present two types of result. First we
investigate the question from a purely statistical perspective, and ask whether
there is any test that can distinguish between the two graph models. We provide
necessary and sufficient conditions that are essentially tight for small enough
subgraphs.
  Next we study two polynomial-time algorithms for solving the same problem: a
spectral algorithm, and a semidefinite programming (SDP) relaxation. For the
spectral algorithm, we establish sufficient conditions under which it
distinguishes the two graph models with high probability. Under the same
conditions the spectral algorithm indeed identifies the hidden subgraph.
  The spectral algorithm is substantially sub-optimal with respect to the
optimal test. We show that a similar gap is present for the more sophisticated
SDP approach.
</dc:description>
 <dc:description>Comment: 40 pages, 1 pdf figure</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05259</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completeness of Randomized Kinodynamic Planners with State-based
  Steering</dc:title>
 <dc:creator>Caron, St&#xe9;phane</dc:creator>
 <dc:creator>Pham, Quang-Cuong</dc:creator>
 <dc:creator>Nakamura, Yoshihiko</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Probabilistic completeness is an important property in motion planning.
Although it has been established with clear assumptions for geometric planners,
the panorama of completeness results for kinodynamic planners is still
incomplete, as most existing proofs rely on strong assumptions that are
difficult, if not impossible, to verify on practical systems. In this paper, we
focus on an important class of kinodynamic planners, namely those that
interpolate trajectories in the state space. We provide a proof of
probabilistic completeness for these planners under assumptions that can be
readily verified from the system's equations of motion and the user-defined
interpolation function. Our proof relies crucially on a property of
interpolated trajectories, termed second-order continuity (SOC), which we show
is tightly related to the ability of a planner to benefit from denser sampling.
We analyze the impact of this property in simulations on a low-torque pendulum.
Our results show that a simple RRT using a second-order continuous
interpolation swiftly finds solution, while it is impossible for the same
planner using standard Bezier curves (which are not SOC) to find any solution.
</dc:description>
 <dc:description>Comment: 21 pages, 5 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05261</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust PCA via Nonconvex Rank Approximation</dc:title>
 <dc:creator>Kang, Zhao</dc:creator>
 <dc:creator>Peng, Chong</dc:creator>
 <dc:creator>Cheng, Qiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Numerous applications in data mining and machine learning require recovering
a matrix of minimal rank. Robust principal component analysis (RPCA) is a
general framework for handling this kind of problems. Nuclear norm based convex
surrogate of the rank function in RPCA is widely investigated. Under certain
assumptions, it can recover the underlying true low rank matrix with high
probability. However, those assumptions may not hold in real-world
applications. Since the nuclear norm approximates the rank by adding all
singular values together, which is essentially a $\ell_1$-norm of the singular
values, the resulting approximation error is not trivial and thus the resulting
matrix estimator can be significantly biased. To seek a closer approximation
and to alleviate the above-mentioned limitations of the nuclear norm, we
propose a nonconvex rank approximation. This approximation to the matrix rank
is tighter than the nuclear norm. To solve the associated nonconvex
minimization problem, we develop an efficient augmented Lagrange multiplier
based optimization algorithm. Experimental results demonstrate that our method
outperforms current state-of-the-art algorithms in both accuracy and
efficiency.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Data Mining</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05261</dc:identifier>
 <dc:identifier>doi:10.1109/ICDM.2015.15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05262</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Requirements Engineering for General Recommender Systems</dc:title>
 <dc:creator>Portugal, Ivens</dc:creator>
 <dc:creator>Alencar, Paulo</dc:creator>
 <dc:creator>Cowan, Donald</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In requirements engineering for recommender systems, software engineers must
identify the data that drives the recommendations. This is a labor-intensive
task, which is error-prone and expensive. One possible solution to this problem
is the adoption of automatic recommender system development approach based on a
general recommender framework. One step towards the creation of such a
framework is to determine the type of data used in recommender systems. In this
paper, a systematic review has been conducted to identify the type of user and
recommendation data items needed by a general recommender system. A user and
item model is proposed, and some considerations about algorithm specific
parameters are explained. A further goal is to study the impact of the fields
of big data and Internet of things on the development of recommender systems.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05263</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Use of Machine Learning Algorithms in Recommender Systems: A
  Systematic Review</dc:title>
 <dc:creator>Portugal, Ivens</dc:creator>
 <dc:creator>Alencar, Paulo</dc:creator>
 <dc:creator>Cowan, Donald</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommender systems use algorithms to provide users with product or service
recommendations. Recently, these systems have been using machine learning
algorithms from the field of artificial intelligence. However, choosing a
suitable machine learning algorithm for a recommender system is difficult
because of the number of algorithms described in the literature. Researchers
and practitioners developing recommender systems are left with little
information about the current approaches in algorithm usage. Moreover, the
development of a recommender system using a machine learning algorithm often
has problems and open questions that must be evaluated, so software engineers
know where to focus research efforts. This paper presents a systematic review
of the literature that analyzes the use of machine learning algorithms in
recommender systems and identifies research opportunities for software
engineering research. The study concludes that Bayesian and decision tree
algorithms are widely used in recommender systems because of their relative
simplicity, and that requirement and design phases of recommender system
development appear to offer opportunities for further research.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05265</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AUC-maximized Deep Convolutional Neural Fields for Sequence Labeling</dc:title>
 <dc:creator>Wang, Sheng</dc:creator>
 <dc:creator>Sun, Siqi</dc:creator>
 <dc:creator>Xu, Jinbo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep Convolutional Neural Networks (DCNN) has shown excellent performance in
a variety of machine learning tasks. This manuscript presents Deep
Convolutional Neural Fields (DeepCNF), a combination of DCNN with Conditional
Random Field (CRF), for sequence labeling with highly imbalanced label
distribution. The widely-used training methods, such as maximum-likelihood and
maximum labelwise accuracy, do not work well on highly imbalanced data. To
handle this, we present a new training algorithm called maximum-AUC for
DeepCNF. That is, we train DeepCNF by directly maximizing the empirical Area
Under the ROC Curve (AUC), which is an unbiased measurement for imbalanced
data. To fulfill this, we formulate AUC in a pairwise ranking framework,
approximate it by a polynomial function and then apply a gradient-based
procedure to optimize it. We then test our AUC-maximized DeepCNF on three very
different protein sequence labeling tasks: solvent accessibility prediction,
8-state secondary structure prediction, and disorder prediction. Our
experimental results confirm that maximum-AUC greatly outperforms the other two
training methods on 8-state secondary structure prediction and disorder
prediction since their label distributions are highly imbalanced and also have
similar performance as the other two training methods on the solvent
accessibility prediction problem which has three equally-distributed labels.
Furthermore, our experimental results also show that our AUC-trained DeepCNF
models greatly outperform existing popular predictors of these three tasks.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05266</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Collaborative Ranking with Push at Top</dc:title>
 <dc:creator>Barjasteh, Iman</dc:creator>
 <dc:creator>Forsati, Rana</dc:creator>
 <dc:creator>Esfahanian, Abdol-Hossein</dc:creator>
 <dc:creator>Radha, Hayder</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Existing collaborative ranking based recommender systems tend to perform best
when there is enough observed ratings for each user and the observation is made
completely at random. Under this setting recommender systems can properly
suggest a list of recommendations according to the user interests. However,
when the observed ratings are extremely sparse (e.g. in the case of cold-start
users where no rating data is available), and are not sampled uniformly at
random, existing ranking methods fail to effectively leverage side information
to transduct the knowledge from existing ratings to unobserved ones. We propose
a semi-supervised collaborative ranking model, dubbed \texttt{S$^2$COR}, to
improve the quality of cold-start recommendation. \texttt{S$^2$COR} mitigates
the sparsity issue by leveraging side information about both observed and
missing ratings by collaboratively learning the ranking model. This enables it
to deal with the case of missing data not at random, but to also effectively
incorporate the available side information in transduction. We experimentally
evaluated our proposed algorithm on a number of challenging real-world datasets
and compared against state-of-the-art models for cold-start recommendation. We
report significantly higher quality recommendations with our algorithm compared
to the state-of-the-art.
</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05270</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying Inefficiency of Fair Cost-Sharing Mechanisms for Sharing
  Economy</dc:title>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:creator>Elbassioni, Khaled</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Sharing economy is a distributed peer-to-peer economic paradigm, which gives
rise to a variety of social interactions for economic purposes. One fundamental
distributed decision-making process is coalition formation for sharing certain
replaceable resources collaboratively, for example, sharing hotel rooms among
travelers, sharing taxi-rides among passengers, and sharing regular passes
among users. Motivated by the applications of sharing economy, this paper
studies a coalition formation game subject to the capacity of $K$ participants
per coalition. The participants in each coalition are supposed to split the
associated cost according to a given cost-sharing mechanism. A stable coalition
structure is established when no group of participants can opt out to form
another coalition that leads to lower individual payments. We quantify the
inefficiency of distributed decision-making processes under a cost-sharing
mechanism by the strong price of anarchy (SPoA), comparing a worst-case stable
coalition structure and a social optimum. In particular, we derive SPoA for
common fair cost-sharing mechanisms (e.g., equal-split, proportional-split,
egalitarian and Nash bargaining solutions of bargaining games, and usage based
cost-sharing). We show that the SPoA for equal-split, proportional-split, and
usage based cost-sharing (under certain conditions) is $\Theta(\log K)$,
whereas the one for egalitarian and Nash bargaining solutions is $O(\sqrt{K}
\log K)$. Therefore, distributed decision-making processes under common fair
cost-sharing mechanisms induce only moderate inefficiency.
</dc:description>
 <dc:description>Comment: Abridged version of this paper appears in IEEE Transactions on
  Control of Network Systems</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05270</dc:identifier>
 <dc:identifier>doi:10.1109/TCNS.2017.2763747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05271</identifier>
 <datestamp>2016-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced detectability of community structure in multilayer networks
  through layer aggregation</dc:title>
 <dc:creator>Taylor, Dane</dc:creator>
 <dc:creator>Shai, Saray</dc:creator>
 <dc:creator>Stanley, Natalie</dc:creator>
 <dc:creator>Mucha, Peter J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Many systems are naturally represented by a multilayer network in which edges
exist in multiple layers that encode different, but potentially related, types
of interactions, and it is important to understand limitations on the
detectability of community structure in these networks. Using random matrix
theory, we analyze detectability limitations for multilayer (specifically,
multiplex) stochastic block models (SBMs) in which L layers are derived from a
common SBM. We study the effect of layer aggregation on detectability for
several aggregation methods, including summation of the layers' adjacency
matrices for which we show the detectability limit vanishes as O(L^{-1/2}) with
increasing number of layers, L. Importantly, we find a similar scaling behavior
when the summation is thresholded at an optimal value, providing insight into
the common - but not well understood - practice of thresholding
pairwise-interaction data to obtain sparse network representations.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05271</dc:identifier>
 <dc:identifier>Phys. Rev. Lett. 116, 228301 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevLett.116.228301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05273</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards composition of conformant systems</dc:title>
 <dc:creator>Abbas, Houssam</dc:creator>
 <dc:creator>Fainekos, Georgios</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Motivated by the Model-Based Design process for Cyber-Physical Systems, we
consider issues in conformance testing of systems. Conformance is a
quantitative notion of similarity between the output trajectories of systems,
which considers both temporal and spatial aspects of the outputs. Previous work
developed algorithms for computing the conformance degree between two systems,
and demonstrated how formal verification results for one system can be re-used
for a system that is conformant to it. In this paper, we study the relation
between conformance and a generalized approximate simulation relation for the
class of Open Metric Transition Systems (OMTS). This allows us to prove a
small-gain theorem for OMTS, which gives sufficient conditions under which the
feedback interconnection of systems respects the conformance relation, thus
allowing the building of more complex systems from conformant components.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05284</identifier>
 <datestamp>2016-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Compositional Captioning: Describing Novel Object Categories
  without Paired Training Data</dc:title>
 <dc:creator>Hendricks, Lisa Anne</dc:creator>
 <dc:creator>Venugopalan, Subhashini</dc:creator>
 <dc:creator>Rohrbach, Marcus</dc:creator>
 <dc:creator>Mooney, Raymond</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While recent deep neural network models have achieved promising results on
the image captioning task, they rely largely on the availability of corpora
with paired image and sentence captions to describe objects in context. In this
work, we propose the Deep Compositional Captioner (DCC) to address the task of
generating descriptions of novel objects which are not present in paired
image-sentence datasets. Our method achieves this by leveraging large object
recognition datasets and external text corpora and by transferring knowledge
between semantically similar concepts. Current deep caption models can only
describe objects contained in paired image-sentence corpora, despite the fact
that they are pre-trained with large object recognition datasets, namely
ImageNet. In contrast, our model can compose sentences that describe novel
objects and their interactions with other objects. We demonstrate our model's
ability to describe novel concepts by empirically evaluating its performance on
MSCOCO and show qualitative results on ImageNet images of objects for which no
paired image-caption data exist. Further, we extend our approach to generate
descriptions of objects in video clips. Our results show that DCC has distinct
advantages over existing image and video captioning approaches for generating
descriptions of new objects in context.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05286</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classifying and Segmenting Microscopy Images Using Convolutional
  Multiple Instance Learning</dc:title>
 <dc:creator>Kraus, Oren Z.</dc:creator>
 <dc:creator>Ba, Lei Jimmy</dc:creator>
 <dc:creator>Frey, Brendan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Subcellular Processes</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Convolutional neural networks (CNN) have achieved state of the art
performance on both classification and segmentation tasks. Applying CNNs to
microscopy images is challenging due to the lack of datasets labeled at the
single cell level. We extend the application of CNNs to microscopy image
classification and segmentation using multiple instance learning (MIL). We
present the adaptive Noisy-AND MIL pooling function, a new MIL operator that is
robust to outliers. Combining CNNs with MIL enables training CNNs using full
resolution microscopy images with global labels. We base our approach on the
similarity between the aggregation function used in MIL and pooling layers used
in CNNs. We show that training MIL CNNs end-to-end outperforms several previous
methods on both mammalian and yeast microscopy images without requiring any
segmentation steps.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05286</dc:identifier>
 <dc:identifier>Bioinformatics (2016) 32 (12): i52-i59</dc:identifier>
 <dc:identifier>doi:10.1093/bioinformatics/btw252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05292</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Spatial Sum-Product Networks for Action Recognition in
  Still Images</dc:title>
 <dc:creator>Wang, Jinghua</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing actions from still images is popularly studied recently. In this
paper, we model an action class as a flexible number of spatial configurations
of body parts by proposing a new spatial SPN (Sum-Product Networks). First, we
discover a set of parts in image collections via unsupervised learning. Then,
our new spatial SPN is applied to model the spatial relationship and also the
high-order correlations of parts. To learn robust networks, we further develop
a hierarchical spatial SPN method, which models pairwise spatial relationship
between parts inside sub-images and models the correlation of sub-images via
extra layers of SPN. Our method is shown to be effective on two benchmark
datasets.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05296</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Predicting the Likeability of Fashion Images</dc:title>
 <dc:creator>Wang, Jinghua</dc:creator>
 <dc:creator>Nabi, Abrar Abdul</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Wan, Chengde</dc:creator>
 <dc:creator>Ng, Tian-Tsong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a method for ranking fashion images to find the
ones which might be liked by more people. We collect two new datasets from
image sharing websites (Pinterest and Polyvore). We represent fashion images
based on attributes: semantic attributes and data-driven attributes. To learn
semantic attributes from limited training data, we use an algorithm on
multi-task convolutional neural networks to share visual knowledge among
different semantic attribute categories. To discover data-driven attributes
unsupervisedly, we propose an algorithm to simultaneously discover visual
clusters and learn fashion-specific feature representations. Given attributes
as representations, we propose to learn a ranking SPN (sum product networks) to
rank pairs of fashion images. The proposed ranking SPN can capture the
high-order correlations of the attributes. We show the effectiveness of our
method on our two newly collected datasets.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05297</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the interplay of network structure and gradient convergence in deep
  learning</dc:title>
 <dc:creator>Ithapu, Vamsi K</dc:creator>
 <dc:creator>Ravi, Sathya N</dc:creator>
 <dc:creator>Singh, Vikas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The regularization and output consistency behavior of dropout and layer-wise
pretraining for learning deep networks have been fairly well studied. However,
our understanding of how the asymptotic convergence of backpropagation in deep
architectures is related to the structural properties of the network and other
design choices (like denoising and dropout rate) is less clear at this time. An
interesting question one may ask is whether the network architecture and input
data statistics may guide the choices of learning parameters and vice versa. In
this work, we explore the association between such structural, distributional
and learnability aspects vis-\`a-vis their interaction with parameter
convergence rates. We present a framework to address these questions based on
convergence of backpropagation for general nonconvex objectives using
first-order information. This analysis suggests an interesting relationship
between feature denoising and dropout. Building upon these results, we obtain a
setup that provides systematic guidance regarding the choice of learning
parameters and network sizes that achieve a certain level of convergence (in
the optimization sense) often mediated by statistical attributes of the inputs.
Our results are supported by a set of experimental evaluations as well as
independent empirical observations reported by other groups.
</dc:description>
 <dc:description>Comment: 54th Allerton Conference on Communication, Control and Computing
  2016; pgs 488-495</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05298</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural-RNN: Deep Learning on Spatio-Temporal Graphs</dc:title>
 <dc:creator>Jain, Ashesh</dc:creator>
 <dc:creator>Zamir, Amir R.</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep Recurrent Neural Network architectures, though remarkably capable at
modeling sequences, lack an intuitive high-level spatio-temporal structure.
That is while many problems in computer vision inherently have an underlying
high-level structure and can benefit from it. Spatio-temporal graphs are a
popular tool for imposing such high-level intuitions in the formulation of real
world problems. In this paper, we propose an approach for combining the power
of high-level spatio-temporal graphs and sequence learning success of Recurrent
Neural Networks~(RNNs). We develop a scalable method for casting an arbitrary
spatio-temporal graph as a rich RNN mixture that is feedforward, fully
differentiable, and jointly trainable. The proposed method is generic and
principled as it can be used for transforming any spatio-temporal graph through
employing a certain set of well defined steps. The evaluations of the proposed
approach on a diverse set of problems, ranging from modeling human motion to
object interactions, shows improvement over the state-of-the-art with a large
margin. We expect this method to empower new approaches to problem formulation
through high-level spatio-temporal graphs and Recurrent Neural Networks.
</dc:description>
 <dc:description>Comment: CVPR 2016 (Oral)</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05300</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research of the Correlation between the H1N1 Morbidity Data and Google
  Trends in Egypt</dc:title>
 <dc:creator>Li, Shengli</dc:creator>
 <dc:creator>Zhou, Xichuan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The search engine based on influenza monitoring system has been widely
applied in many European and American countries. However, there are not any
correlative researches reported for African developing countries. Especially,
the countries Egypt has not designed an influenza monitoring system on the
basis of the Internet search data. This study aims at analyzing the correlation
between the Google search data and the H1N1 morbidity data of Egypt, and
examining the feasibility of Google Flu Model in predicting the H1N1 influenza
trend.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05318</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Performance Analysis for 1-bit Bayesian Smoothing</dc:title>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Stein, Manuel</dc:creator>
 <dc:creator>Nossek, Josef A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy-efficient signal processing systems require estimation methods
operating on data collected with low-complexity devices. Using
analog-to-digital converters (ADC) with $1$-bit amplitude resolution has been
identified as a possible option in order to obtain low power consumption. The
$1$-bit performance loss, in comparison to an ideal receiver with $\infty$-bit
ADC, is well-established and moderate for low SNR applications ($2/\pi$ or
$-1.96$ dB). Recently it has been shown that for parameter estimation with
state-space models the $1$-bit performance loss with Bayesian filtering can be
significantly smaller ($\sqrt{2/\pi}$ or $-0.98$ dB). Here we extend the
analysis to Bayesian smoothing where additional measurements are used to
reconstruct the current state of the system parameter. Our results show that a
$1$-bit receiver performing smoothing is able to outperform an ideal
$\infty$-bit system carrying out filtering by the cost of an additional
processing delay $\Delta$.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05324</identifier>
 <datestamp>2017-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Human-Machine Networks: A Cross-Disciplinary Survey</dc:title>
 <dc:creator>Tsvetkova, Milena</dc:creator>
 <dc:creator>Yasseri, Taha</dc:creator>
 <dc:creator>Meyer, Eric T.</dc:creator>
 <dc:creator>Pickering, J. Brian</dc:creator>
 <dc:creator>Engen, Vegard</dc:creator>
 <dc:creator>Walland, Paul</dc:creator>
 <dc:creator>L&#xfc;ders, Marika</dc:creator>
 <dc:creator>F&#xf8;lstad, Asbj&#xf8;rn</dc:creator>
 <dc:creator>Bravos, George</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>A.1</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>K.6.0</dc:subject>
 <dc:description>  In the current hyper-connected era, modern Information and Communication
Technology systems form sophisticated networks where not only do people
interact with other people, but also machines take an increasingly visible and
participatory role. Such human-machine networks (HMNs) are embedded in the
daily lives of people, both for personal and professional use. They can have a
significant impact by producing synergy and innovations. The challenge in
designing successful HMNs is that they cannot be developed and implemented in
the same manner as networks of machines nodes alone, nor following a wholly
human-centric view of the network. The problem requires an interdisciplinary
approach. Here, we review current research of relevance to HMNs across many
disciplines. Extending the previous theoretical concepts of socio-technical
systems, actor-network theory, cyber-physical-social systems, and social
machines, we concentrate on the interactions among humans and between humans
and machines. We identify eight types of HMNs: public-resource computing,
crowdsourcing, web search engines, crowdsensing, online markets, social media,
multiplayer online games and virtual worlds, and mass collaboration. We
systematically select literature on each of these types and review it with a
focus on implications for designing HMNs. Moreover, we discuss risks associated
with HMNs and identify emerging design and development trends.
</dc:description>
 <dc:description>Comment: Forthcoming in ACM Computing Surveys</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05334</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting and Generating Terms in the Binary Lambda Calculus (Extended
  version)</dc:title>
 <dc:creator>Grygiel, Katarzyna</dc:creator>
 <dc:creator>Lescanne, Pierre</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In a paper entitled Binary lambda calculus and combinatory logic, John Tromp
presents a simple way of encoding lambda calculus terms as binary sequences. In
what follows, we study the numbers of binary strings of a given size that
represent lambda terms and derive results from their generating functions,
especially that the number of terms of size n grows roughly like 1.963447954.
.. n. In a second part we use this approach to generate random lambda terms
using Boltzmann samplers.
</dc:description>
 <dc:description>Comment: extended version of arXiv:1401.0379</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05334</dc:identifier>
 <dc:identifier>J. Funct. Prog. 25 (2015) e24</dc:identifier>
 <dc:identifier>doi:10.1017/S0956796815000271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05338</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>World Migration Degree Global migration flows in directed networks</dc:title>
 <dc:creator>Porat, Idan</dc:creator>
 <dc:creator>Benguigui, Lucien</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this article we analyze the global flow of migrants from 206 source
countries to 145 destination countries (2006-2010) and focus on the differences
in the migration network pattern between destination and source counters as
represented by its degree and weight distribution. Degree represents the
connectivity of a country to the global migration network, and plays an
important role in defining migration processes and characteristics. Global
analysis of migration degree distribution offers a strong potential
contribution to understanding of migration as a global phenomenon. In regard to
immigration, we found that it is possible to classify destination countries
into three classes: global migration hubs with high connectivity and high
migration rate; local migration hubs with low connectivity and high migration
rate; and local migration hubs with opposite strategy of high connectivity and
low migration rate. The different migration strategies of destination countries
are emerging from similar and homogenies pattern of emigration from source
countries were similar network patterns were found for most of the countries.
These findings, of similar behavior which creates different results is a
complex phenomenon which represents the diverse nature of migration.
</dc:description>
 <dc:description>Comment: 22 pages 10 figures</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05341</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Weakness of Fully Homomorphic Encryption</dc:title>
 <dc:creator>Cao, Zhengjun</dc:creator>
 <dc:creator>Liu, Lihua</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Fully homomorphic encryption (FHE) allows anyone to perform computations on
encrypted data, despite not having the secret decryption key. Since the
Gentry's work in 2009, the primitive has interested many researchers. In this
paper, we stress that any computations performed on encrypted data are
constrained to the encrypted domain (finite fields or rings). This restriction
makes the primitive useless for most computations involving common arithmetic
expressions and relational expressions. It is only applicable to the
computations related to modular arithmetic. We want to reaffirm that
cryptography uses modular arithmetic a lot in order to obscure and dissipate
the redundancies in a plaintext message, not to perform any numerical
calculations. We think it might be an overstated claim that FHE is of great
importance to client-server computing or cloud computing.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05357</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial-Noise-Aided Message Authentication Codes with
  Information-Theoretic Security</dc:title>
 <dc:creator>Wu, Xiaofu</dc:creator>
 <dc:creator>Yang, Zhen</dc:creator>
 <dc:creator>Ling, Cong</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the past, two main approaches for the purpose of authentication, including
information-theoretic authentication codes and complexity-theoretic message
authentication codes (MACs), were almost independently developed. In this
paper, we propose a new cryptographic primitive, namely, artificial-noise-aided
MACs (ANA-MACs), which can be considered as both computationally secure and
information-theoretically secure. For ANA-MACs, we introduce artificial noise
to interfere with the complexity-theoretic MACs and quantization is further
employed to facilitate packet-based transmission. With a channel coding
formulation of key recovery in the MACs, the generation of standard
authentication tags can be seen as an encoding process for the ensemble of
codes, where the shared key between Alice and Bob is considered as the input
and the message is used to specify a code from the ensemble of codes. Then, we
show that the introduction of artificial noise in ANA-MACs can be well employed
to resist the key recovery attack even if the opponent has an unlimited
computing power. Finally, a pragmatic approach for the analysis of ANA-MACs is
provided, and we show how to balance the three performance metrics, including
the completeness error, the false acceptance probability, and the conditional
equivocation about the key. The analysis can be well applied to a class of
ANA-MACs, where MACs with Rijndael cipher are employed.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, submitted for possible publication</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05358</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavioral Compatibility of Simulink Models for Product Line Maintenance
  and Evolution</dc:title>
 <dc:creator>Rumpe, Bernhard</dc:creator>
 <dc:creator>Schulze, Christoph</dc:creator>
 <dc:creator>von Wenckstern, Michael</dc:creator>
 <dc:creator>Ringert, Jan Oliver</dc:creator>
 <dc:creator>Manhart, Peter</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Embedded software systems, e.g. automotive, robotic or automation systems are
highly configurable and consist of many software components being available in
different variants and versions. To identify the degree of reusability between
these different occurrences of a component, it is necessary to determine the
functional backward and forward compatibility between them. Based on this
information it is possible to identify in which system context a component can
be replaced safely by another version, e.g. exchanging an older component, or
variant, e.g. introducing new features, to achieve the same functionality. This
paper presents a model checking approach to determine behavioral compatibility
of Simulink models, obtained from different component variants or during
evolution. A prototype for automated compatibility checking demonstrates its
feasibility. In addition implemented optimizations make the analysis more
efficient, when the compared variants or versions are structurally similar. A
case study on a driver assistance system provided by Daimler AG shows the
effectiveness of the approach to automatically compare Simulink components.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures, 4 tables, Proceedings of the 19th International
  Conference on Software Product Line (SPLC)</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05358</dc:identifier>
 <dc:identifier>doi:10.1145/2791060.2791077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05359</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimation of Timing Offsets and Phase Shifts Between Packet Replicas in
  MARSALA Random Access</dc:title>
 <dc:creator>Zidane, Karine</dc:creator>
 <dc:creator>Lacan, J&#xe9;rome</dc:creator>
 <dc:creator>Gineste, Mathieu</dc:creator>
 <dc:creator>Bes, Caroline</dc:creator>
 <dc:creator>Deramecourt, Arnaud</dc:creator>
 <dc:creator>Dervin, Mathieu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multi-replicA decoding using corRelation baSed LocALisAtion (MARSALA) is a
recent random access technique designed for satellite return links. It follows
the multiple transmission and interference cancellation scheme of Contention
Resolution Diversity Slotted Aloha (CRDSA). In addition, at the receiver side,
MARSALA uses autocorrelation to localise replicas of a same packet so as to
coherently combine them. Previous work has shown good performance of MARSALA
with an assumption of ideal channel state information and perfectly coherent
combining of the different replicas of a given packet. However, in a real
system, synchronisation errors such as timing offsets and phase shifts between
the replicas on separate timeslots will result in less constructive combining
of the received signals. This paper describes a method to estimate and
compensate the timing and phase differences between the replicas, prior to
their combination. Then, the impact of signal misalignment in terms of residual
timing offsets and phase shifts, is modeled and evaluated analytically.
Finally, the performance of MARSALA in realistic channel conditions is assessed
through simulations, and compared to CRDSA in various scenarios.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05362</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Random Kaczmarz Algorithm Based on Clustering Information</dc:title>
 <dc:creator>Li, Yujun</dc:creator>
 <dc:creator>Mo, Kaichun</dc:creator>
 <dc:creator>Ye, Haishan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Kaczmarz algorithm is an efficient iterative algorithm to solve
overdetermined consistent system of linear equations. During each updating
step, Kaczmarz chooses a hyperplane based on an individual equation and
projects the current estimate for the exact solution onto that space to get a
new estimate. Many vairants of Kaczmarz algorithms are proposed on how to
choose better hyperplanes. Using the property of randomly sampled data in
high-dimensional space, we propose an accelerated algorithm based on clustering
information to improve block Kaczmarz and Kaczmarz via Johnson-Lindenstrauss
lemma. Additionally, we theoretically demonstrate convergence improvement on
block Kaczmarz algorithm.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05363</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Modelling of the Impact on Bus Punctuality of a Speed
  Limit Proposal in Edinburgh (Extended Version)</dc:title>
 <dc:creator>Reijsbergen, Dani&#xeb;l</dc:creator>
 <dc:creator>Ratan, Rajeev</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We propose a data-driven methodology for evaluating the impact of the
introduction of a speed limit on the punctuality of bus services. In
particular, we use high-frequency Automatic Vehicle Location data to
parameterise a model that represents the movement of a bus along predefined
patches of the route. We fit the probability distributions of the time spent in
each patch to two classes of probability distributions: hyper-Erlang
distributions, for which we use the tool HyperStar, and a variation of the
three-parameter gamma distributions recommended by the Traffic Engineering
Handbook. In both cases we obtain models that can be expressed using the
framework of Probabilistic Timed Automata, allowing us to evaluate bus
punctuality using the model checking tool UPPAAL. We conduct a case study
involving a proposed speed limit in Edinburgh. This is an extended version of a
paper presented at ValueTools 2015.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05364</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tailoring the MontiArcAutomaton Component &amp; Connector ADL for Generative
  Development</dc:title>
 <dc:creator>Ringert, Jan O.</dc:creator>
 <dc:creator>Rumpe, Bernhard</dc:creator>
 <dc:creator>Wortmann, Andreas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Component&amp;connector (C&amp;C) architecture description languages (ADLs) combine
component-based software engineering and model-driven engineering to increase
reuse and to abstract from implementation details. Applied to robotics
application development, current C&amp;C ADLs often require domain experts to
provide component behavior descriptions as programming language artifacts or as
models of a-priori mixed behavior modeling languages. They are limited to
specific target platforms or require extensive handcrafting to transform
platform-independent software architecture models into platform-specific
implementations. We have developed the MontiArcAutomaton framework that
combines structural extension of C&amp;C concepts with integration of
application-specific component behavior modeling languages, seamless
transformation from logical into platform-specific software architectures, and
a-posteriori black-box composition of code generators for different robotics
platforms. This paper describes the roles and activities for tailoring
MontiArcAutomaton to application-specific demands.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05365</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transforming Platform-Independent to Platform-Specific Component and
  Connector Software Architecture Models</dc:title>
 <dc:creator>Ringert, Jan O.</dc:creator>
 <dc:creator>Rumpe, Bernhard</dc:creator>
 <dc:creator>Wortmann, Andreas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Combining component &amp; connector architecture
descriptionlanguageswithcomponentbehaviormodelinglanguages enables modeling
great parts of software architectures platformindependently. Nontrivial systems
typically contain components with programming language behavior descriptions to
interface with APIs. These components tie the complete software architecture to
a specific platform and thus hamper reuse. Previous work on software
architecture reuse with multiple platforms either requires platform-specific
handcrafting or the effort of explicit platform models. We present an automated
approach to transform platform-independent, logical software architectures into
architectures with platform-specific components. This approach introduces
abstract components to the platform-independent architecture and refines the se
with components specific to the target platform prior to code generation.
Consequently, a single logical software architecture model can be reused with
multiple target platforms, which increases architecture maturity and reduces
the maintenance effort of multiple similar software architectures.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, 2 listings 2nd International Workshop on
  Model-Driven Engineering for Component-Based Software Systems (ModComp)</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05366</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematically Deriving Domain-Specific Transformation Languages</dc:title>
 <dc:creator>H&#xf6;lldobler, Katrin</dc:creator>
 <dc:creator>Weisem&#xf6;ller, Bernhard Rumpe Ingo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Model transformations are helpful to evolve, refactor, refine and maintain
models. While domain-specific languages are normally intuitive for modelers,
common model transformation approaches (regardless of whether they transform
graphical or textual models) are based on the modeling language's abstract
syntax requiring the modeler to learn the internal representation of the model
to describe transformations. This paper presents a process that allows to
systematically derive a textual domainspecific transformation language from the
grammar of a given textual modeling language. As example, we apply this
systematic derivation to UML class diagrams to obtain a domain-specific
transformation language called CDTrans. CDTrans incorporates the concrete
syntax of class diagrams which is already familiar to the modeler and extends
it with a few transformation operators. To demonstrate the usefulness of the
derived transformation language, we describe several refactoring
transformations.
</dc:description>
 <dc:description>Comment: 10 listings, 1 figure, Conference on Model Driven Engineering
  Languages and Systems (MODELS)</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05371</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Time EXPected Similarity Estimation using Stochastic
  Optimization</dc:title>
 <dc:creator>Schneider, Markus</dc:creator>
 <dc:creator>Ertel, Wolfgang</dc:creator>
 <dc:creator>Palm, G&#xfc;nther</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A new algorithm named EXPected Similarity Estimation (EXPoSE) was recently
proposed to solve the problem of large-scale anomaly detection. It is a
non-parametric and distribution free kernel method based on the Hilbert space
embedding of probability measures. Given a dataset of $n$ samples, EXPoSE needs
only $\mathcal{O}(n)$ (linear time) to build a model and $\mathcal{O}(1)$
(constant time) to make a prediction. In this work we improve the linear
computational complexity and show that an $\epsilon$-accurate model can be
estimated in constant time, which has significant implications for large-scale
learning problems. To achieve this goal, we cast the original EXPoSE
formulation into a stochastic optimization problem. It is crucial that this
approach allows us to determine the number of iteration based on a desired
accuracy $\epsilon$, independent of the dataset size $n$. We will show that the
proposed stochastic gradient descent algorithm works in general (possible
infinite-dimensional) Hilbert spaces, is easy to implement and requires no
additional step-size parameters.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05384</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On path sequences of graphs</dc:title>
 <dc:creator>Bakalarski, S&#x142;awomir</dc:creator>
 <dc:creator>Zygad&#x142;o, Jakub</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C38, 68R10</dc:subject>
 <dc:description>  A subset $S$ of vertices of a graph $G=(V,E)$ is called a $k$-path vertex
cover if every path on $k$ vertices in $G$ contains at least one vertex from
$S$. Denote by $\psi_k(G)$ the minimum cardinality of a $k$-path vertex cover
in $G$ and form a sequence
$\psi(G)=(\psi_1(G),\psi_2(G),\ldots,\psi_{|V|}(G))$, called the path sequence
of $G$. In this paper we prove necessary and sufficient conditions for two
integers to appear on fixed positions in $\psi(G)$. A complete list of all
possible path sequences (with multiplicities) for small connected graphs is
also given.
</dc:description>
 <dc:description>Comment: 10 pages, 3 tables; submitted to Schedae Informaticae</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05384</dc:identifier>
 <dc:identifier>Schedae Informaticae, vol. 24 (2015), pp. 230-242</dc:identifier>
 <dc:identifier>doi:10.4467/20838476SI.16.020.4361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05385</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Optimization with Dimension Scheduling: Application to
  Biological Systems</dc:title>
 <dc:creator>Ulmasov, Doniyor</dc:creator>
 <dc:creator>Baroukh, Caroline</dc:creator>
 <dc:creator>Chachuat, Benoit</dc:creator>
 <dc:creator>Deisenroth, Marc Peter</dc:creator>
 <dc:creator>Misener, Ruth</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Bayesian Optimization (BO) is a data-efficient method for global black-box
optimization of an expensive-to-evaluate fitness function. BO typically assumes
that computation cost of BO is cheap, but experiments are time consuming or
costly. In practice, this allows us to optimize ten or fewer critical
parameters in up to 1,000 experiments. But experiments may be less expensive
than BO methods assume: In some simulation models, we may be able to conduct
multiple thousands of experiments in a few hours, and the computational burden
of BO is no longer negligible compared to experimentation time. To address this
challenge we introduce a new Dimension Scheduling Algorithm (DSA), which
reduces the computational burden of BO for many experiments. The key idea is
that DSA optimizes the fitness function only along a small set of dimensions at
each iteration. This DSA strategy (1) reduces the necessary computation time,
(2) finds good solutions faster than the traditional BO method, and (3) can be
parallelized straightforwardly. We evaluate the DSA in the context of
optimizing parameters of dynamic models of microalgae metabolism and show
faster convergence than traditional BO.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05389</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to retrieve out-of-vocabulary words in speech recognition</dc:title>
 <dc:creator>Sheikh, Imran</dc:creator>
 <dc:creator>Illina, Irina</dc:creator>
 <dc:creator>Fohr, Dominique</dc:creator>
 <dc:creator>Linar&#xe8;s, Georges</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech
recognition systems used to process diachronic audio data. To help recovery of
the PNs missed by the system, relevant OOV PNs can be retrieved out of the many
OOVs by exploiting semantic context of the spoken content. In this paper, we
propose two neural network models targeted to retrieve OOV PNs relevant to an
audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b)
Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models
take document words as input and learn with an objective to maximise the
retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new
approach in which the input embedding layer is augmented with a context anchor
layer. This layer learns to assign importance to input words and has the
ability to capture (task specific) key-words in a bag-of-word neural network
model. With experiments on French broadcast news videos we show that these two
models outperform the baseline methods based on raw embeddings from LDA,
Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives
faster convergence during training.
</dc:description>
 <dc:description>Comment: Updated references, added appendix discussing more results; added
  more discussion, replaced simple phone search results with KWS results; added
  KWS results for both training phase, probably last update</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05392</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the Dimensionality of Word Embeddings</dc:title>
 <dc:creator>Nalisnick, Eric</dc:creator>
 <dc:creator>Ravi, Sachin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a method for learning word embeddings with data-dependent
dimensionality. Our Stochastic Dimensionality Skip-Gram (SD-SG) and Stochastic
Dimensionality Continuous Bag-of-Words (SD-CBOW) are nonparametric analogs of
Mikolov et al.'s (2013) well-known 'word2vec' models. Vector dimensionality is
made dynamic by employing techniques used by Cote &amp; Larochelle (2016) to define
an RBM with an infinite number of hidden units. We show qualitatively and
quantitatively that SD-SG and SD-CBOW are competitive with their
fixed-dimension counterparts while providing a distribution over embedding
dimensionalities, which offers a window into how semantics distribute across
dimensions.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05398</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Existence of Tree Backbones that Realize the Chromatic Number on
  a Backbone Coloring</dc:title>
 <dc:creator>Araujo, Julio</dc:creator>
 <dc:creator>Cezar, Alexandre A.</dc:creator>
 <dc:creator>Silva, Ana</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A proper $k$-coloring of a graph $G=(V,E)$ is a function $c: V(G)\to
\{1,\ldots,k\}$ such that $c(u)\neq c(v)$, for every $uv\in E(G)$. The
chromatic number $\chi(G)$ is the minimum $k$ such that there exists a proper
$k$-coloring of $G$. Given a spanning subgraph $H$ of $G$, a $q$-backbone
$k$-coloring of $(G,H)$ is a proper $k$-coloring $c$ of $V(G)$ such that
$\lvert c(u)-c(v)\rvert \ge q$, for every edge $uv\in E(H)$. The $q$-backbone
chromatic number $BBC_q(G,H)$ is the smallest $k$ for which there exists a
$q$-backbone $k$-coloring of $(G,H)$. In this work, we show that every
connected graph $G$ has a generating tree $T$ such that $BBC_q(G,T) =
\max\{\chi(G),\left\lceil\frac{\chi(G)}{2}\right\rceil+q\}$, and that this
value is the best possible.
  As a direct consequence, we get that every connected graph $G$ has a spanning
tree $T$ for which $BBC_2(G,T)=\chi(G)$, if $\chi(G)\ge 4$, or
$BBC_2(G,T)=\chi(G)+1$, otherwise. Thus, by applying the Four Color Theorem, we
have that every connected nonbipartite planar graph $G$ has a spanning tree $T$
such that $BBC_2(G,T)=4$. This settles a question by Wang, Bu, Montassier and
Raspaud (2012), and generalizes a number of previous partial results to their
question.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05404</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction in complex systems: the case of the international trade
  network</dc:title>
 <dc:creator>Vidmer, Alexandre</dc:creator>
 <dc:creator>Zeng, An</dc:creator>
 <dc:creator>Medo, Mat&#xfa;&#x161;</dc:creator>
 <dc:creator>Zhang, Yi-Cheng</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Finance - Trading and Market Microstructure</dc:subject>
 <dc:description>  Predicting the future evolution of complex systems is one of the main
challenges in complexity science. Based on a current snapshot of a network,
link prediction algorithms aim to predict its future evolution. We apply here
link prediction algorithms to data on the international trade between
countries. This data can be represented as a complex network where links
connect countries with the products that they export. Link prediction
techniques based on heat and mass diffusion processes are employed to obtain
predictions for products exported in the future. These baseline predictions are
improved using a recent metric of country fitness and product similarity. The
overall best results are achieved with a newly developed metric of product
similarity which takes advantage of causality in the network evolution.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05404</dc:identifier>
 <dc:identifier>Vidmer, A., Zeng, A., Medo, M., &amp; Zhang, Y. C. (2015). Prediction
  in complex systems: The case of the international trade network. Physica A:
  Statistical Mechanics and its Applications, 436, 188-199</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.05.057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05410</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Layer Optimization of Fast Video Delivery in Cache-Enabled
  Relaying Networks</dc:title>
 <dc:creator>Xiang, Lin</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Islam, Toufiqul</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Wong, Vincent W. S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper investigates the cross-layer optimization of fast video delivery
and caching for minimization of the overall video delivery time in a two-hop
relaying network. The half-duplex relay nodes are equipped with both a cache
and a buffer which facilitate joint scheduling of fetching and delivery to
exploit the channel diversity for improving the overall delivery performance.
The fast delivery control is formulated as a two-stage functional non-convex
optimization problem. By exploiting the underlying convex and quasi-convex
structures, the problem can be solved exactly and efficiently by the developed
algorithm. Simulation results show that significant caching and buffering gains
can be achieved with the proposed framework, which translates into a reduction
of the overall video delivery time. Besides, a trade-off between caching and
buffering gains is unveiled.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures; accepted for presentation at IEEE Globecom, San
  Diego, CA, Dec. 2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05413</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyclic codes over $\mathbb{F}_{2^m}[u]/\langle u^k\rangle$ of oddly even
  length</dc:title>
 <dc:creator>Cao, Yonglin</dc:creator>
 <dc:creator>Cao, Yuan</dc:creator>
 <dc:creator>Fu, Fang-Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Let $\mathbb{F}_{2^m}$ be a finite field of characteristic $2$ and
$R=\mathbb{F}_{2^m}[u]/\langle u^k\rangle=\mathbb{F}_{2^m}
+u\mathbb{F}_{2^m}+\ldots+u^{k-1}\mathbb{F}_{2^m}$ ($u^k=0$) where $k\in
\mathbb{Z}^{+}$ satisfies $k\geq 2$. For any odd positive integer $n$, it is
known that cyclic codes over $R$ of length $2n$ are identified with ideals of
the ring $R[x]/\langle x^{2n}-1\rangle$. In this paper, an explicit
representation for each cyclic code over $R$ of length $2n$ is provided and a
formula to count the number of codewords in each code is given. Then a formula
to calculate the number of cyclic codes over $R$ of length $2n$ is obtained.
Moreover, the dual code of each cyclic code and self-dual cyclic codes over $R$
of length $2n$ are investigated. (AAECC-1522)
</dc:description>
 <dc:description>Comment: AAECC-1522</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05422</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-b-coloring Trees</dc:title>
 <dc:creator>Campos, Victor</dc:creator>
 <dc:creator>Silva, Ana</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A b-coloring of the vertices of a graph is a proper coloring where each color
class contains a vertex which is adjacent to at least one vertex in each other
color class. The b-chromatic number of $G$ is the maximum integer $b(G)$ for
which $G$ has a b-coloring with $b(G)$ colors. This problem was introduced by
Irving and Manlove in 1999, where they showed that computing $b(G)$ is
$\mathcal{NP}$-hard in general and polynomial-time solvable for trees. Since
then, a number of complexity results were shown, including NP-hardness results
for chordal graphs (Havet et. al., 2011) and line graphs (Campos et. al.,
2015). In this article, we present a polynomial time algorithm that solves the
problem restricted to claw-free block graphs, an important subclass of chordal
graphs and line graphs. This is equivalent to solving the edge coloring version
of the problem restricted to trees.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05427</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Matching Algorithm for Multidimensional Persistence</dc:title>
 <dc:creator>Allili, Madjid</dc:creator>
 <dc:creator>Kaczynski, Tomasz</dc:creator>
 <dc:creator>Landi, Claudia</dc:creator>
 <dc:creator>Masoni, Filippo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Primary 65D18, Secondary 52C45, 57Q10</dc:subject>
 <dc:description>  An algorithm is presented that constructs an acyclic partial matching on the
cells of a given simplicial complex from a vector-valued function defined on
the vertices and extended to each simplex by taking the least common upper
bound of the values on its vertices. The resulting acyclic partial matching may
be used to construct a reduced filtered complex with the same multidimensional
persistent homology as the original simplicial complex filtered by the sublevel
sets of the function. Numerical tests show that in practical cases the rate of
reduction in the number of cells achieved by the algorithm is substantial. This
promises to be useful for the computation of multidimensional persistent
homology of simplicial complexes filtered by sublevel sets of vector-valued
functions.
</dc:description>
 <dc:description>Comment: Changes to version 2: proof of Lemma 3.6 expanded</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05427</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05432</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Adversarial Training: Increasing Local Stability of Neural
  Nets through Robust Optimization</dc:title>
 <dc:creator>Shaham, Uri</dc:creator>
 <dc:creator>Yamada, Yutaro</dc:creator>
 <dc:creator>Negahban, Sahand</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a general framework for increasing local stability of Artificial
Neural Nets (ANNs) using Robust Optimization (RO). We achieve this through an
alternating minimization-maximization procedure, in which the loss of the
network is minimized over perturbed examples that are generated at each
parameter update. We show that adversarial training of ANNs is in fact
robustification of the network optimization, and that our proposed framework
generalizes previous approaches for increasing local stability of ANNs.
Experimental results reveal that our approach increases the robustness of the
network to existing adversarial examples, while making it harder to generate
new ones. Furthermore, our algorithm improves the accuracy of the network also
on the original test data.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05437</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PPV modelling of memristor-based oscillator</dc:title>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Wang, Hanyu</dc:creator>
 <dc:creator>Qi, Miao</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In this letter, we propose for the first time a method of abstracting the PPV
(Perturbation Projection Vector) characteristic of the up-to-date
memristor-based oscillators. Inspired from biological oscillators and its
characteristic named PRC (Phase Response Curve), we build a bridge between PRC
and PPV. This relationship is verified rigorously using the transistor level
simulation of Colpitts and ring oscillators, i.e., comparing the PPV converted
from PRC and the PPV obtained from accurate PSS+PXF simulation. Then we apply
this method to the PPV calculation of the memristor-based oscillator. By
keeping the phase dynamics of the oscillator and dropping the details of
voltage/current amplitude, the PPV modelling is highly efficient to describe
the phase dynamics due to the oscillator coupling, and will be very suitable
for the fast simulation of large scale oscillatory neural networks.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05440</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep multi-scale video prediction beyond mean square error</dc:title>
 <dc:creator>Mathieu, Michael</dc:creator>
 <dc:creator>Couprie, Camille</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning to predict future images from a video sequence involves the
construction of an internal representation that models the image evolution
accurately, and therefore, to some degree, its content and dynamics. This is
why pixel-space video prediction may be viewed as a promising avenue for
unsupervised feature learning. In addition, while optical flow has been a very
studied problem in computer vision for a long time, future frame prediction is
rarely approached. Still, many vision applications could benefit from the
knowledge of the next frames of videos, that does not require the complexity of
tracking every pixel trajectories. In this work, we train a convolutional
network to generate future frames given an input sequence. To deal with the
inherently blurry predictions obtained from the standard Mean Squared Error
(MSE) loss function, we propose three different and complementary feature
learning strategies: a multi-scale architecture, an adversarial training
method, and an image gradient difference loss function. We compare our
predictions to different published results based on recurrent neural networks
on the UCF101 dataset
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05449</identifier>
 <datestamp>2016-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Running Time Lower Bounds for Vertex Deletion Problems</dc:title>
 <dc:creator>Komusiewicz, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  For a graph class $\Pi$, the $\Pi$-Vertex Deletion problem has as input an
undirected graph $G=(V,E)$ and an integer $k$ and asks whether there is a set
of at most $k$ vertices that can be deleted from $G$ such that the resulting
graph is a member of $\Pi$. By a classic result of Lewis and Yannakakis [J.
Comput. Syst. Sci. '80], $\Pi$-Vertex Deletion is NP-hard for all hereditary
properties $\Pi$. We adapt the original NP-hardness construction to show that
under the Exponential Time Hypothesis (ETH) tight complexity results can be
obtained. We show that $\Pi$-Vertex Deletion does not admit a $2^{o(n)}$-time
algorithm where $n$ is the number of vertices in $G$. We also obtain a
dichotomy for running time bounds that include the number $m$ of edges in the
input graph: On the one hand, if $\Pi$ contains all independent sets, then
there is no $2^{o(n+m)}$-time algorithm for $\Pi$-Vertex Deletion. On the other
hand, if there is a fixed independent set that is not contained in $\Pi$ and
containment in $\Pi$ can determined in $2^{O(n)}$ time or $2^{o(m)}$ time, then
$\Pi$-Vertex Deletion can be solved in $2^{O(\sqrt{m})}+O(n)$ or
$2^{o({m})}+O(n)$ time, respectively. We also consider restrictions on the
domain of the input graph $G$. For example, we obtain that $\Pi$-Vertex
Deletion cannot be solved in $2^{o(\sqrt{n})}$ time if $G$ is planar and $\Pi$
is hereditary and contains and excludes infinitely many planar graphs. Finally,
we provide similar results for the problem variant where the deleted vertex set
has to induce a connected graph.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05453</identifier>
 <datestamp>2017-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Avoiding The Man on the Wire: Improving Tor's Security with Trust-Aware
  Path Selection</dc:title>
 <dc:creator>Johnson, Aaron</dc:creator>
 <dc:creator>Jansen, Rob</dc:creator>
 <dc:creator>Jaggard, Aaron D.</dc:creator>
 <dc:creator>Feigenbaum, Joan</dc:creator>
 <dc:creator>Syverson, Paul</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Tor users are vulnerable to deanonymization by an adversary that can observe
some Tor relays or some parts of the network. We demonstrate that previous
network-aware path-selection algorithms that propose to solve this problem are
vulnerable to attacks across multiple Tor connections. We suggest that users
use trust to choose the paths through Tor that are less likely to be observed,
where trust is flexibly modeled as a probability distribution on the location
of the user's adversaries, and we present the Trust-Aware Path Selection
algorithm for Tor that helps users avoid traffic-analysis attacks while still
choosing paths that could have been selected by many other users. We evaluate
this algorithm in two settings using a high-level map of Internet routing: (i)
users try to avoid a single global adversary that has an independent chance to
control each Autonomous System organization, Internet Exchange Point
organization, and Tor relay family, and (ii) users try to avoid deanonymization
by any single country. We also examine the performance of Trust-Aware Path
selection using the Shadow network simulator.
</dc:description>
 <dc:description>Comment: A conference version of this paper appears in Proceedings of the 24th
  Network and Distributed System Security Symposium (NDSS 2017)</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05464</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extending Gossip Algorithms to Distributed Estimation of U-Statistics</dc:title>
 <dc:creator>Colin, Igor</dc:creator>
 <dc:creator>Bellet, Aur&#xe9;lien</dc:creator>
 <dc:creator>Salmon, Joseph</dc:creator>
 <dc:creator>Cl&#xe9;men&#xe7;on, St&#xe9;phan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>68Uxx, 62J15, 68Q32, 62-04,</dc:subject>
 <dc:description>  Efficient and robust algorithms for decentralized estimation in networks are
essential to many distributed systems. Whereas distributed estimation of sample
mean statistics has been the subject of a good deal of attention, computation
of $U$-statistics, relying on more expensive averaging over pairs of
observations, is a less investigated area. Yet, such data functionals are
essential to describe global properties of a statistical population, with
important examples including Area Under the Curve, empirical variance, Gini
mean difference and within-cluster point scatter. This paper proposes new
synchronous and asynchronous randomized gossip algorithms which simultaneously
propagate data across the network and maintain local estimates of the
$U$-statistic of interest. We establish convergence rate bounds of $O(1/t)$ and
$O(\log t / t)$ for the synchronous and asynchronous cases respectively, where
$t$ is the number of iterations, with explicit data and network dependent
terms. Beyond favorable comparisons in terms of rate analysis, numerical
experiments provide empirical evidence the proposed algorithms surpasses the
previously introduced approach.
</dc:description>
 <dc:description>Comment: to be presented at NIPS 2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05479</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Declutter and Resample: Towards parameter free denoising</dc:title>
 <dc:creator>Buchet, Micka&#xeb;l</dc:creator>
 <dc:creator>Dey, Tamal K.</dc:creator>
 <dc:creator>Wang, Jiayuan</dc:creator>
 <dc:creator>Wang, Yusu</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In many data analysis applications the following scenario is commonplace: we
are given a point set that is supposed to sample a hidden ground truth $K$ in a
metric space, but it got corrupted with noise so that some of the data points
lie far away from $K$ creating outliers also termed as {\em ambient noise}. One
of the main goals of denoising algorithms is to eliminate such noise so that
the curated data lie within a bounded Hausdorff distance of $K$. Popular
denoising approaches such as deconvolution and thresholding often require the
user to set several parameters and/or to choose an appropriate noise model
while guaranteeing only asymptotic convergence. Our goal is to lighten this
burden as much as possible while ensuring theoretical guarantees in all cases.
  Specifically, first, we propose a simple denoising algorithm that requires
only a single parameter but provides a theoretical guarantee on the quality of
the output on general input points. We argue that this single parameter cannot
be avoided. We next present a simple algorithm that avoids even this parameter
by paying for it with a slight strengthening of the sampling condition on the
input points which is not unrealistic. We also provide some preliminary
empirical evidence that our algorithms are effective in practice.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05488</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active exploration of sensor networks from a robotics perspective</dc:title>
 <dc:creator>Blum, Christian</dc:creator>
 <dc:creator>Hafner, Verena V.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Traditional algorithms for robots who need to integrate into a wireless
network often focus on one specific task. In this work we want to develop
simple, adaptive and reusable algorithms for real world applications for this
scenario. Starting with the most basic task for mobile wireless network nodes,
finding the position of another node, we introduce an algorithm able to solve
this task. We then show how this algorithm can readily be employed to solve a
large number of other related tasks like finding the optimal position to bridge
two static network nodes. For this we first introduce a meta-algorithm inspired
by autonomous robot learning strategies and the concept of internal models
which yields a class of source seeking algorithms for mobile nodes. The
effectiveness of this algorithm is demonstrated in real world experiments using
a physical mobile robot and standard 802.11 wireless LAN in an office
environment. We also discuss the differences to conventional algorithms and
give the robotics perspective on this class of algorithms. Then we proceed to
show how more complex tasks, which might be encountered by mobile nodes, can be
encoded in the same framework and how the introduced algorithm can solve them.
These tasks can be direct (cross layer) optimization tasks or can also encode
more complex tasks like bridging two network nodes. We choose the bridging
scenario as an example, implemented on a real physical robot, and show how the
robot can solve it in a real world experiment.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05490</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SPIDER: Fault Resilient SDN Pipeline with Recovery Delay Guarantees</dc:title>
 <dc:creator>Cascone, Carmelo</dc:creator>
 <dc:creator>Pollini, Luca</dc:creator>
 <dc:creator>Sanvito, Davide</dc:creator>
 <dc:creator>Capone, Antonio</dc:creator>
 <dc:creator>Sans&#xf2;, Brunilde</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  When dealing with node or link failures in Software Defined Networking (SDN),
the network capability to establish an alternative path depends on controller
reachability and on the round trip times (RTTs) between controller and involved
switches. Moreover, current SDN data plane abstractions for failure detection
(e.g. OpenFlow &quot;Fast-failover&quot;) do not allow programmers to tweak switches'
detection mechanism, thus leaving SDN operators still relying on proprietary
management interfaces (when available) to achieve guaranteed detection and
recovery delays. We propose SPIDER, an OpenFlow-like pipeline design that
provides i) a detection mechanism based on switches' periodic link probing and
ii) fast reroute of traffic flows even in case of distant failures, regardless
of controller availability. SPIDER can be implemented using stateful data plane
abstractions such as OpenState or Open vSwitch, and it offers guaranteed short
(i.e. ms) failure detection and recovery delays, with a configurable trade off
between overhead and failover responsiveness. We present here the SPIDER
pipeline design, behavioral model, and analysis on flow tables' memory impact.
We also implemented and experimentally validated SPIDER using OpenState (an
OpenFlow 1.3 extension for stateful packet processing), showing numerical
results on its performance in terms of recovery latency and packet losses.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05493</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gated Graph Sequence Neural Networks</dc:title>
 <dc:creator>Li, Yujia</dc:creator>
 <dc:creator>Tarlow, Daniel</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:creator>Zemel, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Graph-structured data appears frequently in domains including chemistry,
natural language semantics, social networks, and knowledge bases. In this work,
we study feature learning techniques for graph-structured inputs. Our starting
point is previous work on Graph Neural Networks (Scarselli et al., 2009), which
we modify to use gated recurrent units and modern optimization techniques and
then extend to output sequences. The result is a flexible and broadly useful
class of neural network models that has favorable inductive biases relative to
purely sequence-based models (e.g., LSTMs) when the problem is
graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and
graph algorithm learning tasks. We then show it achieves state-of-the-art
performance on a problem from program verification, in which subgraphs need to
be matched to abstract data structures.
</dc:description>
 <dc:description>Comment: Published as a conference paper in ICLR 2016. Fixed a typo</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05497</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Neural Network Architectures using Backpropagation</dc:title>
 <dc:creator>Srinivas, Suraj</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep neural networks with millions of parameters are at the heart of many
state of the art machine learning models today. However, recent works have
shown that models with much smaller number of parameters can also perform just
as well. In this work, we introduce the problem of architecture-learning, i.e;
learning the architecture of a neural network along with weights. We introduce
a new trainable parameter called tri-state ReLU, which helps in eliminating
unnecessary neurons. We also propose a smooth regularizer which encourages the
total number of neurons after elimination to be small. The resulting objective
is differentiable and simple to optimize. We experimentally validate our method
on both small and large networks, and show that it can learn models with a
considerably small number of parameters without affecting prediction accuracy.
</dc:description>
 <dc:description>Comment: BMVC 2016 ; Title modified from 'Learning the Architecture of Deep
  Neural Networks'</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05498</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feasibility Study of Stochastic Streaming with 4K UHD Video Traces</dc:title>
 <dc:creator>Kim, Joongheon</dc:creator>
 <dc:creator>Ryu, Eun-Seok</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper performs the feasibility study of stochastic video streaming
algorithms with up-to-date 4K ultra-high-definition (UHD) video traces. In
previous work, various stochastic video streaming algorithms were proposed
which maximize time-average video streaming quality subject to queue stability
based on the information of queue-backlog length. The performance improvements
with the stochastic video streaming algorithms were verified with traditional
MPEG test sequences; but there is no study how much the proposed stochastic
algorithm is better when we consider up-to-date 4K UHD video traces. Therefore,
this paper evaluates the stochastic streaming algorithms with 4K UHD video
traces; and verifies that the stochastic algorithms perform better than
queue-independent algorithms, as desired.
</dc:description>
 <dc:description>Comment: Presented at the International Conference on ICT Convergence (ICTC),
  Jeju Island, Korea, 28 - 30 October 2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05499</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary CPMs with Improved Spectral Efficiency</dc:title>
 <dc:creator>Messai, Malek</dc:creator>
 <dc:creator>Piemontese, Amina</dc:creator>
 <dc:creator>Colavolpe, Giulio</dc:creator>
 <dc:creator>Amis, Karine</dc:creator>
 <dc:creator>Guilloud, Frederic</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We design new continuous phase modulation (CPM) formats which are based on
the combination of a proper precoder with binary input and a ternary CPM. The
proposed precoder constrains the signal phase evolution in order to increase
the minimum Euclidean distance, and to limit the bandwidth expansion due to the
use of a ternary CPM. The resulting schemes are highly spectrally efficient and
outperform classical binary and quaternary formats in terms of coded and
uncoded performance.
</dc:description>
 <dc:description>Comment: This paper is accepted to be published as an IEEE Communication
  Letter</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05499</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2015.2502247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05506</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neurocontrol methods review</dc:title>
 <dc:creator>Chernodub, Artem</dc:creator>
 <dc:creator>Dziuba, Dmitry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Methods of applying neural networks to control plants are considered. Methods
and schemes are described, their advantages and disadvantages are discussed.
</dc:description>
 <dc:description>Comment: in Russian</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05506</dc:identifier>
 <dc:identifier>Problems in Systems Programming, 2011, No. 2, p. 79-94</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05509</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Performance of Linear Analog Codes</dc:title>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Li, Jing</dc:creator>
 <dc:creator>Xie, Kai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we carefully study the MSE performance of the linear analog
codes. We have derived a lower bound of the MSE performance under
Likelihood(ML) and Linear Minimal Mean Square Error(LMMSE) decoding criteria
respectively. It is proved in this essay that a kind of linear analog codes
called \emph {unitary codes} can simultaneously achieve both of these two
bounds. At the same time, we compare the obtained linear analog codes' MSE
bounds with the performance of some existing nonlinear codes. The results
showed that linear analog codes are actually not very satisfying and convinced
us that more concerns should be cast onto the nonlinear class in order to find
powerful analog codes.
</dc:description>
 <dc:description>Comment: This manuscript has been withdrawn since a new kind of nonlinear
  analog code is now being developed and the results of the linear analog codes
  in this paper will be included as parts of a new manuscript</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05512</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Moral Lineage Tracing</dc:title>
 <dc:creator>Jug, Florian</dc:creator>
 <dc:creator>Levinkov, Evgeny</dc:creator>
 <dc:creator>Blasse, Corinna</dc:creator>
 <dc:creator>Myers, Eugene W.</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Lineage tracing, the tracking of living cells as they move and divide, is a
central problem in biological image analysis. Solutions, called lineage
forests, are key to understanding how the structure of multicellular organisms
emerges. We propose an integer linear program (ILP) whose feasible solutions
define a decomposition of each image in a sequence into cells (segmentation),
and a lineage forest of cells across images (tracing). Unlike previous
formulations, we do not constrain the set of decompositions, except by
contracting pixels to superpixels. The main challenge, as we show, is to
enforce the morality of lineages, i.e., the constraint that cells do not merge.
To enforce morality, we introduce path-cut inequalities. To find feasible
solutions of the NP-hard ILP, with certified bounds to the global optimum, we
define efficient separation procedures and apply these as part of a
branch-and-cut algorithm. We show the effectiveness of this approach by
analyzing feasible solutions for real microscopy data in terms of bounds and
run-time, and by their weighted edit distance to ground truth lineage forests
traced by humans.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05512</dc:identifier>
 <dc:identifier>The IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR), 2016, pp. 5926-5935</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2016.638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05514</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better $s$-$t$-Tours by Gao Trees</dc:title>
 <dc:creator>Gottschalk, Corinna</dc:creator>
 <dc:creator>Vygen, Jens</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We consider the $s$-$t$-path TSP: given a finite metric space with two
elements $s$ and $t$, we look for a path from $s$ to $t$ that contains all the
elements and has minimum total distance. We improve the approximation ratio for
this problem from 1.599 to 1.566. Like previous algorithms, we solve the
natural LP relaxation and represent an optimum solution $x^*$ as a convex
combination of spanning trees. Gao showed that there exists a spanning tree in
the support of $x^*$ that has only one edge in each narrow cut (i.e., each cut
$C$ with $x^*(C)&lt;2$). Our main theorem says that the spanning trees in the
convex combination can be chosen such that many of them are such &quot;Gao trees''.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05520</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Instrument Recognition in Polyphonic Music Using Convolutional
  Neural Networks</dc:title>
 <dc:creator>Li, Peter</dc:creator>
 <dc:creator>Qian, Jiyuan</dc:creator>
 <dc:creator>Wang, Tian</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Traditional methods to tackle many music information retrieval tasks
typically follow a two-step architecture: feature engineering followed by a
simple learning algorithm. In these &quot;shallow&quot; architectures, feature
engineering and learning are typically disjoint and unrelated. Additionally,
feature engineering is difficult, and typically depends on extensive domain
expertise.
  In this paper, we present an application of convolutional neural networks for
the task of automatic musical instrument identification. In this model, feature
extraction and learning algorithms are trained together in an end-to-end
fashion. We show that a convolutional neural network trained on raw audio can
achieve performance surpassing traditional methods that rely on hand-crafted
features.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05526</identifier>
 <datestamp>2016-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Articulated Motion Models from Visual and Lingual Signals</dc:title>
 <dc:creator>Wu, Zhengyang</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Walter, Matthew R.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In order for robots to operate effectively in homes and workplaces, they must
be able to manipulate the articulated objects common within environments built
for and by humans. Previous work learns kinematic models that prescribe this
manipulation from visual demonstrations. Lingual signals, such as natural
language descriptions and instructions, offer a complementary means of
conveying knowledge of such manipulation models and are suitable to a wide
range of interactions (e.g., remote manipulation). In this paper, we present a
multimodal learning framework that incorporates both visual and lingual
information to estimate the structure and parameters that define kinematic
models of articulated objects. The visual signal takes the form of an RGB-D
image stream that opportunistically captures object motion in an unprepared
scene. Accompanying natural language descriptions of the motion constitute the
lingual signal. We present a probabilistic language model that uses word
embeddings to associate lingual verbs with their corresponding kinematic
structures. By exploiting the complementary nature of the visual and lingual
input, our method infers correct kinematic structures for various multiple-part
objects on which the previous state-of-the-art, visual-only system fails. We
evaluate our multimodal learning framework on a dataset comprised of a variety
of household objects, and demonstrate a 36% improvement in model accuracy over
the vision-only baseline.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05526</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05538</identifier>
 <datestamp>2016-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Material degradation due to moisture and temperature. Part 1:
  Mathematical model, analysis, and analytical solutions</dc:title>
 <dc:creator>Xu, C.</dc:creator>
 <dc:creator>Mudunuru, M. K.</dc:creator>
 <dc:creator>Nakshatrala, K. B.</dc:creator>
 <dc:subject>Condensed Matter - Materials Science</dc:subject>
 <dc:subject>Condensed Matter - Soft Condensed Matter</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The mechanical response, serviceability, and load bearing capacity of
materials and structural components can be adversely affected due to external
stimuli, which include exposure to a corrosive chemical species, high
temperatures, temperature fluctuations (i.e., freezing-thawing), cyclic
mechanical loading, just to name a few. It is, therefore, of paramount
importance in several branches of engineering -- ranging from aerospace
engineering, civil engineering to biomedical engineering -- to have a
fundamental understanding of degradation of materials, as the materials in
these applications are often subjected to adverse environments. As a result of
recent advancements in material science, new materials like fiber-reinforced
polymers and multi-functional materials that exhibit high ductility have been
developed and widely used; for example, as infrastructural materials or in
medical devices (e.g., stents). The traditional small-strain approaches of
modeling these materials will not be adequate. In this paper, we study
degradation of materials due to an exposure to chemical species and temperature
under large-strain and large-deformations. In the first part of our research
work, we present a consistent mathematical model with firm thermodynamic
underpinning. We then obtain semi-analytical solutions of several canonical
problems to illustrate the nature of the quasi-static and unsteady behaviors of
degrading hyperelastic solids.
</dc:description>
 <dc:date>2015-11-14</dc:date>
 <dc:date>2016-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05538</dc:identifier>
 <dc:identifier>doi:10.1007/s00161-016-0511-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05539</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Wireless Powered Communication
  Networks</dc:title>
 <dc:creator>Wu, Qingqing</dc:creator>
 <dc:creator>Tao, Meixia</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Chen, Wen</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers a wireless powered communication network (WPCN), where
multiple users harvest energy from a dedicated power station and then
communicate with an information receiving station. Our goal is to investigate
the maximum achievable energy efficiency (EE) of the network via joint time
allocation and power control while taking into account the initial battery
energy of each user. We first study the EE maximization problem in the WPCN
without any system throughput requirement. We show that the EE maximization
problem for the WPCN can be cast into EE maximization problems for two
simplified networks via exploiting its special structure. For each problem, we
derive the optimal solution and provide the corresponding physical
interpretation, despite the non-convexity of the problems. Subsequently, we
study the EE maximization problem under a minimum system throughput constraint.
Exploiting fractional programming theory, we transform the resulting non-convex
problem into a standard convex optimization problem. This allows us to
characterize the optimal solution structure of joint time allocation and power
control and to derive an efficient iterative algorithm for obtaining the
optimal solution. Simulation results verify our theoretical findings and
demonstrate the effectiveness of the proposed joint time and power
optimization.
</dc:description>
 <dc:description>Comment: Transactions on Wireless Communications</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05546</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity and Approximability of Parameterized MAX-CSPs</dc:title>
 <dc:creator>Dell, Holger</dc:creator>
 <dc:creator>Kim, Eun Jung</dc:creator>
 <dc:creator>Lampis, Michael</dc:creator>
 <dc:creator>Mitsou, Valia</dc:creator>
 <dc:creator>M&#xf6;mke, Tobias</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the optimization version of constraint satisfaction problems
(Max-CSPs) in the framework of parameterized complexity; the goal is to compute
the maximum fraction of constraints that can be satisfied simultaneously. In
standard CSPs, we want to decide whether this fraction equals one. The
parameters we investigate are structural measures, such as the treewidth or the
clique-width of the variable-constraint incidence graph of the CSP instance.
  We consider Max-CSPs with the constraint types AND, OR, PARITY, and MAJORITY,
and with various parameters k, and we attempt to fully classify them into the
following three cases: 1. The exact optimum can be computed in FPT time. 2. It
is W[1]-hard to compute the exact optimum, but there is a randomized FPT
approximation scheme (FPTAS), which computes a $(1-\epsilon)$-approximation in
time $f(k,\epsilon)\cdot poly(n)$. 3. There is no FPTAS unless FPT=W[1].
  For the corresponding standard CSPs, we establish FPT vs. W[1]-hardness
results.
</dc:description>
 <dc:description>Comment: Appeared in IPEC 2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05546</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.IPEC.2015.294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05547</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Return of Frustratingly Easy Domain Adaptation</dc:title>
 <dc:creator>Sun, Baochen</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Unlike human learning, machine learning often fails to handle changes between
training (source) and test (target) input distributions. Such domain shifts,
common in practical scenarios, severely damage the performance of conventional
machine learning methods. Supervised domain adaptation methods have been
proposed for the case when the target data have labels, including some that
perform very well despite being &quot;frustratingly easy&quot; to implement. However, in
practice, the target domain is often unlabeled, requiring unsupervised
adaptation. We propose a simple, effective, and efficient method for
unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL
minimizes domain shift by aligning the second-order statistics of source and
target distributions, without requiring any target labels. Even though it is
extraordinarily simple--it can be implemented in four lines of Matlab
code--CORAL performs remarkably well in extensive evaluations on standard
benchmark datasets.
</dc:description>
 <dc:description>Comment: Fixed typos. Full paper to appear in AAAI-16. Extended Abstract of
  the full paper to appear in TASK-CV 2015 workshop</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05552</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Neural Networks Hardware Implementation on FPGA</dc:title>
 <dc:creator>Chang, Andre Xian Ming</dc:creator>
 <dc:creator>Martini, Berin</dc:creator>
 <dc:creator>Culurciello, Eugenio</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNNs) have the ability to retain memory and learn
data sequences. Due to the recurrent nature of RNNs, it is sometimes hard to
parallelize all its computations on conventional hardware. CPUs do not
currently offer large parallelism, while GPUs offer limited parallelism due to
sequential components of RNN models. In this paper we present a hardware
implementation of Long-Short Term Memory (LSTM) recurrent network on the
programmable logic Zynq 7020 FPGA from Xilinx. We implemented a RNN with $2$
layers and $128$ hidden units in hardware and it has been tested using a
character level language model. The implementation is more than $21\times$
faster than the ARM CPU embedded on the Zynq 7020 FPGA. This work can
potentially evolve to a RNN co-processor for future mobile devices.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures, changed format, added figures, added references,
  modified introduction</dc:description>
 <dc:date>2015-11-16</dc:date>
 <dc:date>2016-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05578</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second-Generation Curvelets on the Sphere</dc:title>
 <dc:creator>Chan, Jennifer Y. H.</dc:creator>
 <dc:creator>Leistedt, Boris</dc:creator>
 <dc:creator>Kitching, Thomas D.</dc:creator>
 <dc:creator>McEwen, Jason D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  Curvelets are efficient to represent highly anisotropic signal content, such
as a local linear and curvilinear structure. First-generation curvelets on the
sphere, however, suffered from blocking artefacts. We present a new
second-generation curvelet transform, where scale-discretised curvelets are
constructed directly on the sphere. Scale-discretised curvelets exhibit a
parabolic scaling relation, are well-localised in both spatial and harmonic
domains, support the exact analysis and synthesis of both scalar and spin
signals, and are free of blocking artefacts. We present fast algorithms to
compute the exact curvelet transform, reducing computational complexity from
$\mathcal{O}(L^5)$ to $\mathcal{O}(L^3\log_{2}{L})$ for signals band-limited at
$L$. The implementation of these algorithms is made publicly available.
Finally, we present an illustrative application demonstrating the effectiveness
of curvelets for representing directional curve-like features in natural
spherical images.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, Code available at
  http://astro-informatics.github.io/s2let/</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05578</dc:identifier>
 <dc:identifier>IEEE Trans. on Signal Processing. Vol. 65, No. 1, 2017, pp 5-14</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2600506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05583</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of Massive-MIMO-NOMA with Limited Feedback</dc:title>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this letter, a low-feedback non-orthogonal multiple access (NOMA) scheme
using massive multiple-input multiple-output (MIMO) transmission is proposed.
In particular, the proposed scheme can decompose a massive-MIMO-NOMA system
into multiple separated single-input single-output NOMA channels, and
analytical results are developed to evaluate the performance of the proposed
scheme for two scenarios, with perfect user ordering and with one-bit feedback,
respectively.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05583</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2543025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05585</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Driven Automatic Tiling with Cache Associativity Lattices</dc:title>
 <dc:creator>Adjiashvili, David</dc:creator>
 <dc:creator>Haus, Utz-Uwe</dc:creator>
 <dc:creator>Tate, Adrian</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>B.3.2</dc:subject>
 <dc:description>  Traditional compiler optimization theory distinguishes three separate classes
of cache miss -- Cold, Conflict and Capacity. Tiling for cache is typically
guided by capacity miss counts. Models of cache function have not been
effectively used to guide cache tiling optimizations due to model error and
expense. Instead, heuristic or empirical approaches are used to select tilings.
We argue that conflict misses, traditionally neglected or seen as a small
constant effect, are the only fundamentally important cache miss category, that
they form a solid basis by which caches can become modellable, and that models
leaning on cache associatvity analysis can be used to generate cache performant
tilings. We develop a mathematical framework that expresses potential and
actual cache misses in associative caches using Associativity Lattices. We show
these lattices to possess two theoretical advantages over rectangular tiles --
volume maximization and miss regularity. We also show that to generate such
lattice tiles requires, unlike rectangular tiling, no explicit, expensive
lattice point counting. We also describe an implementation of our lattice
tiling approach, show that it can be used to give speedups of over 10x versus
unoptimized code, and despite currently only tiling for one level of cache, can
already be competitive with the aggressive compiler optimizations used in
general purposes compares such as GCC and Intel's ICC. We also show that the
tiling approach can lead to reasonable automatic parallelism when compared to
existing auto-threading compilers.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05587</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum lifetime broadcasting problem in sensor networks</dc:title>
 <dc:creator>Lipi&#x144;ski, Zbigniew</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We solve the maximum lifetime problem for the point-to-point and
point-to-multipoint broadcast data transmission in one dimensional regular
sensor network. Based on the analytical solution of the problem for one
dimension we propose an algorithm solving the maximum lifetime broadcasting
problem for point-to-point data transmission for any dimension.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05587</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05607</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying the Absorption Bump with Deep Learning</dc:title>
 <dc:creator>Li, Min</dc:creator>
 <dc:creator>Gaddam, Sudeep</dc:creator>
 <dc:creator>Li, Xiaolin</dc:creator>
 <dc:creator>Zhao, Yinan</dc:creator>
 <dc:creator>Ma, Jingzhe</dc:creator>
 <dc:creator>Ge, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The pervasive interstellar dust grains provide significant insights to
understand the formation and evolution of the stars, planetary systems, and the
galaxies, and may harbor the building blocks of life. One of the most effective
way to analyze the dust is via their interaction with the light from background
sources. The observed extinction curves and spectral features carry the size
and composition information of dust. The broad absorption bump at 2175 Angstrom
is the most prominent feature in the extinction curves. Traditionally,
statistical methods are applied to detect the existence of the absorption bump.
These methods require heavy preprocessing and the co-existence of other
reference features to alleviate the influence from the noises. In this paper,
we apply Deep Learning techniques to detect the broad absorption bump. We
demonstrate the key steps for training the selected models and their results.
The success of Deep Learning based method inspires us to generalize a common
methodology for broader science discovery problems. We present our on-going
work to build the DeepDis system for such kind of applications.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05610</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounded Stability in Networked Systems with Parameter Mismatch and
  Adaptive Decentralized Estimation</dc:title>
 <dc:creator>Manaffam, Saeed</dc:creator>
 <dc:creator>Seyedi, Alireza</dc:creator>
 <dc:creator>Vosoughi, Azadeh</dc:creator>
 <dc:creator>Javidi, Tara</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Here, we study the ultimately bounded stability of network of mismatched
systems using Lyapunov direct method. The upper bound on the error of
oscillators from the center of the neighborhood is derived. Then the
performance of an adaptive compensation via decentralized control is analyzed.
Finally, the analytical results for a network of globally connected Lorenz
oscillators are verified.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, Accepted and presented in IEEE Conference
  Allerton 2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05612</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Block Regression Model for Short-Term Mobile Traffic Forecasting</dc:title>
 <dc:creator>Pan, Huimin</dc:creator>
 <dc:creator>Liu, Jingchu</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Accurate mobile traffic forecast is important for efficient network planning
and operations. However, existing traffic forecasting models have high
complexity, making the forecasting process slow and costly. In this paper, we
analyze some characteristics of mobile traffic such as periodicity, spatial
similarity and short term relativity. Based on these characteristics, we
propose a \emph{Block Regression} ({BR}) model for mobile traffic forecasting.
This model employs seasonal differentiation so as to take into account of the
temporally repetitive nature of mobile traffic. One of the key features of our
{BR} model lies in its low complexity since it constructs a single model for
all base stations. We evaluate the accuracy of {BR} model based on real traffic
data and compare it with the existing models. Results show that our {BR} model
offers equal accuracy to the existing models but has much less complexity.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures. IEEE/CIC ICCC'15</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05612</dc:identifier>
 <dc:identifier>doi:10.1109/ICCChina.2015.7448619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05616</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Structured Inference Neural Networks with Label Relations</dc:title>
 <dc:creator>Hu, Hexiang</dc:creator>
 <dc:creator>Zhou, Guang-Tong</dc:creator>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Liao, Zicheng</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Images of scenes have various objects as well as abundant attributes, and
diverse levels of visual categorization are possible. A natural image could be
assigned with fine-grained labels that describe major components,
coarse-grained labels that depict high level abstraction or a set of labels
that reveal attributes. Such categorization at different concept layers can be
modeled with label graphs encoding label information. In this paper, we exploit
this rich information with a state-of-art deep learning framework, and propose
a generic structured model that leverages diverse label relations to improve
image classification performance. Our approach employs a novel stacked label
prediction neural network, capturing both inter-level and intra-level label
semantics. We evaluate our method on benchmark image datasets, and empirical
results illustrate the efficacy of our model.
</dc:description>
 <dc:description>Comment: Conference on Computer Vision and Pattern Recognition(CVPR) 2016</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05618</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topic Model Based Behaviour Modeling and Clustering Analysis for
  Wireless Network Users</dc:title>
 <dc:creator>Leng, Bingjie</dc:creator>
 <dc:creator>Liu, Jingchu</dc:creator>
 <dc:creator>Pan, Huimin</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  User behaviour analysis based on traffic log in wireless networks can be
beneficial to many fields in real life: not only for commercial purposes, but
also for improving network service quality and social management. We cluster
users into groups marked by the most frequently visited websites to find their
preferences. In this paper, we propose a user behaviour model based on Topic
Model from document classification problems. We use the logarithmic TF-IDF
(term frequency - inverse document frequency) weighing to form a
high-dimensional sparse feature matrix. Then we apply LSA (Latent semantic
analysis) to deduce the latent topic distribution and generate a
low-dimensional dense feature matrix. K-means++, which is a classic clustering
algorithm, is then applied to the dense feature matrix and several
interpretable user clusters are found. Moreover, by combining the clustering
results with additional demographical information, including age, gender, and
financial information, we are able to uncover more realistic implications from
the clustering results.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures. APCC'15</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05619</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyclus Archetypes</dc:title>
 <dc:creator>Scopatz, Anthony M.</dc:creator>
 <dc:creator>Gidden, Matthew J.</dc:creator>
 <dc:creator>Carlsen, Robert W.</dc:creator>
 <dc:creator>Flanagan, Robert R.</dc:creator>
 <dc:creator>Huff, Kathryn D.</dc:creator>
 <dc:creator>McGarry, Meghan B.</dc:creator>
 <dc:creator>Opotowsky, Arrielle C.</dc:creator>
 <dc:creator>Rakhimov, Olzhas</dc:creator>
 <dc:creator>Welch, Zach</dc:creator>
 <dc:creator>Wilson, Paul P. H.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The current state of nuclear fuel cycle simulation exists in highly
customized form. Satisfying a wide range of users requires model modularity
within such a tool. Cyclus is a fuel cycle simulator specifically designed to
combat the lack of adaptability of previous generations of simulators. This is
accomplished through an agent-based infrastructure and treating time
discretely. The Cyclus kernel was developed to allow for models, called
archetypes, of differing fidelity and function depending on need of the users.
To take advantage of this flexibility, a user must write an archetype for their
desired simulation if it does not yet exist within the Cyclus ecosystem. At
this stage, a user graduates to the title of archetype developer.
  Without automation, archetype development is difficult for the uninitiated.
This paper presents the framework developed for simplifying the writing of
archetypes: the Cyclus preprocessor, or cycpp. cycpp addresses the computer
science and software development aspects of archetype development that can be
addressed algorithmically, allowing the developer to focus on modeling the
physics, social policies, and economics. cycpp passes through the code three
times to perform the following tasks: normalizing the code via the C
preprocessor, accumulation of notations, and code generation. Not only does
this reduce the amount of code a developer must write by approximately an order
of magnitude, but the archetypes are automatically validated.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05622</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting distributions with Linearizing Belief Networks</dc:title>
 <dc:creator>Dauphin, Yann N.</dc:creator>
 <dc:creator>Grangier, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conditional belief networks introduce stochastic binary variables in neural
networks. Contrary to a classical neural network, a belief network can predict
more than the expected value of the output $Y$ given the input $X$. It can
predict a distribution of outputs $Y$ which is useful when an input can admit
multiple outputs whose average is not necessarily a valid answer. Such networks
are particularly relevant to inverse problems such as image prediction for
denoising, or text to speech. However, traditional sigmoid belief networks are
hard to train and are not suited to continuous problems. This work introduces a
new family of networks called linearizing belief nets or LBNs. A LBN decomposes
into a deep linear network where each linear unit can be turned on or off by
non-deterministic binary latent units. It is a universal approximator of
real-valued conditional distributions and can be trained using gradient
descent. Moreover, the linear pathways efficiently propagate continuous
information and they act as multiplicative skip-connections that help
optimization by removing gradient diffusion. This yields a model which trains
efficiently and improves the state-of-the-art on image denoising and facial
expression generation with the Toronto faces dataset.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-05-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05625</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOEA/D-GM: Using probabilistic graphical models in MOEA/D for solving
  combinatorial optimization problems</dc:title>
 <dc:creator>de Souza, Murilo Zangari</dc:creator>
 <dc:creator>Santana, Roberto</dc:creator>
 <dc:creator>Pozo, Aurora Trinidad Ramirez</dc:creator>
 <dc:creator>Mendiburu, Alexander</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Evolutionary algorithms based on modeling the statistical dependencies
(interactions) between the variables have been proposed to solve a wide range
of complex problems. These algorithms learn and sample probabilistic graphical
models able to encode and exploit the regularities of the problem. This paper
investigates the effect of using probabilistic modeling techniques as a way to
enhance the behavior of MOEA/D framework. MOEA/D is a decomposition based
evolutionary algorithm that decomposes a multi-objective optimization problem
(MOP) in a number of scalar single-objective subproblems and optimizes them in
a collaborative manner. MOEA/D framework has been widely used to solve several
MOPs. The proposed algorithm, MOEA/D using probabilistic Graphical Models
(MOEA/D-GM) is able to instantiate both univariate and multi-variate
probabilistic models for each subproblem. To validate the introduced framework
algorithm, an experimental study is conducted on a multi-objective version of
the deceptive function Trap5. The results show that the variant of the
framework (MOEA/D-Tree), where tree models are learned from the matrices of the
mutual information between the variables, is able to capture the structure of
the problem. MOEA/D-Tree is able to achieve significantly better results than
both MOEA/D using genetic operators and MOEA/D using univariate probability
models, in terms of the approximation to the true Pareto front.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05635</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Multi-scale Convolution</dc:title>
 <dc:creator>Liao, Zhibin</dc:creator>
 <dc:creator>Carneiro, Gustavo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we introduce a new deep convolutional neural network (ConvNet)
module that promotes competition among a set of multi-scale convolutional
filters. This new module is inspired by the inception module, where we replace
the original collaborative pooling stage (consisting of a concatenation of the
multi-scale filter outputs) by a competitive pooling represented by a maxout
activation unit. This extension has the following two objectives: 1) the
selection of the maximum response among the multi-scale filters prevents filter
co-adaptation and allows the formation of multiple sub-networks within the same
model, which has been shown to facilitate the training of complex learning
problems; and 2) the maxout unit reduces the dimensionality of the outputs from
the multi-scale filters. We show that the use of our proposed module in typical
deep ConvNets produces classification results that are either better than or
comparable to the state of the art on the following benchmark datasets: MNIST,
CIFAR-10, CIFAR-100 and SVHN.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05641</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Net2Net: Accelerating Learning via Knowledge Transfer</dc:title>
 <dc:creator>Chen, Tianqi</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Shlens, Jonathon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce techniques for rapidly transferring the information stored in
one neural net into another neural net. The main purpose is to accelerate the
training of a significantly larger neural net. During real-world workflows, one
often trains very many different neural networks during the experimentation and
design process. This is a wasteful process in which each new model is trained
from scratch. Our Net2Net technique accelerates the experimentation process by
instantaneously transferring the knowledge from a previous network to each new
deeper or wider network. Our techniques are based on the concept of
function-preserving transformations between neural network specifications. This
differs from previous approaches to pre-training that altered the function
represented by a neural net when adding layers to it. Using our knowledge
transfer mechanism to add depth to Inception modules, we demonstrate a new
state of the art accuracy rating on the ImageNet dataset.
</dc:description>
 <dc:description>Comment: ICLR 2016 submission</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05643</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Smooth Approximation to the Zero One Loss with a Probabilistic
  Interpretation</dc:title>
 <dc:creator>Hasan, Md Kamrul</dc:creator>
 <dc:creator>Pal, Christopher J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We examine a new form of smooth approximation to the zero one loss in which
learning is performed using a reformulation of the widely used logistic
function. Our approach is based on using the posterior mean of a novel
generalized Beta-Bernoulli formulation. This leads to a generalized logistic
function that approximates the zero one loss, but retains a probabilistic
formulation conferring a number of useful properties. The approach is easily
generalized to kernel logistic regression and easily integrated into methods
for structured prediction. We present experiments in which we learn such models
using an optimization method consisting of a combination of gradient descent
and coordinate descent using localized grid search so as to escape from local
minima. Our experiments indicate that optimization quality is improved when
learning meta-parameters are themselves optimized using a validation set. Our
experiments show improved performance relative to widely used logistic and
hinge loss methods on a wide variety of problems ranging from standard UC
Irvine and libSVM evaluation datasets to product review predictions and a
visual information extraction task. We observe that the approach: 1) is more
robust to outliers compared to the logistic and hinge losses; 2) outperforms
comparable logistic and max margin models on larger scale benchmark problems;
3) when combined with Gaussian- Laplacian mixture prior on parameters the
kernelized version of our formulation yields sparser solutions than Support
Vector Machine classifiers; and 4) when integrated into a probabilistic
structured prediction technique our approach provides more accurate
probabilities yielding improved inference and increasing information extraction
performance.
</dc:description>
 <dc:description>Comment: 32 pages, 7 figures, 15 tables</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05644</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Autoencoders</dc:title>
 <dc:creator>Makhzani, Alireza</dc:creator>
 <dc:creator>Shlens, Jonathon</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Frey, Brendan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose the &quot;adversarial autoencoder&quot; (AAE), which is a
probabilistic autoencoder that uses the recently proposed generative
adversarial networks (GAN) to perform variational inference by matching the
aggregated posterior of the hidden code vector of the autoencoder with an
arbitrary prior distribution. Matching the aggregated posterior to the prior
ensures that generating from any part of prior space results in meaningful
samples. As a result, the decoder of the adversarial autoencoder learns a deep
generative model that maps the imposed prior to the data distribution. We show
how the adversarial autoencoder can be used in applications such as
semi-supervised classification, disentangling style and content of images,
unsupervised clustering, dimensionality reduction and data visualization. We
performed experiments on MNIST, Street View House Numbers and Toronto Face
datasets and show that adversarial autoencoders achieve competitive results in
generative modeling and semi-supervised classification tasks.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05646</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Invisible Hand of Dynamic Market Pricing</dc:title>
 <dc:creator>Cohen-Addad, Vincent</dc:creator>
 <dc:creator>Eden, Alon</dc:creator>
 <dc:creator>Feldman, Michal</dc:creator>
 <dc:creator>Fiat, Amos</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Walrasian prices, if they exist, have the property that one can assign every
buyer some bundle in her demand set, such that the resulting assignment will
maximize social welfare. Unfortunately, this assumes carefully breaking ties
amongst different bundles in the buyer demand set. Presumably, the shopkeeper
cleverly convinces the buyer to break ties in a manner consistent with
maximizing social welfare. Lacking such a shopkeeper, if buyers arrive
sequentially and simply choose some arbitrary bundle in their demand set, the
social welfare may be arbitrarily bad. In the context of matching markets, we
show how to compute dynamic prices, based upon the current inventory, that
guarantee that social welfare is maximized. Such prices are set without knowing
the identity of the next buyer to arrive. We also show that this is impossible
in general (e.g., for coverage valuations), but consider other scenarios where
this can be done.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05650</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models</dc:title>
 <dc:creator>Lee, Juho</dc:creator>
 <dc:creator>Choi, Seungjin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Normalized random measures (NRMs) provide a broad class of discrete random
measures that are often used as priors for Bayesian nonparametric models.
Dirichlet process is a well-known example of NRMs. Most of posterior inference
methods for NRM mixture models rely on MCMC methods since they are easy to
implement and their convergence is well studied. However, MCMC often suffers
from slow convergence when the acceptance rate is low. Tree-based inference is
an alternative deterministic posterior inference method, where Bayesian
hierarchical clustering (BHC) or incremental Bayesian hierarchical clustering
(IBHC) have been developed for DP or NRM mixture (NRMM) models, respectively.
Although IBHC is a promising method for posterior inference for NRMM models due
to its efficiency and applicability to online inference, its convergence is not
guaranteed since it uses heuristics that simply selects the best solution after
multiple trials are made. In this paper, we present a hybrid inference
algorithm for NRMM models, which combines the merits of both MCMC and IBHC.
Trees built by IBHC outlines partitions of data, which guides
Metropolis-Hastings procedure to employ appropriate proposals. Inheriting the
nature of MCMC, our tree-guided MCMC (tgMCMC) is guaranteed to converge, and
enjoys the fast convergence thanks to the effective proposals guided by trees.
Experiments on both synthetic and real-world datasets demonstrate the benefit
of our method.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, NIPS-2015</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05650</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05653</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why are deep nets reversible: A simple theory, with implications for
  training</dc:title>
 <dc:creator>Arora, Sanjeev</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative models for deep learning are promising both to improve
understanding of the model, and yield training methods requiring fewer labeled
samples.
  Recent works use generative model approaches to produce the deep net's input
given the value of a hidden layer several levels above. However, there is no
accompanying &quot;proof of correctness&quot; for the generative model, showing that the
feedforward deep net is the correct inference method for recovering the hidden
layer given the input. Furthermore, these models are complicated.
  The current paper takes a more theoretical tack. It presents a very simple
generative model for RELU deep nets, with the following characteristics: (i)
The generative model is just the reverse of the feedforward net: if the forward
transformation at a layer is $A$ then the reverse transformation is $A^T$.
(This can be seen as an explanation of the old weight tying idea for denoising
autoencoders.) (ii) Its correctness can be proven under a clean theoretical
assumption: the edge weights in real-life deep nets behave like random numbers.
Under this assumption ---which is experimentally tested on real-life nets like
AlexNet--- it is formally proved that feed forward net is a correct inference
method for recovering the hidden layer.
  The generative model suggests a simple modification for training: use the
generative model to produce synthetic data with labels and include it in the
training set. Experiments are shown to support this theory of random-like deep
nets; and that it helps the training.
</dc:description>
 <dc:date>2015-11-17</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05659</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Discriminative Representations for Semantic Cross Media
  Retrieval</dc:title>
 <dc:creator>Jiang, Aiwen</dc:creator>
 <dc:creator>Li, Hanxi</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:creator>Wang, Mingwen</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Heterogeneous gap among different modalities emerges as one of the critical
issues in modern AI problems. Unlike traditional uni-modal cases, where raw
features are extracted and directly measured, the heterogeneous nature of cross
modal tasks requires the intrinsic semantic representation to be compared in a
unified framework. This paper studies the learning of different representations
that can be retrieved across different modality contents. A novel approach for
mining cross-modal representations is proposed by incorporating explicit linear
semantic projecting in Hilbert space. The insight is that the discriminative
structures of different modality data can be linearly represented in
appropriate high dimension Hilbert spaces, where linear operations can be used
to approximate nonlinear decisions in the original spaces. As a result, an
efficient linear semantic down mapping is jointly learned for multimodal data,
leading to a common space where they can be compared. The mechanism of &quot;feature
up-lifting and down-projecting&quot; works seamlessly as a whole, which accomplishes
crossmodal retrieval tasks very well. The proposed method, named as shared
discriminative semantic representation learning (\textbf{SDSRL}), is tested on
two public multimodal dataset for both within- and inter- modal retrieval. The
experiments demonstrate that it outperforms several state-of-the-art methods in
most scenarios.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05660</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian hypothesis testing for one bit compressed sensing with sensing
  matrix perturbation</dc:title>
 <dc:creator>Zayyani, H.</dc:creator>
 <dc:creator>Korki, M.</dc:creator>
 <dc:creator>Marvasti, F.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter proposes a low-computational Bayesian algorithm for noisy sparse
recovery in the context of one bit compressed sensing with sensing matrix
perturbation. The proposed algorithm which is called BHT-MLE comprises a sparse
support detector and an amplitude estimator. The support detector utilizes
Bayesian hypothesis test, while the amplitude estimator uses an ML estimator
which is obtained by solving a convex optimization problem. Simulation results
show that BHT-MLE algorithm offers more reconstruction accuracy than that of an
ML estimator (MLE) at a low computational cost.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05662</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Underlying Plans Based on Distributed Representations of
  Actions</dc:title>
 <dc:creator>Tian, Xin</dc:creator>
 <dc:creator>Zhuo, Hankz Hankui</dc:creator>
 <dc:creator>Kambhampati, Subbarao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Plan recognition aims to discover target plans (i.e., sequences of actions)
behind observed actions, with history plan libraries or domain models in hand.
Previous approaches either discover plans by maximally &quot;matching&quot; observed
actions to plan libraries, assuming target plans are from plan libraries, or
infer plans by executing domain models to best explain the observed actions,
assuming complete domain models are available. In real world applications,
however, target plans are often not from plan libraries and complete domain
models are often not available, since building complete sets of plans and
complete domain models are often difficult or expensive. In this paper we view
plan libraries as corpora and learn vector representations of actions using the
corpora; we then discover target plans based on the vector representations. Our
approach is capable of discovering underlying plans that are not from plan
libraries, without requiring domain models provided. We empirically demonstrate
the effectiveness of our approach by comparing its performance to traditional
plan recognition approaches in three planning domains.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05666</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolution with Deep Convolutional Sufficient Statistics</dc:title>
 <dc:creator>Bruna, Joan</dc:creator>
 <dc:creator>Sprechmann, Pablo</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inverse problems in image and audio, and super-resolution in particular, can
be seen as high-dimensional structured prediction problems, where the goal is
to characterize the conditional distribution of a high-resolution output given
its low-resolution corrupted observation. When the scaling ratio is small,
point estimates achieve impressive performance, but soon they suffer from the
regression-to-the-mean problem, result of their inability to capture the
multi-modality of this conditional distribution. Modeling high-dimensional
image and audio distributions is a hard task, requiring both the ability to
model complex geometrical structures and textured regions. In this paper, we
propose to use as conditional model a Gibbs distribution, where its sufficient
statistics are given by deep convolutional neural networks. The features
computed by the network are stable to local deformation, and have reduced
variance when the input is a stationary texture. These properties imply that
the resulting sufficient statistics minimize the uncertainty of the target
signals given the degraded observations, while being highly informative. The
filters of the CNN are initialized by multiscale complex wavelets, and then we
propose an algorithm to fine-tune them by estimating the gradient of the
conditional log-likelihood, which bears some similarities with Generative
Adversarial Networks. We evaluate experimentally the proposed approach in the
image super-resolution task, but the approach is general and could be used in
other challenging ill-posed problems such as audio bandwidth extension.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05667</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perancangan teknologi cloud untuk penjualan online kain songket
  Palembang</dc:title>
 <dc:creator>Fikri</dc:creator>
 <dc:creator>Abdillah, Leon Andretti</dc:creator>
 <dc:creator>Apriyani, Ema</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Cloud Computing is a paradigm in which information is permanently stored in
servers on the Internet and temporarily stored on the user's computer (client)
including the desktop. This study aims to design an online sales application
based cloud computing technology to help the artisans Palembang songket and do
not rule out the possibility for other small medium enterprises (SMEs) to
manage assets and market their products online so it can be accessed anytime
and anywhere via personal computer, laptop, tabblet, mobile phone or
smartphone. Cloud infrastructure used in this study is a Software-as-a-service
(SaaS) that enables cloud users to exploit online sales application without
having to install on your local computer, set up a dedicated server, operator
labor, maintenance costs and other support resources that can make savings in
terms of cost.
</dc:description>
 <dc:description>Comment: 6 pages in Seminar Nasional Sistem Informasi Indonesia ke-8
  (SESINDO2015), Institut Teknologi Sepuluh Nopember (ITS), Surabaya, 2015</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05671</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sigma Delta quantization with Harmonic frames and partial Fourier
  ensembles</dc:title>
 <dc:creator>Wang, Rongrong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sigma Delta quantization, a quantization method which first surfaced in the
1960s, has now been used widely in various digital products such as cameras,
cell phones, radars, etc. The method samples an input signal at a rate higher
than the Nyquist rate, thus achieves great robustness to quantization noise.
Compressed Sensing (CS) is a frugal acquisition method that utilizes the
possible sparsity of the signals to reduce the required number of samples for a
lossless acquisition. One can deem the reduced number as an effective
dimensionality of the set of sparse signals and accordingly, define an
effective oversampling rate as the ratio between the actual sampling rate and
the effective dimensionality. A natural conjecture is that the error of Sigma
Delta quantization, previously shown to decay with the vanilla oversampling
rate, should now decay with the effective oversampling rate when carried out in
the regime of compressed sensing. Confirming this intuition is one of the main
goals in this direction.
  The study of quantization in CS has so far been limited to proving error
convergence results for Gaussian and sub-Gaussian sensing matrices, as the
number of bits and/or the number of samples grow to infinity. In this paper, we
provide a first result for the more realistic Fourier sensing matrices. The
major idea is to randomly permute the Fourier samples before feeding them into
the quantizer. We show that the random permutation can effectively increase the
low frequency power of the measurements, thus enhance the quality of
$\Sigma\Delta$ quantization.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05671</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05672</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Could We Distinguish Child Users from Adults Using Keystroke Dynamics?</dc:title>
 <dc:creator>Uzun, Yasin</dc:creator>
 <dc:creator>Bicakci, Kemal</dc:creator>
 <dc:creator>Uzunay, Yusuf</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Significant portion of contemporary computer users are children, who are
vulnerable to threats coming from the Internet. To protect children from such
threats, in this study, we investigate how successfully typing data can be used
to distinguish children from adults. For this purpose, we collect a dataset
comprising keystroke data of 100 users and show that distinguishing child
Internet users from adults is possible using Keystroke Dynamics with equal
error rates less than 10 percent. However the error rates increase
significantly when there are impostors in the system.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05676</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional Memory for Visual Question Answering</dc:title>
 <dc:creator>Jiang, Aiwen</dc:creator>
 <dc:creator>Wang, Fang</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:creator>Li, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual Question Answering (VQA) emerges as one of the most fascinating topics
in computer vision recently. Many state of the art methods naively use holistic
visual features with language features into a Long Short-Term Memory (LSTM)
module, neglecting the sophisticated interaction between them. This coarse
modeling also blocks the possibilities of exploring finer-grained local
features that contribute to the question answering dynamically over time.
  This paper addresses this fundamental problem by directly modeling the
temporal dynamics between language and all possible local image patches. When
traversing the question words sequentially, our end-to-end approach explicitly
fuses the features associated to the words and the ones available at multiple
local patches in an attention mechanism, and further combines the fused
information to generate dynamic messages, which we call episode. We then feed
the episodes to a standard question answering module together with the
contextual visual information and linguistic information. Motivated by recent
practices in deep learning, we use auxiliary loss functions during training to
improve the performance. Our experiments on two latest public datasets suggest
that our method has a superior performance. Notably, on the DARQUAR dataset we
advanced the state of the art by 6$\%$, and we also evaluated our approach on
the most recent MSCOCO-VQA dataset.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05677</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demand Response with Communicating Rational Consumers</dc:title>
 <dc:creator>Eksin, Ceyhun</dc:creator>
 <dc:creator>Delic, Hakan</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The performance of an energy system under a real-time pricing mechanism
depends on the consumption behavior of its customers, which involves
uncertainties. In this paper, we consider a system operator that charges its
customers with a real-time price that depends on the total realized
consumption. Customers have unknown and heterogeneous consumption preferences.
We propose behavior models in which customers act selfishly, altruistically or
as welfare-maximizers. In addition, we consider information models where
customers keep their consumption levels private, communicate with a neighboring
set of customers, or receive broadcasted demand from the operator. Our analysis
focuses on the dispersion of the system performance under different consumption
models. To this end, for each pair of behavior and information model we define
and characterize optimal rational behavior, and provide a local algorithm that
can be implemented by the consumption scheduler devices. Analytical comparisons
of the two extreme information models, namely, private and complete information
models, show that communication model reduces demand uncertainty while having
negligible effect on aggregate consumer utility and welfare. In addition, we
show the impact of real-time price policy parameters have on the expected
welfare loss due to selfish behavior affording critical policy insights.
</dc:description>
 <dc:description>Comment: A revised version is to appear on IEEE Trans. on Smart Grid</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05677</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2016.2613993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05678</identifier>
 <datestamp>2016-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Expressiveness of Rectifier Networks</dc:title>
 <dc:creator>Pan, Xingyuan</dc:creator>
 <dc:creator>Srikumar, Vivek</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Rectified Linear Units (ReLUs) have been shown to ameliorate the vanishing
gradient problem, allow for efficient backpropagation, and empirically promote
sparsity in the learned parameters. They have led to state-of-the-art results
in a variety of applications. However, unlike threshold and sigmoid networks,
ReLU networks are less explored from the perspective of their expressiveness.
This paper studies the expressiveness of ReLU networks. We characterize the
decision boundary of two-layer ReLU networks by constructing functionally
equivalent threshold networks. We show that while the decision boundary of a
two-layer ReLU network can be captured by a threshold network, the latter may
require an exponentially larger number of hidden units. We also formulate
sufficient conditions for a corresponding logarithmic reduction in the number
of hidden units to represent a sign network as a ReLU network. Finally, we
experimentally compare threshold networks and their much smaller ReLU
counterparts with respect to their ability to learn from synthetically
generated data.
</dc:description>
 <dc:description>Comment: Published in ICML 2016. Supplementary material included</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05680</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wishart Mechanism for Differentially Private Principal Components
  Analysis</dc:title>
 <dc:creator>Jiang, Wuxuan</dc:creator>
 <dc:creator>Xie, Cong</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new input perturbation mechanism for publishing a covariance
matrix to achieve $(\epsilon,0)$-differential privacy. Our mechanism uses a
Wishart distribution to generate matrix noise. In particular, We apply this
mechanism to principal component analysis. Our mechanism is able to keep the
positive semi-definiteness of the published covariance matrix. Thus, our
approach gives rise to a general publishing framework for input perturbation of
a symmetric positive semidefinite matrix. Moreover, compared with the classic
Laplace mechanism, our method has better utility guarantee. To the best of our
knowledge, Wishart mechanism is the best input perturbation approach for
$(\epsilon,0)$-differentially private PCA. We also compare our work with
previous exponential mechanism algorithms in the literature and provide near
optimal bound while having more flexibility and less computational
intractability.
</dc:description>
 <dc:description>Comment: A full version with technical proofs. Accepted to AAAI-16</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05682</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trust-in-the-Middle: Towards Establishing Trustworthiness of
  Authentication Proxies using Trusted Computing</dc:title>
 <dc:creator>Uzunay, Yusuf</dc:creator>
 <dc:creator>Bicakci, Kemal</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Authentication proxies, which store users' secret credentials and submit them
to servers on their behalf, offer benefits with respect to security of the
authentication and usability of credential management. However, as being a
service that is not in control of users, one important problem they suffer is
the trust problem; how users trust that their secrets are handled securely in
the proxy and not revealed to third parties. In this paper, we present a
solution called Trust-in-the-Middle, a TPM based proxy system which ensures
that user credentials are securely stored and submitted without disclosing them
even if the proxy is compromised. We build our architecture on a trust chain
bootstrapped by TPM DRTM and prevent access to credentials if any entity in the
chain is maliciously modified. We use remote attestation to guarantee that all
critical operations on the proxy are performed securely and credentials are
cryptographically protected when they are not in DRTM-supported isolation.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05683</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transceiver Design to Maximize Sum Secrecy Rate in Full Duplex SWIPT
  Systems</dc:title>
 <dc:creator>Wang, Ying</dc:creator>
 <dc:creator>Sun, Ruijin</dc:creator>
 <dc:creator>Wang, Xinshui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter considers secrecy simultaneous wireless information and power
transfer (SWIPT) in full duplex systems. In such a system, full duplex capable
base station (FD-BS) is designed to transmit data to one downlink user and
concurrently receive data from one uplink user, while one idle user harvests
the radio-frequency (RF) signals energy to extend its lifetime. Moreover, to
prevent eavesdropping, artificial noise (AN) is exploited by FD-BS to degrade
the channel of the idle user, as well as to provide energy supply to the idle
user. To maximize the sum of downlink secrecy rate and uplink secrecy rate, we
jointly optimize the information covariance matrix, AN covariance matrix and
receiver vector, under the constraints of the sum transmission power of FD-BS
and the minimum harvested energy of the idle user. Since the problem is
non-convex, the log-exponential reformulation and sequential parametric convex
approximation (SPCA) method are used. Extensive simulation results are provided
and demonstrate that our proposed full duplex scheme extremely outperforms the
half duplex scheme.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05683</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2553171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05688</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distribution Adaptive Framework for Prediction Interval Estimation
  Using Nominal Variables</dc:title>
 <dc:creator>Eetemadi, Ameen</dc:creator>
 <dc:creator>Tagkopoulos, Ilias</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Proposed methods for prediction interval estimation so far focus on cases
where input variables are numerical. In datasets with solely nominal input
variables, we observe records with the exact same input $x^u$, but different
real valued outputs due to the inherent noise in the system. Existing
prediction interval estimation methods do not use representations that can
accurately model such inherent noise in the case of nominal inputs. We propose
a new prediction interval estimation method tailored for this type of data,
which is prevalent in biology and medicine. We call this method Distribution
Adaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and has
four main phases. First, we select a distribution function that can best
represent the inherent noise of the system for all unique inputs. Then we infer
the parameters $\theta_i$ (e.g. $\theta_i=[mean_i, variance_i]$) of the
selected distribution function for all unique input vectors $x^u_i$ and
generate a new corresponding training set using pairs of $x^u_i, \theta_i$.
III). Then, we train a model to predict $\theta$ given a new $x_u$. Finally, we
calculate the prediction interval for a new sample using the inverse of the
cumulative distribution function once the parameters $\theta$ is predicted by
the trained model. We compared DAPIEN to the commonly used Bootstrap method on
three synthetic datasets. Our results show that DAPIEN provides tighter
prediction intervals while preserving the requested coverage when compared to
Bootstrap. This work can facilitate broader usage of regression methods in
medicine and biology where it is necessary to provide tight prediction
intervals while preserving coverage when input variables are nominal.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05690</identifier>
 <datestamp>2016-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Computation on Semirings Isomorphic to $(\times, \max)$ on
  $\mathbb{R}_+$</dc:title>
 <dc:creator>Serang, Oliver</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Important problems across multiple disciplines involve computations on the
semiring $(\times, \max)$ (or its equivalents, the negated version $(\times,
\min)$), the log-transformed version $(+, \max)$, or the negated
log-transformed version $(+, \min)$): max-convolution, all-pairs shortest paths
in a weighted graph, and finding the largest $k$ values in $x_i+y_j$ for two
lists $x$ and $y$. However, fast algorithms such as those enabling FFT
convolution, sub-cubic matrix multiplication, \emph{etc.}, require inverse
operations, and thus cannot be computed on semirings. This manuscript
generalizes recent advances on max-convolution: in this approach a small family
of $p$-norm rings are used to efficiently approximate results on a nonnegative
semiring. The general approach can be used to easily compute sub-cubic
estimates of the all-pairs shortest paths in a graph with nonnegative edge
weights and sub-quadratic estimates of the top $k$ values in $x_i+y_j$ when $x$
and $y$ are nonnegative. These methods are fast in practice and can benefit
from coarse-grained parallelization.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05706</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Output Kernel Learning for Multiple Tasks</dc:title>
 <dc:creator>Jawanpuria, Pratik</dc:creator>
 <dc:creator>Lapin, Maksim</dc:creator>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paradigm of multi-task learning is that one can achieve better
generalization by learning tasks jointly and thus exploiting the similarity
between the tasks rather than learning them independently of each other. While
previously the relationship between tasks had to be user-defined in the form of
an output kernel, recent approaches jointly learn the tasks and the output
kernel. As the output kernel is a positive semidefinite matrix, the resulting
optimization problems are not scalable in the number of tasks as an
eigendecomposition is required in each step. \mbox{Using} the theory of
positive semidefinite kernels we show in this paper that for a certain class of
regularizers on the output kernel, the constraint of being positive
semidefinite can be dropped as it is automatically satisfied for the relaxed
problem. This leads to an unconstrained dual problem which can be solved
efficiently. Experiments on several multi-task and multi-class data sets
illustrate the efficacy of our approach in terms of computational efficiency as
well as generalization performance.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05709</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Author Evaluation Based on H-index and Citation Response</dc:title>
 <dc:creator>Kud&#x11b;lka, Milo&#x161;</dc:creator>
 <dc:creator>Plato&#x161;, Jan</dc:creator>
 <dc:creator>Kr&#xf6;mer, Pavel</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  An accurate and fair assessment of the efficiency and impact of scientific
work is, despite a lot of recent research effort, still an open problem. The
measurement of quality and success of individual scientists and research groups
can be approached from many different directions, none of which is universal. A
reason for this is inherently different behavior of different scientists within
the global research community. A complex evaluation of ones publication
activities requires a careful consideration of a wide variety of factors. The
well-known H-index is one of the most used bibliometric indices. Despite its
many imperfections, its simplicity and ease of interpretation make it a popular
scientometric method. This short paper uses the ideas behind the H-index ~to
analyze communities of authors who cite publishing scientists. A new author
evaluation measure named aH-index is proposed, and intuitive interpretations of
its properties and semantics are presented. Preliminary experiments with
authors with high H-index active in the area of computer science are presented
to demonstrate the properties of the proposed measure.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05710</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex-Valued Gaussian Processes for Regression: A Widely Non-Linear
  Approach</dc:title>
 <dc:creator>Boloix-Tortosa, Rafael</dc:creator>
 <dc:creator>Arias-de-Reyna, Eva</dc:creator>
 <dc:creator>Payan-Somet, F. Javier</dc:creator>
 <dc:creator>Murillo-Fuentes, Juan J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we propose a novel Bayesian kernel based solution for
regression in complex fields. We develop the formulation of the Gaussian
process for regression (GPR) to deal with complex-valued outputs. Previous
solutions for kernels methods usually assume a complexification approach, where
the real-valued kernel is replaced by a complex-valued one. However, based on
the results in complex-valued linear theory, we prove that both a kernel and a
pseudo-kernel are to be included in the solution. This is the starting point to
develop the new formulation for the complex-valued GPR. The obtained
formulation resembles the one of the widely linear minimum mean-squared
(WLMMSE) approach. Just in the particular case where the outputs are proper,
the pseudo-kernel cancels and the solution simplifies to a real-valued GPR
structure, as the WLMMSE does into a strictly linear solution. We include some
numerical experiments to show that the novel solution, denoted as widely
non-linear complex GPR (WCGPR), outperforms a strictly complex GPR where a
pseudo-kernel is not included.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05719</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Abduction in Markov Logic Networks for Root Cause Analysis</dc:title>
 <dc:creator>Schoenfisch, Joerg</dc:creator>
 <dc:creator>von Stulpnagel, Janno</dc:creator>
 <dc:creator>Ortmann, Jens</dc:creator>
 <dc:creator>Meilicke, Christian</dc:creator>
 <dc:creator>Stuckenschmidt, Heiner</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  IT infrastructure is a crucial part in most of today's business operations.
High availability and reliability, and short response times to outages are
essential. Thus a high amount of tool support and automation in risk management
is desirable to decrease outages. We propose a new approach for calculating the
root cause for an observed failure in an IT infrastructure. Our approach is
based on Abduction in Markov Logic Networks. Abduction aims to find an
explanation for a given observation in the light of some background knowledge.
In failure diagnosis, the explanation corresponds to the root cause, the
observation to the failure of a component, and the background knowledge to the
dependency graph extended by potential risks. We apply a method to extend a
Markov Logic Network in order to conduct abductive reasoning, which is not
naturally supported in this formalism. Our approach exhibits a high amount of
reusability and enables users without specific knowledge of a concrete
infrastructure to gain viable insights in the case of an incident. We
implemented the method in a tool and illustrate its suitability for root cause
analysis by applying it to a sample scenario.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05720</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online learning in repeated auctions</dc:title>
 <dc:creator>Weed, Jonathan</dc:creator>
 <dc:creator>Perchet, Vianney</dc:creator>
 <dc:creator>Rigollet, Philippe</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Primary 62L05, secondary 62C20</dc:subject>
 <dc:description>  Motivated by online advertising auctions, we consider repeated Vickrey
auctions where goods of unknown value are sold sequentially and bidders only
learn (potentially noisy) information about a good's value once it is
purchased. We adopt an online learning approach with bandit feedback to model
this problem and derive bidding strategies for two models: stochastic and
adversarial. In the stochastic model, the observed values of the goods are
random variables centered around the true value of the good. In this case,
logarithmic regret is achievable when competing against well behaved
adversaries. In the adversarial model, the goods need not be identical and we
simply compare our performance against that of the best fixed bid in hindsight.
We show that sublinear regret is also achievable in this case and prove
matching minimax lower bounds. To our knowledge, this is the first complete set
of strategies for bidders participating in auctions of this type.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05732</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating the Degree Centrality Ranking of a Node</dc:title>
 <dc:creator>Saxena, Akrati</dc:creator>
 <dc:creator>Malik, Vaibhav</dc:creator>
 <dc:creator>Iyengar, S. R. S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Complex networks have gained more attention from the last few years. The size
of the real world complex networks, such as online social networks, WWW
networks, collaboration networks, is exponentially increasing with time. It is
not feasible to completely collect, store and process these networks. In the
present work, we propose a method to estimate the degree centrality ranking of
a node without having complete structure of the graph. The proposed algorithm
uses degree of a node and power law exponent of the degree distribution to
calculate the ranking. We also study simulation results on Barabasi-Albert
model. Simulation results show that the average error in the estimated ranking
is approximately $5\%$ of the total number of nodes.
</dc:description>
 <dc:description>Comment: Submitted in Complenet 2016 conference</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05737</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing for Collaborative Sensemaking: Leveraging Human Cognition For
  Complex Tasks</dc:title>
 <dc:creator>Goyal, Nitesh</dc:creator>
 <dc:creator>Fussell, Susan R.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  My research aims to design systems for complex sensemaking by remotely
located non-expert collaborators (crowds), to solve computationally hard
problems like crimes.
</dc:description>
 <dc:description>Comment: Conference. Companion of 15th IFIP TC 13 Human-Computer Interaction
  INTERACT 2015</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05740</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Modern Banking Ledgers through Blockchain Technologies:
  Future of Transaction Processing and Smart Contracts on the Internet of Money</dc:title>
 <dc:creator>Peters, Gareth William</dc:creator>
 <dc:creator>Panayi, Efstathios</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this chapter we provide an overview of the concept of blockchain
technology and its potential to disrupt the world of banking through
facilitating global money remittance, smart contracts, automated banking
ledgers and digital assets. In this regard, we first provide a brief overview
of the core aspects of this technology, as well as the second-generation
contract-based developments. From there we discuss key issues that must be
considered in developing such ledger based technologies in a banking context.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05743</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse learning of maximum likelihood model for optimization of complex
  loss function</dc:title>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Chandrasekar, Prathamesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Traditional machine learning methods usually minimize a simple loss function
to learn a predictive model, and then use a complex performance measure to
measure the prediction performance. However, minimizing a simple loss function
cannot guarantee that an optimal performance. In this paper, we study the
problem of optimizing the complex performance measure directly to obtain a
predictive model. We proposed to construct a maximum likelihood model for this
problem, and to learn the model parameter, we minimize a com- plex loss
function corresponding to the desired complex performance measure. To optimize
the loss function, we approximate the upper bound of the complex loss. We also
propose impose the sparsity to the model parameter to obtain a sparse model. An
objective is constructed by combining the upper bound of the loss function and
the sparsity of the model parameter, and we develop an iterative algorithm to
minimize it by using the fast iterative shrinkage- thresholding algorithm
framework. The experiments on optimization on three different complex
performance measures, including F-score, receiver operating characteristic
curve, and recall precision curve break even point, over three real-world
applications, aircraft event recognition of civil aviation safety, in- trusion
detection in wireless mesh networks, and image classification, show the
advantages of the proposed method over state-of-the-art methods.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05747</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HistComp : bibliographic analysis and visualization of 'The Biological
  Bulletin'</dc:title>
 <dc:creator>Wulff, Enrique</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  A collection of citation data, the HistComp, is available from the Internet
as a database of examples of real life citation networks. The purposes of this
approach is the analysis of these citation networks on learned literature by
presenting its typical steps and results. We have selected the bibliographic
insights into the &quot;The Biological Bulletin&quot;, the journal published since 1897
by the Woods Hole Marine Biological Laboratory. Since the bibliographic
networks tend to be very scattered, their visualization requires of criteria of
convergence. To simplify, the main features in such a structure should include
the survey for authoritative sources in the hyperlinked environment and the
identification of thematic areas. By avoiding excessive loose connections and
too dense clustered layouts to be useful, a smooth presentation is obtained by
graphically depicting the citation patterns. HistComp computes 8884 articles
published by 'The Biological Bulletin' between 1945-2003. A two-dimensional
positioning of these papers that represent the extent of their bibliographic
coupling and co-citation is offered as a histograph. The criteria to construct
it is the adequateness of the visualization relative to the 8884 data set. The
spatial representation obtained optimizes the identification of the clusters or
topic areas. The thematic importance of marine science involves its
participation in 7 of the 7 presenting clusters. The mainstream subjects were
crustaceans and echinoderms, with some 60% of the material presented in the
graph. But sea anemone, with about 16% of the total, remains as the best
visualized topical area. A perspective of the highly relevant papers is readily
confirmed by the visual inspection of width of the glyphs used for nodes
representation. For user interaction, HistComp employs mouse-over labels.
</dc:description>
 <dc:description>Comment: 32nd IAMSLIC Annual Conference: Every continent, every ocean., Oct
  2006, Portland, Oregon, United States</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05749</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solution Repair/Recovery in Uncertain Optimization Environment</dc:title>
 <dc:creator>Khaled, Oumaima</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Operation management problems (such as Production Planning and Scheduling)
are represented and formulated as optimization models. The resolution of such
optimization models leads to solutions which have to be operated in an
organization. However, the conditions under which the optimal solution is
obtained rarely correspond exactly to the conditions under which the solution
will be operated in the organization.Therefore, in most practical contexts, the
computed optimal solution is not anymore optimal under the conditions in which
it is operated. Indeed, it can be &quot;far from optimal&quot; or even not feasible. For
different reasons, we hadn't the possibility to completely re-optimize the
existing solution or plan. As a consequence, it is necessary to look for
&quot;repair solutions&quot;, i.e., solutions that have a good behavior with respect to
possible scenarios, or with respect to uncertainty of the parameters of the
model. To tackle the problem, the computed solution should be such that it is
possible to &quot;repair&quot; it through a local re-optimization guided by the user or
through a limited change aiming at minimizing the impact of taking into
consideration the scenarios.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05750</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextual equivalences in configuration structures and reversibility</dc:title>
 <dc:creator>Aubert, Cl&#xe9;ment</dc:creator>
 <dc:creator>Cristescu, Ioana</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  Contextual equivalence equate terms that have the same observable behaviour
in any context. A standard contextual equivalence for CCS is the strong barbed
congruence. Configuration structures are a denotational semantics for processes
in which one define equivalences that are more discriminating, i.e. that
distinguish the denotation of terms equated by barbed congruence. Hereditary
history preserving bisimulation (HHPB) is such a relation. We define a strong
back-and-forth barbed congruence on RCCS, a reversible variant of CCS. We show
that the relation induced by the back-and-forth congruence on configuration
structures is equivalent to HHPB, thus providing a contextual characterization
of HHPB.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05756</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Question Answering using Convolutional Neural Network with Dynamic
  Parameter Prediction</dc:title>
 <dc:creator>Noh, Hyeonwoo</dc:creator>
 <dc:creator>Seo, Paul Hongsuck</dc:creator>
 <dc:creator>Han, Bohyung</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We tackle image question answering (ImageQA) problem by learning a
convolutional neural network (CNN) with a dynamic parameter layer whose weights
are determined adaptively based on questions. For the adaptive parameter
prediction, we employ a separate parameter prediction network, which consists
of gated recurrent unit (GRU) taking a question as its input and a
fully-connected layer generating a set of candidate weights as its output.
However, it is challenging to construct a parameter prediction network for a
large number of parameters in the fully-connected dynamic parameter layer of
the CNN. We reduce the complexity of this problem by incorporating a hashing
technique, where the candidate weights given by the parameter prediction
network are selected using a predefined hash function to determine individual
weights in the dynamic parameter layer. The proposed network---joint network
with the CNN for ImageQA and the parameter prediction network---is trained
end-to-end through back-propagation, where its weights are initialized using a
pre-trained CNN and GRU. The proposed algorithm illustrates the
state-of-the-art performance on all available public ImageQA benchmarks.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05757</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Hands-off Control without Normality Assumption</dc:title>
 <dc:creator>Ikeda, Takuya</dc:creator>
 <dc:creator>Nagahara, Masaaki</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Maximum hands-off control is a control that has the minimum L0 norm among all
feasible controls. It is known that the maximum hands-off (or L0-optimal)
control problem is equivalent to the L1-optimal control under the assumption of
normality. In this article, we analyze the maximum hands-off control for linear
time-invariant systems without the normality assumption. For this purpose, we
introduce the Lp-optimal control with 0&lt;p&lt;1, which is a natural relaxation of
the L0 problem. By using this, we investigate the existence and the
bang-off-bang property (i.e. the control takes values of 1, 0 and -1) of the
maximum hands-off control. We then describe a general relation between the
maximum hands-off control and the L1-optimal control. We also prove the
continuity and convexity property of the value function, which plays an
important role to prove the stability when the (finite-horizon) control is
extended to model predictive control.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05768</identifier>
 <datestamp>2017-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Labeled pupils in the wild: A dataset for studying pupil detection in
  unconstrained environments</dc:title>
 <dc:creator>Tonsen, Marc</dc:creator>
 <dc:creator>Zhang, Xucong</dc:creator>
 <dc:creator>Sugano, Yusuke</dc:creator>
 <dc:creator>Bulling, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present labelled pupils in the wild (LPW), a novel dataset of 66
high-quality, high-speed eye region videos for the development and evaluation
of pupil detection algorithms. The videos in our dataset were recorded from 22
participants in everyday locations at about 95 FPS using a state-of-the-art
dark-pupil head-mounted eye tracker. They cover people with different
ethnicities, a diverse set of everyday indoor and outdoor illumination
environments, as well as natural gaze direction distributions. The dataset also
includes participants wearing glasses, contact lenses, as well as make-up. We
benchmark five state-of-the-art pupil detection algorithms on our dataset with
respect to robustness and accuracy. We further study the influence of image
resolution, vision aids, as well as recording location (indoor, outdoor) on
pupil detection performance. Our evaluations provide valuable insights into the
general pupil detection problem and allow us to identify key challenges for
robust pupil detection on head-mounted eye trackers.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05768</dc:identifier>
 <dc:identifier>doi:10.1145/2857491.2857520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05770</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On LR(k)-parsers of polynomial size</dc:title>
 <dc:creator>Blum, Norbert</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Usually, a parser for an $LR(k)$-grammar $G$ is a deterministic pushdown
transducer which produces backwards the unique rightmost derivation for a given
input string $x \in L(G)$. The best known upper bound for the size of such a
parser is $O(2^{|G||\Sigma|^k+k\log |\Sigma| + \log |G|})$ where $|G|$ and
$|\Sigma|$ are the sizes of the grammar $G$ and the terminal alphabet $\Sigma$,
respectively. If we add to a parser the possibility to manipulate a directed
graph of size $O(|G|n)$ where $n$ is the length of the input then we obtain an
extended parser. The graph is used for an efficient parallel simulation of all
potential leftmost derivations of the current right sentential form such that
the unique rightmost derivation of the input can be computed. Given an
arbitrary $LR(k)$-grammar $G$, we show how to construct an extended parser of
$O(|G| + \#LA |N|2^k k \log k)$ size where $|N|$ is the number of nonterminal
symbols and $\#LA$ is the number of relevant lookaheads with respect to the
grammar $G$. As the usual parser, this extended parser uses only tables as data
structure. Using some ingenious data structures and increasing the parsing time
by a small constant factor, the size of the extended parser can be reduced to
$O(|G| + \#LA|N|k^2)$. The parsing time is $O(ld(input) + k|G|n)$ where
$ld(input)$ is the length of the derivation of the input. Moreover, we have
constructed a one pass parser.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper appeared in 37th International
  Colloquium, ICALP 2010, Bordeaux, France, July 2010, Proceedings, Part II,
  LNCS 6199, pp. 163--174, Springer-Verlag Berlin Heidelberg 2010</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05771</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Transparent Heterogeneous Systems</dc:title>
 <dc:creator>Delporte, Baptiste</dc:creator>
 <dc:creator>Rigamonti, Roberto</dc:creator>
 <dc:creator>Dassatti, Alberto</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Heterogeneous parallel systems are widely spread nowadays. Despite their
availability, their usage and adoption are still limited, and even more rarely
they are used to full power. Indeed, compelling new technologies are constantly
developed and keep changing the technological landscape, but each of them
targets a limited sub-set of supported devices, and nearly all of them require
new programming paradigms and specific toolsets. Software, however, can hardly
keep the pace with the growing number of computational capabilities, and
developers are less and less motivated in learning skills that could quickly
become obsolete. In this paper we present our effort in the direction of a
transparent system optimization based on automatic code profiling and
Just-In-Time compilation, that resulted in a fully-working embedded prototype
capable of dynamically detect computing-intensive code blocks and automatically
dispatch them to different computation units. Experimental results show that
our system allows gains up to 32x in performance --- after an initial warm-up
phase --- without requiring any human intervention.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05774</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applications of Multi-Agent Slime Mould Computing</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The giant single-celled slime mould Physarum polycephalum has inspired rapid
develop- ments in unconventional computing substrates since the start of this
century. This is primarily due to its simple component parts and the
distributed nature of the computation which it approximates during its growth,
foraging and adaptation to a changing environment. Slime mould functions as a
living embodied computational material which can be influenced (or pro-
grammed) by the placement of external stimuli. The goal of exploiting this
material behaviour for unconventional computation led to the development of a
multi-agent approach to the ap- proximation of slime mould behaviour. The basis
of the model is a simple dynamical pattern formation mechanism which exhibits
self-organised formation and subsequent adaptation of collective transport
networks. The system exhibits emergent properties such as relaxation and
minimisation and it can be considered as a virtual computing material,
influenced by the external application of spatial concentration gradients. In
this paper we give an overview of this multi-agent approach to unconventional
computing. We describe its computational mechanisms and different generic
application domains, together with concrete example ap- plications of material
computation. We examine the potential exploitation of the approach for
computational geometry, path planning, combinatorial optimisation, data
smoothing and statistical applications.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05774</dc:identifier>
 <dc:identifier>Int. J. of Parallel, Emergent and Distributed Systems, 1-30 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05778</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache-Conscious Run-time Decomposition of Data Parallel Computations</dc:title>
 <dc:creator>Paulino, Herv&#xe9;</dc:creator>
 <dc:creator>Delgado, Nuno</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Multi-core architectures feature an intricate hierarchy of cache memories,
with multiple levels and sizes. To adequately decompose an application
according to the traits of a particular memory hierarchy is a cumbersome task
that may be rewarded with significant performance gains. The current
state-of-the-art in memory-hierarchy-aware parallel computing delegates this
endeavour on the programmer, demanding from him deep knowledge of both parallel
programming and computer architecture. In this paper we propose the shifting of
these memory-hierarchy-related concerns to the run-time system, which then
takes on the responsibility of distributing the computation's data across the
target memory hierarchy. We evaluate our approach from a performance
perspective, comparing it against the common cache-neglectful data
decomposition strategy.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05779</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Lateral Inhibition and Collective Perception in Unorganised
  Non-Neural Systems</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Could simple organisms such as slime mould approximate LI without recourse to
neural tissue? We describe a model whereby LI can emerge without explicit
inhibitory wiring, using only bulk transport effects. We use a multi-agent
model of slime mould to reproduce the char- acteristic edge contrast
amplification effects of LI using excitation via attractant based stimuli. We
also explore a counterpart behaviour, Lateral Activation (where stimulated
regions are inhibited and lateral regions are excited), using simulated
exposure to light irradiation. In both cases restoration of baseline activity
occurs when the stimuli are removed. In addition to the enhancement of local
edge contrast the long-term change in population density distribution
corresponds to a collective response to the global brightness of 2D image
stimuli, including the scalloped inten- sity profile of the Chevreul staircase
and the perceived difference of two identically bright patches in the
Simultaneous Brightness Contrast (SBC) effect. This simple
modelapproximatesLIcontrastenhancementphenomenaandglobalbrightnessper- ception
in collective unorganised systems without fixed neural architectures. This may
encourage further research into unorganised analogues of neural processes in
simple organisms and suggests novel mechanisms to generate collective
perception of contrast and brightness in distributed computing and robotic
devices.
</dc:description>
 <dc:description>Comment: Computational Intelligence, Medicine and Biology, Eds. Pancerz, K.,
  Zaitseva, E., p. 103-122</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05787</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Paillier's Cryptosystem and Some Variants Revisited</dc:title>
 <dc:creator>Cao, Zhengjun</dc:creator>
 <dc:creator>Liu, Lihua</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  At Eurocrypt'99, Paillier presented a public-key cryptosystem based on a
novel computational problem. It has interested many researchers because it was
additively homomorphic. In this paper, we show that there is a big difference
between the original Paillier's encryption and some variants. The Paillier's
encryption can be naturally transformed into a signature scheme but these
variants miss the feature. In particular, we simplify the alternative
decryption procedure of Bresson-Catalano-Pointcheval encryption scheme proposed
at Asiacrypt'03. The new version is more applicable to cloud computing because
of its double trapdoor decryption mechanism and its flexibility to be
integrated into other cryptographic schemes. It captures a new feature that its
two groups of secret keys can be distributed to different users so as to
enhance the robustness of key management.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05788</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Pose to Activity: Surveying Datasets and Introducing CONVERSE</dc:title>
 <dc:creator>Edwards, Michael</dc:creator>
 <dc:creator>Deng, Jingjing</dc:creator>
 <dc:creator>Xie, Xianghua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a review on the current state of publicly available datasets
within the human action recognition community; highlighting the revival of pose
based methods and recent progress of understanding person-person interaction
modeling. We categorize datasets regarding several key properties for usage as
a benchmark dataset; including the number of class labels, ground truths
provided, and application domain they occupy. We also consider the level of
abstraction of each dataset; grouping those that present actions, interactions
and higher level semantic activities. The survey identifies key appearance and
pose based datasets, noting a tendency for simplistic, emphasized, or scripted
action classes that are often readily definable by a stable collection of
sub-action gestures. There is a clear lack of datasets that provide closely
related actions, those that are not implicitly identified via a series of poses
and gestures, but rather a dynamic set of interactions. We therefore propose a
novel dataset that represents complex conversational interactions between two
individuals via 3D pose. 8 pairwise interactions describing 7 separate
conversation based scenarios were collected using two Kinect depth sensors. The
intention is to provide events that are constructed from numerous primitive
actions, interactions and motions, over a period of time; providing a set of
subtle action classes that are more representative of the real world, and a
challenge to currently developed recognition methodologies. We believe this is
among one of the first datasets devoted to conversational interaction
classification using 3D pose features and the attributed papers show this task
is indeed possible. The full dataset is made publicly available to the research
community at www.csvision.swansea.ac.uk/converse.
</dc:description>
 <dc:description>Comment: Presentation of pose-based conversational human interaction dataset,
  review of current appearance and depth based action recognition datasets,
  public dataset, 38 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05789</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric learning approach for graph-based label propagation</dc:title>
 <dc:creator>Wauquier, Pauline</dc:creator>
 <dc:creator>Keller, Mikaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The efficiency of graph-based semi-supervised algorithms depends on the graph
of instances on which they are applied. The instances are often in a vectorial
form before a graph linking them is built. The construction of the graph relies
on a metric over the vectorial space that help define the weight of the
connection between entities. The classic choice for this metric is usually a
distance measure or a similarity measure based on the euclidean norm. We claim
that in some cases the euclidean norm on the initial vectorial space might not
be the more appropriate to solve the task efficiently. We propose an algorithm
that aims at learning the most appropriate vectorial representation for
building a graph on which the task at hand is solved efficiently.
</dc:description>
 <dc:description>Comment: Workshop track submission ICLR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05797</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying the evolution of a scientific topic: reaction of the
  academic community to the Chornobyl disaster</dc:title>
 <dc:creator>Mryglod, Olesya</dc:creator>
 <dc:creator>Holovatch, Yurij</dc:creator>
 <dc:creator>Kenna, Ralph</dc:creator>
 <dc:creator>Berche, Bertrand</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We analyze the reaction of academic communities to a particular urgent topic
which abruptly arises as a scientific problem. To this end, we have chosen the
disaster that occurred in 1986 in Chornobyl (Chernobyl), Ukraine, considered as
one of the most devastating nuclear power plant accidents in history. The
academic response is evaluated using scientific-publication data concerning the
disaster using the Scopus database to present the picture on an international
scale and the bibliographic database &quot;Ukrainika naukova&quot; to consider it on a
national level. We measured distributions of papers in different scientific
fields, their growth rates and properties of co-authorship networks. {The
elements of descriptive statistics and the tools of the complex network theory
are used to highlight the interdisciplinary as well as international effects.}
Our analysis allows to compare contributions of the international community to
Chornobyl-related research as well as integration of Ukraine in the
international research on this subject. Furthermore, the content analysis of
titles and abstracts of the publications allowed to detect the most important
terms used for description of Chornobyl-related problems.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05797</dc:identifier>
 <dc:identifier>Scientometrics 106 (2016) 1151-1166</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-015-1820-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05798</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Problems with the use of Web search engines to find results in foreign
  languages</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Purpose - To test the ability of major search engines, Google, Yahoo, MSN,
and Ask, to distinguish between German and English-language documents
  Design/methodology/approach - 50 queries, using words common in German and in
English, were posed to the engines. The advanced search option of language
restriction was used, once in German and once in English. The first 20 results
per engine in each language were investigated.
  Findings - While none of the search engines faces problems in providing
results in the language of the interface that is used, both Google and MSN face
problems when the results are restricted to a foreign language.
  Research limitations/implications - Search engines were only tested in German
and in English. We have only anecdotal evidence that the problems are the same
with other languages.
  Practical implications - Searchers should not use the language restriction in
Google and MSN when searching for foreign-language documents. Instead,
searchers should use Yahoo or Ask. If searching for foreign language documents
in Google or MSN, the interface in the target language/country should be used.
  Value of paper - Demonstrates a problem with search engines that has not been
previously investigated.
</dc:description>
 <dc:description>Comment: Research paper, World Wide Web, search engines, advanced search
  options, language restriction</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05800</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Retrieval Effectiveness of Web Search Engines: Considering Results
  Descriptions</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Purpose: To compare five major Web search engines (Google, Yahoo, MSN,
Ask.com, and Seekport) for their retrieval effectiveness, taking into account
not only the results but also the results descriptions.
  Design/Methodology/Approach: The study uses real-life queries. Results are
made anonymous and are randomised. Results are judged by the persons posing the
original queries.
  Findings: The two major search engines, Google and Yahoo, perform best, and
there are no significant differences between them. Google delivers
significantly more relevant result descriptions than any other search engine.
This could be one reason for users perceiving this engine as superior.
  Research Limitations: The study is based on a user model where the user takes
into account a certain amount of results rather systematically. This may not be
the case in real life.
  Practical Implications: Implies that search engines should focus on relevant
descriptions. Searchers are advised to use other search engines in addition to
Google.
  Originality/Value: This is the first major study comparing results and
descriptions systematically and proposes new retrieval measures to take into
account results descriptions
</dc:description>
 <dc:description>Comment: Research paper, Word Wide Web, search engines, retrieval
  effectiveness, results descriptions, retrieval measures</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05802</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Users See - Structures in Search Engine Results Pages</dc:title>
 <dc:creator>Hoechstoetter, Nadine</dc:creator>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper investigates the composition of search engine results pages. We
define what elements the most popular web search engines use on their results
pages (e.g., organic results, advertisements, shortcuts) and to which degree
they are used for popular vs. rare queries. Therefore, we send 500 queries of
both types to the major search engines Google, Yahoo, Live.com and Ask. We
count how often the different elements are used by the individual engines. In
total, our study is based on 42,758 elements. Findings include that search
engines use quite different approaches to results pages composition and
therefore, the user gets to see quite different results sets depending on the
search engine and search query used. Organic results still play the major role
in the results pages, but different shortcuts are of some importance, too.
Regarding the frequency of certain host within the results sets, we find that
all search engines show Wikipedia results quite often, while other hosts shown
depend on the search engine used. Both Google and Yahoo prefer results from
their own offerings (such as YouTube or Yahoo Answers). Since we used the .com
interfaces of the search engines, results may not be valid for other
country-specific interfaces.
</dc:description>
 <dc:description>Comment: Search engines, evaluation, search engine results pages, search
  shortcuts</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05806</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ranking library materials</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Purpose: This paper discusses ranking factors suitable for library materials
and shows that ranking in general is a complex process and that ranking for
library materials requires a variety of techniques.
Design/methodology/approach: The relevant literature is reviewed to provide a
systematic overview of suitable ranking factors. The discussion is based on an
overview of ranking factors used in Web search engines. Findings: While there
are a wide variety of ranking factors applicable to library materials, todays
library systems use only some of them. When designing a ranking component for
the library catalogue, an individual weighting of applicable factors is
necessary. Research limitations/applications: While this article discusses
different factors, no particular ranking formula is given. However, this
article presents the argument that such a formula must always be individual to
a certain use case. Practical implications: The factors presented can be
considered when designing a ranking component for a librarys search system or
when discussing such a project with an ILS vendor. Originality/value: This
paper is original in that it is the first to systematically discuss ranking of
library materials based on the main factors used by Web search engines.
</dc:description>
 <dc:description>Comment: Conceptual paper, OPAC, search engines, ranking, results presentation</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05807</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of Wireless Techniques in Data and Power Transmission -
  Application for Particle Physics Detectors</dc:title>
 <dc:creator>Brenner, R.</dc:creator>
 <dc:creator>Ceuterickx, S.</dc:creator>
 <dc:creator>Dehos, C.</dc:creator>
 <dc:creator>De Lurgio, P.</dc:creator>
 <dc:creator>Djurcic, Z.</dc:creator>
 <dc:creator>Drake, G.</dc:creator>
 <dc:creator>Gimenez, J. L. Gonzalez</dc:creator>
 <dc:creator>Gustafsson, L.</dc:creator>
 <dc:creator>Kim, D. W.</dc:creator>
 <dc:creator>Locci, E.</dc:creator>
 <dc:creator>Roehrich, D.</dc:creator>
 <dc:creator>Schoening, A.</dc:creator>
 <dc:creator>Siligaris, A.</dc:creator>
 <dc:creator>Soltveit, H. K.</dc:creator>
 <dc:creator>Ullaland, K.</dc:creator>
 <dc:creator>Vincent, P.</dc:creator>
 <dc:creator>Wiednert, D.</dc:creator>
 <dc:creator>Yang, S.</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  Wireless techniques have developed extremely fast over the last decade and
using them for data and power transmission in particle physics detectors is not
science- fiction any more. During the last years several research groups have
independently thought of making it a reality. Wireless techniques became a
mature field for research and new developments might have impact on future
particle physics experiments. The Instrumentation Frontier was set up as a part
of the SnowMass 2013 Community Summer Study [1] to examine the instrumentation
R&amp;D for the particle physics research over the coming decades: {\guillemotleft}
To succeed we need to make technical and scientific innovation a priority in
the field {\guillemotright}. Wireless data transmission was identified as one
of the innovations that could revolutionize the transmission of data out of the
detector. Power delivery was another challenge mentioned in the same report. We
propose a collaboration to identify the specific needs of different projects
that might benefit from wireless techniques. The objective is to provide a
common platform for research and development in order to optimize effectiveness
and cost, with the aim of designing and testing wireless demonstrators for
large instrumentation systems.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05808</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Search Engine Technology to Improve Library Catalogs</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This chapter outlines how search engine technology can be used in online
public access library catalogs (OPACs) to help improve users experiences, to
identify users intentions, and to indicate how it can be applied in the library
context, along with how sophisticated ranking criteria can be applied to the
online library catalog. A review of the literature and current OPAC
developments form the basis of recommendations on how to improve OPACs.
Findings were that the major shortcomings of current OPACs are that they are
not sufficiently user-centered and that their results presentations lack
sophistication. Further, these shortcomings are not addressed in current 2.0
developments. It is argued that OPAC development should be made search-centered
before additional features are applied. While the recommendations on ranking
functionality and the use of user intentions are only conceptual and not yet
applied to a library catalogue, practitioners will find recommendations for
developing better OPACs in this chapter. In short, readers will find a
systematic view on how the search engines strengths can be applied to improving
libraries online catalogs.
</dc:description>
 <dc:description>Comment: Search engines, online catalogs, ranking, information seeking
  behavior, query types</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05809</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Google Scholar as a tool for discovering journal articles in library and
  information science</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Purpose: The purpose of this paper is to measure the coverage of Google
Scholar for the Library and Information Science (LIS) journal literature as
identified by a list of core LIS journals from a study by Schloegl and
Petschnig (2005).
  Methods: We checked every article from 35 major LIS journals from the years
2004 to 2006 for availability in Google Scholar (GS). We also collected
information on the type of availability-i.e., whether a certain article was
available as a PDF for a fee, as a free PDF, or as a preprint.
  Results: We found that only some journals are completely indexed by Google
Scholar, that the ratio of versions available depends on the type of publisher,
and that availability varies a lot from journal to journal. Google Scholar
cannot substitute for abstracting and indexing services in that it does not
cover the complete literature of the field. However, it can be used in many
cases to easily find available full texts of articles already found using
another tool.
  Originality/value: This study differs from other Google Scholar coverage
studies in that it takes into account not only whether an article is indexed in
GS at all, but also the type of availability.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05810</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Influence of Commercial Intent of Search Results on Their Perceived
  Relevance</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We carried out a retrieval effectiveness test on the three major web search
engines (i.e., Google, Microsoft and Yahoo). In addition to relevance
judgments, we classified the results according to their commercial intent and
whether or not they carried any advertising. We found that all search engines
provide a large number of results with a commercial intent. Google provides
significantly more commercial results than the other search engines do.
However, the commercial intent of a result did not influence jurors in their
relevance judgments.
</dc:description>
 <dc:description>Comment: Measurement, Performance, Experimentation, Worldwide Web, search
  engines, commerciality, evaluation</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05812</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The retrieval effectiveness of search engines on navigational queries</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Purpose - To test major Web search engines on their performance on
navigational queries, i.e. searches for homepages. Design/methodology/approach
- 100 real user queries are posed to six search engines (Google, Yahoo, MSN,
Ask, Seekport, and Exalead). Users described the desired pages, and the results
position of these is recorded. Measured success N and mean reciprocal rank are
calculated. Findings - Performance of the major search engines Google, Yahoo,
and MSN is best, with around 90 percent of queries answered correctly. Ask and
Exalead perform worse but receive good scores as well. Research
limitations/implications - All queries were in German, and the German-language
interfaces of the search engines were used. Therefore, the results are only
valid for German queries. Practical implications - When designing a search
engine to compete with the major search engines, care should be taken on the
performance on navigational queries. Users can be influenced easily in their
quality ratings of search engines based on this performance. Originality/value
- This study systematically compares the major search engines on navigational
queries and compares the findings with studies on the retrieval effectiveness
of the engines on informational queries. Paper type - research paper
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05817</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Evaluating the Retrieval Effectiveness of Search Engines</dc:title>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This chapter presents a theoretical framework for evaluating next generation
search engines. We focus on search engines whose results presentation is
enriched with additional information and does not merely present the usual list
of 10 blue links, that is, of ten links to results, accompanied by a short
description. While Web search is used as an example here, the framework can
easily be applied to search engines in any other area. The framework not only
addresses the results presentation, but also takes into account an extension of
the general design of retrieval effectiveness tests. The chapter examines the
ways in which this design might influence the results of such studies and how a
reliable test is best designed.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05819</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The relationship between internet user type and user performance when
  carrying out simple vs. complex search tasks</dc:title>
 <dc:creator>Singer, Georg</dc:creator>
 <dc:creator>Pruulmann-Vengerfeldt, Pille</dc:creator>
 <dc:creator>Norbisrath, Ulrich</dc:creator>
 <dc:creator>Lewandowski, Dirk</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  It is widely known that people become better at an activity if they perform
this activity long and often. Yet, the question is whether being active in
related areas like communicating online, writing blog articles or commenting on
community forums have an impact on a persons ability to perform Web searches,
is still unanswered. Web searching has become a key task conducted online; in
this paper we present our findings on whether the user type, which categorises
a persons online activities, has an impact on her or his search capabilities.
We show (1) the characteristics of different user types when carrying out
simple search tasks; (2) their characteristics when carrying out complex search
tasks; and, (3) the significantly different user type characteristics between
simple and complex search tasks. The results are based on an experiment with 56
ordinary Web users in a laboratory environment. The Search-Logger study
framework was used to analyze and measure user behavior when carrying out a set
of 12 predefined search tasks. Our findings include the fact that depending on
task type (simple or complex) significant differences can be observed between
users of different types.
</dc:description>
 <dc:description>Comment: http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/3960/3245</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05819</dc:identifier>
 <dc:identifier>doi:10.5210/fm.v17i6.3960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05823</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structure and Stability of the 1-Dimensional Mapper</dc:title>
 <dc:creator>Carri&#xe8;re, Mathieu</dc:creator>
 <dc:creator>Oudot, Steve</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a continuous function $f:X\to\mathbb{R}$ and a cover $\mathcal{I}$ of
its image by intervals, the Mapper is the nerve of a refinement of the pullback
cover $f^{-1}(\mathcal{I})$. Despite its success in applications, little is
known about the structure and stability of this construction from a theoretical
point of view. As a pixelized version of the Reeb graph of $f$, it is expected
to capture a subset of its features (branches, holes), depending on how the
interval cover is positioned with respect to the critical values of the
function. Its stability should also depend on this positioning. We propose a
theoretical framework that relates the structure of the Mapper to the one of
the Reeb graph, making it possible to predict which features will be present
and which will be absent in the Mapper given the function and the cover, and
for each feature, to quantify its degree of (in-)stability. Using this
framework, we can derive guarantees on the structure of the Mapper, on its
stability, and on its convergence to the Reeb graph as the granularity of the
cover $\mathcal{I}$ goes to zero.
</dc:description>
 <dc:description>Comment: Minor corrections</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05823</dc:identifier>
 <dc:identifier>Published in Journal of Computational Mathematics in Oct. 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s10208-017-9370-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05834</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO Relaying with Hybrid Processing</dc:title>
 <dc:creator>Fozooni, Milad</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Jin, Shi</dc:creator>
 <dc:creator>Alexandropoulos, George C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) relaying is a promising
technological paradigm which can offer high spectral efficiency and
substantially improved coverage. Yet, these configurations face some formidable
challenges in terms of digital signal processing (DSP) power consumption and
circuitry complexity, since the number of radio frequency (RF) chains may scale
with the number of antennas at the relay station. In this paper, we advocate
that performing a portion of the power-intensive DSP in the analog domain,
using simple phase shifters and with a reduced number of RF paths, can address
these challenges. In particular, we consider a multipair amplify-and-forward
(AF) relay system with maximum ratio combining/transmission (MRC/MRT) and we
determine the asymptotic spectral efficiency for this hybrid analog/digital
architecture. After that, we extend our analytical results to account for
heavily quantized analog phase shifters and show that the performance loss with
2 quantization bits is only 10%.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05835</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternative Markov and Causal Properties for Acyclic Directed Mixed
  Graphs</dc:title>
 <dc:creator>Pe&#xf1;a, Jose M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We extend Andersson-Madigan-Perlman chain graphs by (i) relaxing the
semidirected acyclity constraint so that only directed cycles are forbidden,
and (ii) allowing up to two edges between any pair of nodes. We introduce
global, and ordered local and pairwise Markov properties for the new models. We
show the equivalence of these properties for strictly positive probability
distributions. We also show that when the random variables are continuous, the
new models can be interpreted as systems of structural equations with
correlated errors. This enables us to adapt Pearl's do-calculus to them.
Finally, we describe an exact algorithm for learning the new models from
observational and interventional data via answer set programming.
</dc:description>
 <dc:description>Comment: Minor changes</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05842</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring Responsiveness in the Online Public Sphere for the 2016 U.S.
  Election: Concepts</dc:title>
 <dc:creator>Kung, Pau Perng-Hwa</dc:creator>
 <dc:creator>Roy, Deb</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The election narrative is formed under the competitions of ideas among
critical players involving politicians, news media, public influentials, and
the general public. Untangling the complex process of narrative formation,
however, is no easy task due to implicit influences among the key players. This
paper outlines a conceptual framework to untangle this complex process. We
propose the problem of measuring &quot;responsiveness&quot; that quantifies a player's
influence on another given a specific election topic over time. In particular,
we make use of multivariate Hawkes Process to infer the influence network
between pairs of election players. We demonstrate an early version system of
analytic pipeline of online public sphere discussions from data ingestion,
influence inference, to visualization. The paper concludes by showcasing some
preliminary results based on Twitter and news media election-related contents
from July to October 2015 and discussing plans for future research.
</dc:description>
 <dc:description>Comment: 7 pages, Workshop on Networks in the Social and Information Sciences
  NIPS 2015</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05846</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eigenspectra optoacoustic tomography achieves quantitative blood
  oxygenation imaging deep in tissues</dc:title>
 <dc:creator>Tzoumas, Stratis</dc:creator>
 <dc:creator>Nunes, Antonio</dc:creator>
 <dc:creator>Olefir, Ivan</dc:creator>
 <dc:creator>Stangl, Stefan</dc:creator>
 <dc:creator>Symvoulidis, Panagiotis</dc:creator>
 <dc:creator>Glasl, Sarah</dc:creator>
 <dc:creator>Bayer, Christine</dc:creator>
 <dc:creator>Multhoff, Gabriele</dc:creator>
 <dc:creator>Ntziachristos, Vasilis</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Light propagating in tissue attains a spectrum that varies with location due
to wavelength-dependent fluence attenuation by tissue optical properties, an
effect that causes spectral corruption. Predictions of the spectral variations
of light fluence in tissue are challenging since the spatial distribution of
optical properties in tissue cannot be resolved in high resolution or with high
accuracy by current methods. Spectral corruption has fundamentally limited the
quantification accuracy of optical and optoacoustic methods and impeded the
long sought-after goal of imaging blood oxygen saturation (sO2) deep in
tissues; a critical but still unattainable target for the assessment of
oxygenation in physiological processes and disease. We discover a new principle
underlying light fluence in tissues, which describes the wavelength dependence
of light fluence as an affine function of a few reference base spectra,
independently of the specific distribution of tissue optical properties. This
finding enables the introduction of a previously undocumented concept termed
eigenspectra Multispectral Optoacoustic Tomography (eMSOT) that can effectively
account for wavelength dependent light attenuation without explicit knowledge
of the tissue optical properties. We validate eMSOT in more than 2000
simulations and with phantom and animal measurements. We find that eMSOT can
quantitatively image tissue sO2 reaching in many occasions a better than
10-fold improved accuracy over conventional spectral optoacoustic methods.
Then, we show that eMSOT can spatially resolve sO2 in muscle and tumor;
revealing so far unattainable tissue physiology patterns. Last, we related
eMSOT readings to cancer hypoxia and found congruence between eMSOT tumor sO2
images and tissue perfusion and hypoxia maps obtained by correlative
histological analysis.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05846</dc:identifier>
 <dc:identifier>doi:10.1038/ncomms12121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05847</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trees with small b-chromatic index</dc:title>
 <dc:creator>Silva, Ana</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In a recent article [5], the authors claim that the distance between the
b-chromatic index of a tree and a known upper bound is at most 1. At the same
time, in [7] the authors claim to be able to construct a tree where this
difference is bigger than 1. However, the given example was disconnected, i.e.,
actually consisted of a forest. Here, we slightly modify their construction in
order to produce trees, thus getting that indeed the difference between the
b-chromatic index of trees and the known upper bound can be arbitrarily large.
We also point out the mistake made in [5].
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05850</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomalous Contagion and Renormalization in Dynamical Networks with Nodal
  Mobility</dc:title>
 <dc:creator>Manrique, Pedro D.</dc:creator>
 <dc:creator>Qi, Hong</dc:creator>
 <dc:creator>Zheng, Minzhang</dc:creator>
 <dc:creator>Xu, Chen</dc:creator>
 <dc:creator>Hui, Pak Ming</dc:creator>
 <dc:creator>Johnson, Neil F.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  The common real-world feature of individuals migrating through a network --
either in real space or online -- significantly complicates understanding of
network processes. Here we show that even though a network may appear static on
average, underlying nodal mobility can dramatically distort outbreak profiles.
Highly nonlinear dynamical regimes emerge in which increasing mobility either
amplifies or suppresses outbreak severity. Predicted profiles mimic recent
outbreaks of real-space contagion (social unrest) and online contagion
(pro-ISIS support). We show that this nodal mobility can be renormalized in a
precise way for a particular class of dynamical networks.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05850</dc:identifier>
 <dc:identifier>doi:10.1209/0295-5075/115/18001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05860</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scampi: a robust approximate message-passing framework for compressive
  imaging</dc:title>
 <dc:creator>Barbier, Jean</dc:creator>
 <dc:creator>Tramel, Eric W.</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Reconstruction of images from noisy linear measurements is a core problem in
image processing, for which convex optimization methods based on total
variation (TV) minimization have been the long-standing state-of-the-art. We
present an alternative probabilistic reconstruction procedure based on
approximate message-passing, Scampi, which operates in the compressive regime,
where the inverse imaging problem is underdetermined. While the proposed method
is related to the recently proposed GrAMPA algorithm of Borgerding, Schniter,
and Rangan, we further develop the probabilistic approach to compressive
imaging by introducing an expectation-maximizaiton learning of model
parameters, making the Scampi robust to model uncertainties. Additionally, our
numerical experiments indicate that Scampi can provide reconstruction
performance superior to both GrAMPA as well as convex approaches to TV
reconstruction. Finally, through exhaustive best-case experiments, we show that
in many cases the maximal performance of both Scampi and convex TV can be quite
close, even though the approaches are a prori distinct. The theoretical reasons
for this correspondence remain an open question. Nevertheless, the proposed
algorithm remains more practical, as it requires far less parameter tuning to
perform optimally.
</dc:description>
 <dc:description>Comment: Presented at the 2015 International Meeting on High-Dimensional Data
  Driven Science, Kyoto, Japan</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05860</dc:identifier>
 <dc:identifier>2016 J. Phys.: Conf. Ser. 699 012013</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/699/1/012013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05862</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representation of Shape Mediated by Environmental Stimuli in Physarum
  polycephalum and a Multi-agent Model</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:creator>Mayne, Richard</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The slime mould Physarum polycephalum is known to construct proto- plasmic
transport networks which approximate proximity graphs by forag- ing for
nutrients during its plasmodial life cycle stage. In these networks, nodes are
represented by nutrients and edges are represented by proto- plasmic tubes.
These networks have been shown to be efficient in terms of length and
resilience of the overall network to random damage. However relatively little
research has been performed in the potential for Physarum transport networks to
approximate the overall shape of a dataset. In this paper we distinguish
between connectivity and shape of a planar point dataset and demonstrate, using
scoping experiments with plasmodia of P. polycephalum and a multi-agent model
of the organism, how we can gen- erate representations of the external and
internal shapes of a set of points. As with proximity graphs formed by P.
polycephalum, the behaviour of the plasmodium (real and model) is mediated by
environmental stimuli. We further explore potential morphological computation
approaches with the multi-agent model, presenting methods which approximate the
Convex Hull and the Concave Hull. We demonstrate how a growth parameter in the
model can be used to transition between Convex and Concave Hulls. These results
suggest novel mechanisms of morphological computation mediated by environmental
stimuli.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05865</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Transformation for Implementation of Adder Circuits in
  Physical Systems</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:creator>Whiting, James G. H.</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Computing devices are composed of spatial arrangements of simple funda-
mental logic gates. These gates may be combined to form more complex adding
circuits and, ultimately, complete computer systems. Implementing classical
adding circuits using unconventional, or even living substrates such as slime
mould Physarum polycephalum, is made difficult and often impracti- cal by the
challenges of branching fan-out of inputs and regions where circuit lines must
cross without interference. In this report we explore whether it is possible to
avoid spatial propagation, branching and crossing completely in the design of
adding circuits. We analyse the input and output patterns of a single-bit full
adder circuit. A simple quantitative transformation of the input patterns which
considers the total number of bits in the input string allows us to map the
respective input combinations to the correct outputs patterns of the full adder
circuit, reducing the circuit combinations from a 2:1 mapping to a 1:1 mapping.
The mapping of inputs to outputs also shows an incremental linear progression,
suggesting its implementation in a range of physical systems. We demonstrate an
example implementation, first in simulation, inspired by self-oscillatory
dynamics of the acellular slime mould Physarum polycephalum. We then assess the
potential implementation using plasmodium of slime mould itself. This simple
transformation may enrich the potential for using unconventional computing
substrates to implement digital circuits.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05865</dc:identifier>
 <dc:identifier>Quantitative Transformation for Implementation of Adder Circuits
  in Physical Systems, Biosystems, 134, p. 16-23 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05866</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bisimulation of Labelled State-to-Function Transition Systems
  Coalgebraically</dc:title>
 <dc:creator>Latella, Diego</dc:creator>
 <dc:creator>Massink, Mieke</dc:creator>
 <dc:creator>De Vink, Erik P</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Labeled state-to-function transition systems, FuTS for short, are
characterized by transitions which relate states to functions of states over
general semirings, equipped with a rich set of higher-order operators. As such,
FuTS constitute a convenient modeling instrument to deal with process languages
and their quantitative extensions in particular. In this paper, the notion of
bisimulation induced by a FuTS is addressed from a coalgebraic point of view. A
correspondence result is established stating that FuTS-bisimilarity coincides
with behavioural equivalence of the associated functor. As generic examples,
the equivalences underlying substantial fragments of major examples of
quantitative process algebras are related to the bisimilarity of specific FuTS.
The examples range from a stochastic process language, PEPA, to a language for
Interactive Markov Chains, IML, a (discrete) timed process language, TPC, and a
language for Markov Automata, MAL. The equivalences underlying these languages
are related to the bisimilarity of their specific FuTS. By the correspondence
result coalgebraic justification of the equivalences of these calculi is
obtained. The specific selection of languages, besides covering a large variety
of process interaction models and modelling choices involving quantities,
allows us to show different classes of FuTS, namely so-called simple FuTS,
combined FuTS, nested FuTS, and general FuTS.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05866</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 11, Issue 4 (December
  22, 2015) lmcs:1617</dc:identifier>
 <dc:identifier>doi:10.2168/LMCS-11(4:16)2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05869</identifier>
 <datestamp>2016-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mechanisms Inducing Parallel Computation in a Model of Physarum
  polycephalum Transport Networks</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  P. polycephalum may be considered as a spatially represented parallel
unconventional computing substrate, but how can this `computer' be programmed?
In this paper we examine and catalogue individual low-level mechanisms which
may be used to induce network formation and adaptation in a multi-agent model
of P. polycephalum. These mechanisms include those intrinsic to the model
(particle sensor angle, rotation angle, and scaling parameters) and those
mediated by the environment (stimulus loca- tion, distance, angle,
concentration, engulfment and consumption of nutrients, and the presence of
simulated light irradiation, repellents and obstacles). The mechanisms in- duce
a concurrent integration of chemoattractant and chemorepellent gradients
diffusing within the 2D lattice upon which the agent population resides,
stimulating growth, move- ment, morphological adaptation and network
minimisation. Chemoattractant gradients, and their modulation by the engulfment
and consumption of nutrients by the model population, represent an efficient
outsourcing of spatial computation. The mechanisms may prove useful in
understanding the search strategies and adaptation of distributed organisms
within their environment, in understanding the minimal requirements for com-
plex adaptive behaviours, and in developing methods of spatially programming
parallel unconventional computers and robotic devices.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05869</dc:identifier>
 <dc:identifier>Transport Networks, Parallel Processing Letters, (25), 1, 1540004
  (2015)</dc:identifier>
 <dc:identifier>doi:10.1142/S0129626415400046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05875</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Avoiding two consecutive blocks of same size and same sum over
  $\mathbb{Z}^2$</dc:title>
 <dc:creator>Rao, Micha&#xeb;l</dc:creator>
 <dc:creator>Rosenfeld, Matthieu</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  A long standing question asks whether $\mathbb{Z}$ is uniformly 2-repetitive
[Justin 1972, Pirillo and Varricchio, 1994], that is, whether there is an
infinite sequence over a finite subset of $\mathbb{Z}$ avoiding two consecutive
blocks of same size and same sum or not. Cassaigne \emph{et al.} [2014] showed
that $\mathbb{Z}$ is not uniformly 3-repetitive. We show that $\mathbb{Z}^2$ is
not uniformly 2-repetitive. Moreover, this problem is related to a question
from M\&quot;akel\&quot;a in combinatorics on words and we answer to a weak version of
it.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05879</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Particular object retrieval with integral max-pooling of CNN activations</dc:title>
 <dc:creator>Tolias, Giorgos</dc:creator>
 <dc:creator>Sicre, Ronan</dc:creator>
 <dc:creator>J&#xe9;gou, Herv&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, image representation built upon Convolutional Neural Network (CNN)
has been shown to provide effective descriptors for image search, outperforming
pre-CNN features as short-vector representations. Yet such models are not
compatible with geometry-aware re-ranking methods and still outperformed, on
some particular object retrieval benchmarks, by traditional image search
systems relying on precise descriptor matching, geometric re-ranking, or query
expansion. This work revisits both retrieval stages, namely initial search and
re-ranking, by employing the same primitive information derived from the CNN.
We build compact feature vectors that encode several image regions without the
need to feed multiple inputs to the network. Furthermore, we extend integral
images to handle max-pooling on convolutional layer activations, allowing us to
efficiently localize matching objects. The resulting bounding box is finally
used for image re-ranking. As a result, this paper significantly improves
existing CNN-based recognition pipeline: We report for the first time results
competing with traditional methods on the challenging Oxford5k and Paris6k
datasets.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05886</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomization can be as helpful as a glimpse of the future in online
  computation</dc:title>
 <dc:creator>Mikkelsen, Jesper W.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We provide simple but surprisingly useful direct product theorems for proving
lower bounds on online algorithms with a limited amount of advice about the
future. As a consequence, we are able to translate decades of research on
randomized online algorithms to the advice complexity model. Doing so improves
significantly on the previous best advice complexity lower bounds for many
online problems, or provides the first known lower bounds. For example, if $n$
is the number of requests, we show that:
  (1) A paging algorithm needs $\Omega(n)$ bits of advice to achieve a
competitive ratio better than $H_k=\Omega(\log k)$, where $k$ is the cache
size. Previously, it was only known that $\Omega(n)$ bits of advice were
necessary to achieve a constant competitive ratio smaller than $5/4$.
  (2) Every $O(n^{1-\varepsilon})$-competitive vertex coloring algorithm must
use $\Omega(n\log n)$ bits of advice. Previously, it was only known that
$\Omega(n\log n)$ bits of advice were necessary to be optimal.
  For certain online problems, including the MTS, $k$-server, paging, list
update, and dynamic binary search tree problem, our results imply that
randomization and sublinear advice are equally powerful (if the underlying
metric space or node set is finite). This means that several long-standing open
questions regarding randomized online algorithms can be equivalently stated as
questions regarding online algorithms with sublinear advice. For example, we
show that there exists a deterministic $O(\log k)$-competitive $k$-server
algorithm with advice complexity $o(n)$ if and only if there exists a
randomized $O(\log k)$-competitive $k$-server algorithm without advice.
  Technically, our main direct product theorem is obtained by extending an
information theoretical lower bound technique due to Emek, Fraigniaud, Korman,
and Ros\'en [ICALP'09].
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05888</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preservation and decomposition theorems for bounded degree structures</dc:title>
 <dc:creator>Harwath, Frederik</dc:creator>
 <dc:creator>Heimberg, Lucas</dc:creator>
 <dc:creator>Schweikardt, Nicole</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We provide elementary algorithms for two preservation theorems for
first-order sentences (FO) on the class \^ad of all finite structures of degree
at most d: For each FO-sentence that is preserved under extensions
(homomorphisms) on \^ad, a \^ad-equivalent existential (existential-positive)
FO-sentence can be constructed in 5-fold (4-fold) exponential time. This is
complemented by lower bounds showing that a 3-fold exponential blow-up of the
computed existential (existential-positive) sentence is unavoidable. Both
algorithms can be extended (while maintaining the upper and lower bounds on
their time complexity) to input first-order sentences with modulo m counting
quantifiers (FO+MODm). Furthermore, we show that for an input FO-formula, a
\^ad-equivalent Feferman-Vaught decomposition can be computed in 3-fold
exponential time. We also provide a matching lower bound.
</dc:description>
 <dc:description>Comment: 42 pages and 3 figures. This is the full version of: Frederik
  Harwath, Lucas Heimberg, and Nicole Schweikardt. Preservation and
  decomposition theorems for bounded degree structures. In Joint Meeting of the
  23rd EACSL Annual Conference on Computer Science Logic (CSL) and the 29th
  Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), CSL-LICS'14,
  pages 49:1-49:10. ACM, 2014</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05888</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 11, Issue 4 (December
  29, 2015) lmcs:1618</dc:identifier>
 <dc:identifier>doi:10.2168/LMCS-11(4:17)2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05892</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Optimization of Sparse Random Linear Network Coding for
  Reliable Multicast Services</dc:title>
 <dc:creator>Tassi, Andrea</dc:creator>
 <dc:creator>Chatzigeorgiou, Ioannis</dc:creator>
 <dc:creator>Lucani, Daniel E.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Point-to-multipoint communications are expected to play a pivotal role in
next-generation networks. This paper refers to a cellular system transmitting
layered multicast services to a multicast group of users. Reliability of
communications is ensured via different Random Linear Network Coding (RLNC)
techniques. We deal with a fundamental problem: the computational complexity of
the RLNC decoder. The higher the number of decoding operations is, the more the
user's computational overhead grows and, consequently, the faster the battery
of mobile devices drains. By referring to several sparse RLNC techniques, and
without any assumption on the implementation of the RLNC decoder in use, we
provide an efficient way to characterize the performance of users targeted by
ultra-reliable layered multicast services. The proposed modeling allows to
efficiently derive the average number of coded packet transmissions needed to
recover one or more service layers. We design a convex resource allocation
framework that allows to minimize the complexity of the RLNC decoder by jointly
optimizing the transmission parameters and the sparsity of the code. The
designed optimization framework also ensures service guarantees to
predetermined fractions of users. The performance of the proposed optimization
framework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC
video services.
</dc:description>
 <dc:description>Comment: To appear on IEEE Transactions on Communications</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05892</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2015.2503398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05897</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Censoring Representations with an Adversary</dc:title>
 <dc:creator>Edwards, Harrison</dc:creator>
 <dc:creator>Storkey, Amos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In practice, there are often explicit constraints on what representations or
decisions are acceptable in an application of machine learning. For example it
may be a legal requirement that a decision must not favour a particular group.
Alternatively it can be that that representation of data must not have
identifying information. We address these two related issues by learning
flexible representations that minimize the capability of an adversarial critic.
This adversary is trying to predict the relevant sensitive variable from the
representation, and so minimizing the performance of the adversary ensures
there is little or no information in the representation about the sensitive
variable. We demonstrate this adversarial approach on two problems: making
decisions free from discrimination and removing private information from
images. We formulate the adversarial model as a minimax problem, and optimize
that minimax objective using a stochastic gradient alternate min-max optimizer.
We demonstrate the ability to provide discriminant free representations for
standard test problems, and compare with previous state of the art methods for
fairness, showing statistically significant improvement across most cases. The
flexibility of this method is shown via a novel problem: removing annotations
from images, from unaligned training examples of annotated and unannotated
images, and with no a priori knowledge of the form of annotation provided to
the model.
</dc:description>
 <dc:description>Comment: Paper accepted to ICLR</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05904</identifier>
 <datestamp>2016-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Human Body Correspondences Using Convolutional Networks</dc:title>
 <dc:creator>Wei, Lingyu</dc:creator>
 <dc:creator>Huang, Qixing</dc:creator>
 <dc:creator>Ceylan, Duygu</dc:creator>
 <dc:creator>Vouga, Etienne</dc:creator>
 <dc:creator>Li, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We propose a deep learning approach for finding dense correspondences between
3D scans of people. Our method requires only partial geometric information in
the form of two depth maps or partial reconstructed surfaces, works for humans
in arbitrary poses and wearing any clothing, does not require the two people to
be scanned from similar viewpoints, and runs in real time. We use a deep
convolutional neural network to train a feature descriptor on depth map pixels,
but crucially, rather than training the network to solve the shape
correspondence problem directly, we train it to solve a body region
classification problem, modified to increase the smoothness of the learned
descriptors near region boundaries. This approach ensures that nearby points on
the human body are nearby in feature space, and vice versa, rendering the
feature descriptor suitable for computing dense correspondences between the
scans. We validate our method on real and synthetic data for both clothed and
unclothed humans, and show that our correspondences are more robust than is
possible with state-of-the-art unsupervised methods, and more accurate than
those found using methods that require full watertight 3D geometry.
</dc:description>
 <dc:description>Comment: CVPR 2016 oral presentation</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05911</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavior Query Discovery in System-Generated Temporal Graphs</dc:title>
 <dc:creator>Zong, Bo</dc:creator>
 <dc:creator>Xiao, Xusheng</dc:creator>
 <dc:creator>Li, Zhichun</dc:creator>
 <dc:creator>Wu, Zhenyu</dc:creator>
 <dc:creator>Qian, Zhiyun</dc:creator>
 <dc:creator>Yan, Xifeng</dc:creator>
 <dc:creator>Singh, Ambuj K.</dc:creator>
 <dc:creator>Jiang, Guofei</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Computer system monitoring generates huge amounts of logs that record the
interaction of system entities. How to query such data to better understand
system behaviors and identify potential system risks and malicious behaviors
becomes a challenging task for system administrators due to the dynamics and
heterogeneity of the data. System monitoring data are essentially heterogeneous
temporal graphs with nodes being system entities and edges being their
interactions over time. Given the complexity of such graphs, it becomes
time-consuming for system administrators to manually formulate useful queries
in order to examine abnormal activities, attacks, and vulnerabilities in
computer systems.
  In this work, we investigate how to query temporal graphs and treat query
formulation as a discriminative temporal graph pattern mining problem. We
introduce TGMiner to mine discriminative patterns from system logs, and these
patterns can be taken as templates for building more complex queries. TGMiner
leverages temporal information in graphs to prune graph patterns that share
similar growth trend without compromising pattern quality. Experimental results
on real system data show that TGMiner is 6-32 times faster than baseline
methods. The discovered patterns were verified by system experts; they achieved
high precision (97%) and recall (91%).
</dc:description>
 <dc:description>Comment: The full version of the paper &quot;Behavior Query Discovery in
  System-Generated Temporal Graphs&quot;, to appear in VLDB'16</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05913</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Convergence in Semi-Anonymous Potential Games</dc:title>
 <dc:creator>Borowski, Holly</dc:creator>
 <dc:creator>Marden, Jason</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Log-linear learning has been extensively studied in both the game theoretic
and distributed control literature. It is appealing for many applications
because it often guarantees that the agents' collective behavior will converge
in probability to the optimal system configuration. However, the worst case
convergence time can be prohibitively long, i.e., exponential in the number of
players. We formalize a modified log-linear learning algorithm whose worst case
convergence time is roughly linear in the number of players. We prove this
characterization for a class of potential games where agents' utility functions
can be expressed as a function of aggregate behavior within a finite collection
of populations. Finally, we show that the convergence time remains roughly
linear in the number of players even when the players are permitted to enter
and exit the game over time.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures (including bio pictures)</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05913</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05914</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collecting and Annotating the Large Continuous Action Dataset</dc:title>
 <dc:creator>Barrett, Daniel Paul</dc:creator>
 <dc:creator>Xu, Ran</dc:creator>
 <dc:creator>Yu, Haonan</dc:creator>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We make available to the community a new dataset to support
action-recognition research. This dataset is different from prior datasets in
several key ways. It is significantly larger. It contains streaming video with
long segments containing multiple action occurrences that often overlap in
space and/or time. All actions were filmed in the same collection of
backgrounds so that background gives little clue as to action class. We had
five humans replicate the annotation of temporal extent of action occurrences
labeled with their class and measured a surprisingly low level of intercoder
agreement. A baseline experiment shows that recent state-of-the-art methods
perform poorly on this dataset. This suggests that this will be a challenging
dataset to foster advances in action-recognition research. This manuscript
serves to describe the novel content and characteristics of the LCA dataset,
present the design decisions made when filming the dataset, and document the
novel methods employed to annotate the dataset.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05926</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Neural Networks and Log-linear Models to Improve Relation
  Extraction</dc:title>
 <dc:creator>Nguyen, Thien Huu</dc:creator>
 <dc:creator>Grishman, Ralph</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The last decade has witnessed the success of the traditional feature-based
method on exploiting the discrete structures such as words or lexical patterns
to extract relations from text. Recently, convolutional and recurrent neural
networks has provided very effective mechanisms to capture the hidden
structures within sentences via continuous representations, thereby
significantly advancing the performance of relation extraction. The advantage
of convolutional neural networks is their capacity to generalize the
consecutive k-grams in the sentences while recurrent neural networks are
effective to encode long ranges of sentence context. This paper proposes to
combine the traditional feature-based method, the convolutional and recurrent
neural networks to simultaneously benefit from their advantages. Our systematic
evaluation of different network architectures and combination methods
demonstrates the effectiveness of this approach and results in the
state-of-the-art performance on the ACE 2005 and SemEval dataset.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05932</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Global Linear Convergence of Frank-Wolfe Optimization Variants</dc:title>
 <dc:creator>Lacoste-Julien, Simon</dc:creator>
 <dc:creator>Jaggi, Martin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>90C52, 90C90, 68T05</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity
thanks in particular to its ability to nicely handle the structured constraints
appearing in machine learning applications. However, its convergence rate is
known to be slow (sublinear) when the solution lies at the boundary. A simple
less-known fix is to add the possibility to take 'away steps' during
optimization, an operation that importantly does not require a feasibility
oracle. In this paper, we highlight and clarify several variants of the
Frank-Wolfe optimization algorithm that have been successfully applied in
practice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimum
norm point algorithm, and prove for the first time that they all enjoy global
linear convergence, under a weaker condition than strong convexity of the
objective. The constant in the convergence rate has an elegant interpretation
as the product of the (classical) condition number of the function with a novel
geometric quantity that plays the role of a 'condition number' of the
constraint set. We provide pointers to where these algorithms have made a
difference in practice, in particular with the flow polytope, the marginal
polytope and the base polytope for submodular optimization.
</dc:description>
 <dc:description>Comment: Appears in: Advances in Neural Information Processing Systems 28
  (NIPS 2015). 26 pages</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05933</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seeding K-Means using Method of Moments</dc:title>
 <dc:creator>Dasgupta, Sayantan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  K-means is one of the most widely used algorithms for clustering in Data
Mining applications, which attempts to minimize the sum of the square of the
Euclidean distance of the points in the clusters from the respective means of
the clusters. However, K-means suffers from local minima problem and is not
guaranteed to converge to the optimal cost. K-means++ tries to address the
problem by seeding the means using a distance-based sampling scheme. However,
seeding the means in K-means++ needs $O\left(K\right)$ sequential passes
through the entire dataset, and this can be very costly for large datasets.
Here we propose a method of seeding the initial means based on factorizations
of higher order moments for bounded data. Our method takes $O\left(1\right)$
passes through the entire dataset to extract the initial set of means, and its
final cost can be proven to be within $O(\sqrt{K})$ of the optimal cost. We
demonstrate the performance of our algorithm in comparison with the existing
algorithms on various benchmark datasets.
</dc:description>
 <dc:description>Comment: Paper contained an error in Equation 5 and 7</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05939</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric Learning with Adaptive Density Discrimination</dc:title>
 <dc:creator>Rippel, Oren</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:creator>Dollar, Piotr</dc:creator>
 <dc:creator>Bourdev, Lubomir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Distance metric learning (DML) approaches learn a transformation to a
representation space where distance is in correspondence with a predefined
notion of similarity. While such models offer a number of compelling benefits,
it has been difficult for these to compete with modern classification
algorithms in performance and even in feature extraction.
  In this work, we propose a novel approach explicitly designed to address a
number of subtle yet important issues which have stymied earlier DML
algorithms. It maintains an explicit model of the distributions of the
different classes in representation space. It then employs this knowledge to
adaptively assess similarity, and achieve local discrimination by penalizing
class distribution overlap.
  We demonstrate the effectiveness of this idea on several tasks. Our approach
achieves state-of-the-art classification results on a number of fine-grained
visual recognition datasets, surpassing the standard softmax classifier and
outperforming triplet loss by a relative margin of 30-40%. In terms of
computational performance, it alleviates training inefficiencies in the
traditional triplet loss, reaching the same error in 5-30 times fewer
iterations. Beyond classification, we further validate the saliency of the
learnt representations via their attribute concentration and hierarchy recovery
properties, achieving 10-25% relative gains on the softmax classifier and
25-50% on triplet loss in these tasks.
</dc:description>
 <dc:description>Comment: ICLR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05942</identifier>
 <datestamp>2016-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doctor AI: Predicting Clinical Events via Recurrent Neural Networks</dc:title>
 <dc:creator>Choi, Edward</dc:creator>
 <dc:creator>Bahadori, Mohammad Taha</dc:creator>
 <dc:creator>Schuetz, Andy</dc:creator>
 <dc:creator>Stewart, Walter F.</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Leveraging large historical data in electronic health record (EHR), we
developed Doctor AI, a generic predictive model that covers observed medical
conditions and medication uses. Doctor AI is a temporal model using recurrent
neural networks (RNN) and was developed and applied to longitudinal time
stamped EHR data from 260K patients over 8 years. Encounter records (e.g.
diagnosis codes, medication codes or procedure codes) were input to RNN to
predict (all) the diagnosis and medication categories for a subsequent visit.
Doctor AI assesses the history of patients to make multilabel predictions (one
label for each diagnosis or medication category). Based on separate blind test
set evaluation, Doctor AI can perform differential diagnosis with up to 79%
recall@30, significantly higher than several baselines. Moreover, we
demonstrate great generalizability of Doctor AI by adapting the resulting
models from one institution to another without losing substantial accuracy.
</dc:description>
 <dc:description>Comment: Presented at 2016 Machine Learning and Healthcare Conference (MLHC
  2016), Los Angeles, CA</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05943</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unitary-Group Invariant Kernels and Features from Transformed Unlabeled
  Data</dc:title>
 <dc:creator>Pal, Dipan K.</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The study of representations invariant to common transformations of the data
is important to learning. Most techniques have focused on local approximate
invariance implemented within expensive optimization frameworks lacking
explicit theoretical guarantees. In this paper, we study kernels that are
invariant to the unitary group while having theoretical guarantees in
addressing practical issues such as (1) unavailability of transformed versions
of labelled data and (2) not observing all transformations. We present a
theoretically motivated alternate approach to the invariant kernel SVM. Unlike
previous approaches to the invariant SVM, the proposed formulation solves both
issues mentioned. We also present a kernel extension of a recent technique to
extract linear unitary-group invariant features addressing both issues and
extend some guarantees regarding invariance and stability. We present
experiments on the UCI ML datasets to illustrate and validate our methods.
</dc:description>
 <dc:description>Comment: 11 page main paper (including references), 2 page supplementary, for
  a total of 13 pages. Submitted for review at ICLR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05946</identifier>
 <datestamp>2016-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ACDC: A Structured Efficient Linear Layer</dc:title>
 <dc:creator>Moczulski, Marcin</dc:creator>
 <dc:creator>Denil, Misha</dc:creator>
 <dc:creator>Appleyard, Jeremy</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The linear layer is one of the most pervasive modules in deep learning
representations. However, it requires $O(N^2)$ parameters and $O(N^2)$
operations. These costs can be prohibitive in mobile applications or prevent
scaling in many domains. Here, we introduce a deep, differentiable,
fully-connected neural network module composed of diagonal matrices of
parameters, $\mathbf{A}$ and $\mathbf{D}$, and the discrete cosine transform
$\mathbf{C}$. The core module, structured as $\mathbf{ACDC^{-1}}$, has $O(N)$
parameters and incurs $O(N log N )$ operations. We present theoretical results
showing how deep cascades of ACDC layers approximate linear layers. ACDC is,
however, a stand-alone module and can be used in combination with any other
types of module. In our experiments, we show that it can indeed be successfully
interleaved with ReLU modules in convolutional neural networks for image
recognition. Our experiments also study critical factors in the training of
these structured modules, including initialization and depth. Finally, this
paper also provides a connection between structured linear transforms used in
deep learning and the field of Fourier optics, illustrating how ACDC could in
principle be implemented with lenses and diffractive elements.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05950</identifier>
 <datestamp>2016-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Staleness-aware Async-SGD for Distributed Deep Learning</dc:title>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Gupta, Suyog</dc:creator>
 <dc:creator>Lian, Xiangru</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks have been shown to achieve state-of-the-art performance
in several machine learning tasks. Stochastic Gradient Descent (SGD) is the
preferred optimization algorithm for training these networks and asynchronous
SGD (ASGD) has been widely adopted for accelerating the training of large-scale
deep networks in a distributed computing environment. However, in practice it
is quite challenging to tune the training hyperparameters (such as learning
rate) when using ASGD so as achieve convergence and linear speedup, since the
stability of the optimization algorithm is strongly influenced by the
asynchronous nature of parameter updates. In this paper, we propose a variant
of the ASGD algorithm in which the learning rate is modulated according to the
gradient staleness and provide theoretical guarantees for convergence of this
algorithm. Experimental verification is performed on commonly-used image
classification benchmarks: CIFAR10 and Imagenet to demonstrate the superior
effectiveness of the proposed approach, compared to SSGD (Synchronous SGD) and
the conventional ASGD algorithm.
</dc:description>
 <dc:description>Comment: Accepted by IJCAI 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05952</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prioritized Experience Replay</dc:title>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>Quan, John</dc:creator>
 <dc:creator>Antonoglou, Ioannis</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Experience replay lets online reinforcement learning agents remember and
reuse experiences from the past. In prior work, experience transitions were
uniformly sampled from a replay memory. However, this approach simply replays
transitions at the same frequency that they were originally experienced,
regardless of their significance. In this paper we develop a framework for
prioritizing experience, so as to replay important transitions more frequently,
and therefore learn more efficiently. We use prioritized experience replay in
Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved
human-level performance across many Atari games. DQN with prioritized
experience replay achieves a new state-of-the-art, outperforming DQN with
uniform replay on 41 out of 49 games.
</dc:description>
 <dc:description>Comment: Published at ICLR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05952</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05957</identifier>
 <datestamp>2016-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supplementary Materials for &quot;How to Avoid Reidentification with Proper
  Anonymization&quot;- Comment on &quot;Unique in the shopping mall: on the
  reidentifiability of credit card metadata&quot;</dc:title>
 <dc:creator>S&#xe1;nchez, David</dc:creator>
 <dc:creator>Mart&#xed;nez, Sergio</dc:creator>
 <dc:creator>Domingo-Ferrer, Josep</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:description>  The study by De Montjoye et al. (&quot;Science&quot;, 30 January 2015, p. 536) claimed
that most individuals can be reidentified from a deidentified credit card
transaction database and that anonymization mechanisms are not effective
against reidentification. Such claims deserve detailed quantitative scrutiny,
as they might seriously undermine the willingness of data owners and subjects
to share data for research. In a recent Technical Comment published in
&quot;Science&quot; (18 March 2016, p. 1274), we demonstrate that the reidentification
risk reported by De Montjoye et al. was significantly overestimated (due to a
misunderstanding of the reidentification attack) and that the alleged
ineffectiveness of anonymization is due to the choice of poor and undocumented
methods and to a general disregard of 40 years of anonymization literature. The
technical comment also shows how to properly anonymize data, in order to reduce
unequivocal reidentifications to zero while retaining even more analytical
utility than with the poor anonymization mechanisms employed by De Montjoye et
al. In conclusion, data owners, subjects and users can be reassured that sound
privacy models and anonymization methods exist to produce safe and useful
anonymized data.
  Supplementary materials detailing the data sets, algorithms and extended
results of our study are available here. Moreover, unlike the De Montjoye et
al.'s data set, which was never made available, our data, anonymized results,
and anonymization algorithms can be freely downloaded from
http://crises-deim.urv.cat/opendata/SPD_Science.zip
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05957</dc:identifier>
 <dc:identifier>Supplementary materials to &quot;Comment on &quot;Unique in the shopping
  mall: on the reidentifiability of credit card metadata&quot;&quot;, Science, Vol. 351,
  Issue 6279, p. 1274, 18 Mar. 2016.
  http://science.sciencemag.org/content/351/6279/1274.1.full</dc:identifier>
 <dc:identifier>doi:10.1126/science.aad9295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05958</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Design, Scaling, and Control of Appendages for Inertial
  Reorientation</dc:title>
 <dc:creator>Libby, Thomas</dc:creator>
 <dc:creator>Johnson, Aaron M.</dc:creator>
 <dc:creator>Chang-Siu, Evan</dc:creator>
 <dc:creator>Full, Robert J.</dc:creator>
 <dc:creator>Koditschek, D. E.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper develops a comparative framework for the design of actuated
inertial appendages for planar, aerial reorientation. We define the Inertial
Reorientation template, the simplest model of this behavior, and leverage its
linear dynamics to reveal the design constraints linking a task with the body
designs capable of completing it. As practicable inertial appendage designs
lead to morphology that is generally more complex, we advance a notion of
&quot;anchoring&quot; whereby a judicious choice of physical design in concert with an
appropriate control policy yields a system whose closed loop dynamics are
sufficiently captured by the template as to permit all further design to take
place in its far simpler parameter space. This approach is effective and
accurate over the diverse design spaces afforded by existing platforms,
enabling performance comparison through the shared task space. We analyze
examples from the literature and find advantages to each body type, but
conclude that tails provide the highest potential performance for reasonable
designs. Thus motivated, we build a physical example by retrofitting a tail to
a RHex robot and present empirical evidence of its efficacy.
</dc:description>
 <dc:description>Comment: Technical report included at the end of this file</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05958</dc:identifier>
 <dc:identifier>IEEE Transactions on Robotics, vol. 32, no. 6, pp. 1380-1398, Dec.
  2016</dc:identifier>
 <dc:identifier>doi:10.1109/TRO.2016.2597316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05960</identifier>
 <datestamp>2016-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ABC-CNN: An Attention Based Convolutional Neural Network for Visual
  Question Answering</dc:title>
 <dc:creator>Chen, Kan</dc:creator>
 <dc:creator>Wang, Jiang</dc:creator>
 <dc:creator>Chen, Liang-Chieh</dc:creator>
 <dc:creator>Gao, Haoyuan</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:creator>Nevatia, Ram</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel attention based deep learning architecture for visual
question answering task (VQA). Given an image and an image related natural
language question, VQA generates the natural language answer for the question.
Generating the correct answers requires the model's attention to focus on the
regions corresponding to the question, because different questions inquire
about the attributes of different image regions. We introduce an attention
based configurable convolutional neural network (ABC-CNN) to learn such
question-guided attention. ABC-CNN determines an attention map for an
image-question pair by convolving the image feature map with configurable
convolutional kernels derived from the question's semantics. We evaluate the
ABC-CNN architecture on three benchmark VQA datasets: Toronto COCO-QA, DAQUAR,
and VQA dataset. ABC-CNN model achieves significant improvements over
state-of-the-art methods on these datasets. The question-guided attention
generated by ABC-CNN is also shown to reflect the regions that are highly
relevant to the questions.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05986</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing with Harmonic Functions</dc:title>
 <dc:creator>Axler, Sheldon</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>31B05, 31B20</dc:subject>
 <dc:description>  This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions.
</dc:description>
 <dc:description>Comment: 77 pages. Software available at http://axler.net/HFT_Math.html</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05987</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Communication Problems for Mobile Agents Exchanging
  Energy</dc:title>
 <dc:creator>Czyzowicz, Jerzy</dc:creator>
 <dc:creator>Diks, Krzysztof</dc:creator>
 <dc:creator>Moussi, Jean</dc:creator>
 <dc:creator>Rytter, Wojciech</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider communication problems in the setting of mobile agents deployed
in an edge-weighted network. The assumption of the paper is that each agent has
some energy that it can transfer to any other agent when they meet (together
with the information it holds).
  The paper deals with three communication problems: data delivery,convergecast
and broadcast. These problems are posed for a centralized scheduler which has
full knowledge of the instance.
  It is already known that, without energy exchange, all three problems are
NP-complete even if the network is a line. Surprisingly, if we allow the agents
to exchange energy, we show that all three problems are polynomially solvable
on trees and have linear time algorithms on the line. On the other hand for
general undirected and directed graphs we show that these problems, even if
energy exchange is allowed, are still NP-complete.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05996</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncertainty-based Arbitration of Human-Machine Shared Control</dc:title>
 <dc:creator>Owan, Parker</dc:creator>
 <dc:creator>Garbini, Joseph</dc:creator>
 <dc:creator>Devasia, Santosh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>93C85 (primary), 68T40 (secondary)</dc:subject>
 <dc:description>  Manufacturing requires consistent production rate and task success for
sustainable operation. Some manufacturing tasks require a semi-autonomous
approach, exploiting the combination of human adaptability and machine
precision and speed, to be cost effective. The main contribution of this paper
is a new approach to determine the level of autonomy for human-machine shared
control based on the automation uncertainty. Moreover, the haptic feedback is
scaled by the level of autonomy to indicate machine confidence to the operator.
Experimentation results, with a human-robot peg-in-a-hole testbed, show more
than 5 times improvement in the error tolerance for task completion with the
shared control approach when compared to a purely autonomous method.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures. Submitted to the 2016 American Control
  Conference</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.05996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06000</identifier>
 <datestamp>2016-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Duality Based 2-Approximation Algorithm for Maximum Agreement Forest</dc:title>
 <dc:creator>Schalekamp, Frans</dc:creator>
 <dc:creator>van Zuylen, Anke</dc:creator>
 <dc:creator>van der Ster, Suzanne</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a 2-approximation algorithm for the Maximum Agreement Forest problem
on two rooted binary trees. This NP-hard problem has been studied extensively
in the past two decades, since it can be used to compute the Subtree
Prune-and-Regraft (SPR) distance between two phylogenetic trees. Our result
improves on the very recent 2.5-approximation algorithm due to Shi, Feng, You
and Wang (2015). Our algorithm is the first approximation algorithm for this
problem that uses LP duality in its analysis.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06001</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A pilot study on the daily control capability of s-EMG prosthetic hands
  by amputees</dc:title>
 <dc:creator>Giordaniello, Francesca</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Surface electromyography is a valid tool to gather muscular contraction
signals from intact and amputated subjects. Electromyographic signals can be
used to control prosthetic devices in a noninvasive way distinguishing the
movements performed by the particular EMG electrodes activity. According to the
literature, several algorithms have been used to control prosthetic hands
through s-EMG signals. The main issue is to correctly classify the signals
acquired as the movement actually performed. This work presents a study on the
Support Vector Machine's performance in a short-time period, gained using two
different feature representation (Mean Absolute Value and Waveform Length) of
the sEMG signals. In particular, we paid close attention to the repeatability
problem, that is the capability to achieve a stable and satisfactory level of
accuracy in repeated experiments. Results on a limited setting are encouraging,
as they show an average accuracy above 73% even in the worst case scenario.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06004</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Studying the control of non invasive prosthetic hands over large time
  spans</dc:title>
 <dc:creator>Graziani, Mara</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The electromyography (EMG) signal is the electrical manifestation of a
neuromuscular activation that provides access to physiological processes which
cause the muscle to generate force and produce movement. Non invasive
prostheses use such signals detected by the electrodes placed on the user's
stump, as input to generate hand posture movements according to the intentions
of the prosthesis wearer. The aim of this pilot study is to explore the
repeatability issue, i.e. the ability to classify 17 different hand postures,
represented by EMG signal, across a time span of days by a control algorithm.
Data collection experiments lasted four days and signals were collected from
the forearm of a single subject. We find that Support Vector Machine (SVM)
classification results are high enough to guarantee a correct classification of
more than 10 postures in each moment of the considered time span.
</dc:description>
 <dc:description>Comment: 10 pages, 18 figures, 8 tables</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06014</identifier>
 <datestamp>2016-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regret Analysis of the Finite-Horizon Gittins Index Strategy for
  Multi-Armed Bandits</dc:title>
 <dc:creator>Lattimore, Tor</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  I analyse the frequentist regret of the famous Gittins index strategy for
multi-armed bandits with Gaussian noise and a finite horizon. Remarkably it
turns out that this approach leads to finite-time regret guarantees comparable
to those available for the popular UCB algorithm. Along the way I derive
finite-time bounds on the Gittins index that are asymptotically exact and may
be of independent interest. I also discuss some computational issues and
present experimental results suggesting that a particular version of the
Gittins index strategy is a modest improvement on existing algorithms with
finite-time regret guarantees such as UCB and Thompson sampling.
</dc:description>
 <dc:description>Comment: 32 pages, to appear in COLT 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06015</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Object Localization with Deep Reinforcement Learning</dc:title>
 <dc:creator>Caicedo, Juan C.</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an active detection model for localizing objects in scenes. The
model is class-specific and allows an agent to focus attention on candidate
regions for identifying the correct location of a target object. This agent
learns to deform a bounding box using simple transformation actions, with the
goal of determining the most specific location of target objects following
top-down reasoning. The proposed localization agent is trained using deep
reinforcement learning, and evaluated on the Pascal VOC 2007 dataset. We show
that agents guided by the proposed model are able to localize a single instance
of an object after analyzing only between 11 and 25 regions in an image, and
obtain the best detection results among systems that do not use object
proposals for object localization.
</dc:description>
 <dc:description>Comment: IEEE ICCV 2015</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06017</identifier>
 <datestamp>2016-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rate of Price Discovery in Iterative Combinatorial Auctions</dc:title>
 <dc:creator>Abernethy, Jacob</dc:creator>
 <dc:creator>Lahaie, S&#xe9;bastien</dc:creator>
 <dc:creator>Telgarsky, Matus</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study a class of iterative combinatorial auctions which can be viewed as
subgradient descent methods for the problem of pricing bundles to balance
supply and demand. We provide concrete convergence rates for auctions in this
class, bounding the number of auction rounds needed to reach clearing prices.
Our analysis allows for a variety of pricing schemes, including item, bundle,
and polynomial pricing, and the respective convergence rates confirm that more
expressive pricing schemes come at the cost of slower convergence. We consider
two models of bidder behavior. In the first model, bidders behave
stochastically according to a random utility model, which includes standard
best-response bidding as a special case. In the second model, bidders behave
arbitrarily (even adversarially), and meaningful convergence relies on properly
designed activity rules.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06018</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmental Recurrent Neural Networks</dc:title>
 <dc:creator>Kong, Lingpeng</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce segmental recurrent neural networks (SRNNs) which define, given
an input sequence, a joint probability distribution over segmentations of the
input and labelings of the segments. Representations of the input segments
(i.e., contiguous subsequences of the input) are computed by encoding their
constituent tokens using bidirectional recurrent neural nets, and these
&quot;segment embeddings&quot; are used to define compatibility scores with output
labels. These local compatibility scores are integrated using a global
semi-Markov conditional random field. Both fully supervised training -- in
which segment boundaries and labels are observed -- as well as partially
supervised training -- in which segment boundaries are latent -- are
straightforward. Experiments on handwriting recognition and joint Chinese word
segmentation/POS tagging show that, compared to models that do not explicitly
represent segments such as BIO tagging schemes and connectionist temporal
classification (CTC), SRNNs obtain substantially higher accuracies.
</dc:description>
 <dc:description>Comment: 10 pages, published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06022</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulating Branching Programs with Edit Distance and Friends or: A
  Polylog Shaved is a Lower Bound Made</dc:title>
 <dc:creator>Abboud, Amir</dc:creator>
 <dc:creator>Hansen, Thomas Dueholm</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:creator>Williams, Ryan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A recent and active line of work achieves tight lower bounds for fundamental
problems under the Strong Exponential Time Hypothesis (SETH). A celebrated
result of Backurs and Indyk (STOC'15) proves that the Edit Distance of two
sequences of length n cannot be computed in strongly subquadratic time under
SETH. The result was extended by follow-up works to simpler looking problems
like finding the Longest Common Subsequence (LCS).
  SETH is a very strong assumption, asserting that even linear size CNF
formulas cannot be analyzed for satisfiability with an exponential speedup over
exhaustive search. We consider much safer assumptions, e.g. that such a speedup
is impossible for SAT on much more expressive representations, like NC
circuits. Intuitively, this seems much more plausible: NC circuits can
implement complex cryptographic primitives, while CNFs cannot even
approximately compute an XOR of bits.
  Our main result is a surprising reduction from SAT on Branching Programs to
fundamental problems in P like Edit Distance, LCS, and many others. Truly
subquadratic algorithms for these problems therefore have consequences that we
consider to be far more remarkable than merely faster CNF SAT algorithms. For
example, SAT on arbitrary o(n)-depth bounded fan-in circuits (and therefore
also NC-Circuit-SAT) can be solved in (2-eps)^n time.
  A very interesting feature of our work is that we can prove major
consequences even from mildly subquadratic algorithms for Edit Distance or LCS.
For example, we show that if we can shave an arbitrarily large polylog factor
from n^2 for Edit Distance then NEXP does not have non-uniform NC^1 circuits. A
more fine-grained examination shows that even shaving a $\log^c{n}$ factor, for
a specific constant $c \approx 10^3$, already implies new circuit lower bounds.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06029</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tensor-Train accelerated solver for integral equations in complex
  geometries</dc:title>
 <dc:creator>Corona, Eduardo</dc:creator>
 <dc:creator>Rahimian, Abtin</dc:creator>
 <dc:creator>Zorin, Denis</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We present a framework using the Quantized Tensor Train (QTT) decomposition
to accurately and efficiently solve volume and boundary integral equations in
three dimensions. We describe how the QTT decomposition can be used as a
hierarchical compression and inversion scheme for matrices arising from the
discretization of integral equations. For a broad range of problems,
computational and storage costs of the inversion scheme are extremely modest
$O(\log N)$ and once the inverse is computed, it can be applied in $O(N \log
N)$.
  We analyze the QTT ranks for hierarchically low rank matrices and discuss its
relationship to commonly used hierarchical compression techniques such as FMM
and HSS. We prove that the QTT ranks are bounded for translation-invariant
systems and argue that this behavior extends to non-translation invariant
volume and boundary integrals.
  For volume integrals, the QTT decomposition provides an efficient direct
solver requiring significantly less memory compared to other fast direct
solvers. We present results demonstrating the remarkable performance of the
QTT-based solver when applied to both translation and non-translation invariant
volume integrals in 3D.
  For boundary integral equations, we demonstrate that using a QTT
decomposition to construct preconditioners for a Krylov subspace method leads
to an efficient and robust solver with a small memory footprint. We test the
QTT preconditioners in the iterative solution of an exterior elliptic boundary
value problem (Laplace) formulated as a boundary integral equation in complex,
multiply connected geometries.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06030</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BIRDNEST: Bayesian Inference for Ratings-Fraud Detection</dc:title>
 <dc:creator>Hooi, Bryan</dc:creator>
 <dc:creator>Shah, Neil</dc:creator>
 <dc:creator>Beutel, Alex</dc:creator>
 <dc:creator>Gunnemann, Stephan</dc:creator>
 <dc:creator>Akoglu, Leman</dc:creator>
 <dc:creator>Kumar, Mohit</dc:creator>
 <dc:creator>Makhija, Disha</dc:creator>
 <dc:creator>Faloutsos, Christos</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Review fraud is a pervasive problem in online commerce, in which fraudulent
sellers write or purchase fake reviews to manipulate perception of their
products and services. Fake reviews are often detected based on several signs,
including 1) they occur in short bursts of time; 2) fraudulent user accounts
have skewed rating distributions. However, these may both be true in any given
dataset. Hence, in this paper, we propose an approach for detecting fraudulent
reviews which combines these 2 approaches in a principled manner, allowing
successful detection even when one of these signs is not present. To combine
these 2 approaches, we formulate our Bayesian Inference for Rating Data (BIRD)
model, a flexible Bayesian model of user rating behavior. Based on our model we
formulate a likelihood-based suspiciousness metric, Normalized Expected
Surprise Total (NEST). We propose a linear-time algorithm for performing
Bayesian inference using our model and computing the metric. Experiments on
real data show that BIRDNEST successfully spots review fraud in large,
real-world graphs: the 50 most suspicious users of the Flipkart platform
flagged by our algorithm were investigated and all identified as fraudulent by
domain experts at Flipkart.
</dc:description>
 <dc:description>Comment: 9 pages; v2: minor typos corrected</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06033</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EigenRec: Generalizing PureSVD for Effective and Efficient Top-N
  Recommendations</dc:title>
 <dc:creator>Nikolakopoulos, Athanasios N.</dc:creator>
 <dc:creator>Kalantzis, Vassilis</dc:creator>
 <dc:creator>Gallopoulos, Efstratios</dc:creator>
 <dc:creator>Garofalakis, John D.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:description>  We introduce EigenRec; a versatile and efficient Latent-Factor framework for
Top-N Recommendations that includes the well-known PureSVD algorithm as a
special case. EigenRec builds a low dimensional model of an inter-item
proximity matrix that combines a similarity component, with a scaling operator,
designed to control the influence of the prior item popularity on the final
model. Seeing PureSVD within our framework provides intuition about its inner
workings, exposes its inherent limitations, and also, paves the path towards
painlessly improving its recommendation performance. A comprehensive set of
experiments on the MovieLens and the Yahoo datasets based on widely applied
performance metrics, indicate that EigenRec outperforms several
state-of-the-art algorithms, in terms of Standard and Long-Tail recommendation
accuracy, exhibiting low susceptibility to sparsity, even in its most extreme
manifestations -- the Cold-Start problems. At the same time EigenRec has an
attractive computational profile and it can apply readily in large-scale
recommendation settings.
</dc:description>
 <dc:description>Comment: 23 pages. Journal version of the conference paper &quot;Factored Proximity
  Models for Top-N Recommendation&quot;</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06034</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Locally Repairable Codes ---Sequential Repair for Multiple
  Erasures</dc:title>
 <dc:creator>Song, Wentu</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Locally repairable codes (LRC) for distribute storage allow two approaches to
locally repair multiple failed nodes: 1) parallel approach, by which each
newcomer access a set of $r$ live nodes $(r$ is the repair locality$)$ to
download data and recover the lost packet; and 2) sequential approach, by which
the newcomers are properly ordered and each newcomer access a set of $r$ other
nodes, which can be either a live node or a newcomer ordered before it. An
$[n,k]$ linear code with locality $r$ and allows local repair for up to $t$
failed nodes by sequential approach is called an $(n,k,r,t)$-exact locally
repairable code (ELRC).
  In this paper, we present a family of binary codes which is equivalent to the
direct product of $m$ copies of the $[r+1,r]$ single-parity-check code. We
prove that such codes are $(n,k,r,t)$-ELRC with $n=(r+1)^m,k=r^m$ and
$t=2^m-1$, which implies that they permit local repair for up to $2^m-1$
erasures by sequential approach. Our result shows that the sequential approach
has much bigger advantage than parallel approach.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06035</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Malthusian Locks</dc:title>
 <dc:creator>Dice, Dave</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>D.4.1</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Applications running in modern multithreaded environments are sometimes
\emph{over-threaded}. The excess threads do not improve performance, and in
fact may act to degrade performance via \emph{scalability collapse}. Often,
such software also has highly contended locks. We opportunistically leverage
the existence of such locks by modifying the lock admission policy so as to
intentionally limit the number of threads circulating over the lock in a given
period. Specifically, if there are more threads circulating than are necessary
to keep the lock saturated, our approach will selectively cull and passivate
some of those threads. We borrow the concept of \emph{swapping} from the field
of memory management and intentionally impose \emph{concurrency restriction}
(CR) if a lock is oversubscribed. In the worst case CR does no harm, but it
often yields performance benefits. The resultant admission order is unfair over
the short term but we explicitly provide long-term fairness by periodically
shifting threads between the set of passivated threads and those actively
circulating. Our approach is palliative, but often effective.
</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06036</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic gradient method with accelerated stochastic dynamics</dc:title>
 <dc:creator>Ohzeki, Masayuki</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel technique to implement stochastic gradient
methods, which are beneficial for learning from large datasets, through
accelerated stochastic dynamics. A stochastic gradient method is based on
mini-batch learning for reducing the computational cost when the amount of data
is large. The stochasticity of the gradient can be mitigated by the injection
of Gaussian noise, which yields the stochastic Langevin gradient method; this
method can be used for Bayesian posterior sampling. However, the performance of
the stochastic Langevin gradient method depends on the mixing rate of the
stochastic dynamics. In this study, we propose violating the detailed balance
condition to enhance the mixing rate. Recent studies have revealed that
violating the detailed balance condition accelerates the convergence to a
stationary state and reduces the correlation time between the samplings. We
implement this violation of the detailed balance condition in the stochastic
gradient Langevin method and test our method for a simple model to demonstrate
its performance.
</dc:description>
 <dc:description>Comment: 12 pages, proceedings for International Meeting on High-Dimensional
  Data Driven Science (HD3-2015)
  (http://www.sparse-modeling.jp/HD3-2015/index_e.html)</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06036</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/699/1/012019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06037</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enumeration and Random Generation of Unlabeled Classes of Graphs: A
  Practical Study of Cycle Pointing and the Dissymmetry Theorem</dc:title>
 <dc:creator>Iriza, Alexander</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Our work studies the enumeration and random generation of unlabeled
combinatorial classes of unrooted graphs. While the technique of vertex
pointing provides a straightforward procedure for analyzing a labeled class of
unrooted graphs by first studying its rooted counterpart, the existence of
nontrivial symmetries in the unlabeled case causes this technique to break
down. Instead, techniques such as the dissymmetry theorem (of Otter) and cycle
pointing (of Bodirsky et al.) have emerged in the unlabeled case, with the
former providing an enumeration of the class and the latter providing both an
enumeration and an unbiased sampler. In this work, we extend the power of the
dissymmetry theorem by showing that it in fact provides a Boltzmann sampler for
the class in question. We then present an exposition of the cycle pointing
technique, with a focus on the enumeration and random generation of the
underlying unpointed class. Finally, we apply cycle pointing to enumerate and
implement samplers for the classes of distance-hereditary graphs and three-leaf
power graphs.
</dc:description>
 <dc:description>Comment: 59 pages, 43 figures. Master's thesis, supervised by J\'er\'emie
  Lumbroso and Robert Sedgewick. Full code available at
  https://github.com/alexiriza/unlabeled-graph-samplers</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06038</identifier>
 <datestamp>2016-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Variational Inference for Text Processing</dc:title>
 <dc:creator>Miao, Yishu</dc:creator>
 <dc:creator>Yu, Lei</dc:creator>
 <dc:creator>Blunsom, Phil</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent advances in neural variational inference have spawned a renaissance in
deep latent variable models. In this paper we introduce a generic variational
inference framework for generative and conditional models of text. While
traditional variational methods derive an analytic approximation for the
intractable distributions over latent variables, here we construct an inference
network conditioned on the discrete text input to provide the variational
distribution. We validate this framework on two very different text modelling
applications, generative document modelling and supervised question answering.
Our neural variational document model combines a continuous stochastic document
representation with a bag-of-words generative model and achieves the lowest
reported perplexities on two standard test corpora. The neural answer selection
model employs a stochastic representation layer within an attention mechanism
to extract the semantics between a question and answer pair. On two question
answering benchmarks this model exceeds all previous published benchmarks.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06040</identifier>
 <datestamp>2016-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hierarchical Deep Temporal Model for Group Activity Recognition</dc:title>
 <dc:creator>Ibrahim, Moustafa</dc:creator>
 <dc:creator>Muralidharan, Srikanth</dc:creator>
 <dc:creator>Deng, Zhiwei</dc:creator>
 <dc:creator>Vahdat, Arash</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In group activity recognition, the temporal dynamics of the whole activity
can be inferred based on the dynamics of the individual people representing the
activity. We build a deep model to capture these dynamics based on LSTM
(long-short term memory) models. To make use of these ob- servations, we
present a 2-stage deep temporal model for the group activity recognition
problem. In our model, a LSTM model is designed to represent action dynamics of
in- dividual people in a sequence and another LSTM model is designed to
aggregate human-level information for whole activity understanding. We evaluate
our model over two datasets: the collective activity dataset and a new volley-
ball dataset. Experimental results demonstrate that our proposed model improves
group activity recognition perfor- mance with compared to baseline methods.
</dc:description>
 <dc:description>Comment: cs.cv Accepted to CVPR 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06049</identifier>
 <datestamp>2016-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Objective Does Self-paced Learning Indeed Optimize?</dc:title>
 <dc:creator>Meng, Deyu</dc:creator>
 <dc:creator>Zhao, Qian</dc:creator>
 <dc:creator>Jiang, Lu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-paced learning (SPL) is a recently raised methodology designed through
simulating the learning principle of humans/animals. A variety of SPL
realization schemes have been designed for different computer vision and
pattern recognition tasks, and empirically substantiated to be effective in
these applications. However, the investigation on its theoretical insight is
still a blank. To this issue, this study attempts to provide some new
theoretical understanding under the SPL scheme. Specifically, we prove that the
solving strategy on SPL accords with a majorization minimization algorithm
implemented on a latent objective function. Furthermore, we find that the loss
function contained in this latent objective has a similar configuration with
non-convex regularized penalty (NSPR) known in statistics and machine learning.
Such connection inspires us discovering more intrinsic relationship between SPL
regimes and NSPR forms, like SCAD, LOG and EXP. The robustness insight under
SPL can then be finely explained. We also analyze the capability of SPL on its
easy loss prior embedding property, and provide an insightful interpretation to
the effectiveness mechanism under previous SPL variations. Besides, we design a
group-partial-order loss prior, which is especially useful to weakly labeled
large-scale data processing tasks. Through applying SPL with this loss prior to
the FCVID dataset, which is currently one of the biggest manually annotated
video dataset, our method achieves state-of-the-art performance beyond previous
methods, which further helps supports the proposed theoretical arguments.
</dc:description>
 <dc:description>Comment: 25 pages, 1 figures</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06051</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SparkNet: Training Deep Networks in Spark</dc:title>
 <dc:creator>Moritz, Philipp</dc:creator>
 <dc:creator>Nishihara, Robert</dc:creator>
 <dc:creator>Stoica, Ion</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Training deep networks is a time-consuming process, with networks for object
recognition often requiring multiple days to train. For this reason, leveraging
the resources of a cluster to speed up training is an important area of work.
However, widely-popular batch-processing computational frameworks like
MapReduce and Spark were not designed to support the asynchronous and
communication-intensive workloads of existing distributed deep learning
systems. We introduce SparkNet, a framework for training deep networks in
Spark. Our implementation includes a convenient interface for reading data from
Spark RDDs, a Scala interface to the Caffe deep learning framework, and a
lightweight multi-dimensional tensor library. Using a simple parallelization
scheme for stochastic gradient descent, SparkNet scales well with the cluster
size and tolerates very high-latency communication. Furthermore, it is easy to
deploy and use with no parameter tuning, and it is compatible with existing
Caffe models. We quantify the dependence of the speedup obtained by SparkNet on
the number of machines, the communication frequency, and the cluster's
communication overhead, and we benchmark our system's performance on the
ImageNet dataset.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06052</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcoming Language Variation in Sentiment Analysis with Social
  Attention</dc:title>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:creator>Eisenstein, Jacob</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Variation in language is ubiquitous, particularly in newer forms of writing
such as social media. Fortunately, variation is not random, it is often linked
to social properties of the author. In this paper, we show how to exploit
social networks to make sentiment analysis more robust to social language
variation. The key idea is linguistic homophily: the tendency of socially
linked individuals to use language in similar ways. We formalize this idea in a
novel attention-based neural network architecture, in which attention is
divided among several basis models, depending on the author's position in the
social network. This has the effect of smoothing the classification function
across the social network, and makes it possible to induce personalized
classifiers even for authors for whom there is no labeled data or demographic
metadata. This model significantly improves the accuracies of sentiment
analysis on Twitter and on review data.
</dc:description>
 <dc:description>Comment: Published in Transactions of the Association for Computational
  Linguistics (TACL), 2017. Please cite the TACL version:
  https://transacl.org/ojs/index.php/tacl/article/view/1024</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06053</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing for Collaborative Sensemaking: Using Expert &amp; Non-Expert Crowd</dc:title>
 <dc:creator>Goyal, Nitesh</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Crime solving is a domain where solution discovery is often serendipitous.
Unstructured mechanisms, like Reddit, for crime solving through crowds have
failed so far. Mechanisms, collaborations, workflows, and micro-tasks necessary
for successful crime solving might also vary across different crimes.
Cognitively, while experts might have deeper domain knowledge, they might also
fall prey to biased analysis. Non-experts, while lacking formal training, might
instead offer non-conventional perspectives requiring direction. The analytical
process is itself an iterative process of foraging and sensemaking. Users would
explore to broaden solution space and narrow down to a solution iteratively
until identifying the global maxima instead of local maxima. In this proposal,
my research aims to design systems for enabling complex sensemaking tasks that
require collaboration between remotely located non-expert crowds with expert
crowds to compensate for their cognitive challenges and lack of training. This
would require better understanding of the structure, workflow, and micro-tasks
necessary for successful collaborations. This proposal builds upon previous
work on collaborative sensemaking between remote partners in lab experiments
and endeavors to scale it across multiple team members, with varying expertise
levels.
</dc:description>
 <dc:description>Comment: conference in Companion of The Third AAAI Conference on Human
  Computation and Crowdsourcing (HCOMP-2015). arXiv admin note: substantial
  text overlap with arXiv:1511.05737</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06061</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Min-O-Mee: A Proximity Based Network Application Leveraging The AllJoyn
  Framework</dc:title>
 <dc:creator>Lokhandwala, Hatim</dc:creator>
 <dc:creator>Kala, Srikant Manas</dc:creator>
 <dc:creator>Tamma, Bheemarjuna Reddy</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Close proximity of mobile devices can be utilized to create ad hoc and
dynamic networks. These mobile Proximity Based Networks (PBNs) are
Opportunistic Networks that enable devices to identify and communicate with
each other without relying on any communication infrastructure. In addition,
these networks are self organizing, highly dynamic and facilitate effective
real-time communication. These characteristics render them very useful in a
wide variety of complex scenarios such as vehicular communication, e-health,
disaster networks, mobile social networks etc. In this work we employ the
AllJoyn framework from Qualcomm which facilitates smooth discovery, attachment
and data sharing between devices in close proximity. We develop
\textit{Min-O-Mee}, a Minutes-of-Meeting app prototype in the Android platform,
utilizing the AllJoyn framework. Min-O-Mee allows one of the participants to
create a minutes-of-meeting document which can be shared with and edited by the
other participants in the meeting. The app harnesses the spatial proximity of
participants in a meeting and enables seamless data exchange between them. This
characteristic allows Min-O-Mee to share not just minutes-of-meeting, but any
data that needs to be exchanged among the participants, making it a versatile
app. Further, we extend the basic AllJoyn framework to enable multi-hop
communication among the devices in the PBN. We devise a novel routing mechanism
that is suited to a proximity centric wireless network as it facilitates data
routing and delivery over several hops to devices that are at the fringe of the
PBN.
</dc:description>
 <dc:description>Comment: Accepted in 2015 International Conference on Computing and Network
  Communications (CoCoNet'15) (IEEE)</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06061</dc:identifier>
 <dc:identifier>doi:10.1109/CoCoNet.2015.7411252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06062</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Bilinear Pooling</dc:title>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Beijbom, Oscar</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Bilinear models has been shown to achieve impressive performance on a wide
range of visual tasks, such as semantic segmentation, fine grained recognition
and face recognition. However, bilinear features are high dimensional,
typically on the order of hundreds of thousands to a few million, which makes
them impractical for subsequent analysis. We propose two compact bilinear
representations with the same discriminative power as the full bilinear
representation but with only a few thousand dimensions. Our compact
representations allow back-propagation of classification errors enabling an
end-to-end optimization of the visual recognition system. The compact bilinear
representations are derived through a novel kernelized analysis of bilinear
pooling which provide insights into the discriminative power of bilinear
pooling, and a platform for further research in compact pooling methods.
Experimentation illustrate the utility of the proposed representations for
image classification and few-shot learning across several datasets.
</dc:description>
 <dc:description>Comment: Camera ready version for CVPR</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06063</identifier>
 <datestamp>2016-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Approach for Phase Identification in Smart Grids Using Graph
  Theory and Principal Component Analysis</dc:title>
 <dc:creator>Jayadev, P Satya</dc:creator>
 <dc:creator>Rajeswaran, Aravind</dc:creator>
 <dc:creator>Bhatt, Nirav P</dc:creator>
 <dc:creator>Pasumarthy, Ramkrishna</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Consumers with low demand, like households, are generally supplied
single-phase power by connecting their service mains to one of the phases of a
distribution transformer. The distribution companies face the problem of
keeping a record of consumer connectivity to a phase due to uninformed changes
that happen. The exact phase connectivity information is important for the
efficient operation and control of distribution system. We propose a new data
driven approach to the problem based on Principal Component Analysis (PCA) and
its Graph Theoretic interpretations, using energy measurements in equally timed
short intervals, generated from smart meters. We propose an algorithm for
inferring phase connectivity from noisy measurements. The algorithm is
demonstrated using simulated data for phase connectivities in distribution
networks.
</dc:description>
 <dc:description>Comment: Accepted for the presentation at ACC 16</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06065</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning for Tactile Understanding From Visual and Haptic Data</dc:title>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Hendricks, Lisa Anne</dc:creator>
 <dc:creator>Kuchenbecker, Katherine J.</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Robots which interact with the physical world will benefit from a
fine-grained tactile understanding of objects and surfaces. Additionally, for
certain tasks, robots may need to know the haptic properties of an object
before touching it. To enable better tactile understanding for robots, we
propose a method of classifying surfaces with haptic adjectives (e.g.,
compressible or smooth) from both visual and physical interaction data. Humans
typically combine visual predictions and feedback from physical interactions to
accurately predict haptic properties and interact with the world. Inspired by
this cognitive pattern, we propose and explore a purely visual haptic
prediction model. Purely visual models enable a robot to &quot;feel&quot; without
physical interaction. Furthermore, we demonstrate that using both visual and
physical interaction signals together yields more accurate haptic
classification. Our models take advantage of recent advances in deep neural
networks by employing a unified approach to learning features for physical
interaction and visual observations. Even though we employ little domain
specific knowledge, our model still achieves better results than methods based
on hand-designed features.
</dc:description>
 <dc:description>Comment: Camera ready version for ICRA 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06066</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning for Speech and Language Processing</dc:title>
 <dc:creator>Wang, Dong</dc:creator>
 <dc:creator>Zheng, Thomas Fang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Transfer learning is a vital technique that generalizes models trained for
one setting or task to other settings or tasks. For example in speech
recognition, an acoustic model trained for one language can be used to
recognize speech in another language, with little or no re-training data.
Transfer learning is closely related to multi-task learning (cross-lingual vs.
multilingual), and is traditionally studied in the name of `model adaptation'.
Recent advance in deep learning shows that transfer learning becomes much
easier and more effective with high-level abstract features learned by deep
models, and the `transfer' can be conducted not only between data distributions
and data types, but also between model structures (e.g., shallow nets and deep
nets) or even model types (e.g., Bayesian models and neural models). This
review paper summarizes some recent prominent research towards this direction,
particularly for speech and language processing. We also report some results
from our group and highlight the potential of this very interesting research
field.
</dc:description>
 <dc:description>Comment: 13 pages, APSIPA 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06067</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional neural networks with low-rank regularization</dc:title>
 <dc:creator>Tai, Cheng</dc:creator>
 <dc:creator>Xiao, Tong</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>E, Weinan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Large CNNs have delivered impressive performance in various computer vision
applications. But the storage and computation requirements make it problematic
for deploying these models on mobile devices. Recently, tensor decompositions
have been used for speeding up CNNs. In this paper, we further develop the
tensor decomposition technique. We propose a new algorithm for computing the
low-rank tensor decomposition for removing the redundancy in the convolution
kernels. The algorithm finds the exact global optimizer of the decomposition
and is more effective than iterative methods. Based on the decomposition, we
further propose a new method for training low-rank constrained CNNs from
scratch. Interestingly, while achieving a significant speedup, sometimes the
low-rank constrained CNNs delivers significantly better performance than their
non-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank
NIN model achieves $91.31\%$ accuracy (without data augmentation), which also
improves upon state-of-the-art result. We evaluated the proposed method on
CIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,
NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is
reduced by half while the performance is still comparable. Empirical success
suggests that low-rank tensor decompositions can be a very useful tool for
speeding up large CNNs.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06068</identifier>
 <datestamp>2016-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing Overfitting in Deep Networks by Decorrelating Representations</dc:title>
 <dc:creator>Cogswell, Michael</dc:creator>
 <dc:creator>Ahmed, Faruk</dc:creator>
 <dc:creator>Girshick, Ross</dc:creator>
 <dc:creator>Zitnick, Larry</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  One major challenge in training Deep Neural Networks is preventing
overfitting. Many techniques such as data augmentation and novel regularizers
such as Dropout have been proposed to prevent overfitting without requiring a
massive amount of training data. In this work, we propose a new regularizer
called DeCov which leads to significantly reduced overfitting (as indicated by
the difference between train and val performance), and better generalization.
Our regularizer encourages diverse or non-redundant representations in Deep
Neural Networks by minimizing the cross-covariance of hidden activations. This
simple intuition has been explored in a number of past works but surprisingly
has never been applied as a regularizer in supervised learning. Experiments
across a range of datasets and network architectures show that this loss always
reduces overfitting while almost always maintaining or increasing
generalization performance and often improving performance over Dropout.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, 5 tables, Accepted to ICLR 2016, (v4 adds
  acknowledgements)</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06069</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stateless multicast switching in software defined networks</dc:title>
 <dc:creator>Reed, Martin J.</dc:creator>
 <dc:creator>Al-Naday, Mays</dc:creator>
 <dc:creator>Thomos, Nikolaos</dc:creator>
 <dc:creator>Trossen, Dirk</dc:creator>
 <dc:creator>Petropoulos, George</dc:creator>
 <dc:creator>Spirou, Spiros</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Multicast data delivery can significantly reduce traffic in operators'
networks, but has been limited in deployment due to concerns such as the
scalability of state management. This paper shows how multicast can be
implemented in contemporary software defined networking (SDN) switches, with
less state than existing unicast switching strategies, by utilising a Bloom
Filter (BF) based switching technique. Furthermore, the proposed mechanism uses
only proactive rule insertion, and thus, is not limited by congestion or delay
incurred by reactive controller-aided rule insertion. We compare our solution
against common switching mechanisms such as layer-2 switching and MPLS in
realistic network topologies by modelling the TCAM state sizes in SDN switches.
The results demonstrate that our approach has significantly smaller state size
compared to existing mechanisms and thus is a multicast switching solution for
next generation networks.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06070</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Depth Prediction in Challenging Monocular Video Sequences</dc:title>
 <dc:creator>Liu, Miaomiao</dc:creator>
 <dc:creator>Salzmann, Mathieu</dc:creator>
 <dc:creator>He, Xuming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we tackle the problem of estimating the depth of a scene from
a monocular video sequence. In particular, we handle challenging scenarios,
such as non-translational camera motion and dynamic scenes, where traditional
structure from motion and motion stereo methods do not apply. To this end, we
first study the problem of depth estimation from a single image. In this
context, we exploit the availability of a pool of images for which the depth is
known, and formulate monocular depth estimation as a discrete-continuous
optimization problem, where the continuous variables encode the depth of the
superpixels in the input image, and the discrete ones represent relationships
between neighboring superpixels. The solution to this discrete-continuous
optimization problem is obtained by performing inference in a graphical model
using particle belief propagation. To handle video sequences, we then extend
our single image model to a two-frame one that naturally encodes short-range
temporal consistency and inherently handles dynamic objects. Based on the
prediction of this model, we then introduce a fully-connected pairwise CRF that
accounts for longer range spatio-temporal interactions throughout a video. We
demonstrate the effectiveness of our model in both the indoor and outdoor
scenarios.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06071</identifier>
 <datestamp>2017-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Simulation and Coded Source Compression</dc:title>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:creator>Watanabe, Shun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  This work establishes connection between channel simulation and coded source
compression. First, we consider classical source coding with quantum
side-information where the quantum side-information is observed by a helper and
sent to the decoder via a classical channel. We derive a single-letter
characterization of the achievable rate region for this problem. The direct
part of our result is proved via the measurement compression theory by Winter,
a quantum to classical channel simulation. Our result reveals that a helper's
scheme that separately conducts a measurement and a compression is suboptimal,
and the measurement compression is fundamentally needed to achieve the optimal
rate region. We then study coded source compression in the fully quantum
regime. We characterise the quantum resources involved in this problem, and
derive a single-letter expression of the achievable rate region when
entanglement assistance is available. The direct coding proof is based on a
combination of two fundamental protocols, namely the quantum state merging
protocol and the quantum reverse Shannon theorem. Our work hence resolves coded
source compression in the quantum regime.
</dc:description>
 <dc:description>Comment: The manuscript is a combination of results in arXiv:1501.04366 and
  arXiv:1504.05227. In particular, we show that channel simulation is a
  subroutine that the helper employs in the task of coded source compression in
  both classical and quantum regimes</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06071</dc:identifier>
 <dc:identifier>IEEE Transactions on Information Theory, vol. 62, no. 11, pp.
  6609-6619, Nov. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2597853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06072</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mediated Experts for Deep Convolutional Networks</dc:title>
 <dc:creator>Agethen, Sebastian</dc:creator>
 <dc:creator>Hsu, Winston H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present a new supervised architecture termed Mediated Mixture-of-Experts
(MMoE) that allows us to improve classification accuracy of Deep Convolutional
Networks (DCN). Our architecture achieves this with the help of expert
networks: A network is trained on a disjoint subset of a given dataset and then
run in parallel to other experts during deployment. A mediator is employed if
experts contradict each other. This allows our framework to naturally support
incremental learning, as adding new classes requires (re-)training of the new
expert only. We also propose two measures to control computational complexity:
An early-stopping mechanism halts experts that have low confidence in their
prediction. The system allows to trade-off accuracy and complexity without
further retraining. We also suggest to share low-level convolutional layers
between experts in an effort to avoid computation of a near-duplicate feature
set. We evaluate our system on a popular dataset and report improved accuracy
compared to a single model of same configuration.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06074</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Expressions for Ergodic Capacities of Optical Fibers and Wireless
  MIMO Channels</dc:title>
 <dc:creator>Nafkha, Amor</dc:creator>
 <dc:creator>Demni, Nizar</dc:creator>
 <dc:creator>Bonnefoi, Remi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Multimode/multicore fibers are expected to provide an attractive solution to
overcome the capacity limit of current optical communication system. In
presence of high crosstalk between modes/cores, the squared singular values of
the input/output transfer matrix follow the law of the Jacobi ensemble of
random matrices. Assuming that the channel state information is only available
at the receiver, we derive in this paper a new expression for the ergodic
capacity of the Jacobi MIMO channel. This expression involves double integrals
which can be evaluated easily and efficiently. Moreover, the method used in
deriving this expression does not appeal to the classical one-point correlation
function of the random matrix model. Using a limiting transition between Jacobi
and Laguerre polynomials, we derive a similar formula for the ergodic capacity
of the Gaussian MIMO channel. The analytical results are compared with Monte
Carlo simulations and related results available in the literature. A perfect
agreement is obtained.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06078</identifier>
 <datestamp>2016-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Structure-Preserving Image-Text Embeddings</dc:title>
 <dc:creator>Wang, Liwei</dc:creator>
 <dc:creator>Li, Yin</dc:creator>
 <dc:creator>Lazebnik, Svetlana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper proposes a method for learning joint embeddings of images and text
using a two-branch neural network with multiple layers of linear projections
followed by nonlinearities. The network is trained using a large margin
objective that combines cross-view ranking constraints with within-view
neighborhood structure preservation constraints inspired by metric learning
literature. Extensive experiments show that our approach gains significant
improvements in accuracy for image-to-text and text-to-image retrieval. Our
method achieves new state-of-the-art results on the Flickr30K and MSCOCO
image-sentence datasets and shows promise on the new task of phrase
localization on the Flickr30K Entities dataset.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06085</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Rate Image Compression with Recurrent Neural Networks</dc:title>
 <dc:creator>Toderici, George</dc:creator>
 <dc:creator>O'Malley, Sean M.</dc:creator>
 <dc:creator>Hwang, Sung Jin</dc:creator>
 <dc:creator>Vincent, Damien</dc:creator>
 <dc:creator>Minnen, David</dc:creator>
 <dc:creator>Baluja, Shumeet</dc:creator>
 <dc:creator>Covell, Michele</dc:creator>
 <dc:creator>Sukthankar, Rahul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A large fraction of Internet traffic is now driven by requests from mobile
devices with relatively small screens and often stringent bandwidth
requirements. Due to these factors, it has become the norm for modern
graphics-heavy websites to transmit low-resolution, low-bytecount image
previews (thumbnails) as part of the initial page load process to improve
apparent page responsiveness. Increasing thumbnail compression beyond the
capabilities of existing codecs is therefore a current research focus, as any
byte savings will significantly enhance the experience of mobile device users.
Toward this end, we propose a general framework for variable-rate image
compression and a novel architecture based on convolutional and deconvolutional
LSTM recurrent networks. Our models address the main issues that have prevented
autoencoder neural networks from competing with existing image compression
algorithms: (1) our networks only need to be trained once (not per-image),
regardless of input image dimensions and the desired compression rate; (2) our
networks are progressive, meaning that the more bits are sent, the more
accurate the image reconstruction; and (3) the proposed architecture is at
least as efficient as a standard purpose-trained autoencoder for a given number
of bits. On a large-scale benchmark of 32$\times$32 thumbnails, our LSTM-based
approaches provide better visual quality than (headerless) JPEG, JPEG2000 and
WebP, with a storage size that is reduced by 10% or more.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06090</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Master of Puppets: Analyzing And Attacking A Botnet For Fun And Profit</dc:title>
 <dc:creator>Saito, Genki</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A botnet is a network of compromised machines (bots), under the control of an
attacker. Many of these machines are infected without their owners' knowledge,
and botnets are the driving force behind several misuses and criminal
activities on the Internet (for example spam emails). Depending on its
topology, a botnet can have zero or more command and control (C&amp;C) servers,
which are centralized machines controlled by the cybercriminal that issue
commands and receive reports back from the co-opted bots.
  In this paper, we present a comprehensive analysis of the command and control
infrastructure of one of the world's largest proprietary spamming botnets
between 2007 and 2012: Cutwail/Pushdo. We identify the key functionalities
needed by a spamming botnet to operate effectively. We then develop a number of
attacks against the command and control logic of Cutwail that target those
functionalities, and make the spamming operations of the botnet less effective.
This analysis was made possible by having access to the source code of the C&amp;C
software, as well as setting up our own Cutwail C&amp;C server, and by implementing
a clone of the Cutwail bot. With the help of this tool, we were able to
enumerate the number of bots currently registered with the C&amp;C server,
impersonate an existing bot to report false information to the C&amp;C server, and
manipulate spamming statistics of an arbitrary bot stored in the C&amp;C database.
Furthermore, we were able to make the control server inaccessible by conducting
a distributed denial of service (DDoS) attack. Our results may be used by law
enforcement and practitioners to develop better techniques to mitigate and
cripple other botnets, since many of findings are generic and are due to the
workflow of C&amp;C communication in general.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06098</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Management with Partial Uplink/Downlink Spectrum Overlap</dc:title>
 <dc:creator>Randrianantenaina, Itsikiantsoa</dc:creator>
 <dc:creator>Elsawy, Hesham</dc:creator>
 <dc:creator>Dahrouj, Hayssam</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Simultaneous reuse of spectral resources by uplink and downlink, denoted as
in-band full duplex (FD) communication, is promoted to double the spectral
efficiency when compared to its half-duplex (HD) counterpart. Interference
management, however, remains challenging in FD cellular networks, especially
when high disparity between uplink and downlink transmission powers exists. The
uplink performance can be particularly deteriorated when operating on channels
that are simultaneously occupied with downlink transmission. This paper
considers a cellular wireless system with partial spectrum overlap between the
downlink and uplink. The performance of the system becomes, therefore, a
function of the overlap fraction, as well as the power level of both the uplink
and downlink transmissions. The paper considers the problem of maximizing an
overall network utility to find the uplink/downlink transmission powers and the
spectrum overlap fraction between the uplink and downlink spectrum in each
cell, and proposes solving the problem using interior point method. Simulations
results confirm the vulnerability of the uplink performance to the FD
operation, and show the superiority of the proposed scheme over the FD and HD
schemes. The results further show that explicit uplink and downlink performance
should be considered for efficient design of cellular networks with overlapping
uplink/downlink resources.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06099</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Sketching Quadratic Forms</dc:title>
 <dc:creator>Andoni, Alexandr</dc:creator>
 <dc:creator>Chen, Jiecao</dc:creator>
 <dc:creator>Krauthgamer, Robert</dc:creator>
 <dc:creator>Qin, Bo</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:creator>Zhang, Qin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We undertake a systematic study of sketching a quadratic form: given an $n
\times n$ matrix $A$, create a succinct sketch $\textbf{sk}(A)$ which can
produce (without further access to $A$) a multiplicative
$(1+\epsilon)$-approximation to $x^T A x$ for any desired query $x \in
\mathbb{R}^n$. While a general matrix does not admit non-trivial sketches,
positive semi-definite (PSD) matrices admit sketches of size
$\Theta(\epsilon^{-2} n)$, via the Johnson-Lindenstrauss lemma, achieving the
&quot;for each&quot; guarantee, namely, for each query $x$, with a constant probability
the sketch succeeds. (For the stronger &quot;for all&quot; guarantee, where the sketch
succeeds for all $x$'s simultaneously, again there are no non-trivial
sketches.)
  We design significantly better sketches for the important subclass of graph
Laplacian matrices, which we also extend to symmetric diagonally dominant
matrices. A sequence of work culminating in that of Batson, Spielman, and
Srivastava (SIAM Review, 2014), shows that by choosing and reweighting
$O(\epsilon^{-2} n)$ edges in a graph, one achieves the &quot;for all&quot; guarantee.
Our main results advance this front.
  $\bullet$ For the &quot;for all&quot; guarantee, we prove that Batson et al.'s bound is
optimal even when we restrict to &quot;cut queries&quot; $x\in \{0,1\}^n$.
  In contrast, previous lower bounds showed the bound only for {\em
spectral-sparsifiers}.
  $\bullet$ For the &quot;for each&quot; guarantee, we design a sketch of size $\tilde
O(\epsilon^{-1} n)$ bits for &quot;cut queries&quot; $x\in \{0,1\}^n$. We prove a
nearly-matching lower bound of $\Omega(\epsilon^{-1} n)$ bits. For general
queries $x \in \mathbb{R}^n$, we construct sketches of size
$\tilde{O}(\epsilon^{-1.6} n)$ bits.
</dc:description>
 <dc:description>Comment: 46 pages; merging of arXiv:1403.7058 and arXiv:1412.8225</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06103</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principled Parallel Mean-Field Inference for Discrete Random Fields</dc:title>
 <dc:creator>Baqu&#xe9;, Pierre</dc:creator>
 <dc:creator>Bagautdinov, Timur</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Mean-field variational inference is one of the most popular approaches to
inference in discrete random fields. Standard mean-field optimization is based
on coordinate descent and in many situations can be impractical. Thus, in
practice, various parallel techniques are used, which either rely on ad-hoc
smoothing with heuristically set parameters, or put strong constraints on the
type of models. In this paper, we propose a novel proximal gradient-based
approach to optimizing the variational objective. It is naturally
parallelizable and easy to implement. We prove its convergence, and then
demonstrate that, in practice, it yields faster convergence and often finds
better optima than more traditional mean-field optimization techniques.
Moreover, our method is less sensitive to the choice of parameters.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06104</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Learning for Convolutional Neural Networks via Online
  Graph Construction</dc:title>
 <dc:creator>Bai, Sheng-Yi</dc:creator>
 <dc:creator>Agethen, Sebastian</dc:creator>
 <dc:creator>Chao, Ting-Hsuan</dc:creator>
 <dc:creator>Hsu, Winston</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The recent promising achievements of deep learning rely on the large amount
of labeled data. Considering the abundance of data on the web, most of them do
not have labels at all. Therefore, it is important to improve generalization
performance using unlabeled data on supervised tasks with few labeled
instances. In this work, we revisit graph-based semi-supervised learning
algorithms and propose an online graph construction technique which suits deep
convolutional neural network better. We consider an EM-like algorithm for
semi-supervised learning on deep neural networks: In forward pass, the graph is
constructed based on the network output, and the graph is then used for loss
calculation to help update the network by back propagation in the backward
pass. We demonstrate the strength of our online approach compared to the
conventional ones whose graph is constructed on static but not robust enough
feature representations beforehand.
</dc:description>
 <dc:description>Comment: As the original submission of iclr is withdrawn, the arxiv submission
  should be withdrawn as well</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06106</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Analysis of Particles Segregation</dc:title>
 <dc:creator>Peng, Ting</dc:creator>
 <dc:creator>Qu, Aiping</dc:creator>
 <dc:creator>Wang, Xiaoling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segregation is a popular phenomenon. It has considerable effects on material
performance. To the author's knowledge, there is still no automated objective
quantitative indicator for segregation. In order to full fill this task,
segregation of particles is analyzed. Edges of the particles are extracted from
the digital picture. Then, the whole picture of particles is splintered to
small rectangles with the same shape. Statistical index of the edges in each
rectangle is calculated. Accordingly, segregation between the indexes
corresponding to the rectangles is evaluated. The results show coincident with
subjective evaluated results. Further more, it can be implemented as an
automated system, which would facilitate the materials quality control
mechanism during production process.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06114</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-task Sequence to Sequence Learning</dc:title>
 <dc:creator>Luong, Minh-Thang</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Kaiser, Lukasz</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sequence to sequence learning has recently emerged as a new paradigm in
supervised learning. To date, most of its applications focused on only one task
and not much work explored this framework for multiple tasks. This paper
examines three multi-task learning (MTL) settings for sequence to sequence
models: (a) the oneto-many setting - where the encoder is shared between
several tasks such as machine translation and syntactic parsing, (b) the
many-to-one setting - useful when only the decoder can be shared, as in the
case of translation and image caption generation, and (c) the many-to-many
setting - where multiple encoders and decoders are shared, which is the case
with unsupervised objectives and translation. Our results show that training on
a small amount of parsing and image caption data can improve the translation
quality between English and German by up to 1.5 BLEU points over strong
single-task baselines on the WMT benchmarks. Furthermore, we have established a
new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we
reveal interesting properties of the two unsupervised learning objectives,
autoencoder and skip-thought, in the MTL context: autoencoder helps less in
terms of perplexities but more on BLEU scores compared to skip-thought.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, ICLR 2016 camera-ready, added parsing SOTA
  results</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06117</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TOA-based passive localization of multiple targets with inaccurate
  receivers based on belief propagation on factor graph</dc:title>
 <dc:creator>Wu, Nan</dc:creator>
 <dc:creator>Yuan, Weijie</dc:creator>
 <dc:creator>Wang, Hua</dc:creator>
 <dc:creator>Kuang, Jingming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Location awareness is now becoming a vital requirement for many practical
applications. In this paper, we consider passive localization of multiple
targets with one transmitter and several receivers based on time of arrival
(TOA) measurements. Existing studies assume that positions of receivers are
perfectly known. However, in practice, receivers' positions might be
inaccurate, which leads to localization error of targets. We propose factor
graph (FG)-based belief propagation (BP) algorithms to locate the passive
targets and improve the position accuracy of receivers simultaneously. Due to
the nonlinearity of the likelihood function, messages on the FG cannot be
derived in closed form. We propose both sample-based and parametric methods to
solve this problem. In the sample-based BP algorithm, particle swarm
optimization is employed to reduce the number of particles required to
represent messages. In parametric BP algorithm, the nonlinear terms in messages
are linearized, which results in closed-form Gaussian message passing on FG.
The Bayesian Cramer-Rao bound (BCRB) for passive targets localization with
uncertain receivers is derived to evaluate the performance of the proposed
algorithms. Simulation results show that both the sample-based and parametric
BP algorithms outperform the conventional method and attain the proposed BCRB.
Receivers' positions can also be improved via the proposed BP algorithms.
Although the parametric BP algorithm performs slightly worse than the
sample-based BP method, it could be more attractive in practical applications
due to the significantly lower computational complexity.
</dc:description>
 <dc:description>Comment: 37 pages, 11 figures, accepted by Digital Signal Processing</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06117</dc:identifier>
 <dc:identifier>doi:10.1016/j.dsp.2015.10.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06132</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds of distance Estrada index of graphs</dc:title>
 <dc:creator>Shang, Yilun</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C12, 15A42</dc:subject>
 <dc:description>  Let $\lambda_1,\lambda_2,\cdots,\lambda_n$ be the eigenvalues of the distance
matrix of a connected graph $G$. The distance Estrada index of $G$ is defined
as $DEE(G)=\sum_{i=1}^ne^{\lambda_i}$. In this note, we present new lower and
upper bounds for $DEE(G)$. In addition, a Nordhaus-Gaddum type inequality for
$DEE(G)$ is given.
</dc:description>
 <dc:description>Comment: To appear in Ars Combin</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06132</dc:identifier>
 <dc:identifier>Ars Combinatoria, 2016, vol. 128, pp. 287-294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06146</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RIP-like Properties in Subsampled Blind Deconvolution</dc:title>
 <dc:creator>Lee, Kiryung</dc:creator>
 <dc:creator>Junge, Marius</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We derive near optimal performance guarantees for subsampled blind
deconvolution. Blind deconvolution is an ill-posed bilinear inverse problem and
additional subsampling makes the problem even more challenging. Sparsity and
spectral flatness priors on unknown signals are introduced to overcome these
difficulties. While being crucial for deriving desired near optimal performance
guarantees, unlike the sparsity prior with a nice union-of-subspaces structure,
the spectral flatness prior corresponds to a nonconvex cone structure, which is
not preserved by elementary set operations. This prohibits the operator arising
in subsampled blind deconvolution from satisfying the standard restricted
isometry property (RIP) at near optimal sample complexity, which motivated us
to study other RIP-like properties. Combined with the performance guarantees
derived using these RIP-like properties in a companion paper, we show that
subsampled blind deconvolution is provably solved at near optimal sample
complexity by a practical algorithm.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06147</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coreset-Based Adaptive Tracking</dc:title>
 <dc:creator>Dubey, Abhimanyu</dc:creator>
 <dc:creator>Naik, Nikhil</dc:creator>
 <dc:creator>Raviv, Dan</dc:creator>
 <dc:creator>Sukthankar, Rahul</dc:creator>
 <dc:creator>Raskar, Ramesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a method for learning from streaming visual data using a compact,
constant size representation of all the data that was seen until a given
moment. Specifically, we construct a 'coreset' representation of streaming data
using a parallelized algorithm, which is an approximation of a set with
relation to the squared distances between this set and all other points in its
ambient space. We learn an adaptive object appearance model from the coreset
tree in constant time and logarithmic space and use it for object tracking by
detection. Our method obtains excellent results for object tracking on three
standard datasets over more than 100 videos. The ability to summarize data
efficiently makes our method ideally suited for tracking in long videos in
presence of space and time constraints. We demonstrate this ability by
outperforming a variety of algorithms on the TLD dataset with 2685 frames on
average. This coreset based learning approach can be applied for both real-time
learning of small, varied data and fast learning of big data.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, In submission to IEEE TPAMI (Transactions on
  Pattern Analysis and Machine Intelligence)</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06149</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Recovery of Sparse Signals from Subsampled Convolution</dc:title>
 <dc:creator>Lee, Kiryung</dc:creator>
 <dc:creator>Li, Yanjun</dc:creator>
 <dc:creator>Junge, Marius</dc:creator>
 <dc:creator>Bresler, Yoram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Subsampled blind deconvolution is the recovery of two unknown signals from
samples of their convolution. To overcome the ill-posedness of this problem,
solutions based on priors tailored to specific application have been developed
in practical applications. In particular, sparsity models have provided
promising priors. However, in spite of empirical success of these methods in
many applications, existing analyses are rather limited in two main ways: by
disparity between the theoretical assumptions on the signal and/or measurement
model versus practical setups; or by failure to provide a performance guarantee
for parameter values within the optimal regime defined by the information
theoretic limits. In particular, it has been shown that a naive sparsity model
is not a strong enough prior for identifiability in the blind deconvolution
problem. Instead, in addition to sparsity, we adopt a conic constraint, which
enforces spectral flatness of the signals. Under this prior, we provide an
iterative algorithm that achieves guaranteed performance in blind deconvolution
at near optimal sample complexity. Numerical results show the empirical
performance of the iterative algorithm agrees with the performance guarantee.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06181</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Players do with the Ball: A Physically Constrained Interaction
  Modeling</dc:title>
 <dc:creator>Maksai, Andrii</dc:creator>
 <dc:creator>Wang, Xinchao</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Tracking the ball is critical for video-based analysis of team sports.
However, it is difficult, especially in low-resolution images, due to the small
size of the ball, its speed that creates motion blur, and its often being
occluded by players. In this paper, we propose a generic and principled
approach to modeling the interaction between the ball and the players while
also imposing appropriate physical constraints on the ball's trajectory. We
show that our approach, formulated in terms of a Mixed Integer Program, is more
robust and more accurate than several state-of-the-art approaches on real-life
volleyball, basketball, and soccer sequences.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06191</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Abstract Attribute Exploration with Partial Object Descriptions</dc:title>
 <dc:creator>Borchmann, Daniel</dc:creator>
 <dc:creator>Ganter, Bernhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Attribute exploration has been investigated in several studies, with
particular emphasis on the algorithmic aspects of this knowledge acquisition
method. In its basic version the method itself is rather simple and
transparent. But when background knowledge and partially described
counter-examples are admitted, it gets more difficult. Here we discuss this
case in an abstract, somewhat &quot;axiomatic&quot; setting, providing a terminology that
clarifies the abstract strategy of the method rather than its algorithmic
implementation.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06198</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spherical Cap Packing Asymptotics and Rank-Extreme Detection</dc:title>
 <dc:creator>Zhang, Kai</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the spherical cap packing problem with a probabilistic approach.
Such probabilistic considerations result in an asymptotic sharp universal
uniform bound on the maximal inner product between any set of unit vectors and
a stochastically independent uniformly distributed unit vector. When the set of
unit vectors are themselves independently uniformly distributed, we further
develop the extreme value distribution limit of the maximal inner product,
which characterizes its uncertainty around the bound.
  As applications of the above asymptotic results, we derive (1) an asymptotic
sharp universal uniform bound on the maximal spurious correlation, as well as
its uniform convergence in distribution when the explanatory variables are
independently Gaussian distributed; and (2) an asymptotic sharp universal bound
on the maximum norm of a low-rank elliptically distributed vector, as well as
related limiting distributions. With these results, we develop a fast detection
method for a low-rank structure in high-dimensional Gaussian data without using
the spectrum information.
</dc:description>
 <dc:description>Comment: 14 pages; 1 figure. Accepted Jan 31, 2017 by IEEE Transactions on
  Information Theory</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06198</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2700202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06201</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adjustable Bounded Rectifiers: Towards Deep Binary Representations</dc:title>
 <dc:creator>Wu, Zhirong</dc:creator>
 <dc:creator>Lin, Dahua</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Binary representation is desirable for its memory efficiency, computation
speed and robustness. In this paper, we propose adjustable bounded rectifiers
to learn binary representations for deep neural networks. While hard
constraining representations across layers to be binary makes training
unreasonably difficult, we softly encourage activations to diverge from real
values to binary by approximating step functions. Our final representation is
completely binary. We test our approach on MNIST, CIFAR10, and ILSVRC2012
dataset, and systematically study the training dynamics of the binarization
process. Our approach can binarize the last layer representation without loss
of performance and binarize all the layers with reasonably small degradations.
The memory space that it saves may allow more sophisticated models to be
deployed, thus compensating the loss. To the best of our knowledge, this is the
first work to report results on current deep network architectures using
complete binary middle representations. Given the learned representations, we
find that the firing or inhibition of a binary neuron is usually associated
with a meaningful interpretation across different classes. This suggests that
the semantic structure of a neural network may be manifested through a guided
binarization process.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06208</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion Representations</dc:title>
 <dc:creator>Salhov, Moshe</dc:creator>
 <dc:creator>Bermanis, Amit</dc:creator>
 <dc:creator>Wolf, Guy</dc:creator>
 <dc:creator>Averbuch, Amir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:description>  Diffusion Maps framework is a kernel based method for manifold learning and
data analysis that defines diffusion similarities by imposing a Markovian
process on the given dataset. Analysis by this process uncovers the intrinsic
geometric structures in the data. Recently, it was suggested to replace the
standard kernel by a measure-based kernel that incorporates information about
the density of the data. Thus, the manifold assumption is replaced by a more
general measure-based assumption.
  The measure-based diffusion kernel incorporates two separate independent
representations. The first determines a measure that correlates with a density
that represents normal behaviors and patterns in the data. The second consists
of the analyzed multidimensional data points.
  In this paper, we present a representation framework for data analysis of
datasets that is based on a closed-form decomposition of the measure-based
kernel. The proposed representation preserves pairwise diffusion distances that
does not depend on the data size while being invariant to scale. For a
stationary data, no out-of-sample extension is needed for embedding newly
arrived data points in the representation space. Several aspects of the
presented methodology are demonstrated on analytically generated data.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06214</identifier>
 <datestamp>2016-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatically selecting inference algorithms for discrete energy
  minimisation</dc:title>
 <dc:creator>Henderson, Paul</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Minimisation of discrete energies defined over factors is an important
problem in computer vision, and a vast number of MAP inference algorithms have
been proposed. Different inference algorithms perform better on factor graph
models (GMs) from different underlying problem classes, and in general it is
difficult to know which algorithm will yield the lowest energy for a given GM.
To mitigate this difficulty, survey papers advise the practitioner on what
algorithms perform well on what classes of models. We take the next step
forward, and present a technique to automatically select the best inference
algorithm for an input GM. We validate our method experimentally on an extended
version of the OpenGM2 benchmark, containing a diverse set of vision problems.
On average, our method selects an inference algorithm yielding labellings with
96% of variables the same as the best available algorithm.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06219</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Base Population using Semantic Label Propagation</dc:title>
 <dc:creator>Sterckx, Lucas</dc:creator>
 <dc:creator>Demeester, Thomas</dc:creator>
 <dc:creator>Deleu, Johannes</dc:creator>
 <dc:creator>Develder, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A crucial aspect of a knowledge base population system that extracts new
facts from text corpora, is the generation of training data for its relation
extractors. In this paper, we present a method that maximizes the effectiveness
of newly trained relation extractors at a minimal annotation cost. Manual
labeling can be significantly reduced by Distant Supervision, which is a method
to construct training data automatically by aligning a large text corpus with
an existing knowledge base of known facts. For example, all sentences
mentioning both 'Barack Obama' and 'US' may serve as positive training
instances for the relation born_in(subject,object). However, distant
supervision typically results in a highly noisy training set: many training
sentences do not really express the intended relation. We propose to combine
distant supervision with minimal manual supervision in a technique called
feature labeling, to eliminate noise from the large and noisy initial training
set, resulting in a significant increase of precision. We further improve on
this approach by introducing the Semantic Label Propagation method, which uses
the similarity between low-dimensional representations of candidate training
instances, to extend the training set in order to increase recall while
maintaining high precision. Our proposed strategy for generating training data
is studied and evaluated on an established test collection designed for
knowledge base population tasks. The experimental results show that the
Semantic Label Propagation strategy leads to substantial performance gains when
compared to existing approaches, while requiring an almost negligible manual
annotation effort.
</dc:description>
 <dc:description>Comment: Submitted to Knowledge Based Systems, special issue on Knowledge
  Bases for Natural Language Processing</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06227</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Empirical Research and Automatic Processing Method of Precision-specific
  Operation</dc:title>
 <dc:creator>Wang, Ran</dc:creator>
 <dc:creator>He, Xinrui</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Significant inaccuracy often occurs during the process of mathematical
calculation due to the digit limitation of floating point, which may lead to
catastrophic loss. Normally, people believe that adjustment of floating-point
precision is an effective way to solve this problem, since high-precision
floating-point has more digits to store information. Thus, it is a prevalent
method to reduce the inaccuracy in much floating-point related research, that
performing all the operations with higher precision. However, we discover that
some operations may lead to larger error in higher precision. In this paper, we
define this kind of operation that generates large error due to precision
adjustment a precision-specific operation. Furthermore, we propose a
light-weight searching algorithm for detecting precision-specific operations
and figure out an automatic processing method to fixing them. In addition, we
conducted an experiment on the scientific mathematical library of GLIBC. The
result shows that there are many precision-specific operations, and our fixing
approach can significantly reduce the inaccuracy.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06230</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refined analysis of RGHWs of code pairs coming from Garcia-Stichtenoth's
  second tower</dc:title>
 <dc:creator>Geil, Olav</dc:creator>
 <dc:creator>Martin, Stefano</dc:creator>
 <dc:creator>Mart&#xed;nez-Pe&#xf1;as, Umberto</dc:creator>
 <dc:creator>Ruano, Diego</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Asymptotically good sequences of ramp secret sharing schemes were given in
[Asymptotically good ramp secret sharing schemes, arXiv:1502.05507] by using
one-point algebraic geometric codes defined from asymptotically good towers of
function fields. Their security is given by the relative generalized Hamming
weights of the corresponding codes. In this paper we demonstrate how to obtain
refined information on the RGHWs when the codimension of the codes is small.
For general codimension, we give an improved estimate for the highest RGHW.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06233</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Open Set Deep Networks</dc:title>
 <dc:creator>Bendale, Abhijit</dc:creator>
 <dc:creator>Boult, Terrance</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep networks have produced significant gains for various visual recognition
problems, leading to high impact academic and commercial applications. Recent
work in deep networks highlighted that it is easy to generate images that
humans would never classify as a particular object class, yet networks classify
such images high confidence as that given class - deep network are easily
fooled with images humans do not consider meaningful. The closed set nature of
deep networks forces them to choose from one of the known classes leading to
such artifacts. Recognition in the real world is open set, i.e. the recognition
system should reject unknown/unseen classes at test time. We present a
methodology to adapt deep networks for open set recognition, by introducing a
new model layer, OpenMax, which estimates the probability of an input being
from an unknown class. A key element of estimating the unknown probability is
adapting Meta-Recognition concepts to the activation patterns in the
penultimate layer of the network. OpenMax allows rejection of &quot;fooling&quot; and
unrelated open set images presented to the system; OpenMax greatly reduces the
number of obvious errors made by a deep network. We prove that the OpenMax
concept provides bounded open space risk, thereby formally providing an open
set recognition solution. We evaluate the resulting open set deep networks
using pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation
data, and thousands of fooling and open set images. The proposed OpenMax model
significantly outperforms open set recognition accuracy of basic deep networks
as well as deep networks with thresholding of SoftMax probabilities.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06236</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A mass-flow MILP formulation for energy-efficient supplying in assembly
  lines</dc:title>
 <dc:creator>Muguerza, Maria</dc:creator>
 <dc:creator>Briand, Cyril</dc:creator>
 <dc:creator>Jozefowiez, Nicolas</dc:creator>
 <dc:creator>Ngueveu, Sandra Ulrich</dc:creator>
 <dc:creator>Rodr&#xed;guez, Victoria</dc:creator>
 <dc:creator>Moris, Matias Urenda</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper focuses on the problem of supplying the workstations of assembly
lines with components during the production process. For that specific problem,
this paper presents a Mixed Integer Linear Program (MILP) that aims at
minimizing the energy consumption of the supplying strategy. More specifically,
in contrast of the usual formulations that only consider component flows, this
MILP handles the mass flow that are routed from one workstation to the other.
</dc:description>
 <dc:description>Comment: MISTA 2015, Aug 2015, Prague, Czech Republic. The MISTA conference
  series ISSN 2305-249X. 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06238</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal sparse representation learning and applications</dc:title>
 <dc:creator>Cha, Miriam</dc:creator>
 <dc:creator>Gwon, Youngjune</dc:creator>
 <dc:creator>Kung, H. T.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Unsupervised methods have proven effective for discriminative tasks in a
single-modality scenario. In this paper, we present a multimodal framework for
learning sparse representations that can capture semantic correlation between
modalities. The framework can model relationships at a higher level by forcing
the shared sparse representation. In particular, we propose the use of joint
dictionary learning technique for sparse coding and formulate the joint
representation for concision, cross-modal representations (in case of a missing
modality), and union of the cross-modal representations. Given the accelerated
growth of multimodal data posted on the Web such as YouTube, Wikipedia, and
Twitter, learning good multimodal features is becoming increasingly important.
We show that the shared representations enabled by our framework substantially
improve the classification performance under both unimodal and multimodal
settings. We further show how deep architectures built on the proposed
framework are effective for the case of highly nonlinear correlations between
modalities. The effectiveness of our approach is demonstrated experimentally in
image denoising, multimedia event detection and retrieval on the TRECVID
dataset (audio-video), category classification on the Wikipedia dataset
(image-text), and sentiment classification on PhotoTweet (image-text).
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06241</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Clustering for Unsupervised Learning</dc:title>
 <dc:creator>Dundar, Aysegul</dc:creator>
 <dc:creator>Jin, Jonghoon</dc:creator>
 <dc:creator>Culurciello, Eugenio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of labeling data for training deep neural networks is daunting and
tedious, requiring millions of labels to achieve the current state-of-the-art
results. Such reliance on large amounts of labeled data can be relaxed by
exploiting hierarchical features via unsupervised learning techniques. In this
work, we propose to train a deep convolutional network based on an enhanced
version of the k-means clustering algorithm, which reduces the number of
correlated parameters in the form of similar filters, and thus increases test
categorization accuracy. We call our algorithm convolutional k-means
clustering. We further show that learning the connection between the layers of
a deep convolutional neural network improves its ability to be trained on a
smaller amount of labeled data. Our experiments show that the proposed
algorithm outperforms other techniques that learn filters unsupervised.
Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error
of 0.5% on MNIST.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06244</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unlicensed LTE/WiFi Coexistence: Is LBT Inherently Fairer Than CSAT?</dc:title>
 <dc:creator>Cano, Cristina</dc:creator>
 <dc:creator>Leith, Douglas J.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Ensuring fair co-existence between unlicensed LTE and WiFi networks is
currently of major concern to both cellular operators and WiFi providers. Two
main unlicensed LTE approaches currently being discussed, namely Carrier Sense
Adaptive Transmission (CSAT) and Listen Before Talk (LBT). While these
mechanisms differ in their compatibility with existing LTE specifications and
regulatory compliance in different countries, they also use fundamentally
different approaches to access the channel. Nevertheless, we show in this
article that when optimally configured both approaches are capable of providing
the same level of fairness to WiFi and that the choice between CSAT and LBT is
solely driven by the LTE operator's interests.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06246</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Mixture Embeddings for Multiple Word Prototypes</dc:title>
 <dc:creator>Chen, Xinchi</dc:creator>
 <dc:creator>Qiu, Xipeng</dc:creator>
 <dc:creator>Jiang, Jingxiang</dc:creator>
 <dc:creator>Huang, Xuanjing</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, word representation has been increasingly focused on for its
excellent properties in representing the word semantics. Previous works mainly
suffer from the problem of polysemy phenomenon. To address this problem, most
of previous models represent words as multiple distributed vectors. However, it
cannot reflect the rich relations between words by representing words as points
in the embedded space. In this paper, we propose the Gaussian mixture skip-gram
(GMSG) model to learn the Gaussian mixture embeddings for words based on
skip-gram framework. Each word can be regarded as a gaussian mixture
distribution in the embedded space, and each gaussian component represents a
word sense. Since the number of senses varies from word to word, we further
propose the Dynamic GMSG (D-GMSG) model by adaptively increasing the sense
number of words during training. Experiments on four benchmarks show the
effectiveness of our proposed model.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06246</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06247</identifier>
 <datestamp>2016-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting online user behaviour using deep learning algorithms</dc:title>
 <dc:creator>Vieira, Armando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a robust classifier to predict buying intentions based on user
behaviour within a large e-commerce website. In this work we compare
traditional machine learning techniques with the most advanced deep learning
approaches. We show that both Deep Belief Networks and Stacked Denoising
auto-Encoders achieved a substantial improvement by extracting features from
high dimensional data during the pre-train phase. They prove also to be more
convenient to deal with severe class imbalance.
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1412.6601, arXiv:1406.1231, arXiv:1508.03856 by other authors</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06248</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Parameters in Particle Swarm Optimisation</dc:title>
 <dc:creator>Herrmann, J. Michael</dc:creator>
 <dc:creator>Erskine, Adam</dc:creator>
 <dc:creator>Joyce, Thomas</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Particle swarm optimisation is a metaheuristic algorithm which finds
reasonable solutions in a wide range of applied problems if suitable parameters
are used. We study the properties of the algorithm in the framework of random
dynamical systems which, due to the quasi-linear swarm dynamics, yields
analytical results for the stability properties of the particles. Such
considerations predict a relationship between the parameters of the algorithm
that marks the edge between convergent and divergent behaviours. Comparison
with simulations indicates that the algorithm performs best near this margin of
instability.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06251</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic modified equations and adaptive stochastic gradient
  algorithms</dc:title>
 <dc:creator>Li, Qianxiao</dc:creator>
 <dc:creator>Tai, Cheng</dc:creator>
 <dc:creator>E, Weinan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68W20</dc:subject>
 <dc:description>  We develop the method of stochastic modified equations (SME), in which
stochastic gradient algorithms are approximated in the weak sense by
continuous-time stochastic differential equations. We exploit the continuous
formulation together with optimal control theory to derive novel adaptive
hyper-parameter adjustment policies. Our algorithms have competitive
performance with the added benefit of being robust to varying models and
datasets. This provides a general methodology for the analysis and design of
stochastic gradient algorithms.
</dc:description>
 <dc:description>Comment: Major changes including a proof of the weak approximation, asymptotic
  expansions and application-oriented adaptive algorithms</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06252</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network-based recommendation algorithms: A review</dc:title>
 <dc:creator>Yu, Fei</dc:creator>
 <dc:creator>Zeng, An</dc:creator>
 <dc:creator>Gillard, Sebastien</dc:creator>
 <dc:creator>Medo, Matus</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recommender systems are a vital tool that helps us to overcome the
information overload problem. They are being used by most e-commerce web sites
and attract the interest of a broad scientific community. A recommender system
uses data on users' past preferences to choose new items that might be
appreciated by a given individual user. While many approaches to recommendation
exist, the approach based on a network representation of the input data has
gained considerable attention in the past. We review here a broad range of
network-based recommendation algorithms and for the first time compare their
performance on three distinct real datasets. We present recommendation topics
that go beyond the mere question of which algorithm to use - such as the
possible influence of recommendation on the evolution of systems that use it -
and finally discuss open research directions and challenges.
</dc:description>
 <dc:description>Comment: review article; 16 pages, 4 figures, 4 tables</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06252</dc:identifier>
 <dc:identifier>Physica A 452, 192 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2016.02.021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06253</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusing Private Data over Networks</dc:title>
 <dc:creator>Koufogiannis, Fragkiskos</dc:creator>
 <dc:creator>Pappas, George</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The emergence of social and technological networks has enabled rapid sharing
of data and information. This has resulted in significant privacy concerns
where private information can be either leaked or inferred from public data.
The problem is significantly harder for social networks where we may reveal
more information to our friends than to strangers. Nonetheless, our private
information can still leak to strangers as our friends are their friends and so
on. In order to address this important challenge, in this paper, we present a
privacy-preserving mechanism that enables private data to be diffused over a
network. In particular, whenever a user wants to access another users' data,
the proposed mechanism returns a differentially private response that ensures
that the amount of private data leaked depends on the distance between the two
users in the network. While allowing global statistics to be inferred by users
acting as analysts, our mechanism guarantees that no individual user, or a
group of users, can harm the privacy guarantees of any other user. We
illustrate our mechanism with two examples: one on synthetic data where the
users share their GPS coordinates; and one on a Facebook ego-network where a
user shares her infection status.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06260</identifier>
 <datestamp>2016-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game Semantics and the Geometry of Backtracking: a New Complexity
  Analysis of Interaction</dc:title>
 <dc:creator>Aschieri, Federico</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present abstract complexity results about Coquand and Hyland-Ong game
semantics, that will lead to new bounds on the length of first-order
cut-elimination, normalization, interaction between expansion trees and any
other dialogical process game semantics can model and apply to. In particular,
we provide a novel method to bound the length of interactions between visible
strategies and to measure precisely the tower of exponentials defining the
worst-case complexity. Our study improves the old estimates on average by
several exponentials.
</dc:description>
 <dc:description>Comment: Final version</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06266</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-dynamic Green Resource Management in Downlink Heterogeneous
  Networks by Group Sparse Power Control</dc:title>
 <dc:creator>Cao, Pan</dc:creator>
 <dc:creator>Liu, Wenjia</dc:creator>
 <dc:creator>Thompson, John S.</dc:creator>
 <dc:creator>Yang, Chenyang</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the energy-saving problem for the downlink of
heterogeneous networks, which aims at minimizing the total base stations (BSs)
power consumption while each user's rate requirement is supported. The basic
idea of this work is to make use of the flexibility and scalability of the
system such that more benefits can be gained by efficient resource management.
This motivates us to propose a flexible BS power consumption model, which can
control system resources, such as antennas, frequency carriers and transmit
power allocation in an energy efficient manner rather than the &quot;on/off&quot; binary
sleep mode for BSs. To denote these power-saving modes, we employ the group
sparsity of the transmit power vector instead of the {0, 1} variables. Based on
this power model, a semi-dynamic green resource management mechanism is
proposed, which can jointly solve a series of resource management problems,
including BS association, frequency carriers (FCs) assignment, and the transmit
power allocation, by group sparse power control based on the large scale fading
values. In particular, the successive convex approximation (SCA)-based
algorithm is applied to solve a stationary solution to the original non-convex
problem. Simulation results also verify the proposed BS power model and the
green resource management mechanism.
</dc:description>
 <dc:description>Comment: submitted to IEEE Journal on Selected Areas in Communications Green
  Communications and Networking: Second Issue (under revision)</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06267</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding
  For Image &amp; Text Retrieval</dc:title>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Marcheret, Etienne</dc:creator>
 <dc:creator>Goel, Vaibhava</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Joint modeling of language and vision has been drawing increasing interest. A
multimodal data representation allowing for bidirectional retrieval of images
by sentences and vice versa is a key aspect. In this paper we present three
contributions in canonical correlation analysis (CCA) based multimodal
retrieval. Firstly, we show that an asymmetric weighting of the canonical
weights, while achieving a cross view mapping from the search to the query
space, improves the retrieval performance. Secondly, we devise a
computationally efficient model selection, crucial to generalization and
stability, in the framework of the Bj\&quot;ork Golub algorithm for regularized CCA
via spectral filtering. Finally, we introduce a Hierarchical Kernel Sentence
Embedding (HKSE) that approximates Kernel CCA for a special similarity kernel
between distribution of words embedded in a vector space. State of the art
results are obtained on MSCOCO and Flickr benchmarks when these three
techniques are used in conjunction.
</dc:description>
 <dc:description>Comment: Under Review CVPR 2017</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06276</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster method for Deep Belief Network based Object classification using
  DWT</dc:title>
 <dc:creator>Sihag, Saurabh</dc:creator>
 <dc:creator>Dutta, Pranab Kumar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A Deep Belief Network (DBN) requires large, multiple hidden layers with high
number of hidden units to learn good features from the raw pixels of large
images. This implies more training time as well as computational complexity. By
integrating DBN with Discrete Wavelet Transform (DWT), both training time and
computational complexity can be reduced. The low resolution images obtained
after application of DWT are used to train multiple DBNs. The results obtained
from these DBNs are combined using a weighted voting algorithm. The performance
of this method is found to be competent and faster in comparison with that of
traditional DBNs.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06278</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Walks with Gremlin</dc:title>
 <dc:creator>Rodriguez, Marko A.</dc:creator>
 <dc:creator>Watkins, Jennifer H.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A quantum walk places a traverser into a superposition of both graph location
and traversal &quot;spin.&quot; The walk is defined by an initial condition, an evolution
determined by a unitary coin/shift-operator, and a measurement based on the
sampling of the probability distribution generated from the quantum
wavefunction. Simple quantum walks are studied analytically, but for large
graph structures with complex topologies, numerical solutions are typically
required. For the quantum theorist, the Gremlin graph traversal machine and
language can be used for the numerical analysis of quantum walks on such
structures. Additionally, for the graph theorist, the adoption of quantum walk
principles can transform what are currently side-effect laden traversals into
pure, stateless functional flows. This is true even when the constraints of
quantum mechanics are not fully respected (e.g. reversible and unitary
evolution). In sum, Gremlin allows both types of theorist to leverage each
other's constructs for the advancement of their respective disciplines.
</dc:description>
 <dc:description>Comment: GraphDay '16, 1(1), pages 1-16, Austin Texas, January 2016</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06279</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Programmer-Interpreters</dc:title>
 <dc:creator>Reed, Scott</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose the neural programmer-interpreter (NPI): a recurrent and
compositional neural network that learns to represent and execute programs. NPI
has three learnable components: a task-agnostic recurrent core, a persistent
key-value program memory, and domain-specific encoders that enable a single NPI
to operate in multiple perceptually diverse environments with distinct
affordances. By learning to compose lower-level programs to express
higher-level programs, NPI reduces sample complexity and increases
generalization ability compared to sequence-to-sequence LSTMs. The program
memory allows efficient learning of additional tasks by building on existing
programs. NPI can also harness the environment (e.g. a scratch pad with
read-write pointers) to cache intermediate results of computation, lessening
the long-term memory burden on recurrent hidden units. In this work we train
the NPI with fully-supervised execution traces; each program has example
sequences of calls to the immediate subprograms conditioned on the input.
Rather than training on a huge number of relatively weak labels, NPI learns
from a small number of rich examples. We demonstrate the capability of our
model to learn several types of compositional programs: addition, sorting, and
canonicalizing 3D models. Furthermore, a single NPI learns to execute these
programs and all 21 associated subprograms.
</dc:description>
 <dc:description>Comment: ICLR 2016 conference submission</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06281</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Density Modeling of Images using a Generalized Normalization
  Transformation</dc:title>
 <dc:creator>Ball&#xe9;, Johannes</dc:creator>
 <dc:creator>Laparra, Valero</dc:creator>
 <dc:creator>Simoncelli, Eero P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a parametric nonlinear transformation that is well-suited for
Gaussianizing data from natural images. The data are linearly transformed, and
each component is then normalized by a pooled activity measure, computed by
exponentiating a weighted sum of rectified and exponentiated components and a
constant. We optimize the parameters of the full transformation (linear
transform, exponents, weights, constant) over a database of natural images,
directly minimizing the negentropy of the responses. The optimized
transformation substantially Gaussianizes the data, achieving a significantly
smaller mutual information between transformed components than alternative
methods including ICA and radial Gaussianization. The transformation is
differentiable and can be efficiently inverted, and thus induces a density
model on images. We show that samples of this model are visually similar to
samples of natural image patches. We demonstrate the use of the model as a
prior probability density that can be used to remove additive noise. Finally,
we show that the transformation can be cascaded, with each layer optimized
using the same Gaussianization objective, thus offering an unsupervised method
of optimizing a deep network architecture.
</dc:description>
 <dc:description>Comment: published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06285</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harvesting comparable corpora and mining them for equivalent bilingual
  sentences using statistical classification and analogy- based heuristics</dc:title>
 <dc:creator>Wo&#x142;k, Krzysztof</dc:creator>
 <dc:creator>Rejmund, Emilia</dc:creator>
 <dc:creator>Marasek, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Parallel sentences are a relatively scarce but extremely useful resource for
many applications including cross-lingual retrieval and statistical machine
translation. This research explores our new methodologies for mining such data
from previously obtained comparable corpora. The task is highly practical since
non-parallel multilingual data exist in far greater quantities than parallel
corpora, but parallel sentences are a much more useful resource. Here we
propose a web crawling method for building subject-aligned comparable corpora
from e.g. Wikipedia dumps and Euronews web page. The improvements in machine
translation are shown on Polish-English language pair for various text domains.
We also tested another method of building parallel corpora based on comparable
corpora data. It lets automatically broad existing corpus of sentences from
subject of corpora based on analogies between them.
</dc:description>
 <dc:description>Comment: Springer p. 433-441, 2015</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06285</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-25252-0_46</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06292</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Foveation-based Mechanisms Alleviate Adversarial Examples</dc:title>
 <dc:creator>Luo, Yan</dc:creator>
 <dc:creator>Boix, Xavier</dc:creator>
 <dc:creator>Roig, Gemma</dc:creator>
 <dc:creator>Poggio, Tomaso</dc:creator>
 <dc:creator>Zhao, Qi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We show that adversarial examples, i.e., the visually imperceptible
perturbations that result in Convolutional Neural Networks (CNNs) fail, can be
alleviated with a mechanism based on foveations---applying the CNN in different
image regions. To see this, first, we report results in ImageNet that lead to a
revision of the hypothesis that adversarial perturbations are a consequence of
CNNs acting as a linear classifier: CNNs act locally linearly to changes in the
image regions with objects recognized by the CNN, and in other regions the CNN
may act non-linearly. Then, we corroborate that when the neural responses are
linear, applying the foveation mechanism to the adversarial example tends to
significantly reduce the effect of the perturbation. This is because,
hypothetically, the CNNs for ImageNet are robust to changes of scale and
translation of the object produced by the foveation, but this property does not
generalize to transformations of the perturbation. As a result, the accuracy
after a foveation is almost the same as the accuracy of the CNN without the
adversarial perturbation, even if the adversarial perturbation is calculated
taking into account a foveation.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06295</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Policy Distillation</dc:title>
 <dc:creator>Rusu, Andrei A.</dc:creator>
 <dc:creator>Colmenarejo, Sergio Gomez</dc:creator>
 <dc:creator>Gulcehre, Caglar</dc:creator>
 <dc:creator>Desjardins, Guillaume</dc:creator>
 <dc:creator>Kirkpatrick, James</dc:creator>
 <dc:creator>Pascanu, Razvan</dc:creator>
 <dc:creator>Mnih, Volodymyr</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:creator>Hadsell, Raia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Policies for complex visual tasks have been successfully learned with deep
reinforcement learning, using an approach called deep Q-networks (DQN), but
relatively large (task-specific) networks and extensive training are needed to
achieve good performance. In this work, we present a novel method called policy
distillation that can be used to extract the policy of a reinforcement learning
agent and train a new network that performs at the expert level while being
dramatically smaller and more efficient. Furthermore, the same method can be
used to consolidate multiple task-specific policies into a single policy. We
demonstrate these claims using the Atari domain and show that the multi-task
distilled agent outperforms the single-task teachers as well as a
jointly-trained DQN agent.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06297</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Computation in Neural Networks for faster models</dc:title>
 <dc:creator>Bengio, Emmanuel</dc:creator>
 <dc:creator>Bacon, Pierre-Luc</dc:creator>
 <dc:creator>Pineau, Joelle</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning has become the state-of-art tool in many applications, but the
evaluation and training of deep models can be time-consuming and
computationally expensive. The conditional computation approach has been
proposed to tackle this problem (Bengio et al., 2013; Davis &amp; Arel, 2013). It
operates by selectively activating only parts of the network at a time. In this
paper, we use reinforcement learning as a tool to optimize conditional
computation policies. More specifically, we cast the problem of learning
activation-dependent policies for dropping out blocks of units as a
reinforcement learning problem. We propose a learning scheme motivated by
computation speed, capturing the idea of wanting to have parsimonious
activations while maintaining prediction accuracy. We apply a policy gradient
algorithm for learning policies that optimize this loss function and propose a
regularization mechanism that encourages diversification of the dropout policy.
We present encouraging empirical results showing that this approach improves
the speed of computation without impacting the quality of the approximation.
</dc:description>
 <dc:description>Comment: ICLR 2016 submission, revised</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06303</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternative structures for character-level RNNs</dc:title>
 <dc:creator>Bojanowski, Piotr</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recurrent neural networks are convenient and efficient models for language
modeling. However, when applied on the level of characters instead of words,
they suffer from several problems. In order to successfully model long-term
dependencies, the hidden representation needs to be large. This in turn implies
higher computational costs, which can become prohibitive in practice. We
propose two alternative structural modifications to the classical RNN model.
The first one consists on conditioning the character level representation on
the previous word representation. The other one uses the character history to
condition the output probability. We evaluate the performance of the two
proposed modifications on challenging, multi-lingual real world data.
</dc:description>
 <dc:description>Comment: First revision. Updated Table 3, extended Sec. 5.3 and added a
  paragraph to the conclusion,</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06306</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Convolutional Neural Networks under Adversarial Noise</dc:title>
 <dc:creator>Jin, Jonghoon</dc:creator>
 <dc:creator>Dundar, Aysegul</dc:creator>
 <dc:creator>Culurciello, Eugenio</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent studies have shown that Convolutional Neural Networks (CNNs) are
vulnerable to a small perturbation of input called &quot;adversarial examples&quot;. In
this work, we propose a new feedforward CNN that improves robustness in the
presence of adversarial noise. Our model uses stochastic additive noise added
to the input image and to the CNN models. The proposed model operates in
conjunction with a CNN trained with either standard or adversarial objective
function. In particular, convolution, max-pooling, and ReLU layers are modified
to benefit from the noise model. Our feedforward model is parameterized by only
a mean and variance per pixel which simplifies computations and makes our
method scalable to a deep architecture. From CIFAR-10 and ImageNet test, the
proposed model outperforms other methods and the improvement is more evident
for difficult classification tasks or stronger adversarial noise.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06309</identifier>
 <datestamp>2016-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatio-temporal video autoencoder with differentiable memory</dc:title>
 <dc:creator>Patraucean, Viorica</dc:creator>
 <dc:creator>Handa, Ankur</dc:creator>
 <dc:creator>Cipolla, Roberto</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe a new spatio-temporal video autoencoder, based on a classic
spatial image autoencoder and a novel nested temporal autoencoder. The temporal
encoder is represented by a differentiable visual memory composed of
convolutional long short-term memory (LSTM) cells that integrate changes over
time. Here we target motion changes and use as temporal decoder a robust
optical flow prediction module together with an image sampler serving as
built-in feedback loop. The architecture is end-to-end differentiable. At each
time step, the system receives as input a video frame, predicts the optical
flow based on the current observation and the LSTM memory state as a dense
transformation map, and applies it to the current frame to generate the next
frame. By minimising the reconstruction error between the predicted next frame
and the corresponding ground truth next frame, we train the whole system to
extract features useful for motion estimation without any supervision effort.
We present one direct application of the proposed framework in
weakly-supervised semantic segmentation of videos through label propagation
using optical flow.
</dc:description>
 <dc:description>Comment: The experiments section has been extended and a direct application to
  weakly-supervised video segmentation through label propagation has been
  included</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06312</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good, Better, Best: Choosing Word Embedding Context</dc:title>
 <dc:creator>Cross, James</dc:creator>
 <dc:creator>Xiang, Bing</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose two methods of learning vector representations of words and
phrases that each combine sentence context with structural features extracted
from dependency trees. Using several variations of neural network classifier,
we show that these combined methods lead to improved performance when used as
input features for supervised term-matching.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06313</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preprint WebVRGIS Based Traffic Analysis and Visualization System</dc:title>
 <dc:creator>Li, Xiaoming</dc:creator>
 <dc:creator>Lv, Zhihan</dc:creator>
 <dc:creator>Wang, Weixi</dc:creator>
 <dc:creator>Zhang, Baoyun</dc:creator>
 <dc:creator>Hu, Jinxing</dc:creator>
 <dc:creator>Yin, Ling</dc:creator>
 <dc:creator>Feng, Shengzhong</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This is the preprint version of our paper on Advances in Engineering
Software. With several characteristics, such as large scale, diverse
predictability and timeliness, the city traffic data falls in the range of
definition of Big Data. A Virtual Reality GIS based traffic analysis and
visualization system is proposed as a promising and inspiring approach to
manage and develop traffic big data. In addition to the basic GIS interaction
functions, the proposed system also includes some intelligent visual analysis
and forecasting functions. The passenger flow forecasting algorithm is
introduced in detail.
</dc:description>
 <dc:description>Comment: This is the preprint version of our paper on Advances in Engineering
  Software. arXiv admin note: substantial text overlap with arXiv:1504.01057,
  arXiv:1504.01375</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06314</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why M Heads are Better than One: Training a Diverse Ensemble of Deep
  Networks</dc:title>
 <dc:creator>Lee, Stefan</dc:creator>
 <dc:creator>Purushwalkam, Senthil</dc:creator>
 <dc:creator>Cogswell, Michael</dc:creator>
 <dc:creator>Crandall, David</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Convolutional Neural Networks have achieved state-of-the-art performance on a
wide range of tasks. Most benchmarks are led by ensembles of these powerful
learners, but ensembling is typically treated as a post-hoc procedure
implemented by averaging independently trained models with model variation
induced by bagging or random initialization. In this paper, we rigorously treat
ensembling as a first-class problem to explicitly address the question: what
are the best strategies to create an ensemble? We first compare a large number
of ensembling strategies, and then propose and evaluate novel strategies, such
as parameter sharing (through a new family of models we call TreeNets) as well
as training under ensemble-aware and diversity-encouraging losses. We
demonstrate that TreeNets can improve ensemble performance and that diverse
ensembles can be trained end-to-end under a unified loss, achieving
significantly higher &quot;oracle&quot; accuracies than classical ensembles.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06316</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>face anti-spoofing based on color texture analysis</dc:title>
 <dc:creator>Boulkenafet, Zinelabidine</dc:creator>
 <dc:creator>Komulainen, Jukka</dc:creator>
 <dc:creator>Hadid, Abdenour</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research on face spoofing detection has mainly been focused on analyzing the
luminance of the face images, hence discarding the chrominance information
which can be useful for discriminating fake faces from genuine ones. In this
work, we propose a new face anti-spoofing method based on color texture
analysis. We analyze the joint color-texture information from the luminance and
the chrominance channels using a color local binary pattern descriptor. More
specifically, the feature histograms are extracted from each image band
separately. Extensive experiments on two benchmark datasets, namely CASIA face
anti-spoofing and Replay-Attack databases, showed excellent results compared to
the state-of-the-art. Most importantly, our inter-database evaluation depicts
that the proposed approach showed very promising generalization capabilities.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06321</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural network-based clustering using pairwise constraints</dc:title>
 <dc:creator>Hsu, Yen-Chang</dc:creator>
 <dc:creator>Kira, Zsolt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a neural network-based end-to-end clustering framework.
We design a novel strategy to utilize the contrastive criteria for pushing
data-forming clusters directly from raw data, in addition to learning a feature
embedding suitable for such clustering. The network is trained with weak
labels, specifically partial pairwise relationships between data instances. The
cluster assignments and their probabilities are then obtained at the output
layer by feed-forwarding the data. The framework has the interesting
characteristic that no cluster centers need to be explicitly specified, thus
the resulting cluster distribution is purely data-driven and no distance
metrics need to be predefined. The experiments show that the proposed approach
beats the conventional two-stage method (feature embedding with k-means) by a
significant margin. It also compares favorably to the performance of the
standard cross entropy loss for classification. Robustness analysis also shows
that the method is largely insensitive to the number of clusters. Specifically,
we show that the number of dominant clusters is close to the true number of
clusters even when a large k is used for clustering.
</dc:description>
 <dc:description>Comment: ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06324</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Convergence of ADMM in Nonconvex Nonsmooth Optimization</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Yin, Wotao</dc:creator>
 <dc:creator>Zeng, Jinshan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we analyze the convergence of the alternating direction method
of multipliers (ADMM) for minimizing a nonconvex and possibly nonsmooth
objective function, $\phi(x_0,\ldots,x_p,y)$, subject to coupled linear
equality constraints. Our ADMM updates each of the primal variables
$x_0,\ldots,x_p,y$, followed by updating the dual variable. We separate the
variable $y$ from $x_i$'s as it has a special role in our analysis.
  The developed convergence guarantee covers a variety of nonconvex functions
such as piecewise linear functions, $\ell_q$ quasi-norm, Schatten-$q$
quasi-norm ($0&lt;q&lt;1$), minimax concave penalty (MCP), and smoothly clipped
absolute deviation (SCAD) penalty. It also allows nonconvex constraints such as
compact manifolds (e.g., spherical, Stiefel, and Grassman manifolds) and linear
complementarity constraints. Also, the $x_0$-block can be almost any lower
semi-continuous function.
  By applying our analysis, we show, for the first time, that several ADMM
algorithms applied to solve nonconvex models in statistical learning,
optimization on manifold, and matrix decomposition are guaranteed to converge.
  Our results provide sufficient conditions for ADMM to converge on (convex or
nonconvex) monotropic programs with three or more blocks, as they are special
cases of our model.
  ADMM has been regarded as a variant to the augmented Lagrangian method (ALM).
We present a simple example to illustrate how ADMM converges but ALM diverges
with bounded penalty parameter $\beta$. Indicated by this example and other
analysis in this paper, ADMM might be a better choice than ALM for some
nonconvex \emph{nonsmooth} problems, because ADMM is not only easier to
implement, it is also more likely to converge for the concerned scenarios.
</dc:description>
 <dc:description>Comment: 33 pages, 1 figure, Accepted by Journal of Scientific Computing</dc:description>
 <dc:date>2015-11-18</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06328</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manifold Regularized Discriminative Neural Networks</dc:title>
 <dc:creator>Zhai, Shuangfei</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unregularized deep neural networks (DNNs) can be easily overfit with a
limited sample size. We argue that this is mostly due to the disriminative
nature of DNNs which directly model the conditional probability (or score) of
labels given the input. The ignorance of input distribution makes DNNs
difficult to generalize to unseen data. Recent advances in regularization
techniques, such as pretraining and dropout, indicate that modeling input data
distribution (either explicitly or implicitly) greatly improves the
generalization ability of a DNN. In this work, we explore the manifold
hypothesis which assumes that instances within the same class lie in a smooth
manifold. We accordingly propose two simple regularizers to a standard
discriminative DNN. The first one, named Label-Aware Manifold Regularization,
assumes the availability of labels and penalizes large norms of the loss
function w.r.t. data points. The second one, named Label-Independent Manifold
Regularization, does not use label information and instead penalizes the
Frobenius norm of the Jacobian matrix of prediction scores w.r.t. data points,
which makes semi-supervised learning possible. We perform extensive control
experiments on fully supervised and semi-supervised tasks using the MNIST,
CIFAR10 and SVHN datasets and achieve excellent results.
</dc:description>
 <dc:description>Comment: In submission to ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06333</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) and Its
  Application to Inverse Problems</dc:title>
 <dc:creator>Ravishankar, Saiprasad</dc:creator>
 <dc:creator>Nadakuditi, Raj Rao</dc:creator>
 <dc:creator>Fessler, Jeffrey A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The sparsity of signals in a transform domain or dictionary has been
exploited in applications such as compression, denoising and inverse problems.
More recently, data-driven adaptation of synthesis dictionaries has shown
promise compared to analytical dictionary models. However, dictionary learning
problems are typically non-convex and NP-hard, and the usual alternating
minimization approaches for these problems are often computationally expensive,
with the computations dominated by the NP-hard synthesis sparse coding step.
This paper exploits the ideas that drive algorithms such as K-SVD, and
investigates in detail efficient methods for aggregate sparsity penalized
dictionary learning by first approximating the data with a sum of sparse
rank-one matrices (outer products) and then using a block coordinate descent
approach to estimate the unknowns. The resulting block coordinate descent
algorithms involve efficient closed-form solutions. Furthermore, we consider
the problem of dictionary-blind image reconstruction, and propose novel and
efficient algorithms for adaptive image reconstruction using block coordinate
descent and sum of outer products methodologies. We provide a convergence study
of the algorithms for dictionary learning and dictionary-blind image
reconstruction. Our numerical experiments show the promising performance and
speed-ups provided by the proposed methods over previous schemes in sparse data
representation and compressed sensing-based image reconstruction.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Computational Imaging. This paper
  also cites experimental results reported in arXiv:1511.08842</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06333</dc:identifier>
 <dc:identifier>doi:10.1109/TCI.2017.2697206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06335</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Deep Embedding for Clustering Analysis</dc:title>
 <dc:creator>Xie, Junyuan</dc:creator>
 <dc:creator>Girshick, Ross</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Clustering is central to many data-driven application domains and has been
studied extensively in terms of distance functions and grouping algorithms.
Relatively little work has focused on learning representations for clustering.
In this paper, we propose Deep Embedded Clustering (DEC), a method that
simultaneously learns feature representations and cluster assignments using
deep neural networks. DEC learns a mapping from the data space to a
lower-dimensional feature space in which it iteratively optimizes a clustering
objective. Our experimental evaluations on image and text corpora show
significant improvement over state-of-the-art methods.
</dc:description>
 <dc:description>Comment: icml2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06340</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Classification by Pre-conditioned LASSO and Transductive
  Diffusion Component Analysis</dc:title>
 <dc:creator>Fu, Yanwei</dc:creator>
 <dc:creator>Huang, De-An</dc:creator>
 <dc:creator>Sigal, Leonid</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Modern machine learning-based recognition approaches require large-scale
datasets with large number of labelled training images. However, such datasets
are inherently difficult and costly to collect and annotate. Hence there is a
great and growing interest in automatic dataset collection methods that can
leverage the web. % which are collected % in a cheap, efficient and yet
unreliable way. Collecting datasets in this way, however, requires robust and
efficient ways for detecting and excluding outliers that are common and
prevalent. % Outliers are thus a % prominent treat of using these dataset. So
far, there have been a limited effort in machine learning community to directly
detect outliers for robust classification. Inspired by the recent work on
Pre-conditioned LASSO, this paper formulates the outlier detection task using
Pre-conditioned LASSO and employs \red{unsupervised} transductive diffusion
component analysis to both integrate the topological structure of the data
manifold, from labeled and unlabeled instances, and reduce the feature
dimensionality. Synthetic experiments as well as results on two real-world
classification tasks show that our framework can robustly detect the outliers
and improve classification.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06341</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communicating Semantics: Reference by Description</dc:title>
 <dc:creator>Guha, Ramanathan V</dc:creator>
 <dc:creator>Gupta, Vineet</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Messages often refer to entities such as people, places and events. Correct
identification of the intended reference is an essential part of communication.
Lack of shared unique names often complicates entity reference. Shared
knowledge can be used to construct uniquely identifying descriptive references
for entities with ambiguous names. We introduce a mathematical model for
`Reference by Description', derive results on the conditions under which, with
high probability, programs can construct unambiguous references to most
entities in the domain of discourse and provide empirical validation of these
results.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06342</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning</dc:title>
 <dc:creator>Parisotto, Emilio</dc:creator>
 <dc:creator>Ba, Jimmy Lei</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The ability to act in multiple environments and transfer previous knowledge
to new situations can be considered a critical aspect of any intelligent agent.
Towards this goal, we define a novel method of multitask and transfer learning
that enables an autonomous agent to learn how to behave in multiple tasks
simultaneously, and then generalize its knowledge to new domains. This method,
termed &quot;Actor-Mimic&quot;, exploits the use of deep reinforcement learning and model
compression techniques to train a single policy network that learns how to act
in a set of distinct tasks by using the guidance of several expert teachers. We
then show that the representations learnt by the deep policy network are
capable of generalizing to new tasks with no prior expert guidance, speeding up
learning in novel environments. Although our method can in general be applied
to a wide range of problems, we use Atari games as a testing environment to
demonstrate these methods.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06343</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Batch Selection for Faster Training of Neural Networks</dc:title>
 <dc:creator>Loshchilov, Ilya</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Deep neural networks are commonly trained using stochastic non-convex
optimization procedures, which are driven by gradient information estimated on
fractions (batches) of the dataset. While it is commonly accepted that batch
size is an important parameter for offline tuning, the benefits of online
selection of batches remain poorly understood. We investigate online batch
selection strategies for two state-of-the-art methods of stochastic
gradient-based optimization, AdaDelta and Adam. As the loss function to be
minimized for the whole dataset is an aggregation of loss functions of
individual datapoints, intuitively, datapoints with the greatest loss should be
considered (selected in a batch) more frequently. However, the limitations of
this intuition and the proper control of the selection pressure over time are
open questions. We propose a simple strategy where all datapoints are ranked
w.r.t. their latest known loss value and the probability to be selected decays
exponentially as a function of rank. Our experimental results on the MNIST
dataset suggest that selecting batches speeds up both AdaDelta and Adam by a
factor of about 5.
</dc:description>
 <dc:description>Comment: Workshop paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06344</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel-Adaptive Packetization Policy for Minimal Latency and Maximal
  Energy Efficiency</dc:title>
 <dc:creator>Razi, Abolfazl</dc:creator>
 <dc:creator>Afghah, Fatemeh</dc:creator>
 <dc:creator>Abedi, Ali</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This article considers the problem of delay optimal bundling of the input
symbols into transmit packets in the entry point of a wireless sensor network
such that the link delay is minimized under an arbitrary arrival rate and a
given channel error rate. The proposed policy exploits the variable packet
length feature of contemporary communications protocols in order to minimize
the link delay via packet length regularization. This is performed through
concrete characterization of the end-to-end link delay for zero error tolerance
system with First Come First Serve (FCFS)queuing discipline and Automatic
Repeat Request (ARQ) retransmission mechanism. The derivations are provided for
an uncoded system as well as a coded system with a given bit error rate. The
proposed packetization policy provides an optimal packetization interval that
minimizes the end-to-end delay for a given channel with certain bit error
probability. This algorithm can also be used for near-optimal bundling of input
symbols for dynamic channel conditions provided that the channel condition
varies slowly over time with respect to symbol arrival rate. This algorithm
complements the current network-based delay-optimal routing and scheduling
algorithms in order to further reduce the end-to-end delivery time. Moreover,
the proposed method is employed to solve the problem of energy efficiency
maximization under an average delay constraint by recasting it as a convex
optimization problem.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Wireless Communications, to appear 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06344</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2015.2503750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06348</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How much data is needed to train a medical image deep learning system to
  achieve necessary high accuracy?</dc:title>
 <dc:creator>Cho, Junghwan</dc:creator>
 <dc:creator>Lee, Kyewook</dc:creator>
 <dc:creator>Shin, Ellie</dc:creator>
 <dc:creator>Choy, Garry</dc:creator>
 <dc:creator>Do, Synho</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The use of Convolutional Neural Networks (CNN) in natural image
classification systems has produced very impressive results. Combined with the
inherent nature of medical images that make them ideal for deep-learning,
further application of such systems to medical image classification holds much
promise. However, the usefulness and potential impact of such a system can be
completely negated if it does not reach a target accuracy. In this paper, we
present a study on determining the optimum size of the training data set
necessary to achieve high classification accuracy with low variance in medical
image classification systems. The CNN was applied to classify axial Computed
Tomography (CT) images into six anatomical classes. We trained the CNN using
six different sizes of training data set (5, 10, 20, 50, 100, and 200) and then
tested the resulting system with a total of 6000 CT images. All images were
acquired from the Massachusetts General Hospital (MGH) Picture Archiving and
Communication System (PACS). Using this data, we employ the learning curve
approach to predict classification accuracy at a given training sample size.
Our research will present a general methodology for determining the training
data set size necessary to achieve a certain target classification accuracy
that can be easily applied to other problems within such systems.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06349</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Sentences from a Continuous Space</dc:title>
 <dc:creator>Bowman, Samuel R.</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Dai, Andrew M.</dc:creator>
 <dc:creator>Jozefowicz, Rafal</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The standard recurrent neural network language model (RNNLM) generates
sentences one word at a time and does not work from an explicit global sentence
representation. In this work, we introduce and study an RNN-based variational
autoencoder generative model that incorporates distributed latent
representations of entire sentences. This factorization allows it to explicitly
model holistic properties of sentences such as style, topic, and high-level
syntactic features. Samples from the prior over these sentence representations
remarkably produce diverse and well-formed sentences through simple
deterministic decoding. By examining paths through this latent space, we are
able to generate coherent novel sentences that interpolate between known
sentences. We present techniques for solving the difficult learning problem
presented by this model, demonstrate its effectiveness in imputing missing
words, explore many interesting properties of the model's latent sentence
space, and present negative results on the use of the model in language
modeling.
</dc:description>
 <dc:description>Comment: First two authors contributed equally. Work was done when all authors
  were at Google, Inc</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06349</dc:identifier>
 <dc:identifier>SIGNLL Conference on Computational Natural Language Learning
  (CONLL), 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06350</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structured Prediction Energy Networks</dc:title>
 <dc:creator>Belanger, David</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce structured prediction energy networks (SPENs), a flexible
framework for structured prediction. A deep architecture is used to define an
energy function of candidate labels, and then predictions are produced by using
back-propagation to iteratively optimize the energy with respect to the labels.
This deep architecture captures dependencies between labels that would lead to
intractable graphical models, and performs structure learning by automatically
learning discriminative features of the structured output. One natural
application of our technique is multi-label classification, which traditionally
has required strict prior assumptions about the interactions between labels to
ensure tractable learning and prediction. We are able to apply SPENs to
multi-label problems with substantially larger label sets than previous
applications of structured prediction, while modeling high-order interactions
using minimal structural assumptions. Overall, deep learning provides
remarkable tools for learning features of the inputs to a prediction problem,
and this work extends these techniques to learning features of structured
outputs. Our experiments provide impressive performance on a variety of
benchmark multi-label classification tasks, demonstrate that our technique can
be used to provide interpretable structure learning, and illuminate fundamental
trade-offs between feed-forward and iterative structured prediction.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06351</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Representations Using Complex-Valued Nets</dc:title>
 <dc:creator>Sarroff, Andy M.</dc:creator>
 <dc:creator>Shepardson, Victor</dc:creator>
 <dc:creator>Casey, Michael A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Complex-valued neural networks (CVNNs) are an emerging field of research in
neural networks due to their potential representational properties for audio,
image, and physiological signals. It is common in signal processing to
transform sequences of real values to the complex domain via a set of complex
basis functions, such as the Fourier transform. We show how CVNNs can be used
to learn complex representations of real valued time-series data. We present
methods and results using a framework that can compose holomorphic and
non-holomorphic functions in a multi-layer network using a theoretical result
called the Wirtinger derivative. We test our methods on a representation
learning task for real-valued signals, recurrent complex-valued networks and
their real-valued counterparts. Our results show that recurrent complex-valued
networks can perform as well as their real-valued counterparts while learning
filters that are representative of the domain of the data.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06353</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution of public cooperation in a monitored society with implicated
  punishment and within-group enforcement</dc:title>
 <dc:creator>Chen, Xiaojie</dc:creator>
 <dc:creator>Sasaki, Tatsuya</dc:creator>
 <dc:creator>Perc, Matjaz</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Monitoring with implicated punishment is common in human societies to avert
freeriding on common goods. But is it effective in promoting public
cooperation? We show that the introduction of monitoring and implicated
punishment is indeed effective, as it transforms the public goods game to a
coordination game, thus rendering cooperation viable in infinite and finite
well-mixed populations. We also show that the addition of within-group
enforcement further promotes the evolution of public cooperation. However,
although the group size in this context has nonlinear effects on collective
action, an intermediate group size is least conductive to cooperative
behaviour. This contradicts recent field observations, where an intermediate
group size was declared optimal with the conjecture that group-size effects and
within-group enforcement are responsible. Our theoretical research thus
clarifies key aspects of monitoring with implicated punishment in human
societies, and additionally, it reveals fundamental group-size effects that
facilitate prosocial collective action.
</dc:description>
 <dc:description>Comment: 9 two-column pages, 5 figures; accepted for publication in Scientific
  Reports</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06353</dc:identifier>
 <dc:identifier>Sci. Rep. 5 (2015) 17050</dc:identifier>
 <dc:identifier>doi:10.1038/srep17050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06359</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FRIST - Flipping and Rotation Invariant Sparsifying Transform Learning
  and Applications</dc:title>
 <dc:creator>Wen, Bihan</dc:creator>
 <dc:creator>Ravishankar, Saiprasad</dc:creator>
 <dc:creator>Bresler, Yoram</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Features based on sparse representation, especially using the synthesis
dictionary model, have been heavily exploited in signal processing and computer
vision. However, synthesis dictionary learning typically involves NP-hard
sparse coding and expensive learning steps. Recently, sparsifying transform
learning received interest for its cheap computation and its optimal updates in
the alternating algorithms. In this work, we develop a methodology for learning
Flipping and Rotation Invariant Sparsifying Transforms, dubbed FRIST, to better
represent natural images that contain textures with various geometrical
directions. The proposed alternating FRIST learning algorithm involves
efficient optimal updates. We provide a convergence guarantee, and demonstrate
the empirical convergence behavior of the proposed FRIST learning approach.
Preliminary experiments show the promising performance of FRIST learning for
sparse image representation, segmentation, denoising, robust inpainting, and
compressed sensing-based magnetic resonance image reconstruction.
</dc:description>
 <dc:description>Comment: Published in Inverse Problems</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06361</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Order-Embeddings of Images and Language</dc:title>
 <dc:creator>Vendrov, Ivan</dc:creator>
 <dc:creator>Kiros, Ryan</dc:creator>
 <dc:creator>Fidler, Sanja</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hypernymy, textual entailment, and image captioning can be seen as special
cases of a single visual-semantic hierarchy over words, sentences, and images.
In this paper we advocate for explicitly modeling the partial order structure
of this hierarchy. Towards this goal, we introduce a general method for
learning ordered representations, and show how it can be applied to a variety
of tasks involving images and language. We show that the resulting
representations improve performance over current approaches for hypernym
prediction and image-caption retrieval.
</dc:description>
 <dc:description>Comment: ICLR camera-ready version</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06362</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient inference in occlusion-aware generative models of images</dc:title>
 <dc:creator>Huang, Jonathan</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a generative model of images based on layering, in which image
layers are individually generated, then composited from front to back. We are
thus able to factor the appearance of an image into the appearance of
individual objects within the image --- and additionally for each individual
object, we can factor content from pose. Unlike prior work on layered models,
we learn a shape prior for each object/layer, allowing the model to tease out
which object is in front by looking for a consistent shape, without needing
access to motion cues or any labeled data. We show that ordinary stochastic
gradient variational bayes (SGVB), which optimizes our fully differentiable
lower-bound on the log-likelihood, is sufficient to learn an interpretable
representation of images. Finally we present experiments demonstrating the
effectiveness of the model for inferring foreground and background objects in
images.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06363</identifier>
 <datestamp>2016-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization of two memristive coupled van der Pol oscillators</dc:title>
 <dc:creator>Ignatov, M.</dc:creator>
 <dc:creator>Hansen, M.</dc:creator>
 <dc:creator>Ziegler, M.</dc:creator>
 <dc:creator>Kohlstedt, H.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  The objective of this paper is to explore the possibility to couple two van
der Pol (vdP) oscillators via a resistance-capacitance (RC) network comprising
a Ag-TiOx-Al memristive device. The coupling was mediated by connecting the
gate terminals of two programmable unijunction transistors (PUTs) through the
network. In the high resistance state (HRS) the memresistance was in the order
of MOhm leading to two independent selfsustained oscillators characterized by
the different frequencies f1 and f2 and no phase relation between the
oscillations. After a few cycles and in dependency of the mediated pulse
amplitude the memristive device switched to the low resistance state (LRS) and
a frequency adaptation and phase locking was observed. The experimental results
are underlined by theoretically considering a system of two coupled vdP
equations. The presented neuromorphic circuitry conveys two essentials
principle of interacting neuronal ensembles: synchronization and memory. The
experiment may path the way to larger neuromorphic networks in which the
coupling parameters can vary in time and strength and are realized by
memristive devices.
</dc:description>
 <dc:date>2015-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06363</dc:identifier>
 <dc:identifier>doi:10.1063/1.4942832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06379</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Adaptive Network Intelligence</dc:title>
 <dc:creator>Searle, Richard</dc:creator>
 <dc:creator>Bingham-Walker, Megan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Accurate representational learning of both the explicit and implicit
relationships within data is critical to the ability of machines to perform
more complex and abstract reasoning tasks. We describe the efficient weakly
supervised learning of such inferences by our Dynamic Adaptive Network
Intelligence (DANI) model. We report state-of-the-art results for DANI over
question answering tasks in the bAbI dataset that have proved difficult for
contemporary approaches to learning representation (Weston et al., 2015).
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, 3 tables, ICLR 2016 conference paper submission</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06380</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Visual Structure using Predictive Generative
  Networks</dc:title>
 <dc:creator>Lotter, William</dc:creator>
 <dc:creator>Kreiman, Gabriel</dc:creator>
 <dc:creator>Cox, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  The ability to predict future states of the environment is a central pillar
of intelligence. At its core, effective prediction requires an internal model
of the world and an understanding of the rules by which the world changes.
Here, we explore the internal models developed by deep neural networks trained
using a loss based on predicting future frames in synthetic video sequences,
using a CNN-LSTM-deCNN framework. We first show that this architecture can
achieve excellent performance in visual sequence prediction tasks, including
state-of-the-art performance in a standard 'bouncing balls' dataset (Sutskever
et al., 2009). Using a weighted mean-squared error and adversarial loss
(Goodfellow et al., 2014), the same architecture successfully extrapolates
out-of-the-plane rotations of computer-generated faces. Furthermore, despite
being trained end-to-end to predict only pixel-level information, our
Predictive Generative Networks learn a representation of the latent structure
of the underlying three-dimensional objects themselves. Importantly, we find
that this representation is naturally tolerant to object transformations, and
generalizes well to new tasks, such as classification of static images. Similar
models trained solely with a reconstruction loss fail to generalize as
effectively. We argue that prediction can serve as a powerful unsupervised loss
for learning rich internal representations of high-level object features.
</dc:description>
 <dc:description>Comment: under review as conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06381</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Manifold Regularized Deep Neural Networks using Adversarial Examples</dc:title>
 <dc:creator>Lee, Taehoon</dc:creator>
 <dc:creator>Choi, Minsuk</dc:creator>
 <dc:creator>Yoon, Sungroh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning meaningful representations using deep neural networks involves
designing efficient training schemes and well-structured networks. Currently,
the method of stochastic gradient descent that has a momentum with dropout is
one of the most popular training protocols. Based on that, more advanced
methods (i.e., Maxout and Batch Normalization) have been proposed in recent
years, but most still suffer from performance degradation caused by small
perturbations, also known as adversarial examples. To address this issue, we
propose manifold regularized networks (MRnet) that utilize a novel training
objective function that minimizes the difference between multi-layer embedding
results of samples and those adversarial. Our experimental results demonstrated
that MRnet is more resilient to adversarial examples and helps us to generalize
representations on manifolds. Furthermore, combining MRnet and dropout allowed
us to achieve competitive classification performances for three well-known
benchmarks: MNIST, CIFAR-10, and SVHN.
</dc:description>
 <dc:description>Comment: Figure 2, 5, 7, and several descriptions revised</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06382</identifier>
 <datestamp>2016-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Refinement of Approximate Posterior for Training Directed
  Belief Networks</dc:title>
 <dc:creator>Hjelm, R Devon</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Chung, Junyoung</dc:creator>
 <dc:creator>Salakhutdinov, Russ</dc:creator>
 <dc:creator>Calhoun, Vince</dc:creator>
 <dc:creator>Jojic, Nebojsa</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Variational methods that rely on a recognition network to approximate the
posterior of directed graphical models offer better inference and learning than
previous methods. Recent advances that exploit the capacity and flexibility in
this approach have expanded what kinds of models can be trained. However, as a
proposal for the posterior, the capacity of the recognition network is limited,
which can constrain the representational power of the generative model and
increase the variance of Monte Carlo estimates. To address these issues, we
introduce an iterative refinement procedure for improving the approximate
posterior of the recognition network and show that training with the refined
posterior is competitive with state-of-the-art methods. The advantages of
refinement are further evident in an increased effective sample size, which
implies a lower variance of gradient estimates.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06384</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralization of a Machine: Some Definitions</dc:title>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We define some notions of the decentralization of a deterministic
input-output machine. This opens the possibility for introducing game-theoretic
elements -- such as strategic players -- inside the machine, as part of its
design.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06385</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Gradient Regularization Family for Adversarial Examples</dc:title>
 <dc:creator>Lyu, Chunchuan</dc:creator>
 <dc:creator>Huang, Kaizhu</dc:creator>
 <dc:creator>Liang, Hai-Ning</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adversarial examples are augmented data points generated by imperceptible
perturbation of input samples. They have recently drawn much attention with the
machine learning and data mining community. Being difficult to distinguish from
real examples, such adversarial examples could change the prediction of many of
the best learning models including the state-of-the-art deep learning models.
Recent attempts have been made to build robust models that take into account
adversarial examples. However, these methods can either lead to performance
drops or lack mathematical motivations. In this paper, we propose a unified
framework to build robust machine learning models against adversarial examples.
More specifically, using the unified framework, we develop a family of gradient
regularization methods that effectively penalize the gradient of loss function
w.r.t. inputs. Our proposed framework is appealing in that it offers a unified
view to deal with adversarial examples. It incorporates another
recently-proposed perturbation based approach as a special case. In addition,
we present some visual effects that reveals semantic meaning in those
perturbations, and thus support our regularization method and provide another
explanation for generalizability of adversarial examples. By applying this
technique to Maxout networks, we conduct a series of experiments and achieve
encouraging results on two benchmark datasets. In particular,we attain the best
accuracy on MNIST data (without data augmentation) and competitive performance
on CIFAR-10 data.
</dc:description>
 <dc:description>Comment: The paper has been presented at ICDM 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06388</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In
  Neural Word Embeddings</dc:title>
 <dc:creator>Trask, Andrew</dc:creator>
 <dc:creator>Michalak, Phil</dc:creator>
 <dc:creator>Liu, John</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Neural word representations have proven useful in Natural Language Processing
(NLP) tasks due to their ability to efficiently model complex semantic and
syntactic word relationships. However, most techniques model only one
representation per word, despite the fact that a single word can have multiple
meanings or &quot;senses&quot;. Some techniques model words by using multiple vectors
that are clustered based on context. However, recent neural approaches rarely
focus on the application to a consuming NLP algorithm. Furthermore, the
training process of recent word-sense models is expensive relative to
single-sense embedding processes. This paper presents a novel approach which
addresses these concerns by modeling multiple embeddings for each word based on
supervised disambiguation, which provides a fast and accurate way for a
consuming NLP model to select a sense-disambiguated embedding. We demonstrate
that these embeddings can disambiguate both contrastive senses such as nominal
and verbal senses as well as nuanced senses such as sarcasm. We further
evaluate Part-of-Speech disambiguated embeddings on neural dependency parsing,
yielding a greater than 8% average error reduction in unlabeled attachment
scores across 6 languages.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06390</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised and Semi-supervised Learning with Categorical Generative
  Adversarial Networks</dc:title>
 <dc:creator>Springenberg, Jost Tobias</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we present a method for learning a discriminative classifier
from unlabeled or partially labeled data. Our approach is based on an objective
function that trades-off mutual information between observed examples and their
predicted categorical class distribution, against robustness of the classifier
to an adversarial generative model. The resulting algorithm can either be
interpreted as a natural generalization of the generative adversarial networks
(GAN) framework or as an extension of the regularized information maximization
(RIM) framework to robust classification against an optimal adversary. We
empirically evaluate our method - which we dub categorical generative
adversarial networks (or CatGAN) - on synthetic data as well as on challenging
image classification tasks, demonstrating the robustness of the learned
classifiers. We further qualitatively assess the fidelity of samples generated
by the adversarial generator that is learned alongside the discriminative
classifier, and identify links between the CatGAN objective and discriminative
clustering algorithms (such as RIM).
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06391</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Order Matters: Sequence to sequence for sets</dc:title>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Bengio, Samy</dc:creator>
 <dc:creator>Kudlur, Manjunath</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sequences have become first class citizens in supervised learning thanks to
the resurgence of recurrent neural networks. Many complex tasks that require
mapping from or to a sequence of observations can now be formulated with the
sequence-to-sequence (seq2seq) framework which employs the chain rule to
efficiently represent the joint probability of sequences. In many cases,
however, variable sized inputs and/or outputs might not be naturally expressed
as sequences. For instance, it is not clear how to input a set of numbers into
a model where the task is to sort them; similarly, we do not know how to
organize outputs when they correspond to random variables and the task is to
model their unknown joint probability. In this paper, we first show using
various examples that the order in which we organize input and/or output data
matters significantly when learning an underlying model. We then discuss an
extension of the seq2seq framework that goes beyond sequences and handles input
sets in a principled way. In addition, we propose a loss which, by searching
over possible orders during training, deals with the lack of structure of
output sets. We show empirical evidence of our claims regarding ordering, and
on the modifications to the seq2seq framework on benchmark language modeling
and parsing tasks, as well as two artificial tasks -- sorting numbers and
estimating the joint probability of unknown graphical models.
</dc:description>
 <dc:description>Comment: Accepted as a conference paper at ICLR 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06392</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Random-Access Machines</dc:title>
 <dc:creator>Kurach, Karol</dc:creator>
 <dc:creator>Andrychowicz, Marcin</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this paper, we propose and investigate a new neural network architecture
called Neural Random Access Machine. It can manipulate and dereference pointers
to an external variable-size random-access memory. The model is trained from
pure input-output examples using backpropagation.
  We evaluate the new model on a number of simple algorithmic tasks whose
solutions require pointer manipulation and dereferencing. Our results show that
the proposed model can learn to solve algorithmic tasks of such type and is
capable of operating on simple data structures like linked-lists and binary
trees. For easier tasks, the learned solutions generalize to sequences of
arbitrary length. Moreover, memory access during inference can be done in a
constant time under some assumptions.
</dc:description>
 <dc:description>Comment: ICLR submission, 17 pages, 9 figures, 6 tables (with bibliography and
  appendix)</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06393</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed Point Quantization of Deep Convolutional Networks</dc:title>
 <dc:creator>Lin, Darryl D.</dc:creator>
 <dc:creator>Talathi, Sachin S.</dc:creator>
 <dc:creator>Annapureddy, V. Sreekanth</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years increasingly complex architectures for deep convolution
networks (DCNs) have been proposed to boost the performance on image
recognition tasks. However, the gains in performance have come at a cost of
substantial increase in computation and model storage resources. Fixed point
implementation of DCNs has the potential to alleviate some of these
complexities and facilitate potential deployment on embedded hardware. In this
paper, we propose a quantizer design for fixed point implementation of DCNs. We
formulate and solve an optimization problem to identify optimal fixed point
bit-width allocation across DCN layers. Our experiments show that in comparison
to equal bit-width settings, the fixed point DCNs with optimized bit width
allocation offer &gt;20% reduction in the model size without any loss in accuracy
on CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhance
the accuracy of fixed point DCNs beyond that of the original floating point
model. In doing so, we report a new state-of-the-art fixed point performance of
6.78% error-rate on CIFAR-10 benchmark.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06394</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geodesics of learned representations</dc:title>
 <dc:creator>H&#xe9;naff, Olivier J.</dc:creator>
 <dc:creator>Simoncelli, Eero P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a new method for visualizing and refining the invariances of
learned representations. Specifically, we test for a general form of
invariance, linearization, in which the action of a transformation is confined
to a low-dimensional subspace. Given two reference images (typically, differing
by some transformation), we synthesize a sequence of images lying on a path
between them that is of minimal length in the space of the representation (a
&quot;representational geodesic&quot;). If the transformation relating the two reference
images is linearized by the representation, this sequence should follow the
gradual evolution of this transformation. We use this method to assess the
invariance properties of a state-of-the-art image classification network and
find that geodesics generated for image pairs differing by translation,
rotation, and dilation do not evolve according to their associated
transformations. Our method also suggests a remedy for these failures, and
following this prescription, we show that the modified representation is able
to linearize a variety of geometric image transformations.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06396</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilingual Relation Extraction using Compositional Universal Schema</dc:title>
 <dc:creator>Verga, Patrick</dc:creator>
 <dc:creator>Belanger, David</dc:creator>
 <dc:creator>Strubell, Emma</dc:creator>
 <dc:creator>Roth, Benjamin</dc:creator>
 <dc:creator>McCallum, Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Universal schema builds a knowledge base (KB) of entities and relations by
jointly embedding all relation types from input KBs as well as textual patterns
expressing relations from raw text. In most previous applications of universal
schema, each textual pattern is represented as a single embedding, preventing
generalization to unseen patterns. Recent work employs a neural network to
capture patterns' compositional semantics, providing generalization to all
possible input text. In response, this paper introduces significant further
improvements to the coverage and flexibility of universal schema relation
extraction: predictions for entities unseen in training and multilingual
transfer learning to domains with no annotation. We evaluate our model through
extensive experiments on the English and Spanish TAC KBP benchmark,
outperforming the top system from TAC 2013 slot-filling using no handwritten
patterns or additional annotation. We also consider a multilingual setting in
which English training data entities overlap with the seed KB, but Spanish text
does not. Despite having no annotation for Spanish data, we train an accurate
predictor, with additional improvements obtained by tying word embeddings
across languages. Furthermore, we find that multilingual training improves
English relation extraction accuracy. Our approach is thus suited to
broad-coverage automated knowledge base construction in a variety of languages
and domains.
</dc:description>
 <dc:description>Comment: Accepted to NAACL 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06397</identifier>
 <datestamp>2016-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressing Word Embeddings</dc:title>
 <dc:creator>Andrews, Martin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent methods for learning vector space representations of words have
succeeded in capturing fine-grained semantic and syntactic regularities using
vector arithmetic. However, these vector space representations (created through
large-scale text analysis) are typically stored verbatim, since their internal
structure is opaque. Using word-analogy tests to monitor the level of detail
stored in compressed re-representations of the same vector space, the
trade-offs between the reduction in memory usage and expressiveness are
investigated. A simple scheme is outlined that can reduce the memory footprint
of a state-of-the-art embedding by a factor of 10, with only minimal impact on
performance. Then, using the same `bit budget', a binary (approximate)
factorisation of the same space is also explored, with the aim of creating an
equivalent representation with better interpretability.
</dc:description>
 <dc:description>Comment: 10 pages, 0 figures, submitted to ICONIP-2016. Previous experimental
  results were submitted to ICLR-2016, but the paper has been significantly
  updated, since a new experimental set-up worked much better</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06406</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising Criterion for Variational Auto-Encoding Framework</dc:title>
 <dc:creator>Im, Daniel Jiwoong</dc:creator>
 <dc:creator>Ahn, Sungjin</dc:creator>
 <dc:creator>Memisevic, Roland</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Denoising autoencoders (DAE) are trained to reconstruct their clean inputs
with noise injected at the input level, while variational autoencoders (VAE)
are trained with noise injected in their stochastic hidden layer, with a
regularizer that encourages this noise injection. In this paper, we show that
injecting noise both in input and in the stochastic hidden layer can be
advantageous and we propose a modified variational lower bound as an improved
objective function in this setup. When input is corrupted, then the standard
VAE lower bound involves marginalizing the encoder conditional distribution
over the input noise, which makes the training criterion intractable. Instead,
we propose a modified training criterion which corresponds to a tractable bound
when input is corrupted. Experimentally, we find that the proposed denoising
variational autoencoder (DVAE) yields better average log-likelihood than the
VAE and the importance weighted autoencoder on the MNIST and Frey Face
datasets.
</dc:description>
 <dc:description>Comment: ICLR conference submission</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06407</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Models for Auditory Attention in Multi-Microphone Distance
  Speech Recognition</dc:title>
 <dc:creator>Kim, Suyoun</dc:creator>
 <dc:creator>Lane, Ian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Integration of multiple microphone data is one of the key ways to achieve
robust speech recognition in noisy environments or when the speaker is located
at some distance from the input device. Signal processing techniques such as
beamforming are widely used to extract a speech signal of interest from
background noise. These techniques, however, are highly dependent on prior
spatial information about the microphones and the environment in which the
system is being used. In this work, we present a neural attention network that
directly combines multi-channel audio to generate phonetic states without
requiring any prior knowledge of the microphone layout or any explicit signal
preprocessing for speech enhancement. We embed an attention mechanism within a
Recurrent Neural Network (RNN) based acoustic model to automatically tune its
attention to a more reliable input source. Unlike traditional multi-channel
preprocessing, our system can be optimized towards the desired output in one
step. Although attention-based models have recently achieved impressive results
on sequence-to-sequence learning, no attention mechanisms have previously been
applied to learn potentially asynchronous and non-stationary multiple inputs.
We evaluate our neural attention model on the CHiME-3 challenge task, and show
that the model achieves comparable performance to beamforming using a purely
data-driven method.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06408</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature-based Attention in Convolutional Neural Networks</dc:title>
 <dc:creator>Lindsay, Grace W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have proven effective for image
processing tasks, such as object recognition and classification. Recently, CNNs
have been enhanced with concepts of attention, similar to those found in
biology. Much of this work on attention has focused on effective serial spatial
processing. In this paper, I introduce a simple procedure for applying
feature-based attention (FBA) to CNNs and compare multiple implementation
options. FBA is a top-down signal applied globally to an input image which
aides in detecting chosen objects in cluttered or noisy settings. The concept
of FBA and the implementation details tested here were derived from what is
known (and debated) about biological object- and feature-based attention. The
implementations of FBA described here increase performance on challenging
object detection tasks using a procedure that is simple, fast, and does not
require additional iterative training. Furthermore, the comparisons performed
here suggest that a proposed model of biological FBA (the &quot;feature similarity
gain model&quot;) is effective in increasing performance.
</dc:description>
 <dc:description>Comment: 9 pages (plus 3 page Appendix), 7 figures total, submitted to ICLR
  2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06408</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06409</identifier>
 <datestamp>2017-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Generate Images with Perceptual Similarity Metrics</dc:title>
 <dc:creator>Snell, Jake</dc:creator>
 <dc:creator>Ridgeway, Karl</dc:creator>
 <dc:creator>Liao, Renjie</dc:creator>
 <dc:creator>Roads, Brett D.</dc:creator>
 <dc:creator>Mozer, Michael C.</dc:creator>
 <dc:creator>Zemel, Richard S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep networks are increasingly being applied to problems involving image
synthesis, e.g., generating images from textual descriptions and reconstructing
an input image from a compact representation. Supervised training of
image-synthesis networks typically uses a pixel-wise loss (PL) to indicate the
mismatch between a generated image and its corresponding target image. We
propose instead to use a loss function that is better calibrated to human
perceptual judgments of image quality: the multiscale structural-similarity
score (MS-SSIM). Because MS-SSIM is differentiable, it is easily incorporated
into gradient-descent learning. We compare the consequences of using MS-SSIM
versus PL loss on training deterministic and stochastic autoencoders. For three
different architectures, we collected human judgments of the quality of image
reconstructions. Observers reliably prefer images synthesized by
MS-SSIM-optimized models over those synthesized by PL-optimized models, for two
distinct PL measures ($\ell_1$ and $\ell_2$ distances). We also explore the
effect of training objective on image encoding and analyze conditions under
which perceptually-optimized representations yield better performance on image
classification. Finally, we demonstrate the superiority of
perceptually-optimized networks for super-resolution imaging. Just as computer
vision has advanced through the use of convolutional architectures that mimic
the structure of the mammalian visual system, we argue that significant
additional advances can be made in modeling images through the use of training
objectives that are well aligned to characteristics of human perception.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06410</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Computer Go Player with Neural Network and Long-term Prediction</dc:title>
 <dc:creator>Tian, Yuandong</dc:creator>
 <dc:creator>Zhu, Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Competing with top human players in the ancient game of Go has been a
long-term goal of artificial intelligence. Go's high branching factor makes
traditional search techniques ineffective, even on leading-edge hardware, and
Go's evaluation function could change drastically with one stone change. Recent
works [Maddison et al. (2015); Clark &amp; Storkey (2015)] show that search is not
strictly necessary for machine Go players. A pure pattern-matching approach,
based on a Deep Convolutional Neural Network (DCNN) that predicts the next
move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source
Go engines such as Pachi [Baudis &amp; Gailly (2012)] if its search budget is
limited. We extend this idea in our bot named darkforest, which relies on a
DCNN designed for long-term predictions. Darkforest substantially improves the
win rate for pattern-matching approaches against MCTS-based approaches, even
with looser search budgets. Against human players, the newest versions,
darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a
substantial improvement upon the estimated 4k-5k ranks for DCNN reported in
Clark &amp; Storkey (2015) based on games against other machine players. Adding
MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000
rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts
it achieves a stable 5d level in KGS server, on par with state-of-the-art Go
AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al.
(2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament.
</dc:description>
 <dc:description>Comment: 10 pages, 9 without references. Submission for ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06411</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep Neural Networks via Direct Loss Minimization</dc:title>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Schwing, Alexander G.</dc:creator>
 <dc:creator>Zemel, Richard S.</dc:creator>
 <dc:creator>Urtasun, Raquel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Supervised training of deep neural nets typically relies on minimizing
cross-entropy. However, in many domains, we are interested in performing well
on metrics specific to the application. In this paper we propose a direct loss
minimization approach to train deep neural networks, which provably minimizes
the application-specific loss function. This is often non-trivial, since these
functions are neither smooth nor decomposable and thus are not amenable to
optimization with standard gradient-based methods. We demonstrate the
effectiveness of our approach in the context of maximizing average precision
for ranking problems. Towards this goal, we develop a novel dynamic programming
algorithm that can efficiently compute the weight updates. Our approach proves
superior to a variety of baselines in the context of action classification and
object detection, especially in the presence of label noise.
</dc:description>
 <dc:description>Comment: ICML2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06412</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QBDC: Query by dropout committee for training deep supervised
  architecture</dc:title>
 <dc:creator>Ducoffe, Melanie</dc:creator>
 <dc:creator>Precioso, Frederic</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While the current trend is to increase the depth of neural networks to
increase their performance, the size of their training database has to grow
accordingly. We notice an emergence of tremendous databases, although providing
labels to build a training set still remains a very expensive task. We tackle
the problem of selecting the samples to be labelled in an online fashion. In
this paper, we present an active learning strategy based on query by committee
and dropout technique to train a Convolutional Neural Network (CNN). We derive
a commmittee of partial CNNs resulting from batchwise dropout runs on the
initial CNN. We evaluate our active learning strategy for CNN on MNIST
benchmark, showing in particular that selecting less than 30 % from the
annotated database is enough to get similar error rate as using the full
training set on MNIST. We also studied the robustness of our method against
adversarial examples.
</dc:description>
 <dc:description>Comment: Submitted to ICLR2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06416</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Parallel SAME Gibbs Sampling on General Discrete Bayesian Networks</dc:title>
 <dc:creator>Seita, Daniel</dc:creator>
 <dc:creator>Chen, Haoyu</dc:creator>
 <dc:creator>Canny, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A fundamental task in machine learning and related fields is to perform
inference on Bayesian networks. Since exact inference takes exponential time in
general, a variety of approximate methods are used. Gibbs sampling is one of
the most accurate approaches and provides unbiased samples from the posterior
but it has historically been too expensive for large models. In this paper, we
present an optimized, parallel Gibbs sampler augmented with state replication
(SAME or State Augmented Marginal Estimation) to decrease convergence time. We
find that SAME can improve the quality of parameter estimates while
accelerating convergence. Experiments on both synthetic and real data show that
our Gibbs sampler is substantially faster than the state of the art sampler,
JAGS, without sacrificing accuracy. Our ultimate objective is to introduce the
Gibbs sampler to researchers in many fields to expand their range of feasible
inference problems.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06418</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binding via Reconstruction Clustering</dc:title>
 <dc:creator>Greff, Klaus</dc:creator>
 <dc:creator>Srivastava, Rupesh Kumar</dc:creator>
 <dc:creator>Schmidhuber, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Disentangled distributed representations of data are desirable for machine
learning, since they are more expressive and can generalize from fewer
examples. However, for complex data, the distributed representations of
multiple objects present in the same input can interfere and lead to
ambiguities, which is commonly referred to as the binding problem. We argue for
the importance of the binding problem to the field of representation learning,
and develop a probabilistic framework that explicitly models inputs as a
composition of multiple objects. We propose an unsupervised algorithm that uses
denoising autoencoders to dynamically bind features together in multi-object
inputs through an Expectation-Maximization-like clustering process. The
effectiveness of this method is demonstrated on artificially generated datasets
of binary images, showing that it can even generalize to bind together new
objects never seen by the autoencoder during training.
</dc:description>
 <dc:description>Comment: 12 pages, plus 12 pages Appendix</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06419</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canonical Autocorrelation Analysis</dc:title>
 <dc:creator>De-Arteaga, Maria</dc:creator>
 <dc:creator>Dubrawski, Artur</dc:creator>
 <dc:creator>Huggins, Peter</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an extension of sparse Canonical Correlation Analysis (CCA)
designed for finding multiple-to-multiple linear correlations within a single
set of variables. Unlike CCA, which finds correlations between two sets of data
where the rows are matched exactly but the columns represent separate sets of
variables, the method proposed here, Canonical Autocorrelation Analysis (CAA),
finds multivariate correlations within just one set of variables. This can be
useful when we look for hidden parsimonious structures in data, each involving
only a small subset of all features. In addition, the discovered correlations
are highly interpretable as they are formed by pairs of sparse linear
combinations of the original features. We show how CAA can be of use as a tool
for anomaly detection when the expected structure of correlations is not
followed by anomalous data. We illustrate the utility of CAA in two application
domains where single-class and unsupervised learning of correlation structures
are particularly relevant: breast cancer diagnosis and radiation threat
detection. When applied to the Wisconsin Breast Cancer data, single-class CAA
is competitive with supervised methods used in literature. On the radiation
threat detection task, unsupervised CAA performs significantly better than an
unsupervised alternative prevalent in the domain, while providing valuable
additional insights for threat analysis.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06420</identifier>
 <datestamp>2015-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skip-Thought Memory Networks</dc:title>
 <dc:creator>Caballero, Ethan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Question Answering (QA) is fundamental to natural language processing in that
most nlp problems can be phrased as QA (Kumar et al., 2015). Current weakly
supervised memory network models that have been proposed so far struggle at
answering questions that involve relations among multiple entities (such as
facebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To address
this problem of learning multi-argument multi-hop semantic relations for the
purpose of QA, we propose a method that combines the jointly learned long-term
read-write memory and attentive inference components of end-to-end memory
networks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vector
representations encoded by a Skip-Thought model (Kiros et al., 2015). This
choice to append Skip-Thought Vectors to the existing MemN2N framework is
motivated by the fact that Skip-Thought Vectors have been shown to accurately
model multi-argument semantic relations (Kiros et al., 2015).
</dc:description>
 <dc:description>Comment: Removed by arXiv administrators because submission violated the terms
  of arXiv's license agreement</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06421</identifier>
 <datestamp>2016-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Manifold Traversal: Changing Labels with Convolutional Features</dc:title>
 <dc:creator>Gardner, Jacob R.</dc:creator>
 <dc:creator>Upchurch, Paul</dc:creator>
 <dc:creator>Kusner, Matt J.</dc:creator>
 <dc:creator>Li, Yixuan</dc:creator>
 <dc:creator>Weinberger, Kilian Q.</dc:creator>
 <dc:creator>Bala, Kavita</dc:creator>
 <dc:creator>Hopcroft, John E.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many tasks in computer vision can be cast as a &quot;label changing&quot; problem,
where the goal is to make a semantic change to the appearance of an image or
some subject in an image in order to alter the class membership. Although
successful task-specific methods have been developed for some label changing
applications, to date no general purpose method exists. Motivated by this we
propose deep manifold traversal, a method that addresses the problem in its
most general form: it first approximates the manifold of natural images then
morphs a test image along a traversal path away from a source class and towards
a target class while staying near the manifold throughout. The resulting
algorithm is surprisingly effective and versatile. It is completely data
driven, requiring only an example set of images from the desired source and
target domains. We demonstrate deep manifold traversal on highly diverse label
changing tasks: changing an individual's appearance (age and hair color),
changing the season of an outdoor image, and transforming a city skyline
towards nighttime.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06422</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All you need is a good init</dc:title>
 <dc:creator>Mishkin, Dmytro</dc:creator>
 <dc:creator>Matas, Jiri</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Layer-sequential unit-variance (LSUV) initialization - a simple method for
weight initialization for deep net learning - is proposed. The method consists
of the two steps. First, pre-initialize weights of each convolution or
inner-product layer with orthonormal matrices. Second, proceed from the first
to the final layer, normalizing the variance of the output of each layer to be
equal to one.
  Experiment with different activation functions (maxout, ReLU-family, tanh)
show that the proposed initialization leads to learning of very deep nets that
(i) produces networks with test accuracy better or equal to standard methods
and (ii) is at least as fast as the complex schemes proposed specifically for
very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava
et al. (2015)).
  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets
and the state-of-the-art, or very close to it, is achieved on the MNIST,
CIFAR-10/100 and ImageNet datasets.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06423</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Information Retrieval Approach to Finding Dependent Subspaces of
  Multiple Views</dc:title>
 <dc:creator>Lin, Ziyuan</dc:creator>
 <dc:creator>Peltonen, Jaakko</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Finding relationships between multiple views of data is essential both for
exploratory analysis and as pre-processing for predictive tasks. A prominent
approach is to apply variants of Canonical Correlation Analysis (CCA), a
classical method seeking correlated components between views. The basic CCA is
restricted to maximizing a simple dependency criterion, correlation, measured
directly between data coordinates. We introduce a new method that finds
dependent subspaces of views directly optimized for the data analysis task of
\textit{neighbor retrieval between multiple views}. We optimize mappings for
each view such as linear transformations to maximize cross-view similarity
between neighborhoods of data samples. The criterion arises directly from the
well-defined retrieval task, detects nonlinear and local similarities, is able
to measure dependency of data relationships rather than only individual data
coordinates, and is related to well understood measures of information
retrieval quality. In experiments we show the proposed method outperforms
alternatives in preserving cross-view neighborhood similarities, and yields
insights into local dependencies between multiple views.
</dc:description>
 <dc:description>Comment: 9 pages, 15 figures. Submitted for ICLR 2016; the authors contributed
  equally</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06425</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First Step toward Model-Free, Anonymous Object Tracking with Recurrent
  Neural Networks</dc:title>
 <dc:creator>Gan, Quan</dc:creator>
 <dc:creator>Guo, Qipeng</dc:creator>
 <dc:creator>Zhang, Zheng</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose and study a novel visual object tracking approach
based on convolutional networks and recurrent networks. The proposed approach
is distinct from the existing approaches to visual object tracking, such as
filtering-based ones and tracking-by-detection ones, in the sense that the
tracking system is explicitly trained off-line to track anonymous objects in a
noisy environment. The proposed visual tracking model is end-to-end trainable,
minimizing any adversarial effect from mismatches in object representation and
between the true underlying dynamics and learning dynamics. We empirically show
that the proposed tracking approach works well in various scenarios by
generating artificial video sequences with varying conditions; the number of
objects, amount of noise and the match between the training shapes and test
shapes.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06426</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reasoning in Vector Space: An Exploratory Study of Question Answering</dc:title>
 <dc:creator>Lee, Moontae</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Yih, Wen-tau</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:creator>Smolensky, Paul</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Question answering tasks have shown remarkable progress with distributed
vector representation. In this paper, we investigate the recently proposed
Facebook bAbI tasks which consist of twenty different categories of questions
that require complex reasoning. Because the previous work on bAbI are all
end-to-end models, errors could come from either an imperfect understanding of
semantics or in certain steps of the reasoning. For clearer analysis, we
propose two vector space models inspired by Tensor Product Representation (TPR)
to perform knowledge encoding and logical reasoning based on common-sense
inference. They together achieve near-perfect accuracy on all categories
including positional reasoning and path finding that have proved difficult for
most of the previous approaches. We hypothesize that the difficulties in these
categories are due to the multi-relations in contrast to uni-relational
characteristic of other categories. Our exploration sheds light on designing
more sophisticated dataset and moving one step toward integrating transparent
and interpretable formalism of TPR into existing learning paradigms.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06428</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Controller-Recognizer Framework: How necessary is recognition for
  control?</dc:title>
 <dc:creator>Moczulski, Marcin</dc:creator>
 <dc:creator>Xu, Kelvin</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently there has been growing interest in building active visual object
recognizers, as opposed to the usual passive recognizers which classifies a
given static image into a predefined set of object categories. In this paper we
propose to generalize these recently proposed end-to-end active visual
recognizers into a controller-recognizer framework. A model in the
controller-recognizer framework consists of a controller, which interfaces with
an external manipulator, and a recognizer which classifies the visual input
adjusted by the manipulator. We describe two most recently proposed
controller-recognizer models: recurrent attention model and spatial transformer
network as representative examples of controller-recognizer models. Based on
this description we observe that most existing end-to-end
controller-recognizers tightly, or completely, couple a controller and
recognizer. We ask a question whether this tight coupling is necessary, and try
to answer this empirically by building a controller-recognizer model with a
decoupled controller and recognizer. Our experiments revealed that it is not
always necessary to tightly couple them and that by decoupling a controller and
recognizer, there is a possibility of building a generic controller that is
pretrained and works together with any subsequent recognizer.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06429</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patterns for Learning with Side Information</dc:title>
 <dc:creator>Jonschkowski, Rico</dc:creator>
 <dc:creator>H&#xf6;fer, Sebastian</dc:creator>
 <dc:creator>Brock, Oliver</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Supervised, semi-supervised, and unsupervised learning estimate a function
given input/output samples. Generalization of the learned function to unseen
data can be improved by incorporating side information into learning. Side
information are data that are neither from the input space nor from the output
space of the function, but include useful information for learning it. In this
paper we show that learning with side information subsumes a variety of related
approaches, e.g. multi-task learning, multi-view learning and learning using
privileged information. Our main contributions are (i) a new perspective that
connects these previously isolated approaches, (ii) insights about how these
methods incorporate different types of prior knowledge, and hence implement
different patterns, (iii) facilitating the application of these methods in
novel tasks, as well as (iv) a systematic experimental evaluation of these
patterns in two supervised learning tasks.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally to this work</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06430</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deconstructing the Ladder Network Architecture</dc:title>
 <dc:creator>Pezeshki, Mohammad</dc:creator>
 <dc:creator>Fan, Linxi</dc:creator>
 <dc:creator>Brakel, Philemon</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Manual labeling of data is and will remain a costly endeavor. For this
reason, semi-supervised learning remains a topic of practical importance. The
recently proposed Ladder Network is one such approach that has proven to be
very successful. In addition to the supervised objective, the Ladder Network
also adds an unsupervised objective corresponding to the reconstruction costs
of a stack of denoising autoencoders. Although the empirical results are
impressive, the Ladder Network has many components intertwined, whose
contributions are not obvious in such a complex architecture. In order to help
elucidate and disentangle the different ingredients in the Ladder Network
recipe, this paper presents an extensive experimental investigation of variants
of the Ladder Network in which we replace or remove individual components to
gain more insight into their relative importance. We find that all of the
components are necessary for achieving optimal performance, but they do not
contribute equally. For semi-supervised tasks, we conclude that the most
important contribution is made by the lateral connection, followed by the
application of noise, and finally the choice of what we refer to as the
`combinator function' in the decoder path. We also find that as the number of
labeled training examples increases, the lateral connections and reconstruction
criterion become less important, with most of the improvement in generalization
being due to the injection of noise in each layer. Furthermore, we present a
new type of combinator function that outperforms the original design in both
fully- and semi-supervised tasks, reducing record test error rates on
Permutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%
and 1.0% for semi-supervised settings with 1000 and 100 labeled examples
respectively.
</dc:description>
 <dc:description>Comment: Proceedings of the 33 rd International Conference on Machine
  Learning, New York, NY, USA, 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06432</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delving Deeper into Convolutional Networks for Learning Video
  Representations</dc:title>
 <dc:creator>Ballas, Nicolas</dc:creator>
 <dc:creator>Yao, Li</dc:creator>
 <dc:creator>Pal, Chris</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose an approach to learn spatio-temporal features in videos from
intermediate visual representations we call &quot;percepts&quot; using
Gated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts
that are extracted from all level of a deep convolutional network trained on
the large ImageNet dataset. While high-level percepts contain highly
discriminative information, they tend to have a low-spatial resolution.
Low-level percepts, on the other hand, preserve a higher spatial resolution
from which we can model finer motion patterns. Using low-level percepts can
leads to high-dimensionality video representations. To mitigate this effect and
control the model number of parameters, we introduce a variant of the GRU model
that leverages the convolution operations to enforce sparse connectivity of the
model units and share parameters across the input spatial locations.
  We empirically validate our approach on both Human Action Recognition and
Video Captioning tasks. In particular, we achieve results equivalent to
state-of-art on the YouTube2Text dataset using a simpler text-decoder model and
without extra 3D CNN features.
</dc:description>
 <dc:description>Comment: ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06433</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blending LSTMs into CNNs</dc:title>
 <dc:creator>Geras, Krzysztof J.</dc:creator>
 <dc:creator>Mohamed, Abdel-rahman</dc:creator>
 <dc:creator>Caruana, Rich</dc:creator>
 <dc:creator>Urban, Gregor</dc:creator>
 <dc:creator>Wang, Shengjie</dc:creator>
 <dc:creator>Aslan, Ozlem</dc:creator>
 <dc:creator>Philipose, Matthai</dc:creator>
 <dc:creator>Richardson, Matthew</dc:creator>
 <dc:creator>Sutton, Charles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider whether deep convolutional networks (CNNs) can represent decision
functions with similar accuracy as recurrent networks such as LSTMs. First, we
show that a deep CNN with an architecture inspired by the models recently
introduced in image recognition can yield better accuracy than previous
convolutional and LSTM networks on the standard 309h Switchboard automatic
speech recognition task. Then we show that even more accurate CNNs can be
trained under the guidance of LSTMs using a variant of model compression, which
we call model blending because the teacher and student models are similar in
complexity but different in inductive bias. Blending further improves the
accuracy of our CNN, yielding a computationally efficient model of accuracy
higher than any of the other individual models. Examining the effect of &quot;dark
knowledge&quot; in this model compression task, we find that less than 1% of the
highest probability labels are needed for accurate model compression.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06433</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06434</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Representation Learning with Deep Convolutional Generative
  Adversarial Networks</dc:title>
 <dc:creator>Radford, Alec</dc:creator>
 <dc:creator>Metz, Luke</dc:creator>
 <dc:creator>Chintala, Soumith</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In recent years, supervised learning with convolutional networks (CNNs) has
seen huge adoption in computer vision applications. Comparatively, unsupervised
learning with CNNs has received less attention. In this work we hope to help
bridge the gap between the success of CNNs for supervised learning and
unsupervised learning. We introduce a class of CNNs called deep convolutional
generative adversarial networks (DCGANs), that have certain architectural
constraints, and demonstrate that they are a strong candidate for unsupervised
learning. Training on various image datasets, we show convincing evidence that
our deep convolutional adversarial pair learns a hierarchy of representations
from object parts to scenes in both the generator and discriminator.
Additionally, we use the learned features for novel tasks - demonstrating their
applicability as general image representations.
</dc:description>
 <dc:description>Comment: Under review as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06435</identifier>
 <datestamp>2016-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Study of Deep Learning Software Frameworks</dc:title>
 <dc:creator>Bahrampour, Soheil</dc:creator>
 <dc:creator>Ramakrishnan, Naveen</dc:creator>
 <dc:creator>Schott, Lukas</dc:creator>
 <dc:creator>Shah, Mohak</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning methods have resulted in significant performance improvements
in several application domains and as such several software frameworks have
been developed to facilitate their implementation. This paper presents a
comparative study of five deep learning frameworks, namely Caffe, Neon,
TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware
utilization, and speed. The study is performed on several types of deep
learning architectures and we evaluate the performance of the above frameworks
when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia
Titan X) settings. The speed performance metrics used here include the gradient
computation time, which is important during the training phase of deep
networks, and the forward time, which is important from the deployment
perspective of trained networks. For convolutional networks, we also report how
each of these frameworks support various convolutional algorithms and their
corresponding performance. From our experiments, we observe that Theano and
Torch are the most easily extensible frameworks. We observe that Torch is best
suited for any deep architecture on CPU, followed by Theano. It also achieves
the best performance on the GPU for large convolutional and fully connected
networks, followed closely by Neon. Theano achieves the best performance on GPU
for training and deployment of LSTM networks. Caffe is the easiest for
evaluating the performance of standard deep architectures. Finally, TensorFlow
is a very flexible framework, similar to Theano, but its performance is
currently not competitive compared to the other studied frameworks.
</dc:description>
 <dc:description>Comment: Submitted to KDD 2016 with TensorFlow results added. At the time of
  submission to KDD, TensorFlow was available only with cuDNN v.2 and thus its
  performance is reported with that version</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06436</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the robust hardness of Gr\&quot;obner basis computation</dc:title>
 <dc:creator>Spencer, Gwen</dc:creator>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We introduce a new problem in the approximate computation of Gr\&quot;obner bases
that allows the algorithm to ignore a constant fraction of the generators - of
the algorithm's choice - then compute a Gr\&quot;obner basis for the remaining
polynomial system. The set ignored is subject to one quite-natural structural
constraint. For lexicographic orders, when the discarded fraction is less than
$(1/4-\epsilon)$, for $\epsilon&gt;0$, we prove that this problem cannot be solved
in polynomial time, even when the original polynomial system has maximum degree
3 and each polynomial contains at most 3 variables. Qualitatively, even for
sparse systems composed of low-degree polynomials, we show that Gr\&quot;obner basis
computation is robustly hard: even producing a Gr\&quot;obner basis for a large
subset of the generators is NP-hard.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06437</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A convnet for non-maximum suppression</dc:title>
 <dc:creator>Hosang, Jan</dc:creator>
 <dc:creator>Benenson, Rodrigo</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Non-maximum suppression (NMS) is used in virtually all state-of-the-art
object detection pipelines. While essential object detection ingredients such
as features, classifiers, and proposal methods have been extensively researched
surprisingly little work has aimed to systematically address NMS. The de-facto
standard for NMS is based on greedy clustering with a fixed distance threshold,
which forces to trade-off recall versus precision. We propose a convnet
designed to perform NMS of a given set of detections. We report experiments on
a synthetic setup, and results on crowded pedestrian detection scenes. Our
approach overcomes the intrinsic limitations of greedy NMS, obtaining better
recall and precision.
</dc:description>
 <dc:description>Comment: Included comments from reviewers</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06438</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Word Representation Learning using a Corpus and a Semantic Lexicon</dc:title>
 <dc:creator>Bollegala, Danushka</dc:creator>
 <dc:creator>Mohammed, Alsuhaibani</dc:creator>
 <dc:creator>Maehara, Takanori</dc:creator>
 <dc:creator>Kawarabayashi, Ken-ichi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Methods for learning word representations using large text corpora have
received much attention lately due to their impressive performance in numerous
natural language processing (NLP) tasks such as, semantic similarity
measurement, and word analogy detection. Despite their success, these
data-driven word representation learning methods do not consider the rich
semantic relational structure between words in a co-occurring context. On the
other hand, already much manual effort has gone into the construction of
semantic lexicons such as the WordNet that represent the meanings of words by
defining the various relationships that exist among the words in a language. We
consider the question, can we improve the word representations learnt using a
corpora by integrating the knowledge from semantic lexicons?. For this purpose,
we propose a joint word representation learning method that simultaneously
predicts the co-occurrences of two words in a sentence subject to the
relational constrains given by the semantic lexicon. We use relations that
exist between words in the lexicon to regularize the word representations
learnt from the corpus. Our proposed method statistically significantly
outperforms previously proposed methods for incorporating semantic lexicons
into word representations on several benchmark datasets for semantic similarity
and word analogy.
</dc:description>
 <dc:description>Comment: Accepted to AAAI-2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06438</dc:identifier>
 <dc:identifier>Proceedings of the AAAI 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06440</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Principled Unsupervised Learning</dc:title>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Jozefowicz, Rafal</dc:creator>
 <dc:creator>Gregor, Karol</dc:creator>
 <dc:creator>Rezende, Danilo</dc:creator>
 <dc:creator>Lillicrap, Tim</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  General unsupervised learning is a long-standing conceptual problem in
machine learning. Supervised learning is successful because it can be solved by
the minimization of the training error cost function. Unsupervised learning is
not as successful, because the unsupervised objective may be unrelated to the
supervised task of interest. For an example, density modelling and
reconstruction have often been used for unsupervised learning, but they did not
produced the sought-after performance gains, because they have no knowledge of
the supervised tasks.
  In this paper, we present an unsupervised cost function which we name the
Output Distribution Matching (ODM) cost, which measures a divergence between
the distribution of predictions and distributions of labels. The ODM cost is
appealing because it is consistent with the supervised cost in the following
sense: a perfect supervised classifier is also perfect according to the ODM
cost. Therefore, by aggressively optimizing the ODM cost, we are almost
guaranteed to improve our supervised performance whenever the space of possible
predictions is exponentially large.
  We demonstrate that the ODM cost works well on number of small and
semi-artificial datasets using no (or almost no) labelled training cases.
Finally, we show that the ODM cost can be used for one-shot domain adaptation,
which allows the model to classify inputs that differ from the input
distribution in significant ways without the need for prior exposure to the new
domain.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06441</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A parallel algorithm for the constrained shortest path problem on
  lattice graphs</dc:title>
 <dc:creator>Matic, Ivan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The edges of a graph are assigned weights and passage times which are assumed
to be positive integers. We present a parallel algorithm for finding the
shortest path whose total weight is smaller than a pre-determined value. In
each step the processing elements are not analyzing the entire graph. Instead
they are focusing on a subset of vertices called {\em active vertices}. The set
of active vertices at time $t$ is related to the boundary of the ball $B_t$ of
radius $t$ in the first passage percolation metric. Although it is believed
that the number of active vertices is an order of magnitude smaller than the
size of the graph, we prove that this need not be the case with an example of a
graph for which the active vertices form a large fractal. We analyze an OpenCL
implementation of the algorithm on GPU for cubes in $\mathbb Z^d$.
</dc:description>
 <dc:description>Comment: In: Adamatzky, A (Ed.) Shortest path solvers. From software to
  wetware. Springer, 2018</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06442</identifier>
 <datestamp>2016-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Metric Learning For Deep Neural Networks</dc:title>
 <dc:creator>Gouk, Henry</dc:creator>
 <dc:creator>Pfahringer, Bernhard</dc:creator>
 <dc:creator>Cree, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Similarity metrics are a core component of many information retrieval and
machine learning systems. In this work we propose a method capable of learning
a similarity metric from data equipped with a binary relation. By considering
only the similarity constraints, and initially ignoring the features, we are
able to learn target vectors for each instance using one of several
appropriately designed loss functions. A regression model can then be
constructed that maps novel feature vectors to the same target vector space,
resulting in a feature extractor that computes vectors for which a predefined
metric is a meaningful measure of similarity. We present results on both
multiclass and multi-label classification datasets that demonstrate
considerably faster convergence, as well as higher accuracy on the majority of
the intrinsic evaluation tasks and all extrinsic evaluation tasks.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06443</identifier>
 <datestamp>2015-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Matrix Factorization</dc:title>
 <dc:creator>Dziugaite, Gintare Karolina</dc:creator>
 <dc:creator>Roy, Daniel M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Data often comes in the form of an array or matrix. Matrix factorization
techniques attempt to recover missing or corrupted entries by assuming that the
matrix can be written as the product of two low-rank matrices. In other words,
matrix factorization approximates the entries of the matrix by a simple, fixed
function---namely, the inner product---acting on the latent feature vectors for
the corresponding row and column. Here we consider replacing the inner product
by an arbitrary function that we learn from the data at the same time as we
learn the latent feature vectors. In particular, we replace the inner product
by a multi-layer feed-forward neural network, and learn by alternating between
optimizing the network for fixed latent features, and optimizing the latent
features for a fixed network. The resulting approach---which we call neural
network matrix factorization or NNMF, for short---dominates standard low-rank
techniques on a suite of benchmark but is dominated by some recent proposals
that take advantage of the graph features. Given the vast range of
architectures, activation functions, regularizers, and optimization techniques
that could be used within the NNMF framework, it seems likely the true
potential of the approach has yet to be reached.
</dc:description>
 <dc:description>Comment: Minor modifications to notation. Added additional experiments and
  discussion. 7 pages, 2 tables</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06444</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal halting times in optimization and machine learning</dc:title>
 <dc:creator>Sagun, Levent</dc:creator>
 <dc:creator>Trogdon, Thomas</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>65K10, 82D30, 37E20</dc:subject>
 <dc:description>  The authors present empirical distributions for the halting time (measured by
the number of iterations to reach a given accuracy) of optimization algorithms
applied to two random systems: spin glasses and deep learning. Given an
algorithm, which we take to be both the optimization routine and the form of
the random landscape, the fluctuations of the halting time follow a
distribution that, after centering and scaling, remains unchanged even when the
distribution on the landscape is changed. We observe two qualitative classes: A
Gumbel-like distribution that appears in Google searches, human decision times,
the QR eigenvalue algorithm and spin glasses, and a Gaussian-like distribution
that appears in conjugate gradient method, deep network with MNIST input data
and deep network with random input data. This empirical evidence suggests
presence of a class of distributions for which the halting time is independent
of the underlying distribution under some conditions.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06448</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Representations from EEG with Deep Recurrent-Convolutional
  Neural Networks</dc:title>
 <dc:creator>Bashivan, Pouya</dc:creator>
 <dc:creator>Rish, Irina</dc:creator>
 <dc:creator>Yeasin, Mohammed</dc:creator>
 <dc:creator>Codella, Noel</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One of the challenges in modeling cognitive events from electroencephalogram
(EEG) data is finding representations that are invariant to inter- and
intra-subject differences, as well as to inherent noise associated with such
data. Herein, we propose a novel approach for learning such representations
from multi-channel EEG time-series, and demonstrate its advantages in the
context of mental load classification task. First, we transform EEG activities
into a sequence of topology-preserving multi-spectral images, as opposed to
standard EEG analysis techniques that ignore such spatial information. Next, we
train a deep recurrent-convolutional network inspired by state-of-the-art video
classification to learn robust representations from the sequence of images. The
proposed approach is designed to preserve the spatial, spectral, and temporal
structure of EEG which leads to finding features that are less sensitive to
variations and distortions within each dimension. Empirical evaluation on the
cognitive load classification task demonstrated significant improvements in
classification accuracy over current state-of-the-art approaches in this field.
</dc:description>
 <dc:description>Comment: To be published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06449</identifier>
 <datestamp>2016-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to decompose for object detection and instance segmentation</dc:title>
 <dc:creator>Park, Eunbyung</dc:creator>
 <dc:creator>Berg, Alexander C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although deep convolutional neural networks(CNNs) have achieved remarkable
results on object detection and segmentation, pre- and post-processing steps
such as region proposals and non-maximum suppression(NMS), have been required.
These steps result in high computational complexity and sensitivity to
hyperparameters, e.g. thresholds for NMS. In this work, we propose a novel
end-to-end trainable deep neural network architecture, which consists of
convolutional and recurrent layers, that generates the correct number of object
instances and their bounding boxes (or segmentation masks) given an image,
using only a single network evaluation without any pre- or post-processing
steps. We have tested on detecting digits in multi-digit images synthesized
using MNIST, automatically segmenting digits in these images, and detecting
cars in the KITTI benchmark dataset. The proposed approach outperforms a strong
CNN baseline on the synthesized digits datasets and shows promising results on
KITTI car detection.
</dc:description>
 <dc:description>Comment: ICLR 2016 Workshop</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06452</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Metric Learning via Lifted Structured Feature Embedding</dc:title>
 <dc:creator>Song, Hyun Oh</dc:creator>
 <dc:creator>Xiang, Yu</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning the distance metric between pairs of examples is of great importance
for learning and visual recognition. With the remarkable success from the state
of the art convolutional neural networks, recent works have shown promising
results on discriminatively training the networks to learn semantic feature
embeddings where similar examples are mapped close to each other and dissimilar
examples are mapped farther apart. In this paper, we describe an algorithm for
taking full advantage of the training batches in the neural network training by
lifting the vector of pairwise distances within the batch to the matrix of
pairwise distances. This step enables the algorithm to learn the state of the
art feature embedding by optimizing a novel structured prediction objective on
the lifted problem. Additionally, we collected Online Products dataset: 120k
images of 23k classes of online products for metric learning. Our experiments
on the CUB-200-2011, CARS196, and Online Products datasets demonstrate
significant improvement over existing deep feature embedding methods on all
experimented embedding sizes with the GoogLeNet network.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06455</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Auto-encoded Deep Gaussian Processes</dc:title>
 <dc:creator>Dai, Zhenwen</dc:creator>
 <dc:creator>Damianou, Andreas</dc:creator>
 <dc:creator>Gonz&#xe1;lez, Javier</dc:creator>
 <dc:creator>Lawrence, Neil</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop a scalable deep non-parametric generative model by augmenting deep
Gaussian processes with a recognition model. Inference is performed in a novel
scalable variational framework where the variational posterior distributions
are reparametrized through a multilayer perceptron. The key aspect of this
reformulation is that it prevents the proliferation of variational parameters
which otherwise grow linearly in proportion to the sample size. We derive a new
formulation of the variational lower bound that allows us to distribute most of
the computation in a way that enables to handle datasets of the size of
mainstream deep learning tasks. We show the efficacy of the method on a variety
of challenges including deep unsupervised learning and deep Bayesian
optimization.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06456</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task Loss Estimation for Sequence Prediction</dc:title>
 <dc:creator>Bahdanau, Dzmitry</dc:creator>
 <dc:creator>Serdyuk, Dmitriy</dc:creator>
 <dc:creator>Brakel, Phil&#xe9;mon</dc:creator>
 <dc:creator>Ke, Nan Rosemary</dc:creator>
 <dc:creator>Chorowski, Jan</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Often, the performance on a supervised machine learning task is evaluated
with a emph{task loss} function that cannot be optimized directly. Examples of
such loss functions include the classification error, the edit distance and the
BLEU score. A common workaround for this problem is to instead optimize a
emph{surrogate loss} function, such as for instance cross-entropy or hinge
loss. In order for this remedy to be effective, it is important to ensure that
minimization of the surrogate loss results in minimization of the task loss, a
condition that we call emph{consistency with the task loss}. In this work, we
propose another method for deriving differentiable surrogate losses that
provably meet this requirement. We focus on the broad class of models that
define a score for every input-output pair. Our idea is that this score can be
interpreted as an estimate of the task loss, and that the estimation error may
be used as a consistent surrogate loss. A distinct feature of such an approach
is that it defines the desirable value of the score for every input-output
pair. We use this property to design specialized surrogate losses for
Encoder-Decoder models often used for sequence prediction tasks. In our
experiment, we benchmark on the task of speech recognition. Using a new
surrogate loss instead of cross-entropy to train an Encoder-Decoder speech
recognizer brings a significant ~13% relative improvement in terms of Character
Error Rate (CER) in the case when no extra corpora are used for language
modeling.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06457</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DOC: Deep OCclusion Estimation From a Single Image</dc:title>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recovering the occlusion relationships between objects is a fundamental human
visual ability which yields important information about the 3D world. In this
paper we propose a deep network architecture, called DOC, which acts on a
single image, detects object boundaries and estimates the border ownership
(i.e. which side of the boundary is foreground and which is background). We
represent occlusion relations by a binary edge map, to indicate the object
boundary, and an occlusion orientation variable which is tangential to the
boundary and whose direction specifies border ownership by a left-hand rule. We
train two related deep convolutional neural networks, called DOC, which exploit
local and non-local image cues to estimate this representation and hence
recover occlusion relations. In order to train and test DOC we construct a
large-scale instance occlusion boundary dataset using PASCAL VOC images, which
we call the PASCAL instance occlusion dataset (PIOD). This contains 10,000
images and hence is two orders of magnitude larger than existing occlusion
datasets for outdoor images. We test two variants of DOC on PIOD and on the
BSDS occlusion dataset and show they outperform state-of-the-art methods.
Finally, we perform numerous experiments investigating multiple settings of DOC
and transfer between BSDS and PIOD, which provides more insights for further
study of occlusion estimation.
</dc:description>
 <dc:description>Comment: Accepted to ECCV 2016</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06458</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian inference via rejection filtering</dc:title>
 <dc:creator>Wiebe, Nathan</dc:creator>
 <dc:creator>Granade, Christopher</dc:creator>
 <dc:creator>Kapoor, Ashish</dc:creator>
 <dc:creator>Svore, Krysta M</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We provide a method for approximating Bayesian inference using rejection
sampling. We not only make the process efficient, but also dramatically reduce
the memory required relative to conventional methods by combining rejection
sampling with particle filtering. We also provide an approximate form of
rejection sampling that makes rejection filtering tractable in cases where
exact rejection sampling is not efficient. Finally, we present several
numerical examples of rejection filtering that show its ability to track time
dependent parameters in online settings and also benchmark its performance on
MNIST classification problems.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06459</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QINL: Query-integrated Languages</dc:title>
 <dc:creator>Schultz, Patrick</dc:creator>
 <dc:creator>Spivak, David I.</dc:creator>
 <dc:creator>Wisnesky, Ryan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We describe an alternative solution to the impedance-mismatch problem between
programming and query languages: rather than embed queries in a programming
language, as done in LINQ systems, we embed programs in a query language, and
dub the result QINL.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06463</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MaxOutProbe: An Algorithm for Increasing the Size of Partially Observed
  Networks</dc:title>
 <dc:creator>Soundarajan, Sucheta</dc:creator>
 <dc:creator>Eliassi-Rad, Tina</dc:creator>
 <dc:creator>Gallagher, Brian</dc:creator>
 <dc:creator>Pinar, Ali</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Networked representations of real-world phenomena are often partially
observed, which lead to incomplete networks. Analysis of such incomplete
networks can lead to skewed results. We examine the following problem: given an
incomplete network, which $b$ nodes should be probed to bring the largest
number of new nodes into the observed network? Many graph-mining tasks require
having observed a considerable amount of the network. Examples include
community discovery, belief propagation, influence maximization, etc. For
instance, consider someone who has observed a portion (say 1%) of the Twitter
retweet network via random tweet sampling. She wants to estimate the size of
the largest connected component of the fully observed retweet network. To
improve her estimate, how should she use her limited budget to reduce the
incompleteness of the network? In this work, we propose a novel algorithm,
called MaxOutProbe, which uses a budget $b$ (on nodes probed) to increase the
size of the observed network in terms of the number of nodes. Our experiments,
across a range of datasets and conditions, demonstrate the advantages of
MaxOutProbe over existing methods.
</dc:description>
 <dc:description>Comment: NIPS Workshop on Networks in the Social and Information Sciences</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06464</identifier>
 <datestamp>2016-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unitary Evolution Recurrent Neural Networks</dc:title>
 <dc:creator>Arjovsky, Martin</dc:creator>
 <dc:creator>Shah, Amar</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) are notoriously difficult to train. When the
eigenvalues of the hidden to hidden weight matrix deviate from absolute value
1, optimization becomes difficult due to the well studied issue of vanishing
and exploding gradients, especially when trying to learn long-term
dependencies. To circumvent this problem, we propose a new architecture that
learns a unitary weight matrix, with eigenvalues of absolute value exactly 1.
The challenge we address is that of parametrizing unitary matrices in a way
that does not require expensive computations (such as eigendecomposition) after
each weight update. We construct an expressive unitary weight matrix by
composing several structured matrices that act as building blocks with
parameters to be learned. Optimization with this parameterization becomes
feasible only when considering hidden states in the complex domain. We
demonstrate the potential of this architecture by achieving state of the art
results in several hard tasks involving very long-term dependencies.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06468</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Parallel Solver for Positive Linear Programs via
  Dynamically-Bucketed Selective Coordinate Descent</dc:title>
 <dc:creator>Wang, Di</dc:creator>
 <dc:creator>Mahoney, Michael</dc:creator>
 <dc:creator>Mohan, Nishanth</dc:creator>
 <dc:creator>Rao, Satish</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We provide improved parallel approximation algorithms for the important class
of packing and covering linear programs. In particular, we present new parallel
$\epsilon$-approximate packing and covering solvers which run in
$\tilde{O}(1/\epsilon^2)$ expected time, i.e., in expectation they take
$\tilde{O}(1/\epsilon^2)$ iterations and they do $\tilde{O}(N/\epsilon^2)$
total work, where $N$ is the size of the constraint matrix and $\epsilon$ is
the error parameter, and where the $\tilde{O}$ hides logarithmic factors. To
achieve our improvement, we introduce an algorithmic technique of broader
interest: dynamically-bucketed selective coordinate descent (DB-SCD). At each
step of the iterative optimization algorithm, the DB-SCD method dynamically
buckets the coordinates of the gradient into those of roughly equal magnitude,
and it updates all the coordinates in one of the buckets. This
dynamically-bucketed updating permits us to take steps along several
coordinates with similar-sized gradients, thereby permitting more appropriate
step sizes at each step of the algorithm. In particular, this technique allows
us to use in a straightforward manner the recent analysis from the breakthrough
results of Allen-Zhu and Orecchia [2] to achieve our still-further improved
bounds. More generally, this method addresses &quot;interference&quot; among coordinates,
by which we mean the impact of the update of one coordinate on the gradients of
other coordinates. Such interference is a core issue in parallelizing
optimization routines that rely on smoothness properties. Since our DB-SCD
method reduces interference via updating a selective subset of variables at
each iteration, we expect it may also have more general applicability in
optimization.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06468</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06470</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comment on Two schemes for Secure Outsourcing of Linear Programming</dc:title>
 <dc:creator>Cao, Zhengjun</dc:creator>
 <dc:creator>Liu, Lihua</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recently, Wang et al. [IEEE INFOCOM 2011, 820-828], and Nie et al. [IEEE AINA
2014, 591-596] have proposed two schemes for secure outsourcing of large-scale
linear programming (LP). They did not consider the standard form: minimize
c^{T}x, subject to Ax=b, x&gt;0. Instead, they studied a peculiar form: minimize
c^{T}x, subject to Ax = b, Bx&gt;0, where B is a non-singular matrix. In this
note, we stress that the proposed peculiar form is unsolvable and meaningless.
The two schemes have confused the functional inequality constraints Bx&gt;0 with
the nonnegativity constraints x&gt;0 in the linear programming model. But the
condition x&gt;0 is indispensable to the simplex method. Therefore, both two
schemes failed.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06477</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Cooperative Behavior of Open Homogeneous Chemical Reaction Systems in
  the Extent Domain</dc:title>
 <dc:creator>Bhatt, Nirav</dc:creator>
 <dc:creator>Srinivasan, Sriniketh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Material balance equations describe the dynamics of the species in open
reaction systems and contain information regarding reaction topology, kinetics
and operation mode. For reaction systems, the state variables (the numbers of
moles, or concentrations) have recently been transformed into decoupled
reaction variants (extents of reaction), and reaction invariants (extents of
flow) (Amrhein et al., AIChE Journal, 2010). This paper analyses the conditions
under which an open homogeneous reaction system is cooperative in the extents
domain. Further, it is shown that the dynamics of the extents of flow exhibit
cooperative behavior. Further, we provide the conditions under which the
dynamics of the extents of reaction exhibit cooperative behavior. Our results
provide physical insights into cooperative and competitive nature of the
underlying reaction system in the presence of material exchange with
surrounding (i.e., inlet and outlet flows). The results of the article are
demonstrated via examples.
</dc:description>
 <dc:description>Comment: The paper was presented in the first Indian Control Conference 2015</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06480</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Binary Embedding using Circulant Matrices</dc:title>
 <dc:creator>Yu, Felix X.</dc:creator>
 <dc:creator>Bhaskara, Aditya</dc:creator>
 <dc:creator>Kumar, Sanjiv</dc:creator>
 <dc:creator>Gong, Yunchao</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Binary embeddings provide efficient and powerful ways to perform operations
on large scale data. However binary embedding typically requires long codes in
order to preserve the discriminative power of the input space. Thus binary
coding methods traditionally suffer from high computation and storage costs in
such a scenario. To address this problem, we propose Circulant Binary Embedding
(CBE) which generates binary codes by projecting the data with a circulant
matrix. The circulant structure allows us to use Fast Fourier Transform
algorithms to speed up the computation. For obtaining $k$-bit binary codes from
$d$-dimensional data, this improves the time complexity from $O(dk)$ to
$O(d\log{d})$, and the space complexity from $O(dk)$ to $O(d)$.
  We study two settings, which differ in the way we choose the parameters of
the circulant matrix. In the first, the parameters are chosen randomly and in
the second, the parameters are learned using the data. For randomized CBE, we
give a theoretical analysis comparing it with binary embedding using an
unstructured random projection matrix. The challenge here is to show that the
dependencies in the entries of the circulant matrix do not lead to a loss in
performance. In the second setting, we design a novel time-frequency
alternating optimization to learn data-dependent circulant projections, which
alternatively minimizes the objective in original and Fourier domains. In both
the settings, we show by extensive experiments that the CBE approach gives much
better performance than the state-of-the-art approaches if we fix a running
time, and provides much faster computation with negligible performance
degradation if we fix the number of bits in the embedding.
</dc:description>
 <dc:description>Comment: This is an extended version of a paper by the first, third, fourth
  and fifth authors that appeared in ICML 2014 [arXiv:1405.3162]</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2015-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06481</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variance Reduction in SGD by Distributed Importance Sampling</dc:title>
 <dc:creator>Alain, Guillaume</dc:creator>
 <dc:creator>Lamb, Alex</dc:creator>
 <dc:creator>Sankar, Chinnadhurai</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Humans are able to accelerate their learning by selecting training materials
that are the most informative and at the appropriate level of difficulty. We
propose a framework for distributing deep learning in which one set of workers
search for the most informative examples in parallel while a single worker
updates the model on examples selected by importance sampling. This leads the
model to update using an unbiased estimate of the gradient which also has
minimum variance when the sampling proposal is proportional to the L2-norm of
the gradient. We show experimentally that this method reduces gradient variance
even in a context where the cost of synchronization across machines cannot be
ignored, and where the factors for importance sampling are not updated
instantly across the training set.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06483</identifier>
 <datestamp>2016-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Directional Initial Access for Millimeter Wave Cellular Systems</dc:title>
 <dc:creator>Barati, C. Nicolas</dc:creator>
 <dc:creator>Hosseini, S. Amir</dc:creator>
 <dc:creator>Mezzavilla, Marco</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Korakis, Thanasis</dc:creator>
 <dc:creator>Panwar, Shivendra S.</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The millimeter wave (mmWave) bands have recently attracted considerable
interest for next-generation cellular systems due to the massive available
bandwidths at these frequencies. However, a key challenge in designing mmWave
cellular systems is initial access -- the procedure by which a mobile
establishes an initial link-layer connection to a base station cell. MmWave
communication relies on highly directional transmissions and the initial access
procedure must thus provide a mechanism by which initial transmission
directions can be searched in a potentially large angular space. Design options
are compared considering different scanning and signaling procedures to
evaluate access delay and system overhead. The channel structure and multiple
access issues are also considered. The analysis demonstrates significant
benefits of low-resolution fully digital architectures in comparison to single
stream analog beamforming.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06485</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the energy landscape of deep networks</dc:title>
 <dc:creator>Chaudhari, Pratik</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce &quot;AnnealSGD&quot;, a regularized stochastic gradient descent algorithm
motivated by an analysis of the energy landscape of a particular class of deep
networks with sparse random weights. The loss function of such networks can be
approximated by the Hamiltonian of a spherical spin glass with Gaussian
coupling. While different from currently-popular architectures such as
convolutional ones, spin glasses are amenable to analysis, which provides
insights on the topology of the loss function and motivates algorithms to
minimize it. Specifically, we show that a regularization term akin to a
magnetic field can be modulated with a single scalar parameter to transition
the loss function from a complex, non-convex landscape with exponentially many
local minima, to a phase with a polynomial number of minima, all the way down
to a trivial landscape with a unique minimum. AnnealSGD starts training in the
relaxed polynomial regime and gradually tightens the regularization parameter
to steer the energy towards the original exponential regime. Even for
convolutional neural networks, which are quite unlike sparse random networks,
we empirically show that AnnealSGD improves the generalization error using
competitive baselines on MNIST and CIFAR-10.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06487</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>mplrs: A scalable parallel vertex/facet enumeration code</dc:title>
 <dc:creator>Avis, David</dc:creator>
 <dc:creator>Jordan, Charles</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>90C05</dc:subject>
 <dc:description>  We describe a new parallel implementation, mplrs, of the vertex enumeration
code lrs that uses the MPI parallel environment and can be run on a network of
computers. The implementation makes use of a C wrapper that essentially uses
the existing lrs code with only minor modifications. mplrs was derived from the
earlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses
the Boost library and runs on a shared memory machine. In developing mplrs we
discovered a method of balancing the parallel tree search, called budgeting,
that greatly improves parallelization beyond the bottleneck encountered
previously at around 32 cores.
  This method can be readily adapted for use in other reverse search
enumeration codes. We also report some preliminary computational results
comparing parallel and sequential codes for vertex/facet enumeration problems
for convex polyhedra. The problems chosen span the range from simple to highly
degenerate polytopes. For most problems tested, the results clearly show the
advantage of using the parallel implementation mplrs of the reverse search
based code lrs, even when as few as 8 cores are available. For some problems
almost linear speedup was observed up to 1200 cores, the largest number of
cores tested.
</dc:description>
 <dc:description>Comment: Revision incorporating additional suggested changes</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06488</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resiliency of Deep Neural Networks under Quantization</dc:title>
 <dc:creator>Sung, Wonyong</dc:creator>
 <dc:creator>Shin, Sungho</dc:creator>
 <dc:creator>Hwang, Kyuyeon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The complexity of deep neural network algorithms for hardware implementation
can be much lowered by optimizing the word-length of weights and signals.
Direct quantization of floating-point weights, however, does not show good
performance when the number of bits assigned is small. Retraining of quantized
networks has been developed to relieve this problem. In this work, the effects
of retraining are analyzed for a feedforward deep neural network (FFDNN) and a
convolutional neural network (CNN). The network complexity is controlled to
know their effects on the resiliency of quantized networks by retraining. The
complexity of the FFDNN is controlled by varying the unit size in each hidden
layer and the number of layers, while that of the CNN is done by modifying the
feature map configuration. We find that the performance gap between the
floating-point and the retrain-based ternary (+1, 0, -1) weight neural networks
exists with a fair amount in 'complexity limited' networks, but the discrepancy
almost vanishes in fully complex networks whose capability is limited by the
training data, rather than by the number of connections. This research shows
that highly complex DNNs have the capability of absorbing the effects of severe
weight quantization through retraining, but connection limited networks are
less resilient. This paper also presents the effective compression ratio to
guide the trade-off between the network size and the precision when the
hardware resource is limited.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06489</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Hierarchical Pooling Data Structure for Loop Closure</dc:title>
 <dc:creator>Fei, Xiaohan</dc:creator>
 <dc:creator>Tsotsos, Konstantine</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a data structure obtained by hierarchically averaging bag-of-word
descriptors during a sequence of views that achieves average speedups in
large-scale loop closure applications ranging from 4 to 20 times on benchmark
datasets. Although simple, the method works as well as sophisticated
agglomerative schemes at a fraction of the cost with minimal loss of
performance.
</dc:description>
 <dc:date>2015-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06491</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>eBear: An Expressive Bear-Like Robot</dc:title>
 <dc:creator>Zhang, Xiao</dc:creator>
 <dc:creator>Mollahosseini, Ali</dc:creator>
 <dc:creator>B., Amir H. Kargar</dc:creator>
 <dc:creator>Boucher, Evan</dc:creator>
 <dc:creator>Voyles, Richard M.</dc:creator>
 <dc:creator>Nielsen, Rodney</dc:creator>
 <dc:creator>Mahoor, Mohammd H.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents an anthropomorphic robotic bear for the exploration of
human-robot interaction including verbal and non-verbal communications. This
robot is implemented with a hybrid face composed of a mechanical faceplate with
10 DOFs and an LCD-display-equipped mouth. The facial emotions of the bear are
designed based on the description of the Facial Action Coding System as well as
some animal-like gestures described by Darwin. The mouth movements are realized
by synthesizing emotions with speech. User acceptance investigations have been
conducted to evaluate the likability of these facial behaviors exhibited by the
eBear. Multiple Kernel Learning is proposed to fuse different features for
recognizing user's facial expressions. Our experimental results show that the
developed Bear-Like robot can perceive basic facial expressions and provide
emotive conveyance towards human beings.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06491</dc:identifier>
 <dc:identifier>The 23rd IEEE International Symposium on Robot and Human
  Interactive Communication, 2014 RO-MAN</dc:identifier>
 <dc:identifier>doi:10.1109/ROMAN.2014.6926378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06493</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embarrassingly Parallel Time Series Analysis for Large Scale Weak Memory
  Systems</dc:title>
 <dc:creator>Belletti, Francois</dc:creator>
 <dc:creator>Sparks, Evan</dc:creator>
 <dc:creator>Franklin, Michael</dc:creator>
 <dc:creator>Bayen, Alexandre M.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68M14, 37M10, 62M10</dc:subject>
 <dc:description>  Second order stationary models in time series analysis are based on the
analysis of essential statistics whose computations follow a common pattern. In
particular, with a map-reduce nomenclature, most of these operations can be
modeled as mapping a kernel that only depends on short windows of consecutive
data and reducing the results produced by each computation. This computational
pattern stems from the ergodicity of the model under consideration and is often
referred to as weak or short memory when it comes to data indexed with respect
to time. In the following we will show how studying weak memory systems can be
done in a scalable manner thanks to a framework relying on specifically
designed overlapping distributed data structures that enable fragmentation and
replication of the data across many machines as well as parallelism in
computations. This scheme has been implemented for Apache Spark but is
certainly not system specific. Indeed we prove it is also adapted to leveraging
high bandwidth fragmented memory blocks on GPUs.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06494</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Warping of Active Appearance Model</dc:title>
 <dc:creator>Mollahosseini, Ali</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Active Appearance Model (AAM) is a commonly used method for facial image
analysis with applications in face identification and facial expression
recognition. This paper proposes a new approach based on image alignment for
AAM fitting called bidirectional warping. Previous approaches warp either the
input image or the appearance template. We propose to warp both the input
image, using incremental update by an affine transformation, and the appearance
template, using an inverse compositional approach. Our experimental results on
Multi-PIE face database show that the bidirectional approach outperforms
state-of-the-art inverse compositional fitting approaches in extracting
landmark points of faces with shape and pose variations.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06494</dc:identifier>
 <dc:identifier>2013 IEEE Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW)</dc:identifier>
 <dc:identifier>doi:10.1109/CVPRW.2013.129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06499</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Variational Gaussian Process</dc:title>
 <dc:creator>Tran, Dustin</dc:creator>
 <dc:creator>Ranganath, Rajesh</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Variational inference is a powerful tool for approximate inference, and it
has been recently applied for representation learning with deep generative
models. We develop the variational Gaussian process (VGP), a Bayesian
nonparametric variational family, which adapts its shape to match complex
posterior distributions. The VGP generates approximate posterior samples by
generating latent inputs and warping them through random non-linear mappings;
the distribution over random mappings is learned during inference, enabling the
transformed outputs to adapt to varying complexity. We prove a universal
approximation theorem for the VGP, demonstrating its representative power for
learning any model. For inference we present a variational objective inspired
by auto-encoders and perform black box inference over a wide class of models.
The VGP achieves new state-of-the-art results for unsupervised learning,
inferring models such as the deep latent Gaussian model and the recently
proposed DRAW.
</dc:description>
 <dc:description>Comment: Appears in International Conference on Learning Representations, 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06502</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ExpressionBot: An Emotive Lifelike Robotic Face for Face-to-Face
  Communication</dc:title>
 <dc:creator>Mollahosseini, Ali</dc:creator>
 <dc:creator>Graitzer, Gabriel</dc:creator>
 <dc:creator>Borts, Eric</dc:creator>
 <dc:creator>Conyers, Stephen</dc:creator>
 <dc:creator>Voyles, Richard M.</dc:creator>
 <dc:creator>Cole, Ronald</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This article proposes an emotive lifelike robotic face, called ExpressionBot,
that is designed to support verbal and non-verbal communication between the
robot and humans, with the goal of closely modeling the dynamics of natural
face-to-face communication. The proposed robotic head consists of two major
components: 1) a hardware component that contains a small projector, a fish-eye
lens, a custom-designed mask and a neck system with 3 degrees of freedom; 2) a
facial animation system, projected onto the robotic mask, that is capable of
presenting facial expressions, realistic eye movement, and accurate visual
speech. We present three studies that compare Human-Robot Interaction with
Human-Computer Interaction with a screen-based model of the avatar. The studies
indicate that the robotic face is well accepted by users, with some advantages
in recognition of facial expression and mutual eye gaze contact.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06502</dc:identifier>
 <dc:identifier>14th IEEE-RAS International Conference on Humanoid Robots
  (Humanoids), 2014</dc:identifier>
 <dc:identifier>doi:10.1109/HUMANOIDS.2014.7041505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06504</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Duty Cycling for Heterogenous Energy Harvesting Networks</dc:title>
 <dc:creator>Zhang, Jianhui</dc:creator>
 <dc:creator>Wang, Mengmeng</dc:creator>
 <dc:creator>Li, Zhi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In recent years, there have been several kinds of energy harvesting networks
containing some tiny devices, such as ambient backscatter, ring and renewable
sensor networks. During energy harvesting, such networks suffer from the energy
heterogeneity, dynamics and prediction hardness because the access to natural
resources is often spatiotemporal different and timely changing among the
devices. Meanwhile, the charging efficiency is quite low especially when the
power of the harvested energy is weak. It results in the energy waste to store
the harvested energy indirectly. These features bring challenging and
interesting issues on efficient allocation of the harvested energy. This paper
studies the \emph{stochastic duty cycling} by considering these features with
the objective characterized by maximizing the common active time. We consider
two cases: offline and online stochastic duty cycling. For the offline case, we
design an optimal solution: offline duty cycling algorithm. For the online
case, we design an online duty cycling algorithm, which achieves the
approximation ratio with at least $1-e^{-\gamma^2}$, where $\gamma$ is the
probability able to harvest energy. We also evaluate our algorithms with the
experiment on a real energy harvesting network. The experiment results show
that the performance of the online algorithm can be very close to the offline
algorithm.
</dc:description>
 <dc:description>Comment: Publised on 34th IEEE-International Performance Computing and
  Communications Conference (IPCCC 2015)</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2015-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06510</identifier>
 <datestamp>2016-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TOBE: Tangible Out-of-Body Experience</dc:title>
 <dc:creator>Gervais, Renaud</dc:creator>
 <dc:creator>Frey, J&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>Gay, Alexis</dc:creator>
 <dc:creator>Lotte, Fabien</dc:creator>
 <dc:creator>Hachet, Martin</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We propose a toolkit for creating Tangible Out-of-Body Experiences: exposing
the inner states of users using physiological signals such as heart rate or
brain activity. Tobe can take the form of a tangible avatar displaying live
physiological readings to reflect on ourselves and others. Such a toolkit could
be used by researchers and designers to create a multitude of potential
tangible applications, including (but not limited to) educational tools about
Science Technologies Engineering and Mathematics (STEM) and cognitive science,
medical applications or entertainment and social experiences with one or
several users or Tobes involved. Through a co-design approach, we investigated
how everyday people picture their physiology and we validated the acceptability
of Tobe in a scientific museum. We also give a practical example where two
users relax together, with insights on how Tobe helped them to synchronize
their signals and share a moment.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06510</dc:identifier>
 <dc:identifier>Tangible, Embedded and Embodied Interaction (TEI), Feb 2016,
  Eindhoven, Netherlands. 2016, \&amp;lt;http://www.tei-conf.org/16/\&amp;gt;.
  \&amp;lt;10.1145/2839462.2839486\&amp;gt;</dc:identifier>
 <dc:identifier>doi:10.1145/2839462.2839486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06518</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Transmit Antenna Selection Scheme for Secure Throughput
  Maximization Without CSI at the Transmitter and its Applications on Smart
  Grids</dc:title>
 <dc:creator>Alves, Hirley</dc:creator>
 <dc:creator>Tom&#xe9;, Mauricio</dc:creator>
 <dc:creator>Nardelli, Pedro H. J.</dc:creator>
 <dc:creator>de Lima, Carlos H. M.</dc:creator>
 <dc:creator>Latva-aho, Matti</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the establishment of secure communication links between
smart-meters (Alice) and an aggregator (Bob) in the presence of an eavesdropper
(Eve). The proposed scenario assumes: (i) MIMOME wiretap channel; (ii) transmit
antenna selection at the Alice; (iii) no channel state information at the
transmitter; (iv) fixed Wyner codes; and (v) guarantee of secure throughput by
both quality of service and secrecy outage constraints. We propose a simple
protocol to enhance security via transmit antenna selection, and then assess
its performance in closed-form by means of secrecy outage and successful
transmission probabilities. We assume these probabilities are our constraints
and then maximize the secure throughput, establishing a security-reliability
trade-off for the proposed scenario. Our numerical results illustrate the
effect of this trade-off on the secure throughput as well as on the number of
antennas at Alice, Bob and Eve. Interestingly, a small sacrifice in reliability
allows secrecy enhancement in terms of secure bps/Hz. We apply this idea in our
smart grid application to exemplify that, although Eve may acquire some samples
of the average power demand of a household, it is not enough to properly
reconstruct such curve.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06522</identifier>
 <datestamp>2016-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrating Deep Features for Material Recognition</dc:title>
 <dc:creator>Zhang, Yan</dc:creator>
 <dc:creator>Ozay, Mete</dc:creator>
 <dc:creator>Liu, Xing</dc:creator>
 <dc:creator>Okatani, Takayuki</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a method for integration of features extracted using deep
representations of Convolutional Neural Networks (CNNs) each of which is
learned using a different image dataset of objects and materials for material
recognition. Given a set of representations of multiple pre-trained CNNs, we
first compute activations of features using the representations on the images
to select a set of samples which are best represented by the features. Then, we
measure the uncertainty of the features by computing the entropy of class
distributions for each sample set. Finally, we compute the contribution of each
feature to representation of classes for feature selection and integration. We
examine the proposed method on three benchmark datasets for material
recognition. Experimental results show that the proposed method achieves
state-of-the-art performance by integrating deep features. Additionally, we
introduce a new material dataset called EFMD by extending Flickr Material
Database (FMD). By the employment of the EFMD with transfer learning for
updating the learned CNN models, we achieve 84.0%+/-1.8% accuracy on the FMD
dataset which is close to human performance that is 84.9%.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06523</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WIDER FACE: A Face Detection Benchmark</dc:title>
 <dc:creator>Yang, Shuo</dc:creator>
 <dc:creator>Luo, Ping</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face detection is one of the most studied topics in the computer vision
community. Much of the progresses have been made by the availability of face
detection benchmark datasets. We show that there is a gap between current face
detection performance and the real world requirements. To facilitate future
face detection research, we introduce the WIDER FACE dataset, which is 10 times
larger than existing datasets. The dataset contains rich annotations, including
occlusions, poses, event categories, and face bounding boxes. Faces in the
proposed dataset are extremely challenging due to large variations in scale,
pose and occlusion, as shown in Fig. 1. Furthermore, we show that WIDER FACE
dataset is an effective training source for face detection. We benchmark
several representative detection systems, providing an overview of
state-of-the-art performance and propose a solution to deal with large scale
variation. Finally, we discuss common failure cases that worth to be further
investigated. Dataset can be downloaded at:
mmlab.ie.cuhk.edu.hk/projects/WIDERFace
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06530</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compression of Deep Convolutional Neural Networks for Fast and Low Power
  Mobile Applications</dc:title>
 <dc:creator>Kim, Yong-Deok</dc:creator>
 <dc:creator>Park, Eunhyeok</dc:creator>
 <dc:creator>Yoo, Sungjoo</dc:creator>
 <dc:creator>Choi, Taelim</dc:creator>
 <dc:creator>Yang, Lu</dc:creator>
 <dc:creator>Shin, Dongjun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Although the latest high-end smartphone has powerful CPU and GPU, running
deeper convolutional neural networks (CNNs) for complex tasks such as ImageNet
classification on mobile devices is challenging. To deploy deep CNNs on mobile
devices, we present a simple and effective scheme to compress the entire CNN,
which we call one-shot whole network compression. The proposed scheme consists
of three steps: (1) rank selection with variational Bayesian matrix
factorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning
to recover accumulated loss of accuracy, and each step can be easily
implemented using publicly available tools. We demonstrate the effectiveness of
the proposed scheme by testing the performance of various compressed CNNs
(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant
reductions in model size, runtime, and energy consumption are obtained, at the
cost of small loss in accuracy. In addition, we address the important
implementation level issue on 1?1 convolution, which is a key operation of
inception module of GoogLeNet as well as CNNs compressed by our proposed
scheme.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06545</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A dense subgraph based algorithm for compact salient image region
  detection</dc:title>
 <dc:creator>Chakraborty, Souradeep</dc:creator>
 <dc:creator>Mitra, Pabitra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an algorithm for graph based saliency computation that utilizes
the underlying dense subgraphs in finding visually salient regions in an image.
To compute the salient regions, the model first obtains a saliency map using
random walks on a Markov chain. Next, k-dense subgraphs are detected to further
enhance the salient regions in the image. Dense subgraphs convey more
information about local graph structure than simple centrality measures. To
generate the Markov chain, intensity and color features of an image in addition
to region compactness is used. For evaluating the proposed model, we do
extensive experiments on benchmark image data sets. The proposed method
performs comparable to well-known algorithms in salient region detection.
</dc:description>
 <dc:description>Comment: 33 pages, 18 figures, Single column manuscript pre-print, Accepted at
  Computer Vision and Image Understanding, Elsevier</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2015-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06545</dc:identifier>
 <dc:identifier>doi:10.1016/j.cviu.2015.12.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06554</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation into the Use of Common Libraries in Android Apps</dc:title>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Bissyand&#xe9;, Tegawend&#xe9; F.</dc:creator>
 <dc:creator>Klein, Jacques</dc:creator>
 <dc:creator>Traon, Yves Le</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The packaging model of Android apps requires the entire code necessary for
the execution of an app to be shipped into one single apk file. Thus, an
analysis of Android apps often visits code which is not part of the
functionality delivered by the app. Such code is often contributed by the
common libraries which are used pervasively by all apps. Unfortunately, Android
analyses, e.g., for piggybacking detection and malware detection, can produce
inaccurate results if they do not take into account the case of library code,
which constitute noise in app features. Despite some efforts on investigating
Android libraries, the momentum of Android research has not yet produced a
complete set of common libraries to further support in-depth analysis of
Android apps. In this paper, we leverage a dataset of about 1.5 million apps
from Google Play to harvest potential common libraries, including advertisement
libraries. With several steps of refinements, we finally collect by far the
largest set of 1,113 libraries supporting common functionalities and 240
libraries for advertisement. We use the dataset to investigates several aspects
of Android libraries, including their popularity and their proportion in
Android app code. Based on these datasets, we have further performed several
empirical investigations to confirm the motivations behind our work.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06558</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal UGC-hardness of Approximating Max k-CSP_R</dc:title>
 <dc:creator>Manurangsi, Pasin</dc:creator>
 <dc:creator>Nakkiran, Preetum</dc:creator>
 <dc:creator>Trevisan, Luca</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we prove an almost-optimal hardness for Max $k$-CSP$_R$ based
on Khot's Unique Games Conjecture (UGC). In Max $k$-CSP$_R$, we are given a set
of predicates each of which depends on exactly $k$ variables. Each variable can
take any value from $1, 2, \dots, R$. The goal is to find an assignment to
variables that maximizes the number of satisfied predicates.
  Assuming the Unique Games Conjecture, we show that it is NP-hard to
approximate Max $k$-CSP$_R$ to within factor $2^{O(k \log k)}(\log
R)^{k/2}/R^{k - 1}$ for any $k, R$. To the best of our knowledge, this result
improves on all the known hardness of approximation results when $3 \leq k =
o(\log R/\log \log R)$. In this case, the previous best hardness result was
NP-hardness of approximating within a factor $O(k/R^{k-2})$ by Chan. When $k =
2$, our result matches the best known UGC-hardness result of Khot, Kindler,
Mossel and O'Donnell.
  In addition, by extending an algorithm for Max 2-CSP$_R$ by Kindler, Kolla
and Trevisan, we provide an $\Omega(\log R/R^{k - 1})$-approximation algorithm
for Max $k$-CSP$_R$. This algorithm implies that our inapproximability result
is tight up to a factor of $2^{O(k \log k)}(\log R)^{k/2 - 1}$. In comparison,
when $3 \leq k$ is a constant, the previously known gap was $O(R)$, which is
significantly larger than our gap of $O(\text{polylog } R)$.
  Finally, we show that we can replace the Unique Games Conjecture assumption
with Khot's $d$-to-1 Conjecture and still get asymptotically the same hardness
of approximation.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06559</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Directed Steiner Problems via Tree Embedding</dc:title>
 <dc:creator>Laekhanukit, Bundit</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In the k-edge connected directed Steiner tree (k-DST) problem, we are given a
directed graph G on n vertices with edge-costs, a root vertex r, a set of h
terminals T and an integer k. The goal is to find a min-cost subgraph H of G
that connects r to each terminal t by k edge-disjoint r,t-paths. This problem
includes as special cases the well-known directed Steiner tree (DST) problem
(the case k = 1) and the group Steiner tree (GST) problem. Despite having been
studied and mentioned many times in literature, e.g., by Feldman et al.
[SODA'09, JCSS'12], by Cheriyan et al. [SODA'12, TALG'14] and by Laekhanukit
[SODA'14], there was no known non-trivial approximation algorithm for k-DST for
k &gt;= 2 even in the special case that an input graph is directed acyclic and has
a constant number of layers. If an input graph is not acyclic, the complexity
status of k-DST is not known even for a very strict special case that k= 2 and
|T| = 2.
  In this paper, we make a progress toward developing a non-trivial
approximation algorithm for k-DST. We present an O(D k^{D-1} log
n)-approximation algorithm for k-DST on directed acyclic graphs (DAGs) with D
layers, which can be extended to a special case of k-DST on &quot;general graphs&quot;
when an instance has a D-shallow optimal solution, i.e., there exist k
edge-disjoint r,t-paths, each of length at most D, for every terminal t. For
the case k= 1 (DST), our algorithm yields an approximation ratio of O(D log h),
thus implying an O(log^3 h)-approximation algorithm for DST that runs in
quasi-polynomial-time (due to the height-reduction of Zelikovsky
[Algorithmica'97]). Consequently, as our algorithm works for general graphs, we
obtain an O(D k^{D-1} log n)-approximation algorithm for a D-shallow instance
of the k-edge-connected directed Steiner subgraph problem, where we wish to
connect every pair of terminals by k-edge-disjoint paths.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06559</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06566</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Acceleration of the PDHGM on strongly convex subspaces</dc:title>
 <dc:creator>Valkonen, Tuomo</dc:creator>
 <dc:creator>Pock, Thomas</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>90C25, 49M29, 94A08</dc:subject>
 <dc:description>  We propose several variants of the primal-dual method due to Chambolle and
Pock. Without requiring full strong convexity of the objective functions, our
methods are accelerated on subspaces with strong convexity. This yields mixed
rates, $O(1/N^2)$ with respect to initialisation and $O(1/N)$ with respect to
the dual sequence, and the residual part of the primal sequence. We demonstrate
the efficacy of the proposed methods on image processing problems lacking
strong convexity, such as total generalised variation denoising and total
variation deblurring.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06568</identifier>
 <datestamp>2017-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matchings of quadratic size extend to long cycles in hypercubes</dc:title>
 <dc:creator>Dvo&#x159;&#xe1;k, Tom&#xe1;&#x161;</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C38, 05C45, 05C70</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Ruskey and Savage in 1993 asked whether every matching in a hypercube can be
extended to a Hamiltonian cycle. A positive answer is known for perfect
matchings, but the general case has been resolved only for matchings of linear
size. In this paper we show that there is a quadratic function $q(n)$ such that
every matching in the $n$-dimensional hypercube of size at most $q(n)$ may be
extended to a cycle which covers at least $\frac34$ of the vertices.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06568</dc:identifier>
 <dc:identifier>Discrete Mathematics &amp; Theoretical Computer Science, Vol. 18 no.
  3, Graph Theory (September 1, 2016) dmtcs:2012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06569</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hankel Matrices for the Period-Doubling Sequence</dc:title>
 <dc:creator>Fokkink, Robbert J.</dc:creator>
 <dc:creator>Kraaikamp, Cor</dc:creator>
 <dc:creator>Shallit, Jeffrey</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We give an explicit evaluation, in terms of products of Jacobsthal numbers,
of the Hankel determinants of order a power of two for the period-doubling
sequence. We also explicitly give the eigenvalues and eigenvectors of the
corresponding Hankel matrices. Similar considerations give the Hankel
determinants for other orders.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06575</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ElSe: Ellipse Selection for Robust Pupil Detection in Real-World
  Environments</dc:title>
 <dc:creator>Fuhl, Wolfgang</dc:creator>
 <dc:creator>Santini, Thiago C.</dc:creator>
 <dc:creator>Kuebler, Thomas</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Fast and robust pupil detection is an essential prerequisite for video-based
eye-tracking in real-world settings. Several algorithms for image-based pupil
detection have been proposed, their applicability is mostly limited to
laboratory conditions. In realworld scenarios, automated pupil detection has to
face various challenges, such as illumination changes, reflections (on
glasses), make-up, non-centered eye recording, and physiological eye
characteristics. We propose ElSe, a novel algorithm based on ellipse evaluation
of a filtered edge image. We aim at a robust, resource-saving approach that can
be integrated in embedded architectures e.g. driving. The proposed algorithm
was evaluated against four state-of-the-art methods on over 93,000 hand-labeled
images from which 55,000 are new images contributed by this work. On average,
the proposed method achieved a 14.53% improvement on the detection rate
relative to the best state-of-the-art performer.
download:ftp://emmapupildata@messor.informatik.unituebingen. de
(password:eyedata).
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06578</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actually, It's About Ethics in Computational Social Science: A
  Multi-party Risk-Benefit Framework for Online Community Research</dc:title>
 <dc:creator>Keegan, Brian C.</dc:creator>
 <dc:creator>Matias, J. Nathan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Managers regularly face a complex ethical dilemma over how to best govern
online communities by evaluating the effectiveness of different social or
technical strategies. What ethical considerations should guide researchers and
managers when they employ causal research methods that make different community
members bear different risks and benefits, under different levels of consent?
We introduce a structural framework for evaluating the flows of risks and
benefits in social systems with multiple interacting parties. This framework
has implications for understanding the governmentality of managing
socio-technical systems, for making research ethics discussions more
commensurable, and for enumerating alternative goals researchers might pursue
with interventions.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure; AAAI Spring Symp. on Observational Studies through
  Social Media and Other Human-Generated Content, 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06581</identifier>
 <datestamp>2016-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dueling Network Architectures for Deep Reinforcement Learning</dc:title>
 <dc:creator>Wang, Ziyu</dc:creator>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>Hessel, Matteo</dc:creator>
 <dc:creator>van Hasselt, Hado</dc:creator>
 <dc:creator>Lanctot, Marc</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In recent years there have been many successes of using deep representations
in reinforcement learning. Still, many of these applications use conventional
architectures, such as convolutional networks, LSTMs, or auto-encoders. In this
paper, we present a new neural network architecture for model-free
reinforcement learning. Our dueling network represents two separate estimators:
one for the state value function and one for the state-dependent action
advantage function. The main benefit of this factoring is to generalize
learning across actions without imposing any change to the underlying
reinforcement learning algorithm. Our results show that this architecture leads
to better policy evaluation in the presence of many similar-valued actions.
Moreover, the dueling architecture enables our RL agent to outperform the
state-of-the-art on the Atari 2600 domain.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures, and 5 tables</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06586</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowd Behavior Analysis: A Review where Physics meets Biology</dc:title>
 <dc:creator>Kok, Ven Jyn</dc:creator>
 <dc:creator>Lim, Mei Kuan</dc:creator>
 <dc:creator>Chan, Chee Seng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Although the traits emerged in a mass gathering are often non-deliberative,
the act of mass impulse may lead to irre- vocable crowd disasters. The two-fold
increase of carnage in crowd since the past two decades has spurred significant
advances in the field of computer vision, towards effective and proactive crowd
surveillance. Computer vision stud- ies related to crowd are observed to
resonate with the understanding of the emergent behavior in physics (complex
systems) and biology (animal swarm). These studies, which are inspired by
biology and physics, share surprisingly common insights, and interesting
contradictions. However, this aspect of discussion has not been fully explored.
Therefore, this survey provides the readers with a review of the
state-of-the-art methods in crowd behavior analysis from the physics and
biologically inspired perspectives. We provide insights and comprehensive
discussions for a broader understanding of the underlying prospect of blending
physics and biology studies in computer vision.
</dc:description>
 <dc:description>Comment: Accepted in Neurocomputing, 31 pages, 180 references</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06586</dc:identifier>
 <dc:identifier>Neurocomputing 177 (2016) 342-362</dc:identifier>
 <dc:identifier>doi:10.1016/j.neucom.2015.11.021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06591</identifier>
 <datestamp>2016-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polysemy in Controlled Natural Language Texts</dc:title>
 <dc:creator>Gruzitis, Normunds</dc:creator>
 <dc:creator>Barzdins, Guntis</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Computational semantics and logic-based controlled natural languages (CNL) do
not address systematically the word sense disambiguation problem of content
words, i.e., they tend to interpret only some functional words that are crucial
for construction of discourse representation structures. We show that
micro-ontologies and multi-word units allow integration of the rich and
polysemous multi-domain background knowledge into CNL thus providing
interpretation for the content words. The proposed approach is demonstrated by
extending the Attempto Controlled English (ACE) with polysemous and procedural
constructs resulting in a more natural CNL named PAO covering narrative
multi-domain texts.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06591</dc:identifier>
 <dc:identifier>Controlled Natural Language, Lecture Notes in Computer Science,
  Vol. 5972, Springer, 2010, pp. 102-120</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-14418-9_7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06594</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bezier curves and surfaces based on modified Bernstein polynomials</dc:title>
 <dc:creator>Khan, Khalid</dc:creator>
 <dc:creator>Lobiyal, D. K.</dc:creator>
 <dc:creator>Kilicman, Adem</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>65D17, 41A10, 41A25, 41A36</dc:subject>
 <dc:description>  In this paper, we use the blending functions of Bernstein polynomials with
shifted knots for construction of Bezier curves and surfaces. We study the
nature of degree elevation and degree reduction for Bezier Bernstein functions
with shifted knots.
  Parametric curves are represented using these modified Bernstein basis and
the concept of total positivity is applied to investigate the shape properties
of the curve. We get Bezier curve defined on [0, 1] when we set the parameter
\alpha=\beta to the value 0. We also present a de Casteljau algorithm to
compute Bernstein Bezier curves and surfaces with shifted knots. The new curves
have some properties similar to Bezier curves. Furthermore, some fundamental
properties for Bernstein Bezier curves and surfaces are discussed.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1507.04110</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06603</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponential Natural Particle Filter</dc:title>
 <dc:creator>Zand, Ghazal</dc:creator>
 <dc:creator>Taherkhani, Mojtaba</dc:creator>
 <dc:creator>Safabakhsh, Reza</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Particle Filter algorithm (PF) suffers from some problems such as the loss of
particle diversity, the need for large number of particles, and the costly
selection of the importance density functions. In this paper, a novel
Exponential Natural Particle Filter (xNPF) is introduced to solve the above
problems. In this approach, a state transitional probability with the use of
natural gradient learning is proposed which balances exploration and
exploitation more robustly. The results show that xNPF converges much closer to
the true target states than the other state of the art particle filter.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06606</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Representation and Compression Using Linear-Programming
  Approximations</dc:title>
 <dc:creator>Paskov, Hristo S.</dc:creator>
 <dc:creator>Mitchell, John C.</dc:creator>
 <dc:creator>Hastie, Trevor J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose `Dracula', a new framework for unsupervised feature selection from
sequential data such as text. Dracula learns a dictionary of $n$-grams that
efficiently compresses a given corpus and recursively compresses its own
dictionary; in effect, Dracula is a `deep' extension of Compressive Feature
Learning. It requires solving a binary linear program that may be relaxed to a
linear program. Both problems exhibit considerable structure, their solution
paths are well behaved, and we identify parameters which control the depth and
diversity of the dictionary. We also discuss how to derive features from the
compressed documents and show that while certain unregularized linear models
are invariant to the structure of the compressed dictionary, this structure may
be used to regularize learning. Experiments are presented that demonstrate the
efficacy of Dracula's features.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06613</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Diffusion in Random Network Graphs</dc:title>
 <dc:creator>Meghanathan, Natarajan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper, we consider a random network such that there could be a link
between any two nodes in the network with a certain probability (plink).
Diffusion is the phenomenon of spreading information throughout the network,
starting from one or more initial set of nodes (called the early adopters).
Information spreads along the links with a certain probability (pdiff).
Diffusion happens in rounds with the first round involving the early adopters.
The nodes that receive the information for the first time are said to be
covered and become candidates for diffusion in the subsequent round. Diffusion
continues until all the nodes in the network have received the information
(successful diffusion) or there are no more candidate nodes to spread the
information but one or more nodes are yet to receive the information (diffusion
failure). On the basis of exhaustive simulations conducted in this paper, we
observe that for a given plink and pdiff values, the fraction of successful
diffusion attempts does not appreciably change with increase in the number of
early adopters; whereas, the average number of rounds per successful diffusion
attempt decreases with increase in the number of early adopters. The invariant
nature of the fraction of successful diffusion attempts with increase in the
number of early adopters for a random network (for fixed plink and pdiff
values) is an interesting and noteworthy observation (for further research) and
it has not been hitherto reported in the literature.
</dc:description>
 <dc:description>Comment: 7 papers; 5 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06613</dc:identifier>
 <dc:identifier>International Journal in Foundations of Computer Science and
  Technology (IJFCST), vol. 5, no. 5, pp. 1-7, September 2015</dc:identifier>
 <dc:identifier>doi:10.5121/ijfcst.2015.5501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06620</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use of Eigenvector Centrality to Detect Graph Isomorphism</dc:title>
 <dc:creator>Meghanathan, Natarajan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Graph Isomorphism is one of the classical problems of graph theory for which
no deterministic polynomial-time algorithm is currently known, but has been
neither proven to be NP-complete. Several heuristic algorithms have been
proposed to determine whether or not two graphs are isomorphic (i.e.,
structurally the same). In this research, we propose to use the sequence
(either the non-decreasing or nonincreasing order) of eigenvector centrality
(EVC) values of the vertices of two graphs as a precursor step to decide
whether or not to further conduct tests for graph isomorphism. The eigenvector
centrality of a vertex in a graph is a measure of the degree of the vertex as
well as the degrees of its neighbors. We hypothesize that if the non-increasing
(or non-decreasing) order of listings of the EVC values of the vertices of two
test graphs are not the same, then the two graphs are not isomorphic. If two
test graphs have an identical non-increasing order of the EVC sequence, then
they are declared to be potentially isomorphic and confirmed through additional
heuristics. We test our hypothesis on random graphs (generated according to the
Erdos-Renyi model) and we observe the hypothesis to be indeed true: graph pairs
that have the same sequence of non-increasing order of EVC values have been
confirmed to be isomorphic using the well-known Nauty software.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures; Proceedings of the Fourth International
  Conference on Advanced Information Technologies and Applications (ICAITA),
  pp. 1-9, Dubai, UAE, November 6-7, 2015</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06620</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.51501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06624</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TEMPO: Feature-Endowed Teichm\&quot;uller Extremal Mappings of Point Clouds</dc:title>
 <dc:creator>Meng, Ting Wei</dc:creator>
 <dc:creator>Choi, Gary Pui-Tung</dc:creator>
 <dc:creator>Lui, Lok Ming</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:description>  In recent decades, the use of 3D point clouds has been widespread in computer
industry. The development of techniques in analyzing point clouds is
increasingly important. In particular, mapping of point clouds has been a
challenging problem. In this paper, we develop a discrete analogue of the
Teichm\&quot;{u}ller extremal mappings, which guarantee uniform conformality
distortions, on point cloud surfaces. Based on the discrete analogue, we
propose a novel method called TEMPO for computing Teichm\&quot;{u}ller extremal
mappings between feature-endowed point clouds. Using our proposed method, the
Teichm\&quot;{u}ller metric is introduced for evaluating the dissimilarity of point
clouds. Consequently, our algorithm enables accurate recognition and
classification of point clouds. Experimental results demonstrate the
effectiveness of our proposed method.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06627</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Arbitrary-View Face Alignment by Recommendation Trees</dc:title>
 <dc:creator>Zhu, Shizhan</dc:creator>
 <dc:creator>Li, Cheng</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning to simultaneously handle face alignment of arbitrary views, e.g.
frontal and profile views, appears to be more challenging than we thought. The
difficulties lay in i) accommodating the complex appearance-shape relations
exhibited in different views, and ii) encompassing the varying landmark point
sets due to self-occlusion and different landmark protocols. Most existing
studies approach this problem via training multiple viewpoint-specific models,
and conduct head pose estimation for model selection. This solution is
intuitive but the performance is highly susceptible to inaccurate head pose
estimation. In this study, we address this shortcoming through learning an
Ensemble of Model Recommendation Trees (EMRT), which is capable of selecting
optimal model configuration without prior head pose estimation. The unified
framework seamlessly handles different viewpoints and landmark protocols, and
it is trained by optimising directly on landmark locations, thus yielding
superior results on arbitrary-view face alignment. This is the first study that
performs face alignment on the full AFLWdataset with faces of different views
including profile view. State-of-the-art performances are also reported on
MultiPIE and AFW datasets containing both frontaland profile-view faces.
</dc:description>
 <dc:description>Comment: This is our original submission to ICCV 2015</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06631</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Contrast MRI Reconstruction with Structure-Guided Total Variation</dc:title>
 <dc:creator>Ehrhardt, Matthias J.</dc:creator>
 <dc:creator>Betcke, Marta M.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Magnetic resonance imaging (MRI) is a versatile imaging technique that allows
different contrasts depending on the acquisition parameters. Many clinical
imaging studies acquire MRI data for more than one of these contrasts---such as
for instance T1 and T2 weighted images---which makes the overall scanning
procedure very time consuming. As all of these images show the same underlying
anatomy one can try to omit unnecessary measurements by taking the similarity
into account during reconstruction. We will discuss two modifications of total
variation---based on i) location and ii) direction---that take structural a
priori knowledge into account and reduce to total variation in the degenerate
case when no structural knowledge is available. We solve the resulting convex
minimization problem with the alternating direction method of multipliers that
separates the forward operator from the prior. For both priors the
corresponding proximal operator can be implemented as an extension of the fast
gradient projection method on the dual problem for total variation. We tested
the priors on six data sets that are based on phantoms and real MRI images. In
all test cases exploiting the structural information from the other contrast
yields better results than separate reconstruction with total variation in
terms of standard metrics like peak signal-to-noise ratio and structural
similarity index. Furthermore, we found that exploiting the two dimensional
directional information results in images with well defined edges, superior to
those reconstructed solely using a priori information about the edge location.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06631</dc:identifier>
 <dc:identifier>doi:10.1137/15M1047325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06639</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed and quantized correlation estimators</dc:title>
 <dc:creator>Zebadua, Augusto</dc:creator>
 <dc:creator>Amblard, Pierre-Olivier</dc:creator>
 <dc:creator>Moisan, Eric</dc:creator>
 <dc:creator>Michel, Olivier . J. J.</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In passive monitoring using sensor networks, low energy supplies drastically
constrain sensors in terms of calculation and communication abilities.
Designing processing algorithms at the sensor level that take into account
these constraints is an important problem in this context. We study here the
estimation of correlation functions between sensors using compressed
acquisition and one-bit-quantization. The estimation is achieved directly using
compressed samples, without considering any reconstruction of the signals. We
show that if the signals of interest are far from white noise, estimation of
the correlation using $M$ compressed samples out of $N\geq M$ can be more
advantageous than estimation of the correlation using $M$ consecutive samples.
The analysis consists of studying the asymptotic performance of the estimators
at a fixed compression rate. We provide the analysis when the compression is
realized by a random projection matrix composed of independent and identically
distributed entries. The framework includes widely used random projection
matrices, such as Gaussian and Bernoulli matrices, and it also includes very
sparse matrices. However, it does not include subsampling without replacement,
for which a separate analysis is provided. When considering
one-bit-quantization as well, the theoretical analysis is not tractable.
However, empirical evidence allows the conclusion that in practical situations,
compressed and quantized estimators behave sufficiently correctly to be useful
in, for example, time-delay estimation and model estimation.
</dc:description>
 <dc:description>Comment: submitted</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06641</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary Control of Reaction-Diffusion PDEs on Balls in Spaces of
  Arbitrary Dimensions</dc:title>
 <dc:creator>Vazquez, Rafael</dc:creator>
 <dc:creator>Krstic, Miroslav</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An explicit output-feedback boundary feedback law is introduced that
stabilizes an unstable linear constant-coefficient reaction-diffusion equation
on an $n$-ball (which in 2-D reduces to a disk and in 3-D reduces to a sphere)
using only measurements from the boundary. The backstepping method is used to
design both the control law and a boundary observer. To apply backstepping the
system is reduced to an infinite sequence of 1-D systems using spherical
harmonics. Well-posedness and stability are proved in the $H^1$ space. The
resulting control and output injection gain kernels are the product of the
backstepping kernel used in control of one-dimensional reaction-diffusion
equations and a function closely related to the Poisson kernel in the $n$-ball.
</dc:description>
 <dc:description>Comment: Submitted to ESAIM: Control and Calculus of Variations</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06644</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Gaussian Processes</dc:title>
 <dc:creator>Mattos, C&#xe9;sar Lincoln C.</dc:creator>
 <dc:creator>Dai, Zhenwen</dc:creator>
 <dc:creator>Damianou, Andreas</dc:creator>
 <dc:creator>Forth, Jeremy</dc:creator>
 <dc:creator>Barreto, Guilherme A.</dc:creator>
 <dc:creator>Lawrence, Neil D.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We define Recurrent Gaussian Processes (RGP) models, a general family of
Bayesian nonparametric models with recurrent GP priors which are able to learn
dynamical patterns from sequential data. Similar to Recurrent Neural Networks
(RNNs), RGPs can have different formulations for their internal states,
distinct inference methods and be extended with deep structures. In such
context, we propose a novel deep RGP model whose autoregressive states are
latent, thereby performing representation and dynamical learning
simultaneously. To fully exploit the Bayesian nature of the RGP model we
develop the Recurrent Variational Bayes (REVARB) framework, which enables
efficient inference and strong regularization through coherent propagation of
uncertainty across the RGP layers and states. We also introduce a RGP extension
where variational parameters are greatly reduced by being reparametrized
through RNN-based sequential recognition models. We apply our model to the
tasks of nonlinear system identification and human motion modeling. The
promising obtained results indicate that our RGP model maintains its highly
flexibility while being able to avoid overfitting and being applicable even
when larger datasets are not available.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016. 12 pages, 3 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06645</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepCut: Joint Subset Partition and Labeling for Multi Person Pose
  Estimation</dc:title>
 <dc:creator>Pishchulin, Leonid</dc:creator>
 <dc:creator>Insafutdinov, Eldar</dc:creator>
 <dc:creator>Tang, Siyu</dc:creator>
 <dc:creator>Andres, Bjoern</dc:creator>
 <dc:creator>Andriluka, Mykhaylo</dc:creator>
 <dc:creator>Gehler, Peter</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper considers the task of articulated human pose estimation of
multiple people in real world images. We propose an approach that jointly
solves the tasks of detection and pose estimation: it infers the number of
persons in a scene, identifies occluded body parts, and disambiguates body
parts between people in close proximity of each other. This joint formulation
is in contrast to previous strategies, that address the problem by first
detecting people and subsequently estimating their body pose. We propose a
partitioning and labeling formulation of a set of body-part hypotheses
generated with CNN-based part detectors. Our formulation, an instance of an
integer linear program, implicitly performs non-maximum suppression on the set
of part candidates and groups them to form configurations of body parts
respecting geometric and appearance constraints. Experiments on four different
datasets demonstrate state-of-the-art results for both single person and multi
person pose estimation. Models and code available at
http://pose.mpi-inf.mpg.de.
</dc:description>
 <dc:description>Comment: Accepted at IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2016)</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06653</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Encoder Multi-Decoder Networks, Semi-supervised Classification
  and Constrained Adversarial Generation</dc:title>
 <dc:creator>Harvey, F&#xe9;lix G.</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We explore recurrent encoder multi-decoder neural network architectures for
semi-supervised sequence classification and reconstruction. We find that the
use of multiple reconstruction modules helps models generalize. Our experiments
are conducted on two well known Motion Capture data sets. We also explore a
novel formulation for future predicting decoders based on conditional recurrent
generative adversarial networks. Further our networks have both soft and hard
constraints derived from desired physical properties of synthesized future
movements and desired animation goals. We find that networks with these
properties reduce common artifacts in generated sequences compared to using
simpler architectures.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06654</identifier>
 <datestamp>2016-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracklet Association by Online Target-Specific Metric Learning and
  Coherent Dynamics Estimation</dc:title>
 <dc:creator>Wang, Bing</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Chan, Kap Luk</dc:creator>
 <dc:creator>Wang, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a novel method based on online target-specific
metric learning and coherent dynamics estimation for tracklet (track fragment)
association by network flow optimization in long-term multi-person tracking.
Our proposed framework aims to exploit appearance and motion cues to prevent
identity switches during tracking and to recover missed detections.
Furthermore, target-specific metrics (appearance cue) and motion dynamics
(motion cue) are proposed to be learned and estimated online, i.e. during the
tracking process. Our approach is effective even when such cues fail to
identify or follow the target due to occlusions or object-to-object
interactions. We also propose to learn the weights of these two tracking cues
to handle the difficult situations, such as severe occlusions and
object-to-object interactions effectively. Our method has been validated on
several public datasets and the experimental results show that it outperforms
several state-of-the-art tracking methods.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Pattern Analysis and Machine Intelligence, in
  press, 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06654</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2016.2551245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06656</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Study of Age and Gender seen through Mobile Phone Usage Patterns in
  Mexico</dc:title>
 <dc:creator>Sarraute, Carlos</dc:creator>
 <dc:creator>Blanc, Pablo</dc:creator>
 <dc:creator>Burroni, Javier</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Mobile phone usage provides a wealth of information, which can be used to
better understand the demographic structure of a population. In this paper we
focus on the population of Mexican mobile phone users. Our first contribution
is an observational study of mobile phone usage according to gender and age
groups. We were able to detect significant differences in phone usage among
different subgroups of the population. Our second contribution is to provide a
novel methodology to predict demographic features (namely age and gender) of
unlabeled users by leveraging individual calling patterns, as well as the
structure of the communication graph. We provide details of the methodology and
show experimental results on a real world dataset that involves millions of
users.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06656</dc:identifier>
 <dc:identifier>Proc. 2014 IEEE/ACM International Conference on Advances in Social
  Networks Analysis and Mining (ASONAM), Beijing, China, 17-20 August 2014, pp.
  836 - 843</dc:identifier>
 <dc:identifier>doi:10.1109/ASONAM.2014.6921683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06660</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling the Temporal Nature of Human Behavior for Demographics
  Prediction</dc:title>
 <dc:creator>Felbo, Bjarke</dc:creator>
 <dc:creator>Sunds&#xf8;y, P&#xe5;l</dc:creator>
 <dc:creator>Pentland, Alex 'Sandy'</dc:creator>
 <dc:creator>Lehmann, Sune</dc:creator>
 <dc:creator>de Montjoye, Yves-Alexandre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Mobile phone metadata is increasingly used for humanitarian purposes in
developing countries as traditional data is scarce. Basic demographic
information is however often absent from mobile phone datasets, limiting the
operational impact of the datasets. For these reasons, there has been a growing
interest in predicting demographic information from mobile phone metadata.
Previous work focused on creating increasingly advanced features to be modeled
with standard machine learning algorithms. We here instead model the raw mobile
phone metadata directly using deep learning, exploiting the temporal nature of
the patterns in the data. From high-level assumptions we design a data
representation and convolutional network architecture for modeling patterns
within a week. We then examine three strategies for aggregating patterns across
weeks and show that our method reaches state-of-the-art accuracy on both age
and gender prediction using only the temporal modality in mobile metadata. We
finally validate our method on low activity users and evaluate the modeling
assumptions.
</dc:description>
 <dc:description>Comment: Accepted at ECML 2017. A previous version of this paper was titled
  'Using Deep Learning to Predict Demographics from Mobile Phone Metadata' and
  was accepted at the ICLR 2016 workshop</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06663</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>L1 logistic regression as a feature selection step for training stable
  classification trees for the prediction of severity criteria in imported
  malaria</dc:title>
 <dc:creator>Talenti, Luca</dc:creator>
 <dc:creator>Luck, Margaux</dc:creator>
 <dc:creator>Yartseva, Anastasia</dc:creator>
 <dc:creator>Argy, Nicolas</dc:creator>
 <dc:creator>Houz&#xe9;, Sandrine</dc:creator>
 <dc:creator>Damon, Cecilia</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Multivariate classification methods using explanatory and predictive models
are necessary for characterizing subgroups of patients according to their risk
profiles. Popular methods include logistic regression and classification trees
with performances that vary according to the nature and the characteristics of
the dataset. In the context of imported malaria, we aimed at classifying
severity criteria based on a heterogeneous patient population. We investigated
these approaches by implementing two different strategies: L1 logistic
regression (L1LR) that models a single global solution and classification trees
that model multiple local solutions corresponding to discriminant subregions of
the feature space. For each strategy, we built a standard model, and a sparser
version of it. As an alternative to pruning, we explore a promising approach
that first constrains the tree model with an L1LR-based feature selection, an
approach we called L1LR-Tree. The objective is to decrease its vulnerability to
small data variations by removing variables corresponding to unstable local
phenomena. Our study is twofold: i) from a methodological perspective comparing
the performances and the stability of the three previous methods, i.e L1LR,
classification trees and L1LR-Tree, for the classification of severe forms of
imported malaria, and ii) from an applied perspective improving the actual
classification of severe forms of imported malaria by identifying more
personalized profiles predictive of several clinical criteria based on
variables dismissed for the clinical definition of the disease. The main
methodological results show that the combined method L1LR-Tree builds sparse
and stable models that significantly predicts the different severity criteria
and outperforms all the other methods in terms of accuracy.
</dc:description>
 <dc:description>Comment: 18 pages, 10 figures, ICLR, computational science - Learning,
  Imported Malaria, L1 logistic regression, Decision tree</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06668</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving non-linear Horn clauses using a linear solver</dc:title>
 <dc:creator>Kafle, Bishoksan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Developing an efficient non-linear Horn clause solver is a challenging task
since the solver has to reason about the tree structures rather than the linear
ones as in a linear solver. In this paper we propose an incremental approach to
solving a set of non-linear Horn clauses using a linear Horn clause solver. We
achieve this by interleaving a program transformation and a linear solver. The
program transformation is based on the notion of tree dimension, which we apply
to trees corresponding to Horn clause derivations. The dimension of a tree is a
measure of its non-linearity -- for example a linear tree (whose nodes have at
most one child) has dimension zero while a complete binary tree has dimension
equal to its height.
  A given set of Horn clauses $P$ can be transformed into a new set of clauses
$P^k$ (whose derivation trees are the subset of $P$'s derivation trees with
dimension at most $k$). We start by generating $P^k$ with $k=0$, which is
linear by definition, then pass it to a linear solver. If $P^k$ has a solution
$M$, and is a solution to $P$ then $P$ has a solution $M$. If $M$ is not a
solution of $P$, we plugged $M$ to $P^{(k+1)}$ which again becomes linear and
pass it to the solver and continue successively for increasing value of $k$
until we find a solution to $P$ or resources are exhausted. Experiment on some
Horn clause verification benchmarks indicates that this is a promising approach
for solving a set of non-linear Horn clauses using a linear solver. It
indicates that many times a solution obtained for some under-approximation
$P^k$ of $P$ becomes a solution for $P$ for a fairly small value of $k$.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06669</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Sparsity-Aware Distributed Conjugate Gradient Algorithms for
  Sensor Networks</dc:title>
 <dc:creator>de Lamare, Rodrigo C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes distributed adaptive algorithms based on the conjugate
gradient (CG) method and the diffusion strategy for parameter estimation over
sensor networks. We present sparsity-aware conventional and modified
distributed CG algorithms using $l_{1}$ and log-sum penalty functions. The
proposed sparsity-aware diffusion distributed CG algorithms have an improved
performance in terms of mean square deviation (MSD) and convergence as compared
with the consensus least-mean square (Diffusion-LMS) algorithm, the diffusion
CG algorithms and a close performance to the diffusion distributed recursive
least squares (Consensus-RLS) algorithm. Numerical results show that the
proposed algorithms are reliable and can be applied in several scenarios.
</dc:description>
 <dc:description>Comment: 1 figure, 7 pages</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06674</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stories in the Eye: Contextual Visual Interactions for Efficient Video
  to Language Translation</dc:title>
 <dc:creator>Goyal, Anirudh</dc:creator>
 <dc:creator>Leordeanu, Marius</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Integrating higher level visual and linguistic interpretations is at the
heart of human intelligence. As automatic visual category recognition in images
is approaching human performance, the high level understanding in the dynamic
spatiotemporal domain of videos and its translation into natural language is
still far from being solved. While most works on vision-to-text translations
use pre-learned or pre-established computational linguistic models, in this
paper we present an approach that uses vision alone to efficiently learn how to
translate into language the video content. We discover, in simple form, the
story played by main actors, while using only visual cues for representing
objects and their interactions. Our method learns in a hierarchical manner
higher level representations for recognizing subjects, actions and objects
involved, their relevant contextual background and their interaction to one
another over time. We have a three stage approach: first we take in
consideration features of the individual entities at the local level of
appearance, then we consider the relationship between these objects and actions
and their video background, and third, we consider their spatiotemporal
relations as inputs to classifiers at the highest level of interpretation.
Thus, our approach finds a coherent linguistic description of videos in the
form of a subject, verb and object based on their role played in the overall
visual story learned directly from training data, without using a known
language model. We test the efficiency of our approach on a large scale dataset
containing YouTube clips taken in the wild and demonstrate state-of-the-art
performance, often superior to current approaches that use more complex,
pre-learned linguistic knowledge.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06676</identifier>
 <datestamp>2016-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalizing Human Video Pose Estimation</dc:title>
 <dc:creator>Charles, James</dc:creator>
 <dc:creator>Pfister, Tomas</dc:creator>
 <dc:creator>Magee, Derek</dc:creator>
 <dc:creator>Hogg, David</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a personalized ConvNet pose estimator that automatically adapts
itself to the uniqueness of a person's appearance to improve pose estimation in
long videos. We make the following contributions: (i) we show that given a few
high-precision pose annotations, e.g. from a generic ConvNet pose estimator,
additional annotations can be generated throughout the video using a
combination of image-based matching for temporally distant frames, and dense
optical flow for temporally local frames; (ii) we develop an occlusion aware
self-evaluation model that is able to automatically select the high-quality and
reject the erroneous additional annotations; and (iii) we demonstrate that
these high-quality annotations can be used to fine-tune a ConvNet pose
estimator and thereby personalize it to lock on to key discriminative features
of the person's appearance. The outcome is a substantial improvement in the
pose estimates for the target video using the personalized ConvNet compared to
the original generic ConvNet. Our method outperforms the state of the art
(including top ConvNet methods) by a large margin on two standard benchmarks,
as well as on a new challenging YouTube video dataset. Furthermore, we show
that training from the automatically generated annotations can be used to
improve the performance of a generic ConvNet on other benchmarks.
</dc:description>
 <dc:description>Comment: CVPR 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06681</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep End2End Voxel2Voxel Prediction</dc:title>
 <dc:creator>Tran, Du</dc:creator>
 <dc:creator>Bourdev, Lubomir</dc:creator>
 <dc:creator>Fergus, Rob</dc:creator>
 <dc:creator>Torresani, Lorenzo</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Over the last few years deep learning methods have emerged as one of the most
prominent approaches for video analysis. However, so far their most successful
applications have been in the area of video classification and detection, i.e.,
problems involving the prediction of a single class label or a handful of
output variables per video. Furthermore, while deep networks are commonly
recognized as the best models to use in these domains, there is a widespread
perception that in order to yield successful results they often require
time-consuming architecture search, manual tweaking of parameters and
computationally intensive pre-processing or post-processing methods.
  In this paper we challenge these views by presenting a deep 3D convolutional
architecture trained end to end to perform voxel-level prediction, i.e., to
output a variable at every voxel of the video. Most importantly, we show that
the same exact architecture can be used to achieve competitive results on three
widely different voxel-prediction tasks: video semantic segmentation, optical
flow estimation, and video coloring. The three networks learned on these
problems are trained from raw video without any form of preprocessing and their
outputs do not require post-processing to achieve outstanding performance.
Thus, they offer an efficient alternative to traditional and much more
computationally expensive methods in these video domains.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06683</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-k Multiclass SVM</dc:title>
 <dc:creator>Lapin, Maksim</dc:creator>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Class ambiguity is typical in image classification problems with a large
number of classes. When classes are difficult to discriminate, it makes sense
to allow k guesses and evaluate classifiers based on the top-k error instead of
the standard zero-one loss. We propose top-k multiclass SVM as a direct method
to optimize for top-k performance. Our generalization of the well-known
multiclass SVM is based on a tight convex upper bound of the top-k error. We
propose a fast optimization scheme based on an efficient projection onto the
top-k simplex, which is of its own interest. Experiments on five datasets show
consistent improvements in top-k accuracy compared to various baselines.
</dc:description>
 <dc:description>Comment: NIPS 2015</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06692</identifier>
 <datestamp>2016-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Prediction of 3D Body Poses from Motion Compensated Sequences</dc:title>
 <dc:creator>Tekin, Bugra</dc:creator>
 <dc:creator>Rozantsev, Artem</dc:creator>
 <dc:creator>Lepetit, Vincent</dc:creator>
 <dc:creator>Fua, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an efficient approach to exploiting motion information from
consecutive frames of a video sequence to recover the 3D pose of people.
Previous approaches typically compute candidate poses in individual frames and
then link them in a post-processing step to resolve ambiguities. By contrast,
we directly regress from a spatio-temporal volume of bounding boxes to a 3D
pose in the central frame.
  We further show that, for this approach to achieve its full potential, it is
essential to compensate for the motion in consecutive frames so that the
subject remains centered. This then allows us to effectively overcome
ambiguities and improve upon the state-of-the-art by a large margin on the
Human3.6m, HumanEva, and KTH Multiview Football 3D human pose estimation
benchmarks.
</dc:description>
 <dc:description>Comment: Published in CVPR 2016. supersedes arXiv:1504.08200</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06702</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view 3D Models from Single Images with a Convolutional Network</dc:title>
 <dc:creator>Tatarchenko, Maxim</dc:creator>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a convolutional network capable of inferring a 3D representation
of a previously unseen object given a single image of this object. Concretely,
the network can predict an RGB image and a depth map of the object as seen from
an arbitrary view. Several of these depth maps fused together give a full point
cloud of the object. The point cloud can in turn be transformed into a surface
mesh. The network is trained on renderings of synthetic 3D models of cars and
chairs. It successfully deals with objects on cluttered background and
generates reasonable predictions for real images of cars.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06703</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Through-Wall Person Localization Using Transceivers in Motion</dc:title>
 <dc:creator>Hillyard, Peter</dc:creator>
 <dc:creator>Maas, Dustin</dc:creator>
 <dc:creator>Premnath, Sriram</dc:creator>
 <dc:creator>Patwari, Neal</dc:creator>
 <dc:creator>Kasera, Sneha</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We develop novel methods for device-free localization (DFL) using
transceivers in motion. Such localization technologies are useful in various
cross-layer applications/protocols including those that are related to security
situations where it is important to know the presence and position of an
unauthorized person; in monitoring the daily activities of elderly or special
needs individuals; or in emergency situations when police or firefighters can
use the locations of people inside of a building in order to save lives. We
propose that transceivers mounted on autonomous vehicles could be both quickly
deployed and kept moving to ``sweep'' an area for changes in the channel that
would indicate the location of moving people and objects. The challenge is that
changes to channel measurements are introduced both by changes in the
environment and from motion of the transceivers. In this paper, we demonstrate
a method to detect human movement despite transceiver motion using
ultra-wideband impulse radar (UWB-IR) transceivers. The measurements reliably
detect a person's presence on a link line despite small-scale fading. We
explore via multiple experiments the ability of mobile UWB-IR transceivers,
moving outside of the walls of a room, to measure many lines crossing through
the room and accurately locate a person inside within 0.25 m average error.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06704</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Diversity versus Visual Diversity in Visual Dictionaries</dc:title>
 <dc:creator>Penatti, Ot&#xe1;vio A. B.</dc:creator>
 <dc:creator>Avila, Sandra</dc:creator>
 <dc:creator>Valle, Eduardo</dc:creator>
 <dc:creator>Torres, Ricardo da S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Visual dictionaries are a critical component for image
classification/retrieval systems based on the bag-of-visual-words (BoVW) model.
Dictionaries are usually learned without supervision from a training set of
images sampled from the collection of interest. However, for large,
general-purpose, dynamic image collections (e.g., the Web), obtaining a
representative sample in terms of semantic concepts is not straightforward. In
this paper, we evaluate the impact of semantics in the dictionary quality,
aiming at verifying the importance of semantic diversity in relation visual
diversity for visual dictionaries. In the experiments, we vary the amount of
classes used for creating the dictionary and then compute different BoVW
descriptors, using multiple codebook sizes and different coding and pooling
methods (standard BoVW and Fisher Vectors). Results for image classification
show that as visual dictionaries are based on low-level visual appearances,
visual diversity is more important than semantic diversity. Our conclusions
open the opportunity to alleviate the burden in generating visual dictionaries
as we need only a visually diverse set of images instead of the whole
collection to create a good dictionary.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06709</identifier>
 <datestamp>2016-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Neural Machine Translation Models with Monolingual Data</dc:title>
 <dc:creator>Sennrich, Rico</dc:creator>
 <dc:creator>Haddow, Barry</dc:creator>
 <dc:creator>Birch, Alexandra</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Neural Machine Translation (NMT) has obtained state-of-the art performance
for several language pairs, while only using parallel data for training.
Target-side monolingual data plays an important role in boosting fluency for
phrase-based statistical machine translation, and we investigate the use of
monolingual data for NMT. In contrast to previous work, which combines NMT
models with separately trained language models, we note that encoder-decoder
NMT architectures already have the capacity to learn the same information as a
language model, and we explore strategies to train with monolingual data
without changing the neural network architecture. By pairing monolingual
training data with an automatic back-translation, we can treat it as additional
parallel training data, and we obtain substantial improvements on the WMT 15
task English&lt;-&gt;German (+2.8-3.7 BLEU), and for the low-resourced IWSLT 14 task
Turkish-&gt;English (+2.1-3.4 BLEU), obtaining new state-of-the-art results. We
also show that fine-tuning on in-domain monolingual and parallel data gives
substantial improvements for the IWSLT 15 task English-&gt;German.
</dc:description>
 <dc:description>Comment: accepted to ACL 2016; new section on effect of back-translation
  quality</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06715</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Precoding for Physical Layer Multicasting</dc:title>
 <dc:creator>Dai, Mingbo</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work investigates the problem of downlink transmit precoding for
physical layer multicasting with a limited number of radio-frequency (RF)
chains. To tackle the RF hardware constraint, we consider a hybrid precoder
that is partitioned into a high-dimensional RF precoder and a low-dimensional
baseband precoder. Considering a total transmit power constraint over the RF
chains, the goal is to maximize the minimum (max-min) received signal-to-noise
ratio (SNR) among all users. We propose a low complexity algorithm to compute
the RF precoder that achieves near-optimal max-min performance. Moreover, we
derive a simple condition under which the hybrid precoding driven by a limited
number of RF chains incurs no loss of optimality with respect to the fully
digital precoding case. Finally, numerical results validate the effectiveness
of the proposed algorithm and theoretical findings.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Commun. Lett</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06715</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2015.2503273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06718</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-N recommendations from expressive recommender systems</dc:title>
 <dc:creator>Stark, Cyril</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Normalized nonnegative models assign probability distributions to users and
random variables to items; see [Stark, 2015]. Rating an item is regarded as
sampling the random variable assigned to the item with respect to the
distribution assigned to the user who rates the item. Models of that kind are
highly expressive. For instance, using normalized nonnegative models we can
understand users' preferences as mixtures of interpretable user stereotypes,
and we can arrange properties of users and items in a hierarchical manner.
These features would not be useful if the predictive power of normalized
nonnegative models was poor. Thus, we analyze here the performance of
normalized nonnegative models for top-N recommendation and observe that their
performance matches the performance of methods like PureSVD which was
introduced in [Cremonesi et al., 2010]. We conclude that normalized nonnegative
models not only provide accurate recommendations but they also deliver (for
free) representations that are interpretable. We deepen the discussion of
normalized nonnegative models by providing further theoretical insights. In
particular, we introduce total variational distance as an operational
similarity measure, we discover scenarios where normalized nonnegative models
yield unique representations of users and items, we prove that the inference of
optimal normalized nonnegative models is NP-hard and finally, we discuss the
relationship between normalized nonnegative models and nonnegative matrix
factorization.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06722</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of SVN Repositories for Remote Access</dc:title>
 <dc:creator>Sadaf</dc:creator>
 <dc:creator>Soomro, Safeeullah</dc:creator>
 <dc:creator>Abbasi, Suhni</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Software Evolution is considered to be essential and challenging
characteristic in the field of software engineering. Version control system is
an incremental versions tracking system, introduced to avoid unnecessary
overwriting of files such as programming code, web pages and records. It also
helps to decrease the confusion affected by duplicate or outdated data. In this
proposed research SVN repository is maintained and analyzed for
msitone.wikispaces.com to minimize the efforts as well as resources for the
future users. We have used two semester data for the analysis purpose that is
observed SVN repository. The result shows that, implementing the SVN
repositories are helpful for maintenance of the Wikispaces as it also reduce
the cost, time and efforts for their evolution. Whereas without implementing
the SVN repositories Wikispaces were just supposed to be building the house by
putting each brick from start.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06726</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testable Design of Repeaterless Low Swing On-Chip Interconnect</dc:title>
 <dc:creator>Kadayinti, Naveen</dc:creator>
 <dc:creator>Sharma, Dinesh K.</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Repeaterless low swing interconnects use mixed signal circuits to achieve
high performance at low power. When these interconnects are used in large scale
and high volume digital systems their testability becomes very important. This
paper discusses the testability of low swing repeaterless on-chip interconnects
with equalization and clock synchronization. A capacitively coupled transmitter
with a weak driver is used as the transmitter. The receiver samples the low
swing input data at the center of the data eye and converts it to rail to rail
levels and also synchronizes the data to the receiver's clock domain. The
system is a mixed signal circuit and the digital components are all scan
testable. For the analog section, just a DC test has a fault coverage of 50% of
the structural faults. Simple techniques allow integration of the analog
components into the digital scan chain increasing the coverage to 74%. Finally,
a BIST with low overhead enhances the coverage to 95% of the structural faults.
The design and simulations have been done in UMC 130 nm CMOS technology.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06726</dc:identifier>
 <dc:identifier>Proceedings of Design Automation and Test in Europe (DATE) 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06727</identifier>
 <datestamp>2016-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Gradient-Based Tuning of Continuous Regularization
  Hyperparameters</dc:title>
 <dc:creator>Luketina, Jelena</dc:creator>
 <dc:creator>Berglund, Mathias</dc:creator>
 <dc:creator>Greff, Klaus</dc:creator>
 <dc:creator>Raiko, Tapani</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Hyperparameter selection generally relies on running multiple full training
trials, with selection based on validation set performance. We propose a
gradient-based approach for locally adjusting hyperparameters during training
of the model. Hyperparameters are adjusted so as to make the model parameter
gradients, and hence updates, more advantageous for the validation cost. We
explore the approach for tuning regularization hyperparameters and find that in
experiments on MNIST, SVHN and CIFAR-10, the resulting regularization levels
are within the optimal regions. The additional computational cost depends on
how frequently the hyperparameters are trained, but the tested scheme adds only
30% computational overhead regardless of the model size. Since the method is
significantly less computationally demanding compared to similar gradient-based
approaches to hyperparameter optimization, and consistently finds good
hyperparameter values, it can be a useful tool for training neural network
models.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures. Accepted at ICML 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06728</identifier>
 <datestamp>2017-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hand Pose Estimation through Semi-Supervised and Weakly-Supervised
  Learning</dc:title>
 <dc:creator>Neverova, Natalia</dc:creator>
 <dc:creator>Wolf, Christian</dc:creator>
 <dc:creator>Nebout, Florian</dc:creator>
 <dc:creator>Taylor, Graham</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a method for hand pose estimation based on a deep regressor
trained on two different kinds of input. Raw depth data is fused with an
intermediate representation in the form of a segmentation of the hand into
parts. This intermediate representation contains important topological
information and provides useful cues for reasoning about joint locations. The
mapping from raw depth to segmentation maps is learned in a
semi/weakly-supervised way from two different datasets: (i) a synthetic dataset
created through a rendering pipeline including densely labeled ground truth
(pixelwise segmentations); and (ii) a dataset with real images for which ground
truth joint positions are available, but not dense segmentations. Loss for
training on real images is generated from a patch-wise restoration process,
which aligns tentative segmentation maps with a large dictionary of synthetic
poses. The underlying premise is that the domain shift between synthetic and
real data is smaller in the intermediate representation, where labels carry
geometric and topological meaning, than in the raw input domain. Experiments on
the NYU dataset show that the proposed training method decreases error on
joints over direct regression of joints from depth data by 15.7%.
</dc:description>
 <dc:description>Comment: 13 pages, 10 figures, 4 tables</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2017-09-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06729</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple and efficient self-healing strategy for damaged complex networks</dc:title>
 <dc:creator>Gallos, Lazaros K.</dc:creator>
 <dc:creator>Fefferman, Nina H.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The process of destroying a complex network through node removal has been the
subject of extensive interest and research. Node loss typically leaves the
network disintegrated into many small and isolated clusters. Here we show that
these clusters typically remain close to each other and we suggest a simple
algorithm that is able to reverse the inflicted damage by restoring the
network's functionality. After damage, each node decides independently whether
to create a new link depending on the fraction of neighbors it has lost. In
addition to relying only on local information, where nodes do not need
knowledge of the global network status, we impose the additional constraint
that new links should be as short as possible (i.e. that the new edge completes
a shortest possible new cycle). We demonstrate that this self-healing method
operates very efficiently, both in model and real networks. For example, after
removing the most connected airports in USA, the self-healing algorithm
re-joined almost 90\% of the surviving airports.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06729</dc:identifier>
 <dc:identifier>Physical Review E 92, 052806 (2015)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.92.052806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06732</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Level Training with Recurrent Neural Networks</dc:title>
 <dc:creator>Ranzato, Marc'Aurelio</dc:creator>
 <dc:creator>Chopra, Sumit</dc:creator>
 <dc:creator>Auli, Michael</dc:creator>
 <dc:creator>Zaremba, Wojciech</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Many natural language processing applications use language models to generate
text. These models are typically trained to predict the next word in a
sequence, given the previous words and some context such as an image. However,
at test time the model is expected to generate the entire sequence from
scratch. This discrepancy makes generation brittle, as errors may accumulate
along the way. We address this issue by proposing a novel sequence level
training algorithm that directly optimizes the metric used at test time, such
as BLEU or ROUGE. On three different tasks, our approach outperforms several
strong baselines for greedy generation. The method is also competitive when
these baselines employ beam search, while being several times faster.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06735</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Feasibility of 5G-Grade Dedicated RF Charging Technology for
  Wireless-Powered Wearables</dc:title>
 <dc:creator>Galinina, Olga</dc:creator>
 <dc:creator>Tabassum, Hina</dc:creator>
 <dc:creator>Mikhaylov, Konstantin</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  For decades, wireless energy transfer and harvesting remained of focused
attention in the research community, but with limited practical applications.
Recently, with the development of fifth-generation (5G) mobile technology, the
concept of dedicated radio-frequency (RF) charging promises to support the
growing market of wearable devices. In this work, we shed light on the
potential of wireless RF power transfer by elaborating upon feasible system
parameters and architecture, emphasizing the basic trade-offs behind
omni-directional and directional out-of-band energy transmission, providing
system-level performance evaluation, as well as discussing open challenges on
the way to sustainable wireless-powered wearables. The key aspects highlighted
in this article include system operation choices, user mobility effects, impact
of network and user densities, as well as regulatory issues. Ultimately, our
research targets to facilitate the integration of wireless RF charging
technology into the emerging 5G ecosystem.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures, 15 references</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2015-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06739</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superpixel Convolutional Networks using Bilateral Inceptions</dc:title>
 <dc:creator>Gadde, Raghudeep</dc:creator>
 <dc:creator>Jampani, Varun</dc:creator>
 <dc:creator>Kiefel, Martin</dc:creator>
 <dc:creator>Kappler, Daniel</dc:creator>
 <dc:creator>Gehler, Peter V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  In this paper we propose a CNN architecture for semantic image segmentation.
We introduce a new 'bilateral inception' module that can be inserted in
existing CNN architectures and performs bilateral filtering, at multiple
feature-scales, between superpixels in an image. The feature spaces for
bilateral filtering and other parameters of the module are learned end-to-end
using standard backpropagation techniques. The bilateral inception module
addresses two issues that arise with general CNN segmentation architectures.
First, this module propagates information between (super) pixels while
respecting image edges, thus using the structured information of the problem
for improved results. Second, the layer recovers a full resolution segmentation
result from the lower resolution solution of a CNN. In the experiments, we
modify several existing CNN architectures by inserting our inception module
between the last CNN (1x1 convolution) layers. Empirical results on three
different datasets show reliable improvements not only in comparison to the
baseline networks, but also in comparison to several dense-pixel prediction
techniques such as CRFs, while being competitive in time.
</dc:description>
 <dc:description>Comment: European Conference on Computer Vision (ECCV), 2016</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06744</identifier>
 <datestamp>2016-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training CNNs with Low-Rank Filters for Efficient Image Classification</dc:title>
 <dc:creator>Ioannou, Yani</dc:creator>
 <dc:creator>Robertson, Duncan</dc:creator>
 <dc:creator>Shotton, Jamie</dc:creator>
 <dc:creator>Cipolla, Roberto</dc:creator>
 <dc:creator>Criminisi, Antonio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a new method for creating computationally efficient convolutional
neural networks (CNNs) by using low-rank representations of convolutional
filters. Rather than approximating filters in previously-trained networks with
more efficient versions, we learn a set of small basis filters from scratch;
during training, the network learns to combine these basis filters into more
complex filters that are discriminative for image classification. To train such
networks, a novel weight initialization scheme is used. This allows effective
initialization of connection weights in convolutional layers composed of groups
of differently-shaped filters. We validate our approach by applying it to
several existing CNN architectures and training these networks from scratch
using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or
higher accuracy than conventional CNNs with much less compute. Applying our
method to an improved version of VGG-11 network using global max-pooling, we
achieve comparable validation accuracy using 41% less compute and only 24% of
the original VGG-11 model parameters; another variant of our method gives a 1
percentage point increase in accuracy over our improved VGG-11 model, giving a
top-5 center-crop validation accuracy of 89.7% while reducing computation by
16% relative to the original VGG-11 model. Applying our method to the GoogLeNet
architecture for ILSVRC, we achieved comparable accuracy with 26% less compute
and 41% fewer model parameters. Applying our method to a near state-of-the-art
network for CIFAR, we achieved comparable accuracy with 46% less compute and
55% fewer parameters.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016. v3: updated ICLR
  status. v2: Incorporated reviewer's feedback including: Amend Fig. 2 and 5
  descriptions to explain that there are no ReLUs within the figures. Fix
  headings of Table 5 - Fix typo in the sentence at bottom of page 6. Add ref.
  to Predicting Parameters in Deep Learning. Fix Table 6, GMP-LR and GMP-LR-2x
  had incorrect numbers of filters</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06744</dc:identifier>
 <dc:identifier>International Conference on Learning Representations (ICLR), San
  Juan, Puerto Rico, 2-4 May 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06746</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Images Don't Lie: Transferring Deep Visual Semantic Features to
  Large-Scale Multimodal Learning to Rank</dc:title>
 <dc:creator>Lynch, Corey</dc:creator>
 <dc:creator>Aryafar, Kamelia</dc:creator>
 <dc:creator>Attenberg, Josh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Search is at the heart of modern e-commerce. As a result, the task of ranking
search results automatically (learning to rank) is a multibillion dollar
machine learning problem. Traditional models optimize over a few
hand-constructed features based on the item's text. In this paper, we introduce
a multimodal learning to rank model that combines these traditional features
with visual semantic features transferred from a deep convolutional neural
network. In a large scale experiment using data from the online marketplace
Etsy, we verify that moving to a multimodal representation significantly
improves ranking quality. We show how image features can capture fine-grained
style information not available in a text-only representation. In addition, we
show concrete examples of how image information can successfully disentangle
pairs of highly different items that are ranked similarly by a text-only model.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06747</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Dependent Path Normalization in Neural Networks</dc:title>
 <dc:creator>Neyshabur, Behnam</dc:creator>
 <dc:creator>Tomioka, Ryota</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a unified framework for neural net normalization, regularization
and optimization, which includes Path-SGD and Batch-Normalization and
interpolates between them across two different dimensions. Through this
framework we investigate issue of invariance of the optimization, data
dependence and the connection with natural gradients.
</dc:description>
 <dc:description>Comment: 17 pages, 3 figures</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06759</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WLAN Specific IoT Enable Power Efficient RAM Design on 40nm FPGA</dc:title>
 <dc:creator>Kumar, Tanesh</dc:creator>
 <dc:creator>Khan, Faizan</dc:creator>
 <dc:creator>Soomro, Safeeullah</dc:creator>
 <dc:creator>Memon, Areez Khalil</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Increasing the speed of computer is one of the important aspects of the
Random Access Memory (RAM) and for better and fast processing it should be
efficient. In this work, the main focus is to design energy efficient RAM and
it also can be accessed through internet. A 128-bit IPv6 address is added to
the RAM in order to control it via internet. Four different types of Low
Voltage CMOS (LCVMOS) IO standards are used to make it low power under five
different WLAN frequencies is taken. At WLAN frequency 2.4GHz, there is maximum
power reduction of 85% is achieved when LVCMOS12 is taken in place of LVCMOS25.
This design is implemented using Virtex-6 FPGA, Device xc6vlx75t and Package
FF484
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06773</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying and Strengthening Hardness for Dynamic Problems via the Online
  Matrix-Vector Multiplication Conjecture</dc:title>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Krinninger, Sebastian</dc:creator>
 <dc:creator>Nanongkai, Danupon</dc:creator>
 <dc:creator>Saranurak, Thatchaphol</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Consider the following Online Boolean Matrix-Vector Multiplication problem:
We are given an $n\times n$ matrix $M$ and will receive $n$ column-vectors of
size $n$, denoted by $v_1,\ldots,v_n$, one by one. After seeing each vector
$v_i$, we have to output the product $Mv_i$ before we can see the next vector.
A naive algorithm can solve this problem using $O(n^3)$ time in total, and its
running time can be slightly improved to $O(n^3/\log^2 n)$ [Williams SODA'07].
We show that a conjecture that there is no truly subcubic ($O(n^{3-\epsilon})$)
time algorithm for this problem can be used to exhibit the underlying
polynomial time hardness shared by many dynamic problems. For a number of
problems, such as subgraph connectivity, Pagh's problem, $d$-failure
connectivity, decremental single-source shortest paths, and decremental
transitive closure, this conjecture implies tight hardness results. Thus,
proving or disproving this conjecture will be very interesting as it will
either imply several tight unconditional lower bounds or break through a common
barrier that blocks progress with these problems. This conjecture might also be
considered as strong evidence against any further improvement for these
problems since refuting it will imply a major breakthrough for combinatorial
Boolean matrix multiplication and other long-standing problems if the term
&quot;combinatorial algorithms&quot; is interpreted as &quot;non-Strassen-like algorithms&quot;
[Ballard et al. SPAA'11]. The conjecture also leads to hardness results for
problems that were previously based on diverse problems and conjectures, such
as 3SUM, combinatorial Boolean matrix multiplication, triangle detection, and
multiphase, thus providing a uniform way to prove polynomial hardness results
for dynamic algorithms; some of the new proofs are also simpler or even become
trivial. The conjecture also leads to stronger and new, non-trivial, hardness
results.
</dc:description>
 <dc:description>Comment: A preliminary version of this paper was presented at the 47th ACM
  Symposium on Theory of Computing (STOC 2015)</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06773</dc:identifier>
 <dc:identifier>doi:10.1145/2746539.2746609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06783</identifier>
 <datestamp>2016-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognizing Activities of Daily Living with a Wrist-mounted Camera</dc:title>
 <dc:creator>Ohnishi, Katsunori</dc:creator>
 <dc:creator>Kanehira, Atsushi</dc:creator>
 <dc:creator>Kanezaki, Asako</dc:creator>
 <dc:creator>Harada, Tatsuya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel dataset and a novel algorithm for recognizing activities
of daily living (ADL) from a first-person wearable camera. Handled objects are
crucially important for egocentric ADL recognition. For specific examination of
objects related to users' actions separately from other objects in an
environment, many previous works have addressed the detection of handled
objects in images captured from head-mounted and chest-mounted cameras.
Nevertheless, detecting handled objects is not always easy because they tend to
appear small in images. They can be occluded by a user's body. As described
herein, we mount a camera on a user's wrist. A wrist-mounted camera can capture
handled objects at a large scale, and thus it enables us to skip object
detection process. To compare a wrist-mounted camera and a head-mounted camera,
we also develop a novel and publicly available dataset that includes videos and
annotations of daily activities captured simultaneously by both cameras.
Additionally, we propose a discriminative video representation that retains
spatial and temporal information after encoding frame descriptors extracted by
Convolutional Neural Networks (CNN).
</dc:description>
 <dc:description>Comment: CVPR2016 spotlight presentation</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06787</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Model for Web-Intelligence Index to Evaluate the Web Intelligence
  Capacity of Government Web Sites of Sri Lanka</dc:title>
 <dc:creator>Abeysiriwardana, Prabath Chaminda</dc:creator>
 <dc:creator>Kodituwakku, S. R.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Web intelligence can be considered as a subset of Artificial Intelligence. It
uses existing data in web to produce new data, knowledge and wisdom to support
decision making and new predictions for web users. Artificial Intelligence is
ever changing and evolving field of computer science and it is extensively used
in wide array of web based business applications. Although it is used
substantially in web based systems in developed countries, it is not examined
whether it is being substantially used in Sri Lanka. Every Sri Lankan citizen
depends on Public Service more or less throughout his/ her life time and at
least more than 3 times: at birth, marriage and death. So providing most of
these services to its citizen, Sri Lankan Government uses more or less of its
country web portal. This paper presents a model to evaluate web intelligence
capability based on weight to key functionalities with respect to web
intelligence. The government websites were checked by the proposed criteria to
show the potential of using web intelligent technology to provide website based
services. The result indicates that the use of web intelligence techniques
openly and publicly to provide web based services through government web portal
to its citizens is not satisfactory. It also indicates that lack of using the
technologies pertaining to web intelligence in the public service web hinders
the most of the advantages that citizen and government can gain from such
technological involvement.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06787</dc:identifier>
 <dc:identifier>British Journal of Mathematics &amp; Computer Science, 12(6): 1-12,
  2016, Article no.BJMCS.22654, ISSN: 2231-0851</dc:identifier>
 <dc:identifier>doi:10.9734/BJMCS/2016/22654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06789</identifier>
 <datestamp>2016-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Unreasonable Effectiveness of Noisy Data for Fine-Grained
  Recognition</dc:title>
 <dc:creator>Krause, Jonathan</dc:creator>
 <dc:creator>Sapp, Benjamin</dc:creator>
 <dc:creator>Howard, Andrew</dc:creator>
 <dc:creator>Zhou, Howard</dc:creator>
 <dc:creator>Toshev, Alexander</dc:creator>
 <dc:creator>Duerig, Tom</dc:creator>
 <dc:creator>Philbin, James</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Current approaches for fine-grained recognition do the following: First,
recruit experts to annotate a dataset of images, optionally also collecting
more structured data in the form of part annotations and bounding boxes.
Second, train a model utilizing this data. Toward the goal of solving
fine-grained recognition, we introduce an alternative approach, leveraging
free, noisy data from the web and simple, generic methods of recognition. This
approach has benefits in both performance and scalability. We demonstrate its
efficacy on four fine-grained datasets, greatly exceeding existing state of the
art without the manual collection of even a single label, and furthermore show
first results at scaling to more than 10,000 fine-grained categories.
Quantitatively, we achieve top-1 accuracies of 92.3% on CUB-200-2011, 85.4% on
Birdsnap, 93.4% on FGVC-Aircraft, and 80.8% on Stanford Dogs without using
their annotated training sets. We compare our approach to an active learning
approach for expanding fine-grained datasets.
</dc:description>
 <dc:description>Comment: ECCV 2016, data is released</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06795</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Key Exchange Trust Evaluation in Peer-to-Peer Sensor Networks with
  Unconditionally Secure Key Exchange</dc:title>
 <dc:creator>Gonzalez, Elias</dc:creator>
 <dc:creator>Kish, Laszlo B.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  As the utilization of sensor networks continue to increase, the importance of
security becomes more profound. Many industries depend on sensor networks for
critical tasks, and a malicious entity can potentially cause catastrophic
damage. We propose a new key exchange trust evaluation for peer-to-peer sensor
networks, where part of the network has unconditionally secure key exchange.
For a given sensor, the higher the portion of channels with unconditionally
secure key exchange the higher the trust value. We give a brief introduction to
unconditionally secured key exchange concepts and mention current trust
measures in sensor networks. We demonstrate the new key exchange trust measure
on a hypothetical sensor network using both wired and wireless communication
channels.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures, submitted for publication</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06798</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conducting sparse feature selection on arbitrarily long phrases in text
  corpora with a focus on interpretability</dc:title>
 <dc:creator>Miratrix, Luke</dc:creator>
 <dc:creator>Ackerman, Robin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  We propose a general framework for topic-specific summarization of large text
corpora, and illustrate how it can be used for analysis in two quite different
contexts: an OSHA database of fatality and catastrophe reports (to facilitate
surveillance for patterns in circumstances leading to injury or death) and
legal decisions on workers' compensation claims (to explore relevant case law).
Our summarization framework, built on sparse classification methods, is a
compromise between simple word frequency based methods currently in wide use,
and more heavyweight, model-intensive methods such as Latent Dirichlet
Allocation (LDA). For a particular topic of interest (e.g., mental health
disability, or chemical reactions), we regress a labeling of documents onto the
high-dimensional counts of all the other words and phrases in the documents.
The resulting small set of phrases found as predictive are then harvested as
the summary. Using a branch-and-bound approach, this method can be extended to
allow for phrases of arbitrary length, which allows for potentially rich
summarization. We discuss how focus on the purpose of the summaries can inform
choices of regularization parameters and model constraints. We evaluate this
tool by comparing computational time and summary statistics of the resulting
word lists to three other methods in the literature. We also present a new R
package, textreg. Overall, we argue that sparse methods have much to offer text
analysis, and is a branch of research that should be considered further in this
context.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06807</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adding Gradient Noise Improves Learning for Very Deep Networks</dc:title>
 <dc:creator>Neelakantan, Arvind</dc:creator>
 <dc:creator>Vilnis, Luke</dc:creator>
 <dc:creator>Le, Quoc V.</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:creator>Kaiser, Lukasz</dc:creator>
 <dc:creator>Kurach, Karol</dc:creator>
 <dc:creator>Martens, James</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep feedforward and recurrent networks have achieved impressive results in
many perception and language processing applications. This success is partially
attributed to architectural innovations such as convolutional and long
short-term memory networks. The main motivation for these architectural
innovations is that they capture better domain knowledge, and importantly are
easier to optimize than more basic architectures. Recently, more complex
architectures such as Neural Turing Machines and Memory Networks have been
proposed for tasks including question answering and general computation,
creating a new set of optimization challenges. In this paper, we discuss a
low-overhead and easy-to-implement technique of adding gradient noise which we
find to be surprisingly effective when training these very deep architectures.
The technique not only helps to avoid overfitting, but also can result in lower
training loss. This method alone allows a fully-connected 20-layer deep network
to be trained with standard gradient descent, even starting from a poor
initialization. We see consistent improvements for many complex models,
including a 72% relative reduction in error rate over a carefully-tuned
baseline on a challenging question-answering task, and a doubling of the number
of accurate binary multiplication models learned across 7,000 random restarts.
We encourage further application of this technique to additional complex modern
architectures.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06811</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning visual groups from co-occurrences in space and time</dc:title>
 <dc:creator>Isola, Phillip</dc:creator>
 <dc:creator>Zoran, Daniel</dc:creator>
 <dc:creator>Krishnan, Dilip</dc:creator>
 <dc:creator>Adelson, Edward H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a self-supervised framework that learns to group visual entities
based on their rate of co-occurrence in space and time. To model statistical
dependencies between the entities, we set up a simple binary classification
problem in which the goal is to predict if two visual primitives occur in the
same spatial or temporal context. We apply this framework to three domains:
learning patch affinities from spatial adjacency in images, learning frame
affinities from temporal adjacency in videos, and learning photo affinities
from geospatial proximity in image collections. We demonstrate that in each
case the learned affinities uncover meaningful semantic groupings. From patch
affinities we generate object proposals that are competitive with
state-of-the-art supervised methods. From frame affinities we generate movie
scene segmentations that correlate well with DVD chapter structure. Finally,
from geospatial affinities we learn groups that relate well to semantic place
categories.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06815</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Immersive Telepresence System using RGB-D Sensors and Head Mounted
  Display</dc:title>
 <dc:creator>Lu, Xinzhong</dc:creator>
 <dc:creator>Shen, Ju</dc:creator>
 <dc:creator>Perugini, Saverio</dc:creator>
 <dc:creator>Yang, Jianjun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  We present a tele-immersive system that enables people to interact with each
other in a virtual world using body gestures in addition to verbal
communication. Beyond the obvious applications, including general online
conversations and gaming, we hypothesize that our proposed system would be
particularly beneficial to education by offering rich visual contents and
interactivity. One distinct feature is the integration of egocentric pose
recognition that allows participants to use their gestures to demonstrate and
manipulate virtual objects simultaneously. This functionality enables the
instructor to ef- fectively and efficiently explain and illustrate complex
concepts or sophisticated problems in an intuitive manner. The highly
interactive and flexible environment can capture and sustain more student
attention than the traditional classroom setting and, thus, delivers a
compelling experience to the students. Our main focus here is to investigate
possible solutions for the system design and implementation and devise
strategies for fast, efficient computation suitable for visual data processing
and network transmission. We describe the technique and experiments in details
and provide quantitative performance results, demonstrating our system can be
run comfortably and reliably for different application scenarios. Our
preliminary results are promising and demonstrate the potential for more
compelling directions in cyberlearning.
</dc:description>
 <dc:description>Comment: IEEE International Symposium on Multimedia 2015</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06815</dc:identifier>
 <dc:identifier>doi:10.1109/ISM.2015.108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06820</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Comparison of the Summarization Power of Graph Clustering
  Methods</dc:title>
 <dc:creator>Liu, Yike</dc:creator>
 <dc:creator>Shah, Neil</dc:creator>
 <dc:creator>Koutra, Danai</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  How do graph clustering techniques compare with respect to their
summarization power? How well can they summarize a million-node graph with a
few representative structures? Graph clustering or community detection
algorithms can summarize a graph in terms of coherent and tightly connected
clusters. In this paper, we compare and contrast different techniques: METIS,
Louvain, spectral clustering, SlashBurn and KCBC, our proposed k-core-based
clustering method. Unlike prior work that focuses on various measures of
cluster quality, we use vocabulary structures that often appear in real graphs
and the Minimum Description Length (MDL) principle to obtain a graph summary
per clustering method. Our main contributions are: (i) Formulation: We propose
a summarization-based evaluation of clustering methods. Our method,
VOG-OVERLAP, concisely summarizes graphs in terms of their important structures
which lead to small edge overlap, and large node/edge coverage; (ii) Algorithm:
we introduce KCBC, a graph decomposition technique, in the heart of which lies
the k-core algorithm (iii) Evaluation: We compare the summarization power of
five clustering techniques on large real graphs, and analyze their compression
performance, summary statistics and runtimes.
</dc:description>
 <dc:description>Comment: NIPS workshop: Networks in the Social and Information Sciences</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06825</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EMinRET: Heuristic for Energy-Aware VM Placement with Fixed Intervals
  and Non-preemption</dc:title>
 <dc:creator>Quang-Hung, Nguyen</dc:creator>
 <dc:creator>Thoai, Nam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4, F.2, H.4</dc:subject>
 <dc:description>  Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling
users to run applications under virtual machines. This paper investigates the
energy-aware virtual machine (VM) allocation problems in IaaS clouds along
characteristics: multiple resources, and fixed interval times and
non-preemption of virtual machines. Many previous works proposed to use a
minimum number of physical machines, however, this is not necessarily a good
solution to minimize total energy consumption in the VM placement with multiple
resources, fixed interval times and non-preemption. We observed that minimizing
total energy consumption of physical machines is equivalent to minimize the sum
of total completion time of all physical machines. Based on the observation, we
propose EMinRET algorithm. The EMinRET algorithm swaps an allocating VM with a
suitable overlapped VM, which is of the same VM type and is allocated on the
same physical machine, to minimize total completion time of all physical
machines. The EMinRET uses resource utilization during executing time period of
a physical machine as the evaluation metric, and will then choose a host that
minimizes the metric to allocate a new VM. In addition, this work studies some
heuristics for sorting the list of virtual machines (e.g., sorting by the
earliest starting time, or the longest duration time first, etc.) to allocate
VM. Using the realistic log-trace in the Parallel Workloads Archive, our
simulation results show that the EMinRET algorithm could reduce from 25% to 45%
energy consumption compared with power-aware best-fit decreasing (PABFD)) and
vector bin-packing norm-based greedy algorithms. Moreover, the EMinRET
heuristic has also less total energy consumption than our previous heuristics
(e.g. MinDFT and EPOBF) in the simulations (using same virtual machines sorting
method).
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, The International Conference on Advanced
  Computing and Applications (ACOMP)</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06827</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GradNets: Dynamic Interpolation Between Neural Architectures</dc:title>
 <dc:creator>Almeida, Diogo</dc:creator>
 <dc:creator>Sauder, Nate</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In machine learning, there is a fundamental trade-off between ease of
optimization and expressive power. Neural Networks, in particular, have
enormous expressive power and yet are notoriously challenging to train. The
nature of that optimization challenge changes over the course of learning.
Traditionally in deep learning, one makes a static trade-off between the needs
of early and late optimization. In this paper, we investigate a novel
framework, GradNets, for dynamically adapting architectures during training to
get the benefits of both. For example, we can gradually transition from linear
to non-linear networks, deterministic to stochastic computation, shallow to
deep architectures, or even simple downsampling to fully differentiable
attention mechanisms. Benefits include increased accuracy, easier convergence
with more complex architectures, solutions to test-time execution of batch
normalization, and the ability to train networks of up to 200 layers.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06828</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Valued Khatri-Rao Subspace Approaches on the ULA and a New Nested
  Array</dc:title>
 <dc:creator>Duan, Huiping</dc:creator>
 <dc:creator>Tuo, Tiantian</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Zeng, Bing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In underdetermined direction-of-arrival (DOA) estimation using the
covariance-based signal models, the computational complexity turns into a
noticeable issue because of the high dimension of the virtual array manifold.
In this paper, real-valued Khatri-Rao (KR) approaches are developed on the
uniform linear array (ULA) and the nested array. The complexities of subspace
decomposition and spectral search are reduced compared with the complex-valued
KR approach. By designing a special transformation matrix, the influence of the
noise is removed in the mean time while the data is transformed from the
complex domain to the real domain. Deploying the sensors with nonuniform
spacings can raise the degree of freedom (DOF) and hence help detect more
sources in the underdetermined situation. To increase the DOF further, a new
nested array geometry is designed. The real-valued denoising KR approach
developed on the new nested array can resolve more sources with reduced
complexities. The performance improvement is demonstrated by numerical studies.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06830</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ground-truth dataset and baseline evaluations for image base-detail
  separation algorithms</dc:title>
 <dc:creator>Dong, Xuan</dc:creator>
 <dc:creator>Bonev, Boyan</dc:creator>
 <dc:creator>Li, Weixin</dc:creator>
 <dc:creator>Qiu, Weichao</dc:creator>
 <dc:creator>Chen, Xianjie</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Base-detail separation is a fundamental computer vision problem consisting of
modeling a smooth base layer with the coarse structures, and a detail layer
containing the texture-like structures. One of the challenges of estimating the
base is to preserve sharp boundaries between objects or parts to avoid halo
artifacts. Many methods have been proposed to address this problem, but there
is no ground-truth dataset of real images for quantitative evaluation. We
proposed a procedure to construct such a dataset, and provide two datasets:
Pascal Base-Detail and Fashionista Base-Detail, containing 1000 and 250 images,
respectively. Our assumption is that the base is piecewise smooth and we label
the appearance of each piece by a polynomial model. The pieces are objects and
parts of objects, obtained from human annotations. Finally, we proposed a way
to evaluate methods with our base-detail ground-truth and we compared the
performances of seven state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to some un-proper
  examples</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:date>2016-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06833</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Bootstrapping approach for Named Entity Recognition</dc:title>
 <dc:creator>Thenmalar, S.</dc:creator>
 <dc:creator>Balaji, J.</dc:creator>
 <dc:creator>Geetha, T. V.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The aim of Named Entity Recognition (NER) is to identify references of named
entities in unstructured documents, and to classify them into pre-defined
semantic categories. NER often aids from added background knowledge in the form
of gazetteers. However using such a collection does not deal with name variants
and cannot resolve ambiguities associated in identifying the entities in
context and associating them with predefined categories. We present a
semi-supervised NER approach that starts with identifying named entities with a
small set of training data. Using the identified named entities, the word and
the context features are used to define the pattern. This pattern of each named
entity category is used as a seed pattern to identify the named entities in the
test set. Pattern scoring and tuple value score enables the generation of the
new patterns to identify the named entity categories. We have evaluated the
proposed system for English language with the dataset of tagged (IEER) and
untagged (CoNLL 2003) named entity corpus and for Tamil language with the
documents from the FIRE corpus and yield an average f-measure of 75% for both
the languages.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures, 5 tables</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06834</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fidelity-Naturalness Evaluation of Single Image Super Resolution</dc:title>
 <dc:creator>Dong, Xuan</dc:creator>
 <dc:creator>Zhu, Yu</dc:creator>
 <dc:creator>Li, Weixin</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Wong, Alex</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We study the problem of evaluating super resolution methods. Traditional
evaluation methods usually judge the quality of super resolved images based on
a single measure of their difference with the original high resolution images.
In this paper, we proposed to use both fidelity (the difference with original
images) and naturalness (human visual perception of super resolved images) for
evaluation. For fidelity evaluation, a new metric is proposed to solve the bias
problem of traditional evaluation. For naturalness evaluation, we let humans
label preference of super resolution results using pair-wise comparison, and
test the correlation between human labeling results and image quality
assessment metrics' outputs. Experimental results show that our
fidelity-naturalness method is better than the traditional evaluation method
for super resolution methods, which could help future research on single-image
super resolution.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06838</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural
  Nets</dc:title>
 <dc:creator>Narihira, Takuya</dc:creator>
 <dc:creator>Borth, Damian</dc:creator>
 <dc:creator>Yu, Stella X.</dc:creator>
 <dc:creator>Ni, Karl</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We consider the visual sentiment task of mapping an image to an adjective
noun pair (ANP) such as &quot;cute baby&quot;. To capture the two-factor structure of our
ANP semantics as well as to overcome annotation noise and ambiguity, we propose
a novel factorized CNN model which learns separate representations for
adjectives and nouns but optimizes the classification performance over their
product. Our experiments on the publicly available SentiBank dataset show that
our model significantly outperforms not only independent ANP classifiers on
unseen ANPs and on retrieving images of novel ANPs, but also image captioning
models which capture word semantics from co-occurrence of natural text; the
latter turn out to be surprisingly poor at capturing the sentiment evoked by
pure visual experience. That is, our factorized ANP CNN not only trains better
from noisy labels, generalizes better to new images, but can also expands the
ANP vocabulary on its own.
</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06841</identifier>
 <datestamp>2017-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Sequence Training of Recurrent Neural Networks with Connectionist
  Temporal Classification</dc:title>
 <dc:creator>Hwang, Kyuyeon</dc:creator>
 <dc:creator>Sung, Wonyong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Connectionist temporal classification (CTC) based supervised sequence
training of recurrent neural networks (RNNs) has shown great success in many
machine learning areas including end-to-end speech and handwritten character
recognition. For the CTC training, however, it is required to unroll (or
unfold) the RNN by the length of an input sequence. This unrolling requires a
lot of memory and hinders a small footprint implementation of online learning
or adaptation. Furthermore, the length of training sequences is usually not
uniform, which makes parallel training with multiple sequences inefficient on
shared memory models such as graphics processing units (GPUs). In this work, we
introduce an expectation-maximization (EM) based online CTC algorithm that
enables unidirectional RNNs to learn sequences that are longer than the amount
of unrolling. The RNNs can also be trained to process an infinitely long input
sequence without pre-segmentation or external reset. Moreover, the proposed
approach allows efficient parallel training on GPUs. For evaluation, phoneme
recognition and end-to-end speech recognition examples are presented on the
TIMIT and Wall Street Journal (WSJ) corpora, respectively. Our online model
achieves 20.7% phoneme error rate (PER) on the very long input sequence that is
generated by concatenating all 192 utterances in the TIMIT core test set. On
WSJ, a network can be trained with only 64 times of unrolling while sacrificing
4.5% relative word error rate (WER).
</dc:description>
 <dc:description>Comment: Final version: Kyuyeon Hwang and Wonyong Sung, &quot;Sequence to Sequence
  Training of CTC-RNNs with Partial Windowing,&quot; Proceedings of The 33rd
  International Conference on Machine Learning, pp. 2178-2187, 2016. URL:
  http://www.jmlr.org/proceedings/papers/v48/hwanga16.html</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2017-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06852</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A universal data based method for reconstructing complex networks with
  binary-state dynamics</dc:title>
 <dc:creator>Li, Jingwen</dc:creator>
 <dc:creator>Shen, Zhesi</dc:creator>
 <dc:creator>Wang, Wen-Xu</dc:creator>
 <dc:creator>Grebogi, Celso</dc:creator>
 <dc:creator>Lai, Ying-Cheng</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  To understand, predict, and control complex networked systems, a prerequisite
is to reconstruct the network structure from observable data. Despite recent
progress in network reconstruction, binary-state dynamics that are ubiquitous
in nature, technology and society still present an outstanding challenge in
this field. Here we offer a framework for reconstructing complex networks with
binary-state dynamics by developing a universal data-based linearization
approach that is applicable to systems with linear, nonlinear, discontinuous,
or stochastic dynamics governed by monotonous functions. The linearization
procedure enables us to convert the network reconstruction into a sparse signal
reconstruction problem that can be resolved through convex optimization. We
demonstrate generally high reconstruction accuracy for a number of complex
networks associated with distinct binary-state dynamics from using binary data
contaminated by noise and missing data. Our framework is completely data
driven, efficient and robust, and does not require any a priori knowledge about
the detailed dynamical process on the network. The framework represents a
general paradigm for reconstructing, understanding, and exploiting complex
networked systems with binary-state dynamics.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06852</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 032303 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.032303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06853</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TransCut: Transparent Object Segmentation from a Light-Field Image</dc:title>
 <dc:creator>Xu, Yichao</dc:creator>
 <dc:creator>Nagahara, Hajime</dc:creator>
 <dc:creator>Shimada, Atsushi</dc:creator>
 <dc:creator>Taniguchi, Rin-ichiro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The segmentation of transparent objects can be very useful in computer vision
applications. However, because they borrow texture from their background and
have a similar appearance to their surroundings, transparent objects are not
handled well by regular image segmentation methods. We propose a method that
overcomes these problems using the consistency and distortion properties of a
light-field image. Graph-cut optimization is applied for the pixel labeling
problem. The light-field linearity is used to estimate the likelihood of a
pixel belonging to the transparent object or Lambertian background, and the
occlusion detector is used to find the occlusion boundary. We acquire a light
field dataset for the transparent object, and use this dataset to evaluate our
method. The results demonstrate that the proposed method successfully segments
transparent objects from the background.
</dc:description>
 <dc:description>Comment: 9 pages, 14 figures, 2 tables, ICCV 2015</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06855</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised learning of object semantic parts from internal states of
  CNNs by population encoding</dc:title>
 <dc:creator>Wang, Jianyu</dc:creator>
 <dc:creator>Zhang, Zhishuai</dc:creator>
 <dc:creator>Xie, Cihang</dc:creator>
 <dc:creator>Premachandran, Vittal</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the key question of how object part representations can be found
from the internal states of CNNs that are trained for high-level tasks, such as
object classification. This work provides a new unsupervised method to learn
semantic parts and gives new understanding of the internal representations of
CNNs. Our technique is based on the hypothesis that semantic parts are
represented by populations of neurons rather than by single filters. We propose
a clustering technique to extract part representations, which we call Visual
Concepts. We show that visual concepts are semantically coherent in that they
represent semantic parts, and visually coherent in that corresponding image
patches appear very similar. Also, visual concepts provide full spatial
coverage of the parts of an object, rather than a few sparse parts as is
typically found in keypoint annotations. Furthermore, We treat single visual
concept as part detector and evaluate it for keypoint detection using the
PASCAL3D+ dataset and for part detection using our newly annotated ImageNetPart
dataset. The experiments demonstrate that visual concepts can be used to detect
parts. We also show that some visual concepts respond to several semantic
parts, provided these parts are visually similar. Thus visual concepts have the
essential properties: semantic meaning and detection capability. Note that our
ImageNetPart dataset gives rich part annotations which cover the whole object,
making it useful for other part-related applications.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06856</identifier>
 <datestamp>2016-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-dependent Initializations of Convolutional Neural Networks</dc:title>
 <dc:creator>Kr&#xe4;henb&#xfc;hl, Philipp</dc:creator>
 <dc:creator>Doersch, Carl</dc:creator>
 <dc:creator>Donahue, Jeff</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional Neural Networks spread through computer vision like a wildfire,
impacting almost all visual tasks imaginable. Despite this, few researchers
dare to train their models from scratch. Most work builds on one of a handful
of ImageNet pre-trained models, and fine-tunes or adapts these for specific
tasks. This is in large part due to the difficulty of properly initializing
these networks from scratch. A small miscalibration of the initial weights
leads to vanishing or exploding gradients, as well as poor convergence
properties. In this work we present a fast and simple data-dependent
initialization procedure, that sets the weights of a network such that all
units in the network train at roughly the same rate, avoiding vanishing or
exploding gradients. Our initialization matches the current state-of-the-art
unsupervised or self-supervised pre-training methods on standard computer
vision tasks, such as image classification and object detection, while being
roughly three orders of magnitude faster. When combined with pre-training
methods, our initialization significantly outperforms prior work, narrowing the
gap between supervised and unsupervised pre-training.
</dc:description>
 <dc:description>Comment: ICLR 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06858</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applying Social Media Intelligence for Predicting and Identifying
  On-line Radicalization and Civil Unrest Oriented Threats</dc:title>
 <dc:creator>Agarwal, Swati</dc:creator>
 <dc:creator>Sureka, Ashish</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Research shows that various social media platforms on Internet such as
Twitter, Tumblr (micro-blogging websites), Facebook (a popular social
networking website), YouTube (largest video sharing and hosting website), Blogs
and discussion forums are being misused by extremist groups for spreading their
beliefs and ideologies, promoting radicalization, recruiting members and
creating online virtual communities sharing a common agenda. Popular
microblogging websites such as Twitter are being used as a real-time platform
for information sharing and communication during planning and mobilization if
civil unrest related events. Applying social media intelligence for predicting
and identifying online radicalization and civil unrest oriented threats is an
area that has attracted several researchers' attention over past 10 years.
There are several algorithms, techniques and tools that have been proposed in
existing literature to counter and combat cyber-extremism and predicting
protest related events in much advance. In this paper, we conduct a literature
review of all these existing techniques and do a comprehensive analysis to
understand state-of-the-art, trends and research gaps. We present a one class
classification approach to collect scholarly articles targeting the topics and
subtopics of our research scope. We perform characterization, classification
and an in-depth meta analysis meta-anlaysis of about 100 conference and journal
papers to gain a better understanding of existing literature.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures, 4 tables. This paper is a comprehensive and
  detailed literature survey to understand current state-of-the-art of Online
  Social Media Intelligence to counter and combat ISI related threats</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06860</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Sparse Spectral Clustering: Single-view to Multi-view</dc:title>
 <dc:creator>Lu, Canyi</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Spectral Clustering (SC) is one of the most widely used methods for data
clustering. It first finds a low-dimensonal embedding $\U$ of data by computing
the eigenvectors of the normalized Laplacian matrix, and then performs k-means
on $\U^\top$ to get the final clustering result. In this work, we observe that,
in the ideal case, $\U\U^\top$ should be block diagonal and thus sparse.
Therefore we propose the Sparse Spectral Clustering (SSC) method which extends
SC with sparse regularization on $\U\U^\top$. To address the computational
issue of the nonconvex SSC model, we propose a novel convex relaxation of SSC
based on the convex hull of the fixed rank projection matrices. Then the convex
SSC model can be efficiently solved by the Alternating Direction Method of
\canyi{Multipliers} (ADMM). Furthermore, we propose the Pairwise Sparse
Spectral Clustering (PSSC) which extends SSC to boost the clustering
performance by using the multi-view information of data. Experimental
comparisons with several baselines on real-world datasets testify to the
efficacy of our proposed methods.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06860</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2553459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06866</identifier>
 <datestamp>2017-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feedback Capacity of Gaussian Channels Revisited</dc:title>
 <dc:creator>Gattami, Ather</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we revisit the problem of finding the average capacity of the
Gaussian feedback channel. First, we consider the problem of finding the
average capacity of the analog colored Gaussian noise channel where the noise
has an arbitrary spectral density. We introduce a new approach to the problem
where we solve the problem over a finite number of transmissions and then
consider the limit of the average capacity of the case of infinite number of
transmissions. We then consider the important special case of stationary
Gaussian noise with finite memory. We show that the channel capacity at
stationarity can be found by solving a semi-definite program, and hence
computationally tractable. We also give new proofs and structural results of
the non stationary solution which bridges the gap between results in the
literature for the stationary and non stationary feedback channel capacity.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2017-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06881</identifier>
 <datestamp>2016-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zoom Better to See Clearer: Human and Object Parsing with Hierarchical
  Auto-Zoom Net</dc:title>
 <dc:creator>Xia, Fangting</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Chen, Liang-Chieh</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Parsing articulated objects, e.g. humans and animals, into semantic parts
(e.g. body, head and arms, etc.) from natural images is a challenging and
fundamental problem for computer vision. A big difficulty is the large
variability of scale and location for objects and their corresponding parts.
Even limited mistakes in estimating scale and location will degrade the parsing
output and cause errors in boundary details. To tackle these difficulties, we
propose a &quot;Hierarchical Auto-Zoom Net&quot; (HAZN) for object part parsing which
adapts to the local scales of objects and parts. HAZN is a sequence of two
&quot;Auto-Zoom Net&quot; (AZNs), each employing fully convolutional networks that
perform two tasks: (1) predict the locations and scales of object instances
(the first AZN) or their parts (the second AZN); (2) estimate the part scores
for predicted object instance or part regions. Our model can adaptively &quot;zoom&quot;
(resize) predicted image regions into their proper scales to refine the
parsing.
  We conduct extensive experiments over the PASCAL part datasets on humans,
horses, and cows. For humans, our approach significantly outperforms the
state-of-the-arts by 5% mIOU and is especially better at segmenting small
instances and small parts. We obtain similar improvements for parsing cows and
horses over alternative methods. In summary, our strategy of first zooming into
objects and then zooming into parts is very effective. It also enables us to
process different regions of the image at different scales adaptively so that,
for example, we do not need to waste computational resources scaling the entire
image.
</dc:description>
 <dc:description>Comment: A shortened version has been submitted to ECCV 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06888</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Topology Adaptation and Interference Coordination for Energy
  Saving in Heterogeneous Networks</dc:title>
 <dc:creator>Kuang, Quan</dc:creator>
 <dc:creator>Yu, Xiangbin</dc:creator>
 <dc:creator>Utschick, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Interference coupling in heterogeneous networks introduces the inherent
non-convexity to the network resource optimization problem, hindering the
development of effective solutions. A new framework based on multi-pattern
formulation has been proposed in this paper to study the energy efficient
strategy for joint cell activation, user association and multicell multiuser
channel allocation. One key feature of this interference pattern formulation is
that the patterns remain fixed and independent of the optimization process.
This creates a favorable opportunity for a linear programming formulation while
still taking interference coupling into account. A tailored algorithm is
developed to solve the formulated network energy saving problem in the dual
domain by exploiting the problem structure, which gives a significant
complexity saving compared to using standard solvers. Numerical results show a
huge improvement in energy saving achieved by the proposed scheme.
</dc:description>
 <dc:description>Comment: accepted to 41st IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP 2016). This version includes the proof of
  Proposition 1</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06888</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2016.7472346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06890</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaussian Process Planning with Lipschitz Continuous Reward Functions:
  Towards Unifying Bayesian Optimization, Active Learning, and Beyond</dc:title>
 <dc:creator>Ling, Chun Kai</dc:creator>
 <dc:creator>Low, Kian Hsiang</dc:creator>
 <dc:creator>Jaillet, Patrick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a novel nonmyopic adaptive Gaussian process planning
(GPP) framework endowed with a general class of Lipschitz continuous reward
functions that can unify some active learning/sensing and Bayesian optimization
criteria and offer practitioners some flexibility to specify their desired
choices for defining new tasks/problems. In particular, it utilizes a
principled Bayesian sequential decision problem framework for jointly and
naturally optimizing the exploration-exploitation trade-off. In general, the
resulting induced GPP policy cannot be derived exactly due to an uncountable
set of candidate observations. A key contribution of our work here thus lies in
exploiting the Lipschitz continuity of the reward functions to solve for a
nonmyopic adaptive epsilon-optimal GPP (epsilon-GPP) policy. To plan in real
time, we further propose an asymptotically optimal, branch-and-bound anytime
variant of epsilon-GPP with performance guarantee. We empirically demonstrate
the effectiveness of our epsilon-GPP policy and its anytime variant in Bayesian
optimization and an energy harvesting task.
</dc:description>
 <dc:description>Comment: 30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended
  version with proofs, 17 pages</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06891</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Active Learning of Multi-Output Gaussian Processes</dc:title>
 <dc:creator>Zhang, Yehong</dc:creator>
 <dc:creator>Hoang, Trong Nghia</dc:creator>
 <dc:creator>Low, Kian Hsiang</dc:creator>
 <dc:creator>Kankanhalli, Mohan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper addresses the problem of active learning of a multi-output
Gaussian process (MOGP) model representing multiple types of coexisting
correlated environmental phenomena. In contrast to existing works, our active
learning problem involves selecting not just the most informative sampling
locations to be observed but also the types of measurements at each selected
location for minimizing the predictive uncertainty (i.e., posterior joint
entropy) of a target phenomenon of interest given a sampling budget.
Unfortunately, such an entropy criterion scales poorly in the numbers of
candidate sampling locations and selected observations when optimized. To
resolve this issue, we first exploit a structure common to sparse MOGP models
for deriving a novel active learning criterion. Then, we exploit a relaxed form
of submodularity property of our new criterion for devising a polynomial-time
approximation algorithm that guarantees a constant-factor approximation of that
achieved by the optimal set of selected observations. Empirical evaluation on
real-world datasets shows that our proposed approach outperforms existing
algorithms for active learning of MOGP and single-output GP models.
</dc:description>
 <dc:description>Comment: 30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended
  version with proofs, 13 pages</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06892</identifier>
 <datestamp>2016-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum approach to Bertrand duopoly</dc:title>
 <dc:creator>Frackiewicz, Piotr</dc:creator>
 <dc:creator>Sladkowski, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The aim of the paper is to study the Bertrand duopoly example in the quantum
domain. We use two ways to write the game in terms of quantum theory. The first
one adapts the Li-Du-Massar scheme for the Cournot duopoly. The second one is a
simplified model that exploits a two qubit entangled state. In both cases we
focus on finding Nash equilibria in the resulting games.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06905</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Algorithm For Replacement Paths Problem</dc:title>
 <dc:creator>Kare, Anjeneya Swami</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Let G=(V,E)(|V|=n and |E|=m) be an undirected graph with positive edge
weights. Let P_{G}(s, t) be a shortest s-t path in G. Let l be the number of
edges in P_{G}(s, t). The \emph{Edge Replacement Path} problem is to compute a
shortest s-t path in G\{e}, for every edge e in P_{G}(s, t). The \emph{Node
Replacement Path} problem is to compute a shortest s-t path in G\{v}, for every
vertex v in P_{G}(s, t). In this paper we present an O(T_{SPT}(G)+m+l^2) time
and O(m+l^2) space algorithm for both the problems. Where, T_{SPT}(G) is the
asymptotic time to compute a single source shortest path tree in G. The
proposed algorithm is simple and easy to implement.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06905</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06909</identifier>
 <datestamp>2016-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BlackOut: Speeding up Recurrent Neural Network Language Models With Very
  Large Vocabularies</dc:title>
 <dc:creator>Ji, Shihao</dc:creator>
 <dc:creator>Vishwanathan, S. V. N.</dc:creator>
 <dc:creator>Satish, Nadathur</dc:creator>
 <dc:creator>Anderson, Michael J.</dc:creator>
 <dc:creator>Dubey, Pradeep</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose BlackOut, an approximation algorithm to efficiently train massive
recurrent neural network language models (RNNLMs) with million word
vocabularies. BlackOut is motivated by using a discriminative loss, and we
describe a new sampling strategy which significantly reduces computation while
improving stability, sample efficiency, and rate of convergence. One way to
understand BlackOut is to view it as an extension of the DropOut strategy to
the output layer, wherein we use a discriminative training loss and a weighted
sampling scheme. We also establish close connections between BlackOut,
importance sampling, and noise contrastive estimation (NCE). Our experiments,
on the recently released one billion word language modeling benchmark,
demonstrate scalability and accuracy of BlackOut; we outperform the
state-of-the art, and achieve the lowest perplexity scores on this dataset.
Moreover, unlike other established methods which typically require GPUs or CPU
clusters, we show that a carefully implemented version of BlackOut requires
only 1-10 days on a single machine to train a RNNLM with a million word
vocabulary and billions of parameters on one billion words. Although we
describe BlackOut in the context of RNNLM training, it can be used to any
networks with large softmax output layers.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06909</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06910</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ICU Patient Deterioration prediction: a Data-Mining Approach</dc:title>
 <dc:creator>AlNuaimi, Noura</dc:creator>
 <dc:creator>Masud, Mohammad M</dc:creator>
 <dc:creator>Mohammed, Farhan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A huge amount of medical data is generated every day, which presents a
challenge in analysing these data. The obvious solution to this challenge is to
reduce the amount of data without information loss. Dimension reduction is
considered the most popular approach for reducing data size and also to reduce
noise and redundancies in data. In this paper, we investigate the effect of
feature selection in improving the prediction of patient deterioration in ICUs.
We consider lab tests as features. Thus, choosing a subset of features would
mean choosing the most important lab tests to perform. If the number of tests
can be reduced by identifying the most important tests, then we could also
identify the redundant tests. By omitting the redundant tests, observation time
could be reduced and early treatment could be provided to avoid the risk.
Additionally, unnecessary monetary cost would be avoided. Our approach uses
state-ofthe- art feature selection for predicting ICU patient deterioration
using the medical lab results. We apply our technique on the publicly available
MIMIC-II database and show the effectiveness of the feature selection. We also
provide a detailed analysis of the best features identified by our approach.
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures, 10 tables, confeence</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06910</dc:identifier>
 <dc:identifier>doi:10.5121/csit.2015.51517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06911</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Screen Content Image Segmentation Using Sparse-Smooth Decomposition</dc:title>
 <dc:creator>Minaee, Shervin</dc:creator>
 <dc:creator>Abdolrashidi, Amirali</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse decomposition has been extensively used for different applications
including signal compression and denoising and document analysis. In this
paper, sparse decomposition is used for image segmentation. The proposed
algorithm separates the background and foreground using a sparse-smooth
decomposition technique such that the smooth and sparse components correspond
to the background and foreground respectively. This algorithm is tested on
several test images from HEVC test sequences and is shown to have superior
performance over other methods, such as the hierarchical k-means clustering in
DjVu. This segmentation algorithm can also be used for text extraction, video
compression and medical image segmentation.
</dc:description>
 <dc:description>Comment: Asilomar Conference on Signals, Systems and Computers, IEEE, 2015,
  (to Appear)</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06911</dc:identifier>
 <dc:identifier>doi:10.1109/ACSSC.2015.7421331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06915</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Countering Social Engineering through Social Media: An Enterprise
  Security Perspective</dc:title>
 <dc:creator>Wilcox, H.</dc:creator>
 <dc:creator>Bhattacharya, Maumita</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68-06</dc:subject>
 <dc:description>  The increasing threat of social engineers targeting social media channels to
advance their attack effectiveness on company data has seen many organizations
introducing initiatives to better understand these vulnerabilities. This paper
examines concerns of social engineering through social media within the
enterprise and explores countermeasures undertaken to stem ensuing risk. Also
included is an analysis of existing social media security policies and
guidelines within the public and private sectors.
</dc:description>
 <dc:description>Comment: Proceedings of The 7th International Conference on Computational
  Collective Intelligence Technologies and Applications (ICCCI 2015), LNAI,
  Springer, Vol. 9330, pp. 54-64</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06918</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ironing in the Dark</dc:title>
 <dc:creator>Roughgarden, Tim</dc:creator>
 <dc:creator>Schrijvers, Okke</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper presents the first polynomial-time algorithm for position and
matroid auction environments that learns, from samples from an unknown bounded
valuation distribution, an auction with expected revenue arbitrarily close to
the maximum possible. In contrast to most previous work, our results apply to
arbitrary (not necessarily regular) distributions and the strongest possible
benchmark, the Myerson-optimal auction. Learning a near-optimal auction for an
irregular distribution is technically challenging because it requires learning
the appropriate &quot;ironed intervals,&quot; a delicate global property of the
distribution.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06919</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Segmentation of Colon Glands with Deep Convolutional Neural
  Networks and Total Variation Segmentation</dc:title>
 <dc:creator>Kainz, Philipp</dc:creator>
 <dc:creator>Pfeiffer, Michael</dc:creator>
 <dc:creator>Urschler, Martin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation of histopathology sections is an ubiquitous requirement in
digital pathology and due to the large variability of biological tissue,
machine learning techniques have shown superior performance over standard image
processing methods. As part of the GlaS@MICCAI2015 colon gland segmentation
challenge, we present a learning-based algorithm to segment glands in tissue of
benign and malignant colorectal cancer. Images are preprocessed according to
the Hematoxylin-Eosin staining protocol and two deep convolutional neural
networks (CNN) are trained as pixel classifiers. The CNN predictions are then
regularized using a figure-ground segmentation based on weighted total
variation to produce the final segmentation result. On two test sets, our
approach achieves a tissue classification accuracy of 98% and 94%, making use
of the inherent capability of our system to distinguish between benign and
malignant tissue.
</dc:description>
 <dc:description>Comment: An extended version of this work has been published in PeerJ
  (https://doi.org/10.7717/peerj.3874), so please cite our journal version
  instead of this preprint</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2017-10-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06931</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems</dc:title>
 <dc:creator>Dodge, Jesse</dc:creator>
 <dc:creator>Gane, Andreea</dc:creator>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:creator>Bordes, Antoine</dc:creator>
 <dc:creator>Chopra, Sumit</dc:creator>
 <dc:creator>Miller, Alexander</dc:creator>
 <dc:creator>Szlam, Arthur</dc:creator>
 <dc:creator>Weston, Jason</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A long-term goal of machine learning is to build intelligent conversational
agents. One recent popular approach is to train end-to-end models on a large
amount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals
&amp; Le, 2015; Shang et al., 2015). However, this approach leaves many questions
unanswered as an understanding of the precise successes and shortcomings of
each model is hard to assess. A contrasting recent proposal are the bAbI tasks
(Weston et al., 2015b) which are synthetic data that measure the ability of
learning machines at various reasoning tasks over toy language. Unfortunately,
those tests are very small and hence may encourage methods that do not scale.
In this work, we propose a suite of new tasks of a much larger scale that
attempt to bridge the gap between the two regimes. Choosing the domain of
movies, we provide tasks that test the ability of models to answer factual
questions (utilizing OMDB), provide personalization (utilizing MovieLens),
carry short conversations about the two, and finally to perform on natural
dialogs from Reddit. We provide a dataset covering 75k movie entities and with
3.5M training examples. We present results of various models on these tasks,
and evaluate their performance.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06936</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Anomaly Detection and Localization in Crowded Scenes</dc:title>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:creator>Fathy, Mahmood</dc:creator>
 <dc:creator>Hosseini, Mojtaba</dc:creator>
 <dc:creator>Klette, Reinhard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a method for real-time anomaly detection and
localization in crowded scenes. Each video is defined as a set of
non-overlapping cubic patches, and is described using two local and global
descriptors. These descriptors capture the video properties from different
aspects. By incorporating simple and cost-effective Gaussian classifiers, we
can distinguish normal activities and anomalies in videos. The local and global
features are based on structure similarity between adjacent patches and the
features learned in an unsupervised way, using a sparse auto- encoder.
Experimental results show that our algorithm is comparable to a
state-of-the-art procedure on UCSD ped2 and UMN benchmarks, but even more
time-efficient. The experiments confirm that our system can reliably detect and
localize anomalies as soon as they happen in a video.
</dc:description>
 <dc:description>Comment: CVPRw 2015</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06938</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>28 GHz Millimeter-Wave Ultrawideband Small-Scale Fading Models in
  Wireless Channels</dc:title>
 <dc:creator>Samimi, Mathew K.</dc:creator>
 <dc:creator>MacCartney, Jr., George R.</dc:creator>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents small-scale fading measurements for 28 GHz outdoor
millimeter-wave ultrawideband channels using directional horn antennas at the
transmitter and receiver. Power delay profiles were measured at half-wavelength
spatial increments over a local area (33 wavelengths) on a linear track in two
orthogonal receiver directions in a typical base-to-mobile scenario with fixed
transmitter and receiver antenna beam pointing directions. The voltage path
amplitudes are shown to follow a Rician distribution, with K-factor ranging
from 9 - 15 dB and 5 - 8 dB in line of sight (LOS) and non-line of sight (NLOS)
for a vertical-to-vertical co-polarized antenna scenario, respectively, and
from 3 - 7 dB in both LOS and NLOS vertical-to-horizontal cross-polarized
antenna scenario. The average spatial autocorrelation functions of individual
multipath components reveal that signal amplitudes reach a correlation of 0
after 2 and 5 wavelengths in LOS and NLOS co-polarized V-V antenna scenarios.
The models provided are useful for recreating path gain statistics of
millimeter-wave wideband channel impulse responses over local areas, for the
study of multi-element antenna simulations and channel estimation algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures, to be published in the 2016 IEEE Vehicular
  Technology Conference (VTC2016-Spring), 15-18 May, 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06938</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2016.7503970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06939</identifier>
 <datestamp>2016-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Session-based Recommendations with Recurrent Neural Networks</dc:title>
 <dc:creator>Hidasi, Bal&#xe1;zs</dc:creator>
 <dc:creator>Karatzoglou, Alexandros</dc:creator>
 <dc:creator>Baltrunas, Linas</dc:creator>
 <dc:creator>Tikk, Domonkos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We apply recurrent neural networks (RNN) on a new domain, namely recommender
systems. Real-life recommender systems often face the problem of having to base
recommendations only on short session-based data (e.g. a small sportsware
website) instead of long user histories (as in the case of Netflix). In this
situation the frequently praised matrix factorization approaches are not
accurate. This problem is usually overcome in practice by resorting to
item-to-item recommendations, i.e. recommending similar items. We argue that by
modeling the whole session, more accurate recommendations can be provided. We
therefore propose an RNN-based approach for session-based recommendations. Our
approach also considers practical aspects of the task and introduces several
modifications to classic RNNs such as a ranking loss function that make it more
viable for this specific problem. Experimental results on two data-sets show
marked improvements over widely used approaches.
</dc:description>
 <dc:description>Comment: Camera ready version (17th February, 2016) Affiliation update (29th
  March, 2016)</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06940</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIMO Channel Modeling and Capacity Analysis for 5G Millimeter-Wave
  Wireless Systems</dc:title>
 <dc:creator>Samimi, Mathew K.</dc:creator>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents a 3-D statistical channel model of the impulse response
with small-scale spatially correlated random coefficients for multi-element
transmitter and receiver antenna arrays, derived using the physically-based
time cluster - spatial lobe (TCSL) clustering scheme. The small-scale
properties of multipath amplitudes are modeled based on 28 GHz outdoor
millimeter-wave small-scale local area channel measurements. The wideband
channel capacity is evaluated by considering measurement-based
Rician-distributed voltage amplitudes, and the spatial autocorrelation of
multipath amplitudes for each pair of transmitter and receiver antenna
elements. Results indicate that Rician channels may exhibit equal or possibly
greater capacity compared to Rayleigh channels, depending on the number of
antennas.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, accepted in the 10th European Conference on
  Antennas and Propagation (EuCAP'2016), April 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06941</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Multipath Model Parameters for Generating 5G Millimeter-Wave
  3GPP-like Channel Impulse Response</dc:title>
 <dc:creator>Samimi, Mathew K.</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents 28 GHz and 73 GHz empirically-derived large-scale and
small-scale channel model parameters that characterize average temporal and
angular properties of multipaths. Omnidirectional azimuth scans at both the
transmitter and receiver used high gain directional antennas, from which global
3GPP modeling parameters for the mean global azimuth and zenith spreads of
arrival were found to be 22 degrees and 6.2 degrees at 28 GHz, and 37.1 degrees
and 3.8 degrees at 73 GHz, respectively, in non-line of sight (NLOS).
Small-scale spatial measurements at 28 GHz reveal a mean cross-polar ratio for
individual multipath components of 29.7 dB and 16.7 dB in line of sight and
NLOS, respectively. Small-scale parameters extracted using the KPowerMeans
algorithm yielded on average 5.3 and 4.6 clusters at 28 GHz and 73 GHz,
respectively, in NLOS. The time cluster - spatial lobe (TCSL) modeling approach
uses an alternative physically-based binning procedure and recreates 3GPP model
parameters to generate channel impulse responses, as well as new parameters
like the RMS lobe angular spreads useful in quantifying millimeter-wave
directionality. The TCSL algorithm faithfully reproduces first- and
second-order statistics of measured millimeter-wave channels.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, accepted in the 10th European Conference on
  Antennas and Propagation (EuCAP'2016), April 2016</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06951</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradual DropIn of Layers to Train Very Deep Neural Networks</dc:title>
 <dc:creator>Smith, Leslie N.</dc:creator>
 <dc:creator>Hand, Emily M.</dc:creator>
 <dc:creator>Doster, Timothy</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the concept of dynamically growing a neural network during
training. In particular, an untrainable deep network starts as a trainable
shallow network and newly added layers are slowly, organically added during
training, thereby increasing the network's depth. This is accomplished by a new
layer, which we call DropIn. The DropIn layer starts by passing the output from
a previous layer (effectively skipping over the newly added layers), then
increasingly including units from the new layers for both feedforward and
backpropagation. We show that deep networks, which are untrainable with
conventional methods, will converge with DropIn layers interspersed in the
architecture. In addition, we demonstrate that DropIn provides regularization
during training in an analogous way as dropout. Experiments are described with
the MNIST dataset and various expanded LeNet architectures, CIFAR-10 dataset
with its architecture expanded from 3 to 11 layers, and on the ImageNet dataset
with the AlexNet architecture expanded to 13 layers and the VGG 16-layer
architecture.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06954</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Budgetary Effects on Pricing Equilibrium in Online Markets</dc:title>
 <dc:creator>Borodin, Allan</dc:creator>
 <dc:creator>Lev, Omer</dc:creator>
 <dc:creator>Strangway, Tyrone</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Following the work of Babaioff et al, we consider the pricing game with
strategic vendors and a single buyer, modeling a scenario in which multiple
competing vendors have very good knowledge of a buyer, as is common in online
markets. We add to this model the realistic assumption that the buyer has a
fixed budget and does not have unlimited funds. When the buyer's valuation
function is additive, we are able to completely characterize the different
possible pure Nash Equilibria (PNE) and in particular obtain a necessary and
sufficient condition for uniqueness. Furthermore, we characterize the market
clearing (or Walresian) equilibria for all submodular valuations.
  Surprisingly, for certain monotone submodular function valuations, we show
that the pure NE can exhibit some counterintuitive phenomena; namely, there is
a valuation such that the pricing will be market clearing and within budget if
the buyer does not reveal the budget but will result in a smaller set of
allocated items (and higher prices for items) if the buyer does reveal the
budget. It is also the case that the conditions that guarantee market clearing
in Babaioff et al for submodular functions are not necessarily market clearing
when there is a budget. Furthermore, with respect to social welfare, while
without budgets all equilibria are optimal (i.e. POA = POS = 1), we show that
with budgets the worst equilibrium may only achieve 1/(n-2) of the best
equilibrium.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06960</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Linear Locally Repairable Codes</dc:title>
 <dc:creator>Huang, Pengfei</dc:creator>
 <dc:creator>Yaakobi, Eitan</dc:creator>
 <dc:creator>Uchikawa, Hironori</dc:creator>
 <dc:creator>Siegel, Paul H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Locally repairable codes (LRCs) are a class of codes designed for the local
correction of erasures. They have received considerable attention in recent
years due to their applications in distributed storage. Most existing results
on LRCs do not explicitly take into consideration the field size $q$, i.e., the
size of the code alphabet. In particular, for the binary case, only a few
results are known.
  In this work, we present an upper bound on the minimum distance $d$ of linear
LRCs with availability, based on the work of Cadambe and Mazumdar. The bound
takes into account the code length $n$, dimension $k$, locality $r$,
availability $t$, and field size $q$. Then, we study binary linear LRCs in
three aspects. First, we focus on analyzing the locality of some classical
codes, i.e., cyclic codes and Reed-Muller codes, and their modified versions,
which are obtained by applying the operations of extend, shorten, expurgate,
augment, and lengthen. Next, we construct LRCs using phantom parity-check
symbols and multi-level tensor product structure, respectively. Compared to
other previous constructions of binary LRCs with fixed locality or minimum
distance, our construction is much more flexible in terms of code parameters,
and gives various families of high-rate LRCs, some of which are shown to be
optimal with respect to their minimum distance. Finally, availability of LRCs
is studied. We investigate the locality and availability properties of several
classes of one-step majority-logic decodable codes, including cyclic simplex
codes, cyclic difference-set codes, and $4$-cycle free regular low-density
parity-check (LDPC) codes. We also show the construction of a long LRC with
availability from a short one-step majority-logic decodable code.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06961</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Linear Algebraic Structure of Distributed Word Representations</dc:title>
 <dc:creator>Lee, Lisa Seung-Yeon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we leverage the linear algebraic structure of distributed word
representations to automatically extend knowledge bases and allow a machine to
learn new facts about the world. Our goal is to extract structured facts from
corpora in a simpler manner, without applying classifiers or patterns, and
using only the co-occurrence statistics of words. We demonstrate that the
linear algebraic structure of word embeddings can be used to reduce data
requirements for methods of learning facts. In particular, we demonstrate that
words belonging to a common category, or pairs of words satisfying a certain
relation, form a low-rank subspace in the projected space. We compute a basis
for this low-rank subspace using singular value decomposition (SVD), then use
this basis to discover new facts and to fit vectors for less frequent words
which we do not yet have vectors for.
</dc:description>
 <dc:description>Comment: 55 pages</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06964</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and
  Denoising Autoencoders</dc:title>
 <dc:creator>Ororbia II, Alexander G.</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:creator>Reitter, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and
the Deep Hybrid Denoising Auto-encoder, are proposed for handling
semi-supervised learning problems. The models combine experts that model
relevant distributions at different levels of abstraction to improve overall
predictive performance on discriminative tasks. Theoretical motivations and
algorithms for joint learning for each are presented. We apply the new models
to the domain of data-streams in work towards life-long learning. The proposed
architectures show improved performance compared to a pseudo-labeled, drop-out
rectifier network.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06964</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06965</identifier>
 <datestamp>2016-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructive Galois Connections: Taming the Galois Connection Framework
  for Mechanized Metatheory</dc:title>
 <dc:creator>Darais, David</dc:creator>
 <dc:creator>Van Horn, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Galois connections are a foundational tool for structuring abstraction in
semantics and their use lies at the heart of the theory of abstract
interpretation. Yet, mechanization of Galois connections remains limited to
restricted modes of use, preventing their general application in mechanized
metatheory and certified programming.
  This paper presents constructive Galois connections, a variant of Galois
connections that is effective both on paper and in proof assistants; is
complete with respect to a large subset of classical Galois connections; and
enables more general reasoning principles, including the &quot;calculational&quot; style
advocated by Cousot.
  To design constructive Galois connection we identify a restricted mode of use
of classical ones which is both general and amenable to mechanization in
dependently-typed functional programming languages. Crucial to our metatheory
is the addition of monadic structure to Galois connections to control a
&quot;specification effect&quot;. Effectful calculations may reason classically, while
pure calculations have extractable computational content. Explicitly moving
between the worlds of specification and implementation is enabled by our
metatheory.
  To validate our approach, we provide two case studies in mechanizing existing
proofs from the literature: one uses calculational abstract interpretation to
design a static analyzer, the other forms a semantic basis for gradual typing.
Both mechanized proofs closely follow their original paper-and-pencil
counterparts, employ reasoning principles not captured by previous
mechanization approaches, support the extraction of verified algorithms, and
are novel.
</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06968</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Configurable Hardware from Parallel Patterns</dc:title>
 <dc:creator>Prabhakar, Raghu</dc:creator>
 <dc:creator>Koeplinger, David</dc:creator>
 <dc:creator>Brown, Kevin</dc:creator>
 <dc:creator>Lee, HyoukJoong</dc:creator>
 <dc:creator>De Sa, Christopher</dc:creator>
 <dc:creator>Kozyrakis, Christos</dc:creator>
 <dc:creator>Olukotun, Kunle</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In recent years the computing landscape has seen an in- creasing shift
towards specialized accelerators. Field pro- grammable gate arrays (FPGAs) are
particularly promising as they offer significant performance and energy
improvements compared to CPUs for a wide class of applications and are far more
flexible than fixed-function ASICs. However, FPGAs are difficult to program.
Traditional programming models for reconfigurable logic use low-level hardware
description languages like Verilog and VHDL, which have none of the pro-
ductivity features of modern software development languages but produce very
efficient designs, and low-level software lan- guages like C and OpenCL coupled
with high-level synthesis (HLS) tools that typically produce designs that are
far less efficient. Functional languages with parallel patterns are a better
fit for hardware generation because they both provide high-level abstractions
to programmers with little experience in hard- ware design and avoid many of
the problems faced when gen- erating hardware from imperative languages. In
this paper, we identify two optimizations that are important when using par-
allel patterns to generate hardware: tiling and metapipelining. We present a
general representation of tiled parallel patterns, and provide rules for
automatically tiling patterns and gen- erating metapipelines. We demonstrate
experimentally that these optimizations result in speedups up to 40x on a set
of benchmarks from the data analytics domain.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06971</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for the Design and Analysis of Sparse FIR Linear
  Equalizers</dc:title>
 <dc:creator>Al-Abbasi, Abubakr O.</dc:creator>
 <dc:creator>Hamila, Ridha</dc:creator>
 <dc:creator>Bajwa, Waheed U.</dc:creator>
 <dc:creator>Al-Dhahir, Naofal</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Complexity of linear finite-impulse-response (FIR) equalizers is proportional
to the square of the number of nonzero taps in the filter. This makes
equalization of channels with long impulse responses using either zero-forcing
or minimum mean square error (MMSE) filters computationally expensive. Sparse
equalization is a widely-used technique to solve this problem. In this paper, a
general framework is provided that transforms the problem of sparse linear
equalizers (LEs) design into the problem of sparsest-approximation of a vector
in different dictionaries. In addition, some possible choices of sparsifying
dictionaries in this framework are discussed. Furthermore, the worst-case
coherence of some of these dictionaries, which determines their sparsifying
strength, are analytically and/or numerically evaluated. Finally, the
usefulness of the proposed framework for the design of sparse FIR LEs is
validated through numerical experiments.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, IEEE GlobalSIP'15 Conference</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06971</dc:identifier>
 <dc:identifier>doi:10.1109/GlobalSIP.2015.7418314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06973</identifier>
 <datestamp>2016-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ask Me Anything: Free-form Visual Question Answering Based on Knowledge
  from External Sources</dc:title>
 <dc:creator>Wu, Qi</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Dick, Anthony</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method for visual question answering which combines an internal
representation of the content of an image with information extracted from a
general knowledge base to answer a broad range of image-based questions. This
allows more complex questions to be answered using the predominant neural
network-based approach than has previously been possible. It particularly
allows questions to be asked about the contents of an image, even when the
image itself does not contain the whole answer. The method constructs a textual
representation of the semantic content of an image, and merges it with textual
information sourced from a knowledge base, to develop a deeper understanding of
the scene viewed. Priming a recurrent neural network with this combined
information, and the submitted question, leads to a very flexible visual
question answering approach. We are specifically able to answer questions posed
in natural language, that refer to information not contained in the image. We
demonstrate the effectiveness of our model on two publicly available datasets,
Toronto COCO-QA and MS COCO-VQA and show that it produces the best reported
results in both cases.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Conf. Computer Vision and Pattern Recognition</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06975</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Integrated Framework to Recommend Personalized Retention Actions to
  Control B2C E-Commerce Customer Churn</dc:title>
 <dc:creator>Renjith, Shini</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Considering the level of competition prevailing in Business-to-Consumer (B2C)
E-Commerce domain and the huge investments required to attract new customers,
firms are now giving more focus to reduce their customer churn rate. Churn rate
is the ratio of customers who part away with the firm in a specific time
period. One of the best mechanism to retain current customers is to identify
any potential churn and respond fast to prevent it. Detecting early signs of a
potential churn, recognizing what the customer is looking for by the movement
and automating personalized win back campaigns are essential to sustain
business in this era of competition. E-Commerce firms normally possess large
volume of data pertaining to their existing customers like transaction history,
search history, periodicity of purchases, etc. Data mining techniques can be
applied to analyse customer behaviour and to predict the potential customer
attrition so that special marketing strategies can be adopted to retain them.
This paper proposes an integrated model that can predict customer churn and
also recommend personalized win back actions.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, Published with International Journal of
  Engineering Trends and Technology (IJETT)</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06975</dc:identifier>
 <dc:identifier>IJETT, V27(3),152-157 September 2015. ISSN:2231-5381.
  www.ijettjournal.org</dc:identifier>
 <dc:identifier>doi:10.14445/22315381/IJETT-V27P227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06982</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trading Safety Versus Performance: Rapid Deployment of Robotic Swarms
  with Robust Performance Constraints</dc:title>
 <dc:creator>Chow, Yin-Lam</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:creator>Sadler, Brian M.</dc:creator>
 <dc:creator>Carpin, Stefano</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we consider a stochastic deployment problem, where a robotic
swarm is tasked with the objective of positioning at least one robot at each of
a set of pre-assigned targets while meeting a temporal deadline. Travel times
and failure rates are stochastic but related, inasmuch as failure rates
increase with speed. To maximize chances of success while meeting the deadline,
a control strategy has therefore to balance safety and performance. Our
approach is to cast the problem within the theory of constrained Markov
Decision Processes, whereby we seek to compute policies that maximize the
probability of successful deployment while ensuring that the expected duration
of the task is bounded by a given deadline. To account for uncertainties in the
problem parameters, we consider a robust formulation and we propose efficient
solution algorithms, which are of independent interest. Numerical experiments
confirming our theoretical results are presented and discussed.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06984</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Learning of Action Detection from Frame Glimpses in Videos</dc:title>
 <dc:creator>Yeung, Serena</dc:creator>
 <dc:creator>Russakovsky, Olga</dc:creator>
 <dc:creator>Mori, Greg</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work we introduce a fully end-to-end approach for action detection in
videos that learns to directly predict the temporal bounds of actions. Our
intuition is that the process of detecting actions is naturally one of
observation and refinement: observing moments in video, and refining hypotheses
about when an action is occurring. Based on this insight, we formulate our
model as a recurrent neural network-based agent that interacts with a video
over time. The agent observes video frames and decides both where to look next
and when to emit a prediction. Since backpropagation is not adequate in this
non-differentiable setting, we use REINFORCE to learn the agent's decision
policy. Our model achieves state-of-the-art results on the THUMOS'14 and
ActivityNet datasets while observing only a fraction (2% or less) of the video
frames.
</dc:description>
 <dc:description>Comment: Update to version in CVPR 2016 proceedings</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06987</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary algorithms</dc:title>
 <dc:creator>Eremeev, Anton V.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This manuscript contains an outline of lectures course &quot;Evolutionary
Algorithms&quot; read by the author in Omsk State University n.a. F.M.Dostoevsky.
The course covers Canonic Genetic Algorithm and various other genetic
algorithms as well as evolutionary strategies, genetic programming, tabu search
and the class of evolutionary algorithms in general. Some facts, such as the
Rotation Property of crossover, the Schemata Theorem, GA performance as a local
search and &quot;almost surely&quot; convergence of evolutionary algorithms are given
with complete proofs. The text is in Russian.
</dc:description>
 <dc:description>Comment: Outline of lectures course &quot;Evolutionary Algorithms&quot; (in Russian)</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06987</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06988</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning High-level Prior with Convolutional Neural Networks for
  Semantic Segmentation</dc:title>
 <dc:creator>Zheng, Haitian</dc:creator>
 <dc:creator>Liu, Yebin</dc:creator>
 <dc:creator>Ji, Mengqi</dc:creator>
 <dc:creator>Wu, Feng</dc:creator>
 <dc:creator>Fang, Lu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a convolutional neural network that can fuse high-level
prior for semantic image segmentation. Motivated by humans' vision recognition
system, our key design is a three-layer generative structure consisting of
high-level coding, middle-level segmentation and low-level image to introduce
global prior for semantic segmentation. Based on this structure, we proposed a
generative model called conditional variational auto-encoder (CVAE) that can
build up the links behind these three layers. These important links include an
image encoder that extracts high level info from image, a segmentation encoder
that extracts high level info from segmentation, and a hybrid decoder that
outputs semantic segmentation from the high level prior and input image. We
theoretically derive the semantic segmentation as an optimization problem
parameterized by these links. Finally, the optimization problem enables us to
take advantage of state-of-the-art fully convolutional network structure for
the implementation of the above encoders and decoder. Experimental results on
several representative datasets demonstrate our supreme performance for
semantic segmentation.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06995</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Sentential Utterances in Dialogue: Experiments in Classification and
  Interpretation</dc:title>
 <dc:creator>Dragone, Paolo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Non-sentential utterances (NSUs) are utterances that lack a complete
sentential form but whose meaning can be inferred from the dialogue context,
such as &quot;OK&quot;, &quot;where?&quot;, &quot;probably at his apartment&quot;. The interpretation of
non-sentential utterances is an important problem in computational linguistics
since they constitute a frequent phenomena in dialogue and they are
intrinsically context-dependent. The interpretation of NSUs is the task of
retrieving their full semantic content from their form and the dialogue
context. The first half of this thesis is devoted to the NSU classification
task. Our work builds upon Fern\'andez et al. (2007) which present a series of
machine-learning experiments on the classification of NSUs. We extended their
approach with a combination of new features and semi-supervised learning
techniques. The empirical results presented in this thesis show a modest but
significant improvement over the state-of-the-art classification performance.
The consecutive, yet independent, problem is how to infer an appropriate
semantic representation of such NSUs on the basis of the dialogue context.
Fern\'andez (2006) formalizes this task in terms of &quot;resolution rules&quot; built on
top of the Type Theory with Records (TTR). Our work is focused on the
reimplementation of the resolution rules from Fern\'andez (2006) with a
probabilistic account of the dialogue state. The probabilistic rules formalism
Lison (2014) is particularly suited for this task because, similarly to the
framework developed by Ginzburg (2012) and Fern\'andez (2006), it involves the
specification of update rules on the variables of the dialogue state to capture
the dynamics of the conversation. However, the probabilistic rules can also
encode probabilistic knowledge, thereby providing a principled account of
ambiguities in the NSU resolution process.
</dc:description>
 <dc:description>Comment: Master thesis, 98 pages, ISBN: 9788887096057</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06996</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differential positivity characterizes one-dimensional normally
  hyperbolic attractors</dc:title>
 <dc:creator>Forni, Fulvio</dc:creator>
 <dc:creator>Mauroy, Alexandre</dc:creator>
 <dc:creator>Sepulchre, Rodolphe</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  The paper shows that normally hyperbolic one-dimensional compact attractors
of smooth dynamical systems are characterized by differential positivity, that
is, the pointwise infinitesimal contraction of a smooth cone field. The result
is analog to the characterization of zero-dimensional hyperbolic attractors by
differential stability, which is the pointwise infinitesimal contraction of a
Riemannian metric.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.06996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07001</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of a Play by Means of CHAPLIN, the Characters and Places
  Interaction Network Software</dc:title>
 <dc:creator>Sparavigna, A. C.</dc:creator>
 <dc:creator>Marazzato, R.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recently, we have developed a software able of gathering information on
social networks from written texts. This software, the CHAracters and PLaces
Interaction Network (CHAPLIN) tool, is implemented in Visual Basic. By means of
it, characters and places of a literary work can be extracted from a list of
raw words. The software interface helps users to select their names out of this
list. Setting some parameters, CHAPLIN creates a network where nodes represent
characters/places and edges give their interactions. Nodes and edges are
labelled by performances. In this paper, we propose to use CHAPLIN for the
analysis a William Shakespeare's play, the famous 'Tragedy of Hamlet, Prince of
Denmark'. Performances of characters in the play as a whole and in each act of
it are given by graphs.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07001</dc:identifier>
 <dc:identifier>International Journal of Sciences, 2015, 4(3):60-68</dc:identifier>
 <dc:identifier>doi:10.18483/ijSci.662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07004</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Music Playlists</dc:title>
 <dc:creator>Choi, Keunwoo</dc:creator>
 <dc:creator>Fazekas, George</dc:creator>
 <dc:creator>Sandler, Mark</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  As music streaming services dominate the music industry, the playlist is
becoming an increasingly crucial element of music consumption. Con- sequently,
the music recommendation problem is often casted as a playlist generation prob-
lem. Better understanding of the playlist is there- fore necessary for
developing better playlist gen- eration algorithms. In this work, we analyse
two playlist datasets to investigate some com- monly assumed hypotheses about
playlists. Our findings indicate that deeper understanding of playlists is
needed to provide better prior infor- mation and improve machine learning
algorithms in the design of recommendation systems.
</dc:description>
 <dc:description>Comment: International Conference on Machine Learning (ICML) 2015, Machine
  Learning for Music Discovery Workshop</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07008</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Time Vowel Tremolo Detection Using Low Level Audio Descriptors</dc:title>
 <dc:creator>Malt, Mikhail</dc:creator>
 <dc:creator>Gentilucci, Marta</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This paper resumes the results of a research conducted in a music production
situation Therefore, it is more a final lab report, a prospective methodology
then a scientific experience. The methodology we are presenting was developed
as an answer to a musical problem raised by the Italian composer Marta
Gentilucci. The problem was &quot;how to extract a temporal structure from a vowel
tremolo, on a tenuto (steady state) pitch.&quot; The musical goal was to apply, in a
compositional context the vowel tremolo time structure on a tenuto pitch chord,
as a transposition control.In this context we decide to follow, to explore the
potential of low-level MPEG7 audio descriptors to build event detection
functions. One of the main problems using low-level audio descriptors in audio
analysis is the redundancy of information among them. We describe an &quot;ad hoc&quot;
interactive methodology, based on side effect use of dimensionality reduction
by PCA, to choose a feature from a set of low-level audio descriptors, to be
used to detect a vowel tremolo rhythm. This methodology is supposed to be
interactive and easy enough to be used in a live creative context.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, 2 tables, lab report</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07017</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Apriori Algorithm with Different Data Structures
  on Hadoop Cluster</dc:title>
 <dc:creator>Singh, Sudhakar</dc:creator>
 <dc:creator>Garg, Rakhi</dc:creator>
 <dc:creator>Mishra, P. K.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Mining frequent itemsets from massive datasets is always being a most
important problem of data mining. Apriori is the most popular and simplest
algorithm for frequent itemset mining. To enhance the efficiency and
scalability of Apriori, a number of algorithms have been proposed addressing
the design of efficient data structures, minimizing database scan and parallel
and distributed processing. MapReduce is the emerging parallel and distributed
technology to process big datasets on Hadoop Cluster. To mine big datasets it
is essential to re-design the data mining algorithm on this new paradigm. In
this paper, we implement three variations of Apriori algorithm using data
structures hash tree, trie and hash table trie i.e. trie with hash technique on
MapReduce paradigm. We emphasize and investigate the significance of these
three data structures for Apriori algorithm on Hadoop cluster, which has not
been given attention yet. Experiments are carried out on both real life and
synthetic datasets which shows that hash table trie data structures performs
far better than trie and hash tree in terms of execution time. Moreover the
performance in case of hash tree becomes worst.
</dc:description>
 <dc:description>Comment: 2009-2015 International Journal of Computer Applications,
  FCS(Foundation of Computer Science)</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07017</dc:identifier>
 <dc:identifier>doi:10.5120/ijca2015906632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07020</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a Natural Dynamics for Linear Programming</dc:title>
 <dc:creator>Straszak, Damian</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.1.7</dc:subject>
 <dc:description>  In this paper we study dynamics inspired by Physarum polycephalum (a slime
mold) for solving linear programs [NTY00, IJNT11, JZ12]. These dynamics are
arrived at by a local and mechanistic interpretation of the inner workings of
the slime mold and a global optimization perspective has been lacking even in
the simplest of instances. Our first result is an interpretation of the
dynamics as an optimization process. We show that Physarum dynamics can be seen
as a steepest-descent type algorithm on a certain Riemannian manifold.
Moreover, we prove that the trajectories of Physarum are in fact paths of
optimizers to a parametrized family of convex programs, in which the objective
is a linear cost function regularized by an entropy barrier. Subsequently, we
rigorously establish several important properties of solution curves of
Physarum. We prove global existence of such solutions and show that they have
limits, being optimal solutions of the underlying LP. Finally, we show that the
discretization of the Physarum dynamics is efficient for a class of linear
programs, which include unimodular constraint matrices. Thus, together, our
results shed some light on how nature might be solving instances of perhaps the
most complex problem in P: linear programming.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07023</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anvaya: An Algorithm and Case-Study on Improving the Goodness of
  Software Process Models generated by Mining Event-Log Data in Issue Tracking
  System</dc:title>
 <dc:creator>Juneja, Prerna</dc:creator>
 <dc:creator>Kundra, Divya</dc:creator>
 <dc:creator>Sureka, Ashish</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process Aware
Information Systems (PAIS) generating event-logs during the life-cycle of a bug
report. Process Mining consists of mining event logs generated from PAIS for
process model discovery, conformance and enhancement. We apply process map
discovery techniques to mine event trace data generated from ITS of open source
Firefox browser project to generate and study process models. Bug life-cycle
consists of diversity and variance. Therefore, the process models generated
from the event-logs are spaghetti-like with large number of edges,
inter-connections and nodes. Such models are complex to analyse and difficult
to comprehend by a process analyst. We improve the Goodness (fitness and
structural complexity) of the process models by splitting the event-log into
homogeneous subsets by clustering structurally similar traces. We adapt the
K-Medoid clustering algorithm with two different distance metrics: Longest
Common Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate the
goodness of the process models generated from the clusters using complexity and
fitness metrics. We study back-forth \&amp; self-loops, bug reopening, and
bottleneck in the clusters obtained and show that clustering enables better
analysis. We also propose an algorithm to automate the clustering process -the
algorithm takes as input the event log and returns the best cluster set.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07031</identifier>
 <datestamp>2016-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Rates of ASK-Based Molecular Communication in Fluid Media</dc:title>
 <dc:creator>Ghavami, Siavash</dc:creator>
 <dc:creator>Adve, Raviraj</dc:creator>
 <dc:creator>Lahouti, Farshad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the capacity of molecular communications in fluid media,
where the information is encoded in the number of transmitted molecules in a
time-slot (amplitude shift keying). The propagation of molecules is governed by
random Brownian motion and the communication is in general subject to
inter-symbol interference (ISI). We first consider the case where ISI is
negligible and analyze the capacity and the capacity per unit cost of the
resulting discrete memoryless molecular channel and the effect of possible
practical constraints, such as limitations on peak and/or average number of
transmitted molecules per transmission. In the case with a constrained peak
molecular emission, we show that as the time-slot duration increases, the input
distribution achieving the capacity per channel use transitions from binary
inputs to a discrete uniform distribution. In this paper, we also analyze the
impact of ISI. Crucially, we account for the correlation that ISI induces
between channel output symbols. We derive an upper bound and two lower bounds
on the capacity in this setting. Using the input distribution obtained by an
extended Blahut-Arimoto algorithm, we maximize the lower bounds. Our results
show that, over a wide range of parameter values, the bounds are close.
</dc:description>
 <dc:description>Comment: 31 pages, 8 figures, Accepted for publication on IEEE Transactions on
  Molecular, Biological, and Multi-Scale Communications</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07031</dc:identifier>
 <dc:identifier>doi:10.1109/TMBMC.2016.2537302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07033</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occurrence Typing Modulo Theories</dc:title>
 <dc:creator>Kent, Andrew M.</dc:creator>
 <dc:creator>Kempe, David</dc:creator>
 <dc:creator>Tobin-Hochstadt, Sam</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present a new type system combining occurrence typing, previously used to
type check programs in dynamically-typed languages such as Racket, JavaScript,
and Ruby, with dependent refinement types. We demonstrate that the addition of
refinement types allows the integration of arbitrary solver-backed reasoning
about logical propositions from external theories. By building on occurrence
typing, we can add our enriched type system as an extension of Typed
Racket---adding dependency and refinement reuses the existing formalism while
increasing its expressiveness.
  Dependent refinement types allow Typed Racket programmers to express rich
type relationships, ranging from data structure invariants such as red-black
tree balance to preconditions such as vector bounds. Refinements allow
programmers to embed the propositions that occurrence typing in Typed Racket
already reasons about into their types. Further, extending occurrence typing to
refinements allows us to make the underlying formalism simpler and more
powerful.
  In addition to presenting the design of our system, we present a formal model
of the system, show how to integrate it with theories over both linear
arithmetic and bitvectors, and evaluate the system in the context of the full
Typed Racket implementation. Specifically, we take safe vector access as a case
study, and examine all vector accesses in a 56,000 line corpus of Typed Racket
programs. Our system is able to prove that 50% of these are safe with no new
annotation, and with a few annotations and modifications, we can capture close
to 80%.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07033</dc:identifier>
 <dc:identifier>SIGPLAN Not. 51, 6 (June 2016), 296-309</dc:identifier>
 <dc:identifier>doi:10.1145/2980983.2908091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07035</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Road Surface Wetness from Audio: A Deep Learning Approach</dc:title>
 <dc:creator>Abdi&#x107;, Irman</dc:creator>
 <dc:creator>Fridman, Lex</dc:creator>
 <dc:creator>Marchi, Erik</dc:creator>
 <dc:creator>Brown, Daniel E</dc:creator>
 <dc:creator>Angell, William</dc:creator>
 <dc:creator>Reimer, Bryan</dc:creator>
 <dc:creator>Schuller, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We introduce a recurrent neural network architecture for automated road
surface wetness detection from audio of tire-surface interaction. The
robustness of our approach is evaluated on 785,826 bins of audio that span an
extensive range of vehicle speeds, noises from the environment, road surface
types, and pavement conditions including international roughness index (IRI)
values from 25 in/mi to 1400 in/mi. The training and evaluation of the model
are performed on different roads to minimize the impact of environmental and
other external factors on the accuracy of the classification. We achieve an
unweighted average recall (UAR) of 93.2% across all vehicle speeds including 0
mph. The classifier still works at 0 mph because the discriminating signal is
present in the sound of other vehicles driving by.
</dc:description>
 <dc:description>Comment: Under review in IEEE Signal Processing Letters</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2015-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07038</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constant Factor Approximation for ATSP with Two Edge Weights</dc:title>
 <dc:creator>Svensson, Ola</dc:creator>
 <dc:creator>Tarnawski, Jakub</dc:creator>
 <dc:creator>V&#xe9;gh, L&#xe1;szl&#xf3; A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We give a constant factor approximation algorithm for the Asymmetric
Traveling Salesman Problem on shortest path metrics of directed graphs with two
different edge weights. For the case of unit edge weights, the first constant
factor approximation was given recently by Svensson. This was accomplished by
introducing an easier problem called Local-Connectivity ATSP and showing that a
good solution to this problem can be used to obtain a constant factor
approximation for ATSP. In this paper, we solve Local-Connectivity ATSP for two
different edge weights. The solution is based on a flow decomposition theorem
for solutions of the Held-Karp relaxation, which may be of independent
interest.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07038</dc:identifier>
 <dc:identifier>Proc. of Integer Programming and Combinatorial Optimization: 18th
  International Conference, IPCO 2016, pages 226-237</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-33461-5_19</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07041</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SceneNet: Understanding Real World Indoor Scenes With Synthetic Data</dc:title>
 <dc:creator>Handa, Ankur</dc:creator>
 <dc:creator>Patraucean, Viorica</dc:creator>
 <dc:creator>Badrinarayanan, Vijay</dc:creator>
 <dc:creator>Stent, Simon</dc:creator>
 <dc:creator>Cipolla, Roberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene understanding is a prerequisite to many high level tasks for any
automated intelligent machine operating in real world environments. Recent
attempts with supervised learning have shown promise in this direction but also
highlighted the need for enormous quantity of supervised data --- performance
increases in proportion to the amount of data used. However, this quickly
becomes prohibitive when considering the manual labour needed to collect such
data. In this work, we focus our attention on depth based semantic per-pixel
labelling as a scene understanding problem and show the potential of computer
graphics to generate virtually unlimited labelled data from synthetic 3D
scenes. By carefully synthesizing training data with appropriate noise models
we show comparable performance to state-of-the-art RGBD systems on NYUv2
dataset despite using only depth data as input and set a benchmark on
depth-based segmentation on SUN RGB-D dataset. Additionally, we offer a route
to generating synthesized frame or video data, and understanding of different
factors influencing performance gains.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07053</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation</dc:title>
 <dc:creator>Visin, Francesco</dc:creator>
 <dc:creator>Ciccone, Marco</dc:creator>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Kastner, Kyle</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:creator>Matteucci, Matteo</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a structured prediction architecture, which exploits the local
generic features extracted by Convolutional Neural Networks and the capacity of
Recurrent Neural Networks (RNN) to retrieve distant dependencies. The proposed
architecture, called ReSeg, is based on the recently introduced ReNet model for
image classification. We modify and extend it to perform the more challenging
task of semantic segmentation. Each ReNet layer is composed of four RNN that
sweep the image horizontally and vertically in both directions, encoding
patches or activations, and providing relevant global information. Moreover,
ReNet layers are stacked on top of pre-trained convolutional layers, benefiting
from generic local features. Upsampling layers follow ReNet layers to recover
the original image resolution in the final predictions. The proposed ReSeg
architecture is efficient, flexible and suitable for a variety of semantic
segmentation tasks. We evaluate ReSeg on several widely-used semantic
segmentation datasets: Weizmann Horse, Oxford Flower, and CamVid; achieving
state-of-the-art performance. Results show that ReSeg can act as a suitable
architecture for semantic segmentation tasks, and may have further applications
in other structured prediction problems. The source code and model
hyperparameters are available on https://github.com/fvisin/reseg.
</dc:description>
 <dc:description>Comment: In CVPR Deep Vision Workshop, 2016</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07057</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Indoor Office Plan Environment and Layout-Based MmWave Path Loss Models
  for 28 GHz and 73 GHz</dc:title>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Deng, Sija</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents large-scale path loss models based on extensive
ultra-wideband millimeter-wave propagation measurements performed at 28 GHz and
73 GHz in three typical indoor office layouts -- namely: corridor, open-plan,
and closed-plan. A previous study combined all indoor layouts together, while
this study separates them for site-specific indoor large-scale path loss model
analysis. Measurements were conducted using a 400 megachips-per-second
broadband sliding correlator channel sounder with 800 MHz first null-to-null RF
bandwidth for 48 transmitter-receiver location combinations with distances
ranging 3.9 m to 45.9 m for both co- and cross-polarized antenna configurations
in line-of-sight and non-line-of-sight environments. Omnidirectional path loss
values were synthesized from over 14,000 directional power delay profiles and
were used to generate single-frequency and multi-frequency path loss models for
combined, co-, and cross-polarized antennas. Large-scale path loss models that
include a cross-polarization discrimination factor are provided for
cross-polarized antenna measurements. The results show the value of using the
close-in free space reference distance single and multi-frequency path loss
models, as they offer simplicity (less parameters) in path loss calculation and
prediction, without sacrificing accuracy. Moreover, the current 3GPP
floating-intercept path loss model only requires a simple and subtle
modification to convert to the close-in free space reference distance models.
</dc:description>
 <dc:description>Comment: To be published in 2016 IEEE 83rd Vehicular Technology Conference
  Spring (VTC 2016-Spring), Nanjing, China, May 2016</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07063</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-grained pose prediction, normalization, and recognition</dc:title>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Shelhamer, Evan</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pose variation and subtle differences in appearance are key challenges to
fine-grained classification. While deep networks have markedly improved general
recognition, many approaches to fine-grained recognition rely on anchoring
networks to parts for better accuracy. Identifying parts to find correspondence
discounts pose variation so that features can be tuned to appearance. To this
end previous methods have examined how to find parts and extract
pose-normalized features. These methods have generally separated fine-grained
recognition into stages which first localize parts using hand-engineered and
coarsely-localized proposal features, and then separately learn deep
descriptors centered on inferred part positions. We unify these steps in an
end-to-end trainable network supervised by keypoint locations and class labels
that localizes parts by a fully convolutional network to focus the learning of
feature representations for the fine-grained classification task. Experiments
on the popular CUB200 dataset show that our method is state-of-the-art and
suggest a continuing role for strong supervision.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07067</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings
  Using Abstract Scenes</dc:title>
 <dc:creator>Kottur, Satwik</dc:creator>
 <dc:creator>Vedantam, Ramakrishna</dc:creator>
 <dc:creator>Moura, Jos&#xe9; M. F.</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We propose a model to learn visually grounded word embeddings (vis-w2v) to
capture visual notions of semantic relatedness. While word embeddings trained
using text have been extremely successful, they cannot uncover notions of
semantic relatedness implicit in our visual world. For instance, although
&quot;eats&quot; and &quot;stares at&quot; seem unrelated in text, they share semantics visually.
When people are eating something, they also tend to stare at the food.
Grounding diverse relations like &quot;eats&quot; and &quot;stares at&quot; into vision remains
challenging, despite recent progress in vision. We note that the visual
grounding of words depends on semantics, and not the literal pixels. We thus
use abstract scenes created from clipart to provide the visual grounding. We
find that the embeddings we learn capture fine-grained, visually grounded
notions of semantic relatedness. We show improvements over text-only word
embeddings (word2vec) on three tasks: common-sense assertion classification,
visual paraphrasing and text-based image retrieval. Our code and datasets are
available online.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07069</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Auxiliary Image Regularization for Deep CNNs with Noisy Labels</dc:title>
 <dc:creator>Azadi, Samaneh</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Precisely-labeled data sets with sufficient amount of samples are very
important for training deep convolutional neural networks (CNNs). However, many
of the available real-world data sets contain erroneously labeled samples and
those errors substantially hinder the learning of very accurate CNN models. In
this work, we consider the problem of training a deep CNN model for image
classification with mislabeled training samples - an issue that is common in
real image data sets with tags supplied by amateur users. To solve this
problem, we propose an auxiliary image regularization technique, optimized by
the stochastic Alternating Direction Method of Multipliers (ADMM) algorithm,
that automatically exploits the mutual context information among training
images and encourages the model to select reliable images to robustify the
learning process. Comprehensive experiments on benchmark data sets clearly
demonstrate our proposed regularized CNN model is resistant to label noise in
training data.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07070</identifier>
 <datestamp>2016-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which Regular Expression Patterns are Hard to Match?</dc:title>
 <dc:creator>Backurs, Arturs</dc:creator>
 <dc:creator>Indyk, Piotr</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Regular expressions constitute a fundamental notion in formal language theory
and are frequently used in computer science to define search patterns. A
classic algorithm for these problems constructs and simulates a
non-deterministic finite automaton corresponding to the expression, resulting
in an $O(mn)$ running time (where $m$ is the length of the pattern and $n$ is
the length of the text). This running time can be improved slightly (by a
polylogarithmic factor), but no significantly faster solutions are known. At
the same time, much faster algorithms exist for various special cases of
regular expressions, including dictionary matching, wildcard matching, subset
matching, word break problem etc.
  In this paper, we show that the complexity of regular expression matching can
be characterized based on its {\em depth} (when interpreted as a formula). Our
results hold for expressions involving concatenation, OR, Kleene star and
Kleene plus. For regular expressions of depth two (involving any combination of
the above operators), we show the following dichotomy: matching and membership
testing can be solved in near-linear time, except for &quot;concatenations of
stars&quot;, which cannot be solved in strongly sub-quadratic time assuming the
Strong Exponential Time Hypothesis (SETH). For regular expressions of depth
three the picture is more complex. Nevertheless, we show that all problems can
either be solved in strongly sub-quadratic time, or cannot be solved in
strongly sub-quadratic time assuming SETH.
  An intriguing special case of membership testing involves regular expressions
of the form &quot;a star of an OR of concatenations&quot;, e.g., $[a|ab|bc]^*$. This
corresponds to the so-called {\em word break} problem, for which a dynamic
programming algorithm with a runtime of (roughly) $O(n\sqrt{m})$ is known. We
show that the latter bound is not tight and improve the runtime to
$O(nm^{0.44\ldots})$.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07076</identifier>
 <datestamp>2016-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approximate Backpropagation Learning Rule for Memristor Based Neural
  Networks Using Synaptic Plasticity</dc:title>
 <dc:creator>Negrov, D. V.</dc:creator>
 <dc:creator>Karandashev, I. M.</dc:creator>
 <dc:creator>Shakirov, V. V.</dc:creator>
 <dc:creator>Matveyev, Yu. A.</dc:creator>
 <dc:creator>Dunin-Barkowski, W. L.</dc:creator>
 <dc:creator>Zenkevich, A. V.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We describe an approximation to backpropagation algorithm for training deep
neural networks, which is designed to work with synapses implemented with
memristors. The key idea is to represent the values of both the input signal
and the backpropagated delta value with a series of pulses that trigger
multiple positive or negative updates of the synaptic weight, and to use the
min operation instead of the product of the two signals. In computational
simulations, we show that the proposed approximation to backpropagation is well
converged and may be suitable for memristor implementations of multilayer
neural networks.
</dc:description>
 <dc:description>Comment: 21 pages, 6 figures, 1 table, title changed, manuscript thoroughly
  rewritten</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:date>2016-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07077</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max-sum diversity via convex programming</dc:title>
 <dc:creator>Cevallos, Alfonso</dc:creator>
 <dc:creator>Eisenbrand, Friedrich</dc:creator>
 <dc:creator>Zenklusen, Rico</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Diversity maximization is an important concept in information retrieval,
computational geometry and operations research. Usually, it is a variant of the
following problem: Given a ground set, constraints, and a function $f(\cdot)$
that measures diversity of a subset, the task is to select a feasible subset
$S$ such that $f(S)$ is maximized. The \emph{sum-dispersion} function $f(S) =
\sum_{x,y \in S} d(x,y)$, which is the sum of the pairwise distances in $S$, is
in this context a prominent diversification measure. The corresponding
diversity maximization is the \emph{max-sum} or \emph{sum-sum diversification}.
Many recent results deal with the design of constant-factor approximation
algorithms of diversification problems involving sum-dispersion function under
a matroid constraint. In this paper, we present a PTAS for the max-sum
diversification problem under a matroid constraint for distances
$d(\cdot,\cdot)$ of \emph{negative type}. Distances of negative type are, for
example, metric distances stemming from the $\ell_2$ and $\ell_1$ norm, as well
as the cosine or spherical, or Jaccard distance which are popular similarity
metrics in web and image search.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07085</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple--Instance Learning: Christoffel Function Approach to
  Distribution Regression Problem</dc:title>
 <dc:creator>Malyshkin, Vladislav Gennadievich</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A two--step Christoffel function based solution is proposed to distribution
regression problem. On the first step, to model distribution of observations
inside a bag, build Christoffel function for each bag of observations. Then, on
the second step, build outcome variable Christoffel function, but use the bag's
Christoffel function value at given point as the weight for the bag's outcome.
The approach allows the result to be obtained in closed form and then to be
evaluated numerically. While most of existing approaches minimize some kind an
error between outcome and prediction, the proposed approach is conceptually
different, because it uses Christoffel function for knowledge representation,
what is conceptually equivalent working with probabilities only. To receive
possible outcomes and their probabilities Gauss quadrature for second--step
measure can be built, then the nodes give possible outcomes and normalized
weights -- outcome probabilities. A library providing numerically stable
polynomial basis for these calculations is available, what make the proposed
approach practical.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07087</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualization in teaching and learning mathematics in elementary,
  secondary and higher education</dc:title>
 <dc:creator>Malesevic, Branko</dc:creator>
 <dc:creator>Jovovic, Ivana</dc:creator>
 <dc:creator>Banjac, Bojan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In this paper we present our experience in using visualization in mathematics
education. The experience with our university courses: &quot;Computer tools in
matematics&quot; and &quot;Symbolic algebra&quot; provides the basis for mathematics teacher
education program http://vizuelizacija.etf.rs/. The program is intended for
elementary and high school teachers. The education program deals with modern
techniques of visualization by using technologies such as GeoGegebra, JAVA and
HTML.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07087</dc:identifier>
 <dc:identifier>Proceedings of International Conference on Engineering Graphics
  and Design, pp. 37-40, Timisoara, Romania, 13-15 june 2013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07093</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a mobile game to thwarts malicious IT threats: A phishing
  threat avoidance perspective</dc:title>
 <dc:creator>Arachchilage, Nalin Asanka Gamagedara</dc:creator>
 <dc:creator>Tarhini, Ali</dc:creator>
 <dc:creator>Love, Steve</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Phishing is an online identity theft, which aims to steal sensitive
information such as username, password and online banking details from victims.
To prevent this, phishing education needs to be considered. Game based
education is becoming more and more popular. This paper introduces a mobile
game prototype for the android platform based on a story, which simplifies and
exaggerates real life. The elements of a game design framework for avoiding
phishing attacks were used to address the game design issues and game design
principles were used as a set of guidelines for structuring and presenting
information. The overall mobile game design was aimed to enhance the user's
avoidance behaviour through motivation to protect themselves against phishing
threats. The prototype mobile game design was presented on MIT App Inventor
Emulator.
</dc:description>
 <dc:description>Comment: 9, International Journal for Infonomics (IJI), Volume 8 Issues 3/4,
  September/December 2015. arXiv admin note: text overlap with arXiv:1511.01622</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07100</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A reduction of the logspace shortest path problem to biconnected graphs</dc:title>
 <dc:creator>Brimkov, Boris</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q25, 05C85</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>F.2.3</dc:subject>
 <dc:description>  In this paper, we reduce the logspace shortest path problem to biconnected
graphs; in particular, we present a logspace shortest path algorithm for
general graphs which uses a logspace shortest path oracle for biconnected
graphs. We also present a linear time logspace shortest path algorithm for
graphs with bounded vertex degree and biconnected component size, which does
not rely on an oracle. The asymptotic time-space product of this algorithm is
the best possible among all shortest path algorithms.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07106</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Volume High Resolution RGB-D Mapping with Dynamic Volume Placement</dc:title>
 <dc:creator>Salvato, Michael</dc:creator>
 <dc:creator>Finman, Ross</dc:creator>
 <dc:creator>Leonard, John</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel RGB-D mapping system for generating 3D maps over spatially
extended regions with higher resolution than current methods using multiple,
dynamically placed mapping volumes. Our method takes in RGB-D frames and
dynamically assigns multiple mapping volumes to the environment, exchanging
mapping volumes between the CPU and GPU. Mapping volumes are added or removed
as needed to allow for spatially extended, high resolution mapping. Our system
is designed to maximize the resolution possible for such volumetric methods,
while working on an unbounded space.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07110</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Generalization Error Bounds of Neural Networks under
  Diversity-Inducing Mutual Angular Regularization</dc:title>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:creator>Deng, Yuntian</dc:creator>
 <dc:creator>Xing, Eric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently diversity-inducing regularization methods for latent variable models
(LVMs), which encourage the components in LVMs to be diverse, have been studied
to address several issues involved in latent variable modeling: (1) how to
capture long-tail patterns underlying data; (2) how to reduce model complexity
without sacrificing expressivity; (3) how to improve the interpretability of
learned patterns. While the effectiveness of diversity-inducing regularizers
such as the mutual angular regularizer has been demonstrated empirically, a
rigorous theoretical analysis of them is still missing. In this paper, we aim
to bridge this gap and analyze how the mutual angular regularizer (MAR) affects
the generalization performance of supervised LVMs. We use neural network (NN)
as a model instance to carry out the study and the analysis shows that
increasing the diversity of hidden units in NN would reduce estimation error
and increase approximation error. In addition to theoretical analysis, we also
present empirical study which demonstrates that the MAR can greatly improve the
performance of NN and the empirical observations are in accordance with the
theoretical analysis.
</dc:description>
 <dc:date>2015-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07111</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adapting Deep Visuomotor Representations with Weak Pairwise Constraints</dc:title>
 <dc:creator>Tzeng, Eric</dc:creator>
 <dc:creator>Devin, Coline</dc:creator>
 <dc:creator>Hoffman, Judy</dc:creator>
 <dc:creator>Finn, Chelsea</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Saenko, Kate</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-world robotics problems often occur in domains that differ significantly
from the robot's prior training environment. For many robotic control tasks,
real world experience is expensive to obtain, but data is easy to collect in
either an instrumented environment or in simulation. We propose a novel domain
adaptation approach for robot perception that adapts visual representations
learned on a large easy-to-obtain source dataset (e.g. synthetic images) to a
target real-world domain, without requiring expensive manual data annotation of
real world data before policy search. Supervised domain adaptation methods
minimize cross-domain differences using pairs of aligned images that contain
the same object or scene in both the source and target domains, thus learning a
domain-invariant representation. However, they require manual alignment of such
image pairs. Fully unsupervised adaptation methods rely on minimizing the
discrepancy between the feature distributions across domains. We propose a
novel, more powerful combination of both distribution and pairwise image
alignment, and remove the requirement for expensive annotation by using weakly
aligned pairs of images in the source and target domains. Focusing on adapting
from simulation to real world data using a PR2 robot, we evaluate our approach
on a manipulation task and show that by using weakly paired images, our method
compensates for domain shift more effectively than previous techniques,
enabling better robot performance in the real world.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07118</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascading Denoising Auto-Encoder as a Deep Directed Generative Model</dc:title>
 <dc:creator>Lee, Dong-Hyun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)
become gener-ative models as a density estimator. However,in practice, the
framework suffers from a mixingproblem in the MCMC sampling process and
nodirect method to estimate the test log-likelihood.We consider a directed
model with an stochas-tic identity mapping (simple corruption pro-cess) as an
inference model and a DAE as agenerative model. By cascading these mod-els, we
propose Cascading Denoising Auto-Encoders(CDAE) which can generate samples
ofdata distribution from tractable prior distributionunder the assumption that
probabilistic distribu-tion of corrupted data approaches tractable
priordistribution as the level of corruption increases.This work tries to
answer two questions. On theone hand, can deep directed models be success-fully
trained without intractable posterior infer-ence and difficult optimization of
very deep neu-ral networks in inference and generative mod-els? These are
unavoidable when recent suc-cessful directed model like VAE (Kingma &amp;Welling,
2014) is trained on complex dataset likereal images. On the other hand, can
DAEs getclean samples of data distribution from heavilycorrupted samples which
can be considered oftractable prior distribution far from data mani-fold?
so-called global denoising scheme.Our results show positive responses of
thesequestions and this work can provide fairly simpleframework for generative
models of very com-plex dataset.
</dc:description>
 <dc:description>Comment: not completed</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07122</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Scale Context Aggregation by Dilated Convolutions</dc:title>
 <dc:creator>Yu, Fisher</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art models for semantic segmentation are based on adaptations of
convolutional networks that had originally been designed for image
classification. However, dense prediction and image classification are
structurally different. In this work, we develop a new convolutional network
module that is specifically designed for dense prediction. The presented module
uses dilated convolutions to systematically aggregate multi-scale contextual
information without losing resolution. The architecture is based on the fact
that dilated convolutions support exponential expansion of the receptive field
without loss of resolution or coverage. We show that the presented context
module increases the accuracy of state-of-the-art semantic segmentation
systems. In addition, we examine the adaptation of image classification
networks to dense prediction and show that simplifying the adapted network can
increase accuracy.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07125</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Happened to My Dog in That Network: Unraveling Top-down Generators
  in Convolutional Neural Networks</dc:title>
 <dc:creator>Gallagher, Patrick W.</dc:creator>
 <dc:creator>Tang, Shuai</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Top-down information plays a central role in human perception, but plays
relatively little role in many current state-of-the-art deep networks, such as
Convolutional Neural Networks (CNNs). This work seeks to explore a path by
which top-down information can have a direct impact within current deep
networks. We explore this path by learning and using &quot;generators&quot; corresponding
to the network internal effects of three types of transformation (each a
restriction of a general affine transformation): rotation, scaling, and
translation. We demonstrate how these learned generators can be used to
transfer top-down information to novel settings, as mediated by the &quot;feature
flows&quot; that the transformations (and the associated generators) correspond to
inside the network. Specifically, we explore three aspects: 1) using generators
as part of a method for synthesizing transformed images --- given a previously
unseen image, produce versions of that image corresponding to one or more
specified transformations, 2) &quot;zero-shot learning&quot; --- when provided with a
feature flow corresponding to the effect of a transformation of unknown amount,
leverage learned generators as part of a method by which to perform an accurate
categorization of the amount of transformation, even for amounts never observed
during training, and 3) (inside-CNN) &quot;data augmentation&quot; --- improve the
classification performance of an existing network by using the learned
generators to directly provide additional training &quot;inside the CNN&quot;.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07130</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Predictive Entropy Search for Batch Global Optimization of
  Expensive Objective Functions</dc:title>
 <dc:creator>Shah, Amar</dc:creator>
 <dc:creator>Ghahramani, Zoubin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop parallel predictive entropy search (PPES), a novel algorithm for
Bayesian optimization of expensive black-box objective functions. At each
iteration, PPES aims to select a batch of points which will maximize the
information gain about the global maximizer of the objective. Well known
strategies exist for suggesting a single evaluation point based on previous
observations, while far fewer are known for selecting batches of points to
evaluate in parallel. The few batch selection schemes that have been studied
all resort to greedy methods to compute an optimal batch. To the best of our
knowledge, PPES is the first non-greedy batch Bayesian optimization strategy.
We demonstrate the benefit of this approach in optimization performance on both
synthetic and real world applications, including problems in machine learning,
rocket science and robotics.
</dc:description>
 <dc:description>Comment: 12 pages in Neural Information Processing Systems 2015</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07131</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeePM: A Deep Part-Based Model for Object Detection and Semantic Part
  Localization</dc:title>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Chen, Xianjie</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a deep part-based model (DeePM) for symbiotic
object detection and semantic part localization. For this purpose, we annotate
semantic parts for all 20 object categories on the PASCAL VOC 2012 dataset,
which provides information on object pose, occlusion, viewpoint and
functionality. DeePM is a latent graphical model based on the state-of-the-art
R-CNN framework, which learns an explicit representation of the object-part
configuration with flexible type sharing (e.g., a sideview horse head can be
shared by a fully-visible sideview horse and a highly truncated sideview horse
with head and neck only). For comparison, we also present an end-to-end
Object-Part (OP) R-CNN which learns an implicit feature representation for
jointly mapping an image ROI to the object and part bounding boxes. We evaluate
the proposed methods for both the object and part detection performance on
PASCAL VOC 2012, and show that DeePM consistently outperforms OP R-CNN in
detecting objects and parts. In addition, it obtains superior performance to
Fast and Faster R-CNNs in object detection.
</dc:description>
 <dc:description>Comment: the final revision to ICLR 2016, in which some color errors in the
  figures are fixed</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07136</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity Testing and Lower Bounds for Read-$k$ Oblivious Algebraic
  Branching Programs</dc:title>
 <dc:creator>Anderson, Matthew</dc:creator>
 <dc:creator>Forbes, Michael A.</dc:creator>
 <dc:creator>Saptharishi, Ramprasad</dc:creator>
 <dc:creator>Shpilka, Amir</dc:creator>
 <dc:creator>Volk, Ben Lee</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Read-$k$ oblivious algebraic branching programs are a natural generalization
of the well-studied model of read-once oblivious algebraic branching program
(ROABPs). In this work, we give an exponential lower bound of
$\exp(n/k^{O(k)})$ on the width of any read-$k$ oblivious ABP computing some
explicit multilinear polynomial $f$ that is computed by a polynomial size
depth-$3$ circuit. We also study the polynomial identity testing (PIT) problem
for this model and obtain a white-box subexponential-time PIT algorithm. The
algorithm runs in time $2^{\tilde{O}(n^{1-1/2^{k-1}})}$ and needs white box
access only to know the order in which the variables appear in the ABP.
</dc:description>
 <dc:description>Comment: 33 pages</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07147</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A PAC Approach to Application-Specific Algorithm Selection</dc:title>
 <dc:creator>Gupta, Rishi</dc:creator>
 <dc:creator>Roughgarden, Tim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>F.2.0</dc:subject>
 <dc:description>  The best algorithm for a computational problem generally depends on the
&quot;relevant inputs,&quot; a concept that depends on the application domain and often
defies formal articulation. While there is a large literature on empirical
approaches to selecting the best algorithm for a given application domain,
there has been surprisingly little theoretical analysis of the problem.
  This paper adapts concepts from statistical and online learning theory to
reason about application-specific algorithm selection. Our models capture
several state-of-the-art empirical and theoretical approaches to the problem,
ranging from self-improving algorithms to empirical performance models, and our
results identify conditions under which these approaches are guaranteed to
perform well. We present one framework that models algorithm selection as a
statistical learning problem, and our work here shows that dimension notions
from statistical learning theory, historically used to measure the complexity
of classes of binary- and real-valued functions, are relevant in a much broader
algorithmic context. We also study the online version of the algorithm
selection problem, and give possibility and impossibility results for the
existence of no-regret learning algorithms.
</dc:description>
 <dc:description>Comment: 28 pages, 2 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07148</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NearBucket-LSH: Efficient Similarity Search in P2P Networks</dc:title>
 <dc:creator>Kraus, Naama</dc:creator>
 <dc:creator>Carmel, David</dc:creator>
 <dc:creator>Keidar, Idit</dc:creator>
 <dc:creator>Orenbach, Meni</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present NearBucket-LSH, an effective algorithm for similarity search in
large-scale distributed online social networks organized as peer-to-peer
overlays. As communication is a dominant consideration in distributed systems,
we focus on minimizing the network cost while guaranteeing good search quality.
Our algorithm is based on Locality Sensitive Hashing (LSH), which limits the
search to collections of objects, called buckets, that have a high probability
to be similar to the query. More specifically, NearBucket-LSH employs an LSH
extension that searches in near buckets, and improves search quality but also
significantly increases the network cost. We decrease the network cost by
considering the internals of both LSH and the P2P overlay, and harnessing their
properties to our needs. We show that our NearBucket-LSH increases search
quality for a given network cost compared to previous art. In many cases, the
search quality increases by more than 50%.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07163</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing Solution Quality in Synchronization Synthesis</dc:title>
 <dc:creator>&#x10c;ern&#xfd;, Pavol</dc:creator>
 <dc:creator>Clarke, Edmund M.</dc:creator>
 <dc:creator>Henzinger, Thomas A.</dc:creator>
 <dc:creator>Radhakrishna, Arjun</dc:creator>
 <dc:creator>Ryzhyk, Leonid</dc:creator>
 <dc:creator>Samanta, Roopsha</dc:creator>
 <dc:creator>Tarrach, Thorsten</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Given a multithreaded program written assuming a friendly, non-preemptive
scheduler, the goal of synchronization synthesis is to automatically insert
synchronization primitives to ensure that the modified program behaves
correctly, even with a preemptive scheduler. In this work, we focus on the
quality of the synthesized solution: we aim to infer synchronization placements
that not only ensure correctness, but also meet some quantitative objectives
such as optimal program performance on a given computing platform.
  The key step that enables solution optimization is the construction of a set
of global constraints over synchronization placements such that each model of
the constraints set corresponds to a correctness-ensuring synchronization
placement. We extract the global constraints from generalizations of
counterexample traces and the control-flow graph of the program. The global
constraints enable us to choose from among the encoded synchronization
solutions using an objective function. We consider two types of objective
functions: ones that are solely dependent on the program (e.g., minimizing the
size of critical sections) and ones that are also dependent on the computing
platform. For the latter, given a program and a computing platform, we
construct a performance model based on measuring average contention for
critical sections and the average time taken to acquire and release a lock
under a given average contention.
  We empirically evaluated that our approach scales to typical module sizes of
many real world concurrent programs such as device drivers and multithreaded
servers, and that the performance predictions match reality. To the best of our
knowledge, this is the first comprehensive approach for optimizing the
placement of synthesized synchronization.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07168</identifier>
 <datestamp>2016-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Secrecy of the Cognitive Interference Channel with Partial
  Channel States</dc:title>
 <dc:creator>Bafghi, Hamid G.</dc:creator>
 <dc:creator>Seyfe, Babak</dc:creator>
 <dc:creator>Mirmohseni, Mahtab</dc:creator>
 <dc:creator>Aref, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The secrecy problem in the state-dependent cognitive interference channel is
considered in this paper. In our model, there are a primary and a secondary
(cognitive) transmitter-receiver pairs, in which the cognitive transmitter has
the message of the primary one as side information. In addition, the channel is
affected by a channel state sequence which is estimated partially at the
cognitive transmitter and the corresponding receiver. The cognitive transmitter
wishes to cooperate with the primary one, and it sends its individual message
which should be confidential at the primary receiver. The achievable
equivocation-rate regions for this channel are derived using two approaches:
the binning scheme coding, and superposition coding. Then the outer bounds on
the capacity are proposed and the results are extended to the Gaussian
examples.
</dc:description>
 <dc:description>Comment: 14 pages, 3 figures, submitted to TRANSACTIONS ON EMERGING
  TELECOMMUNICATIONS TECHNOLOGIES (ETT)</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07174</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing a High Performance Software Library with MPI and CUDA for
  Matrix Computations</dc:title>
 <dc:creator>Oancea, Bogdan</dc:creator>
 <dc:creator>Andrei, Tudorel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Nowadays, the paradigm of parallel computing is changing. CUDA is now a
popular programming model for general purpose computations on GPUs and a great
number of applications were ported to CUDA obtaining speedups of orders of
magnitude comparing to optimized CPU implementations. Hybrid approaches that
combine the message passing model with the shared memory model for parallel
computing are a solution for very large applications. We considered a
heterogeneous cluster that combines the CPU and GPU computations using MPI and
CUDA for developing a high performance linear algebra library. Our library
deals with large linear systems solvers because they are a common problem in
the fields of science and engineering. Direct methods for computing the
solution of such systems can be very expensive due to high memory requirements
and computational cost. An efficient alternative are iterative methods which
computes only an approximation of the solution. In this paper we present an
implementation of a library that uses a hybrid model of computation using MPI
and CUDA implementing both direct and iterative linear systems solvers. Our
library implements LU and Cholesky factorization based solvers and some of the
non-stationary iterative methods using the MPI/CUDA combination. We compared
the performance of our MPI/CUDA implementation with classic programs written to
be run on a single CPU.
</dc:description>
 <dc:description>Comment: in Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07180</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Longest Gapped Repeats and Palindromes</dc:title>
 <dc:creator>Dumitran, Marius</dc:creator>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:creator>Manea, Florin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A gapped repeat (respectively, palindrome) occurring in a word $w$ is a
factor $uvu$ (respectively, $u^Rvu$) of $w$. In such a repeat (palindrome) $u$
is called the arm of the repeat (respectively, palindrome), while $v$ is called
the gap. We show how to compute efficiently, for every position $i$ of the word
$w$, the longest gapped repeat and palindrome occurring at that position,
provided that the length of the gap is subject to various types of
restrictions. That is, that for each position $i$ we compute the longest prefix
$u$ of $w[i..n]$ such that $uv$ (respectively, $u^Rv$) is a suffix of
$w[1..i-1]$ (defining thus a gapped repeat $uvu$ -- respectively, palindrome
$u^Rvu$), and the length of $v$ is subject to the aforementioned restrictions.
</dc:description>
 <dc:description>Comment: This is an extension of the conference papers &quot;Longest
  $\alpha$-Gapped Repeat and Palindrome&quot;, presented by the second and third
  authors at FCT 2015, and &quot;Longest Gapped Repeats and Palindromes&quot;, presented
  by the first and third authors at MFCS 2015</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07180</dc:identifier>
 <dc:identifier>Discrete Mathematics &amp; Theoretical Computer Science, vol 19 no. 4,
  FCT '15, special issue FCT'15 (October 13, 2017) dmtcs:3988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07182</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>National, disciplinary and temporal variations in the extent to which
  articles with more authors have more impact: Evidence from a geometric field
  normalised citation indicator</dc:title>
 <dc:creator>Thelwall, Mike</dc:creator>
 <dc:creator>Sud, Pardeep</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The importance of collaboration in research is widely accepted, as is the
fact that articles with more authors tend to be more cited. Nevertheless,
although previous studies have investigated whether the apparent advantage of
collaboration varies by country, discipline, and number of co-authors, this
study introduces a more fine-grained method to identify differences: the
geometric Mean Normalized Citation Score (gMNCS). Based on comparisons between
disciplines, years and countries for two million journal articles, the average
citation impact of articles increases with the number of authors, even when
international collaboration is excluded. This apparent advantage of
collaboration varies substantially by discipline and country and changes a
little over time. Against the trend, however, in Russia solo articles have more
impact. Across the four broad disciplines examined, collaboration had by far
the strongest association with impact in the arts and humanities. Although
international comparisons are limited by the availability of systematic data
for author country affiliations, the new indicator is the most precise yet and
can give statistical evidence rather than estimates.
</dc:description>
 <dc:description>Comment: Thelwall, M., &amp; Sud, P. (in press). National, disciplinary and
  temporal variations in the extent to which articles with more authors have
  more impact: Evidence from a geometric field normalised citation indicator.
  Journal of Informetrics</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07182</dc:identifier>
 <dc:identifier>Journal of Informetrics, 10(1), 48-61 (2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2015.11.007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07185</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medusa: An Efficient Cloud Fault-Tolerant MapReduce</dc:title>
 <dc:creator>Costa, Pedro A. R. S.</dc:creator>
 <dc:creator>Bai, Xiao</dc:creator>
 <dc:creator>Ramos, Fernando M. V.</dc:creator>
 <dc:creator>Correia, Miguel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Applications such as web search and social networking have been moving from
centralized to decentralized cloud architectures to improve their scalability.
MapReduce, a programming framework for processing large amounts of data using
thousands of machines in a single cloud, also needs to be scaled out to
multiple clouds to adapt to this evolution. The challenge of building a
multi-cloud distributed architecture is substantial. Notwithstanding, the
ability to deal with the new types of faults introduced by such setting, such
as the outage of a whole datacenter or an arbitrary fault caused by a malicious
cloud insider, increases the endeavor considerably.
  In this paper we propose Medusa, a platform that allows MapReduce
computations to scale out to multiple clouds and tolerate several types of
faults. Our solution fulfills four objectives. First, it is transparent to the
user, who writes her typical MapReduce application without modification.
Second, it does not require any modification to the widely used Hadoop
framework. Third, the proposed system goes well beyond the fault-tolerance
offered by MapReduce to tolerate arbitrary faults, cloud outages, and even
malicious faults caused by corrupt cloud insiders. Fourth, it achieves this
increased level of fault tolerance at reasonable cost. We performed an
extensive experimental evaluation in the ExoGENI testbed, demonstrating that
our solution significantly reduces execution time when compared to traditional
methods that achieve the same level of resilience.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07207</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the performance of the linear systems solvers using CUDA</dc:title>
 <dc:creator>Oancea, Bogdan</dc:creator>
 <dc:creator>Andrei, Tudorel</dc:creator>
 <dc:creator>Dragoescu, Raluca Mariana</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Parallel computing can offer an enormous advantage regarding the performance
for very large applications in almost any field: scientific computing, computer
vision, databases, data mining, and economics. GPUs are high performance
many-core processors that can obtain very high FLOP rates. Since the first idea
of using GPU for general purpose computing, things have evolved and now there
are several approaches to GPU programming: CUDA from NVIDIA and Stream from
AMD. CUDA is now a popular programming model for general purpose computations
on GPU for C/C++ programmers. A great number of applications were ported to
CUDA programming model and they obtain speedups of orders of magnitude
comparing to optimized CPU implementations. In this paper we present an
implementation of a library for solving linear systems using the CCUDA
framework. We present the results of performance tests and show that using GPU
one can obtain speedups of about of approximately 80 times comparing with a CPU
implementation.
</dc:description>
 <dc:description>Comment: in Proceedings of the Challenges of the Knowledge Society
  International Conference, 2012</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07209</identifier>
 <datestamp>2016-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Agent Continuous Transportation with Online Balanced Partitioning</dc:title>
 <dc:creator>Wang, Chao</dc:creator>
 <dc:creator>Liemhetcharat, Somchaya</dc:creator>
 <dc:creator>Low, Kian Hsiang</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  We introduce the concept of continuous transportation task to the context of
multi-agent systems. A continuous transportation task is one in which a
multi-agent team visits a number of fixed locations, picks up objects, and
delivers them to a final destination. The goal is to maximize the rate of
transportation while the objects are replenished over time. Examples of
problems that need continuous transportation are foraging, area sweeping, and
first/last mile problem. Previous approaches typically neglect the interference
and are highly dependent on communications among agents. Some also incorporate
an additional reconnaissance agent to gather information. In this paper, we
present a hybrid of centralized and distributed approaches that minimize the
interference and communications in the multi-agent team without the need for a
reconnaissance agent. We contribute two partitioning-transportation algorithms
inspired by existing algorithms, and contribute one novel online
partitioning-transportation algorithm with information gathering in the
multi-agent team. Our algorithms have been implemented and tested extensively
in the simulation. The results presented in this paper demonstrate the
effectiveness of our algorithms that outperform the existing algorithms, even
without any communications between the agents and without the presence of a
reconnaissance agent.
</dc:description>
 <dc:description>Comment: 2 pages, published in the proceedings of the 15th AAMAS conference</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-07-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07210</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearest Neighbor search in Complex Network for Community Detection</dc:title>
 <dc:creator>Saha, Suman</dc:creator>
 <dc:creator>Ghrera, S. P.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Nearest neighbor search is a basic computational tool used extensively in
almost research domains of computer science specially when dealing with large
amount of data. However, the use of nearest neighbor search is restricted for
the purpose of algorithmic development by the existence of the notion of
nearness among the data points. The recent trend of research is on large,
complex networks and their structural analysis, where nodes represent entities
and edges represent any kind of relation between entities. Community detection
in complex network is an important problem of much interest. In general, a
community detection algorithm represents an objective function and captures the
communities by optimizing it to extract the interesting communities for the
user. In this article, we have studied the nearest neighbor search problem in
complex network via the development of a suitable notion of nearness.
Initially, we have studied and analyzed the exact nearest neighbor search using
metric tree on proposed metric space constructed from complex network. After,
the approximate nearest neighbor search problem is studied using locality
sensitive hashing. For evaluation of the proposed nearest neighbor search on
complex network we applied it in community detection problem. The results
obtained using our methods are very competitive with most of the well known
algorithms exists in the literature and this is verified on collection of real
networks. On the other-hand, it can be observed that time taken by our
algorithm is quite less compared to popular methods.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1508.06380</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07211</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Noisy Submodular Maximization via Adaptive Sampling with Applications to
  Crowdsourced Image Collection Summarization</dc:title>
 <dc:creator>Singla, Adish</dc:creator>
 <dc:creator>Tschiatschek, Sebastian</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We address the problem of maximizing an unknown submodular function that can
only be accessed via noisy evaluations. Our work is motivated by the task of
summarizing content, e.g., image collections, by leveraging users' feedback in
form of clicks or ratings. For summarization tasks with the goal of maximizing
coverage and diversity, submodular set functions are a natural choice. When the
underlying submodular function is unknown, users' feedback can provide noisy
evaluations of the function that we seek to maximize. We provide a generic
algorithm -- \submM{} -- for maximizing an unknown submodular function under
cardinality constraints. This algorithm makes use of a novel exploration module
-- \blbox{} -- that proposes good elements based on adaptively sampling noisy
function evaluations. \blbox{} is able to accommodate different kinds of
observation models such as value queries and pairwise comparisons. We provide
PAC-style guarantees on the quality and sampling cost of the solution obtained
by \submM{}. We demonstrate the effectiveness of our approach in an
interactive, crowdsourced image collection summarization application.
</dc:description>
 <dc:description>Comment: Extended version of AAAI'16 paper</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07212</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Alignment Across Large Poses: A 3D Solution</dc:title>
 <dc:creator>Zhu, Xiangyu</dc:creator>
 <dc:creator>Lei, Zhen</dc:creator>
 <dc:creator>Liu, Xiaoming</dc:creator>
 <dc:creator>Shi, Hailin</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Face alignment, which fits a face model to an image and extracts the semantic
meanings of facial pixels, has been an important topic in CV community.
However, most algorithms are designed for faces in small to medium poses (below
45 degree), lacking the ability to align faces in large poses up to 90 degree.
The challenges are three-fold: Firstly, the commonly used landmark-based face
model assumes that all the landmarks are visible and is therefore not suitable
for profile views. Secondly, the face appearance varies more dramatically
across large poses, ranging from frontal view to profile view. Thirdly,
labelling landmarks in large poses is extremely challenging since the invisible
landmarks have to be guessed. In this paper, we propose a solution to the three
problems in an new alignment framework, called 3D Dense Face Alignment (3DDFA),
in which a dense 3D face model is fitted to the image via convolutional neutral
network (CNN). We also propose a method to synthesize large-scale training
samples in profile views to solve the third problem of data labelling.
Experiments on the challenging AFLW database show that our approach achieves
significant improvements over state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07218</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Optimization Based State Estimation against Sparse Integrity
  Attacks</dc:title>
 <dc:creator>Han, Duo</dc:creator>
 <dc:creator>Mo, Yilin</dc:creator>
 <dc:creator>Xie, Lihua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of robust estimation in the presence of integrity
attacks. There are m sensors monitoring the state and p of them are under
attack. The malicious measurements collected by the compromised sensors can be
manipulated arbitrarily by the attacker. The classical estimators such as the
least squares estimator may not provide a reliable estimate under the so-called
(p,m)-sparse attack. In this work, we are not restricting our efforts in
studying whether any specific estimator is resilient to the attack or not, but
instead we aim to present some generic sufficient and necessary conditions for
robustness by considering a general class of convex optimization based
estimators. The sufficient and necessary conditions are shown to be tight, with
a trivial gap.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07233</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of Unit-Memory MDS Convolutional Codes</dc:title>
 <dc:creator>Chan, Chin Hei</dc:creator>
 <dc:creator>Xiong, Maosheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B10</dc:subject>
 <dc:description>  Maximum-distance separable (MDS) convolutional codes form an optimal family
of convolutional codes, the study of which is of great importance. There are
very few general algebraic constructions of MDS convolutional codes. In this
paper, we construct a large family of unit-memory MDS convolutional codes over
$\F$ with flexible parameters. Compared with previous works, the field size $q$
required to define these codes is much smaller. The construction also leads to
many new strongly-MDS convolutional codes, an important subclass of MDS
convolutional codes proposed and studied in \cite{GL2}. Many examples are
presented at the end of the paper.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07236</identifier>
 <datestamp>2017-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Gaussian Approximation Work Well for The Long-Length Polar Code
  Construction?</dc:title>
 <dc:creator>Dai, Jincheng</dc:creator>
 <dc:creator>Niu, Kai</dc:creator>
 <dc:creator>Si, Zhongwei</dc:creator>
 <dc:creator>Dong, Chao</dc:creator>
 <dc:creator>Lin, Jiaru</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Gaussian approximation (GA) is widely used to construct polar codes. However
when the code length is long, the subchannel selection inaccuracy due to the
calculation error of conventional approximate GA (AGA), which uses a
two-segment approximation function, results in a catastrophic performance loss.
In this paper, new principles to design the GA approximation functions for
polar codes are proposed. First, we introduce the concepts of polarization
violation set (PVS) and polarization reversal set (PRS) to explain the
essential reasons that the conventional AGA scheme cannot work well for the
long-length polar code construction. In fact, these two sets will lead to the
rank error of subsequent subchannels, which means the orders of subchannels are
misaligned, which is a severe problem for polar code construction. Second, we
propose a new metric, named cumulative-logarithmic error (CLE), to
quantitatively evaluate the remainder approximation error of AGA in logarithm.
We derive the upper bound of CLE to simplify its calculation. Finally, guided
by PVS, PRS and CLE bound analysis, we propose new construction rules based on
a multi-segment approximation function, which obviously improve the calculation
accuracy of AGA so as to ensure the excellent performance of polar codes
especially for the long code lengths. Numerical and simulation results indicate
that the proposed AGA schemes are critical to construct the high-performance
polar codes.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07237</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Relevance based on Assessor Disagreement: Analysis and
  Practical Applications for Search Evaluation</dc:title>
 <dc:creator>Demeester, Thomas</dc:creator>
 <dc:creator>Aly, Robin</dc:creator>
 <dc:creator>Hiemstra, Djoerd</dc:creator>
 <dc:creator>Nguyen, Dong</dc:creator>
 <dc:creator>Develder, Chris</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Evaluation of search engines relies on assessments of search results for
selected test queries, from which we would ideally like to draw conclusions in
terms of relevance of the results for general (e.g., future, unknown) users. In
practice however, most evaluation scenarios only allow us to conclusively
determine the relevance towards the particular assessor that provided the
judgments. A factor that cannot be ignored when extending conclusions made from
assessors towards users, is the possible disagreement on relevance, assuming
that a single gold truth label does not exist. This paper presents and analyzes
the Predicted Relevance Model (PRM), which allows predicting a particular
result's relevance for a random user, based on an observed assessment and
knowledge on the average disagreement between assessors. With the PRM, existing
evaluation metrics designed to measure binary assessor relevance, can be
transformed into more robust and effectively graded measures that evaluate
relevance towards a random user. It also leads to a principled way of
quantifying multiple graded or categorical relevance levels for use as gains in
established graded relevance measures, such as normalized discounted cumulative
gain (nDCG), which nowadays often use heuristic and data-independent gain
values. Given a set of test topics with graded relevance judgments, the PRM
allows evaluating systems on different scenarios, such as their capability of
retrieving top results, or how well they are able to filter out non-relevant
ones. Its use in actual evaluation scenarios is illustrated on several
information retrieval test collections.
</dc:description>
 <dc:description>Comment: Accepted for publication in Springer Information Retrieval Journal,
  special issue on Information Retrieval Evaluation using Test Collections</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07237</dc:identifier>
 <dc:identifier>doi:10.1007/s10791-015-9275-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07247</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NetVLAD: CNN architecture for weakly supervised place recognition</dc:title>
 <dc:creator>Arandjelovi&#x107;, Relja</dc:creator>
 <dc:creator>Gronat, Petr</dc:creator>
 <dc:creator>Torii, Akihiko</dc:creator>
 <dc:creator>Pajdla, Tomas</dc:creator>
 <dc:creator>Sivic, Josef</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We tackle the problem of large scale visual place recognition, where the task
is to quickly and accurately recognize the location of a given query
photograph. We present the following three principal contributions. First, we
develop a convolutional neural network (CNN) architecture that is trainable in
an end-to-end manner directly for the place recognition task. The main
component of this architecture, NetVLAD, is a new generalized VLAD layer,
inspired by the &quot;Vector of Locally Aggregated Descriptors&quot; image representation
commonly used in image retrieval. The layer is readily pluggable into any CNN
architecture and amenable to training via backpropagation. Second, we develop a
training procedure, based on a new weakly supervised ranking loss, to learn
parameters of the architecture in an end-to-end manner from images depicting
the same places over time downloaded from Google Street View Time Machine.
Finally, we show that the proposed architecture significantly outperforms
non-learnt image representations and off-the-shelf CNN descriptors on two
challenging place recognition benchmarks, and improves over current
state-of-the-art compact image representations on standard image retrieval
benchmarks.
</dc:description>
 <dc:description>Comment: Appears in: IEEE Computer Vision and Pattern Recognition (CVPR) 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07249</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the total $(k,r)$-domination number of random graphs</dc:title>
 <dc:creator>Harutyunyan, Louisa</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A subset $S$ of a vertex set of a graph $G$ is a total $(k,r)$-dominating set
if every vertex $u \in V(G)$ is within distance $k$ of at least $r$ vertices in
$S$. The minimum cardinality among all total $(k,r)$-dominating sets of $G$ is
called the total $(k,r)$-domination number of $G$, denoted by
$\gamma^{t}_{(k,r)}(G)$. We previously gave an upper bound on
$\gamma^{t}_{(2,r)}(G(n,p))$ in random graphs with non-fixed $p \in (0,1)$. In
this paper we generalize this result to give an upper bound on
$\gamma^{t}_{(k,r)}(G(n,p))$ in random graphs with non-fixed $p \in (0,1)$ for
$k\geq 3$ as well as present an upper bound on $\gamma^{t}_{(k,r)}(G)$ in
graphs with large girth.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07261</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Python Extension for the Massively Parallel Multiphysics Simulation
  Framework waLBerla</dc:title>
 <dc:creator>Bauer, Martin</dc:creator>
 <dc:creator>Schornbaum, Florian</dc:creator>
 <dc:creator>Godenschwager, Christian</dc:creator>
 <dc:creator>Markl, Matthias</dc:creator>
 <dc:creator>Anderl, Daniela</dc:creator>
 <dc:creator>K&#xf6;stler, Harald</dc:creator>
 <dc:creator>R&#xfc;de, Ulrich</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  We present a Python extension to the massively parallel HPC simulation
toolkit waLBerla. waLBerla is a framework for stencil based algorithms
operating on block-structured grids, with the main application field being
fluid simulations in complex geometries using the lattice Boltzmann method.
Careful performance engineering results in excellent node performance and good
scalability to over 400,000 cores. To increase the usability and flexibility of
the framework, a Python interface was developed. Python extensions are used at
all stages of the simulation pipeline: They simplify and automate scenario
setup, evaluation, and plotting. We show how our Python interface outperforms
the existing text-file-based configuration mechanism, providing features like
automatic nondimensionalization of physical quantities and handling of complex
parameter dependencies. Furthermore, Python is used to process and evaluate
results while the simulation is running, leading to smaller output files and
the possibility to adjust parameters dependent on the current simulation state.
C++ data structures are exported such that a seamless interfacing to other
numerical Python libraries is possible. The expressive power of Python and the
performance of C++ make development of efficient code with low time effort
possible.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07261</dc:identifier>
 <dc:identifier>doi:10.1080/17445760.2015.1118478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07263</identifier>
 <datestamp>2016-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Input Sparsity Time Low-Rank Approximation via Ridge Leverage Score
  Sampling</dc:title>
 <dc:creator>Cohen, Michael B.</dc:creator>
 <dc:creator>Musco, Cameron</dc:creator>
 <dc:creator>Musco, Christopher</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a new algorithm for finding a near optimal low-rank approximation
of a matrix $A$ in $O(nnz(A))$ time. Our method is based on a recursive
sampling scheme for computing a representative subset of $A$'s columns, which
is then used to find a low-rank approximation.
  This approach differs substantially from prior $O(nnz(A))$ time algorithms,
which are all based on fast Johnson-Lindenstrauss random projections. It
matches the guarantees of these methods while offering a number of advantages.
  Not only are sampling algorithms faster for sparse and structured data, but
they can also be applied in settings where random projections cannot. For
example, we give new single-pass streaming algorithms for the column subset
selection and projection-cost preserving sample problems. Our method has also
been used to give the fastest algorithms for provably approximating kernel
matrices [MM16].
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07267</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Reasoning on Recursive Data-Structures with Sharing</dc:title>
 <dc:creator>Chu, Duc-Hiep</dc:creator>
 <dc:creator>Jaffar, Joxan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We consider the problem of automatically verifying programs which manipulate
arbitrary data structures. Our specification language is expressive, contains a
notion of \emph{separation}, and thus enables a precise specification of
\emph{frames}. The main contribution then is a program verification method
which combines strongest postcondition reasoning in the form symbolic
execution, unfolding recursive definitions of the data structure in question,
and a new frame rule to achieve \emph{local reasoning} so that proofs can be
compositional. Finally, we present an implementation of our verifier, and
demonstrate automation on a number of representative programs. In particular,
we present the first automatic proof of a classic graph marking algorithm,
paving the way for dealing with a class of programs which traverse a complex
data structure.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07271</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Omnidirectional Antenna Patterns, Received Power and Path
  Loss from Directional Antennas for 5G Millimeter-Wave Communications</dc:title>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Samimi, Mathew K.</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Omnidirectional path loss models are vital for radiosystem design in wireless
communication systems, as they allow engineers to perform network simulations
for systems with arbitrary antenna patterns. At millimeter-wave frequencies,
channel measurements are frequently conducted using steerable highgain
directional antennas at both the transmitter and receiver to make up for the
significant increase in free space path loss at these frequencies compared to
traditional cellular systems that operate at lower frequencies. The
omnidirectional antenna pattern, and resulting omnidirectional received power
must therefore be synthesized from many unique pointing angles, where the
transmit and receive antennas are rotated over many different azimuth and
elevation planes. In this paper, the equivalent omnidirectional antenna pattern
and omnidirectional received power are synthesized by summing the received
powers from all measured unique pointing angles obtained at antenna halfpower
beamwidth step increments in the azimuth and elevation planes, and this method
is validated by demonstrating that the synthesized omnidirectional received
power and path loss are independent of antenna beamwidth, through theoretical
analyses and millimeter-wave propagation measurements using antennas with
different beamwidths. The method in this paper is shown to provide accurate
results while enhancing the measurement range substantially through the use of
directional antennas.
</dc:description>
 <dc:description>Comment: to appear in IEEE Global Communications Conference (Globecom), Dec.
  2015</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07275</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Simple Algorithms from Examples</dc:title>
 <dc:creator>Zaremba, Wojciech</dc:creator>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Fergus, Rob</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an approach for learning simple algorithms such as copying,
multi-digit addition and single digit multiplication directly from examples.
Our framework consists of a set of interfaces, accessed by a controller.
Typical interfaces are 1-D tapes or 2-D grids that hold the input and output
data. For the controller, we explore a range of neural network-based models
which vary in their ability to abstract the underlying algorithm from training
instances and generalize to test examples with many thousands of digits. The
controller is trained using $Q$-learning with several enhancements and we show
that the bottleneck is in the capabilities of the controller rather than in the
search incurred by $Q$-learning.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07289</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Accurate Deep Network Learning by Exponential Linear Units
  (ELUs)</dc:title>
 <dc:creator>Clevert, Djork-Arn&#xe9;</dc:creator>
 <dc:creator>Unterthiner, Thomas</dc:creator>
 <dc:creator>Hochreiter, Sepp</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the &quot;exponential linear unit&quot; (ELU) which speeds up learning in
deep neural networks and leads to higher classification accuracies. Like
rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs
(PReLUs), ELUs alleviate the vanishing gradient problem via the identity for
positive values. However, ELUs have improved learning characteristics compared
to the units with other activation functions. In contrast to ReLUs, ELUs have
negative values which allows them to push mean unit activations closer to zero
like batch normalization but with lower computational complexity. Mean shifts
toward zero speed up learning by bringing the normal gradient closer to the
unit natural gradient because of a reduced bias shift effect. While LReLUs and
PReLUs have negative values, too, they do not ensure a noise-robust
deactivation state. ELUs saturate to a negative value with smaller inputs and
thereby decrease the forward propagated variation and information. Therefore,
ELUs code the degree of presence of particular phenomena in the input, while
they do not quantitatively model the degree of their absence. In experiments,
ELUs lead not only to faster learning, but also to significantly better
generalization performance than ReLUs and LReLUs on networks with more than 5
layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with
batch normalization while batch normalization does not improve ELU networks.
ELU networks are among the top 10 reported CIFAR-10 results and yield the best
published result on CIFAR-100, without resorting to multi-view evaluation or
model averaging. On ImageNet, ELU networks considerably speed up learning
compared to a ReLU network with the same architecture, obtaining less than 10%
classification error for a single crop, single model network.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07293</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Recovery via Partial Regularization: Models, Theory and
  Algorithms</dc:title>
 <dc:creator>Lu, Zhaosong</dc:creator>
 <dc:creator>Li, Xiaorui</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the context of sparse recovery, it is known that most of existing
regularizers such as $\ell_1$ suffer from some bias incurred by some leading
entries (in magnitude) of the associated vector. To neutralize this bias, we
propose a class of models with partial regularizers for recovering a sparse
solution of a linear system. We show that every local minimizer of these models
is sufficiently sparse or the magnitude of all its nonzero entries is above a
uniform constant depending only on the data of the linear system. Moreover, for
a class of partial regularizers, any global minimizer of these models is a
sparsest solution to the linear system. We also establish some sufficient
conditions for local or global recovery of the sparsest solution to the linear
system, among which one of the conditions is weaker than the best known
restricted isometry property (RIP) condition for sparse recovery by $\ell_1$.
In addition, a first-order feasible augmented Lagrangian (FAL) method is
proposed for solving these models, in which each subproblem is solved by a
nonmonotone proximal gradient (NPG) method. Despite the complication of the
partial regularizers, we show that each proximal subproblem in NPG can be
solved as a certain number of one-dimensional optimization problems, which
usually have a closed-form solution. We also show that any accumulation point
of the sequence generated by FAL is a first-order stationary point of the
models. Numerical results on compressed sensing and sparse logistic regression
demonstrate that the proposed models substantially outperform the widely used
ones in the literature in terms of solution quality.
</dc:description>
 <dc:description>Comment: 35 pages, 4 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07299</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rendering refraction and reflection of eyeglasses for synthetic eye
  tracker images</dc:title>
 <dc:creator>K&#xfc;bler, Thomas C.</dc:creator>
 <dc:creator>Rittig, Tobias</dc:creator>
 <dc:creator>Ungewiss, Judith</dc:creator>
 <dc:creator>Krauss, Christina</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While for the evaluation of robustness of eye tracking algorithms the use of
real-world data is essential, there are many applications where simulated,
synthetic eye images are of advantage. They can generate labelled ground-truth
data for appearance based gaze estimation algorithms or enable the development
of model based gaze estimation techniques by showing the influence on gaze
estimation error of different model factors that can then be simplified or
extended. We extend the generation of synthetic eye images by a simulation of
refraction and reflection for eyeglasses. On the one hand this allows for the
testing of pupil and glint detection algorithms under different illumination
and reflection conditions, on the other hand the error of gaze estimation
routines can be estimated in conjunction with different eyeglasses. We show how
a polynomial function fitting calibration performs equally well with and
without eyeglasses, and how a geometrical eye model behaves when exposed to
glasses.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07303</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Partitioning the Edges of 1-Plane Graphs</dc:title>
 <dc:creator>Lenhart, William J.</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A 1-plane graph is a graph embedded in the plane such that each edge is
crossed at most once. A 1-plane graph is optimal if it has maximum edge
density. A red-blue edge coloring of an optimal 1-plane graph $G$ partitions
the edge set of $G$ into blue edges and red edges such that no two blue edges
cross each other and no two red edges cross each other. We prove the following:
$(i)$ Every optimal 1-plane graph has a red-blue edge coloring such that the
blue subgraph is maximal planar while the red subgraph has vertex degree at
most four; this bound on the vertex degree is worst-case optimal. $(ii)$ A
red-blue edge coloring may not always induce a red forest of bounded vertex
degree. Applications of these results to graph augmentation and graph drawing
are also discussed.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07305</identifier>
 <datestamp>2016-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block Matrix Formulations for Evolving Networks</dc:title>
 <dc:creator>Fenu, Caterina</dc:creator>
 <dc:creator>Higham, Desmond J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>05C50, 15A69</dc:subject>
 <dc:description>  Many types of pairwise interaction take the form of a fixed set of nodes with
edges that appear and disappear over time. In the case of discrete-time
evolution, the resulting evolving network may be represented by a time-ordered
sequence of adjacency matrices. We consider here the issue of representing the
system as a single, higher dimensional block matrix, built from the individual
time-slices. We focus on the task of computing network centrality measures.
From a modeling perspective, we show that there is a suitable block formulation
that allows us to recover dynamic centrality measures respecting time's arrow.
From a computational perspective, we show that the new block formulation leads
to the design of more effective numerical algorithms.
</dc:description>
 <dc:description>Comment: 18 pages, 2 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07311</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Propagation Path Loss Models for 5G Urban Micro- and Macro-Cellular
  Scenarios</dc:title>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Thomas, Timothy A.</dc:creator>
 <dc:creator>Ghosh, Amitava</dc:creator>
 <dc:creator>Kovacs, Istvan Z.</dc:creator>
 <dc:creator>Rodriguez, Ignacio</dc:creator>
 <dc:creator>Koymen, Ozge</dc:creator>
 <dc:creator>Partyka, Andrzej</dc:creator>
 <dc:creator>Jarvelainen, Jan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents and compares two candidate large-scale propagation path
loss models, the alpha-beta-gamma (ABG) model and the close-in (CI) free space
reference distance model, for the design of fifth generation (5G) wireless
communication systems in urban micro- and macro-cellular scenarios. Comparisons
are made using the data obtained from 20 propagation measurement campaigns or
ray-tracing studies from 2 GHz to 73.5 GHz over distances ranging from 5 m to
1429 m. The results show that the one-parameter CI model has a very similar
goodness of fit (i.e., the shadow fading standard deviation) in both
line-of-sight and non-line-of-sight environments, while offering substantial
simplicity and more stable behavior across frequencies and distances, as
compared to the three-parameter ABG model. Additionally, the CI model needs
only one very subtle and simple modification to the existing 3GPP
floating-intercept path loss model (replacing a constant with a close-in free
space reference value) in order to provide greater simulation accuracy, more
simplicity, better repeatability across experiments, and higher stability
across a vast range of frequencies.
</dc:description>
 <dc:description>Comment: in 2016 IEEE 83rd Vehicular Technology Conference (VTC2016-Spring),
  May 2016, Nanjing, China</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07311</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2016.7504435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07312</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adapting the serial Alpgen event generator to simulate LHC collisions on
  millions of parallel threads</dc:title>
 <dc:creator>Childers, J. T.</dc:creator>
 <dc:creator>Uram, T. D.</dc:creator>
 <dc:creator>LeCompte, T. J.</dc:creator>
 <dc:creator>Papka, M. E.</dc:creator>
 <dc:creator>Benjamin, D. P.</dc:creator>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  As the LHC moves to higher energies and luminosity, the demand for computing
resources increases accordingly and will soon outpace the growth of the
Worldwide LHC Computing Grid. To meet this greater demand, event generation
Monte Carlo was targeted for adaptation to run on Mira, the supercomputer at
the Argonne Leadership Computing Facility. Alpgen is a Monte Carlo event
generation application that is used by LHC experiments in the simulation of
collisions that take place in the Large Hadron Collider. This paper details the
process by which Alpgen was adapted from a single-processor serial-application
to a large-scale parallel-application and the performance that was achieved.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, publication</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07312</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2016.09.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07314</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>1-perfectly orientable graphs and graph products</dc:title>
 <dc:creator>Hartinger, Tatiana Romina</dc:creator>
 <dc:creator>Milani&#x10d;, Martin</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C20, 05C76, 05C75</dc:subject>
 <dc:description>  A graph G is said to be 1-perfectly orientable (1-p.o. for short) if it
admits an orientation such that the out-neighborhood of every vertex is a
clique in G. The class of 1-p.o. graphs forms a common generalization of the
classes of chordal and circular arc graphs. Even though 1-p.o. graphs can be
recognized in polynomial time, no structural characterization of 1-p.o. graphs
is known. In this paper we consider the four standard graph products: the
Cartesian product, the strong product, the direct product, and the
lexicographic product. For each of them, we characterize when a nontrivial
product of two graphs is 1-p.o.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07316</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Complexity Detection Algorithm for the Primary Synchronization
  Signal in LTE</dc:title>
 <dc:creator>Nassralla, Mohammad H.</dc:creator>
 <dc:creator>Mansour, Mohammad M.</dc:creator>
 <dc:creator>Jalloul, Louay M. A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the challenging tasks in LTE baseband receiver design is
synchronization, which determines the symbol boundary and transmitted frame
start-time, and performs cell identification. Conventional algorithms are based
on correlation methods that involve a large number of multiplications and thus
lead to high receiver hardware complexity and power consumption. In this paper,
a hardware-efficient synchronization algorithm for frame timing based on
K-means clustering schemes is proposed. The algorithm reduces the complexity of
the primary synchronization signal for LTE from 24 complex-multiplications,
currently best known in the literature, to just 8. Simulation results
demonstrate that the proposed algorithm has negligible performance degradation
with reduced complexity relative to conventional techniques.
</dc:description>
 <dc:description>Comment: IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07316</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2015.2503606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07319</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Flagg and Friedman's Epistemic and Intuitionistic Formal
  Systems</dc:title>
 <dc:creator>Provetti, Alessandro</dc:creator>
 <dc:creator>Zucchellini, Andrea</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03F55</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We report our findings on the properties of Flagg and Friedman's translation
from Epistemic into Intuitionistic logic, which was proposed as the basis of a
comprehensive proof method for the faithfulness of the Goodel translation. We
focus on the propositional case and raise the issue of the admissibility of the
translated necessitation rule. Then, we contribute to Flagg and Friedman's
program by giving an explicit proof of the soundness of their translation.
</dc:description>
 <dc:description>Comment: Under evaluation by Annals of Pure and Applied Logic</dc:description>
 <dc:date>2015-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07337</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harnessing Mobile Phone Social Network Topology to Infer Users
  Demographic Attributes</dc:title>
 <dc:creator>Brea, Jorge</dc:creator>
 <dc:creator>Burroni, Javier</dc:creator>
 <dc:creator>Minnoni, Martin</dc:creator>
 <dc:creator>Sarraute, Carlos</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study the structure of the social graph of mobile phone users in the
country of Mexico, with a focus on demographic attributes of the users (more
specifically the users' age). We examine assortativity patterns in the graph,
and observe a strong age homophily in the communications preferences. We
propose a graph based algorithm for the prediction of the age of mobile phone
users. The algorithm exploits the topology of the mobile phone network,
together with a subset of known users ages (seeds), to infer the age of
remaining users. We provide the details of the methodology, and show
experimental results on a network GT with more than 70 million users. By
carefully examining the topological relations of the seeds to the rest of the
nodes in GT, we find topological metrics which have a direct influence on the
performance of the algorithm. In particular we characterize subsets of users
for which the accuracy of the algorithm is 62% when predicting between 4 age
categories (whereas a pure random guess would yield an accuracy of 25%). We
also show that we can use the probabilistic information computed by the
algorithm to further increase its inference power to 72% on a significant
subset of users.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07337</dc:identifier>
 <dc:identifier>Proceedings of the 8th Workshop on Social Network Mining and
  Analysis (SNAKDD 2014), New York City, USA, 24-27 August 2014, pp. 1-9</dc:identifier>
 <dc:identifier>doi:10.1145/2659480.2659492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07338</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instantaneous Relaying for the 3-Way Relay Channel with Circular Message
  Exchanges</dc:title>
 <dc:creator>Matthiesen, Bho</dc:creator>
 <dc:creator>Jorswieck, Eduard A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The 3-user discrete memoryless multi-way relay channel with circular message
exchange and instantaneous relaying is investigated. We first show that this
channel is effectively a 3-user interference channel with receiver message side
information for every fixed (and instantaneous) relay mapping. Then, we extend
the Han-Kobayashi coding scheme to this channel. Finally, we apply these
results to Gaussian channels with amplify-and-forward relaying and present
numerical results showing the gain of the proposed scheme compared to the state
of the art.
</dc:description>
 <dc:description>Comment: In Proceedings of the Forty-Ninth Asilomar Conference on Signals,
  Systems, and Computers, Nov. 2015, Pacific Grove, CA</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07338</dc:identifier>
 <dc:identifier>doi:10.1109/ACSSC.2015.7421173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07340</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Autoencoders for Ensemble Feature Extraction</dc:title>
 <dc:creator>Reeve, Henry W J</dc:creator>
 <dc:creator>Brown, Gavin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the concept of a Modular Autoencoder (MAE), capable of learning
a set of diverse but complementary representations from unlabelled data, that
can later be used for supervised tasks. The learning of the representations is
controlled by a trade off parameter, and we show on six benchmark datasets the
optimum lies between two extremes: a set of smaller, independent autoencoders
each with low capacity, versus a single monolithic encoding, outperforming an
appropriate baseline. In the present paper we explore the special case of
linear MAE, and derive an SVD-based algorithm which converges several orders of
magnitude faster than gradient descent.
</dc:description>
 <dc:description>Comment: 18 pages, 8 figures, to appear in a special issue of The Journal Of
  Machine Learning Research (vol.44, Dec 2015)</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07345</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter-Wave Distance-Dependent Large-Scale Propagation Measurements
  and Path Loss Models for Outdoor and Indoor 5G Systems</dc:title>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>MacCartney Jr., George R.</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents millimeter-wave propagation measurements for urban
micro-cellular and indoor office scenarios at 28 GHz and 73 GHz, and
investigates the corresponding path loss using five types of path loss models,
the singlefrequency floating-intercept (FI) model, single-frequency closein
(CI) free space reference distance model, multi-frequency alpha-beta-gamma
(ABG) model, multi-frequency CI model, and multi-frequency CI model with a
frequency-weighted path loss exponent (CIF), in both line-of-sight and
non-line-of-sight environments. Results show that the CI and CIF models provide
good estimation and exhibit stable behavior over frequencies and distances,
with a solid physical basis and less computational complexity when compared
with the FI and ABG models. Furthermore, path loss in outdoor scenarios shows
little dependence on frequency beyond the first meter of free space
propagation, whereas path loss tends to increase with frequency in addition to
the increased free space path loss in indoor environments. Therefore, the CI
model is suitable for outdoor environments over multiple frequencies, while the
CIF model is more appropriate for indoor modeling. This work shows that both
the CI and CIF models use fewer parameters and offer more convenient closedform
expressions suitable for analysis, without compromising model accuracy when
compared to current 3GPP and WINNER path loss models.
</dc:description>
 <dc:description>Comment: in the 10th European Conference on Antennas and Propagation, Davos,
  Switzerland, April 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07347</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Node Specificity in Convolutional Deep Nets Depends on Receptive Field
  Position and Size</dc:title>
 <dc:creator>Zipser, Karl</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In convolutional deep neural networks, receptive field (RF) size increases
with hierarchical depth. When RF size approaches full coverage of the input
image, different RF positions result in RFs with different specificity, as
portions of the RF fall out of the input space. This leads to a departure from
the convolutional concept of positional invariance and opens the possibility
for complex forms of context specificity.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07349</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOS-2: A Two-Dimension Space for Positioning MAS Organizational Models</dc:title>
 <dc:creator>Abbas, Hosny</dc:creator>
 <dc:creator>Shaheen, Samir</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The increased complexity and dynamism of present and future Multi-Agent
Systems (MAS) enforce the need for considering both of their static
(design-time) and the dynamic (run-time) aspects. A type of balance between the
two aspects can definitely give better results related to system stability and
adaptivity. MAS organization is the research area that is concerned with these
issues and it is currently a very active and interesting research area.
Designing a MAS with an initial organization and giving it the ability to
dynamically reorganize to adapt the dynamic changes of its unpredictable and
uncertain environment, is the feasible way to survive and to run effectively.
Normally, MAS organization is tackled by what is called, MAS organizational
models, which are concerned with the description (formally or informally) of
the structural and dynamical aspects of agent organizations. This paper
proposes a two-dimension space, called MOS-2, for positioning and assessing MAS
organizational models based on two dimensions: their adopted engineering
viewpoint (agent-centered or organization-centered) as the vertical dimension
and the agents awareness/unawareness of the existence of the organizational
level as the horizontal dimension. The MOS-2 space is applied for positioning a
number of familiar organizational models. Its future trends and possible
improvements are highlighted. They include the following, (1) adding Time as a
dimension, (2) increasing the considered dimensions, (3) providing a
quantitative approach for positioning MAS organizational models.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures in International Journal of Engineering Research
  and General Science (ISSN 2091-2730)</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07353</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dengue Fever in Perspective of Clustering Algorithms</dc:title>
 <dc:creator>Shaukat, Kamran</dc:creator>
 <dc:creator>Masood, Nayyer</dc:creator>
 <dc:creator>Shafaat, Ahmed Bin</dc:creator>
 <dc:creator>Jabbar, Kamran</dc:creator>
 <dc:creator>Shabbir, Hassan</dc:creator>
 <dc:creator>Shabbir, Shakir</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Dengue fever is a disease which is transmitted and caused by Aedes Aegypti
mosquitos. Dengue has become a serious health issue in all over the world
especially in those countries who are situated in tropical or subtropical
regions because rain is an important factor for growth and increase in the
population of dengue transmitting mosquitos. For a long time, data mining
algorithms have been used by the scientists for the diagnosis and prognosis of
different diseases which includes dengue as well. This was a study to analyses
the attack of dengue fever in different areas of district Jhelum, Pakistan in
2011. As per our knowledge, we are unaware of any kind of research study in the
area of district Jhelum for diagnosis or analysis of dengue fever. According to
our information, we are the first one researching and analyzing dengue fever in
this specific area. Dataset was obtained from the office of Executive District
Officer EDO (health) District Jhelum. We applied DBSCAN algorithm for the
clustering of dengue fever. First we showed overall behavior of dengue in the
district Jhelum. Then we explained dengue fever at tehsil level with the help
of geographical pictures. After that we have elaborated comparison of different
clustering algorithms with the help of graphs based on our dataset. Those
algorithms include k-means, K-mediods, DBSCAN and OPTICS.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07356</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation</dc:title>
 <dc:creator>Honari, Sina</dc:creator>
 <dc:creator>Yosinski, Jason</dc:creator>
 <dc:creator>Vincent, Pascal</dc:creator>
 <dc:creator>Pal, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks with alternating convolutional, max-pooling and
decimation layers are widely used in state of the art architectures for
computer vision. Max-pooling purposefully discards precise spatial information
in order to create features that are more robust, and typically organized as
lower resolution spatial feature maps. On some tasks, such as whole-image
classification, max-pooling derived features are well suited; however, for
tasks requiring precise localization, such as pixel level prediction and
segmentation, max-pooling destroys exactly the information required to perform
well. Precise localization may be preserved by shallow convnets without pooling
but at the expense of robustness. Can we have our max-pooled multi-layered cake
and eat it too? Several papers have proposed summation and concatenation based
methods for combining upsampled coarse, abstract features with finer features
to produce robust pixel level predictions. Here we introduce another model ---
dubbed Recombinator Networks --- where coarse features inform finer features
early in their formation such that finer features can make use of several
layers of computation in deciding how to use coarse features. The model is
trained once, end-to-end and performs better than summation-based
architectures, reducing the error from the previous state of the art on two
facial keypoint datasets, AFW and AFLW, by 30\% and beating the current
state-of-the-art on 300W without using extra data. We improve performance even
further by adding a denoising prediction model based on a novel convnet
formulation.
</dc:description>
 <dc:description>Comment: accepted in CVPR 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07357</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximity in the Age of Distraction: Robust Approximate Nearest Neighbor
  Search</dc:title>
 <dc:creator>Har-Peled, Sariel</dc:creator>
 <dc:creator>Mahabadi, Sepideh</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We introduce a new variant of the nearest neighbor search problem, which
allows for some coordinates of the dataset to be arbitrarily corrupted or
unknown. Formally, given a dataset of $n$ points $P=\{ x_1,\ldots, x_n\}$ in
high-dimensions, and a parameter $k$, the goal is to preprocess the dataset,
such that given a query point $q$, one can compute quickly a point $x \in P$,
such that the distance of the query to the point $x$ is minimized, when
ignoring the &quot;optimal&quot; $k$ coordinates. Note, that the coordinates being
ignored are a function of both the query point and the point returned.
  We present a general reduction from this problem to answering ANN queries,
which is similar in spirit to LSH (locality sensitive hashing) [IM98].
Specifically, we give a sampling technique which achieves a bi-criterion
approximation for this problem. If the distance to the nearest neighbor after
ignoring $k$ coordinates is $r$, the data-structure returns a point that is
within a distance of $O(r)$ after ignoring $O(k)$ coordinates. We also present
other applications and further extensions and refinements of the above result.
  The new data-structures are simple and (arguably) elegant, and should be
practical -- specifically, all bounds are polynomial in all relevant parameters
(including the dimension of the space, and the robustness parameter $k$).
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07361</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpretable Two-level Boolean Rule Learning for Classification</dc:title>
 <dc:creator>Su, Guolong</dc:creator>
 <dc:creator>Wei, Dennis</dc:creator>
 <dc:creator>Varshney, Kush R.</dc:creator>
 <dc:creator>Malioutov, Dmitry M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes algorithms for learning two-level Boolean rules in
Conjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF,
i.e. OR-of-ANDs) as a type of human-interpretable classification model, aiming
for a favorable trade-off between the classification accuracy and the
simplicity of the rule. Two formulations are proposed. The first is an integer
program whose objective function is a combination of the total number of errors
and the total number of features used in the rule. We generalize a previously
proposed linear programming (LP) relaxation from one-level to two-level rules.
The second formulation replaces the 0-1 classification error with the Hamming
distance from the current two-level rule to the closest rule that correctly
classifies a sample. Based on this second formulation, block coordinate descent
and alternating minimization algorithms are developed. Experiments show that
the two-level rules can yield noticeably better performance than one-level
rules due to their dramatically larger modeling capacity, and the two
algorithms based on the Hamming distance formulation are generally superior to
the other two-level rule learning methods in our comparison. A proposed
approach to binarize any fractional values in the optimal solutions of LP
relaxations is also shown to be effective.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07361</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07373</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What is the plausibility of probability?(revised 2003, 2015)</dc:title>
 <dc:creator>Arnborg, Stefan</dc:creator>
 <dc:creator>Sj&#xf6;din, Gunnar</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>62A01</dc:subject>
 <dc:description>  We present and examine a result related to uncertainty reasoning, namely that
a certain plausibility space of Cox's type can be uniquely embedded in a
minimal ordered field. This, although a purely mathematical result, can be
claimed to imply that every rational method to reason with uncertainty must be
based on sets of extended probability distributions, where extended probability
is standard probability extended with infinitesimals.
  This claim must be supported by some argumentation of non-mathematical type,
however, since pure mathematics does not tell us anything about the world. We
propose one such argumentation, and relate it to results from the literature of
uncertainty and statistics.
  In an added retrospective section we discuss some developments in the area
regarding countable additivity, partially ordered domains and robustness, and
philosophical stances on the Cox/Jaynes approach since 2003. We also show that
the most general partially ordered plausibility calculus embeddable in a ring
can be represented as a set of extended probability distributions or, in
algebraic terms, is a subdirect sum of ordered fields. In other words, the
robust Bayesian approach is universal. This result is exemplified by relating
Dempster-Shafer's evidence theory to robust Bayesian analysis.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07374</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path Loss, Shadow Fading, and Line-Of-Sight Probability Models for 5G
  Urban Macro-Cellular Scenarios</dc:title>
 <dc:creator>Sun, Shu</dc:creator>
 <dc:creator>Thomas, Timothy A.</dc:creator>
 <dc:creator>Rappaport, Theodore S.</dc:creator>
 <dc:creator>Nguyen, Huan</dc:creator>
 <dc:creator>Kovacs, Istvan Z.</dc:creator>
 <dc:creator>Rodrigue, Ignacio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents key parameters including the line-of-sight (LOS)
probability, large-scale path loss, and shadow fading models for the design of
future fifth generation (5G) wireless communication systems in urban
macro-cellular (UMa) scenarios, using the data obtained from propagation
measurements at 38 GHz in Austin, US, and at 2, 10, 18, and 28 GHz in Aalborg,
Denmark. A comparison of different LOS probability models is performed for the
Aalborg environment. Alpha-betagamma and close-in reference distance path loss
models are studied in depth to show their value in channel modeling.
Additionally, both single-slope and dual-slope omnidirectional path loss models
are investigated to analyze and contrast their root-mean-square (RMS) errors on
measured path loss values. While the results show that the dual-slope
large-scale path loss model can slightly reduce RMS errors compared to its
singleslope counterpart in non-line-of-sight (NLOS) conditions, the improvement
is not significant enough to warrant adopting the dual-slope path loss model.
Furthermore, the shadow fading magnitude versus distance is explored, showing a
slight increasing trend in LOS and a decreasing trend in NLOS based on the
Aalborg data, but more measurements are necessary to gain a better knowledge of
the UMa channels at centimeter- and millimeter-wave frequency bands.
</dc:description>
 <dc:description>Comment: to appear in proceedings of IEEE Global Communications Conference
  Workshop, Dec. 2015</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07374</dc:identifier>
 <dc:identifier>doi:10.1109/GLOCOMW.2015.7414036</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07376</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNNdroid: GPU-Accelerated Execution of Trained Deep Convolutional Neural
  Networks on Android</dc:title>
 <dc:creator>Oskouei, Seyyed Salar Latifi</dc:creator>
 <dc:creator>Golestani, Hossein</dc:creator>
 <dc:creator>Hashemi, Matin</dc:creator>
 <dc:creator>Ghiasi, Soheil</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many mobile applications running on smartphones and wearable devices would
potentially benefit from the accuracy and scalability of deep CNN-based machine
learning algorithms. However, performance and energy consumption limitations
make the execution of such computationally intensive algorithms on mobile
devices prohibitive. We present a GPU-accelerated library, dubbed CNNdroid, for
execution of trained deep CNNs on Android-based mobile devices. Empirical
evaluations show that CNNdroid achieves up to 60X speedup and 130X energy
saving on current mobile devices. The CNNdroid open source library is available
for download at https://github.com/ENCP/CNNdroid
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07376</dc:identifier>
 <dc:identifier>Proceedings of the 2016 ACM Multimedia Conference, Open Source
  Software Track, pages 1201-1205, October 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2964284.2973801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07386</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pushing the Boundaries of Boundary Detection using Deep Learning</dc:title>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work we show that adapting Deep Convolutional Neural Network training
to the task of boundary detection can result in substantial improvements over
the current state-of-the-art in boundary detection.
  Our contributions consist firstly in combining a careful design of the loss
for boundary detection training, a multi-resolution architecture and training
with external data to improve the detection accuracy of the current state of
the art. When measured on the standard Berkeley Segmentation Dataset, we
improve theoptimal dataset scale F-measure from 0.780 to 0.808 - while human
performance is at 0.803. We further improve performance to 0.813 by combining
deep learning with grouping, integrating the Normalized Cuts technique within a
deep network.
  We also examine the potential of our boundary detector in conjunction with
the task of semantic segmentation and demonstrate clear improvements over
state-of-the-art systems. Our detector is fully integrated in the popular Caffe
framework and processes a 320x420 image in less than a second.
</dc:description>
 <dc:description>Comment: The previous version reported large improvements w.r.t. the LPO
  region proposal baseline, which turned out to be due to a wrong computation
  for the baseline. The improvements are currently less important, and are
  omitted. We are sorry if the reported results caused any confusion. We have
  also integrated reviewer feedback regarding human performance on the BSD
  benchmark</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07392</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache Miss Estimation for Non-Stationary Request Processes</dc:title>
 <dc:creator>Olmos, Felipe</dc:creator>
 <dc:creator>Graham, Carl</dc:creator>
 <dc:creator>Simonian, Alain</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The aim of the paper is to evaluate the miss probability of a Least Recently
Used (LRU) cache, when it is offered a non-stationary request process given by
a Poisson cluster point process. First, we construct a probability space using
Palm theory, describing how to consider a tagged document with respect to the
rest of the request process. This framework allows us to derive a general
integral formula for the expected number of misses of the tagged document.
Then, we consider the limit when the cache size and the arrival rate go to
infinity proportionally, and use the integral formula to derive an asymptotic
expansion of the miss probability in powers of the inverse of the cache size.
This enables us to quantify and improve the accuracy of the so-called Che
approximation.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07394</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Where To Look: Focus Regions for Visual Question Answering</dc:title>
 <dc:creator>Shih, Kevin J.</dc:creator>
 <dc:creator>Singh, Saurabh</dc:creator>
 <dc:creator>Hoiem, Derek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a method that learns to answer visual questions by selecting image
regions relevant to the text-based query. Our method exhibits significant
improvements in answering questions such as &quot;what color,&quot; where it is necessary
to evaluate a specific location, and &quot;what room,&quot; where it selectively
identifies informative image regions. Our model is tested on the VQA dataset
which is the largest human-annotated visual question answering dataset to our
knowledge.
</dc:description>
 <dc:description>Comment: Submitted to CVPR2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07397</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ad auctions and cascade model: GSP inefficiency and algorithms</dc:title>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:creator>Gatti, Nicola</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The design of the best economic mechanism for Sponsored Search Auctions
(SSAs) is a central task in computational mechanism design/game theory. Two
open questions concern the adoption of user models more accurate than that one
currently used and the choice between Generalized Second Price auction (GSP)
and Vickrey-Clark-Groves mechanism (VCG). In this paper, we provide some
contributions to answer these questions. We study Price of Anarchy (PoA) and
Price of Stability (PoS) over social welfare and auctioneer's revenue of GSP
w.r.t. the VCG when the users follow the famous cascade model. Furthermore, we
provide exact, randomized, and approximate algorithms, showing that in
real-world settings (Yahoo! Webscope A3 dataset, 10 available slots) optimal
allocations can be found in less than 1s with up to 1000 ads, and can be
approximated in less than 20ms even with more than 1000 ads with an average
accuracy greater than 99%.
</dc:description>
 <dc:description>Comment: AAAI16, to appear</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07401</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MazeBase: A Sandbox for Learning from Games</dc:title>
 <dc:creator>Sukhbaatar, Sainbayar</dc:creator>
 <dc:creator>Szlam, Arthur</dc:creator>
 <dc:creator>Synnaeve, Gabriel</dc:creator>
 <dc:creator>Chintala, Soumith</dc:creator>
 <dc:creator>Fergus, Rob</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  This paper introduces MazeBase: an environment for simple 2D games, designed
as a sandbox for machine learning approaches to reasoning and planning. Within
it, we create 10 simple games embodying a range of algorithmic tasks (e.g.
if-then statements or set negation). A variety of neural models (fully
connected, convolutional network, memory network) are deployed via
reinforcement learning on these games, with and without a procedurally
generated curriculum. Despite the tasks' simplicity, the performance of the
models is far from optimal, suggesting directions for future development. We
also demonstrate the versatility of MazeBase by using it to emulate small
combat scenarios from StarCraft. Models trained on the MazeBase version can be
directly applied to StarCraft, where they consistently beat the in-game AI.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07404</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Visual Predictive Models of Physics for Playing Billiards</dc:title>
 <dc:creator>Fragkiadaki, Katerina</dc:creator>
 <dc:creator>Agrawal, Pulkit</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to plan and execute goal specific actions in varied, unexpected
settings is a central requirement of intelligent agents. In this paper, we
explore how an agent can be equipped with an internal model of the dynamics of
the external world, and how it can use this model to plan novel actions by
running multiple internal simulations (&quot;visual imagination&quot;). Our models
directly process raw visual input, and use a novel object-centric prediction
formulation based on visual glimpses centered on objects (fixations) to enforce
translational invariance of the learned physical laws. The agent gathers
training data through random interaction with a collection of different
environments, and the resulting model can then be used to plan goal-directed
actions in novel environments that the agent has not seen before. We
demonstrate that our agent can accurately plan actions for playing a simulated
billiards game, which requires pushing a ball into a target position or into
collision with another ball.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07409</identifier>
 <datestamp>2016-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Top-Down Learning for Structured Labeling with Convolutional Pseudoprior</dc:title>
 <dc:creator>Xie, Saining</dc:creator>
 <dc:creator>Huang, Xun</dc:creator>
 <dc:creator>Tu, Zhuowen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Current practice in convolutional neural networks (CNN) remains largely
bottom-up and the role of top-down process in CNN for pattern analysis and
visual inference is not very clear. In this paper, we propose a new method for
structured labeling by developing convolutional pseudo-prior (ConvPP) on the
ground-truth labels. Our method has several interesting properties: (1)
compared with classical machine learning algorithms like CRFs and Structural
SVM, ConvPP automatically learns rich convolutional kernels to capture both
short- and long- range contexts; (2) compared with cascade classifiers like
Auto-Context, ConvPP avoids the iterative steps of learning a series of
discriminative classifiers and automatically learns contextual configurations;
(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPP
learns convolution in the labeling space with much improved modeling capability
and less manual specification; (4) compared with Bayesian models like MRFs,
ConvPP capitalizes on the rich representation power of convolution by
automatically learning priors built on convolutional filters. We accomplish our
task using pseudo-likelihood approximation to the prior under a novel
fixed-point network structure that facilitates an end-to-end learning process.
We show state-of-the-art results on sequential labeling and image labeling
benchmarks.
</dc:description>
 <dc:description>Comment: To appear in ECCV 2016, 16 pages, 6 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07412</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Algorithms for Route Planning with Nonlinear Objectives</dc:title>
 <dc:creator>Yang, Ger</dc:creator>
 <dc:creator>Nikolova, Evdokia</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider optimal route planning when the objective function is a general
nonlinear and non-monotonic function. Such an objective models user behavior
more accurately, for example, when a user is risk-averse, or the utility
function needs to capture a penalty for early arrival. It is known that as
nonlinearity arises, the problem becomes NP-hard and little is known about
computing optimal solutions when in addition there is no monotonicity
guarantee. We show that an approximately optimal non-simple path can be
efficiently computed under some natural constraints. In particular, we provide
a fully polynomial approximation scheme under hop constraints. Our
approximation algorithm can extend to run in pseudo-polynomial time under a
more general linear constraint that sometimes is useful. As a by-product, we
show that our algorithm can be applied to the problem of finding a path that is
most likely to be on time for a given deadline.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figures, main part of this paper is to be appear in
  AAAI'16</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07423</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Total Busy Time for Energy-Aware Virtual Machine Allocation
  Problems</dc:title>
 <dc:creator>Quang-Hung, Nguyen</dc:creator>
 <dc:creator>Thoai, Nam</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.2.4, C.4, D.4</dc:subject>
 <dc:description>  This paper investigates the energy-aware virtual machine (VM) allocation
problems in clouds along characteristics: multiple resources, fixed interval
time and non-preemption of virtual machines. Many previous works have been
proposed to use a minimum number of physical machines, however, this is not
necessarily a good solution to minimize total energy consumption in the VM
placement with multiple resources, fixed interval time and non-preemption. We
observed that minimizing the sum of total busy time of all physical machines
implies minimizing total energy consumption of physical machines. In addition
to, if mapping of a VM onto physical machines have the same total busy time
then the best mapping has physical machine's remaining available resource
minimizing. Based on these observations, we proposed heuristic-based EM
algorithm to solve the energy-aware VM allocation with fixed starting time and
duration time. In addition, this work studies some heuristics for sorting the
list of virtual machines (e.g., sorting by the earliest starting time, or
latest finishing time, or the longest duration time first, etc.) to allocate
VM. We evaluate the EM using CloudSim toolkit and jobs log-traces in the
Feitelson's Parallel Workloads Archive. Simulation's results show that all of
EM-ST, EM-LFT and EM-LDTF algorithms could reduce total energy consumption
compared to state-of-the-art of power-aware VM allocation algorithms. (e.g.
Power-Aware Best-Fit Decreasing (PABFD) [7])).
</dc:description>
 <dc:description>Comment: 8 pages, Proceedings of the Sixth International Symposium on
  Information and Communication Technology. arXiv admin note: substantial text
  overlap with arXiv:1511.06825</dc:description>
 <dc:date>2015-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07425</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Anomalous Behavior Detection and Localization in Crowded
  Scenes</dc:title>
 <dc:creator>Sabokrou, Mohammad</dc:creator>
 <dc:creator>Fathy, Mahmood</dc:creator>
 <dc:creator>Hosseini, Mojtaba</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an accurate and real-time anomaly detection and
localization in crowded scenes, and two descriptors for representing anomalous
behavior in video are proposed. We consider a video as being a set of cubic
patches. Based on the low likelihood of an anomaly occurrence, and the
redundancy of structures in normal patches in videos, two (global and local)
views are considered for modeling the video. Our algorithm has two components,
for (1) representing the patches using local and global descriptors, and for
(2) modeling the training patches using a new representation. We have two
Gaussian models for all training patches respect to global and local
descriptors. The local and global features are based on structure similarity
between adjacent patches and the features that are learned in an unsupervised
way. We propose a fusion strategy to combine the two descriptors as the output
of our system. Experimental results show that our algorithm performs like a
state-of-the-art method on several standard datasets, but even is more
time-efficient.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to some error in
  experimental result. There are some mistakes</dc:description>
 <dc:date>2015-11-21</dc:date>
 <dc:date>2016-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07469</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Allocation and Outage Analysis for An Adaptive Cognitive
  Two-Way Relay Network</dc:title>
 <dc:creator>Li, Qunwei</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, an adaptive two-way relay cooperation scheme is studied for
multiple-relay cognitive radio networks to improve the performance of secondary
transmissions. The power allocation and relay selection schemes are derived to
minimize the secondary outage probability where only statistical channel
information is needed. Exact closed-form expressions for secondary outage
probability are derived under a constraint on the quality of service of primary
transmissions in terms of the required primary outage probability. To better
understand the impact of primary user interference on secondary transmissions,
we further investigate the asymptotic behaviors of the secondary relay network
including power allocation and outage probability, when the primary
signal-to-noise ratio goes to infinity. Simulation results are provided to
illustrate the performance of the proposed schemes.
</dc:description>
 <dc:description>Comment: accepted for publication in IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07469</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2702170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07471</identifier>
 <datestamp>2017-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Convergence Properties of Constrained Emphatic Temporal-difference
  Learning with Constant and Slowly Diminishing Stepsize</dc:title>
 <dc:creator>Yu, Huizhen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>90C40, 62L20, 68W40</dc:subject>
 <dc:description>  We consider the emphatic temporal-difference (TD) algorithm, ETD($\lambda$),
for learning the value functions of stationary policies in a discounted, finite
state and action Markov decision process. The ETD($\lambda$) algorithm was
recently proposed by Sutton, Mahmood, and White to solve a long-standing
divergence problem of the standard TD algorithm when it is applied to
off-policy training, where data from an exploratory policy are used to evaluate
other policies of interest. The almost sure convergence of ETD($\lambda$) has
been proved in our recent work under general off-policy training conditions,
but for a narrow range of diminishing stepsize. In this paper we present
convergence results for constrained versions of ETD($\lambda$) with constant
stepsize and with diminishing stepsize from a broad range. Our results
characterize the asymptotic behavior of the trajectory of iterates produced by
those algorithms, and are derived by combining key properties of ETD($\lambda$)
with powerful convergence theorems from the weak convergence methods in
stochastic approximation theory. For the case of constant stepsize, in addition
to analyzing the behavior of the algorithms in the limit as the stepsize
parameter approaches zero, we also analyze their behavior for a fixed stepsize
and bound the deviations of their averaged iterates from the desired solution.
These results are obtained by exploiting the weak Feller property of the Markov
chains associated with the algorithms, and by using ergodic theorems for weak
Feller Markov chains, in conjunction with the convergence results we get from
the weak convergence methods. Besides ETD($\lambda$), our analysis also applies
to the off-policy TD($\lambda$) algorithm, when the divergence issue is avoided
by setting $\lambda$ sufficiently large.
</dc:description>
 <dc:description>Comment: Minor edits; 53 pages. Longer and more proof details than the journal
  version</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07471</dc:identifier>
 <dc:identifier>Journal of Machine Learning Research, 17(220):1-58, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07480</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parity Separation: A Scientifically Proven Method for Permanent Weight
  Loss</dc:title>
 <dc:creator>Curticapean, Radu</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Given an edge-weighted graph G, let PerfMatch(G) denote the weighted sum over
all perfect matchings M in G, weighting each matching M by the product of
weights of edges in M. If G is unweighted, this plainly counts the perfect
matchings of G.
  In this paper, we introduce parity separation, a new method for reducing
PerfMatch to unweighted instances: For graphs G with edge-weights -1 and 1, we
construct two unweighted graphs G1 and G2 such that PerfMatch(G) =
PerfMatch(G1) - PerfMatch(G2). This yields a novel weight removal technique for
counting perfect matchings, in addition to those known from classical
#P-hardness proofs. We derive the following applications:
  1. An alternative #P-completeness proof for counting unweighted perfect
matchings.
  2. C=P-completeness for deciding whether two given unweighted graphs have the
same number of perfect matchings. To the best of our knowledge, this is the
first C=P-completeness result for the &quot;equality-testing version&quot; of any natural
counting problem that is not already #P-hard under parsimonious reductions.
  3. An alternative tight lower bound for counting unweighted perfect matchings
under the counting exponential-time hypothesis #ETH.
  Our technique is based upon matchgates and the Holant framework. To make our
#P-hardness proof self-contained, we also apply matchgates for an alternative
#P-hardness proof of PerfMatch on graphs with edge-weights -1 and 1.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07487</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing How People Orient to and Spread Rumours in Social Media by
  Looking at Conversational Threads</dc:title>
 <dc:creator>Zubiaga, Arkaitz</dc:creator>
 <dc:creator>Liakata, Maria</dc:creator>
 <dc:creator>Procter, Rob</dc:creator>
 <dc:creator>Hoi, Geraldine Wong Sak</dc:creator>
 <dc:creator>Tolmie, Peter</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  As breaking news unfolds people increasingly rely on social media to stay
abreast of the latest updates. The use of social media in such situations comes
with the caveat that new information being released piecemeal may encourage
rumours, many of which remain unverified long after their point of release.
Little is known, however, about the dynamics of the life cycle of a social
media rumour. In this paper we present a methodology that has enabled us to
collect, identify and annotate a dataset of 330 rumour threads (4,842 tweets)
associated with 9 newsworthy events. We analyse this dataset to understand how
users spread, support, or deny rumours that are later proven true or false, by
distinguishing two levels of status in a rumour life cycle i.e., before and
after its veracity status is resolved. The identification of rumours associated
with each event, as well as the tweet that resolved each rumour as true or
false, was performed by a team of journalists who tracked the events in real
time. Our study shows that rumours that are ultimately proven true tend to be
resolved faster than those that turn out to be false. Whilst one can readily
see users denying rumours once they have been debunked, users appear to be less
capable of distinguishing true from false rumours when their veracity remains
in question. In fact, we show that the prevalent tendency for users is to
support every unverified rumour. We also analyse the role of different types of
users, finding that highly reputable users such as news organisations endeavour
to post well-grounded statements, which appear to be certain and accompanied by
evidence. Nevertheless, these often prove to be unverified pieces of
information that give rise to false rumours. Our study reinforces the need for
developing robust machine learning techniques that can provide assistance for
assessing the veracity of rumours.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07487</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0150989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07488</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding Reed-Muller codes over product sets</dc:title>
 <dc:creator>Kim, John</dc:creator>
 <dc:creator>Kopparty, Swastik</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We give a polynomial time algorithm to decode multivariate polynomial codes
of degree $d$ up to half their minimum distance, when the evaluation points are
an arbitrary product set $S^m$, for every $d &lt; |S|$. Previously known
algorithms can achieve this only if the set $S$ has some very special algebraic
structure, or if the degree $d$ is significantly smaller than $|S|$. We also
give a near-linear time randomized algorithm, which is based on tools from
list-decoding, to decode these codes from nearly half their minimum distance,
provided $d &lt; (1-\epsilon)|S|$ for constant $\epsilon &gt; 0$.
  Our result gives an $m$-dimensional generalization of the well known decoding
algorithms for Reed-Solomon codes, and can be viewed as giving an algorithmic
version of the Schwartz-Zippel lemma.
</dc:description>
 <dc:description>Comment: 25 pages, 0 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07494</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An approximation algorithm for Uniform Capacitated k-Median problem with
  1 + {\epsilon} capacity violation</dc:title>
 <dc:creator>Byrka, Jaros&#x142;aw</dc:creator>
 <dc:creator>Rybicki, Bartosz</dc:creator>
 <dc:creator>Uniyal, Sumedha</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the Capacitated k-Median problem, for which all the known constant
factor approximation algorithms violate either the number of facilities or the
capacities. While the standard LP-relaxation can only be used for algorithms
violating one of the two by a factor of at least two, Shi Li [SODA'15, SODA'16]
gave algorithms violating the number of facilities by a factor of 1+{\epsilon}
exploring properties of extended relaxations.
  In this paper we develop a constant factor approximation algorithm for
Uniform Capacitated k-Median violating only the capacities by a factor of
1+{\epsilon}. The algorithm is based on a configuration LP. Unlike in the
algorithms violating the number of facilities, we cannot simply open extra few
facilities at selected locations. Instead, our algorithm decides about the
facility openings in a carefully designed dependent rounding process.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07497</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Structured Regression with Convolutional Neural Networks</dc:title>
 <dc:creator>Pathak, Deepak</dc:creator>
 <dc:creator>Kr&#xe4;henb&#xfc;hl, Philipp</dc:creator>
 <dc:creator>Yu, Stella X.</dc:creator>
 <dc:creator>Darrell, Trevor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) have recently emerged as the dominant
model in computer vision. If provided with enough training data, they predict
almost any visual quantity. In a discrete setting, such as classification, CNNs
are not only able to predict a label but often predict a confidence in the form
of a probability distribution over the output space. In continuous regression
tasks, such a probability estimate is often lacking. We present a regression
framework which models the output distribution of neural networks. This output
distribution allows us to infer the most likely labeling following a set of
physical or modeling constraints. These constraints capture the intricate
interplay between different input and output variables, and complement the
output of a CNN. However, they may not hold everywhere. Our setup further
allows to learn a confidence with which a constraint holds, in the form of a
distribution of the constrain satisfaction. We evaluate our approach on the
problem of intrinsic image decomposition, and show that constrained structured
regression significantly increases the state-of-the-art.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07499</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Optimal Feedback Rate in Interference-Limited Multi-Antenna
  Cellular Systems</dc:title>
 <dc:creator>Park, Jeonghun</dc:creator>
 <dc:creator>Lee, Namyoon</dc:creator>
 <dc:creator>Andrews, Jeffrey G.</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a downlink cellular network where multi-antenna base stations
(BSs) transmit data to single-antenna users by using one of two linear
precoding methods with limited feedback: (i) maximum ratio transmission (MRT)
for serving a single user or (ii) zero forcing (ZF) for serving multiple users.
The BS and user locations are drawn from a Poisson point process, allowing
expressions for the signal- to-interference coverage probability and the
ergodic spectral efficiency to be derived as a function of system parameters
such as the number of BS antennas and feedback bits, and the pathloss exponent.
We find a tight lower bound on the optimum number of feedback bits to maximize
the net spectral efficiency, which captures the overall system gain by
considering both of downlink and uplink spectral efficiency using limited
feedback. Our main finding is that, when using MRT, the optimum number of
feedback bits scales linearly with the number of antennas, and logarithmically
with the channel coherence time. When using ZF, the feedback scales in the same
ways as MRT, but also linearly with the pathloss exponent. The derived results
provide system-level insights into the preferred channel codebook size by
averaging the effects of short-term fading and long-term pathloss.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07499</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2569089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07500</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Planning in the Wild: Modeling Tools for PDDL</dc:title>
 <dc:creator>Strobel, Volker</dc:creator>
 <dc:creator>Kirsch, Alexandra</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Even though there are sophisticated AI planning algorithms, many integrated,
large-scale projects do not use planning. One reason seems to be the missing
support by engineering tools such as syntax highlighting and visualization. We
propose myPDDL - a modular toolbox for efficiently creating PDDL domains and
problems. To evaluate myPDDL, we compare it to existing knowledge engineering
tools for PDDL and experimentally assess its usefulness for novice PDDL users.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07500</dc:identifier>
 <dc:identifier>Strobel, Volker, and Alexandra Kirsch. &quot;Planning in the Wild:
  Modeling Tools for PDDL.&quot; KI 2014: Advances in Artificial Intelligence.
  Springer International Publishing, 2014. 273-284</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-11206-0_27</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07519</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does the Internet deserve everybody?</dc:title>
 <dc:creator>Elkhatib, Yehia</dc:creator>
 <dc:creator>Tyson, Gareth</dc:creator>
 <dc:creator>Sathiaseelan, Arjuna</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There has been a long standing tradition amongst developed nations of
influencing, both directly and indirectly, the activities of developing
economies. Behind this is one of a range of aims: building/improving living
standards, bettering the social status of recipient communities, etc. In some
cases, this has resulted in prosperous relations, yet often this has been seen
as the exploitation of a power position or a veneer for other activities (e.g.
to tap into new emerging markets). In this paper, we explore whether
initiatives to improve Internet connectivity in developing regions are always
ethical. We draw a list of issues that would aid in formulating Internet
initiatives that are ethical, effective, and sustainable.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07519</dc:identifier>
 <dc:identifier>Proceedings of the 2015 ACM SIGCOMM Workshop on Ethics in
  Networked Systems Research</dc:identifier>
 <dc:identifier>doi:10.1145/2793013.2793018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07521</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A review and evaluation of numerical tools for fractional calculus and
  fractional order control</dc:title>
 <dc:creator>Li, Zhuo</dc:creator>
 <dc:creator>Liu, Lu</dc:creator>
 <dc:creator>Dehghan, Sina</dc:creator>
 <dc:creator>Chen, YangQuan</dc:creator>
 <dc:creator>Xue, Dingyu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In recent years, as fractional calculus becomes more and more broadly used in
research across different academic disciplines, there are increasing demands
for the numerical tools for the computation of fractional
integration/differentiation, and the simulation of fractional order systems.
Time to time, being asked about which tool is suitable for a specific
application, the authors decide to carry out this survey to present
recapitulative information of the available tools in the literature, in hope of
benefiting researchers with different academic backgrounds. With this
motivation, the present article collects the scattered tools into a dashboard
view, briefly introduces their usage and algorithms, evaluates the accuracy,
compares the performance, and provides informative comments for selection.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07521</dc:identifier>
 <dc:identifier>doi:10.1080/00207179.2015.1124290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07527</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tradeoffs for nearest neighbors on the sphere</dc:title>
 <dc:creator>Laarhoven, Thijs</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We consider tradeoffs between the query and update complexities for the
(approximate) nearest neighbor problem on the sphere, extending the recent
spherical filters to sparse regimes and generalizing the scheme and analysis to
account for different tradeoffs. In a nutshell, for the sparse regime the
tradeoff between the query complexity $n^{\rho_q}$ and update complexity
$n^{\rho_u}$ for data sets of size $n$ is given by the following equation in
terms of the approximation factor $c$ and the exponents $\rho_q$ and $\rho_u$:
$$c^2\sqrt{\rho_q}+(c^2-1)\sqrt{\rho_u}=\sqrt{2c^2-1}.$$
  For small $c=1+\epsilon$, minimizing the time for updates leads to a linear
space complexity at the cost of a query time complexity $n^{1-4\epsilon^2}$.
Balancing the query and update costs leads to optimal complexities
$n^{1/(2c^2-1)}$, matching bounds from [Andoni-Razenshteyn, 2015] and [Dubiner,
IEEE-TIT'10] and matching the asymptotic complexities of [Andoni-Razenshteyn,
STOC'15] and [Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt, NIPS'15]. A
subpolynomial query time complexity $n^{o(1)}$ can be achieved at the cost of a
space complexity of the order $n^{1/(4\epsilon^2)}$, matching the bound
$n^{\Omega(1/\epsilon^2)}$ of [Andoni-Indyk-Patrascu, FOCS'06] and
[Panigrahy-Talwar-Wieder, FOCS'10] and improving upon results of
[Indyk-Motwani, STOC'98] and [Kushilevitz-Ostrovsky-Rabani, STOC'98].
  For large $c$, minimizing the update complexity results in a query complexity
of $n^{2/c^2+O(1/c^4)}$, improving upon the related exponent for large $c$ of
[Kapralov, PODS'15] by a factor $2$, and matching the bound $n^{\Omega(1/c^2)}$
of [Panigrahy-Talwar-Wieder, FOCS'08]. Balancing the costs leads to optimal
complexities $n^{1/(2c^2-1)}$, while a minimum query time complexity can be
achieved with update complexity $n^{2/c^2+O(1/c^4)}$, improving upon the
previous best exponents of Kapralov by a factor $2$.
</dc:description>
 <dc:description>Comment: 16 pages, 1 table, 2 figures. Mostly subsumed by arXiv:1608.03580
  [cs.DS] (along with arXiv:1605.02701 [cs.DS])</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07528</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Limitations of Deep Learning in Adversarial Settings</dc:title>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:creator>Jha, Somesh</dc:creator>
 <dc:creator>Fredrikson, Matt</dc:creator>
 <dc:creator>Celik, Z. Berkay</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning takes advantage of large datasets and computationally efficient
training algorithms to outperform other approaches at various machine learning
tasks. However, imperfections in the training phase of deep neural networks
make them vulnerable to adversarial samples: inputs crafted by adversaries with
the intent of causing deep neural networks to misclassify. In this work, we
formalize the space of adversaries against deep neural networks (DNNs) and
introduce a novel class of algorithms to craft adversarial samples based on a
precise understanding of the mapping between inputs and outputs of DNNs. In an
application to computer vision, we show that our algorithms can reliably
produce samples correctly classified by human subjects but misclassified in
specific targets by a DNN with a 97% adversarial success rate while only
modifying on average 4.02% of the input features per sample. We then evaluate
the vulnerability of different sample classes to adversarial perturbations by
defining a hardness measure. Finally, we describe preliminary work outlining
defenses against adversarial samples by defining a predictive measure of
distance between a benign input and a target classification.
</dc:description>
 <dc:description>Comment: Accepted to the 1st IEEE European Symposium on Security &amp; Privacy,
  IEEE 2016. Saarbrucken, Germany</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07529</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calculating the Unrooted Subtree Prune-and-Regraft Distance</dc:title>
 <dc:creator>Whidden, Chris</dc:creator>
 <dc:creator>Matsen IV, Frederick A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  The subtree prune-and-regraft (SPR) distance metric is a fundamental way of
comparing evolutionary trees. It has wide-ranging applications, such as to
study lateral genetic transfer, viral recombination, and Markov chain Monte
Carlo phylogenetic inference. Although the rooted version of SPR distance can
be computed relatively efficiently between rooted trees using
fixed-parameter-tractable maximum agreement forest (MAF) algorithms, no MAF
formulation is known for the unrooted case. Correspondingly, previous
algorithms are unable to compute unrooted SPR distances larger than 7.
  In this paper, we substantially advance understanding of and computational
algorithms for the unrooted SPR distance. First we identify four properties of
optimal SPR paths, each of which suggests that no MAF formulation exists in the
unrooted case. Then we introduce the replug distance, a new lower bound on the
unrooted SPR distance that is amenable to MAF methods, and give an efficient
fixed-parameter algorithm for calculating it. Finally, we develop a
&quot;progressive A*&quot; search algorithm using multiple heuristics, including the TBR
and replug distances, to exactly compute the unrooted SPR distance. Our
algorithm is nearly two orders of magnitude faster than previous methods on
small trees, and allows computation of unrooted SPR distances as large as 14 on
trees with 50 leaves.
</dc:description>
 <dc:description>Comment: 21 double-column pages, 11 figures. Revised in response to peer
  review. The sections introducing socket forests and on chain reduction were
  spun off into a conference-length paper arXiv:1611.02351 to reduce the length
  and complexity of the manuscript</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07531</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Coded Multicasting Scheme Preserving the Multiplicative
  Caching Gain</dc:title>
 <dc:creator>Vettigli, Giuseppe</dc:creator>
 <dc:creator>Ji, Mingyue</dc:creator>
 <dc:creator>Tulino, Antonia M.</dc:creator>
 <dc:creator>Llorca, Jaime</dc:creator>
 <dc:creator>Festa, Paola</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded multicasting has been shown to be a promis- ing approach to
significantly improve the caching performance of content delivery networks with
multiple caches downstream of a common multicast link. However, achievable
schemes proposed to date have been shown to achieve the proved order-optimal
performance only in the asymptotic regime in which the number of packets per
requested item goes to infinity. In this paper, we first extend the asymptotic
analysis of the achievable scheme in [1], [2] to the case of heterogeneous
cache sizes and demand distributions, providing the best known upper bound on
the fundamental limiting performance when the number of packets goes to
infinity. We then show that the scheme achieving this upper bound quickly loses
its multiplicative caching gain for finite content packetization. To overcome
this limitation, we design a novel polynomial-time algorithm based on random
greedy graph- coloring that, while keeping the same finite content
packetization, recovers a significant part of the multiplicative caching gain.
Our results show that the order-optimal coded multicasting schemes proposed to
date, while useful in quantifying the fundamental limiting performance, must be
properly designed for practical regimes of finite packetization.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures, Published in Infocom CNTCV 2015</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07533</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Energy Beamforming with One-Bit Feedback</dc:title>
 <dc:creator>Lee, Seunghyun</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy beamforming (EB) is a key technique for achieving efficient
radio-frequency (RF) transmission enabled wireless energy transfer (WET). By
optimally designing the waveforms from multiple energy transmitters (ETs) over
the wireless channels, they are constructively combined at the energy receiver
(ER) to achieve an EB gain that scales with the number of ETs. However, the
optimal design of transmit waveforms requires accurate channel state
information (CSI) at the ETs, which is challenging to obtain in practical WET
systems. In this paper, we propose a new channel training scheme to achieve
optimal EB gain in a distributed WET system, where multiple separated ETs
adjust their transmit phases to collaboratively send power to a single ER in an
iterative manner, based on one-bit feedback from the ER per training interval
which indicates the increase/decrease of the received power level from one
particular ET over two preassigned transmit phases. The proposed EB algorithm
can be efficiently implemented in practical WET systems even with a large
number of distributed ETs, and is analytically shown to converge quickly to the
optimal EB design as the number of feedback intervals per ET increases.
Numerical results are provided to evaluate the performance of the proposed
algorithm as compared to other distributed EB designs.
</dc:description>
 <dc:description>Comment: submitted for possible conference publication</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07535</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regular sequences and the joint spectral radius</dc:title>
 <dc:creator>Coons, Michael</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We classify the growth of a $k$-regular sequence based on information from
its $k$-kernel. In order to provide such a classification, we introduce the
notion of a growth exponent for $k$-regular sequences and show that this
exponent is equal to the joint spectral radius of any set of a special class of
matrices determined by the $k$-kernel.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07536</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Symbolic Logic with Concrete Bounds for Cryptographic Protocols</dc:title>
 <dc:creator>Datta, Anupam</dc:creator>
 <dc:creator>Halpern, Joseph Y.</dc:creator>
 <dc:creator>Mitchell, John C.</dc:creator>
 <dc:creator>Roy, Arnab</dc:creator>
 <dc:creator>Sen, Shayak</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  We present a formal logic for quantitative reasoning about security
properties of network protocols. The system allows us to derive concrete
security bounds that can be used to choose key lengths and other security
parameters. We provide axioms for reasoning about digital signatures and random
nonces, with security properties based on the concrete security of signature
schemes and pseudorandom number generators (PRG). The formal logic supports
first-order reasoning and reasoning about protocol invariants, taking concrete
security bounds into account. Proofs constructed in our logic also provide
conventional asymptotic security guarantees because of the way that concrete
bounds accumulate in proofs. As an illustrative example, we use the formal
logic to prove an authentication property with concrete bounds of a
signature-based challenge-response protocol.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07538</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of Statistical Learning and Adaptive Learning</dc:title>
 <dc:creator>Roy, Ayan</dc:creator>
 <dc:creator>Basu, Kaustuvi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Numerous strategies have been adopted in order to make the process of
learning simple, efficient and within less amount of time.. Classroom learning
is slowly replaced by E-learning and M- learning. These techniques involve the
usage of computers, smart phones and tablets for the process of learning.
Learning from the internet has become popular among the e-learners where
learner tends to rely greatly upon information provided by the World Wide Web.
However, the e-learners have to go through a huge volume of data produced by
the first tier search engine, some of which are not suited to the interest of
the user. Various strategies, namely Statistical Learning and Adaptive
Learning, have been adopted to cater to the need of the user and produce data
best suited to the interest of the user. The authors have tried to present a
comparative study of Statistical Learning and Adaptive Learning based on
certain parameters, which arise from the characteristics of the learning
process. As a consequence of the comparative study, it has been concluded that
Adaptive learning is more efficient than Statistical learning.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07539</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Multiple-Groupcast Coded Multicasting Scheme for Finite
  Fractional Caching</dc:title>
 <dc:creator>Ji, Mingyue</dc:creator>
 <dc:creator>Shanmugam, Karthikeyan</dc:creator>
 <dc:creator>Vettigli, Giuseppe</dc:creator>
 <dc:creator>Llorca, Jaime</dc:creator>
 <dc:creator>Tulino, Antonia M.</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded multicasting has been shown to improve the caching performance of
content delivery networks with multiple caches downstream of a common multicast
link. However, the schemes that have been shown to achieve order-optimal
perfor- mance require content items to be partitioned into a number of packets
that grows exponentially with the number of users [1]. In this paper, we first
extend the analysis of the achievable scheme in [2] to the case of
heterogeneous cache sizes and demand distribu- tions, providing an achievable
scheme and an upper bound on the limiting average performance when the number
of packets goes to infinity while the remaining system parameters are kept
constant. We then show how the scheme achieving this upper bound can very
quickly loose its multiplicative caching gain for finite content packetization.
To overcome this limitation, we design a novel polynomial-time algorithm based
on greedy local graph-coloring that, while keeping the same content
packetization, recovers a significant part of the multiplicative caching gain.
Our results show that the achievable schemes proposed to date to quantify the
limiting performance, must be properly designed for practical finite system
parameters.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, published in ICC 2015. arXiv admin note: text
  overlap with arXiv:1511.07531</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07540</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pairwise Comparisons Rating Scale Paradox</dc:title>
 <dc:creator>Koczkodaj, W. W.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  This study demonstrates that incorrect data are entered into a pairwise
comparisons matrix for processing into weights for the data collected by a
rating scale. Unprocessed rating scale data lead to a paradox. A solution to
it, based on normalization, is proposed. This is an essential correction for
virtually all pairwise comparisons methods using rating scales. The
illustration of the relative error currently, taking place, is discussed.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figure, 1 table, progress report, (practically) ready for
  submission, call for cooperation, call for corrections of formerly published
  results (especially related to AHP) which may go into tens of thousands</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07542</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Caching-Aided Coded Multicasting with Multiple Random Requests</dc:title>
 <dc:creator>Ji, Mingyue</dc:creator>
 <dc:creator>Tulino, Antonia</dc:creator>
 <dc:creator>Llorca, Jaime</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The capacity of caching networks has received considerable attention in the
past few years. A particularly studied setting is the shared link caching
network, in which a single source with access to a file library communicates
with multiple users, each having the capability to store segments (packets) of
the library files, over a shared multicast link. Each user requests one file
from the library according to a common demand distribution and the server sends
a coded multicast message to satisfy all users at once. The problem consists of
finding the smallest possible average codeword length to satisfy such requests.
In this paper, we consider the generalization to the case where each user
places L &gt;= 1 independent requests according to the same common demand
distribution. We propose an achievable scheme based on random vector
(packetized) caching placement and multiple groupcast index coding, shown to be
order-optimal in the asymptotic regime in which the number of packets per file
B goes to infinity. We then show that the scalar (B = 1) version of the
proposed scheme can still preserve order-optimality when the number of per-user
requests L is large enough. Our results provide the first order-optimal
characterization of the shared link caching network with multiple random
requests, revealing the key effects of L on the performance of caching-aided
coded multicast schemes.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, published in ITW 2015. arXiv admin note: text
  overlap with arXiv:1402.4572</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07543</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergent Learning: Do different neural networks learn the same
  representations?</dc:title>
 <dc:creator>Li, Yixuan</dc:creator>
 <dc:creator>Yosinski, Jason</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:creator>Lipson, Hod</dc:creator>
 <dc:creator>Hopcroft, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent success in training deep neural networks have prompted active
investigation into the features learned on their intermediate layers. Such
research is difficult because it requires making sense of non-linear
computations performed by millions of parameters, but valuable because it
increases our ability to understand current models and create improved versions
of them. In this paper we investigate the extent to which neural networks
exhibit what we call convergent learning, which is when the representations
learned by multiple nets converge to a set of features which are either
individually similar between networks or where subsets of features span similar
low-dimensional spaces. We propose a specific method of probing
representations: training multiple networks and then comparing and contrasting
their individual, learned representations at the level of neurons or groups of
neurons. We begin research into this question using three techniques to
approximately align different neural networks on a feature level: a bipartite
matching approach that makes one-to-one assignments between neurons, a sparse
prediction approach that finds one-to-many mappings, and a spectral clustering
approach that finds many-to-many mappings. This initial investigation reveals a
few previously unknown properties of neural networks, and we argue that future
research into the question of convergent learning will yield many more. The
insights described here include (1) that some features are learned reliably in
multiple networks, yet other features are not consistently learned; (2) that
units learn to span low-dimensional subspaces and, while these subspaces are
common to multiple networks, the specific basis vectors learned are not; (3)
that the representation codes show evidence of being a mix between a local code
and slightly, but not fully, distributed codes across multiple units.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07544</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impacts of suppressing guide on information spreading</dc:title>
 <dc:creator>Xu, Jinghong</dc:creator>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Ma, Baojun</dc:creator>
 <dc:creator>Wu, Ye</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  It is quite common that guides are introduced to suppress the information
spreading in modern society for different purposes. In this paper, an
agent-based model is established to quantitatively analyze the impacts of
suppressing guides on information spreading. We find that the spreading
threshold depends on the attractiveness of the information and the topology of
the social network with no suppressing guides at all. Usually, one would expect
that the existence of suppressing guides in the spreading procedure may result
in less diffusion of information within the overall network. However, we find
that sometimes the opposite is true: the manipulating nodes of suppressing
guides may lead to more extensive information spreading when there are
audiences with the reversal mind. These results can provide valuable
theoretical references to public opinion guidance on various information, e.g.,
rumor or news spreading.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures,</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07544</dc:identifier>
 <dc:identifier>Physica A 444, 922(2016)</dc:identifier>
 <dc:identifier>doi:10.1016/j.physa.2015.10.059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07545</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Deep Metric Learning for Person Re-identification</dc:title>
 <dc:creator>Shi, Hailin</dc:creator>
 <dc:creator>Zhu, Xiangyu</dc:creator>
 <dc:creator>Liao, Shengcai</dc:creator>
 <dc:creator>Lei, Zhen</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Li, Stan Z.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification aims to re-identify the probe image from a given set
of images under different camera views. It is challenging due to large
variations of pose, illumination, occlusion and camera view. Since the
convolutional neural networks (CNN) have excellent capability of feature
extraction, certain deep learning methods have been recently applied in person
re-identification. However, in person re-identification, the deep networks
often suffer from the over-fitting problem. In this paper, we propose a novel
CNN-based method to learn a discriminative metric with good robustness to the
over-fitting problem in person re-identification. Firstly, a novel deep
architecture is built where the Mahalanobis metric is learned with a weight
constraint. This weight constraint is used to regularize the learning, so that
the learned metric has a better generalization ability. Secondly, we find that
the selection of intra-class sample pairs is crucial for learning but has
received little attention. To cope with the large intra-class variations in
pedestrian images, we propose a novel training strategy named moderate positive
mining to prevent the training process from over-fitting to the extreme samples
in intra-class pairs. Experiments show that our approach significantly
outperforms state-of-the-art methods on several benchmarks of person
re-identification.
</dc:description>
 <dc:description>Comment: 11 pages, 16 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07549</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using tropical optimization to solve constrained minimax single-facility
  location problems with rectilinear distance</dc:title>
 <dc:creator>Krivulin, Nikolai</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>90B85 (Primary), 15A80, 65K05, 90C48 (Secondary)</dc:subject>
 <dc:description>  The aim of this paper is twofold: first, to extend the area of applications
of tropical optimization by solving new constrained location problems, and
second, to offer new closed-form solutions to general problems that are of
interest to location analysis. We consider a constrained minimax
single-facility location problem with addends on the plane with rectilinear
distance. The solution commences with the representation of the problem in a
standard form, and then in terms of tropical mathematics, as a constrained
optimization problem. We use a transformation technique, which can act as a
template to handle optimization problems in other application areas, and hence
is of independent interest. To solve the constrained optimization problem, we
apply methods and results of tropical optimization, which provide direct,
explicit solutions. The results obtained serve to derive new solutions of the
location problem, and of its special cases with reduced sets of constraints, in
a closed form, ready for practical implementation and immediate computation. As
illustrations, numerical solutions of example problems and their graphical
representation are given. We conclude with an application of the results to
optimal location of the central monitoring facility in an indoor video
surveillance system in a multi-floor building environment.
</dc:description>
 <dc:description>Comment: 29 pages, 3 figures</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07549</dc:identifier>
 <dc:identifier>Computational Management Science, 2017. Vol.14, N4. P.493-518</dc:identifier>
 <dc:identifier>doi:10.1007/s10287-017-0289-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07551</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transductive Log Opinion Pool of Gaussian Process Experts</dc:title>
 <dc:creator>Cao, Yanshuai</dc:creator>
 <dc:creator>Fleet, David J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a framework for analyzing transductive combination of Gaussian
process (GP) experts, where independently trained GP experts are combined in a
way that depends on test point location, in order to scale GPs to big data. The
framework provides some theoretical justification for the generalized product
of GP experts (gPoE-GP) which was previously shown to work well in practice but
lacks theoretical basis. Based on the proposed framework, an improvement over
gPoE-GP is introduced and empirically validated.
</dc:description>
 <dc:description>Comment: Accepted at NIPS2015 Workshop on Nonparametric Methods for Large
  Scale Representation Learning</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07556</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Wireless Information and Power Transfer in Cooperative
  Relay Networks with Rateless Codes</dc:title>
 <dc:creator>Di, Xiaofei</dc:creator>
 <dc:creator>Xiong, Ke</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Yang, Hongchuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the simultaneous wireless information and power
transfer (SWIPT) in cooperative relay networks, where a relay harvests energy
from the radio frequency (RF) signals transmitted by a source and then uses the
harvested energy to assist the information transmission from the source to its
destination. Both source and relay transmissions use rateless code, which
allows the destination to employ any of the two information receiving
strategies, i.e., the mutual information accumulation (IA) and the energy
accumulation (EA). The SWIPT-enabled relay employs three different SWIPT
receiver architectures, the ideal receiver and two practical receivers (i.e.,
the power splitting (PS) and the time switch (TS) receivers). Accordingly,
three relaying protocols, namely, ideal protocol, PS protocol and TS protocol,
are presented. In order to explore the system performance limits with these
three protocols, optimization problems are formulated to maximize their
achievable information rates. For the ideal protocol, explicit expressions of
the optimal solutions are derived. For the PS protocol, a linear-search
algorithm is designed to solve the non-convex problems. For the TS protocol,
two solving methods are presented. Numerical experiments are carried out to
validate our analysis and algorithms, which also show that, with the same SWIPT
receiver, the IA-based system outperforms the EA-based system, while with the
same information receiving strategy, PS protocol outperforms TS protocol.
Moreover, compared with conventional non-SWIPT and non-rateless-coded systems,
the proposed protocols exhibit considerable performance gains, especially in
relatively low signal-to-noise ratio (SNR) regime. Besides, the effects of the
source-destination direct link and the relay position on system performance are
also discussed, which provides insights on SWIPT-enabled relay systems.
</dc:description>
 <dc:description>Comment: 31 pages,15 figures, submitted to IEEE Journal</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07556</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2588441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07558</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower bounds for constant query affine-invariant LCCs and LTCs</dc:title>
 <dc:creator>Bhattacharyya, Arnab</dc:creator>
 <dc:creator>Gopi, Sivakanth</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Affine-invariant codes are codes whose coordinates form a vector space over a
finite field and which are invariant under affine transformations of the
coordinate space. They form a natural, well-studied class of codes; they
include popular codes such as Reed-Muller and Reed-Solomon. A particularly
appealing feature of affine-invariant codes is that they seem well-suited to
admit local correctors and testers.
  In this work, we give lower bounds on the length of locally correctable and
locally testable affine-invariant codes with constant query complexity. We show
that if a code $\mathcal{C} \subset \Sigma^{\mathbb{K}^n}$ is an $r$-query
locally correctable code (LCC), where $\mathbb{K}$ is a finite field and
$\Sigma$ is a finite alphabet, then the number of codewords in $\mathcal{C}$ is
at most $\exp(O_{\mathbb{K}, r, |\Sigma|}(n^{r-1}))$. Also, we show that if
$\mathcal{C} \subset \Sigma^{\mathbb{K}^n}$ is an $r$-query locally testable
code (LTC), then the number of codewords in $\mathcal{C}$ is at most
$\exp(O_{\mathbb{K}, r, |\Sigma|}(n^{r-2}))$. The dependence on $n$ in these
bounds is tight for constant-query LCCs/LTCs, since Guo, Kopparty and Sudan
(ITCS `13) construct affine-invariant codes via lifting that have the same
asymptotic tradeoffs. Note that our result holds for non-linear codes, whereas
previously, Ben-Sasson and Sudan (RANDOM `11) assumed linearity to derive
similar results.
  Our analysis uses higher-order Fourier analysis. In particular, we show that
the codewords corresponding to an affine-invariant LCC/LTC must be far from
each other with respect to Gowers norm of an appropriate order. This then
allows us to bound the number of codewords, using known decomposition theorems
which approximate any bounded function in terms of a finite number of
low-degree non-classical polynomials, upto a small error in the Gowers norm.
</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07559</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost Minimizing Online Algorithms for Energy Storage Management with
  Worst-case Guarantee</dc:title>
 <dc:creator>Chau, Chi-Kin</dc:creator>
 <dc:creator>Zhang, Guanglin</dc:creator>
 <dc:creator>Chen, Minghua</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The fluctuations of electricity prices in demand response schemes and
intermittency of renewable energy supplies necessitate the adoption of energy
storage in microgrids. However, it is challenging to design effective real-time
energy storage management strategies that can deliver assured optimality,
without being hampered by the uncertainty of volatile electricity prices and
renewable energy supplies. This paper presents a simple effective online
algorithm for the charging and discharging decisions of energy storage that
minimizes the electricity cost in the presence of electricity price
fluctuations and renewable energy supplies, without relying on the future
information of prices, demands or renewable energy supplies. The proposed
algorithm is supported by a near-best worst-case guarantee (i.e., competitive
ratio), as compared to the offline optimal decisions based on full future
information. Furthermore, the algorithm can be adapted to take advantage of
limited future information, if available. By simulations on real-world data, it
is observed that the proposed algorithms can achieve satisfactory outcome in
practice.
</dc:description>
 <dc:description>Comment: To appear in IEEE Transactions on Smart Grid</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:date>2016-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07559</dc:identifier>
 <dc:identifier>IEEE Transactions on Smart Grid, Vol. 7, No. 6, pp2691-2702 (Nov
  2016)</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2016.2514412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07564</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deploying Multiple Antennas on High-speed Trains: Equidistant Strategy
  v.s. Fixed-Interval Strategy</dc:title>
 <dc:creator>Lu, Yang</dc:creator>
 <dc:creator>Xiong, Ke</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Zhong, Zhangdui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Deploying multiple antennas on high speed trains is an effective way to
enhance the information transmission performance for high speed railway (HSR)
wireless communication systems. However, how to efficiently deploy multiple
antennas on a train? This problem has not been studied yet. In this paper, we
shall investigate efficient antenna deployment strategies for HSR communication
systems where two multi-antenna deployment strategies, i.e., the equidistant
strategy and the fixed-interval strategy, are considered. To evaluate the
system performance, mobile service amount and outage time ratio are introduced.
Theoretical analysis and numerical results show that, when the length of the
train is not very large, for two-antenna case, by increasing the distance of
neighboring antennas in a reasonable region, the system performance can be
enhanced. It is also shown that the two strategies have much difference
performance behavior in terms of instantaneous channel capacity, and the
fixed-interval strategy may achieve much better performance than the
equidistant one in terms of service amount and outage time ratio when the
antenna number is much large.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures, submitted to IEEE Conference</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07566</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficiency with Proportional Rate Fairness in Multi-Relay OFDM
  Networks</dc:title>
 <dc:creator>Xiong, Ke</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Lu, Yang</dc:creator>
 <dc:creator>Letaief, Khaled Ben</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the energy efficiency (EE) in multiple relay aided
OFDM system, where decode-and-forward (DF) relay beamforming is employed to
help the information transmission. In order to explore the EE performance with
user fairness for such a system, we formulate an optimization problem to
maximize the EE by jointly considering several factors, the transmission mode
selection (DF relay beamforming or direct-link transmission), the helping relay
set selection, the subcarrier assignment and the power allocation at the source
and relays on subcarriers, under nonlinear proportional rate fairness
constraints, where both transmit power consumption and linearly rate-dependent
circuit power consumption are taken into account. To solve the non-convex
optimization problem, we propose a low-complexity scheme to approximate it.
Simulation results demonstrate its effectiveness. We also investigate the
effects of the circuit power consumption on system performances and observe
that with both the constant and the linearly rate-dependent circuit power
consumption, system EE grows with the increment of system average channel-to
noise ratio (CNR), but the growth rates show different behaviors. For the
constant circuit power consumption, system EE increasing rate is an increasing
function of the system average CNR, while for the linearly rate-dependent one,
system EE increasing rate is a decreasing function of the system average CNR.
This observation is very important which indicates that by deducing the circuit
dynamic power consumption per unit data rate, system EE can be greatly
enhanced. Besides, we also discuss the effects of the number of users and
subcarriers on the system EE performance.
</dc:description>
 <dc:description>Comment: 35 pages, 15 fihures, submitted to IEEE Journal</dc:description>
 <dc:date>2015-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07568</identifier>
 <datestamp>2016-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Cell Multiuser Massive MIMO Networks: User Capacity Analysis and
  Pilot Design</dc:title>
 <dc:creator>Akbar, Noman</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:creator>Sadeghi, Parastoo</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a novel pilot sequence design to mitigate pilot contamination in
multi-cell multiuser massive multiple-input multiple-output networks. Our
proposed design generates pilot sequences in the multi-cell network and devises
power allocation at base stations (BSs) for downlink transmission. The pilot
sequences together with the power allocation ensure that the user capacity of
the network is achieved and the pre-defined signal-to-interference-plus-noise
ratio (SINR) requirements of all users are met. To realize our design, we first
derive new closed-form expressions for the user capacity and the user capacity
region. Built upon these expressions, we then develop a new algorithm to obtain
the required pilot sequences and power allocation. We further determine the
minimum number of antennas required at BSs to achieve certain SINR requirements
of all users. Numerical results are presented to corroborate our analysis and
to examine the impact of key parameters, such as the pilot sequence length and
the total number of users, on the network performance. A pivotal conclusion is
reached that our design achieves a larger user capacity region than the
existing designs and needs less antennas at the BS to fulfill the pre-defined
SINR requirements of all users in the network than the existing designs.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Transactions on Communications</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07568</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2614674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07569</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Signed Network Mining in Social Media</dc:title>
 <dc:creator>Tang, Jiliang</dc:creator>
 <dc:creator>Chang, Yi</dc:creator>
 <dc:creator>Aggarwal, Charu</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Many real-world relations can be represented by signed networks with positive
and negative links, as a result of which signed network analysis has attracted
increasing attention from multiple disciplines. With the increasing prevalence
of social media networks, signed network analysis has evolved from developing
and measuring theories to mining tasks. In this article, we present a review of
mining signed networks in the context of social media and discuss some
promising research directions and new frontiers. We begin by giving basic
concepts and unique properties and principles of signed networks. Then we
classify and review tasks of signed network mining with representative
algorithms. We also delineate some tasks that have not been extensively studied
with formal definitions and also propose research directions to expand the
field of signed network mining.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07570</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Service-Based Cooperative Scheduling for High-Mobility Vehicular
  Networks</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Xiong, Ke</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:creator>Zhou, Xianwei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the downlink scheduling for relay-aided high-mobility
vehicular networks, where the vehicles with good vehicle-to-infrastructure
(V2I) links are employed as cooperative relay nodes to help the ones with poor
V2I links forward information via vehicle-to-vehicle (V2V) links. In existing
works, instantaneous achievable information rate was widely adopted to perform
the link scheduling, but it is not efficient for vehicular networks, especially
for high-mobility scenarios. Different from them, in this paper, we introduce
the mobile service to describe the mobile link capacity of vehicular networks
and then we propose a mobile service based relaying scheduling (MSRS) for high
mobility vehicular networks. In order to explore the system information
transmission performance limit, we formulate an optimization problem to
maximize the mobile service amount of MSRS by jointly scheduling the V2I and
V2V links. Since it is a combinational optimization problem which is too
complex to solve, we design an efficient algorithm with low-complexity for it,
where Sort-then-Select, Hungarian algorithm and Bisection search are employed.
Simulation results demonstrate that our proposed MSRS is able to achieve the
optimal results with an optimal approximation ratio larger than 96.5%. It is
also shown that our proposed MSRS is much more efficient for high-mobility
vehicular systems, which can improve the system average throughput with
increment of 3.63% compared with existing instantaneous achievable information
rate based scheduling method, and with 15% increment compared with traditional
non-cooperation scheduling method, respectively.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, submitted to IEEE Journal</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07571</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DenseCap: Fully Convolutional Localization Networks for Dense Captioning</dc:title>
 <dc:creator>Johnson, Justin</dc:creator>
 <dc:creator>Karpathy, Andrej</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the dense captioning task, which requires a computer vision
system to both localize and describe salient regions in images in natural
language. The dense captioning task generalizes object detection when the
descriptions consist of a single word, and Image Captioning when one predicted
region covers the full image. To address the localization and description task
jointly we propose a Fully Convolutional Localization Network (FCLN)
architecture that processes an image with a single, efficient forward pass,
requires no external regions proposals, and can be trained end-to-end with a
single round of optimization. The architecture is composed of a Convolutional
Network, a novel dense localization layer, and Recurrent Neural Network
language model that generates the label sequences. We evaluate our network on
the Visual Genome dataset, which comprises 94,000 images and 4,100,000
region-grounded captions. We observe both speed and accuracy improvements over
baselines based on current state of the art approaches in both generation and
retrieval settings.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07573</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Marketplace for Mobile Content: Dynamic Pricing and Proactive
  Caching</dc:title>
 <dc:creator>Alotaibi, F.</dc:creator>
 <dc:creator>Hosny, S.</dc:creator>
 <dc:creator>Tadrous, J.</dc:creator>
 <dc:creator>Gamal, H. El</dc:creator>
 <dc:creator>Eryilmaz, A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this work, we investigate the profit maximization problem for a wireless
network carrier and the payment minimization for end-users. Motivated by recent
findings on proactive resource allocation, we focus on the scenario whereby
end-users who are equipped with device-to-device (D2D)communication can harness
predictable demand in proactive data contents caching and the possibility of
trading their proactive downloads to minimize their expected payments. The
carrier, on the other hand, utilizes a dynamic pricing scheme to differentiate
between off-peak and peak time prices and applies commissions on each trading
process to further maximize its profit. A novel marketplace that is based on
risk sharing between end-users is proposed where the tension between carrier
and end-users is formulated as a Stackelberg game. The existence and uniqueness
of the non-cooperative sub-game Nash equilibrium is shown. Furthermore, we
explore the equilibrium points for the case when the D2D is available and when
it is not available, and study the impact of the uncertainty of users future
demands on the system's performance. In particular, we compare the new
equilibrium with the baseline scenario of flat pricing. Despite end-users
connectivity with each other, the uncertainty of their future demands, and the
freshness of the pre-cached contents, we characterize a new equilibrium region
which yields to a win-win situation with respect to the baseline equilibrium.
We show that end-users activity patterns can be harnessed to maximize the
carrier's profit while minimizing the end-users expected payments.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07578</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Case Study on Cloud Based Library Software as a Service: Evaluating
  EZproxy</dc:title>
 <dc:creator>Erturk, Emre</dc:creator>
 <dc:creator>Iles, Howard Robert Edward</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There is a growing relationship between academic libraries and cloud
computing. Therefore, understanding the beginnings and the current use of cloud
base services in libraries is important. This will help understand the factors
that libraries should consider in the future. The purpose of this paper is to
better understand the future implementation of the cloud based software in
academic settings. Using cloud based, web based, and other remote services may
bring both advantages and disadvantages, some of which this paper will bring
out. First, a brief literature review of the academic literature, and a review
of available general-purpose cloud-based library products are conducted. Next,
a real-life scenario for a mid-sized New Zealand institution of higher
education is evaluated. This case involves moving from a locally hosted version
of EZproxy to a cloud based version with support from the vendor. As this
information system decision is an important one, this paper makes a
contribution to the available literature and can be informative for librarians.
In conclusion, academic libraries will gradually involve more pervasive use of
cloud based systems. The examples of important factors to be considered in
future decisions include timing and staffing.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07605</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Computational Complexity of Limit Cycles in Dynamical Systems</dc:title>
 <dc:creator>Papadimitriou, Christos H.</dc:creator>
 <dc:creator>Vishnoi, Nisheeth K.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We study the Poincare-Bendixson theorem for two-dimensional continuous
dynamical systems in compact domains from the point of view of computation,
seeking algorithms for finding the limit cycle promised by this classical
result. We start by considering a discrete analogue of this theorem and show
that both finding a point on a limit cycle, and determining if a given point is
on one, are PSPACE-complete.
  For the continuous version, we show that both problems are uncomputable in
the real complexity sense; i.e., their complexity is arbitrarily high.
Subsequently, we introduce a notion of an &quot;approximate cycle&quot; and prove an
&quot;approximate&quot; Poincar\'e-Bendixson theorem guaranteeing that some orbits come
very close to forming a cycle in the absence of approximate fixpoints;
surprisingly, it holds for all dimensions. The corresponding computational
problem defined in terms of arithmetic circuits is PSPACE-complete.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07607</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Grain Annotation of Cricket Videos</dc:title>
 <dc:creator>Sharma, Rahul Anand</dc:creator>
 <dc:creator>K, Pramod Sankar</dc:creator>
 <dc:creator>Jawahar, CV</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recognition of human activities is one of the key problems in video
understanding. Action recognition is challenging even for specific categories
of videos, such as sports, that contain only a small set of actions.
Interestingly, sports videos are accompanied by detailed commentaries available
online, which could be used to perform action annotation in a weakly-supervised
setting. For the specific case of Cricket videos, we address the challenge of
temporal segmentation and annotation of ctions with semantic descriptions. Our
solution consists of two stages. In the first stage, the video is segmented
into &quot;scenes&quot;, by utilizing the scene category information extracted from
text-commentary. The second stage consists of classifying video-shots as well
as the phrases in the textual description into various categories. The relevant
phrases are then suitably mapped to the video-shots. The novel aspect of this
work is the fine temporal scale at which semantic information is assigned to
the video. As a result of our approach, we enable retrieval of specific actions
that last only a few seconds, from several hours of video. This solution yields
a large number of labeled exemplars, with no manual effort, that could be used
by machine learning algorithms to learn complex actions.
</dc:description>
 <dc:description>Comment: ACPR 2015</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07608</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Picking a Conveyor Clean by an Autonomously Learning Robot</dc:title>
 <dc:creator>Kujala, Janne V.</dc:creator>
 <dc:creator>Lukka, Tuomas J.</dc:creator>
 <dc:creator>Holopainen, Harri</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a research picking prototype related to our company's industrial
waste sorting application. The goal of the prototype is to be as autonomous as
possible and it both calibrates itself and improves its picking with minimal
human intervention. The system learns to pick objects better based on a
feedback sensor in its gripper and uses machine learning to choosing the best
proposal from a random sample produced by simple hard-coded geometric models.
We show experimentally the system improving its picking autonomously by
measuring the pick success rate as function of time. We also show how this
system can pick a conveyor belt clean, depositing 70 out of 80 objects in a
difficult to manipulate pile of novel objects into the correct chute. We
discuss potential improvements and next steps in this direction.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07611</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mouse Pose Estimation From Depth Images</dc:title>
 <dc:creator>Nanjappa, Ashwin</dc:creator>
 <dc:creator>Cheng, Li</dc:creator>
 <dc:creator>Gao, Wei</dc:creator>
 <dc:creator>Xu, Chi</dc:creator>
 <dc:creator>Claridge-Chang, Adam</dc:creator>
 <dc:creator>Bichler, Zoe</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We focus on the challenging problem of efficient mouse 3D pose estimation
based on static images, and especially single depth images. We introduce an
approach to discriminatively train the split nodes of trees in random forest to
improve their performance on estimation of 3D joint positions of mouse. Our
algorithm is capable of working with different types of rodents and with
different types of depth cameras and imaging setups. In particular, it is
demonstrated in this paper that when a top-mounted depth camera is combined
with a bottom-mounted color camera, the final system is capable of delivering
full-body pose estimation including four limbs and the paws. Empirical
examinations on synthesized and real-world depth images confirm the
applicability of our approach on mouse pose estimation, as well as the closely
related task of part-based labeling of mouse.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07616</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention Dynamics in Collaborative Knowledge Creation</dc:title>
 <dc:creator>Wu, Lingfei</dc:creator>
 <dc:creator>Janssen, Marco A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  To uncover the mechanisms underlying the collaborative production of
knowledge, we investigate a very large online Question and Answer system that
includes the question asking and answering activities of millions of users over
five years. We created knowledge networks in which nodes are questions and
edges are the successive answering activities of users. We find that these
networks have two common properties: 1) the mitigation of degree inequality
among nodes; and 2) the assortative mixing of nodes. This means that, while the
system tends to reduce attention investment on old questions in order to supply
sufficient attention to new questions, it is not easy for novel knowledge be
integrated into the existing body of knowledge. We propose a mixing model to
combine preferential attachment and reversed preferential attachment processes
to model the evolution of knowledge networks and successfully reproduce the ob-
served patterns. Our mixing model is not only theoretically interesting but
also provide insights into the management of online communities.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07628</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When is P such that l_0-minimization Equals to l_p-minimization</dc:title>
 <dc:creator>Wang, Changlong</dc:creator>
 <dc:creator>Yue, Shigang</dc:creator>
 <dc:creator>Peng, Jigen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present an analysis expression of p(A,b) such that the
unique solution to l_0-minimization also can be the unique solution to
l_p-minimization for any 0&lt;p&lt;p(A,b). Furthermore, the main contribution of this
paper isn't only the analysis expressed of such p^(A,b) but also its proof.
Finally, we display the results of two examples to confirm the validity of our
conclusions
</dc:description>
 <dc:description>Comment: 16 pages, 3 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07637</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positioning via Direct Localization in C-RAN Systems</dc:title>
 <dc:creator>Jeong, Seongah</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Haimovich, Alexander</dc:creator>
 <dc:creator>Kang, Joonhyuk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Cloud Radio Access Network (C-RAN) is a prominent architecture for 5G
wireless cellular system that is based on the centralization of baseband
processing for multiple distributed radio units (RUs) at a control unit (CU).
In this work, it is proposed to leverage the C-RAN architecture to enable the
implementation of direct localization of the position of mobile devices from
the received signals at distributed RUs. With ideal connections between the CU
and the RUs, direct localization is known to outperform traditional indirect
localization, whereby the location of a source is estimated from intermediary
parameters estimated at the RUs. However, in a C-RAN system with capacity
limited fronthaul links, the advantage of direct localization may be offset by
the distortion caused by the quantization of the received signal at the RUs. In
this paper, the performance of direct localization is studied by accounting for
the effect of fronthaul quantization with or without dithering. An approximate
Maximum Likelihood (ML) localization is developed. Then, the Cramer-Rao Bound
(CRB) on the squared position error (SPE) of direct localization with quantized
observations is derived. Finally, the performance of indirect localization and
direct localization with or without dithering is compared via numerical
results.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures, IET Communications</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07642</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multivariate Complexity Analysis of Geometric {\sc Red Blue Set Cover}</dc:title>
 <dc:creator>Ashok, Pradeesha</dc:creator>
 <dc:creator>Kolay, Sudeshna</dc:creator>
 <dc:creator>Saurabh, Saket</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We investigate the parameterized complexity of GENERALIZED RED BLUE SET COVER
(Gen-RBSC), a generalization of the classic SET COVER problem and the more
recently studied RED BLUE SET COVER problem. Given a universe $U$ containing
$b$ blue elements and $r$ red elements, positive integers $k_\ell$ and $k_r$,
and a family $\F$ of $\ell$ sets over $U$, the \srbsc\ problem is to decide
whether there is a subfamily $\F'\subseteq \F$ of size at most $k_\ell$ that
covers all blue elements, but at most $k_r$ of the red elements. This
generalizes SET COVER and thus in full generality it is intractable in the
parameterized setting. In this paper, we study a geometric version of this
problem, called Gen-RBSC-lines, where the elements are points in the plane and
sets are defined by lines. We study this problem for an array of parameters,
namely, $k_\ell, k_r, r, b$, and $\ell$, and all possible combinations of them.
For all these cases, we either prove that the problem is W-hard or show that
the problem is fixed parameter tractable (FPT). In particular, on the
algorithmic side, our study shows that a combination of $k_\ell$ and $k_r$
gives rise to a nontrivial algorithm for Gen-RBSC-lines. On the hardness side,
we show that the problem is para-NP-hard when parameterized by $k_r$, and
W[1]-hard when parameterized by $k_\ell$. Finally, for the combination of
parameters for which Gen-RBSC-lines admits FPT algorithms, we ask for the
existence of polynomial kernels. We are able to provide a complete
kernelization dichotomy by either showing that the problem admits a polynomial
kernel or that it does not contain a polynomial kernel unless $\CoNP \subseteq
\NP/\mbox{poly}$.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07643</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homophily and missing links in citation networks</dc:title>
 <dc:creator>Ciotti, Valerio</dc:creator>
 <dc:creator>Bonaventura, Moreno</dc:creator>
 <dc:creator>Nicosia, Vincenzo</dc:creator>
 <dc:creator>Panzarasa, Pietro</dc:creator>
 <dc:creator>Latora, Vito</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Citation networks have been widely used to study the evolution of science
through the lenses of the underlying patterns of knowledge flows among academic
papers, authors, research sub-fields, and scientific journals. Here we focus on
citation networks to cast light on the salience of homophily, namely the
principle that similarity breeds connection, for knowledge transfer between
papers. To this end, we assess the degree to which citations tend to occur
between papers that are concerned with seemingly related topics or research
problems. Drawing on a large data set of articles published in the journals of
the American Physical Society between 1893 and 2009, we propose a novel method
for measuring the similarity between articles through the statistical
validation of the overlap between their bibliographies. Results suggest that
the probability of a citation made by one article to another is indeed an
increasing function of the similarity between the two articles. Our study also
enables us to uncover missing citations between pairs of highly related
articles, and may thus help identify barriers to effective knowledge flows. By
quantifying the proportion of missing citations, we conduct a comparative
assessment of distinct journals and research sub-fields in terms of their
ability to facilitate or impede the dissemination of knowledge. Findings
indicate that knowledge transfer seems to be more effectively facilitated by
journals of wide visibility, such as Physical Review Letters, than by
lower-impact ones. Our study has important implications for authors, editors
and reviewers of scientific journals, as well as public preprint repositories,
as it provides a procedure for recommending relevant yet missing references and
properly integrating bibliographies of papers.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 1 table</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07643</dc:identifier>
 <dc:identifier>EPJ Data Science 5:7 doi:10.1140/epjds/s13688-016-0068-2 (2016)</dc:identifier>
 <dc:identifier>doi:10.1140/epjds/s13688-016-0068-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07647</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Environmental Computation in a Multi-Agent Model of Slime
  Mould</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Very simple organisms, such as the single-celled amoeboid slime mould
Physarum polycephalum possess no neural tissue yet, despite this, are known to
exhibit complex biological and computational behaviour. Given such limited
resources, can environmental stimuli play a role in generating the complexity
of slime mould behaviour? We use a multi-agent collective model of slime mould
to explore a two-way mechanism where the collective behaviour is influenced by
simulated chemical concentration gradient fields and, in turn, this behaviour
alters the spatial pattern of the concentration gradients. This simple
mechanism yields complex behaviour amid the dynamically changing gradient
profiles and suggests how the apparently intelligent response of the slime
mould could possibly be due to outsourcing of computation to the environment.
</dc:description>
 <dc:description>Comment: 2014 ABBII International Symposium on Artificial, Biological and
  Bio-Inspired Intelligence, 27-28th September, Rhodes, Greece</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07651</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Material-based Non-neural Analogues of Lateral Inhibition: A Multi-agent
  Approach</dc:title>
 <dc:creator>Jones, Jeff Dale</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Lateral Inhibition (LI) phenomena occur in a wide range of sensory modalities
and are most famously described in the human visual system. In LI the activity
of a stimulated neuron is itself excited and suppresses the activity of its
local neighbours via inhibitory connections, increasing the contrast between
spatial environmental stimuli. Simple or- ganisms, such as the single-celled
slime mould Physarum polycephalum possess no neural tissue yet, despite this,
are known to exhibit complex computational behaviour. Could simple organisms
such as slime mould approximate LI without recourse to neural tissue? We
describe a model whereby LI can emerge without explicit inhibitory wiring,
using only bulk transport effects. We use a multi-agent virtual material model
of slime mould to reproduce the characteristic contrast amplification response
of LI using excitation via attractant stimuli. Restoration of baseline activ-
ity occurs when the stimuli are removed. We also explore an opposite
counterpart behaviour, Lateral Activation (LA), using repellent stimuli. These
preliminary results suggest that simple organisms without neural tissue may
approximate sensory contrast enhancement using alternative analogues of LI and
suggests novel approaches towards generating collec- tive contrast enhancement
in distributed computing and robotic devices.
</dc:description>
 <dc:description>Comment: 2014 - Adaptive Materials, Devices and Systems Towards Unconventional
  Computing and Robotics: Modeling and Implementation, 26th-27th September,
  Rhodes, Greece</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07654</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Guidance of Collective Movement in a Multi-Agent Model of
  Physarum polycephalum</dc:title>
 <dc:creator>Jones, Jeff</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Collective movement occurs in living systems where the simple movements of
individual members of a pop- ulation are combined to generate movement of the
collective as a whole, displaying complex dynamics which cannot be found in the
component parts themselves. The plasmodium stage of slime mould Physarum
polycephalum displays complex amoeboid movement during its foraging and hazard
avoidance and its movement can be influenced by the spatial placement of
attractant and repellent stimuli. Slime mould is attractive to robotics due to
its simple component parts and the distributed nature of its control and
locomotion mechanisms. We investigate methods of automated guidance of a
multi-agent swarm collective along a pre-defined path to a goal location. We
demonstrate a closed-loop feedback mechanism using attractant and repellent
stimuli. We find that guidance by repellent stimuli (a light illumination mask)
provides faster and more accurate guidance than attractant sources, which
exhibit overshooting phenomena at path turns. The method allows traversal of
convoluted arenas with challenging obstacles and provides an insight into how
unconven- tional computing substrates may be hybridised with classical
computing methods to take advantage of the benefits of both approaches.
</dc:description>
 <dc:description>Comment: 2015 - Automated Guidance of Collective Movement in a Multi-Agent
  Model of Physarum polycephalum, Multi-Agent Models on Swarm Behaviour, Swarm
  2015, 28-30 October, Kyoto, Japan</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07658</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Resource Sharing Through GPU Virtualization on Accelerated
  High Performance Computing Systems</dc:title>
 <dc:creator>Li, Teng</dc:creator>
 <dc:creator>Narayana, Vikram K.</dc:creator>
 <dc:creator>El-Ghazawi, Tarek</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The High Performance Computing (HPC) field is witnessing a widespread
adoption of Graphics Processing Units (GPUs) as co-processors for conventional
homogeneous clusters. The adoption of prevalent Single- Program Multiple-Data
(SPMD) programming paradigm for GPU-based parallel processing brings in the
challenge of resource underutilization, with the asymmetrical
processor/co-processor distribution. In other words, under SPMD, balanced
CPU/GPU distribution is required to ensure full resource utilization. In this
paper, we propose a GPU resource virtualization approach to allow underutilized
microprocessors to effi- ciently share the GPUs. We propose an efficient GPU
sharing scenario achieved through GPU virtualization and analyze the
performance potentials through execution models. We further present the
implementation details of the virtualization infrastructure, followed by the
experimental analyses. The results demonstrate considerable performance gains
with GPU virtualization. Furthermore, the proposed solution enables full
utilization of asymmetrical resources, through efficient GPU sharing among
microprocessors, while incurring low overhead due to the added virtualization
layer.
</dc:description>
 <dc:description>Comment: 21 pages</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07663</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Probabilistic Inference via Word-Level Counting</dc:title>
 <dc:creator>Chakraborty, Supratik</dc:creator>
 <dc:creator>Meel, Kuldeep S.</dc:creator>
 <dc:creator>Mistry, Rakesh</dc:creator>
 <dc:creator>Vardi, Moshe Y.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Hashing-based model counting has emerged as a promising approach for
large-scale probabilistic inference on graphical models. A key component of
these techniques is the use of xor-based 2-universal hash functions that
operate over Boolean domains. Many counting problems arising in probabilistic
inference are, however, naturally encoded over finite discrete domains.
Techniques based on bit-level (or Boolean) hash functions require these
problems to be propositionalized, making it impossible to leverage the
remarkable progress made in SMT (Satisfiability Modulo Theory) solvers that can
reason directly over words (or bit-vectors). In this work, we present the first
approximate model counter that uses word-level hashing functions, and can
directly leverage the power of sophisticated SMT solvers. Empirical evaluation
over an extensive suite of benchmarks demonstrates the promise of the approach.
</dc:description>
 <dc:description>Comment: Full version of AAAI 2016 paper</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07677</identifier>
 <datestamp>2016-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A robust extension to the triple plane pressure mode matching method by
  filtering convective perturbations</dc:title>
 <dc:creator>Wohlbrandt, Attila</dc:creator>
 <dc:creator>Weckm&#xfc;ller, Christian</dc:creator>
 <dc:creator>Gu&#xe9;rin, S&#xe9;bastien</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Time-periodic CFD simulations are widely used to investigate turbomachinery
components. The triple-plane pressure mode matching method (TPP) developed by
Ovenden and Rienstra extracts the acoustic part in such simulations. Experience
shows that this method is subject to significant errors when the amplitude of
pseudo-sound is high compared to sound. Pseudo-sound are unsteady pressure
fluctuations with a convective character. The presented extension to the TPP
improves the splitting between acoustics and the rest of the unsteady flow
field. The method is simple: i) the acoustic eigenmodes are analytically
determined for a uniform mean flow as in the original TPP; ii) the suggested
model for convective pressure perturbations uses the convective wavenumber as
axial wavenumber and the same orthogonal radial shape functions as for the
acoustic modes. The reliability is demonstrated on the simulation data of a
low-pressure fan. As acoustic and convective perturbations are separated, the
accuracy of the results increases close to sources, allowing a reduction of the
computational costs by shortening the simulation domain. The extended method is
as robust as the original one--giving the same results for the acoustic modes
in absence of convective perturbations.
</dc:description>
 <dc:description>Comment: Accepted 15-05-11 by International Journal of Aeroacoustics to be
  published in the special issue focusing on turbomachinery aeroacoustics</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07677</dc:identifier>
 <dc:identifier>doi:10.1177/1475472X16630842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07693</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed System for Storing and Processing Data from
  Earth-observing Satellites: System Design and Performance Evaluation of the
  Visualisation Tool</dc:title>
 <dc:creator>Szuba, Marek</dc:creator>
 <dc:creator>Ameri, Parinaz</dc:creator>
 <dc:creator>Grabowski, Udo</dc:creator>
 <dc:creator>Meyer, J&#xf6;rg</dc:creator>
 <dc:creator>Streit, Achim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present a distributed system for storage, processing, three-dimensional
visualisation and basic analysis of data from Earth-observing satellites. The
database and the server have been designed for high performance and
scalability, whereas the client is highly portable thanks to having been
designed as a HTML5- and WebGL-based Web application. The system is based on
the so-called MEAN stack, a modern replacement for LAMP which has steadily been
gaining traction among high-performance Web applications. We demonstrate the
performance of the system from the perspective of an user operating the client.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures. To be published in the proceedings of the 16th
  IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid
  2016)</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07693</dc:identifier>
 <dc:identifier>doi:10.1109/CCGrid.2016.19</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07702</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-complexity Channel Shortening Receiver with Diversity Support for
  Evolved 2G Device</dc:title>
 <dc:creator>Hu, Sha</dc:creator>
 <dc:creator>Kroll, Harald</dc:creator>
 <dc:creator>Huang, Qiuting</dc:creator>
 <dc:creator>Rusek, Fredrik</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The second generation (2G) cellular networks are the current workhorse for
machine-to-machine (M2M) communications. Diversity in 2G devices can be present
both in form of multiple receive branches and blind repetitions. In presence of
diversity, intersymbol interference (ISI) equalization and co-channel
interference (CCI) suppression are usually very complex. In this paper, we
consider the improvements for 2G devices with receive diversity. We derive a
low-complexity receiver based on a channel shortening filter, which allows to
sum up all diversity branches to a single stream after filtering while keeping
the full diversity gain. The summed up stream is subsequently processed by a
single stream Max-log-MAP (MLM) equalizer. The channel shortening filter is
designed to maximize the mutual information lower bound (MILB) with the
Ungerboeck detection model. Its filter coefficients can be obtained mainly by
means of discrete-Fourier transforms (DFTs). Compared with the state-of-art
homomorphic (HOM) filtering based channel shortener which cooperates with a
delayed-decision feedback MLM (DDF-MLM) equalizer, the proposed MILB channel
shortener has superior performance. Moreover, the equalization complexity, in
terms of real-valued multiplications, is decreased by a factor that equals the
number of diversity branches.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07710</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching for Objects using Structure in Indoor Scenes</dc:title>
 <dc:creator>Nagaraja, Varun K.</dc:creator>
 <dc:creator>Morariu, Vlad I.</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  To identify the location of objects of a particular class, a passive computer
vision system generally processes all the regions in an image to finally output
few regions. However, we can use structure in the scene to search for objects
without processing the entire image. We propose a search technique that
sequentially processes image regions such that the regions that are more likely
to correspond to the query class object are explored earlier. We frame the
problem as a Markov decision process and use an imitation learning algorithm to
learn a search strategy. Since structure in the scene is essential for search,
we work with indoor scene images as they contain both unary scene context
information and object-object context in the scene. We perform experiments on
the NYU-depth v2 dataset and show that the unary scene context features alone
can achieve a significantly high average precision while processing only
20-25\% of the regions for classes like bed and sofa. By considering
object-object context along with the scene context features, the performance is
further improved for classes like counter, lamp, pillow and sofa.
</dc:description>
 <dc:description>Comment: Appeared in British Machine Vision Conference (BMVC) 2015</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07710</dc:identifier>
 <dc:identifier>doi:10.5244/C.29.53</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07714</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Python Engine for Teaching Artificial Intelligence in Games</dc:title>
 <dc:creator>Riedl, Mark O.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:subject>K.8.0</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Computer games play an important role in our society and motivate people to
learn computer science. Since artificial intelligence is integral to most
games, they can also be used to teach artificial intelligence. We introduce the
Game AI Game Engine (GAIGE), a Python game engine specifically designed to
teach about how AI is used in computer games. A progression of seven
assignments builds toward a complete, working Multi-User Battle Arena (MOBA)
game. We describe the engine, the assignments, and our experiences using it in
a class on Game Artificial Intelligence.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07727</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DiffSharp: Automatic Differentiation Library</dc:title>
 <dc:creator>Baydin, Atilim Gunes</dc:creator>
 <dc:creator>Pearlmutter, Barak A.</dc:creator>
 <dc:creator>Siskind, Jeffrey Mark</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>68T05, 68W30</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>G.1.4</dc:subject>
 <dc:description>  In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, minor fixes, added coauthor</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07729</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A communication game related to the sensitivity conjecture</dc:title>
 <dc:creator>Gilmer, Justin</dc:creator>
 <dc:creator>Kouck&#xfd;, Michal</dc:creator>
 <dc:creator>Saks, Michael</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68R05 (primary), 68Q01, 05D05 (secondary)</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>G.2.m</dc:subject>
 <dc:description>  One of the major outstanding foundational problems about boolean functions is
the sensitivity conjecture, which (in one of its many forms) asserts that the
degree of a boolean function (i.e. the minimum degree of a real polynomial that
interpolates the function) is bounded above by some fixed power of its
sensitivity (which is the maximum vertex degree of the graph defined on the
inputs where two inputs are adjacent if they differ in exactly one coordinate
and their function values are different). We propose an attack on the
sensitivity conjecture in terms of a novel two-player communication game. A
lower bound of the form $n^{\Omega(1)}$ on the cost of this game would imply
the sensitivity conjecture.
  To investigate the problem of bounding the cost of the game, three natural
(stronger) variants of the question are considered. For two of these variants,
protocols are presented that show that the hoped for lower bound does not hold.
These protocols satisfy a certain monotonicity property, and (in contrast to
the situation for the two variants) we show that the cost of any monotone
protocol satisfies a strong lower bound.
  There is an easy upper bound of $\sqrt{n}$ on the cost of the game. We also
improve slightly on this upper bound.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07732</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Identification of Fixations, Saccades, and Smooth Pursuits</dc:title>
 <dc:creator>Santini, Thiago</dc:creator>
 <dc:creator>Fuhl, Wolfgang</dc:creator>
 <dc:creator>K&#xfc;bler, Thomas</dc:creator>
 <dc:creator>Kasneci, Enkelejda</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:subject>J.7</dc:subject>
 <dc:description>  Smooth pursuit eye movements provide meaningful insights and information on
subject's behavior and health and may, in particular situations, disturb the
performance of typical fixation/saccade classification algorithms. Thus, an
automatic and efficient algorithm to identify these eye movements is paramount
for eye-tracking research involving dynamic stimuli. In this paper, we propose
the Bayesian Decision Theory Identification (I-BDT) algorithm, a novel
algorithm for ternary classification of eye movements that is able to reliably
separate fixations, saccades, and smooth pursuits in an online fashion, even
for low-resolution eye trackers. The proposed algorithm is evaluated on four
datasets with distinct mixtures of eye movements, including fixations,
saccades, as well as straight and circular smooth pursuits; data was collected
with a sample rate of 30 Hz from six subjects, totaling 24 evaluation datasets.
The algorithm exhibits high and consistent performance across all datasets and
movements relative to a manual annotation by a domain expert (recall: \mu =
91.42%, \sigma = 9.52%; precision: \mu = 95.60%, \sigma = 5.29%; specificity
\mu = 95.41%, \sigma = 7.02%) and displays a significant improvement when
compared to I-VDT, an state-of-the-art algorithm (recall: \mu = 87.67%, \sigma
= 14.73%; precision: \mu = 89.57%, \sigma = 8.05%; specificity \mu = 92.10%,
\sigma = 11.21%). For algorithm implementation and annotated datasets, please
contact the first author.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07741</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Fault Tolerant Reachability for Directed Graphs</dc:title>
 <dc:creator>Georgiadis, Loukas</dc:creator>
 <dc:creator>Tarjan, Robert E.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this note we describe an application of low-high orders in fault-tolerant
network design. Baswana et al. [DISC 2015] study the following reachability
problem. We are given a flow graph $G = (V, A)$ with start vertex $s$, and a
spanning tree $T =(V, A_T)$ rooted at $s$. We call a set of arcs $A'$ valid if
the subgraph $G' = (V, A_T \cup A')$ of $G$ has the same dominators as $G$. The
goal is to find a valid set of minimum size. Baswana et al. gave an $O(m
\log{n})$-time algorithm to compute a minimum-size valid set in $O(m \log{n})$
time, where $n = |V|$ and $m = |A|$. Here we provide a simple $O(m)$-time
algorithm that uses the dominator tree $D$ of $G$ and a low-high order of it.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07763</identifier>
 <datestamp>2016-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LocNet: Improving Localization Accuracy for Object Detection</dc:title>
 <dc:creator>Gidaris, Spyros</dc:creator>
 <dc:creator>Komodakis, Nikos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose a novel object localization methodology with the purpose of
boosting the localization accuracy of state-of-the-art object detection
systems. Our model, given a search region, aims at returning the bounding box
of an object of interest inside this region. To accomplish its goal, it relies
on assigning conditional probabilities to each row and column of this region,
where these probabilities provide useful information regarding the location of
the boundaries of the object inside the search region and allow the accurate
inference of the object bounding box under a simple probabilistic framework.
  For implementing our localization model, we make use of a convolutional
neural network architecture that is properly adapted for this task, called
LocNet. We show experimentally that LocNet achieves a very significant
improvement on the mAP for high IoU thresholds on PASCAL VOC2007 test set and
that it can be very easily coupled with recent state-of-the-art object
detection systems, helping them to boost their performance. Finally, we
demonstrate that our detection approach can achieve high detection accuracy
even when it is given as input a set of sliding windows, thus proving that it
is independent of box proposal methods.
</dc:description>
 <dc:description>Comment: Extended technical report -- short version to appear as oral paper on
  CVPR 2016. Code: https://github.com/gidariss/LocNet/</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07788</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spoken Language Translation for Polish</dc:title>
 <dc:creator>Marasek, Krzysztof</dc:creator>
 <dc:creator>Brocki, &#x141;ukasz</dc:creator>
 <dc:creator>Korzinek, Danijel</dc:creator>
 <dc:creator>Wo&#x142;k, Krzysztof</dc:creator>
 <dc:creator>Gubrynowicz, Ryszard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Spoken language translation (SLT) is becoming more important in the
increasingly globalized world, both from a social and economic point of view.
It is one of the major challenges for automatic speech recognition (ASR) and
machine translation (MT), driving intense research activities in these areas.
While past research in SLT, due to technology limitations, dealt mostly with
speech recorded under controlled conditions, today's major challenge is the
translation of spoken language as it can be found in real life. Considered
application scenarios range from portable translators for tourists, lectures
and presentations translation, to broadcast news and shows with live
captioning. We would like to present PJIIT's experiences in the SLT gained from
the Eu-Bridge 7th framework project and the U-Star consortium activities for
the Polish/English language pair. Presented research concentrates on ASR
adaptation for Polish (state-of-the-art acoustic models: DBN-BLSTM training,
Kaldi: LDA+MLLT+SAT+MMI), language modeling for ASR &amp; MT (text normalization,
RNN-based LMs, n-gram model domain interpolation) and statistical translation
techniques (hierarchical models, factored translation models, automatic casing
and punctuation, comparable and bilingual corpora preparation). While results
for the well-defined domains (phrases for travelers, parliament speeches,
medical documentation, movie subtitling) are very encouraging, less defined
domains (presentation, lectures) still form a challenge. Our progress in the
IWSLT TED task (MT only) will be presented, as well as current progress in the
Polish ASR.
</dc:description>
 <dc:description>Comment: Marasek K., Wo{\l}k K., Korzinek D., Brocki {\L}., Spoken Language
  Translation for Polish, Proceedings of Forum Acuscticum 2014, Krak\'ow. arXiv
  admin note: substantial text overlap with arXiv:1509.08909</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07792</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two Countermeasures Against Hardware Trojans Exploiting Non-Zero
  Aliasing Probability of BIST</dc:title>
 <dc:creator>Dubrova, Elena</dc:creator>
 <dc:creator>N&#xe4;slund, Mats</dc:creator>
 <dc:creator>Carlsson, Gunnar</dc:creator>
 <dc:creator>Fornehed, John</dc:creator>
 <dc:creator>Smeets, Ben</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The threat of hardware Trojans has been widely recognized by academia,
industry, and government agencies. A Trojan can compromise security of a system
in spite of cryptographic protection. The damage caused by a Trojan may not be
limited to a business or reputation, but could have a severe impact on public
safety, national economy, or national security. An extremely stealthy way of
implementing hardware Trojans has been presented by Becker et al. at CHES'2012.
Their work have shown that it is possible to inject a Trojan in a random number
generator compliant with FIPS 140-2 and NIST SP800-90 standards by exploiting
non-zero aliasing probability of Logic Built-In-Self-Test (LBIST). In this
paper, we present two methods for modifying LBIST to prevent such an attack.
The first method makes test patterns dependent on a configurable key which is
programed into a chip after the manufacturing stage. The second method uses a
remote test management system which can execute LBIST using a different set of
test patterns at each test cycle.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07803</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Object Boundaries</dc:title>
 <dc:creator>Khoreva, Anna</dc:creator>
 <dc:creator>Benenson, Rodrigo</dc:creator>
 <dc:creator>Omran, Mohamed</dc:creator>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art learning based boundary detection methods require extensive
training data. Since labelling object boundaries is one of the most expensive
types of annotations, there is a need to relax the requirement to carefully
annotate images to make both the training more affordable and to extend the
amount of training data. In this paper we propose a technique to generate
weakly supervised annotations and show that bounding box annotations alone
suffice to reach high-quality object boundaries without using any
object-specific boundary annotations. With the proposed weak supervision
techniques we achieve the top performance on the object boundary detection
task, outperforming by a large margin the current fully supervised
state-of-the-art methods.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07826</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lift-and-Round to Improve Weighted Completion Time on Unrelated Machines</dc:title>
 <dc:creator>Bansal, Nikhil</dc:creator>
 <dc:creator>Srinivasan, Aravind</dc:creator>
 <dc:creator>Svensson, Ola</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of scheduling jobs on unrelated machines so as to
minimize the sum of weighted completion times. Our main result is a
$(3/2-c)$-approximation algorithm for some fixed $c&gt;0$, improving upon the
long-standing bound of 3/2 (independently due to Skutella, Journal of the ACM,
2001, and Sethuraman &amp; Squillante, SODA, 1999). To do this, we first introduce
a new lift-and-project based SDP relaxation for the problem. This is necessary
as the previous convex programming relaxations have an integrality gap of
$3/2$. Second, we give a new general bipartite-rounding procedure that produces
an assignment with certain strong negative correlation properties.
</dc:description>
 <dc:description>Comment: 21 pages, 4 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07829</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$E_{\gamma}$-Resolvability</dc:title>
 <dc:creator>Liu, Jingbo</dc:creator>
 <dc:creator>Cuff, Paul</dc:creator>
 <dc:creator>Verd&#xfa;, Sergio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The conventional channel resolvability refers to the minimum rate needed for
an input process to approximate the channel output distribution in total
variation distance. In this paper we study $E_{\gamma}$-resolvability, in which
total variation is replaced by the more general $E_{\gamma}$ distance. A
general one-shot achievability bound for the precision of such an approximation
is developed. Let $Q_{\sf X|U}$ be a random transformation, $n$ be an integer,
and $E\in(0,+\infty)$. We show that in the asymptotic setting where
$\gamma=\exp(nE)$, a (nonnegative) randomness rate above $\inf_{Q_{\sf U}:
D(Q_{\sf X}\|{{\pi}}_{\sf X})\le E} \{D(Q_{\sf X}\|{{\pi}}_{\sf X})+I(Q_{\sf
U},Q_{\sf X|U})-E\}$ is sufficient to approximate the output distribution
${{\pi}}_{\sf X}^{\otimes n}$ using the channel $Q_{\sf X|U}^{\otimes n}$,
where $Q_{\sf U}\to Q_{\sf X|U}\to Q_{\sf X}$, and is also necessary in the
case of finite $\mathcal{U}$ and $\mathcal{X}$. In particular, a randomness
rate of $\inf_{Q_{\sf U}}I(Q_{\sf U},Q_{\sf X|U})-E$ is always sufficient. We
also study the convergence of the approximation error under the high
probability criteria in the case of random codebooks. Moreover, by developing
simple bounds relating $E_{\gamma}$ and other distance measures, we are able to
determine the exact linear growth rate of the approximation errors measured in
relative entropy and smooth R\'{e}nyi divergences for a fixed-input randomness
rate. The new resolvability result is then used to derive 1) a one-shot upper
bound on the probability of excess distortion in lossy compression, which is
exponentially tight in the i.i.d.~setting, 2) a one-shot version of the mutual
covering lemma, and 3) a lower bound on the size of the eavesdropper list to
include the actual message and a lower bound on the eavesdropper false-alarm
probability in the wiretap channel problem, which is (asymptotically)
ensemble-tight.
</dc:description>
 <dc:description>Comment: 30 pages, 5 figures, presented in part at 2015 IEEE International
  Symposium on Information Theory (ISIT)</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07837</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Conjugate Gradient Methods for $\ell_1$ Regularized Convex
  Quadratic Programming with Finite Convergence</dc:title>
 <dc:creator>Lu, Zhaosong</dc:creator>
 <dc:creator>Chen, Xiaojun</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>65C60, 65K05, 65Y20, 90C06, 90C20, 90C25</dc:subject>
 <dc:description>  The conjugate gradient (CG) method is an efficient iterative method for
solving large-scale strongly convex quadratic programming (QP). In this paper
we propose some generalized CG (GCG) methods for solving the
$\ell_1$-regularized (possibly not strongly) convex QP that terminate at an
optimal solution in a finite number of iterations. At each iteration, our
methods first identify a face of an orthant and then either perform an exact
line search along the direction of the negative projected minimum-norm
subgradient of the objective function or execute a CG subroutine that conducts
a sequence of CG iterations until a CG iterate crosses the boundary of this
face or an approximate minimizer of over this face or a subface is found. We
determine which type of step should be taken by comparing the magnitude of some
components of the minimum-norm subgradient of the objective function to that of
its rest components. Our analysis on finite convergence of these methods makes
use of an error bound result and some key properties of the aforementioned
exact line search and the CG subroutine. We also show that the proposed methods
are capable of finding an approximate solution of the problem by allowing some
inexactness on the execution of the CG subroutine. The overall arithmetic
operation cost of our GCG methods for finding an $\epsilon$-optimal solution
depends on $\epsilon$ in $O(\log(1/\epsilon))$, which is superior to the
accelerated proximal gradient method [2,23] that depends on $\epsilon$ in
$O(1/\sqrt{\epsilon})$. In addition, our GCG methods can be extended
straightforwardly to solve box-constrained convex QP with finite convergence.
Numerical results demonstrate that our methods are very favorable for solving
ill-conditioned problems.
</dc:description>
 <dc:description>Comment: 36 pages, 2 tables</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07838</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Capacity Networks</dc:title>
 <dc:creator>Almahairi, Amjad</dc:creator>
 <dc:creator>Ballas, Nicolas</dc:creator>
 <dc:creator>Cooijmans, Tim</dc:creator>
 <dc:creator>Zheng, Yin</dc:creator>
 <dc:creator>Larochelle, Hugo</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce the Dynamic Capacity Network (DCN), a neural network that can
adaptively assign its capacity across different portions of the input data.
This is achieved by combining modules of two types: low-capacity sub-networks
and high-capacity sub-networks. The low-capacity sub-networks are applied
across most of the input, but also provide a guide to select a few portions of
the input on which to apply the high-capacity sub-networks. The selection is
made using a novel gradient-based attention mechanism, that efficiently
identifies input regions for which the DCN's output is most sensitive and to
which we should devote more capacity. We focus our empirical evaluation on the
Cluttered MNIST and SVHN image datasets. Our findings indicate that DCNs are
able to drastically reduce the number of computations, compared to traditional
convolutional neural networks, while maintaining similar or even better
performance.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07845</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape and Symmetry Induction for 3D Objects</dc:title>
 <dc:creator>Tulsiani, Shubham</dc:creator>
 <dc:creator>Kar, Abhishek</dc:creator>
 <dc:creator>Huang, Qixing</dc:creator>
 <dc:creator>Carreira, Jo&#xe3;o</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Actions as simple as grasping an object or navigating around it require a
rich understanding of that object's 3D shape from a given viewpoint. In this
paper we repurpose powerful learning machinery, originally developed for object
classification, to discover image cues relevant for recovering the 3D shape of
potentially unfamiliar objects. We cast the problem as one of local prediction
of surface normals and global detection of 3D reflection symmetry planes, which
open the door for extrapolating occluded surfaces from visible ones. We
demonstrate that our method is able to recover accurate 3D shape information
for classes of objects it was not trained on, in both synthetic and real
images.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07846</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incremental Query Processing on Big Data Streams</dc:title>
 <dc:creator>Fegaras, Leonidas</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper addresses online query processing for large-scale, incremental
data analysis on a distributed stream processing engine (DSPE). Our goal is to
convert any SQL-like query to an incremental DSPE program automatically. In
contrast to other approaches, we derive incremental programs that return
accurate results, not approximate answers. This is accomplished by retaining a
minimal state during the query evaluation lifetime and by using incremental
evaluation techniques to return an accurate snapshot answer at each time
interval that depends on the current state and the latest batches of data. Our
methods can handle many forms of queries on nested data collections, including
iterative and nested queries, group-by with aggregation, and equi-joins.
Finally, we report on a prototype implementation of our framework, called MRQL
Streaming, running on top of Spark and we experimentally validate the
effectiveness of our methods.
</dc:description>
 <dc:description>Comment: Extended version of a paper submitted to a journal</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07846</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2016.2601103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07847</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shortest Connection Game</dc:title>
 <dc:creator>Darmann, Andreas</dc:creator>
 <dc:creator>Pferschy, Ulrich</dc:creator>
 <dc:creator>Schauer, Joachim</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We introduce Shortest Connection Game, a two-player game played on a directed
graph with edge costs. Given two designated vertices in which they start, the
players take turns in choosing edges emanating from the vertex they are
currently located at. In this way, each of the players forms a path that
origins from its respective starting vertex. The game ends as soon as the two
paths meet, i.e., a connection between the players is established. Each player
has to carry the cost of its chosen edges and thus aims at minimizing its own
total cost.
  In this work we analyze the computational complexity of Shortest Connection
Game. On the negative side, the game turns out to be computationally hard even
on restricted graph classes such as bipartite, acyclic and cactus graphs. On
the positive side, we can give a polynomial time algorithm for cactus graphs
when the game is restricted to simple paths.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07860</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Linear Gate and Super-Quadratic Wire Lower Bounds for Depth-Two
  and Depth-Three Threshold Circuits</dc:title>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Williams, Ryan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68Q17</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  In order to formally understand the power of neural computing, we first need
to crack the frontier of threshold circuits with two and three layers, a regime
that has been surprisingly intractable to analyze. We prove the first
super-linear gate lower bounds and the first super-quadratic wire lower bounds
for depth-two linear threshold circuits with arbitrary weights, and depth-three
majority circuits computing an explicit function.
  $\bullet$ We prove that for all $\epsilon\gg \sqrt{\log(n)/n}$, the
linear-time computable Andreev's function cannot be computed on a
$(1/2+\epsilon)$-fraction of $n$-bit inputs by depth-two linear threshold
circuits of $o(\epsilon^3 n^{3/2}/\log^3 n)$ gates, nor can it be computed with
$o(\epsilon^{3} n^{5/2}/\log^{7/2} n)$ wires. This establishes an average-case
``size hierarchy'' for threshold circuits, as Andreev's function is computable
by uniform depth-two circuits of $o(n^3)$ linear threshold gates, and by
uniform depth-three circuits of $O(n)$ majority gates.
  $\bullet$ We present a new function in $P$ based on small-biased sets, which
we prove cannot be computed by a majority vote of depth-two linear threshold
circuits with $o(n^{3/2}/\log^3 n)$ gates, nor with $o(n^{5/2}/\log^{7/2}n)$
wires.
  $\bullet$ We give tight average-case (gate and wire) complexity results for
computing PARITY with depth-two threshold circuits; the answer turns out to be
the same as for depth-two majority circuits.
  The key is a new random restriction lemma for linear threshold functions. Our
main analytical tool is the Littlewood-Offord Lemma from additive
combinatorics.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07865</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Resolution: a Framework for Coinductive Proof Search and
  Proof Construction in Horn Clause Logic</dc:title>
 <dc:creator>Komendantskaya, Ekaterina</dc:creator>
 <dc:creator>Johann, Patricia</dc:creator>
 <dc:creator>Schmidt, Martin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Logic programming (LP) is a programming language based on first-order Horn
clause logic that uses SLD-resolution as a semi-decision procedure. Finite
SLD-computations are inductively sound and complete with respect to least
Herbrand models of logic programs. Dually, the corecursive approach to
SLD-resolution views infinite SLD-computations as successively approximating
infinite terms contained in programs' greatest complete Herbrand models.
State-of-the-art algorithms implementing corecursion in LP are based on loop
detection. However, such algorithms support inference of logical entailment
only for rational terms, and they do not account for the important property of
productivity in infinite SLD-computations. Loop detection thus lags behind
coinductive methods in interactive theorem proving (ITP) and term-rewriting
systems (TRS).
  Structural resolution is a newly proposed alternative to SLD-resolution that
makes it possible to define and semi-decide a notion of productivity
appropriate to LP. In this paper, we prove soundness of structural resolution
relative to Herbrand model semantics for productive inductive, coinductive, and
mixed inductive-coinductive logic programs.
  We introduce two algorithms that support coinductive proof search for
infinite productive terms. One algorithm combines the method of loop detection
with productive structural resolution, thus guaranteeing productivity of
coinductive proofs for infinite rational terms. The other allows to make lazy
sound observations of fragments of infinite irrational productive terms. This
puts coinductive methods in LP on par with productivity-based observational
approaches to coinduction in ITP and TRS.
</dc:description>
 <dc:description>Comment: A working draft</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07888</identifier>
 <datestamp>2016-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interval peak-to-peak observers for continuous- and discrete-time
  systems with persistent inputs and delays</dc:title>
 <dc:creator>Briat, Corentin</dc:creator>
 <dc:creator>Khammash, Mustafa</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  While the design of optimal peak-to-peak controllers/observers for linear
systems is known to be a difficult problem, this problem becomes interestingly
much easier in the context of interval observers because of the positive nature
of the error dynamics. Indeed, by exploiting several recent results on positive
systems, we propose a novel and non-conservative approach formulated in terms
of tractable finite-dimensional linear programs for designing a class of
interval observers achieving minimum peak-to-peak gain. The optimal observer is
notably shown to be uniform over the set of all possible mappings between
observation errors and their weighted versions, which parallels a recent result
on the stabilization of linear positive systems. Results pertaining on the
interval observation of time-delay and discrete-time systems are then obtained
as a direct application of the proposed method, emphasizing then its
versatility. Several examples on the interval observation of linear and
nonlinear systems are finally given for illustration.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07889</identifier>
 <datestamp>2015-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>rnn : Recurrent Library for Torch</dc:title>
 <dc:creator>L&#xe9;onard, Nicholas</dc:creator>
 <dc:creator>Waghmare, Sagar</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Kim, Jin-Hwa</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  The rnn package provides components for implementing a wide range of
Recurrent Neural Networks. It is built withing the framework of the Torch
distribution for use with the nn package. The components have evolved from 3
iterations, each adding to the flexibility and capability of the package. All
component modules inherit either the AbstractRecurrent or AbstractSequencer
classes. Strong unit testing, continued backwards compatibility and access to
supporting material are the principles followed during its development. The
package is compared against existing implementations of two published papers.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07893</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Investigation of Metrics for Epidemic Processes on Graphs</dc:title>
 <dc:creator>Goering, Max</dc:creator>
 <dc:creator>Sahneh, Faryad Darabi</dc:creator>
 <dc:creator>Albin, Nathan</dc:creator>
 <dc:creator>Scoglio, Caterina</dc:creator>
 <dc:creator>Poggi-Corradini, Pietro</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  This study develops the epidemic hitting time (EHT) metric on graphs
measuring the expected time an epidemic starting at node $a$ in a fully
susceptible network takes to propagate and reach node $b$. An associated EHT
centrality measure is then compared to degree, betweenness, spectral, and
effective resistance centrality measures through exhaustive numerical
simulations on several real-world network data-sets. We find two surprising
observations: first, EHT centrality is highly correlated with effective
resistance centrality; second, the EHT centrality measure is much more
delocalized compared to degree and spectral centrality, highlighting the role
of peripheral nodes in epidemic spreading on graphs.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 3 tables, In Proceedings of 2015 Asilomar
  Conference on Signals, Systems, and Computers</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07896</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Posterior distributions from Variational approximations</dc:title>
 <dc:creator>Karwa, Vishesh</dc:creator>
 <dc:creator>Kifer, Dan</dc:creator>
 <dc:creator>Slavkovi&#x107;, Aleksandra B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Privacy preserving mechanisms such as differential privacy inject additional
randomness in the form of noise in the data, beyond the sampling mechanism.
Ignoring this additional noise can lead to inaccurate and invalid inferences.
In this paper, we incorporate the privacy mechanism explicitly into the
likelihood function by treating the original data as missing, with an end goal
of estimating posterior distributions over model parameters. This leads to a
principled way of performing valid statistical inference using private data,
however, the corresponding likelihoods are intractable. In this paper, we
derive fast and accurate variational approximations to tackle such intractable
likelihoods that arise due to privacy. We focus on estimating posterior
distributions of parameters of the naive Bayes log-linear model, where the
sufficient statistics of this model are shared using a differentially private
interface. Using a simulation study, we show that the posterior approximations
outperform the naive method of ignoring the noise addition mechanism.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07902</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Limits of Stochastic Sub-Gradient Learning, Part I: Single
  Agent Case</dc:title>
 <dc:creator>Ying, Bicheng</dc:creator>
 <dc:creator>Sayed, Ali H.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  In this work and the supporting Part II, we examine the performance of
stochastic sub-gradient learning strategies under weaker conditions than
usually considered in the literature. The new conditions are shown to be
automatically satisfied by several important cases of interest including SVM,
LASSO, and Total-Variation denoising formulations. In comparison, these
problems do not satisfy the traditional assumptions used in prior analyses and,
therefore, conclusions derived from these earlier treatments are not directly
applicable to these problems. The results in this article establish that
stochastic sub-gradient strategies can attain linear convergence rates, as
opposed to sub-linear rates, to the steady-state regime. A realizable
exponential-weighting procedure is employed to smooth the intermediate iterates
and guarantee useful performance bounds in terms of convergence rate and
excessive risk performance. Part I of this work focuses on single-agent
scenarios, which are common in stand-alone learning applications, while Part II
extends the analysis to networked learners. The theoretical conclusions are
illustrated by several examples and simulations, including comparisons with the
FISTA procedure.
</dc:description>
 <dc:description>Comment: Part II is available on http://arxiv.org/abs/1704.06025</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2017-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07903</identifier>
 <datestamp>2016-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Design for $\alpha$-Duplex Communications in Multi-Tier
  Cellular Networks</dc:title>
 <dc:creator>AlAmmouri, Ahmad</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Backward compatibility is an essential ingredient for the success of new
technologies. In the context of in-band full-duplex (FD) communication, FD base
stations (BSs) should support half-duplex (HD) users' equipment (UEs) without
sacrificing the foreseen FD gains. This paper presents flexible and tractable
modeling framework for multi-tier cellular networks with FD BSs and FD/HD UEs.
The presented model is based on stochastic geometry and accounts for the
intrinsic vulnerability of uplink transmissions. The results show that FD UEs
are not necessarily required to harvest rate gains from FD BSs. In particular,
the results show that adding FD UEs to FD BSs offers a maximum of $5\%$ rate
gain over FD BSs and HD UEs case if multi-user diversity is exploited, which is
a marginal gain compared to the burden required to implement FD transceivers at
the UEs' side. To this end, we shed light on practical scenarios where HD UEs
operation with FD BSs outperforms the operation when both the BSs and UEs are
FD and we find a closed form expression for the critical value of the
self-interference attenuation power required for the FD UEs to outperform HD
UEs.
</dc:description>
 <dc:description>Comment: Submitted to Tcom</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07907</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competitive Charging Station Pricing for Plug-in Electric Vehicles</dc:title>
 <dc:creator>Yuan, Wei</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:creator>Zhang, Ying Jun</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers the problem of charging station pricing and plug-in
electric vehicles (PEVs) station selection. When a PEV needs to be charged, it
selects a charging station by considering the charging prices, waiting times,
and travel distances. Each charging station optimizes its charging price based
on the prediction of the PEVs' charging station selection decisions and the
other station's pricing decision, in order to maximize its profit. To obtain
insights of such a highly coupled system, we consider a one-dimensional system
with two competing charging stations and Poisson arriving PEVs. We propose a
multi-leader-multi-follower Stackelberg game model, in which the charging
stations (leaders) announce their charging prices in Stage I, and the PEVs
(followers) make their charging station selections in Stage II. We show that
there always exists a unique charging station selection equilibrium in Stage
II, and such equilibrium depends on the charging stations' service capacities
and the price difference between them. We then characterize the sufficient
conditions for the existence and uniqueness of the pricing equilibrium in Stage
I. We also develop a low complexity algorithm that efficiently computes the
pricing equilibrium and the subgame perfect equilibrium of the two-stage
Stackelberg game.
</dc:description>
 <dc:description>Comment: 15 pages, 21 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2015-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07907</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07910</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Performance of Circularly Pulse-Shaped Waveforms for 5G</dc:title>
 <dc:creator>RezazadehReyhani, Ahmad</dc:creator>
 <dc:creator>Farhang-Boroujeny, Behrouz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The fifth generation of wireless networks (5G) necessitates the use of
waveforms with loose constraints on synchronization in multiuser scenarios.
Also, carrier aggregation, as a way to better utilize the spectrum in 5G, needs
a waveform with low out-of-band (OOB) emission. Generalized frequency division
multiplexing (GFDM) and circular filter bank multicarrier (C-FBMC) are two
candidate waveforms that fulfill these requirements. Both GFDM and C-FBMC
operate based on circular convolution, and use cyclic prefix to combat channel
response. In this paper, we develop an analytical technique for examining the
OOB emission and multiuser interference (MUI) in circularly shaped waveforms,
like GFDM and C-FBMC. To stay focused, the study in this paper is limited to
C-FBMC modulation. However, the approach we take is trivially extendable to
other waveforms as well. We derive equations that quantify OOB emission and
MUI. Our analysis allows us to identify the source of OOB emission and MUI.
This leads us to quantify the methods proposed by other researchers to decrease
OOB emission and MUI. Moreover, we quantify the impact of signal windowing at
the transmitter and receiver in reducing OOB emission and MUI, respectively.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07915</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical circuits with Physarum Wires</dc:title>
 <dc:creator>Whiting, James G. H.</dc:creator>
 <dc:creator>Mayne, Richard</dc:creator>
 <dc:creator>Moody, Nadine</dc:creator>
 <dc:creator>Costello, Ben de Lacy</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Purpose: Protoplasmic tubes of Physarum polycephalum, also know as Physarum
Wires (PW), have been previously suggested as novel bio- electronic components.
Until recently, practical examples of electronic circuits using PWs have been
limited. These PWs have been shown to be self repairing, offering significant
advantage over traditional electronic components. This article documents work
performed to produce practical circuits using PWs. Method: We have demonstrated
through manufacture and testing of hybrid circuits that PWs can be used to
produce a variety of practical electronic circuits. A purality of different
applications of PWs have been tested to show the universality of PWs in
analogue and digital electronics. Results: Voltage dividers can be produced
using a pair of PWs in series with an output voltage accurate to within 12%.
PWs can also transmit analogue and digital data with a frequency of up to 19
kHz, which with the addition of a buffer, can drive high current circuits. We
have demonstrated that PWs can last approximately two months, a 4 fold increase
on previous literature. Protoplasmic tubes can be modified with the addition of
conductive or magnetic nano-particles to provide changes in functionality.
Conclusion This work has documented novel macro-scale data transmission through
biological material; it has advanced the field of bio-electronics by providing
a cheap and easy to grow conducting bio-material which may be used in future
hybrid electronic technology.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07916</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Natural Language Understanding with Distributed Representation</dc:title>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This is a lecture note for the course DS-GA 3001 &lt;Natural Language
Understanding with Distributed Representation&gt; at the Center for Data Science ,
New York University in Fall, 2015. As the name of the course suggests, this
lecture note introduces readers to a neural network based approach to natural
language understanding/processing. In order to make it as self-contained as
possible, I spend much time on describing basics of machine learning and neural
networks, only after which how they are used for natural languages is
introduced. On the language front, I almost solely focus on language modelling
and machine translation, two of which I personally find most fascinating and
most fundamental to natural language understanding.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07916</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07917</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-aware CNNs for person head detection</dc:title>
 <dc:creator>Vu, Tuan-Hung</dc:creator>
 <dc:creator>Osokin, Anton</dc:creator>
 <dc:creator>Laptev, Ivan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Person detection is a key problem for many computer vision tasks. While face
detection has reached maturity, detecting people under a full variation of
camera view-points, human poses, lighting conditions and occlusions is still a
difficult challenge. In this work we focus on detecting human heads in natural
scenes. Starting from the recent local R-CNN object detector, we extend it with
two types of contextual cues. First, we leverage person-scene relations and
propose a Global CNN model trained to predict positions and scales of heads
directly from the full image. Second, we explicitly model pairwise relations
among objects and train a Pairwise CNN model using a structured-output
surrogate loss. The Local, Global and Pairwise models are combined into a joint
CNN framework. To train and test our full model, we introduce a large dataset
composed of 369,846 human heads annotated in 224,740 movie frames. We evaluate
our method and demonstrate improvements of person head detection against
several recent baselines in three datasets. We also show improvements of the
detection speed provided by our model.
</dc:description>
 <dc:description>Comment: To appear in International Conference on Computer Vision (ICCV), 2015</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07922</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contraction of Ore Ideals with Applications</dc:title>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Ore operators form a common algebraic abstraction of linear ordinary
differential and recurrence equations. Given an Ore operator $L$ with
polynomial coefficients in $x$, it generates a left ideal $I$ in the Ore
algebra over the field $\mathbf{k}(x)$ of rational functions. We present an
algorithm for computing a basis of the contraction ideal of $I$ in the Ore
algebra over the ring $R[x]$ of polynomials, where $R$ may be either
$\mathbf{k}$ or a domain with $\mathbf{k}$ as its fraction field. This
algorithm is based on recent work on desingularization for Ore operators by
Chen, Jaroschek, Kauers and Singer. Using a basis of the contraction ideal, we
compute a completely desingularized operator for $L$ whose leading coefficient
not only has minimal degree in $x$ but also has minimal content. Completely
desingularized operators have interesting applications such as certifying
integer sequences and checking special cases of a conjecture of Krattenthaler.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07927</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principal Basis Analysis in Sparse Representation</dc:title>
 <dc:creator>Sun, Hong</dc:creator>
 <dc:creator>Sang, Cheng-Wei</dc:creator>
 <dc:creator>Liu, Chen-Guang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This article introduces a new signal analysis method, which can be
interpreted as a principal component analysis in sparse decomposition of the
signal. The method, called principal basis analysis, is based on a novel
criterion: reproducibility of component which is an intrinsic characteristic of
regularity in natural signals. We show how to measure reproducibility. Then we
present the principal basis analysis method, which chooses, in a sparse
representation of the signal, the components optimizing the reproducibility
degree to build the so-called principal basis. With this principal basis, we
show that the underlying signal pattern could be effectively extracted from
corrupted data. As illustration, we apply the principal basis analysis to image
denoising corrupted by Gaussian and non-Gaussian noises, showing better
performances than some reference methods at suppressing strong noise and at
preserving signal details.
</dc:description>
 <dc:description>Comment: The text propose a Principal Basis Analysis in Sparse Representation
  and apply the principal basis analysis to image denoising corrupted by
  Gaussian and non-Gaussian noises, showing better performances than some
  reference methods at suppressing strong noise and at preserving signal
  details;including 8 pages, 4 figures prepared using pdf according to the
  instructions to Authors</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07932</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding of Hypercube into Cylinder</dc:title>
 <dc:creator>Ji, Weixing</dc:creator>
 <dc:creator>Liu, Qinghui</dc:creator>
 <dc:creator>Wang, Guizhen</dc:creator>
 <dc:creator>Shen, ZhuoJia</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  Task mapping in modern high performance parallel computers can be modeled as
a graph embedding problem, which simulates the mapping as embedding one graph
into another and try to find the minimum wirelength for the mapping. Though
embedding problems have been considered for several regular graphs, such as
hypercubes into grids, binary trees into grids, et al, it is still an open
problem for hypercubes into cylinders. In this paper, we consider the problem
of embedding hypercubes into cylinders to minimize the wirelength. We obtain
the exact wirelength formula of embedding hypercube $Q^r$ into cylinder
$C_{2^3}\times P_{2^{r-3}}$ with $r\ge3$.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07938</identifier>
 <datestamp>2016-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Temporal Convolutional Neural Networks for Diagnosis from Lab Tests</dc:title>
 <dc:creator>Razavian, Narges</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Early diagnosis of treatable diseases is essential for improving healthcare,
and many diseases' onsets are predictable from annual lab tests and their
temporal trends. We introduce a multi-resolution convolutional neural network
for early detection of multiple diseases from irregularly measured sparse lab
values. Our novel architecture takes as input both an imputed version of the
data and a binary observation matrix. For imputing the temporal sparse
observations, we develop a flexible, fast to train method for differentiable
multivariate kernel regression. Our experiments on data from 298K individuals
over 8 years, 18 common lab measurements, and 171 diseases show that the
temporal signatures learned via convolution are significantly more predictive
than baselines commonly used for early disease diagnosis.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07940</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video Tracking Using Learned Hierarchical Features</dc:title>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Liu, Ting</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Chan, Kap Luk</dc:creator>
 <dc:creator>Yang, Qingxiong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose an approach to learn hierarchical features for
visual object tracking. First, we offline learn features robust to diverse
motion patterns from auxiliary video sequences. The hierarchical features are
learned via a two-layer convolutional neural network. Embedding the temporal
slowness constraint in the stacked architecture makes the learned features
robust to complicated motion transformations, which is important for visual
object tracking. Then, given a target video sequence, we propose a domain
adaptation module to online adapt the pre-learned features according to the
specific target object. The adaptation is conducted in both layers of the deep
feature learning module so as to include appearance information of the specific
target object. As a result, the learned hierarchical features can be robust to
both complicated motion transformations and appearance changes of target
objects. We integrate our feature learning algorithm into three tracking
methods. Experimental results demonstrate that significant improvement can be
achieved using our learned hierarchical features, especially on video sequences
with complicated motion transformations.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07940</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, vol. 24, no. 4, April 2015</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2015.2403231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07948</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Halfspaces and Neural Networks with Random Initialization</dc:title>
 <dc:creator>Zhang, Yuchen</dc:creator>
 <dc:creator>Lee, Jason D.</dc:creator>
 <dc:creator>Wainwright, Martin J.</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study non-convex empirical risk minimization for learning halfspaces and
neural networks. For loss functions that are $L$-Lipschitz continuous, we
present algorithms to learn halfspaces and multi-layer neural networks that
achieve arbitrarily small excess risk $\epsilon&gt;0$. The time complexity is
polynomial in the input dimension $d$ and the sample size $n$, but exponential
in the quantity $(L/\epsilon^2)\log(L/\epsilon)$. These algorithms run multiple
rounds of random initialization followed by arbitrary optimization steps. We
further show that if the data is separable by some neural network with constant
margin $\gamma&gt;0$, then there is a polynomial-time algorithm for learning a
neural network that separates the training data with margin $\Omega(\gamma)$.
As a consequence, the algorithm achieves arbitrary generalization error
$\epsilon&gt;0$ with ${\rm poly}(d,1/\epsilon)$ sample and time complexity. We
establish the same learnability result when the labels are randomly flipped
with probability $\eta&lt;1/2$.
</dc:description>
 <dc:description>Comment: 31 pages</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07949</identifier>
 <datestamp>2016-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R\'enyi Information Complexity and an Information Theoretic
  Characterization of the Partition Bound</dc:title>
 <dc:creator>Prabhakaran, Manoj M.</dc:creator>
 <dc:creator>Prabhakaran, Vinod M.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We introduce a new information-theoretic complexity measure $IC_\infty$ for
2-party functions which is a lower-bound on communication complexity, and has
the two leading lower-bounds on communication complexity as its natural
relaxations: (external) information complexity ($IC$) and logarithm of
partition complexity ($\text{prt}$), which have so far appeared conceptually
quite different from each other. $IC_\infty$ is an external information
complexity measure based on R\'enyi mutual information of order infinity. In
the definition of $IC_\infty$, relaxing the order of R\'enyi mutual information
from infinity to 1 yields $IC$, while $\log \text{prt}$ is obtained by
replacing protocol transcripts with what we term &quot;pseudotranscripts,&quot; which
omits the interactive nature of a protocol, but only requires that the
probability of any transcript given the inputs $x$ and $y$ to the two parties,
factorizes into two terms which depend on $x$ and $y$ separately. Further
understanding $IC_\infty$ might have consequences for important direct-sum
problems in communication complexity, as it lies between communication
complexity and information complexity.
  We also show that applying both the above relaxations simultaneously to
$IC_\infty$ gives a complexity measure that is lower-bounded by the (log of)
relaxed partition complexity, a complexity measure introduced by Kerenidis et
al. (FOCS 2012). We obtain a sharper connection between (external) information
complexity and relaxed partition complexity than Kerenidis et al., using an
arguably more direct proof.
</dc:description>
 <dc:description>Comment: Full version of paper appearing at ICALP 2016</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07951</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PASCAL Boundaries: A Class-Agnostic Semantic Boundary Dataset</dc:title>
 <dc:creator>Premachandran, Vittal</dc:creator>
 <dc:creator>Bonev, Boyan</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we address the boundary detection task motivated by the
ambiguities in current definition of edge detection. To this end, we generate a
large database consisting of more than 10k images (which is 20x bigger than
existing edge detection databases) along with ground truth boundaries between
459 semantic classes including both foreground objects and different types of
background, and call it the PASCAL Boundaries dataset, which will be released
to the community. In addition, we propose a novel deep network-based
multi-scale semantic boundary detector and name it Multi-scale Deep Semantic
Boundary Detector (M-DSBD). We provide baselines using models that were trained
on edge detection and show that they transfer reasonably to the task of
boundary detection. Finally, we point to various important research problems
that this dataset can be used for.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07953</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Correlation between Labels to improve Multi-Label
  Classification</dc:title>
 <dc:creator>Garg, Amit</dc:creator>
 <dc:creator>Noyola, Jonathan</dc:creator>
 <dc:creator>Verma, Romil</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:creator>Jami, Aditya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper attempts multi-label classification by extending the idea of
independent binary classification models for each output label, and exploring
how the inherent correlation between output labels can be used to improve
predictions. Logistic Regression, Naive Bayes, Random Forest, and SVM models
were constructed, with SVM giving the best results: an improvement of 12.9\%
over binary models was achieved for hold out cross validation by augmenting
with pairwise correlation probabilities of the labels.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07961</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MOOCs Meet Measurement Theory: A Topic-Modelling Approach</dc:title>
 <dc:creator>He, Jiazhen</dc:creator>
 <dc:creator>Rubinstein, Benjamin I. P.</dc:creator>
 <dc:creator>Bailey, James</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Milligan, Sandra</dc:creator>
 <dc:creator>Chan, Jeffrey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper adapts topic models to the psychometric testing of MOOC students
based on their online forum postings. Measurement theory from education and
psychology provides statistical models for quantifying a person's attainment of
intangible attributes such as attitudes, abilities or intelligence. Such models
infer latent skill levels by relating them to individuals' observed responses
on a series of items such as quiz questions. The set of items can be used to
measure a latent skill if individuals' responses on them conform to a Guttman
scale. Such well-scaled items differentiate between individuals and inferred
levels span the entire range from most basic to the advanced. In practice,
education researchers manually devise items (quiz questions) while optimising
well-scaled conformance. Due to the costly nature and expert requirements of
this process, psychometric testing has found limited use in everyday teaching.
We aim to develop usable measurement models for highly-instrumented MOOC
delivery platforms, by using participation in automatically-extracted online
forum topics as items. The challenge is to formalise the Guttman scale
educational constraint and incorporate it into topic models. To favour topics
that automatically conform to a Guttman scale, we introduce a novel
regularisation into non-negative matrix factorisation-based topic modelling. We
demonstrate the suitability of our approach with both quantitative experiments
on three Coursera MOOCs, and with a qualitative survey of topic
interpretability on two MOOCs by domain expert interviews.
</dc:description>
 <dc:description>Comment: 12 pages, 9 figures; accepted into AAAI'2016</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07962</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-theoretic neuro-correlates boost evolution of cognitive
  systems</dc:title>
 <dc:creator>Schossau, Jory</dc:creator>
 <dc:creator>Adami, Christoph</dc:creator>
 <dc:creator>Hintze, Arend</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Genetic Algorithms (GA) are a powerful set of tools for search and
optimization that mimic the process of natural selection, and have been used
successfully in a wide variety of problems, including evolving neural networks
to solve cognitive tasks. Despite their success, GAs sometimes fail to locate
the highest peaks of the fitness landscape, in particular if the landscape is
rugged and contains multiple peaks. Reaching distant and higher peaks is
difficult because valleys need to be crossed, in a process that (at least
temporarily) runs against the fitness maximization objective. Here we propose
and test a number of information-theoretic (as well as network-based) measures
that can be used in conjunction with a fitness maximization objective
(so-called ``neuro-correlates&quot;) to evolve neural controllers for two widely
different tasks: a behavioral task that requires information integration, and a
cognitive task that requires memory and logic. We find that judiciously chosen
neuro-correlates can significantly aid GAs to find the highest peaks.
</dc:description>
 <dc:description>Comment: 26 pages, 6 figures plus 3 Suppl. figures (included). To appear in
  special issue &quot;Information Theoretic Incentives for Cognitive Systems&quot; of
  journal &quot;Entropy&quot;</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07962</dc:identifier>
 <dc:identifier>Entropy 18 (2016) 6</dc:identifier>
 <dc:identifier>doi:10.3390/e18010006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07963</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calculate distance to object in the area where car, using video analysis</dc:title>
 <dc:creator>Legchekova, Elena</dc:creator>
 <dc:creator>Titov, Oleg</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The method of using video cameras installed on the car, to calculate the
distance to the object in its area of movement.
</dc:description>
 <dc:description>Comment: 5 pages, in Russian</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07963</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07972</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Memory Embeddings</dc:title>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:creator>Esteban, Crist&#xf3;bal</dc:creator>
 <dc:creator>Yang, Yinchong</dc:creator>
 <dc:creator>Baier, Stephan</dc:creator>
 <dc:creator>Krompa&#xdf;, Denis</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Embedding learning, a.k.a. representation learning, has been shown to be able
to model large-scale semantic knowledge graphs. A key concept is a mapping of
the knowledge graph to a tensor representation whose entries are predicted by
models using latent representations of generalized entities. Latent variable
models are well suited to deal with the high dimensionality and sparsity of
typical knowledge graphs. In recent publications the embedding models were
extended to also consider time evolutions, time patterns and subsymbolic
representations. In this paper we map embedding models, which were developed
purely as solutions to technical problems for modelling temporal knowledge
graphs, to various cognitive memory functions, in particular to semantic and
concept memory, episodic memory, sensory memory, short-term memory, and working
memory. We discuss learning, query answering, the path from sensory input to
semantic decoding, and the relationship between episodic memory and semantic
memory. We introduce a number of hypotheses on human memory that can be derived
from the developed mathematical models.
</dc:description>
 <dc:description>Comment: 29 pages, NIPS 2015 Workshop on Nonparametric Methods for Large Scale
  Representation Learning</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07983</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reordering GPU Kernel Launches to Enable Efficient Concurrent Execution</dc:title>
 <dc:creator>Li, Teng</dc:creator>
 <dc:creator>Narayana, Vikram K.</dc:creator>
 <dc:creator>El-Ghazawi, Tarek</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Contemporary GPUs allow concurrent execution of small computational kernels
in order to prevent idling of GPU resources. Despite the potential concurrency
between independent kernels, the order in which kernels are issued to the GPU
will significantly influence the application performance. A technique for
deriving suitable kernel launch orders is therefore presented, with the aim of
reducing the total execution time. Experimental results indicate that the
proposed method yields solutions that are well above the 90 percentile mark in
the design space of all possible permutations of the kernel launch sequences.
</dc:description>
 <dc:description>Comment: 2 Pages</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07992</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipartite entangled states, symmetric matrices and error-correcting
  codes</dc:title>
 <dc:creator>Feng, Keqin</dc:creator>
 <dc:creator>Jin, Lingfei</dc:creator>
 <dc:creator>Xing, Chaoping</dc:creator>
 <dc:creator>Yuan, Chen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  A pure quantum state is called $k$-uniform if all its reductions to $k$-qudit
are maximally mixed. We investigate the general constructions of $k$-uniform
pure quantum states of $n$ subsystems with $d$ levels. We provide one
construction via symmetric matrices and the second one through classical
error-correcting codes. There are three main results arising from our
constructions. Firstly, we show that for any given even $n\ge 2$, there always
exists an $n/2$-uniform $n$-qudit quantum state of level $p$ for sufficiently
large prime $p$. Secondly, both constructions show that their exist $k$-uniform
$n$-qudit pure quantum states such that $k$ is proportional to $n$, i.e.,
$k=\Omega(n)$ although the construction from symmetric matrices outperforms the
one by error-correcting codes. Thirdly, our symmetric matrix construction
provides a positive answer to the open question in \cite{DA} on whether there
exists $3$-uniform $n$-qudit pure quantum state for all $n\ge 8$. In fact, we
can further prove that, for every $k$, there exists a constant $M_k$ such that
there exists a $k$-uniform $n$-qudit quantum state for all $n\ge M_k$. In
addition, by using concatenation of algebraic geometry codes, we give an
explicit construction of $k$-uniform quantum state when $k$ tends to infinity.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.07992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08020</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Authentication With a Guessing Adversary</dc:title>
 <dc:creator>Naghibi, Farshad</dc:creator>
 <dc:creator>Oechtering, Tobias J.</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the authentication problem where a candidate
measurement presented by an unidentified user is compared to a previously
stored measurement of the legitimate user, the enrollment, with respect to a
certain distortion criteria for authentication. An adversary wishes to
impersonate the legitimate user by guessing the enrollment until the system
authenticates him. For this setting, we study the minimum number of required
guesses (on average) by the adversary for a successful impersonation attack and
find the complete characterization of the asymptotic exponent of this metric,
referred to as the deception exponent. Our result is a direct application of
the results of the Guessing problem by Arikan and Merhav [19]. Paralleling the
work in [19] we also extend this result to the case where the adversary may
have access to additional side information correlated to the enrollment data.
The paper is a revised version of a submission to IEEE WIFS 2015, with the
referencing to the paper [19] clarified compared with the conference version.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, revised IEEE WIFS 2015 submission</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08032</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to detect video events from zero or very few video examples</dc:title>
 <dc:creator>Tzelepis, Christos</dc:creator>
 <dc:creator>Galanopoulos, Damianos</dc:creator>
 <dc:creator>Mezaris, Vasileios</dc:creator>
 <dc:creator>Patras, Ioannis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work we deal with the problem of high-level event detection in video.
Specifically, we study the challenging problems of i) learning to detect video
events from solely a textual description of the event, without using any
positive video examples, and ii) additionally exploiting very few positive
training samples together with a small number of ``related'' videos. For
learning only from an event's textual description, we first identify a general
learning framework and then study the impact of different design choices for
various stages of this framework. For additionally learning from example
videos, when true positive training samples are scarce, we employ an extension
of the Support Vector Machine that allows us to exploit ``related'' event
videos by automatically introducing different weights for subsets of the videos
in the overall training set. Experimental evaluations performed on the
large-scale TRECVID MED 2014 video dataset provide insight on the effectiveness
of the proposed methods.
</dc:description>
 <dc:description>Comment: Image and Vision Computing Journal, Elsevier, 2015, accepted for
  publication</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08032</dc:identifier>
 <dc:identifier>Image and Vision Computing Journal, Elsevier, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.imavis.2015.09.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08049</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Industrial Experiences with a Formal DSL Semantics to Check Correctness
  of DSL Transformations</dc:title>
 <dc:creator>Keshishzadeh, Sarmen</dc:creator>
 <dc:creator>Mooij, Arjan J.</dc:creator>
 <dc:creator>Hooman, Jozef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A domain specific language (DSL) abstracts from implementation details and is
aligned with the way domain experts reason about a software component. The
development of DSLs is usually centered around a grammar and transformations
that generate implementation code or analysis models. The semantics of the
language is often defined implicitly and in terms of a transformation to
implementation code. In the presence of multiple transformations from the DSL,
the consistency of the generated artifacts with respect to the semantics of the
DSL is a relevant issue. We show that a formal semantics is essential for
checking the consistency between the generated artifacts. We exploit the formal
semantics in an industrial project and use formal techniques based on
equivalence checking and model-based testing for consistency checking. We
report about our experience with this approach in an industrial development
project.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08054</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The excluded minors for isometric realizability in the plane</dc:title>
 <dc:creator>Fiorini, Samuel</dc:creator>
 <dc:creator>Huynh, Tony</dc:creator>
 <dc:creator>Joret, Gwena&#xeb;l</dc:creator>
 <dc:creator>Varvitsiotis, Antonios</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C10</dc:subject>
 <dc:description>  Let $G$ be a graph and $p \in [1, \infty]$. The parameter $f_p(G)$ is the
least integer $k$ such that for all $m$ and all vectors $(r_v)_{v \in V(G)}
\subseteq \mathbb{R}^m$, there exist vectors $(q_v)_{v \in V(G)} \subseteq
\mathbb{R}^k$ satisfying $$\|r_v-r_w\|_p=\|q_v-q_w\|_p, \ \text{ for all }\
vw\in E(G).$$ It is easy to check that $f_p(G)$ is always finite and that it is
minor monotone. By the graph minor theorem of Robertson and Seymour, there are
a finite number of excluded minors for the property $f_p(G) \leq k$.
  In this paper, we determine the complete set of excluded minors for
$f_\infty(G) \leq 2$. The two excluded minors are the wheel on $5$ vertices and
the graph obtained by gluing two copies of $K_4$ along an edge and then
deleting that edge. We also show that the same two graphs are the complete set
of excluded minors for $f_1(G) \leq 2$. In addition, we give a family of
examples that show that $f_\infty$ is unbounded on the class of planar graphs
and $f_\infty$ is not bounded as a function of tree-width.
</dc:description>
 <dc:description>Comment: 17 pages, 6 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08054</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 31/1:438--453, 2017</dc:identifier>
 <dc:identifier>doi:10.1137/16M1064775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08058</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry</dc:title>
 <dc:creator>Cao, Jiale</dc:creator>
 <dc:creator>Pang, Yanwei</dc:creator>
 <dc:creator>Li, Xuelong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The discrimination and simplicity of features are very important for
effective and efficient pedestrian detection. However, most state-of-the-art
methods are unable to achieve good tradeoff between accuracy and efficiency.
Inspired by some simple inherent attributes of pedestrians (i.e., appearance
constancy and shape symmetry), we propose two new types of non-neighboring
features (NNF): side-inner difference features (SIDF) and symmetrical
similarity features (SSF). SIDF can characterize the difference between the
background and pedestrian and the difference between the pedestrian contour and
its inner part. SSF can capture the symmetrical similarity of pedestrian shape.
However, it's difficult for neighboring features to have such above
characterization abilities. Finally, we propose to combine both non-neighboring
and neighboring features for pedestrian detection. It's found that
non-neighboring features can further decrease the average miss rate by 4.44%.
Experimental results on INRIA and Caltech pedestrian datasets demonstrate the
effectiveness and efficiency of the proposed method. Compared to the
state-of-the-art methods without using CNN, our method achieves the best
detection performance on Caltech, outperforming the second best method (i.e.,
Checkboards) by 1.63%.
</dc:description>
 <dc:description>Comment: 9 pages,17 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08058</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2609807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08060</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An open access repository of images on plant health to enable the
  development of mobile disease diagnostics</dc:title>
 <dc:creator>Hughes, David. P.</dc:creator>
 <dc:creator>Salathe, Marcel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Human society needs to increase food production by an estimated 70% by 2050
to feed an expected population size that is predicted to be over 9 billion
people. Currently, infectious diseases reduce the potential yield by an average
of 40% with many farmers in the developing world experiencing yield losses as
high as 100%. The widespread distribution of smartphones among crop growers
around the world with an expected 5 billion smartphones by 2020 offers the
potential of turning the smartphone into a valuable tool for diverse
communities growing food. One potential application is the development of
mobile disease diagnostics through machine learning and crowdsourcing. Here we
announce the release of over 50,000 expertly curated images on healthy and
infected leaves of crops plants through the existing online platform
PlantVillage. We describe both the data and the platform. These data are the
beginning of an on-going, crowdsourcing effort to enable computer vision
approaches to help solve the problem of yield losses in crop plants due to
infectious diseases.
</dc:description>
 <dc:description>Comment: 11, 1 Figure, 1 table</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08062</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxed Majorization-Minimization for Non-smooth and Non-convex
  Optimization</dc:title>
 <dc:creator>Xu, Chen</dc:creator>
 <dc:creator>Lin, Zhouchen</dc:creator>
 <dc:creator>Zhao, Zhenyu</dc:creator>
 <dc:creator>Zha, Hongbin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We propose a new majorization-minimization (MM) method for non-smooth and
non-convex programs, which is general enough to include the existing MM
methods. Besides the local majorization condition, we only require that the
difference between the directional derivatives of the objective function and
its surrogate function vanishes when the number of iterations approaches
infinity, which is a very weak condition. So our method can use a surrogate
function that directly approximates the non-smooth objective function. In
comparison, all the existing MM methods construct the surrogate function by
approximating the smooth component of the objective function. We apply our
relaxed MM methods to the robust matrix factorization (RMF) problem with
different regularizations, where our locally majorant algorithm shows
advantages over the state-of-the-art approaches for RMF. This is the first
algorithm for RMF ensuring, without extra assumptions, that any limit point of
the iterates is a stationary point.
</dc:description>
 <dc:description>Comment: AAAI16</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08063</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward interoperability for the Internet of Things with meta-hubs</dc:title>
 <dc:creator>Mineraud, Julien</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The Internet of Things (IoT) envisions that objects may be connected to the
Internet, producing and consuming data in real-time. Today, numerous middleware
platforms are available to facilitate the communication with these objects.
Unfortunately, the interoperability of these platforms is very limited because
it requires to &quot;manually&quot; connect the services proposed by each platform. One
key design goal for our contribution is not to build yet another middleware,
but rather to augment the functionalities of existing systems via an extension
to support their integration into a network of heterogeneous IoT hubs. The
extension includes a RESTful API to manipulate the basic component of our
extension, the IoT feeds. The IoT feeds allow the platform's owner to
dynamically marshal the IoT features connected to the platform, as well as the
data that they produce. Furthermore, the feeds enable the owner to manage and
control the data flows before connecting them to his applications.
Subsequently, these feeds may also be published to meta-hubs in order to expose
them to third parties. We evaluated an implementation our extension for Android
systems to show the feasibility of managing the data flows using the RESTful
API on this platform.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08066</identifier>
 <datestamp>2016-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Weight Independent Sets for ($P_7$,Triangle)-Free Graphs in
  Polynomial Time</dc:title>
 <dc:creator>Brandstadt, Andreas</dc:creator>
 <dc:creator>Mosca, Raffaele</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The Maximum Weight Independent Set (MWIS) problem on finite undirected graphs
with vertex weights asks for a set of pairwise nonadjacent vertices of maximum
weight sum. MWIS is one of the most investigated and most important algorithmic
graph problems; it is well known to be NP-complete, and it remains NP-complete
even under various strong restrictions such as for triangle-free graphs. Its
complexity was an open problem for $P_k$-free graphs, $k \ge 5$. Recently,
Lokshtanov, Vatshelle, and Villanger proved that MWIS can be solved in
polynomial time for $P_5$-free graphs, and Lokshtanov, Pilipczuk, and van
Leeuwen proved that MWIS can be solved in quasi-polynomial time for $P_6$-free
graphs. It still remains an open problem whether MWIS can be solved in
polynomial time for $P_k$-free graphs, $k \geq 6$ or in quasi-polynomial time
for $P_k$-free graphs, $k \geq 7$. Some characterizations of $P_k$-free graphs
and some progress are known in the literature but so far did not solve the
problem. In this paper, we show that MWIS can be solved in polynomial time for
($P_7$,triangle)-free graphs. This extends the corresponding result for
($P_6$,triangle)-free graphs and may provide some progress in the study of MWIS
for $P_7$-free graphs.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08073</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remark on a result of Constantine</dc:title>
 <dc:creator>Cath&#xe1;in, Padraig &#xd3;</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this short note we construct codes of length $4n$ with $8n+8$ codewords
and minimum distance $2n-2$ whenever $4n+4$ is the order of a Hadamard matrix.
This generalises work of Constantine who obtained a similar result in the
special case that $n$ is a prime power.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08078</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Desktop to Cloud Migration of Scientific Computing Experiments</dc:title>
 <dc:creator>Srirama, Satish Narayana</dc:creator>
 <dc:creator>Jakovits, Pelle</dc:creator>
 <dc:creator>Ivani&#x161;t&#x161;ev, Vladislav</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Scientific computing applications usually need huge amounts of computational
power. The cloud provides interesting high-performance computing solutions,
with its promise of virtually infinite resources on demand. However, migrating
scientific computing problems to clouds and the re-creation of software
environment on the vendor-supplied OS and cloud instances is often a laborious
task. It is also assumed that the scientist who is performing the experiments
has significant knowledge of computer science, cloud computing and the
migration procedure, which is often not true. Considering these obstacles, we
have designed a tool suite that migrates the complete software environment
directly to the cloud. The developed desktop-to-cloud-migration (D2CM) tool
supports transformation and migration of virtual machine images, reusable
deployment description and life-cycle management for applications to be hosted
on Amazon Cloud or compatible infrastructure such as Eucalyptus. The paper also
presents an electrochemical case study and computational experiments targeted
at designing modern supercapacitors. These experiments have extensively used
the tool in drawing domain specific results. Detailed analysis of the case
showed that D2CM tool not only simplifies the migration procedure for the
scientists, but also helps them in optimizing the calculations and compute
clusters, by providing them a new dimension -- cost-to-value of computational
experiments.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08082</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoE Optimization of Video Multicast with Heterogeneous Channels and
  Playback Requirements</dc:title>
 <dc:creator>Bakhshali, Ali</dc:creator>
 <dc:creator>Chan, Wai-Yip</dc:creator>
 <dc:creator>Blosten, Steven D.</dc:creator>
 <dc:creator>Cao, Yu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We propose an application-layer forward error correction (AL-FEC) code rate
allocation scheme to maximize the quality of experience (QoE) of a video
multicast. The allocation dynamically assigns multicast clients to the quality
layers of a scalable video bitstream, based on their heterogeneous channel
qualities and video playback capabilities. Normalized mean opinion score (NMOS)
is employed to value the client's quality of experience across various possible
adaptations of a multilayer video, coded using mixed spatial-temporal-amplitude
scalability. The scheme provides assurance of reception of the video layers
using fountain coding and effectively allocates coding rates across the layers
to maximize a multicast utility measure. An advantageous feature of the
proposed scheme is that the complexity of the optimization is independent of
the number of clients. Additionally, a convex formulation is proposed that
attains close to the best performance and offers a reliable alternative when
further reduction in computational complexity is desired. The optimization is
extended to perform suppression of QoE fluctuations for clients with marginal
channel qualities. The scheme offers a means to trade-off service utility for
the entire multicast group and clients with the worst channels. According to
the simulation results, the proposed optimization framework is robust against
source rate variations and limited amount of client feedback.
</dc:description>
 <dc:description>Comment: 29 pages, 5 tables, 11 figures, to appear in EURASIP Journal on
  Wireless Communications and Networking</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08082</dc:identifier>
 <dc:identifier>doi:10.1186/s13638-015-0485-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08084</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layered Downlink Precoding for C-RAN Systems with Full Dimensional MIMO</dc:title>
 <dc:creator>Kang, Jinkyu</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Kang, Joonhyuk</dc:creator>
 <dc:creator>Shamai, Shlomo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The implementation of a Cloud Radio Access Network (C-RAN) with Full
Dimensional (FD)-MIMO is faced with the challenge of controlling the fronthaul
overhead for the transmission of baseband signals as the number of horizontal
and vertical antennas grows larger. This work proposes to leverage the special
low-rank structure of FD-MIMO channel, which is characterized by a
time-invariant elevation component and a time-varying azimuth component, by
means of a layered precoding approach, so as to reduce the fronthaul overhead.
According to this scheme, separate precoding matrices are applied for the
azimuth and elevation channel components, with different rates of adaptation to
the channel variations and correspondingly different impacts on the fronthaul
capacity. Moreover, we consider two different Central Unit (CU) - Radio Unit
(RU) functional splits at the physical layer, namely the conventional C-RAN
implementation and an alternative one in which coding and precoding are
performed at the RUs. Via numerical results, it is shown that the layered
schemes significantly outperform conventional non-layered schemes, especially
in the regime of low fronthaul capacity and large number of vertical antennas.
</dc:description>
 <dc:description>Comment: 29 pages, 12 figures, Submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08084</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2572199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08088</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relative Citation Ratio (RCR): An empirical attempt to study a new
  field-normalized bibliometric indicator</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Hutchins, Yuan, M., and Santangelo (2015) proposed the Relative Citation
Ratio (RCR) as a new field-normalized impact indicator. This study investigates
the RCR by correlating it on the level of single publications with established
field-normalized indicators and assessments of the publications by peers. We
find that the RCR correlates highly with established field-normalized
indicators, but the correlation between RCR and peer assessments is only low to
medium.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Journal of the Association for
  Information Science and Technology</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08088</dc:identifier>
 <dc:identifier>doi:10.1002/asi.23729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08096</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Journal Coverage of Web of Science and Scopus: a Comparative
  Analysis</dc:title>
 <dc:creator>Mongeon, Philippe</dc:creator>
 <dc:creator>Paul-Hus, Adele</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Bibliometric methods are used in multiple fields for a variety of purposes,
namely for research evaluation. Most bibliometric analyses have in common their
data sources: Thomson Reuters' Web of Science (WoS) and Elsevier's Scopus. This
research compares the journal coverage of both databases in terms of fields,
countries and languages, using Ulrich's extensive periodical directory as a
base for comparison. Results indicate that the use of either WoS or Scopus for
research evaluation may introduces biases that favor Natural Sciences and
Engineering as well as Biomedical Research to the detriment of Social Sciences
and Arts and Humanities. Similarly, English-language journals are
overrepresented to the detriment of other languages. While both databases share
these biases, their coverage differs substantially. As a consequence, the
results of bibliometric analyses may vary depending on the database used.
</dc:description>
 <dc:description>Comment: Accepted for publication in Scientometrics. 17 pages, 6 Figures, 4
  Tables</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08096</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-015-1765-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08099</identifier>
 <datestamp>2015-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic Dialogue Management via Deep Reinforcement Learning</dc:title>
 <dc:creator>Cuay&#xe1;huitl, Heriberto</dc:creator>
 <dc:creator>Keizer, Simon</dc:creator>
 <dc:creator>Lemon, Oliver</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Artificially intelligent agents equipped with strategic skills that can
negotiate during their interactions with other natural or artificial agents are
still underdeveloped. This paper describes a successful application of Deep
Reinforcement Learning (DRL) for training intelligent agents with strategic
conversational skills, in a situated dialogue setting. Previous studies have
modelled the behaviour of strategic agents using supervised learning and
traditional reinforcement learning techniques, the latter using tabular
representations or learning with linear function approximation. In this study,
we apply DRL with a high-dimensional state space to the strategic board game of
Settlers of Catan---where players can offer resources in exchange for others
and they can also reply to offers made by other players. Our experimental
results report that the DRL-based learnt policies significantly outperformed
several baselines including random, rule-based, and supervised-based
behaviours. The DRL-based policy has a 53% win rate versus 3 automated players
(`bots'), whereas a supervised player trained on a dialogue corpus in this
setting achieved only 27%, versus the same 3 bots. This result supports the
claim that DRL is a promising framework for training dialogue systems, and
strategic agents with negotiation abilities.
</dc:description>
 <dc:description>Comment: NIPS'15 Workshop on Deep Reinforcement Learning</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08101</identifier>
 <datestamp>2017-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on APN permutations in even dimension</dc:title>
 <dc:creator>Calderini, Marco</dc:creator>
 <dc:creator>Sala, Massimilano</dc:creator>
 <dc:creator>Villa, Irene</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  APN permutations in even dimension are vectorial Boolean functions that play
a special role in the design of block ciphers. We study their properties,
providing some general results and some applications to the low-dimension
cases. In particular, we prove that none of their components can be quadratic.
For an APN vectorial Boolean function (in even dimension) with all cubic
components we prove the existence of a component having a large number of
balanced derivatives. Using these restrictions, we obtain the first theoretical
proof of the non-existence of APN permutations in dimension 4. Moreover, we
derive some contraints on APN permutations in dimension 6.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08101</dc:identifier>
 <dc:identifier>Finite Fields and Their Applications, 46:1 - 16, 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.ffa.2017.02.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08111</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Tarski's plank problem to simultaneous approximation</dc:title>
 <dc:creator>Kupavskii, Andrey B.</dc:creator>
 <dc:creator>Pach, J&#xe1;nos</dc:creator>
 <dc:subject>Mathematics - Metric Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>52C17</dc:subject>
 <dc:description>  A {\em slab} (or plank) of width $w$ is a part of the $d$-dimensional space
that lies between two parallel hyperplanes at distance $w$ from each other. It
is conjectured that any slabs $S_1, S_2,\ldots$ whose total width is divergent
have suitable translates that altogether cover $\mathbb{R}^d$. We show that
this statement is true if the widths of the slabs, $w_1, w_2,\ldots$, satisfy
the slightly stronger condition
$\limsup_{n\rightarrow\infty}\frac{w_1+w_2+\ldots+w_n}{\log(1/w_n)}&gt;0$. This
can be regarded as a converse of Bang's theorem, better known as Tarski's plank
problem.
  We apply our results to a problem on simultaneous approximation of
polynomials. Given a positive integer $d$, we say that a sequence of positive
numbers $x_1\le x_2\le\ldots$ {\em controls} all polynomials of degree at most
$d$ if there exist $y_1, y_2,\ldots\in\mathbb{R}$ such that for every
polynomial $p$ of degree at most $d$, there exists an index $i$ with
$|p(x_i)-y_i|\leq 1.$ We prove that a sequence has this property if and only if
$\sum_{i=1}^{\infty}\frac{1}{x_i^d}$ is divergent. This settles an old
conjecture of Makai and Pach.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08113</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Permanent versus determinant, obstructions, and Kronecker coefficients</dc:title>
 <dc:creator>B&#xfc;rgisser, Peter</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17, 20C30, 05E10, 14L24</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We give an introduction to some of the recent ideas that go under the name
&quot;geometric complexity theory&quot;. We first sketch the proof of the known upper and
lower bounds for the determinantal complexity of the permanent. We then
introduce the concept of a representation theoretic obstruction, which has
close links to algebraic combinatorics, and we explain some of the insights
gained so far. In particular, we address very recent insights on the complexity
of testing the positivity of Kronecker coefficients. We also briefly discuss
the related asymptotic version of this question.
</dc:description>
 <dc:description>Comment: Survey, 17 pages, 1 figure</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08114</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Centric Networking: A New Approach for Wireless Multi-Hop
  Networking to Enable the Internet of Things</dc:title>
 <dc:creator>Kuperman, Greg</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Cheng, Bow-Nan</dc:creator>
 <dc:creator>Deutsch, Patricia</dc:creator>
 <dc:creator>Narula-Tam, Aradhana</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we introduce a new networking architecture called Group
Centric Networking (GCN), which is designed to support the large number of
devices expected with the emergence of the Internet of Things. GCN is designed
to enable these devices to operate collaboratively in a highly efficient and
resilient fashion, while not sacrificing their ability to communicate with one
another. We do a full protocol implementation of GCN in NS3, and demonstrate
that GCN utilizes up to an order of magnitude fewer network resources than
traditional wireless networking schemes, while providing high connectivity and
reliability.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08118</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SlicerPET: A workflow based software module for PET/CT guided needle
  biopsy</dc:title>
 <dc:creator>Zuki&#x107;, D&#x17e;enan</dc:creator>
 <dc:creator>Finet, Julien</dc:creator>
 <dc:creator>Wilson, Emmanuel</dc:creator>
 <dc:creator>Banovac, Filip</dc:creator>
 <dc:creator>Esposito, Giuseppe</dc:creator>
 <dc:creator>Cleary, Kevin</dc:creator>
 <dc:creator>Enquobahrie, Andinet</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.4.9</dc:subject>
 <dc:description>  Biopsy is commonly used to confirm cancer diagnosis when radiologically
indicated. Given the ability of PET to localize malignancies in heterogeneous
tumors and tumors that do not have a CT correlate, PET/CT guided biopsy may
improve the diagnostic yield of biopsies. To facilitate PET/CT guided needle
biopsy, we developed a workflow that allows us to bring PET image guidance into
the interventional CT suite. In this abstract, we present SlicerPET, a
user-friendly workflow based module developed using open source software
libraries to guide needle biopsy in the interventional suite.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08118</dc:identifier>
 <dc:identifier>doi:10.1007/s11548-015-1213-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08119</identifier>
 <datestamp>2016-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher Order Conditional Random Fields in Deep Neural Networks</dc:title>
 <dc:creator>Arnab, Anurag</dc:creator>
 <dc:creator>Jayasumana, Sadeep</dc:creator>
 <dc:creator>Zheng, Shuai</dc:creator>
 <dc:creator>Torr, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of semantic segmentation using deep learning. Most
segmentation systems include a Conditional Random Field (CRF) to produce a
structured output that is consistent with the image's visual features. Recent
deep learning approaches have incorporated CRFs into Convolutional Neural
Networks (CNNs), with some even training the CRF end-to-end with the rest of
the network. However, these approaches have not employed higher order
potentials, which have previously been shown to significantly improve
segmentation performance. In this paper, we demonstrate that two types of
higher order potential, based on object detections and superpixels, can be
included in a CRF embedded within a deep network. We design these higher order
potentials to allow inference with the differentiable mean field algorithm. As
a result, all the parameters of our richer CRF model can be learned end-to-end
with our pixelwise CNN classifier. We achieve state-of-the-art segmentation
performance on the PASCAL VOC benchmark with these trainable higher order
potentials.
</dc:description>
 <dc:description>Comment: ECCV 2016</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08130</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Roadmap towards Machine Intelligence</dc:title>
 <dc:creator>Mikolov, Tomas</dc:creator>
 <dc:creator>Joulin, Armand</dc:creator>
 <dc:creator>Baroni, Marco</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The development of intelligent machines is one of the biggest unsolved
challenges in computer science. In this paper, we propose some fundamental
properties these machines should have, focusing in particular on communication
and learning. We discuss a simple environment that could be used to
incrementally teach a machine the basics of natural-language-based
communication, as a prerequisite to more complex interaction with human users.
We also present some conjectures on the sort of algorithms the machine should
support in order to profitably learn from the environment.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08131</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Deep Feature Extraction for Remote Sensing Image
  Classification</dc:title>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Gatta, Carlo</dc:creator>
 <dc:creator>Camps-Valls, Gustau</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces the use of single layer and deep convolutional networks
for remote sensing data analysis. Direct application to multi- and
hyper-spectral imagery of supervised (shallow or deep) convolutional networks
is very challenging given the high input data dimensionality and the relatively
small amount of available labeled data. Therefore, we propose the use of greedy
layer-wise unsupervised pre-training coupled with a highly efficient algorithm
for unsupervised learning of sparse features. The algorithm is rooted on sparse
representations and enforces both population and lifetime sparsity of the
extracted features, simultaneously. We successfully illustrate the expressive
power of the extracted representations in several scenarios: classification of
aerial scenes, as well as land-use classification in very high resolution
(VHR), or land-cover classification from multi- and hyper-spectral images. The
proposed algorithm clearly outperforms standard Principal Component Analysis
(PCA) and its kernel counterpart (kPCA), as well as current state-of-the-art
algorithms of aerial classification, while being extremely computationally
efficient at learning representations of data. Results show that single layer
convolutional networks can extract powerful discriminative features only when
the receptive field accounts for neighboring pixels, and are preferred when the
classification requires high resolution and detailed results. However, deep
architectures significantly outperform single layers variants, capturing
increasing levels of abstraction and complexity throughout the feature
hierarchy.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08131</dc:identifier>
 <dc:identifier>IEEE Transactions on Geoscience and Remote Sensing, Volume:PP ,
  Issue: 99, 2015</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2015.2478379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08136</identifier>
 <datestamp>2016-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying Decision Trees Split Criteria Using Tsallis Entropy</dc:title>
 <dc:creator>Wang, Yisen</dc:creator>
 <dc:creator>Song, Chaobing</dc:creator>
 <dc:creator>Xia, Shu-Tao</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The construction of efficient and effective decision trees remains a key
topic in machine learning because of their simplicity and flexibility. A lot of
heuristic algorithms have been proposed to construct near-optimal decision
trees. ID3, C4.5 and CART are classical decision tree algorithms and the split
criteria they used are Shannon entropy, Gain Ratio and Gini index respectively.
All the split criteria seem to be independent, actually, they can be unified in
a Tsallis entropy framework. Tsallis entropy is a generalization of Shannon
entropy and provides a new approach to enhance decision trees' performance with
an adjustable parameter $q$. In this paper, a Tsallis Entropy Criterion (TEC)
algorithm is proposed to unify Shannon entropy, Gain Ratio and Gini index,
which generalizes the split criteria of decision trees. More importantly, we
reveal the relations between Tsallis entropy with different $q$ and other split
criteria. Experimental results on UCI data sets indicate that the TEC algorithm
achieves statistically significant improvement over the classical algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-08-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08141</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinstating Combinatorial Protections for Manipulation and Bribery in
  Single-Peaked and Nearly Single-Peaked Electorates</dc:title>
 <dc:creator>Menon, Vijay</dc:creator>
 <dc:creator>Larson, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Understanding when and how computational complexity can be used to protect
elections against different manipulative actions has been a highly active
research area over the past two decades. A recent body of work, however, has
shown that many of the NP-hardness shields, previously obtained, vanish when
the electorate has single-peaked or nearly single-peaked preferences. In light
of these results, we investigate whether it is possible to reimpose NP-hardness
shields for such electorates by allowing the voters to specify partial
preferences instead of insisting they cast complete ballots. In particular, we
show that in single-peaked and nearly single-peaked electorates, if voters are
allowed to submit top-truncated ballots, then the complexity of manipulation
and bribery for many voting rules increases from being in P to being
NP-complete.
</dc:description>
 <dc:description>Comment: 28 pages; A shorter version of this paper will appear at the 30th
  AAAI Conference on Artificial Intelligence (AAAI-16)</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08143</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Throughput-Smoothness Trade-offs in Streaming Communication</dc:title>
 <dc:creator>Joshi, Gauri</dc:creator>
 <dc:creator>Kochman, Yuval</dc:creator>
 <dc:creator>Wornell, Gregory</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Unlike traditional file transfer where only total delay matters, streaming
applications impose delay constraints on each packet and require them to be in
order. To achieve fast in-order packet decoding, we have to compromise on the
throughput. We study this trade-off between throughput and smoothness in packet
decoding. We first consider a point-to-point streaming and analyze how the
trade-off is affected by the frequency of block-wise feedback, whereby the
source receives full channel state feedback at periodic intervals. We show that
frequent feedback can drastically improve the throughput-smoothness trade-off.
Then we consider the problem of multicasting a packet stream to two users. For
both point-to-point and multicast streaming, we propose a spectrum of coding
schemes that span different throughput-smoothness tradeoffs. One can choose an
appropriate coding scheme from these, depending upon the delay-sensitivity and
bandwidth limitations of the application. This work introduces a novel style of
analysis using renewal processes and Markov chains to analyze coding schemes.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08152</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max-Cut under Graph Constraints</dc:title>
 <dc:creator>Lee, Jon</dc:creator>
 <dc:creator>Nagarajan, Viswanath</dc:creator>
 <dc:creator>Shen, Xiangkun</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  An instance of the graph-constrained max-cut (GCMC) problem consists of (i)
an undirected graph G and (ii) edge-weights on a complete undirected graph on
the same vertex set. The objective is to find a subset of vertices satisfying
some graph-based constraint in G that maximizes the total weight of edges in
the cut. The types of graph constraints we can handle include independent set,
vertex cover, dominating set and connectivity. Our main results are for the
case when G is a graph with bounded treewidth, where we obtain a
0.5-approximation algorithm. Our algorithm uses an LP relaxation based on the
Sherali-Adams hierarchy. It can handle any graph constraint for which there is
a (certain type of) dynamic program that exactly optimizes linear objectives.
Using known decomposition results, these imply essentially the same
approximation ratio for GCMC under constraints such as independent set,
dominating set and connectivity on a planar graph G (more generally for
bounded-genus or excluded-minor graphs).
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08158</identifier>
 <datestamp>2016-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plan Explicability and Predictability for Robot Task Planning</dc:title>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Sreedharan, Sarath</dc:creator>
 <dc:creator>Kulkarni, Anagha</dc:creator>
 <dc:creator>Chakraborti, Tathagata</dc:creator>
 <dc:creator>Zhuo, Hankz Hankui</dc:creator>
 <dc:creator>Kambhampati, Subbarao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Intelligent robots and machines are becoming pervasive in human populated
environments. A desirable capability of these agents is to respond to
goal-oriented commands by autonomously constructing task plans. However, such
autonomy can add significant cognitive load and potentially introduce safety
risks to humans when agents behave unexpectedly. Hence, for such agents to be
helpful, one important requirement is for them to synthesize plans that can be
easily understood by humans. While there exists previous work that studied
socially acceptable robots that interact with humans in &quot;natural ways&quot;, and
work that investigated legible motion planning, there lacks a general solution
for high level task planning. To address this issue, we introduce the notions
of plan {\it explicability} and {\it predictability}. To compute these
measures, first, we postulate that humans understand agent plans by associating
abstract tasks with agent actions, which can be considered as a labeling
process. We learn the labeling scheme of humans for agent plans from training
examples using conditional random fields (CRFs). Then, we use the learned model
to label a new plan to compute its explicability and predictability. These
measures can be used by agents to proactively choose or directly synthesize
plans that are more explicable and predictable to humans. We provide
evaluations on a synthetic domain and with human subjects using physical robots
to show the effectiveness of our approach
</dc:description>
 <dc:description>Comment: Added physical robot evaluations</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-04-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08166</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracking Motion and Proxemics using Thermal-sensor Array</dc:title>
 <dc:creator>Basu, Chandrayee</dc:creator>
 <dc:creator>Rowe, Anthony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Indoor tracking has all-pervasive applications beyond mere surveillance, for
example in education, health monitoring, marketing, energy management and so
on. Image and video based tracking systems are intrusive. Thermal array sensors
on the other hand can provide coarse-grained tracking while preserving privacy
of the subjects. The goal of the project is to facilitate motion detection and
group proxemics modeling using an 8 x 8 infrared sensor array. Each of the 8 x
8 pixels is a temperature reading in Fahrenheit. We refer to each 8 x 8 matrix
as a scene. We collected approximately 902 scenes with different configurations
of human groups and different walking directions. We infer direction of motion
of a subject across a set of scenes as left-to-right, right-to-left, up-to-down
and down-to-up using cross-correlation analysis. We used features from
connected component analysis of each background subtracted scene and performed
Support Vector Machine classification to estimate number of instances of human
subjects in the scene.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, Machine Learning for Signal Processing Class
  project</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08167</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deseeding Energy Consumption of Network Stacks</dc:title>
 <dc:creator>Ucar, I&#xf1;aki</dc:creator>
 <dc:creator>Azcorra, Arturo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  Regular works on energy efficiency strategies for wireless communications are
based on classical energy models that account for the wireless card only.
Nevertheless, there is a non-negligible energy toll called &quot;cross-factor&quot; that
encompasses the energy drained while a frame crosses the network stack of an
OS.
  This paper addresses the challenge of deepen into the roots of the
cross-factor, deseed its components and analyse its causes. Energy issues are
critical for IoT devices. Thus, this paper conceives and validates a new
comprehensive framework that enables us to measure a wide range of wireless
devices, as well as multiple devices synchronously. We also present a rigorous
methodology to perform whole-device energy measurements in laptops, a more
generic and suitable device to perform energy debugging. Finally, and using
this framework, we provide a collection of measurements and insights that
deepens our understanding of the cross-factor.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08167</dc:identifier>
 <dc:identifier>IEEE 1st International Forum on Research and Technologies for
  Society and Industry Leveraging a better tomorrow (RTSI), Turin, 2015, pp.
  7-16</dc:identifier>
 <dc:identifier>doi:10.1109/RTSI.2015.7325085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08177</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Person Context and Local Scene Context for Object Detection</dc:title>
 <dc:creator>Gupta, Saurabh</dc:creator>
 <dc:creator>Hariharan, Bharath</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we explore two ways of using context for object detection. The
first model focusses on people and the objects they commonly interact with,
such as fashion and sports accessories. The second model considers more general
object detection and uses the spatial relationships between objects and between
objects and scenes. Our models are able to capture precise spatial
relationships between the context and the object of interest, and make
effective use of the appearance of the contextual region. On the newly released
COCO dataset, our models provide relative improvements of up to 5% over
CNN-based state-of-the-art detectors, with the gains concentrated on hard cases
such as small objects (10% relative improvement).
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08178</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>moGrams: a network-based methodology for visualizing the set of
  non-dominated solutions in multiobjective optimization</dc:title>
 <dc:creator>Trawi&#x144;ski, Krzysztof</dc:creator>
 <dc:creator>Chica, Manuel</dc:creator>
 <dc:creator>Pancho, David P.</dc:creator>
 <dc:creator>Damas, Sergio</dc:creator>
 <dc:creator>Cord&#xf3;n, Oscar</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  An appropriate visualization of multiobjective non-dominated solutions is a
valuable asset for decision making. Although there are methods for visualizing
the solutions in the design space, they do not provide any information about
their relationship. In this work, we propose a novel methodology that allows
the visualization of the non-dominated solutions in the design space and their
relationships by means of a network. The nodes represent the solutions in the
objective space, while the edges show the relationships between the solutions
in the design space. Our proposal (called moGrams) thus provides a joint
visualization of both objective and design spaces. It aims at helping the
decision maker to get more understanding of the problem so that (s)he can
choose the more appropriate final solution. moGrams can be applied to any
multicriteria problem in which the solutions are related by a similarity
metric. Besides, the decision maker interaction is facilitated by modifying the
network based on the current preferences to obtain a clearer view. An
exhaustive experimental study is performed using three multiobjective problems
in order to show both the usefulness and versatility of moGrams. The results
exhibit interesting characteristics of our methodology for visualizing and
analyzing solutions of multiobjective problems.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08179</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-charge transportation problems on trees</dc:title>
 <dc:creator>Angulo, Gustavo</dc:creator>
 <dc:creator>Van Vyve, Mathieu</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We consider a class of fixed-charge transportation problems over graphs. We
show that this problem is strongly NP-hard, but solvable in pseudo-polynomial
time over trees using dynamic programming. We also show that the LP formulation
associated to the dynamic program can be obtained from extended formulations of
single-node flow polytopes. Given these results, we present a unary
expansion-based formulation for general graphs that is computationally
advantageous when compared to a standard formulation, even if its LP relaxation
is not stronger.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08179</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08189</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Isomorphism and Circuit Size</dc:title>
 <dc:creator>Allender, Eric</dc:creator>
 <dc:creator>Grochow, Joshua A.</dc:creator>
 <dc:creator>Moore, Cristopher</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show that the Graph Automorphism problem is ZPP-reducible to MKTP, the
problem of minimizing time-bounded Kolmogorov complexity. MKTP has previously
been studied in connection with the Minimum Circuit Size Problem (MCSP) and is
often viewed as essentially a different encoding of MCSP. All prior reductions
to MCSP have applied equally well to MKTP, and vice-versa, and all such
reductions have relied on the fact that functions computable in polynomial time
can be inverted with high probability relative to MCSP and MKTP. Our reduction
uses a different approach, and consequently yields the first example of a
problem -- other than MKTP itself -- that is in ZPP^MKTP but that is not known
to lie in NP intersect coNP. We also show that this approach can be used to
provide a reduction of the Graph Isomorphism problem to MKTP.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08198</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Universal Paraphrastic Sentence Embeddings</dc:title>
 <dc:creator>Wieting, John</dc:creator>
 <dc:creator>Bansal, Mohit</dc:creator>
 <dc:creator>Gimpel, Kevin</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of learning general-purpose, paraphrastic sentence
embeddings based on supervision from the Paraphrase Database (Ganitkevitch et
al., 2013). We compare six compositional architectures, evaluating them on
annotated textual similarity datasets drawn both from the same distribution as
the training data and from a wide range of other domains. We find that the most
complex architectures, such as long short-term memory (LSTM) recurrent neural
networks, perform best on the in-domain data. However, in out-of-domain
scenarios, simple architectures such as word averaging vastly outperform LSTMs.
Our simplest averaging model is even competitive with systems tuned for the
particular tasks while also being extremely efficient and easy to use.
  In order to better understand how these architectures compare, we conduct
further experiments on three supervised NLP tasks: sentence similarity,
entailment, and sentiment classification. We again find that the word averaging
models perform well for sentence similarity and entailment, outperforming
LSTMs. However, on sentiment classification, we find that the LSTM performs
very strongly-even recording new state-of-the-art performance on the Stanford
Sentiment Treebank.
  We then demonstrate how to combine our pretrained sentence embeddings with
these supervised tasks, using them both as a prior and as a black box feature
extractor. This leads to performance rivaling the state of the art on the SICK
similarity and entailment tasks. We release all of our resources to the
research community with the hope that they can serve as the new baseline for
further work on universal sentence embeddings.
</dc:description>
 <dc:description>Comment: Published as a conference paper at ICLR 2016</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08205</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Breaking Symmetries in Graph Search with Canonizing Sets</dc:title>
 <dc:creator>Itzhakov, Avraham</dc:creator>
 <dc:creator>Codish, Michael</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  There are many complex combinatorial problems which involve searching for an
undirected graph satisfying given constraints. Such problems are often highly
challenging because of the large number of isomorphic representations of their
solutions. This paper introduces effective and compact, complete symmetry
breaking constraints for small graph search. Enumerating with these symmetry
breaks generates all and only non-isomorphic solutions. For small search
problems, with up to $10$ vertices, we compute instance independent symmetry
breaking constraints. For small search problems with a larger number of
vertices we demonstrate the computation of instance dependent constraints which
are complete. We illustrate the application of complete symmetry breaking
constraints to extend two known sequences from the OEIS related to graph
enumeration. We also demonstrate the application of a generalization of our
approach to fully-interchangeable matrix search problems.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08228</identifier>
 <datestamp>2016-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural GPUs Learn Algorithms</dc:title>
 <dc:creator>Kaiser, &#x141;ukasz</dc:creator>
 <dc:creator>Sutskever, Ilya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Learning an algorithm from examples is a fundamental problem that has been
widely studied. Recently it has been addressed using neural networks, in
particular by Neural Turing Machines (NTMs). These are fully differentiable
computers that use backpropagation to learn their own programming. Despite
their appeal NTMs have a weakness that is caused by their sequential nature:
they are not parallel and are are hard to train due to their large depth when
unfolded.
  We present a neural network architecture to address this problem: the Neural
GPU. It is based on a type of convolutional gated recurrent unit and, like the
NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly
parallel which makes it easier to train and efficient to run.
  An essential property of algorithms is their ability to handle inputs of
arbitrary size. We show that the Neural GPU can be trained on short instances
of an algorithmic task and successfully generalize to long instances. We
verified it on a number of tasks including long addition and long
multiplication of numbers represented in binary. We train the Neural GPU on
numbers with upto 20 bits and observe no errors whatsoever while testing it,
even on much longer numbers.
  To achieve these results we introduce a technique for training deep recurrent
networks: parameter sharing relaxation. We also found a small amount of dropout
and gradient noise to have a large positive effect on learning and
generalization.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08232</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond One Third Byzantine Failures</dc:title>
 <dc:creator>Wang, Cheng</dc:creator>
 <dc:creator>Delporte-Gallet, Carole</dc:creator>
 <dc:creator>Fauconnier, Hugues</dc:creator>
 <dc:creator>Guerraoui, Rachid</dc:creator>
 <dc:creator>Kermarrec, Anne-Marie</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The Byzantine agreement problem requires a set of $n$ processes to agree on a
value sent by a transmitter, despite a subset of $b$ processes behaving in an
arbitrary, i.e. Byzantine, manner and sending corrupted messages to all
processes in the system. It is well known that the problem has a solution in a
(an eventually) synchronous message passing distributed system iff the number
of processes in the Byzantine subset is less than one third of the total number
of processes, i.e. iff $n &gt; 3b+1$. The rest of the processes are expected to be
correct: they should never deviate from the algorithm assigned to them and send
corrupted messages. But what if they still do?
  We show in this paper that it is possible to solve Byzantine agreement even
if, beyond the $ b$ ($&lt; n/3 $) Byzantine processes, some of the other processes
also send corrupted messages, as long as they do not send them to all. More
specifically, we generalize the classical Byzantine model and consider that
Byzantine failures might be partial. In each communication step, some of the
processes might send corrupted messages to a subset of the processes. This
subset of processes - to which corrupted messages might be sent - could change
over time. We compute the exact number of processes that can commit such
faults, besides those that commit classical Byzantine failures, while still
solving Byzantine agreement. We present a corresponding Byzantine agreement
algorithm and prove its optimality by giving resilience and complexity bounds.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08232</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08238</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Approach to Complex Bayesian-optimal Approximate Message Passing</dc:title>
 <dc:creator>Hannak, Gabor</dc:creator>
 <dc:creator>Mayer, Martin</dc:creator>
 <dc:creator>Matz, Gerald</dc:creator>
 <dc:creator>Goertz, Norbert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we aim to solve the compressed sensing problem for the case of a
complex unknown vector by utilizing the Bayesian-optimal structured signal
approximate message passing (BOSSAMP) algorithm on the jointly sparse real and
imaginary parts of the unknown. By introducing a latent activity variable,
BOSSAMP separates the tasks of activity detection and value estimation to
overcome the problem of detecting different supports in the real and imaginary
parts. We complement the recovery algorithm by two novel support detection
schemes that utilize the updated auxiliary variables of BOSSAMP. Simulations
show the superiority of our proposed method against approximate message passing
(AMP) and its Bayesian-optimal sibling (BAMP), both in mean squared error and
support detection performance.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08245</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shattered Sets and the Hilbert Function</dc:title>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Rashtchian, Cyrus</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We study complexity measures on subsets of the boolean hypercube and exhibit
connections between algebra (the Hilbert function) and combinatorics (VC
theory). These connections yield results in both directions. Our main
complexity-theoretic result proves that most linear program feasibility
problems cannot be computed by polynomial-sized constant-depth circuits.
Moreover, our result applies to a stronger regime in which the hyperplanes are
fixed and only the directions of the inequalities are given as input to the
circuit. We derive this result by proving that a rich class of extremal
functions in VC theory cannot be approximated by low-degree polynomials. We
also present applications of algebra to combinatorics. We provide a new
algebraic proof of the Sandwich Theorem, which is a generalization of the
well-known Sauer-Perles-Shelah Lemma. Finally, we prove a structural result
about downward-closed sets, related to the Chv\'{a}tal conjecture in extremal
combinatorics.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08250</identifier>
 <datestamp>2016-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Instance Segmentation</dc:title>
 <dc:creator>Romera-Paredes, Bernardino</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Instance segmentation is the problem of detecting and delineating each
distinct object of interest appearing in an image. Current instance
segmentation approaches consist of ensembles of modules that are trained
independently of each other, thus missing opportunities for joint learning.
Here we propose a new instance segmentation paradigm consisting in an
end-to-end method that learns how to segment instances sequentially. The model
is based on a recurrent neural network that sequentially finds objects and
their segmentations one at a time. This net is provided with a spatial memory
that keeps track of what pixels have been explained and allows occlusion
handling. In order to train the model we designed a principled loss function
that accurately represents the properties of the instance segmentation problem.
In the experiments carried out, we found that our method outperforms recent
approaches on multiple person segmentation, and all state of the art approaches
on the Plant Phenotyping dataset for leaf counting.
</dc:description>
 <dc:description>Comment: 14 pages (main paper). 24 pages including references and appendix</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08250</dc:identifier>
 <dc:identifier>ECCV 2016. 14th European Conference on Computer Vision</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08253</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Algorithms and Circuits for Scientific Computing</dc:title>
 <dc:creator>Bhaskar, Mihir K.</dc:creator>
 <dc:creator>Hadfield, Stuart</dc:creator>
 <dc:creator>Papageorgiou, Anargyros</dc:creator>
 <dc:creator>Petras, Iasonas</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Quantum algorithms for scientific computing require modules implementing
fundamental functions, such as the square root, the logarithm, and others. We
require algorithms that have a well-controlled numerical error, that are
uniformly scalable and reversible (unitary), and that can be implemented
efficiently. We present quantum algorithms and circuits for computing the
square root, the natural logarithm, and arbitrary fractional powers. We provide
performance guarantees in terms of their worst-case accuracy and cost. We
further illustrate their performance by providing tests comparing them to the
respective floating point implementations found in widely used numerical
software.
</dc:description>
 <dc:description>Comment: 43 pages, 11 figures</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08253</dc:identifier>
 <dc:identifier>Quantum Information and Computation. 16, no. 3&amp;4 (2016): 0197-0236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08256</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtualization of 5G Cellular Networks as a Hierarchical Combinatorial
  Auction</dc:title>
 <dc:creator>Zhu, Kun</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Virtualization has been seen as one of the main evolution trends in the
forthcoming fifth generation (5G) cellular networks which enables the
decoupling of infrastructure from the services it provides. In this case, the
roles of infrastructure providers (InPs) and mobile virtual network operators
(MVNOs) can be logically separated and the resources (e.g., subchannels, power,
and antennas) of a base station owned by an InP can be transparently shared by
multiple MVNOs, while each MVNO virtually owns the entire BS. Naturally, the
issue of resource allocation arises. In particular, the InP is required to
abstract the physical resources into isolated slices for each MVNO who then
allocates the resources within the slice to its subscribed users. In this
paper, we aim to address this two-level hierarchical resource allocation
problem while satisfying the requirements of efficient resource allocation,
strict inter-slice isolation, and the ability of intra-slice customization. To
this end, we design a hierarchical combinatorial auction mechanism, based on
which a truthful and sub-efficient resource allocation framework is provided.
Specifically, winner determination problems (WDPs) are formulated for the InP
and MVNOs, and computationally tractable algorithms are proposed to solve these
WDPs. Also, pricing schemes are designed to ensure incentive compatibility. The
designed mechanism can achieve social efficiency in each level even if each
party involved acts selfishly. Numerical results show the effectiveness of the
proposed scheme.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Mobile Computing, under submission</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08264</identifier>
 <datestamp>2016-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient degree reduction of B\'ezier curves with box constraints using
  dual bases</dc:title>
 <dc:creator>Gospodarczyk, Przemys&#x142;aw</dc:creator>
 <dc:creator>Wo&#x17a;ny, Pawe&#x142;</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we give an efficient algorithm of degree reduction of B\'ezier
curves with box constraints. The idea is to combine the previous iterative
approach, that has been presented recently in (P. Gospodarczyk, Comput. Aided
Des. 62 (2015), 143--151), with a fast method of construction of dual bases
from (P. Wo\'zny, J. Comput. Appl. Math. 260 (2014), 301--311) and a new
efficient method of modification of dual bases.
</dc:description>
 <dc:date>2015-11-24</dc:date>
 <dc:date>2016-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08270</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the hardness of learning sparse parities</dc:title>
 <dc:creator>Bhattacharyya, Arnab</dc:creator>
 <dc:creator>Gadekar, Ameet</dc:creator>
 <dc:creator>Ghoshal, Suprovat</dc:creator>
 <dc:creator>Saket, Rishi</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This work investigates the hardness of computing sparse solutions to systems
of linear equations over F_2. Consider the k-EvenSet problem: given a
homogeneous system of linear equations over F_2 on n variables, decide if there
exists a nonzero solution of Hamming weight at most k (i.e. a k-sparse
solution). While there is a simple O(n^{k/2})-time algorithm for it,
establishing fixed parameter intractability for k-EvenSet has been a notorious
open problem. Towards this goal, we show that unless k-Clique can be solved in
n^{o(k)} time, k-EvenSet has no poly(n)2^{o(sqrt{k})} time algorithm and no
polynomial time algorithm when k = (log n)^{2+eta} for any eta &gt; 0.
  Our work also shows that the non-homogeneous generalization of the problem --
which we call k-VectorSum -- is W[1]-hard on instances where the number of
equations is O(k log n), improving on previous reductions which produced
Omega(n) equations. We also show that for any constant eps &gt; 0, given a system
of O(exp(O(k))log n) linear equations, it is W[1]-hard to decide if there is a
k-sparse linear form satisfying all the equations or if every function on at
most k-variables (k-junta) satisfies at most (1/2 + eps)-fraction of the
equations. In the setting of computational learning, this shows hardness of
approximate non-proper learning of k-parities. In a similar vein, we use the
hardness of k-EvenSet to show that that for any constant d, unless k-Clique can
be solved in n^{o(k)} time there is no poly(m, n)2^{o(sqrt{k}) time algorithm
to decide whether a given set of m points in F_2^n satisfies: (i) there exists
a non-trivial k-sparse homogeneous linear form evaluating to 0 on all the
points, or (ii) any non-trivial degree d polynomial P supported on at most k
variables evaluates to zero on approx. Pr_{F_2^n}[P(z) = 0] fraction of the
points i.e., P is fooled by the set of points.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08277</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Architecture for Semantic Matching with Multiple Positional
  Sentence Representations</dc:title>
 <dc:creator>Wan, Shengxian</dc:creator>
 <dc:creator>Lan, Yanyan</dc:creator>
 <dc:creator>Guo, Jiafeng</dc:creator>
 <dc:creator>Xu, Jun</dc:creator>
 <dc:creator>Pang, Liang</dc:creator>
 <dc:creator>Cheng, Xueqi</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Matching natural language sentences is central for many applications such as
information retrieval and question answering. Existing deep models rely on a
single sentence representation or multiple granularity representations for
matching. However, such methods cannot well capture the contextualized local
information in the matching process. To tackle this problem, we present a new
deep architecture to match two sentences with multiple positional sentence
representations. Specifically, each positional sentence representation is a
sentence representation at this position, generated by a bidirectional long
short term memory (Bi-LSTM). The matching score is finally produced by
aggregating interactions between these different positional sentence
representations, through $k$-Max pooling and a multi-layer perceptron. Our
model has several advantages: (1) By using Bi-LSTM, rich context of the whole
sentence is leveraged to capture the contextualized local information in each
positional sentence representation; (2) By matching with multiple positional
sentence representations, it is flexible to aggregate different important
contextualized local information in a sentence to support the matching; (3)
Experiments on different tasks such as question answering and sentence
completion demonstrate the superiority of our model.
</dc:description>
 <dc:description>Comment: Accepted by AAAI-2016</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08280</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Welfare of Sequential Allocation Mechanisms for Indivisible Goods</dc:title>
 <dc:creator>Aziz, Haris</dc:creator>
 <dc:creator>Kalinowski, Thomas</dc:creator>
 <dc:creator>Walsh, Toby</dc:creator>
 <dc:creator>Xia, Lirong</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Sequential allocation is a simple and attractive mechanism for the allocation
of indivisible goods. Agents take turns, according to a policy, to pick items.
Sequential allocation is guaranteed to return an allocation which is efficient
but may not have an optimal social welfare. We consider therefore the relation
between welfare and efficiency. We study the (computational) questions of what
welfare is possible or necessary depending on the choice of policy. We also
consider a novel control problem in which the chair chooses a policy to improve
social welfare.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08280</dc:identifier>
 <dc:identifier>Frontiers in Artificial Intelligence and Applications, 787-794,
  2016</dc:identifier>
 <dc:identifier>doi:10.3233/978-1-61499-672-9-787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08283</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A tight lower bound for Vertex Planarization on graphs of bounded
  treewidth</dc:title>
 <dc:creator>Pilipczuk, Marcin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the Vertex Planarization problem one asks to delete the minimum possible
number of vertices from an input graph to obtain a planar graph. The
parameterized complexity of this problem, parameterized by the solution size
(the number of deleted vertices) has recently attracted significant attention.
The state-of-the-art algorithm of Jansen, Lokshtanov, and Saurabh [SODA 2014]
runs in time $2^{O(k \log k)} \cdot n$ on $n$-vertex graph with a solution of
size $k$. It remains open if one can obtain a single-exponential dependency on
$k$ in the running time bound.
  One of the core technical contributions of the work of Jansen, Lokshtanov,
and Saurabh is an algorithm that solves a weighted variant of Vertex
Planarization in time $2^{O(w \log w)} \cdot n$ on graphs of treewidth $w$. In
this short note we prove that the running time of this routine is tight under
the Exponential Time Hypothesis, even in unweighted graphs and when
parameterizing by treedepth. Consequently, it is unlikely that a potential
single-exponential algorithm for Vertex Planarization parameterized by the
solution size can be obtained by merely improving upon the aforementioned
bounded treewidth subroutine.
</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08290</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-layer Chase Combining with Selective Retransmission, Analysis and
  Throughput Optimization for OFDM Systems</dc:title>
 <dc:creator>Shafique, Taniya</dc:creator>
 <dc:creator>Muhammad, Zia</dc:creator>
 <dc:creator>Han, Huy-Dung</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  In this paper, we present bandwidth efficient retransmission method employong
selective retransmission approach at modulation layer under orthogonal
frequency division multiplexing (OFDM) signaling. Our proposed cross-layer
design embeds a selective retransmission sublayer in physical layer (PHY) that
targets retransmission of information symbols transmitted over poor quality
OFDM sub-carriers. Most of the times, few errors in decoded bit stream result
in packet failure at medium access control (MAC) layer. The unnecessary
retransmission of good quality information symbols of a failed packet has
detrimental effect on overall throughput of transceiver. We propose a
cross-layer Chase combining with selective retransmission (CCSR) method by
blending Chase combining at MAC layer and selective retransmission in PHY. The
selective retransmission in PHY targets the poor quality information symbols
prior to decoding, which results into lower hybrid automatic repeat reQuest
(HARQ) retransmissions at MAC layer. We also present tight bit-error rate (BER)
upper bound and tight throughput lower bound for CCSR method. In order to
maximize throughput of the proposed method, we formulate optimization problem
with respect to the amount of information to be retransmitted in selective
retransmission. The simulation results demonstrate significant throughput gain
of the proposed CCSR method as compared to conventional Chase combining method.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1503.05819</dc:description>
 <dc:date>2015-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08299</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical classification of e-commerce related social media</dc:title>
 <dc:creator>Long, Matthew</dc:creator>
 <dc:creator>Jami, Aditya</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we attempt to classify tweets into root categories of the
Amazon browse node hierarchy using a set of tweets with browse node ID labels,
a much larger set of tweets without labels, and a set of Amazon reviews.
Examining twitter data presents unique challenges in that the samples are short
(under 140 characters) and often contain misspellings or abbreviations that are
trivial for a human to decipher but difficult for a computer to parse. A
variety of query and document expansion techniques are implemented in an effort
to improve information retrieval to modest success.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08303</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering Oracles for Time-Dependent Road Networks</dc:title>
 <dc:creator>Kontogiannis, Spyros</dc:creator>
 <dc:creator>Michalopoulos, George</dc:creator>
 <dc:creator>Papastavrou, Georgia</dc:creator>
 <dc:creator>Paraskevopoulos, Andreas</dc:creator>
 <dc:creator>Wagner, Dorothea</dc:creator>
 <dc:creator>Zaroliagis, Christos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We implement and experimentally evaluate landmark-based oracles for min-cost
paths in large-scale time-dependent road networks. We exploit parallelism and
lossless compression, combined with a novel travel-time approximation
technique, to severely reduce preprocessing space and time. We significantly
improve the FLAT oracle, improving the previous query time by $30\%$ and
doubling the Dijkstra-rank speedup. We also implement and experimentally
evaluate a novel oracle (HORN), based on a landmark hierarchy, achieving even
better performance wrt to FLAT.
</dc:description>
 <dc:description>Comment: In ALENEX 2016</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08307</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nez: practical open grammar language</dc:title>
 <dc:creator>Kuramitsu, Kimio</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Nez is a PEG(Parsing Expressing Grammar)-based open grammar language that
allows us to describe complex syntax constructs without action code. Since open
grammars are declarative and free from a host programming language of parsers,
software engineering tools and other parser applications can reuse once-defined
grammars across programming languages.
  A key challenge to achieve practical open grammars is the expressiveness of
syntax constructs and the resulting parser performance, as the traditional
action code approach has provided very pragmatic solutions to these two issues.
In Nez, we extend the symbol-based state management to recognize
context-sensitive language syntax, which often appears in major programming
languages. In addition, the Abstract Syntax Tree constructor allows us to make
flexible tree structures, including the left-associative pair of trees. Due to
these extensions, we have demonstrated that Nez can parse not all but many
grammars.
  Nez can generate various types of parsers since all Nez operations are
independent of a specific parser language. To highlight this feature, we have
implemented Nez with dynamic parsing, which allows users to integrate a Nez
parser as a parser library that loads a grammar at runtime. To achieve its
practical performance, Nez operators are assembled into low-level virtual
machine instructions, including automated state modifications when
backtracking, transactional controls of AST construction, and efficient
memoization in packrat parsing. We demonstrate that Nez dynamic parsers achieve
very competitive performance compared to existing efficient parser generators.
</dc:description>
 <dc:description>Comment: unpublished draft work (11 pages)</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08308</identifier>
 <datestamp>2016-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Named Entity Recognition with Bidirectional LSTM-CNNs</dc:title>
 <dc:creator>Chiu, Jason P. C.</dc:creator>
 <dc:creator>Nichols, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Named entity recognition is a challenging task that has traditionally
required large amounts of knowledge in the form of feature engineering and
lexicons to achieve high performance. In this paper, we present a novel neural
network architecture that automatically detects word- and character-level
features using a hybrid bidirectional LSTM and CNN architecture, eliminating
the need for most feature engineering. We also propose a novel method of
encoding partial lexicon matches in neural networks and compare it to existing
approaches. Extensive evaluation shows that, given only tokenized text and
publicly available word embeddings, our system is competitive on the CoNLL-2003
dataset and surpasses the previously reported state of the art performance on
the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed
from publicly-available sources, we establish new state of the art performance
with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing
systems that employ heavy feature engineering, proprietary lexicons, and rich
entity linking information.
</dc:description>
 <dc:description>Comment: To appear in Transactions of the Association for Computational
  Linguistics</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08310</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sic Transit Gloria Manuscriptum: Two Views of the Aggregate Fate of
  Ancient Papers</dc:title>
 <dc:creator>Singh, Mayank</dc:creator>
 <dc:creator>Sarkar, Rajdeep</dc:creator>
 <dc:creator>Goyal, Pawan</dc:creator>
 <dc:creator>Mukherjee, Animesh</dc:creator>
 <dc:creator>Chakrabarti, Soumen</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  When PageRank began to be used for ranking in Web search, a concern soon
arose that older pages have an inherent --- and potentially unfair ---
advantage over emerging pages of high quality, because they have had more time
to acquire hyperlink citations. Algorithms were then proposed to compensate for
this effect. Curiously, in bibliometry, the opposite concern has often been
raised: that a growing body of recent papers crowds out older papers, resulting
in a collective amnesia in research communities, which potentially leads to
reinventions, redundancies, and missed opportunities to connect ideas. A recent
paper by Verstak et al. reported experiments on Google Scholar data, which
seemed to refute the amnesia, or aging, hypothesis. They claimed that more
recently written papers have a larger fraction of outbound citations targeting
papers that are older by a fixed number of years, indicating that ancient
papers are alive and well-loved and increasingly easily found, thanks in part
to Google Scholar. In this paper we show that the full picture is considerably
more nuanced. Specifically, the fate of a fixed sample of papers, as they age,
is rather different from what Verstak et al.'s study suggests: there is clear
and steady abandonment in favor of citations to newer papers. The two
apparently contradictory views are reconciled by the realization that, as time
passes, the number of papers older than a fixed number of years grows rapidly.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08324</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Scale-free Network of Passwords : Visualization and Estimation of
  Empirical Passwords</dc:title>
 <dc:creator>Guo, Xiujia</dc:creator>
 <dc:creator>Chen, Haibo</dc:creator>
 <dc:creator>Liu, Xuqin</dc:creator>
 <dc:creator>Xu, Xiangyu</dc:creator>
 <dc:creator>Chen, Zhong</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we present a novel vision of large scale of empirical password
sets available and improve the understanding of passwords by revealing their
interconnections and considering the security on a level of the whole password
set instead of one single password level. Through the visualization of Yahoo,
Phpbb, 12306, etc. we, for the first time, show what the spatial structure of
empirical password sets are like and take the community and clustering patterns
of the passwords into account to shed lights on the definition of popularity of
a password based on their frequency and degree separately. Furthermore, we
propose a model of statistical guessing attack from the perspective of the
data's topological space, which provide an explanation of the &quot;cracking curve&quot;.
We also give a lower bound of the minimum size of the dictionary needed to
compromise arbitrary ratio of any given password set by proving that it is
equivalent to the minimum dominating set problem, which is a NP-complete
problem. Hence the minimal dictionary problem is also NP-complete.
</dc:description>
 <dc:description>Comment: 9 pages, 14 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08327</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Forests for Big Data</dc:title>
 <dc:creator>Genuer, Robin</dc:creator>
 <dc:creator>Poggi, Jean-Michel</dc:creator>
 <dc:creator>Tuleau-Malot, Christine</dc:creator>
 <dc:creator>Villa-Vialaneix, Nathalie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Big Data is one of the major challenges of statistical science and has
numerous consequences from algorithmic and theoretical viewpoints. Big Data
always involve massive data but they also often include online data and data
heterogeneity. Recently some statistical methods have been adapted to process
Big Data, like linear regression models, clustering methods and bootstrapping
schemes. Based on decision trees combined with aggregation and bootstrap ideas,
random forests were introduced by Breiman in 2001. They are a powerful
nonparametric statistical method allowing to consider in a single and versatile
framework regression problems, as well as two-class and multi-class
classification problems. Focusing on classification problems, this paper
proposes a selective review of available proposals that deal with scaling
random forests to Big Data problems. These proposals rely on parallel
environments or on online adaptations of random forests. We also describe how
related quantities -- such as out-of-bag error and variable importance -- are
addressed in these methods. Then, we formulate various remarks for random
forests in the Big Data context. Finally, we experiment five variants on two
massive datasets (15 and 120 millions of observations), a simulated one as well
as real world data. One variant relies on subsampling while three others are
related to parallel implementations of random forests and involve either
various adaptations of bootstrap to Big Data or to &quot;divide-and-conquer&quot;
approaches. The fifth variant relates on online learning of random forests.
These numerical experiments lead to highlight the relative performance of the
different variants, as well as some of their limitations.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2017-03-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08331</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Value of Information Aware Opportunistic Duty Cycling in Solar
  Harvesting Sensor Networks</dc:title>
 <dc:creator>Zhang, Jianhui</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The energy-harvested Wireless Sensor Networks (WSNs) may operate perpetually
with the extra energy supply from ambient natural energy, such as solar energy.
Nevertheless, the harvested energy is still limited so it's not able to support
the perpetual network operation with full duty cycle. To achieve the perpetual
network operation and process the data with high importance, measured by Value
of Information (VoI), the network has to operate under partial duty cycle and
to improve the efficiency to consume the harvested energy. The challenging
problem is how to deal with the stochastic feature of the natural energy and
the variable data VoI. We consider the energy consumption during storing and
the diversity of the data process including sampling, transmitting and
receiving, which consume different power levels. The problem is then mapped as
the budget-dynamic Multi-Arm Bandit (MAB) problem by treating the energy as the
budget and the data process as arm pulling. This paper proposes an
Opportunistic Duty Cycling (ODC) scheme to improve the energy efficiency while
satisfying the perpetual network operation. ODC chooses the proper
opportunities to store the harvested energy or to spend it on the data process
based on the historical information of the energy harvesting and the VoI of the
processed data. With this scheme, each sensor node need only estimate the
ambient natural energy in short term so as to reduce the computation and the
storage for the historical information. It also can distributively adjust its
own duty cycle according to its local historical information. This paper also
conducts the extensive analysis on the performance of our scheme ODC, and the
theoretical results validate the regret, which is the difference between the
optimal scheme and ours. Our experimental results also manifest the promising
performance of ODC.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08334</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the complexity of heterogeneous multidimensional quantitative games</dc:title>
 <dc:creator>Bruy&#xe8;re, V&#xe9;ronique</dc:creator>
 <dc:creator>Hautem, Quentin</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, we study two-player zero-sum turn-based games played on a
finite multidimensional weighted graph. In recent papers all dimensions use the
same measure, whereas here we allow to combine different measures. Such
heterogeneous multidimensional quantitative games provide a general and natural
model for the study of reactive system synthesis. We focus on classical
measures like the Inf, Sup, LimInf, and LimSup of the weights seen along the
play, as well as on the window mean-payoff (WMP) measure. This new measure is a
natural strengthening of the mean-payoff measure. We allow objectives defined
as Boolean combinations of heterogeneous constraints. While multidimensional
games with Boolean combinations of mean-payoff constraints are undecidable, we
show that the problem becomes EXPTIME-complete for DNF/CNF Boolean combinations
of heterogeneous measures taken among {WMP, Inf, Sup, LimInf, LimSup} and that
exponential memory strategies are sufficient for both players to win. We
provide a detailed study of the complexity and the memory requirements when the
Boolean combination of the measures is replaced by an intersection.
EXPTIME-completeness and exponential memory strategies still hold for the
intersection of measures in {WMP, Inf, Sup, LimInf, LimSup}, and we get
PSPACE-completeness when WMP measure is no longer considered. To avoid
EXPTIME-or PSPACE-hardness, we impose at most one occurrence of WMP measure and
fix the number of Sup measures, and we propose several refinements (on the
number of occurrences of the other measures) for which we get polynomial
algorithms and lower memory requirements. For all the considered classes of
games, we also study parameterized complexity.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08336</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the use of BGP communities for fine-grained inbound traffic
  engineering</dc:title>
 <dc:creator>Shao, Wenqin</dc:creator>
 <dc:creator>Devienne, Francois</dc:creator>
 <dc:creator>Iannone, Luigi</dc:creator>
 <dc:creator>Rougier, Jean-Louis</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the context of Border Gateway Protocol (BGP), inbound inter-domain traffic
engineering (TE) remains a difficult problem without panacea. Each of
previously investigated method solves a part of the problem. In this study, we
try to complement the map by exploring the use of BGP communities. With BGP
community based polices enabled in transit provider networks, we are able to
manipulate incoming traffic for stub Autonomous System (AS) in a finer
granularity than known techniques by customizing the AS-paths perceived by
remote networks. We analyze the constraints using this technique, along with
its effectiveness and granularity.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08342</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient User Association with Open Loop Power Control for
  Uplink Heterogeneous Cellular Networks</dc:title>
 <dc:creator>Zhou, Tianqing</dc:creator>
 <dc:creator>Huang, Yongming</dc:creator>
 <dc:creator>Yang, Luxi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy reduction for wireless systems becomes more and more important due to
its impact on the operation cost and global carbon footprint. In this paper, we
investigate three kinds of energy-efficient association schemes under open loop
power control for uplink heterogeneous cellular networks, which are formulated
as a whole energy efficiency maximization problem, a sum energy efficiency
maximization problem and a utility maximization problem respectively. The third
case takes account of load balancing level and user's fairness in the
energy-efficient association. Considering that the first problem is in a
fractional mixed-integer form, we introduce an energy efficiency parameter to
convert it into a parametric subtractive form, and then design an effective
iterative algorithm to achieve the optimal solutions. As for the third problem,
we first introduce a dual variable to decouple the constraint and then develop
a distributed algorithm using dual decomposition. In addition, we also give the
convergence proof for the proposed algorithms. In order to confirm the
effectiveness of energy-efficient user association algorithms, we introduce
other association rules for comparison, and investigate the influences of
different parameters on the association performance of these association rules.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08343</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Automatic Statistician: A Relational Perspective</dc:title>
 <dc:creator>Hwang, Yunseong</dc:creator>
 <dc:creator>Tong, Anh</dc:creator>
 <dc:creator>Choi, Jaesik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Gaussian Processes (GPs) provide a general and analytically tractable way of
modeling complex time-varying, nonparametric functions. The Automatic Bayesian
Covariance Discovery (ABCD) system constructs natural-language description of
time-series data by treating unknown time-series data nonparametrically using
GP with a composite covariance kernel function. Unfortunately, learning a
composite covariance kernel with a single time-series data set often results in
less informative kernel that may not give qualitative, distinctive descriptions
of data. We address this challenge by proposing two relational kernel learning
methods which can model multiple time-series data sets by finding common,
shared causes of changes. We show that the relational kernel learning methods
find more accurate models for regression problems on several real-world data
sets; US stock data, US house price index data and currency exchange rate data.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08344</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable BGP Prefix Selection for Effective Inter-domain Traffic
  Engineering</dc:title>
 <dc:creator>Shao, Wenqin</dc:creator>
 <dc:creator>Iannone, Luigi</dc:creator>
 <dc:creator>Rougier, Jean-Louis</dc:creator>
 <dc:creator>Devienne, Francois</dc:creator>
 <dc:creator>Viste, Mateusz</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Inter-domain Traffic Engineering for multi-homed networks faces a scalability
challenge, as the size of BGP routing table continue to grow. In this context,
the choice of the best path must be made potentially for each destination
prefix, requiring all available paths to be characterised (e.g., through
measurements) and compared with each other. Fortunately, it is well-known that
a few number of prefixes carry the larger part of the traffic. As a natural
consequence, to engineer large volume of traffic only few prefixes need to be
managed. Yet, traffic characteristics of a given prefix can greatly vary over
time, and little is known on the dynamism of traffic at this aggregation level,
including predicting the set of the most significant prefixes in the near
future. %based on past observations. Sophisticated prediction methods won't
scale in such context. In this paper, we study the relationship between prefix
volume, stability, and predictability, based on recent traffic traces from nine
different networks. Three simple and resource-efficient methods to select the
prefixes associated with the most important foreseeable traffic volume are then
proposed. Such proposed methods allow to select sets of prefixes with both
excellent representativeness (volume coverage) and stability in time, for which
the best routes are identified. The analysis carried out confirm the potential
benefits of a route decision engine.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08344</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08350</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A global Constraint for mining Sequential Patterns with GAP constraint</dc:title>
 <dc:creator>Kemmar, Amina</dc:creator>
 <dc:creator>Loudni, Samir</dc:creator>
 <dc:creator>Lebbah, Yahia</dc:creator>
 <dc:creator>Boizumault, Patrice</dc:creator>
 <dc:creator>Charnois, Thierry</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sequential pattern mining (SPM) under gap constraint is a challenging task.
Many efficient specialized methods have been developed but they are all
suffering from a lack of genericity. The Constraint Programming (CP) approaches
are not so effective because of the size of their encodings. In[7], we have
proposed the global constraint Prefix-Projection for SPM which remedies to this
drawback. However, this global constraint cannot be directly extended to
support gap constraint. In this paper, we propose the global constraint GAP-SEQ
enabling to handle SPM with or without gap constraint. GAP-SEQ relies on the
principle of right pattern extensions. Experiments show that our approach
clearly outperforms both CP approaches and the state-of-the-art cSpade method
on large datasets.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08355</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Static to Dynamic Tag Population Estimation: An Extended Kalman
  Filter Perspective</dc:title>
 <dc:creator>Yu, Jihong</dc:creator>
 <dc:creator>Chen, Lin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Tag population estimation has recently attracted significant research
attention due to its paramount importance on a variety of radio frequency
identification (RFID) applications. However, most, if not all, of existing
estimation mechanisms are proposed for the static case where tag population
remains constant during the estimation process, thus leaving the more
challenging dynamic case unaddressed, despite the fundamental importance of the
latter case on both theoretical analysis and practical application. In order to
bridge this gap, %based on \textit{dynamic framed-slotted ALOHA} (DFSA)
protocol, we devote this paper to designing a generic framework of stable and
accurate tag population estimation schemes based on Kalman filter for both
static and dynamic RFID systems. %The objective is to devise estimation schemes
and analyze the boundedness of estimation error. Technically, we first model
the dynamics of RFID systems as discrete stochastic processes and leverage the
techniques in extended Kalman filter (EKF) and cumulative sum control chart
(CUSUM) to estimate tag population for both static and dynamic systems. By
employing Lyapunov drift analysis, we mathematically characterise the
performance of the proposed framework in terms of estimation accuracy and
convergence speed by deriving the closed-form conditions on the design
parameters under which our scheme can stabilise around the real population size
with bounded relative estimation error that tends to zero with exponential
convergence rate.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08366</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On randomization of neural networks as a form of post-learning strategy</dc:title>
 <dc:creator>Kapanova, K. G.</dc:creator>
 <dc:creator>Dimov, I.</dc:creator>
 <dc:creator>Sellier, J. M.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Today artificial neural networks are applied in various fields - engineering,
data analysis, robotics. While they represent a successful tool for a variety
of relevant applications, mathematically speaking they are still far from being
conclusive. In particular, they suffer from being unable to find the best
configuration possible during the training process (local minimum problem). In
this paper, we focus on this issue and suggest a simple, but effective,
post-learning strategy to allow the search for improved set of weights at a
relatively small extra computational cost. Therefore, we introduce a novel
technique based on analogy with quantum effects occurring in nature as a way to
improve (and sometimes overcome) this problem. Several numerical experiments
are presented to validate the approach.
</dc:description>
 <dc:description>Comment: 15 pages, 26 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08366</dc:identifier>
 <dc:identifier>doi:10.1007/s00500-015-1949-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08367</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Academic research groups: evaluation of their quality and quality of
  their evaluation</dc:title>
 <dc:creator>Berche, Bertrand</dc:creator>
 <dc:creator>Holovatch, Yurij</dc:creator>
 <dc:creator>Kenna, Ralph</dc:creator>
 <dc:creator>Mryglod, Olesya</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  In recent years, evaluation of the quality of academic research has become an
increasingly important and influential business. It determines, often to a
large extent, the amount of research funding flowing into universities and
similar institutes from governmental agencies and it impacts upon academic
careers. Policy makers are becoming increasingly reliant upon, and influenced
by, the outcomes of such evaluations. In response, university managers are
increasingly attracted to simple indicators as guides to the dynamics of the
positions of their various institutions in league tables. However, these league
tables are frequently drawn up by inexpert bodies such as newspapers and
magazines, using rather arbitrary measures and criteria. Terms such as
&quot;critical mass' and &quot;metrics&quot; are often bandied about without proper
understanding of what they actually mean. Rather than accepting the rise and
fall of universities, departments and individuals on a turbulent sea of
arbitrary measures, we suggest it is incumbent upon the scientific community
itself to clarify their nature. Here we report on recent attempts to do that by
properly defining critical mass and showing how group size influences research
quality. We also examine currently predominant metrics and show that these fail
as reliable indicators of group research quality.
</dc:description>
 <dc:description>Comment: Presented at the International Conference on Computer Simulation in
  Physics and Beyond in Moscow, 2015. The Proceedings will appear in Journal of
  Physics: Conference Series (JPCS)</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08367</dc:identifier>
 <dc:identifier>J. Phys.: Conf. Ser. 681 (2016) 012004</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/681/1/012004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08386</identifier>
 <datestamp>2016-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>gMark: Schema-Driven Generation of Graphs and Queries</dc:title>
 <dc:creator>Bagan, Guillaume</dc:creator>
 <dc:creator>Bonifati, Angela</dc:creator>
 <dc:creator>Ciucanu, Radu</dc:creator>
 <dc:creator>Fletcher, George H. L.</dc:creator>
 <dc:creator>Lemay, Aur&#xe9;lien</dc:creator>
 <dc:creator>Advokaat, Nicky</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Massive graph data sets are pervasive in contemporary application domains.
Hence, graph database systems are becoming increasingly important. In the
experimental study of these systems, it is vital that the research community
has shared solutions for the generation of database instances and query
workloads having predictable and controllable properties. In this paper, we
present the design and engineering principles of gMark, a domain- and query
language-independent graph instance and query workload generator. A core
contribution of gMark is its ability to target and control the diversity of
properties of both the generated instances and the generated workloads coupled
to these instances. Further novelties include support for regular path queries,
a fundamental graph query paradigm, and schema-driven selectivity estimation of
queries, a key feature in controlling workload chokepoints. We illustrate the
flexibility and practical usability of gMark by showcasing the framework's
capabilities in generating high quality graphs and workloads, and its ability
to encode user-defined schemas across a variety of application domains.
</dc:description>
 <dc:description>Comment: Accepted in November 2016. URL:
  http://ieeexplore.ieee.org/document/7762945/. in IEEE Transactions on
  Knowledge and Data Engineering 2017</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08386</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2016.2633993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08396</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Basic Properties of Jumping Finite Automata</dc:title>
 <dc:creator>Vorel, Vojt&#x11b;ch</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We complete the initial study of jumping finite automata, which was started
in a former article of Meduna and Zemek \citep{athMED1}. The open questions
about basic closure properties are solved. Besides this, we correct erroneous
results presented in the article. Finally, we point out important relations
between jumping finite automata and some other models studied in the
literature.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08399</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$3$-dimensional Continued Fraction Algorithms Cheat Sheets</dc:title>
 <dc:creator>Labb&#xe9;, S&#xe9;bastien</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>11J70, 37A45, 52C35, 68R15</dc:subject>
 <dc:description>  Multidimensional Continued Fraction Algorithms are generalizations of the
Euclid algorithm and find iteratively the gcd of two or more numbers. They are
defined as linear applications on some subcone of $\mathbb{R}^d$. We consider
multidimensional continued fraction algorithms that acts symmetrically on the
positive cone $\mathbb{R}^d_+$ for $d=3$. We include well-known and old ones
(Poincar\'e, Brun, Selmer, Fully Subtractive) and new ones
(Arnoux-Rauzy-Poincar\'e, Reverse, Cassaigne).
  For each algorithm, one page (called cheat sheet) gathers a handful of
informations most of them generated with the open source software Sage with the
optional Sage package \texttt{slabbe-0.2.spkg}. The information includes the
$n$-cylinders, density function of an absolutely continuous invariant measure,
domain of the natural extension, lyapunov exponents as well as data regarding
combinatorics on words, symbolic dynamics and digital geometry, that is,
associated substitutions, generated $S$-adic systems, factor complexity,
discrepancy, dual substitutions and generation of digital planes.
  The document ends with a table of comparison of Lyapunov exponents and gives
the code allowing to reproduce any of the results or figures appearing in these
cheat sheets.
</dc:description>
 <dc:description>Comment: 9 pages, 66 figures, landscape orientation</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08400</identifier>
 <datestamp>2016-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularizing RNNs by Stabilizing Activations</dc:title>
 <dc:creator>Krueger, David</dc:creator>
 <dc:creator>Memisevic, Roland</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We stabilize the activations of Recurrent Neural Networks (RNNs) by
penalizing the squared distance between successive hidden states' norms.
  This penalty term is an effective regularizer for RNNs including LSTMs and
IRNNs, improving performance on character-level language modeling and phoneme
recognition, and outperforming weight noise and dropout.
  We achieve competitive performance (18.6\% PER) on the TIMIT phoneme
recognition task for RNNs evaluated without beam search or an RNN transducer.
  With this penalty term, IRNN can achieve similar performance to LSTM on
language modeling, although adding the penalty term to the LSTM results in
superior performance.
  Our penalty term also prevents the exponential growth of IRNN's activations
outside of their training horizon, allowing them to generalize to much longer
sequences.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08403</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On bounding the difference between the maximum degree and the chromatic
  number by a constant</dc:title>
 <dc:creator>Schaudt, Oliver</dc:creator>
 <dc:creator>Weil, Vera</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C15, 05C17, 05C69, 05C75</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We provide a finite forbidden induced subgraph characterization for the graph
class $\varUpsilon_k$, for all $k \in \mathbb{N}_0$, which is defined as
follows. A graph is in $\varUpsilon_k$ if for any induced subgraph, $\Delta
\leq \chi -1 + k$ holds, where $\Delta$ is the maximum degree and $\chi$ is the
chromatic number of the subgraph.
  We compare these results with those given in [O. Schaudt, V. Weil, On
bounding the difference between the maximum degree and the clique number,
Graphs and Combinatorics 31(5), 1689-1702 (2015). DOI:
10.1007/s00373-014-1468-3], where we studied the graph class $\varOmega_k$, for
$k \in \mathbb{N}_0$, whose graphs are such that for any induced subgraph,
$\Delta \leq \omega -1 + k$ holds, where $\omega$ denotes the clique number of
a graph. In particular, we give a characterization in terms of $\varOmega_k$
and $\varUpsilon_k$ of those graphs where the neighborhood of every vertex is
perfect.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08405</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gains and Losses are Fundamentally Different in Regret Minimization: The
  Sparse Case</dc:title>
 <dc:creator>Kwon, Joon</dc:creator>
 <dc:creator>Perchet, Vianney</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We demonstrate that, in the classical non-stochastic regret minimization
problem with $d$ decisions, gains and losses to be respectively maximized or
minimized are fundamentally different. Indeed, by considering the additional
sparsity assumption (at each stage, at most $s$ decisions incur a nonzero
outcome), we derive optimal regret bounds of different orders. Specifically,
with gains, we obtain an optimal regret guarantee after $T$ stages of order
$\sqrt{T\log s}$, so the classical dependency in the dimension is replaced by
the sparsity size. With losses, we provide matching upper and lower bounds of
order $\sqrt{Ts\log(d)/d}$, which is decreasing in $d$. Eventually, we also
study the bandit setting, and obtain an upper bound of order $\sqrt{Ts\log
(d/s)}$ when outcomes are losses. This bound is proven to be optimal up to the
logarithmic factor $\sqrt{\log(d/s)}$.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08407</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Mechanism of Additive Composition</dc:title>
 <dc:creator>Tian, Ran</dc:creator>
 <dc:creator>Okazaki, Naoaki</dc:creator>
 <dc:creator>Inui, Kentaro</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Additive composition (Foltz et al, 1998; Landauer and Dumais, 1997; Mitchell
and Lapata, 2010) is a widely used method for computing meanings of phrases,
which takes the average of vector representations of the constituent words. In
this article, we prove an upper bound for the bias of additive composition,
which is the first theoretical analysis on compositional frameworks from a
machine learning point of view. The bound is written in terms of collocation
strength; we prove that the more exclusively two successive words tend to occur
together, the more accurate one can guarantee their additive composition as an
approximation to the natural phrase vector. Our proof relies on properties of
natural language data that are empirically verified, and can be theoretically
derived from an assumption that the data is generated from a Hierarchical
Pitman-Yor Process. The theory endorses additive composition as a reasonable
operation for calculating meanings of phrases, and suggests ways to improve
additive compositionality, including: transforming entries of distributional
word vectors by a function that meets a specific condition, constructing a
novel type of vector representations to make additive composition sensitive to
word order, and utilizing singular value decomposition to train word vectors.
</dc:description>
 <dc:description>Comment: More explanations on theory and additional experiments added.
  Accepted by Machine Learning Journal</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08407</dc:identifier>
 <dc:identifier>doi:10.1007/s10994-017-5634-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08410</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling of anechoich chambers with equivalent materials and equivalent
  sources</dc:title>
 <dc:creator>Chialina, Silvano</dc:creator>
 <dc:creator>Cicuttin, Matteo</dc:creator>
 <dc:creator>Codecasa, Lorenzo</dc:creator>
 <dc:creator>Solari, Giovanni</dc:creator>
 <dc:creator>Specogna, Ruben</dc:creator>
 <dc:creator>Trevisan, Francesco</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Numerical simulation of anechoic chambers is a hot topic since it can provide
useful data about the performance of the EMC site. However, the mathematical
nature of the problem, the physical dimensions of the simulated sites and the
frequency ranges pose nontrivial challenges to the simulation. Computational
requirements in particular will quickly become unmanageable if adequate
techniques are not employed. In this work we describe a novel approach, based
on equivalent elements, that enables the simulation of large chambers with
modest computational resources. The method is then validated against real
measurement results.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08411</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OntoSeg: a Novel Approach to Text Segmentation using Ontological
  Similarity</dc:title>
 <dc:creator>Bayomi, Mostafa</dc:creator>
 <dc:creator>Levacher, Killian</dc:creator>
 <dc:creator>Ghorab, M. Rami</dc:creator>
 <dc:creator>Lawless, S&#xe9;amus</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Text segmentation (TS) aims at dividing long text into coherent segments
which reflect the subtopic structure of the text. It is beneficial to many
natural language processing tasks, such as Information Retrieval (IR) and
document summarisation. Current approaches to text segmentation are similar in
that they all use word-frequency metrics to measure the similarity between two
regions of text, so that a document is segmented based on the lexical cohesion
between its words. Various NLP tasks are now moving towards the semantic web
and ontologies, such as ontology-based IR systems, to capture the
conceptualizations associated with user needs and contents. Text segmentation
based on lexical cohesion between words is hence not sufficient anymore for
such tasks. This paper proposes OntoSeg, a novel approach to text segmentation
based on the ontological similarity between text blocks. The proposed method
uses ontological similarity to explore conceptual relations between text
segments and a Hierarchical Agglomerative Clustering (HAC) algorithm to
represent the text as a tree-like hierarchy that is conceptually structured.
The rich structure of the created tree further allows the segmentation of text
in a linear fashion at various levels of granularity. The proposed method was
evaluated on a wellknown dataset, and the results show that using ontological
similarity in text segmentation is very promising. Also we enhance the proposed
method by combining ontological similarity with lexical similarity and the
results show an enhancement of the segmentation quality.
</dc:description>
 <dc:description>Comment: 10 pages, IEEE ICDMW 2015 (SENTIRE Workshop)</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08411</dc:identifier>
 <dc:identifier>doi:10.1109/ICDMW.2015.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08412</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond OWL 2 QL in OBDA: Rewritings and Approximations (Extended
  Version)</dc:title>
 <dc:creator>Botoeva, Elena</dc:creator>
 <dc:creator>Calvanese, Diego</dc:creator>
 <dc:creator>Santarelli, Valerio</dc:creator>
 <dc:creator>Savo, Domenico Fabio</dc:creator>
 <dc:creator>Solimando, Alessandro</dc:creator>
 <dc:creator>Xiao, Guohui</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Ontology-based data access (OBDA) is a novel paradigm facilitating access to
relational data, realized by linking data sources to an ontology by means of
declarative mappings. DL-Lite_R, which is the logic underpinning the W3C
ontology language OWL 2 QL and the current language of choice for OBDA, has
been designed with the goal of delegating query answering to the underlying
database engine, and thus is restricted in expressive power. E.g., it does not
allow one to express disjunctive information, and any form of recursion on the
data. The aim of this paper is to overcome these limitations of DL-Lite_R, and
extend OBDA to more expressive ontology languages, while still leveraging the
underlying relational technology for query answering. We achieve this by
relying on two well-known mechanisms, namely conservative rewriting and
approximation, but significantly extend their practical impact by bringing into
the picture the mapping, an essential component of OBDA. Specifically, we
develop techniques to rewrite OBDA specifications with an expressive ontology
to &quot;equivalent&quot; ones with a DL-Lite_R ontology, if possible, and to approximate
them otherwise. We do so by exploiting the high expressive power of the mapping
layer to capture part of the domain semantics of rich ontology languages. We
have implemented our techniques in the prototype system OntoProx, making use of
the state-of-the-art OBDA system Ontop and the query answering system Clipper,
and we have shown their feasibility and effectiveness with experiments on
synthetic and real-world data.
</dc:description>
 <dc:description>Comment: The extended version of the AAAI 2016 paper &quot;Beyond OWL 2 QL in OBDA:
  Rewritings and Approximations&quot; by Elena Botoeva, Diego Calvanese, Valerio
  Santarelli, Domenico Fabio Savo, Alessandro Solimando,and Guohui Xiao</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08413</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Code-Based Cryptosystems Using Generalized Concatenated Codes</dc:title>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>M&#xfc;elich, Sven</dc:creator>
 <dc:creator>Ishak, Karim</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The security of public-key cryptosystems is mostly based on number theoretic
problems like factorization and the discrete logarithm. There exists an
algorithm which solves these problems in polynomial time using a quantum
computer. Hence, these cryptosystems will be broken as soon as quantum
computers emerge. Code-based cryptography is an alternative which resists
quantum computers since its security is based on an NP-complete problem, namely
decoding of random linear codes. The McEliece cryptosystem is the most
prominent scheme to realize code-based cryptography. Many codeclasses were
proposed for the McEliece cryptosystem, but most of them are broken by now.
Sendrier suggested to use ordinary concatenated codes, however, he also
presented an attack on such codes. This work investigates generalized
concatenated codes to be used in the McEliece cryptosystem. We examine the
application of Sendrier's attack on generalized concatenated codes and present
alternative methods for both partly finding the code structure and recovering
the plaintext from a cryptogram. Further, we discuss modifications of the
cryptosystem making it resistant against these attacks.
</dc:description>
 <dc:description>Comment: Submitted to Springer Proceedings in Mathematics &amp; Statistics,
  special issue devoted to the conference Application of Computer Algebra (ACA)
  2015</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08414</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A declarative extension of parsing expression grammars for recognizing
  most programming languages</dc:title>
 <dc:creator>Matsumura, Tetsuro</dc:creator>
 <dc:creator>Kuramitsu, Kimio</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Parsing Expression Grammars are a popular foundation for describing syntax.
Unfortunately, several syntax of programming languages are still hard to
recognize with pure PEGs. Notorious cases appears: typedef-defined names in
C/C++, indentation-based code layout in Python, and HERE document in many
scripting languages. To recognize such PEG-hard syntax, we have addressed a
declarative extension to PEGs. The &quot;declarative&quot; extension means no programmed
semantic actions, which are traditionally used to realize the extended parsing
behavior. Nez is our extended PEG language, including symbol tables and
conditional parsing. This paper demonstrates that the use of Nez Extensions can
realize many practical programming languages, such as C, C\#, Ruby, and Python,
which involve PEG-hard syntax.
</dc:description>
 <dc:description>Comment: To appear in Journal of Information Processing, 24(2), 2016</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08416</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who Can Win a Single-Elimination Tournament?</dc:title>
 <dc:creator>Kim, Michael P.</dc:creator>
 <dc:creator>Suksompong, Warut</dc:creator>
 <dc:creator>Williams, Virginia Vassilevska</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  A single-elimination (SE) tournament is a popular way to select a winner in
both sports competitions and in elections. A natural and well-studied question
is the tournament fixing problem (TFP): given the set of all pairwise match
outcomes, can a tournament organizer rig an SE tournament by adjusting the
initial seeding so that their favorite player wins? We prove new sufficient
conditions on the pairwise match outcome information and the favorite player,
under which there is guaranteed to be a seeding where the player wins the
tournament. Our results greatly generalize previous results. We also
investigate the relationship between the set of players that can win an SE
tournament under some seeding (so called SE winners) and other traditional
tournament solutions. In addition, we generalize and strengthen prior work on
probabilistic models for generating tournaments. For instance, we show that
\emph{every} player in an $n$ player tournament generated by the Condorcet
Random Model will be an SE winner even when the noise is as small as possible,
$p=\Theta(\ln n/n)$; prior work only had such results for $p\geq
\Omega(\sqrt{\ln n/n})$. We also establish new results for significantly more
general generative models.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in Proceedings of the 30th AAAI
  Conference on Artificial Intelligence (AAAI), 2016</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08416</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 31(3): 1751-1764 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08417</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TGSum: Build Tweet Guided Multi-Document Summarization Dataset</dc:title>
 <dc:creator>Cao, Ziqiang</dc:creator>
 <dc:creator>Chen, Chengyao</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:creator>Li, Sujian</dc:creator>
 <dc:creator>Wei, Furu</dc:creator>
 <dc:creator>Zhou, Ming</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The development of summarization research has been significantly hampered by
the costly acquisition of reference summaries. This paper proposes an effective
way to automatically collect large scales of news-related multi-document
summaries with reference to social media's reactions. We utilize two types of
social labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to
cluster documents into different topic sets. Also, a tweet with a hyper-link
often highlights certain key points of the corresponding document. We
synthesize a linked document cluster to form a reference summary which can
cover most key points. To this aim, we adopt the ROUGE metrics to measure the
coverage ratio, and develop an Integer Linear Programming solution to discover
the sentence set reaching the upper bound of ROUGE. Since we allow summary
sentences to be selected from both documents and high-quality tweets, the
generated reference summaries could be abstractive. Both informativeness and
readability of the collected summaries are verified by manual judgment. In
addition, we train a Support Vector Regression summarizer on DUC generic
multi-document summarization benchmarks. With the collected data as extra
training resource, the performance of the summarizer improves a lot on all the
test sets. We release this dataset for further research.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure in AAAI 2016</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08418</identifier>
 <datestamp>2016-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Computational Model for Amodal Completion</dc:title>
 <dc:creator>Oliver, Maria</dc:creator>
 <dc:creator>Haro, Gloria</dc:creator>
 <dc:creator>Dimiccoli, Mariella</dc:creator>
 <dc:creator>Mazin, Baptiste</dc:creator>
 <dc:creator>Ballester, Coloma</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a computational model to recover the most likely
interpretation of the 3D scene structure from a planar image, where some
objects may occlude others. The estimated scene interpretation is obtained by
integrating some global and local cues and provides both the complete
disoccluded objects that form the scene and their ordering according to depth.
Our method first computes several distal scenes which are compatible with the
proximal planar image. To compute these different hypothesized scenes, we
propose a perceptually inspired object disocclusion method, which works by
minimizing the Euler's elastica as well as by incorporating the relatability of
partially occluded contours and the convexity of the disoccluded objects. Then,
to estimate the preferred scene we rely on a Bayesian model and define
probabilities taking into account the global complexity of the objects in the
hypothesized scenes as well as the effort of bringing these objects in their
relative position in the planar image, which is also measured by an Euler's
elastica-based quantity. The model is illustrated with numerical experiments
on, both, synthetic and real images showing the ability of our model to
reconstruct the occluded objects and the preferred perceptual order among them.
We also present results on images of the Berkeley dataset with provided
figure-ground ground-truth labeling.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08418</dc:identifier>
 <dc:identifier>doi:10.1007/s10851-016-0652-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08431</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Greedy Algorithm for the Shortest Common Superstring Problem with
  Reversals</dc:title>
 <dc:creator>Fici, Gabriele</dc:creator>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:creator>Radoszewski, Jakub</dc:creator>
 <dc:creator>Rytter, Wojciech</dc:creator>
 <dc:creator>Wale&#x144;, Tomasz</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study a variation of the classical Shortest Common Superstring (SCS)
problem in which a shortest superstring of a finite set of strings $S$ is
sought containing as a factor every string of $S$ or its reversal. We call this
problem Shortest Common Superstring with Reversals (SCS-R). This problem has
been introduced by Jiang et al., who designed a greedy-like algorithm with
length approximation ratio $4$. In this paper, we show that a natural
adaptation of the classical greedy algorithm for SCS has (optimal) compression
ratio $\frac12$, i.e., the sum of the overlaps in the output string is at least
half the sum of the overlaps in an optimal solution. We also provide a
linear-time implementation of our algorithm.
</dc:description>
 <dc:description>Comment: Published in Information Processing Letters</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08431</dc:identifier>
 <dc:identifier>doi:10.1016/j.ipl.2015.11.015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08435</identifier>
 <datestamp>2016-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Typical sumsets of linear codes</dc:title>
 <dc:creator>Zhu, Jingge</dc:creator>
 <dc:creator>Gastpar, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Given two identical linear codes $\mathcal C$ over $\mathbb F_q$ of length
$n$, we independently pick one codeword from each codebook uniformly at random.
A $\textit{sumset}$ is formed by adding these two codewords entry-wise as
integer vectors and a sumset is called $\textit{typical}$, if the sum falls
inside this set with high probability. We ask the question: how large is the
typical sumset for most codes? In this paper we characterize the asymptotic
size of such typical sumset. We show that when the rate $R$ of the linear code
is below a certain threshold $D$, the typical sumset size is roughly $|\mathcal
C|^2=2^{2nR}$ for most codes while when $R$ is above this threshold, most codes
have a typical sumset whose size is roughly $|\mathcal C|\cdot
2^{nD}=2^{n(R+D)}$ due to the linear structure of the codes. The threshold $D$
depends solely on the alphabet size $q$ and takes value in $[1/2, \log
\sqrt{e})$. More generally, we completely characterize the asymptotic size of
typical sumsets of two nested linear codes $\mathcal C_1, \mathcal C_2$ with
different rates. As an application of the result, we study the communication
problem where the integer sum of two codewords is to be decoded through a
general two-user multiple-access channel.
</dc:description>
 <dc:description>Comment: 32 pages, 5 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08446</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Automatic Image Editing: Learning to See another You</dc:title>
 <dc:creator>Ghodrati, Amir</dc:creator>
 <dc:creator>Jia, Xu</dc:creator>
 <dc:creator>Pedersoli, Marco</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning the distribution of images in order to generate new samples is a
challenging task due to the high dimensionality of the data and the highly
non-linear relations that are involved. Nevertheless, some promising results
have been reported in the literature recently,building on deep network
architectures. In this work, we zoom in on a specific type of image generation:
given an image and knowing the category of objects it belongs to (e.g. faces),
our goal is to generate a similar and plausible image, but with some altered
attributes. This is particularly challenging, as the model needs to learn to
disentangle the effect of each attribute and to apply a desired attribute
change to a given input image, while keeping the other attributes and overall
object appearance intact. To this end, we learn a convolutional network, where
the desired attribute information is encoded then merged with the encoded image
at feature map level. We show promising results, both qualitatively as well as
quantitatively, in the context of a retrieval experiment, on two face datasets
(MultiPie and CAS-PEAL-R1).
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08447</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decidability and Complexity for Quiescent Consistency and its Variations</dc:title>
 <dc:creator>Dongol, Brijesh</dc:creator>
 <dc:creator>Hierons, Robert M.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  Quiescent consistency is a notion of correctness for a concurrent object that
gives meaning to the object's behaviours in quiescent states, i.e., states in
which none of the object's operations are being executed. Correctness of an
implementation object is defined in terms of a corresponding abstract
specification. This gives rise to two important verification questions:
membership (checking whether a behaviour of the implementation is allowed by
the specification) and correctness (checking whether all behaviours of the
implementation are allowed by the specification). In this paper, we show that
the membership problem for quiescent consistency is NP-complete and that the
correctness problem is decidable, but coNP-hard and in EXPSPACE. For both
problems, we consider restricted versions of quiescent consistency by assuming
an upper limit on the number of events between two quiescent points. Here, we
show that the membership problem is in PTIME, whereas correctness is in PSPACE.
  Quiescent consistency does not guarantee sequential consistency, i.e., it
allows operation calls by the same process to be reordered when mapping to an
abstract specification. Therefore, we also consider quiescent sequential
consistency, which strengthens quiescent consistency with an additional
sequential consistency condition. We show that the unrestricted versions of
membership and correctness are NP-complete and undecidable, respectively. When
by placing a limit on the number of events between two quiescent points,
membership is in PTIME, while correctness is in PSPACE. Finally, we consider a
version of quiescent sequential consistency that places an upper limit on the
number of processes for every run of the implementation, and show that the
membership problem for quiescent sequential consistency with this restriction
is in PTIME.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08456</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Symbolic SAT-based Algorithm for Almost-sure Reachability with Small
  Strategies in POMDPs</dc:title>
 <dc:creator>Chatterjee, Krishnendu</dc:creator>
 <dc:creator>Chmelik, Martin</dc:creator>
 <dc:creator>Davies, Jessica</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  POMDPs are standard models for probabilistic planning problems, where an
agent interacts with an uncertain environment. We study the problem of
almost-sure reachability, where given a set of target states, the question is
to decide whether there is a policy to ensure that the target set is reached
with probability 1 (almost-surely). While in general the problem is
EXPTIME-complete, in many practical cases policies with a small amount of
memory suffice. Moreover, the existing solution to the problem is explicit,
which first requires to construct explicitly an exponential reduction to a
belief-support MDP. In this work, we first study the existence of
observation-stationary strategies, which is NP-complete, and then small-memory
strategies. We present a symbolic algorithm by an efficient encoding to SAT and
using a SAT solver for the problem. We report experimental results
demonstrating the scalability of our symbolic (SAT-based) approach.
</dc:description>
 <dc:description>Comment: Full version of &quot;A Symbolic SAT-based Algorithm for Almost-sure
  Reachability with Small Strategies in POMDPs&quot; AAAI 2016</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08458</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Introduction to Convolutional Neural Networks</dc:title>
 <dc:creator>O'Shea, Keiron</dc:creator>
 <dc:creator>Nash, Ryan</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The field of machine learning has taken a dramatic twist in recent times,
with the rise of the Artificial Neural Network (ANN). These biologically
inspired computational models are able to far exceed the performance of
previous forms of artificial intelligence in common machine learning tasks. One
of the most impressive forms of ANN architecture is that of the Convolutional
Neural Network (CNN). CNNs are primarily used to solve difficult image-driven
pattern recognition tasks and with their precise yet simple architecture,
offers a simplified method of getting started with ANNs.
  This document provides a brief introduction to CNNs, discussing recently
published papers and newly formed techniques in developing these brilliantly
fantastic image recognition models. This introduction assumes you are familiar
with the fundamentals of ANNs and machine learning.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2015-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08464</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual World, Defined from a Technological Perspective, and Applied to
  Video Games, Mixed Reality and the Metaverse</dc:title>
 <dc:creator>Nevelsteen, Kim J. L.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There is no generally accepted definition for a virtual world, with many
complimentary terms and acronyms having emerged implying a virtual world.
Advances in systems architecture techniques such as, host migration of
instances, mobile ad-hoc networking, and distributed computing, bring in to
question whether those architectures can actually support a virtual world.
Without a concrete definition, controversy ensues and it is problematic to
design an architecture for a virtual world. Several researchers provided a
definition but aspects of each definition are still problematic and simply can
not be applied to contemporary technologies. The approach of this article is to
sample technologies using grounded theory, and obtain a definition for a
`virtual world' that is directly applicable to technology. The obtained
definition is compared with related work and used to classify advanced
technologies, such as: a pseudo-persistent video game, a MANet, virtual and
mixed reality, and the Metaverse. The results of this article include: a break
down of which properties set apart the various technologies; a definition that
is validated by comparing it with other definitions; an ontology showing the
relation of the different complimentary terms and acronyms; and, the usage of
pseudo-persistence to categories those technologies which only mimic
persistence.
</dc:description>
 <dc:description>Comment: 36 pages, 2 figures</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08464</dc:identifier>
 <dc:identifier>doi:10.1002/cav.1752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08474</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Characterization of Feasible Interference Regions in Cognitive Radio
  Networks</dc:title>
 <dc:creator>Monemi, Mehdi</dc:creator>
 <dc:creator>Rasti, Mehdi</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the state-of-the-art interference management schemes for underlay CRNs, it
is considered that all PUs are protected if the cognitive interference for each
primary receiving-point is lower than a maximum threshold, the so called
interference temperature limit (ITL) for the corresponding receiving-point.
This is assumed to be fixed and independent of ITL values for other primary
receiving-points, which corresponds to a box-like FCIR. In this paper, we
characterize the FCIR for {\em uplink} transmissions in cellular CRNs and for
direct transmissions in ad-hoc CRNs. We show that the FCIR is in fact a
polyhedron (i.e., the maximum feasible cognitive interference threshold for
each primary receiving-point is not a constant, and it depends on that for the
other primary receiving-points). Therefore, in practical interference
management algorithms, it is not proper to consider a constant and independent
ITL value for each of the primary receiving-points. This finding would
significantly affect the design of practical interference management schemes
for CRNs. To demonstrate this, based on the characterized FCIR, we propose two
power control algorithms to find the maximum number of admitted SUs and the
maximum aggregate throughput of the SUs in infeasible and feasible CRNs,
respectively. For two distinct objectives, our proposed interference management
schemes outperform the existing ones.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Communications, under review</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08474</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2015.2514093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08476</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity SINR Feasibility Checking and Joint Power and Admission
  Control in Prioritized Multi-tier Cellular Networks</dc:title>
 <dc:creator>Monemi, Mehdi</dc:creator>
 <dc:creator>Rasti, Mehdi</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Next generation cellular networks will consist of multiple tiers of cells and
users associated with different network tiers may have different priorities
(e.g., macrocell-picocell-femtocell networks with macro tier prioritized over
pico tier, which is again prioritized over femto tier). Designing efficient
joint power and admission control (JPAC) algorithms for such networks under a
co-channel deployment (i.e., underlay) scenario is of significant importance.
Feasibility checking of a given target signal-to-noise-plus-interference ratio
(SINR) vector is generally the most significant contributor to the complexity
of JPAC algorithms in single/multi-tier underlay cellular networks. This is
generally accomplished through iterative strategies whose complexity is either
unpredictable or of O(M^3), when the well-known relationship between the SINR
vector and the power vector is used, where $M$ is the number of users/links. In
this paper, we derive a novel relationship between a given SINR vector and its
corresponding uplink/downlink power vector based on which the feasibility
checking can be performed with a complexity of O(B^3+M B), where B is the
number of base stations. This is significantly less compared to O(M^3) in many
cellular wireless networks since the number of base stations is generally much
lower than the number of users/links in such networks. The developed novel
relationship between the SINR and power vector not only substantially reduces
the complexity of designing JPAC algorithms, but also provides insights into
developing efficient but low-complexity power update strategies for prioritized
multi-tier cellular networks. We propose two such algorithms and through
simulations, we show that our proposed algorithms outperform the existing ones
in prioritized cellular networks.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Wireless Communications, to appear</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08478</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An analysis of the factors affecting keypoint stability in scale-space</dc:title>
 <dc:creator>Rey-Otero, Ives</dc:creator>
 <dc:creator>Morel, Jean-Michel</dc:creator>
 <dc:creator>Delbracio, Mauricio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The most popular image matching algorithm SIFT, introduced by D. Lowe a
decade ago, has proven to be sufficiently scale invariant to be used in
numerous applications. In practice, however, scale invariance may be weakened
by various sources of error inherent to the SIFT implementation affecting the
stability and accuracy of keypoint detection. The density of the sampling of
the Gaussian scale-space and the level of blur in the input image are two of
these sources. This article presents a numerical analysis of their impact on
the extracted keypoints stability. Such an analysis has both methodological and
practical implications, on how to compare feature detectors and on how to
improve SIFT. We show that even with a significantly oversampled scale-space
numerical errors prevent from achieving perfect stability. Usual strategies to
filter out unstable detections are shown to be inefficient. We also prove that
the effect of the error in the assumption on the initial blur is asymmetric and
that the method is strongly degraded in presence of aliasing or without a
correct assumption on the camera blur.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08486</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Machine Learning via Sufficient Factor Broadcasting</dc:title>
 <dc:creator>Xie, Pengtao</dc:creator>
 <dc:creator>Kim, Jin Kyu</dc:creator>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Ho, Qirong</dc:creator>
 <dc:creator>Kumar, Abhimanu</dc:creator>
 <dc:creator>Yu, Yaoliang</dc:creator>
 <dc:creator>Xing, Eric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Matrix-parametrized models, including multiclass logistic regression and
sparse coding, are used in machine learning (ML) applications ranging from
computer vision to computational biology. When these models are applied to
large-scale ML problems starting at millions of samples and tens of thousands
of classes, their parameter matrix can grow at an unexpected rate, resulting in
high parameter synchronization costs that greatly slow down distributed
learning. To address this issue, we propose a Sufficient Factor Broadcasting
(SFB) computation model for efficient distributed learning of a large family of
matrix-parameterized models, which share the following property: the parameter
update computed on each data sample is a rank-1 matrix, i.e., the outer product
of two &quot;sufficient factors&quot; (SFs). By broadcasting the SFs among worker
machines and reconstructing the update matrices locally at each worker, SFB
improves communication efficiency --- communication costs are linear in the
parameter matrix's dimensions, rather than quadratic --- without affecting
computational correctness. We present a theoretical convergence analysis of
SFB, and empirically corroborate its efficiency on four different
matrix-parametrized ML models.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08488</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Network Models for Adaptive Testing</dc:title>
 <dc:creator>Plajner, Martin</dc:creator>
 <dc:creator>Vomlel, Ji&#x159;&#xed;</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Computerized adaptive testing (CAT) is an interesting and promising approach
to testing human abilities. In our research we use Bayesian networks to create
a model of tested humans. We collected data from paper tests performed with
grammar school students. In this article we first provide the summary of data
used for our experiments. We propose several different Bayesian networks, which
we tested and compared by cross-validation. Interesting results were obtained
and are discussed in the paper. The analysis has brought a clearer view on the
model selection problem. Future research is outlined in the concluding part of
the paper.
</dc:description>
 <dc:description>Comment: 12th Annual Bayesian Modelling Applications Workshop, Amsterdam,
  Netherlands, (July 2015). 10 pages</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08488</dc:identifier>
 <dc:identifier>Proc. of the Eighth International Conference on Probabilistic
  Graphical Models (JMLR), 2016, pages 403-414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08494</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Mathematical Model for Signal's Energy at the Output of an Ideal DAC</dc:title>
 <dc:creator>Loreti, Paola</dc:creator>
 <dc:creator>Vellucci, Pierluigi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The presented research work considers a mathematical model for energy of the
signal at the output of an ideal DAC, in presence of sampling clock jitter.
When sampling clock jitter occurs, the energy of the signal at the output of
ideal DAC does not satisfies a Parseval identity. Nevertheless, an estimation
of the signal energy is here shown by a direct method involving sinc functions.
</dc:description>
 <dc:date>2015-11-26</dc:date>
 <dc:date>2016-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1511.08494</dc:identifier>
 <dc:identifier>Proceedings of 13-th International Conference on Informatics in
  Control, Automation and Robotics, (2016), p. 347-352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="87000" completeListSize="155308">2369777|88001</resumptionToken>
</ListRecords>
</OAI-PMH>
