<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:31:21Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|124001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05494</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data clustering with edge domination in complex networks</dc:title>
 <dc:creator>Urio, Paulo Roberto</dc:creator>
 <dc:creator>Liang, Zhao</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This paper presents a model for a dynamical system where particles dominate
edges in a complex network. The proposed dynamical system is then extended to
an application on the problem of community detection and data clustering. In
the case of the data clustering problem, 6 different techniques were simulated
on 10 different datasets in order to compare with the proposed technique. The
results show that the proposed algorithm performs well when prior knowledge of
the number of clusters is known to the algorithm.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05495</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian Filtering Algorithm for Gaussian Mixture Models</dc:title>
 <dc:creator>Wills, Adrian G.</dc:creator>
 <dc:creator>Hendriks, Johannes</dc:creator>
 <dc:creator>Renton, Christopher</dc:creator>
 <dc:creator>Ninness, Brett</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A Bayesian filtering algorithm is developed for a class of state-space
systems that can be modelled via Gaussian mixtures. In general, the exact
solution to this filtering problem involves an exponential growth in the number
of mixture terms and this is handled here by utilising a Gaussian mixture
reduction step after both the time and measurement updates. In addition, a
square-root implementation of the unified algorithm is presented and this
algorithm is profiled on several simulated systems. This includes the state
estimation for two non-linear systems that are strictly outside the class
considered in this paper.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05497</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partitioned List Decoding of Polar Codes: Analysis and Improvement of
  Finite Length Performance</dc:title>
 <dc:creator>Hashemi, Seyyed Ali</dc:creator>
 <dc:creator>Mondelli, Marco</dc:creator>
 <dc:creator>Hassani, S. Hamed</dc:creator>
 <dc:creator>Urbanke, Rudiger</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar codes represent one of the major recent breakthroughs in coding theory
and, because of their attractive features, they have been selected for the
incoming 5G standard. As such, a lot of attention has been devoted to the
development of decoding algorithms with good error performance and efficient
hardware implementation. One of the leading candidates in this regard is
represented by successive-cancellation list (SCL) decoding. However, its
hardware implementation requires a large amount of memory. Recently, a
partitioned SCL (PSCL) decoder has been proposed to significantly reduce the
memory consumption. In this paper, we examine the paradigm of PSCL decoding
from both theoretical and practical standpoints: (i) by changing the
construction of the code, we are able to improve the performance at no
additional computational, latency or memory cost, (ii) we present an optimal
scheme to allocate cyclic redundancy checks (CRCs), and (iii) we provide an
upper bound on the list size that allows MAP performance.
</dc:description>
 <dc:description>Comment: 2017 IEEE Global Communications Conference (GLOBECOM)</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05497</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05498</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Geometrical and Statistical Alignment for Visual Domain Adaptation</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:creator>Ogunbona, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel unsupervised domain adaptation method for
cross-domain visual recognition. We propose a unified framework that reduces
the shift between domains both statistically and geometrically, referred to as
Joint Geometrical and Statistical Alignment (JGSA). Specifically, we learn two
coupled projections that project the source domain and target domain data into
low dimensional subspaces where the geometrical shift and distribution shift
are reduced simultaneously. The objective function can be solved efficiently in
a closed form. Extensive experiments have verified that the proposed method
significantly outperforms several state-of-the-art domain adaptation methods on
a synthetic dataset and three different real world cross-domain visual
recognition tasks.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05500</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Signal Minus Interference to Noise Ratio Multiuser Receive
  Beamforming</dc:title>
 <dc:creator>Bavand, Majid</dc:creator>
 <dc:creator>Blostein, Steven D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by massive deployment of low data rate Internet of things (IoT) and
ehealth devices with requirement for highly reliable communications, this paper
proposes receive beamforming techniques for the uplink of a single-input
multiple-output (SIMO) multiple access channel (MAC), based on a per-user
probability of error metric and one-dimensional signalling. Although
beamforming by directly minimizing probability of error (MPE) has potential
advantages over classical beamforming methods such as zero-forcing and minimum
mean square error beamforming, MPE beamforming results in a non-convex and a
highly nonlinear optimization problem. In this paper, by adding a set of
modulation-based constraints, the MPE beamforming problem is transformed into a
convex programming problem. Then, a simplified version of the MPE beamforming
is proposed which reduces the exponential number of constraints in the MPE
beamforming problem. The simplified problem is also shown to be a convex
programming problem. The complexity of the simplified problem is further
reduced by minimizing a convex function which serves as an upper bound on the
error probability. Minimization of this upper bound results in the introduction
of a new metric, which is termed signal minus interference to noise ratio
(SMINR). It is shown that maximizing SMINR leads to a closed-form expression
for beamforming vectors as well as improved performance over existing
beamforming methods.
</dc:description>
 <dc:description>Comment: Part of this work was presented at 27th Biennial Symposium on
  Communications, ON, June 2014, and was the runner-up for the best student
  paper award</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05501</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Service Virtualisation of Internet-of-Things Devices: Techniques and
  Challenges</dc:title>
 <dc:creator>Farahmandpour, Zeinab</dc:creator>
 <dc:creator>Versteeg, Steve</dc:creator>
 <dc:creator>Kameswaran, Anand</dc:creator>
 <dc:creator>Han, Jun</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>K.6.3</dc:subject>
 <dc:description>  Service virtualization is an approach that uses virtualized environments to
automatically test enterprise services in production-like conditions. Many
techniques have been proposed to provide such a realistic environment for
enterprise services. The Internet-of-Things (IoT) is an emerging field which
connects a diverse set of devices over different transport layers, using a
variety of protocols. Provisioning a virtual testbed of IoT devices can
accelerate IoT application development by enabling automated testing without
requiring a continuous connection to the physical devices. One solution is to
expand existing enterprise service virtualization to IoT environments. There
are various structural differences between the two environments that should be
considered to implement appropriate service virtualization for IoT. This paper
examines the structural differences between various IoT protocols and
enterprise protocols and identifies key technical challenges that need to be
addressed to implement service virtualization in IoT environments.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05501</dc:identifier>
 <dc:identifier>In Proceedings of ACM/IEEE 3rd International Workshop on Rapid
  Continuous Software Engineering, (RCoSE2017), Argentina, May 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05502</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The power of deeper networks for expressing natural functions</dc:title>
 <dc:creator>Rolnick, David</dc:creator>
 <dc:creator>Tegmark, Max</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is well-known that neural networks are universal approximators, but that
deeper networks tend to be much more efficient than shallow ones. We shed light
on this by proving that the total number of neurons $m$ required to approximate
natural classes of multivariate polynomials of $n$ variables grows only
linearly with $n$ for deep neural networks, but grows exponentially when merely
a single hidden layer is allowed. We also provide evidence that when the number
of hidden layers is increased from $1$ to $k$, the neuron requirement grows
exponentially not with $n$ but with $n^{1/k}$, suggesting that the minimum
number of layers required for computational tractability grows only
logarithmically with $n$.
</dc:description>
 <dc:description>Comment: 9 pages, 2 figs</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05508</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Body Structure Extraction from Arbitrary 3D Mesh</dc:title>
 <dc:creator>Khoo, Yong</dc:creator>
 <dc:creator>Chung, Sang</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an automated method for 3D character skeleton extraction
that can be applied for generic 3D shapes. Our work is motivated by the
skeleton-based prior work on automatic rigging focused on skeleton extraction
and can automatically aligns the extracted structure to fit the 3D shape of the
given 3D mesh. The body mesh can be subsequently skinned based on the extracted
skeleton and thus enables rigging process. In the experiment, we apply public
dataset to drive the estimated skeleton from different body shapes, as well as
the real data obtained from 3D scanning systems. Satisfactory results are
obtained compared to the existing approaches.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05508</dc:identifier>
 <dc:identifier>Imaging and Graphics, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05509</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New quaternary sequences of even length with optimal auto-correlation</dc:title>
 <dc:creator>Su, W</dc:creator>
 <dc:creator>Yang, Y</dc:creator>
 <dc:creator>Zhou, Z</dc:creator>
 <dc:creator>Tang, X</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Sequences with low auto-correlation property have been applied in
code-division multiple access communication systems, radar and cryptography.
Using the inverse Gray mapping, a quaternary sequence of even length $N$ can be
obtained from two binary sequences of the same length, which are called
component sequences. In this paper, using interleaving method, we present
several classes of component sequences from twin-prime sequences pairs or GMW
sequences pairs given by Tang and Ding in 2010; two, three or four binary
sequences defined by cyclotomic classes of order $4$. Hence we can obtain new
classes of quaternary sequences, which are different from known ones, since
known component sequences are constructed from a pair of binary sequences with
optimal auto-correlation or Sidel'nikov sequences.
</dc:description>
 <dc:description>Comment: This paper was submitted to Science China: Information Sciences at
  Oct 16, 2016, and accpted for publication at Apr 27, 2017</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05510</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Antimatroids Induced by Matchings</dc:title>
 <dc:creator>Kawase, Yasushi</dc:creator>
 <dc:creator>Yamaguchi, Yutaro</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  An antimatroid is a combinatorial structure abstracting the convexity in
geometry. In this paper, we explore novel connections between antimatroids and
matchings in a bipartite graph. In particular, we prove that a combinatorial
structure induced by stable matchings or maximum-weight matchings is an
antimatroid. Moreover, we demonstrate that every antimatroid admits such a
representation by stable matchings and maximum-weight matchings.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05512</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Learning with Visual Attributes</dc:title>
 <dc:creator>Batra, Tanmay</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning paradigms involving varying levels of supervision have received a
lot of interest within the computer vision and machine learning communities.
The supervisory information is typically considered to come from a human
supervisor -- a &quot;teacher&quot; figure. In this paper, we consider an alternate
source of supervision -- a &quot;peer&quot; -- i.e. a different machine. We introduce
cooperative learning, where two agents trying to learn the same visual
concepts, but in potentially different environments using different sources of
data (sensors), communicate their current knowledge of these concepts to each
other. Given the distinct sources of data in both agents, the mode of
communication between the two agents is not obvious. We propose the use of
visual attributes -- semantic mid-level visual properties such as furry,
wooden, etc.-- as the mode of communication between the agents. Our experiments
in three domains -- objects, scenes, and animals -- demonstrate that our
proposed cooperative learning approach improves the performance of both agents
as compared to their performance if they were to learn in isolation. Our
approach is particularly applicable in scenarios where privacy, security and/or
bandwidth constraints restrict the amount and type of information the two
agents can exchange.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05514</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concolic Execution as a General Method of Determining Local Malware
  Signatures</dc:title>
 <dc:creator>Alston, Aubrey</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A commonly shared component of antivirus suites is a local database of
malware signatures that is used during the static analysis process. Despite
possible encryption, heuristic obfuscation, or attempts to hide this database
from malicious end-users (or competitors), a currently avoidable eventuality
for offline static analysis is a need to use the contents of the database in
local computation to detect malicious files. This work serves as a preliminary
exploration of the use of concolic execution as a general-case technique for
reverse-engineering malware signature database contents: indeed, the existence
of a practical technique to such an end would certainly require the use of true
(in the sense of provable security) obfuscation in order for malware databases
to remain private against capable attackers--a major obstacle given the
scarcity of truly practical secure obfuscation constructions. Our work,
however, only shows that existing tools (at the time of this report) for
concolic execution have severe limitations which prevent the realization of
this strategy.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05515</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Method for Determining Weights of Criterias and Alternative of Fuzzy
  Group Decision Making Problem</dc:title>
 <dc:creator>JaeGyong, Jon</dc:creator>
 <dc:creator>JongHui, Mun</dc:creator>
 <dc:creator>GyongIl, Ryang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we constructed a model to determine weights of criterias and
presented a solution for determining the optimal alternative by using the
constructed model and relationship analysis between criterias in fuzzy group
decision-making problem with different forms of preference information of
decision makers on criterias.
</dc:description>
 <dc:description>Comment: 12 pages, 3 tables</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05524</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Hard Alignments with Variational Inference</dc:title>
 <dc:creator>Lawson, Dieterich</dc:creator>
 <dc:creator>Chiu, Chung-Cheng</dc:creator>
 <dc:creator>Tucker, George</dc:creator>
 <dc:creator>Raffel, Colin</dc:creator>
 <dc:creator>Swersky, Kevin</dc:creator>
 <dc:creator>Jaitly, Navdeep</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There has recently been significant interest in hard attention models for
tasks such as object recognition, visual captioning and speech recognition.
Hard attention can offer benefits over soft attention such as decreased
computational cost, but training hard attention models can be difficult because
of the discrete latent variables they introduce. Previous work used REINFORCE
and Q-learning to approach these issues, but those methods can provide
high-variance gradient estimates and be slow to train. In this paper, we tackle
the problem of learning hard attention for a sequential task using variational
inference methods, specifically the recently introduced VIMCO and NVIL.
Furthermore, we propose a novel baseline that adapts VIMCO to this setting. We
demonstrate our method on a phoneme recognition task in clean and noisy
environments and show that our method outperforms REINFORCE, with the
difference being greater for a more complicated task.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05528</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Short Codes with Mismatched Channel State Information: A Case Study</dc:title>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Chiani, Marco</dc:creator>
 <dc:creator>Ullah, Shakeel Salamat</dc:creator>
 <dc:creator>Liew, Soung Chang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The rising interest in applications requiring the transmission of small
amounts of data has recently lead to the development of accurate performance
bounds and of powerful channel codes for the transmission of short-data packets
over the AWGN channel. Much less is known about the interaction between error
control coding and channel estimation at short blocks when transmitting over
channels with states (e.g., fading channels, phase-noise channels, etc...) for
the setup where no a priori channel state information (CSI) is available at the
transmitter and the receiver. In this paper, we use the mismatched-decoding
framework to characterize the fundamental tradeoff occurring in the
transmission of short data packet over an AWGN channel with unknown gain that
stays constant over the packet. Our analysis for this simplified setup aims at
showing the potential of mismatched decoding as a tool to design and analyze
transmission strategies for short blocks. We focus on a pragmatic approach
where the transmission frame contains a codeword as well as a preamble that is
used to estimate the channel (the codeword symbols are not used for channel
estimation). Achievability and converse bounds on the block error probability
achievable by this approach are provided and compared with simulation results
for schemes employing short low-density parity-check codes. Our bounds turn out
to predict accurately the optimal trade-off between the preamble length and the
redundancy introduced by the channel code.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, to appear in Proceedings of the IEEE
  International Workshop on Signal Processing Advances in Wireless
  Communications (SPAWC 2017)</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05541</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithm-Directed Crash Consistence in Non-Volatile Memory for HPC</dc:title>
 <dc:creator>Yang, Shuo</dc:creator>
 <dc:creator>Wu, Kai</dc:creator>
 <dc:creator>Qiao, Yifan</dc:creator>
 <dc:creator>Li, Dong</dc:creator>
 <dc:creator>Zhai, Jidong</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Fault tolerance is one of the major design goals for HPC. The emergence of
non-volatile memories (NVM) provides a solution to build fault tolerant HPC.
Data in NVM-based main memory are not lost when the system crashes because of
the non-volatility nature of NVM. However, because of volatile caches, data
must be logged and explicitly flushed from caches into NVM to ensure
consistence and correctness before crashes, which can cause large runtime
overhead.
  In this paper, we introduce an algorithm-based method to establish crash
consistence in NVM for HPC applications. We slightly extend application data
structures or sparsely flush cache blocks, which introduce ignorable runtime
overhead. Such extension or cache flushing allows us to use algorithm knowledge
to \textit{reason} data consistence or correct inconsistent data when the
application crashes. We demonstrate the effectiveness of our method for three
algorithms, including an iterative solver, dense matrix multiplication, and
Monte-Carlo simulation. Based on comprehensive performance evaluation on a
variety of test environments, we demonstrate that our approach has very small
runtime overhead (at most 8.2\% and less than 3\% in most cases), much smaller
than that of traditional checkpoint, while having the same or less
recomputation cost.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05546</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Through a Gender Lens: An Empirical Study of Emoji Usage over
  Large-Scale Android Users</dc:title>
 <dc:creator>Chen, Zhenpeng</dc:creator>
 <dc:creator>Lu, Xuan</dc:creator>
 <dc:creator>Shen, Sheng</dc:creator>
 <dc:creator>Ai, Wei</dc:creator>
 <dc:creator>Liu, Xuanzhe</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Emojis have gained incredible popularity in recent years and become a new
ubiquitous language for Computer-Mediated Communication (CMC) by worldwide
users. Various research efforts have been made to understand the behaviors of
using emojis. Gender-specific study is always meaningful for HCI community,
however, so far we know very little about whether and how much males and
females vary in emoji usage. To bridge such a knowledge gap, this paper makes
the first effort to explore the emoji usage through a gender lens. Our analysis
is based on the largest data set to date, which covers 134,419 users from 183
countries, along with their over 401 million messages collected in three
months. We conduct a multi-dimensional statistical analysis from various
aspects of emoji usage, including the frequency, preferences, input patterns,
public/private CMC-scenario patterns, temporal patterns, and sentiment
patterns. The results demonstrate that emoji usage can significantly vary
between males and females. Accordingly, we propose some implications that can
raise useful insights to HCI community.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05548</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intel RealSense Stereoscopic Depth Cameras</dc:title>
 <dc:creator>Keselman, Leonid</dc:creator>
 <dc:creator>Woodfill, John Iselin</dc:creator>
 <dc:creator>Grunnet-Jepsen, Anders</dc:creator>
 <dc:creator>Bhowmik, Achintya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  We present a comprehensive overview of the stereoscopic Intel RealSense RGBD
imaging systems. We discuss these systems' mode-of-operation, functional
behavior and include models of their expected performance, shortcomings, and
limitations. We provide information about the systems' optical characteristics,
their correlation algorithms, and how these properties can affect different
applications, including 3D reconstruction and gesture recognition. Our
discussion covers the Intel RealSense R200 and the Intel RealSense D400
(formally RS400).
</dc:description>
 <dc:description>Comment: Accepted to CCD 2017, a CVPR 2017 Workshop</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05551</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Reinforcement Learning Using a Chaotic Neural Network for Emergence
  of &quot;Thinking&quot; - &quot;Exploration&quot; Grows into &quot;Thinking&quot; through Learning -</dc:title>
 <dc:creator>Shibata, Katsunari</dc:creator>
 <dc:creator>Goto, Yuki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Expectation for the emergence of higher functions is getting larger in the
framework of end-to-end reinforcement learning using a recurrent neural
network. However, the emergence of &quot;thinking&quot; that is a typical higher function
is difficult to realize because &quot;thinking&quot; needs non fixed-point, flow-type
attractors with both convergence and transition dynamics. Furthermore, in order
to introduce &quot;inspiration&quot; or &quot;discovery&quot; in &quot;thinking&quot;, not completely random
but unexpected transition should be also required.
  By analogy to &quot;chaotic itinerancy&quot;, we have hypothesized that &quot;exploration&quot;
grows into &quot;thinking&quot; through learning by forming flow-type attractors on
chaotic random-like dynamics. It is expected that if rational dynamics are
learned in a chaotic neural network (ChNN), coexistence of rational state
transition, inspiration-like state transition and also random-like exploration
for unknown situation can be realized.
  Based on the above idea, we have proposed new reinforcement learning using a
ChNN as an actor. The positioning of exploration is completely different from
the conventional one. The chaotic dynamics inside the ChNN produces exploration
factors by itself. Since external random numbers for stochastic action
selection are not used, exploration factors cannot be isolated from the output.
Therefore, the learning method is also completely different from the
conventional one.
  At each non-feedback connection, one variable named causality trace takes in
and maintains the input through the connection according to the change in its
output. Using the trace and TD error, the weight is updated.
  In this paper, as the result of a recent simple task to see whether the new
learning works or not, it is shown that a robot with two wheels and two visual
sensors reaches a target while avoiding an obstacle after learning though there
are still many rooms for improvement.
</dc:description>
 <dc:description>Comment: The Multi-disciplinary Conference on Reinforcement Learning and
  Decision Making (RLDM) 2017, 5 pages, 6 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05552</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IAN: The Individual Aggregation Network for Person Search</dc:title>
 <dc:creator>Xiao, Jimin</dc:creator>
 <dc:creator>Xie, Yanchun</dc:creator>
 <dc:creator>Tillo, Tammam</dc:creator>
 <dc:creator>Huang, Kaizhu</dc:creator>
 <dc:creator>Wei, Yunchao</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person search in real-world scenarios is a new challenging computer version
task with many meaningful applications. The challenge of this task mainly comes
from: (1) unavailable bounding boxes for pedestrians and the model needs to
search for the person over the whole gallery images; (2) huge variance of
visual appearance of a particular person owing to varying poses, lighting
conditions, and occlusions. To address these two critical issues in modern
person search applications, we propose a novel Individual Aggregation Network
(IAN) that can accurately localize persons by learning to minimize intra-person
feature variations. IAN is built upon the state-of-the-art object detection
framework, i.e., faster R-CNN, so that high-quality region proposals for
pedestrians can be produced in an online manner. In addition, to relieve the
negative effect caused by varying visual appearances of the same individual,
IAN introduces a novel center loss that can increase the intra-class
compactness of feature representations. The engaged center loss encourages
persons with the same identity to have similar feature characteristics.
Extensive experimental results on two benchmarks, i.e., CUHK-SYSU and PRW, well
demonstrate the superiority of the proposed model. In particular, IAN achieves
77.23% mAP and 80.45% top-1 accuracy on CUHK-SYSU, which outperform the
state-of-the-art by 1.7% and 1.85%, respectively.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05563</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinematics, workspace and singularity analysis of a multi-mode parallel
  robot</dc:title>
 <dc:creator>Chablat, Damien</dc:creator>
 <dc:creator>Kong, Xianwen</dc:creator>
 <dc:creator>Zhang, Chengwei</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A family of reconfigurable parallel robots can change motion modes by passing
through constraint singularities by locking and releasing some passive joints
of the robot. This paper is about the kinematics, the workspace and singularity
analysis of a 3-PRPiR parallel robot involving lockable Pi and R (revolute)
joints. Here a Pi joint may act as a 1-DOF planar parallelogram if its
lock-able P (prismatic) joint is locked or a 2-DOF RR serial chain if its
lockable P joint is released. The operation modes of the robot include a 3T
operation modes to three 2T1R operation modes with two different directions of
the rotation axis of the moving platform. The inverse kinematics and forward
kinematics of the robot in each operation modes are dealt with in detail. The
workspace analysis of the robot allow us to know the regions of the workspace
that the robot can reach in each operation mode. A prototype built at
Heriot-Watt University is used to illustrate the results of this work.
</dc:description>
 <dc:description>Comment: International Design Engineering Technical Conferences \&amp; Computers
  and Information in Engineering Conference, Aug 2017, Cleveland, United
  States. 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05564</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Invariance: a Theoretical Approach for Coding Sets of Words Modulo
  Literal (Anti)Morphisms</dc:title>
 <dc:creator>N&#xe9;raud, Jean</dc:creator>
 <dc:creator>Selmi, Carla</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $A$ be a finite or countable alphabet and let $\theta$ be literal
(anti)morphism onto $A^*$ (by definition, such a correspondence is determinated
by a permutation of the alphabet). This paper deals with sets which are
invariant under $\theta$ ($\theta$-invariant for short).We establish an
extension of the famous defect theorem. Moreover, we prove that for the
so-called thin $\theta$-invariant codes, maximality and completeness are two
equivalent notions. We prove that a similar property holds in the framework of
some special families of $\theta$-invariant codes such as prefix (bifix) codes,
codes with a finite deciphering delay, uniformly synchronized codes and
circular codes. For a special class of involutive antimorphisms, we prove that
any regular $\theta$-invariant code may be embedded into a complete one.
</dc:description>
 <dc:description>Comment: To appear in Acts of WORDS 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05566</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunistic Communication in Extreme Wireless Sensor Networks</dc:title>
 <dc:creator>Cattani, Marco</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Sensor networks can nowadays deliver 99.9% of their data with duty cycles
below 1%. This remarkable performance is, however, dependent on some important
underlying assumptions: low traffic rates, medium size densities and static
nodes. In this thesis, we investigate the performance of these same
resource-constrained devices, but under scenarios that present extreme
conditions: high traffic rates, high densities and mobility: the so-called
Extreme Wireless Sensor Networks (EWSNs).
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05566</dc:identifier>
 <dc:identifier>doi:10.4233/uuid:73fe7835-43ac-4d65-bbf1-9202c7d72c45</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05569</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Planar Graphs Are Quasiplanar</dc:title>
 <dc:creator>Hoffmann, Michael</dc:creator>
 <dc:creator>T&#xf3;th, Csaba D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R10, 05C10, 05C62</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  It is shown that every 2-planar graph is quasiplanar, that is, if a simple
graph admits a drawing in the plane such that every edge is crossed at most
twice, then it also admits a drawing in which no three edges pairwise cross. We
further show that quasiplanarity is witnessed by a simple topological drawing,
that is, any two edges cross at most once and adjacent edges do not cross.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05571</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tropical F5 algorithm</dc:title>
 <dc:creator>Vaccon, Tristan</dc:creator>
 <dc:creator>Yokoyama, Kazuhiro</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  Let K be a field equipped with a valuation. Tropical varieties over K can be
defined with a theory of Gr{\&quot;o}bner bases taking into account the valuation of
K. While generalizing the classical theory of Gr{\&quot;o}bner bases, it is not
clear how modern algorithms for computing Gr{\&quot;o}bner bases can be adapted to
the tropical case. Among them, one of the most efficient is the celebrated F5
Algorithm of Faug{\`e}re. In this article, we prove that, for homogeneous
ideals, it can be adapted to the tropical case. We prove termination and
correctness. Because of the use of the valuation, the theory of tropical
Gr{\&quot;o}b-ner bases is promising for stable computations over polynomial rings
over a p-adic field. We provide numerical examples to illustrate
time-complexity and p-adic stability of this tropical F5 algorithm.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05573</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balancing the Migration of Virtual Network Functions with Replications
  in Data Centers</dc:title>
 <dc:creator>Carpio, Francisco</dc:creator>
 <dc:creator>Jukan, Admela</dc:creator>
 <dc:creator>Pries, Rastin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Network Function Virtualization (NFV) paradigm is enabling flexibility,
programmability and implementation of traditional network functions into
generic hardware, in form of the so-called Virtual Network Functions (VNFs).
Today, cloud service providers use Virtual Machines (VMs) for the instantiation
of VNFs in the data center (DC) networks. To instantiate multiple VNFs in a
typical scenario of Service Function Chains (SFCs), many important objectives
need to be met simultaneously, such as server load balancing, energy efficiency
and service execution time. The well-known \emph{VNF placement} problem
requires solutions that often consider \emph{migration} of virtual machines
(VMs) to meet this objectives. Ongoing efforts, for instance, are making a
strong case for migrations to minimize energy consumption, while showing that
attention needs to be paid to the Quality of Service (QoS) due to service
interruptions caused by migrations. To balance the server allocation strategies
and QoS, we propose using \emph{replications} of VNFs to reduce migrations in
DC networks. We propose a Linear Programming (LP) model to study a trade-off
between replications, which while beneficial to QoS require additional server
resources, and migrations, which while beneficial to server load management can
adversely impact the QoS. The results show that, for a given objective, the
replications can reduce the number of migrations and can also enable a better
server and data center network load balancing.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05583</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Analysis for the 3-Majority Consensus Dynamics</dc:title>
 <dc:creator>Ghaffari, Mohsen</dc:creator>
 <dc:creator>Lengler, Johannes</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We present a tight analysis for the well-studied randomized 3-majority
dynamics of stabilizing consensus, hence answering the main open question of
Becchetti et al. [SODA'16].
  Consider a distributed system of n nodes, each initially holding an opinion
in {1, 2, ..., k}. The system should converge to a setting where all
(non-corrupted) nodes hold the same opinion. This consensus opinion should be
\emph{valid}, meaning that it should be among the initially supported opinions,
and the (fast) convergence should happen even in the presence of a malicious
adversary who can corrupt a bounded number of nodes per round and in particular
modify their opinions. A well-studied distributed algorithm for this problem is
the 3-majority dynamics, which works as follows: per round, each node gathers
three opinions --- say by taking its own and two of other nodes sampled at
random --- and then it sets its opinion equal to the majority of this set; ties
are broken arbitrarily, e.g., towards the node's own opinion.
  Becchetti et al. [SODA'16] showed that the 3-majority dynamics converges to
consensus in O((k^2\sqrt{\log n} + k\log n)(k+\log n)) rounds, even in the
presence of a limited adversary. We prove that, even with a stronger adversary,
the convergence happens within O(k\log n) rounds. This bound is known to be
optimal.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05584</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metaheuristic Design of Feedforward Neural Networks: A Review of Two
  Decades of Research</dc:title>
 <dc:creator>Ojha, Varun Kumar</dc:creator>
 <dc:creator>Abraham, Ajith</dc:creator>
 <dc:creator>Sn&#xe1;&#x161;el, V&#xe1;clav</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Over the past two decades, the feedforward neural network (FNN) optimization
has been a key interest among the researchers and practitioners of multiple
disciplines. The FNN optimization is often viewed from the various
perspectives: the optimization of weights, network architecture, activation
nodes, learning parameters, learning environment, etc. Researchers adopted such
different viewpoints mainly to improve the FNN's generalization ability. The
gradient-descent algorithm such as backpropagation has been widely applied to
optimize the FNNs. Its success is evident from the FNN's application to
numerous real-world problems. However, due to the limitations of the
gradient-based optimization methods, the metaheuristic algorithms including the
evolutionary algorithms, swarm intelligence, etc., are still being widely
explored by the researchers aiming to obtain generalized FNN for a given
problem. This article attempts to summarize a broad spectrum of FNN
optimization methodologies including conventional and metaheuristic approaches.
This article also tries to connect various research directions emerged out of
the FNN optimization practices, such as evolving neural network (NN),
cooperative coevolution NN, complex-valued NN, deep learning, extreme learning
machine, quantum NN, etc. Additionally, it provides interesting research
challenges for future research to cope-up with the present information
processing era.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05584</dc:identifier>
 <dc:identifier>Engineering Applications of Artificial Intelligence Volume 60,
  April 2017, Pages 97 to 116</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2017.01.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05587</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong Coordination of Signals and Actions over Noisy Channels</dc:title>
 <dc:creator>Cervia, Giulia</dc:creator>
 <dc:creator>Luzzi, Laura</dc:creator>
 <dc:creator>Treust, Ma&#xeb;l Le</dc:creator>
 <dc:creator>Bloch, Matthieu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  -We develop a random binning scheme for strong coordination in a network of
two nodes separated by a noisy channel, in which the input and output signals
have to be coordinated with the source and its reconstruction. In the case of
non-causal encoding and decoding, we propose a joint source-channel coding
scheme and develop inner and outer bounds for the strong coordination region.
While the set of achievable target distributions is the same as for empirical
coordination, we characterize the rate of common randomness required for strong
coordination.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05587</dc:identifier>
 <dc:identifier>IEEE International Symposium on Information Theory, Jun 2017,
  Aachen, Germany</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05589</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Methods - Part 2: A comparative study of reduced order models
  for moisture transfer diffusive problems</dc:title>
 <dc:creator>Gasparin, Suelen</dc:creator>
 <dc:creator>Berger, Julien</dc:creator>
 <dc:creator>Dutykh, Denys</dc:creator>
 <dc:creator>Mendes, Nathan</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Physics - Classical Physics</dc:subject>
 <dc:description>  This paper explores in details the capabilities of two model reduction
techniques - the Spectral Reduced Order Model (Spectral-ROM) and the Proper
Generalised Decomposition (PGD) - to numerically solve moisture diffusion
problems. Both techniques assume separated tensorial representation of the
solution by a finite sum of function products. The Spectral-ROM fixes a set of
spatial basis functions to be the Chebyshev polynomials and then, a system of
ordinary differential equations is built to compute the temporal coefficients
of the solution using the Galerkin projection method, while the PGD aims at
computing directly the basis of functions by minimising the residual. Both
approaches are compared for three different cases: i) linear transfer; ii)
parametric problems and iii) nonlinear diffusive transfer. Results have
highlighted that both numerical techniques provide accurate solution and enable
to reduce significantly the order of the model, allowing a fast computation of
physical phenomena such as the moisture buffer effects that occur in porous
building materials. For the linear and nonlinear cases, the Spectral-ROM error
decreases faster than the one for the PGD. Moreover, fewer modes are required
for the Spectral to compute a solution with equivalent accuracy. However, for
the parametric case, the PGD computed a reduced order model whose outputs
depend not only on the coordinates of space and time x and t, but also on the
coordinate of the parameter belonging to a defined interval. On the other hand,
the outputs of the Spectral-ROM depend only on the coordinates of space and
time. The solution of the parametric problem is obtained by computing the
solution for each numerical value of a given parameter within the defined
interval.
</dc:description>
 <dc:description>Comment: 36 pages, 13 figures, 1 table, 59 references. Other author's papers
  can be downloaded at http://www.denys-dutykh.com/</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05590</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge-Caching Wireless Networks: Energy-Efficient Design and Optimization</dc:title>
 <dc:creator>Vu, Thang X.</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:creator>Ottersten, Bjorn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Edge-caching has received much attention as an efficient technique to reduce
delivery latency and network congestion during peak-traffic times by bringing
data closer to end users. Existing works usually design caching algorithms
separately from physical layer design. In this paper, we analyse edge-caching
wireless networks by taking into account the caching capability when designing
the signal transmission. Particularly, we investigate multi-layer caching where
both base station (BS) and users are capable of storing content data in their
local cache and analyse the performance of edge-caching wireless networks under
two notable uncoded and coded caching strategies. Firstly, we propose a coded
caching strategy that is applied to arbitrary values of cache size. The
required backhaul and access rates are derived as a function of the BS and user
cache size. Secondly, closed-form expressions for the system energy efficiency
(EE) corresponding to the two caching methods are derived. Based on the derived
formulas, the system EE is maximized via precoding vectors design and
optimization while satisfying a predefined user request rate. Thirdly, two
optimization problems are proposed to minimize the content delivery time for
the two caching strategies. Finally, numerical results are presented to verify
the effectiveness of the two caching methods.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05591</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Convex Regularizers for Optimal Bayesian Denoising</dc:title>
 <dc:creator>Nguyen, Ha Q.</dc:creator>
 <dc:creator>Bostan, Emrah</dc:creator>
 <dc:creator>Unser, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a data-driven algorithm for the maximum a posteriori (MAP)
estimation of stochastic processes from noisy observations. The primary
statistical properties of the sought signal is specified by the penalty
function (i.e., negative logarithm of the prior probability density function).
Our alternating direction method of multipliers (ADMM)-based approach
translates the estimation task into successive applications of the proximal
mapping of the penalty function. Capitalizing on this direct link, we define
the proximal operator as a parametric spline curve and optimize the spline
coefficients by minimizing the average reconstruction error for a given
training set. The key aspects of our learning method are that the associated
penalty function is constrained to be convex and the convergence of the ADMM
iterations is proven. As a result of these theoretical guarantees, adaptation
of the proposed framework to different levels of measurement noise is extremely
simple and does not require any retraining. We apply our method to estimation
of both sparse and non-sparse models of L\'{e}vy processes for which the
minimum mean square error (MMSE) estimators are available. We carry out a
single training session and perform comparisons at various signal-to-noise
ratio (SNR) values. Simulations illustrate that the performance of our
algorithm is practically identical to the one of the MMSE estimator
irrespective of the noise power.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05592</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble of heterogeneous flexible neural trees using multiobjective
  genetic programming</dc:title>
 <dc:creator>Ojha, Varun Kumar</dc:creator>
 <dc:creator>Abraham, Ajith</dc:creator>
 <dc:creator>Sn&#xe1;&#x161;el, V&#xe1;clav</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Machine learning algorithms are inherently multiobjective in nature, where
approximation error minimization and model's complexity simplification are two
conflicting objectives. We proposed a multiobjective genetic programming (MOGP)
for creating a heterogeneous flexible neural tree (HFNT), tree-like flexible
feedforward neural network model. The functional heterogeneity in neural tree
nodes was introduced to capture a better insight of data during learning
because each input in a dataset possess different features. MOGP guided an
initial HFNT population towards Pareto-optimal solutions, where the final
population was used for making an ensemble system. A diversity index measure
along with approximation error and complexity was introduced to maintain
diversity among the candidates in the population. Hence, the ensemble was
created by using accurate, structurally simple, and diverse candidates from
MOGP final population. Differential evolution algorithm was applied to
fine-tune the underlying parameters of the selected candidates. A comprehensive
test over classification, regression, and time-series datasets proved the
efficiency of the proposed algorithm over other available prediction methods.
Moreover, the heterogeneous creation of HFNT proved to be efficient in making
ensemble system from the final population.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05592</dc:identifier>
 <dc:identifier>Applied Soft Computing, 2017, Volume 52 Pages 909 to 924</dc:identifier>
 <dc:identifier>doi:10.1016/j.asoc.2016.09.035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05595</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GraphH: High Performance Big Graph Analytics in Small Clusters</dc:title>
 <dc:creator>Sun, Peng</dc:creator>
 <dc:creator>Wen, Yonggang</dc:creator>
 <dc:creator>Duong, Ta Nguyen Binh</dc:creator>
 <dc:creator>Xiao, Xiaokui</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  It is common for real-world applications to analyze big graphs using
distributed graph processing systems. Popular in-memory systems require an
enormous amount of resources to handle big graphs. While several out-of-core
approaches have been proposed for processing big graphs on disk, the high disk
I/O overhead could significantly reduce performance. In this paper, we propose
GraphH to enable high-performance big graph analytics in small clusters.
Specifically, we design a two-stage graph partition scheme to evenly divide the
input graph into partitions, and propose a GAB (Gather-Apply-Broadcast)
computation model to make each worker process a partition in memory at a time.
We use an edge cache mechanism to reduce the disk I/O overhead, and design a
hybrid strategy to improve the communication performance. GraphH can
efficiently process big graphs in small clusters or even a single commodity
server. Extensive evaluations have shown that GraphH could be up to 7.8x faster
compared to popular in-memory systems, such as Pregel+ and PowerGraph when
processing generic graphs, and more than 100x faster than recently proposed
out-of-core systems, such as GraphD and Chaos when processing big graphs.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05596</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Construction of Parallel RIO Codes using Coset Coding with Hamming Codes</dc:title>
 <dc:creator>Yamawaki, Akira</dc:creator>
 <dc:creator>Kamabe, Hiroshi</dc:creator>
 <dc:creator>Lu, Shan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Random input/output (RIO) code is a coding scheme that enables reading of one
logical page using a single read threshold in multilevel flash memory. The
construction of RIO codes is equivalent to the construction of WOM codes.
Parallel RIO (P-RIO) code is an RIO code that encodes all pages in parallel. In
this paper, we utilize coset coding with Hamming codes in order to construct
P-RIO codes. Coset coding is a technique that constructs WOM codes using linear
binary codes. We leverage the information on the data of all pages to encode
each page. Our constructed codes store more pages than RIO codes constructed
via coset coding.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05598</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning how to explain neural networks: PatternNet and
  PatternAttribution</dc:title>
 <dc:creator>Kindermans, Pieter-Jan</dc:creator>
 <dc:creator>Sch&#xfc;tt, Kristof T.</dc:creator>
 <dc:creator>Alber, Maximilian</dc:creator>
 <dc:creator>M&#xfc;ller, Klaus-Robert</dc:creator>
 <dc:creator>Erhan, Dumitru</dc:creator>
 <dc:creator>Kim, Been</dc:creator>
 <dc:creator>D&#xe4;hne, Sven</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  DeConvNet, Guided BackProp, LRP, were invented to better understand deep
neural networks. We show that these methods do not produce the theoretically
correct explanation for a linear model. Yet they are used on multi-layer
networks with millions of parameters. This is a cause for concern since linear
models are simple neural networks. We argue that explanation methods for neural
nets should work reliably in the limit of simplicity, the linear models. Based
on our analysis of linear models we propose a generalization that yields two
explanation techniques (PatternNet and PatternAttribution) that are
theoretically sound for linear models and produce improved explanations for
deep networks.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05599</identifier>
 <datestamp>2017-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Parameterized Complexity of the Equidomination Problem</dc:title>
 <dc:creator>Schaudt, Oliver</dc:creator>
 <dc:creator>Senger, Fabian</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A graph $G=(V,E)$ is called equidominating if there exists a value $t \in
\mathbb{N}$ and a weight function $\omega : V \rightarrow \mathbb{N}$ such that
the total weight of a subset $D\subseteq V$ is equal to $t$ if and only if $D$
is a minimal dominating set. To decide whether or not a given graph is
equidominating is referred to as the Equidomination problem.
  In this paper we show that two parameterized versions of the Equidomination
problem are fixed-parameter tractable: the first parameterization considers the
target value $t$ leading to the Target-$t$ Equidomination problem. The second
parameterization allows only weights up to a value $k$, which yields the
$k$-Equidomination problem.
  In addition, we characterize the graphs whose every induced subgraph is
equidominating. We give a finite forbidden induced subgraph characterization
and derive a fast recognition algorithm.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05606</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Impact of Alternation</dc:title>
 <dc:creator>Iosif, Radu</dc:creator>
 <dc:creator>Xu, Xiao</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Alternating automata have been widely used to model and verify systems that
handle data from finite domains, such as communication protocols or hardware.
The main advantage of the alternating model of computation is that
complementation is possible in linear time, thus allowing to concisely encode
trace inclusion problems that occur often in verification. In this paper we
consider alternating automata over infinite alphabets, whose transition rules
are formulae in a combined theory of booleans and some infinite data domain,
that relate past and current values of the data variables. The data theory is
not fixed, but rather it is a parameter of the class. We show that union,
intersection and complementation are possible in linear time in this model and,
though the emptiness problem is undecidable, we provide two efficient
semi-algorithms, inspired by two state-of-the-art abstraction refinement model
checking methods: lazy predicate abstraction \cite{HJMS02} and the \impact~
semi-algorithm \cite{mcmillan06}. We have implemented both methods and report
the results of an experimental comparison.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05613</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward QoE-Driven Dynamic Control Scheme Switching for Time-Delayed
  Teleoperation Systems: A Dedicated Case Study</dc:title>
 <dc:creator>Xu, Xiao</dc:creator>
 <dc:creator>Liu, Qian</dc:creator>
 <dc:creator>Steinbach, Eckehard</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Networked teleoperation with haptic feedback is a prime example for the
emerging Tactile Internet, which requires a careful orchestration of haptic
communication and control. One major challenge in this context is how to
maximize the user's quality-of-experience (QoE) while ensuring at the same time
the stability of the global control loop in the presence of communication
delay. In this paper, we propose a dynamic control scheme switching strategy
for teleoperation systems, which maximizes the QoE for time-varying
communication delay. In order to validate the feasibility of the proposed
approach, we perform a dedicated case study for a virtual teleoperation
environment consisting of a one-dimensional spring-damper system, and conduct
extensive subjective tests under various delay conditions for two control
schemes: (1) teleoperation with the time-domain passivity approach (TDPA),
which is highly delay-sensitive but supports highly dynamic interaction between
the operator and a potentially quickly changing remote environment; (2)
model-mediated teleoperation (MMT), which is tolerable to relatively larger
communication delays, but unsuitable for quickly changing, highly dynamic
remote environments. For both schemes, we use recently proposed extensions,
which incorporate perceptual data reduction to reduce the required packet rate
between the operator and the teleoperator. One key contribution of this paper
lies in the exploration of the intrinsic relationship among QoE, communication
delay and the control schemes which provides a fundamental guidance, not only
to this research, but also to the future joint optimization of communication
and control for time-delayed teleoperation systems.
</dc:description>
 <dc:description>Comment: 6 pages, 9 figures, conference</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05615</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Edge Representations via Low-Rank Asymmetric Projections</dc:title>
 <dc:creator>Abu-El-Haija, Sami</dc:creator>
 <dc:creator>Perozzi, Bryan</dc:creator>
 <dc:creator>Al-Rfou, Rami</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new method for embedding graphs while preserving directed edge
information. Learning such continuous-space vector representations (or
embeddings) of nodes in a graph is an important first step for using network
information (from social networks, user-item graphs, knowledge bases, etc.) in
many machine learning tasks.
  Unlike previous work, we (1) explicitly model an edge as a function of node
embeddings, and we (2) propose a novel objective, the &quot;graph likelihood&quot;, which
contrasts information from sampled random walks with non-existent edges.
Individually, both of these contributions improve the learned representations,
especially when there are memory constraints on the total size of the
embeddings. When combined, our contributions enable us to significantly improve
the state-of-the-art by learning more concise representations that better
preserve the graph structure.
  We evaluate our method on a variety of link-prediction task including social
networks, collaboration networks, and protein interactions, showing that our
proposed method learn representations with error reductions of up to 76% and
55%, on directed and undirected graphs. In addition, we show that the
representations learned by our method are quite space efficient, producing
embeddings which have higher structure-preserving accuracy but are 10 times
smaller.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05615</dc:identifier>
 <dc:identifier>ACM International Conference on Information and Knowledge
  Management, 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3132847.3132959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05619</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on Bi-mode Biometrics Based on Deep Learning</dc:title>
 <dc:creator>Jiang, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In view of the fact that biological characteristics have excellent
independent distinguishing characteristics,biometric identification technology
involves almost all the relevant areas of human distinction. Fingerprints,
iris, face, voice-print and other biological features have been widely used in
the public security departments to detect detection, mobile equipment unlock,
target tracking and other fields. With the use of electronic devices more and
more widely and the frequency is getting higher and higher. Only the Biometrics
identification technology with excellent recognition rate can guarantee the
long-term development of these fields.
</dc:description>
 <dc:description>Comment: in Chinese</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05627</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Picasso: A Modular Framework for Visualizing the Learning Process of
  Neural Network Image Classifiers</dc:title>
 <dc:creator>Henderson, Ryan</dc:creator>
 <dc:creator>Rothe, Rasmus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Picasso is a free open-source (Eclipse Public License) web application
written in Python for rendering standard visualizations useful for analyzing
convolutional neural networks. Picasso ships with occlusion maps and saliency
maps, two visualizations which help reveal issues that evaluation metrics like
loss and accuracy might hide: for example, learning a proxy classification
task. Picasso works with the Tensorflow deep learning framework, and Keras
(when the model can be loaded into the Tensorflow backend). Picasso can be used
with minimal configuration by deep learning researchers and engineers alike
across various neural network architectures. Adding new visualizations is
simple: the user can specify their visualization code and HTML template
separately from the application code.
</dc:description>
 <dc:description>Comment: 9 pages, submission to the Journal of Open Research Software,
  github.com/merantix/picasso</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05627</dc:identifier>
 <dc:identifier>Journal of Open Research Software. 5(1), p.22 (2017)</dc:identifier>
 <dc:identifier>doi:10.5334/jors.178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05633</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Media-based Substance Use Prediction</dc:title>
 <dc:creator>Ding, Tao</dc:creator>
 <dc:creator>Bickel, Warren K.</dc:creator>
 <dc:creator>Pan, Shimei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this paper, we demonstrate how the state-of-the-art machine learning and
text mining techniques can be used to build effective social media-based
substance use detection systems. Since a substance use ground truth is
difficult to obtain on a large scale, to maximize system performance, we
explore different feature learning methods to take advantage of a large amount
of unsupervised social media data. We also demonstrate the benefit of using
multi-view unsupervised feature learning to combine heterogeneous user
information such as Facebook `&quot;likes&quot; and &quot;status updates&quot; to enhance system
performance. Based on our evaluation, our best models achieved 86% AUC for
predicting tobacco use, 81% for alcohol use and 84% for drug use, all of which
significantly outperformed existing methods. Our investigation has also
uncovered interesting relations between a user's social media behavior (e.g.,
word usage) and substance use.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05637</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text-based Adventures of the Golovin AI Agent</dc:title>
 <dc:creator>Kostka, Bartosz</dc:creator>
 <dc:creator>Kwiecien, Jaroslaw</dc:creator>
 <dc:creator>Kowalski, Jakub</dc:creator>
 <dc:creator>Rychlikowski, Pawel</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The domain of text-based adventure games has been recently established as a
new challenge of creating the agent that is both able to understand natural
language, and acts intelligently in text-described environments.
  In this paper, we present our approach to tackle the problem. Our agent,
named Golovin, takes advantage of the limited game domain. We use genre-related
corpora (including fantasy books and decompiled games) to create language
models suitable to this domain. Moreover, we embed mechanisms that allow us to
specify, and separately handle, important tasks as fighting opponents, managing
inventory, and navigating on the game map.
  We validated usefulness of these mechanisms, measuring agent's performance on
the set of 50 interactive fiction games. Finally, we show that our agent plays
on a level comparable to the winner of the last year Text-Based Adventure AI
Competition.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05640</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WebVision Challenge: Visual Learning and Understanding With Web Data</dc:title>
 <dc:creator>Li, Wen</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Li, Wei</dc:creator>
 <dc:creator>Agustsson, Eirikur</dc:creator>
 <dc:creator>Berent, Jesse</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:creator>Sukthankar, Rahul</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present the 2017 WebVision Challenge, a public image recognition challenge
designed for deep learning based on web images without instance-level human
annotation. Following the spirit of previous vision challenges, such as ILSVRC,
Places2 and PASCAL VOC, which have played critical roles in the development of
computer vision by contributing to the community with large scale annotated
data for model designing and standardized benchmarking, we contribute with this
challenge a large scale web images dataset, and a public competition with a
workshop co-located with CVPR 2017. The WebVision dataset contains more than
$2.4$ million web images crawled from the Internet by using queries generated
from the $1,000$ semantic concepts of the benchmark ILSVRC 2012 dataset. Meta
information is also included. A validation set and test set containing human
annotated images are also provided to facilitate algorithmic development. The
2017 WebVision challenge consists of two tracks, the image classification task
on WebVision test set, and the transfer learning task on PASCAL VOC 2012
dataset. In this paper, we describe the details of data collection and
annotation, highlight the characteristics of the dataset, and introduce the
evaluation metrics.
</dc:description>
 <dc:description>Comment: project page: http://www.vision.ee.ethz.ch/webvision/</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05646</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadratic and Near-Quadratic Lower Bounds for the CONGEST Model</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Khoury, Seri</dc:creator>
 <dc:creator>Paz, Ami</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present the first super-linear lower bounds for natural graph problems in
the CONGEST model, answering a long-standing open question.
  Specifically, we show that any exact computation of a minimum vertex cover or
a maximum independent set requires $\Omega(n^2/\log^2{n})$ rounds in the worst
case in the CONGEST model, as well as any algorithm for $\chi$-coloring a
graph, where $\chi$ is the chromatic number of the graph. We further show that
such strong lower bounds are not limited to NP-hard problems, by showing two
simple graph problems in P which require a quadratic and near-quadratic number
of rounds.
  Finally, we address the problem of computing an exact solution to weighted
all-pairs-shortest-paths (APSP), which arguably may be considered as a
candidate for having a super-linear lower bound. We show a simple $\Omega(n)$
lower bound for this problem, which implies a separation between the weighted
and unweighted cases, since the latter is known to have a complexity of
$\Theta(n/\log{n})$. We also formally prove that the standard Alice-Bob
framework is incapable of providing a super-linear lower bound for exact
weighted APSP, whose complexity remains an intriguing open question.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05649</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-resolution channel estimation for mmWave massive MIMO with hybrid
  precoding</dc:title>
 <dc:creator>Hu, Chen</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Gao, Zhen</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Channel estimation is challenging for millimeter-wave (mmWave) massive MIMO
with hybrid precoding, since the number of radio frequency (RF) chains is much
smaller than that of antennas. Conventional compressive sensing based channel
estimation schemes suffer from severe resolution loss due to the channel angle
quantization. To improve the channel estimation accuracy, we propose an
iterative reweight (IR)-based super-resolution channel estimation scheme in
this paper. By optimizing an objective function through the gradient descent
method, the proposed scheme can iteratively move the estimated angle of
arrivals/departures (AoAs/AoDs) towards the optimal solutions, and finally
realize the super-resolution channel estimation. In the optimization, a weight
parameter is used to control the tradeoff between the sparsity and the data
fitting error. In addition, a singular value decomposition (SVD)-based
preconditioning is developed to reduce the computational complexity of the
proposed scheme. Simulation results verify the better performance of the
proposed scheme than conventional solutions.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05649</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05650</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kleisli, Parikh and Peleg Compositions and Liftings for Multirelations</dc:title>
 <dc:creator>Furusawa, Hitoshi</dc:creator>
 <dc:creator>Kawahara, Yasuo</dc:creator>
 <dc:creator>Struth, Georg</dc:creator>
 <dc:creator>Tsumagari, Norihiro</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Multirelations provide a semantic domain for computing systems that involve
two dual kinds of nondeterminism. This paper presents relational formalisations
of Kleisli, Parikh and Peleg compositions and liftings of multirelations. These
liftings are similar to those that arise in the Kleisli category of the
powerset monad. We show that Kleisli composition of multirelations is
associative, but need not have units. Parikh composition may neither be
associative nor have units, but yields a category on the subclass of up-closed
multirelations. Finally, Peleg composition has units, but need not be
associative; a category is obtained when multirelations are union-closed.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05650</dc:identifier>
 <dc:identifier>doi:10.1016/j.jlamp.2017.04.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05651</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of Urban Expansion and Farmland Loss in China by Integrating
  Cellular Automata and Random Forest</dc:title>
 <dc:creator>Yao, Yao</dc:creator>
 <dc:creator>Liu, Xiaoping</dc:creator>
 <dc:creator>Zhang, Dachuan</dc:creator>
 <dc:creator>Liang, Zhaotang</dc:creator>
 <dc:creator>Zhang, Yatao</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  China has encountered serious land loss problems along with urban expansion
due to rapid urbanization. Without considering complicated spatiotemporal
heterogeneity, previous studies could not extract urban transition rules at
large scale well. This study proposed a random forest algorithm (RFA) based
cellular automata (CA) model to simulate China's urban expansion and farmland
loss in a fine scale from 2000 to 2030. The objectives of this study are to 1)
mine urban conversion rules in different homogeneous economic development
regions, and 2) simulate China's urban expansion process and farmland loss at
high spatial resolution (30 meters). Firstly, we clustered several homogeneous
economic development regions among China according to official statistical
data. Secondly, we constructed a RFA-based CA model to mine complex urban
conversion rules and carried out simulation of urban expansion and farmland
loss at each homo-region. The proposed model was implemented on Tianhe-1
supercomputer located in Guangzhou, China. The accuracy evaluation demonstrates
that the simulation result of proposed RFA-based CA model is more in agreement
with actual land use change. This study proves that the primary factor of
farmland loss in China is rapid urbanization from 2000, and the farmland loss
rate is expected to slow down gradually and will stabilize from 2010 to 2030.
It shows that China is able to preserve the 1.20 million km farmland without
crossing the &quot;red line&quot; within the next 20 years, but the situation remains
severe.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05654</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>To tune or not to tune the number of trees in random forest?</dc:title>
 <dc:creator>Probst, Philipp</dc:creator>
 <dc:creator>Boulesteix, Anne-Laure</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The number of trees T in the random forest (RF) algorithm for supervised
learning has to be set by the user. It is controversial whether T should simply
be set to the largest computationally manageable value or whether a smaller T
may in some cases be better. While the principle underlying bagging is that
&quot;more trees are better&quot;, in practice the classification error rate sometimes
reaches a minimum before increasing again for increasing number of trees. The
goal of this paper is four-fold: (i) providing theoretical results showing that
the expected error rate may be a non-monotonous function of the number of trees
and explaining under which circumstances this happens; (ii) providing
theoretical results showing that such non-monotonous patterns cannot be
observed for other performance measures such as the Brier score and the
logarithmic loss (for classification) and the mean squared error (for
regression); (iii) illustrating the extent of the problem through an
application to a large number (n = 306) of datasets from the public database
OpenML; (iv) finally arguing in favor of setting it to a computationally
feasible large number, depending on convergence properties of the desired
performance measure.
</dc:description>
 <dc:description>Comment: 20 pages, 4 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05660</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Position and line-of-sight stabilization of spherical robot using
  feedforward proportional-derivative geometric controller</dc:title>
 <dc:creator>Kosaraju, Krishna Chaitanya</dc:creator>
 <dc:creator>Mahindrakar, Arun D.</dc:creator>
 <dc:creator>Muralidharan, Vijay</dc:creator>
 <dc:creator>Ekbote, Anup K.</dc:creator>
 <dc:creator>Pasumarthy, Ramkrishna</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper we present a geometric control law for position and
line-of-sight stabilization of the nonholonomic spherical robot actuated by
three independent actuators. A simple configuration error function with an
appropriately defined transport map is proposed to extract feedforward and
proportional-derivative control law. Simulations are provided to validate the
controller performance.
</dc:description>
 <dc:description>Comment: Published in Indian Control Conference, Indian Institute of
  Technology Madras, January 5-7, 2015. Chennai, India</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05665</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Image Relations with Contrast Association Networks</dc:title>
 <dc:creator>Lu, Yao</dc:creator>
 <dc:creator>Yang, Zhirong</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Inferring the relations between two images is an important class of tasks in
computer vision. Examples of such tasks include computing optical flow and
stereo disparity. We treat the relation inference tasks as a machine learning
problem and tackle it with neural networks. A key to the problem is learning a
representation of relations. We propose a new neural network module, contrast
association unit (CAU), which explicitly models the relations between two sets
of input variables. Due to the non-negativity of the weights in CAU, we adopt a
multiplicative update algorithm for learning these weights. Experiments show
that neural networks with CAUs are more effective in learning five fundamental
image transformations than conventional neural networks.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05668</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmitter Beam Selection in Millimeter-wave MIMO with In-Band
  Position-Aiding</dc:title>
 <dc:creator>Garcia, Gabriel E.</dc:creator>
 <dc:creator>Seco-Granados, Gonzalo</dc:creator>
 <dc:creator>Karipidis, Eleftherios</dc:creator>
 <dc:creator>Wymeersch, Henk</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Emerging wireless communication systems will be characterized by a tight
coupling between communication and positioning. This is particularly apparent
in millimeter-wave (mm-wave) communications, where devices use a large number
of antennas and the propagation is well described by geometric channel models.
For mm-wave communications, initial access, consisting in the beam selection
and alignment of two devices, is challenging and time-consuming in the absence
of location information. Conversely, accurate positioning relies on
high-quality communication links with proper beam alignment. This paper studies
this interaction and proposes a new position-aided beam selection protocol,
which considers the problem of joint communication and positioning in scenarios
with direct line-of-sight and scattering. Simulation results show significant
reductions in latency with respect to a standard protocol.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, journal. Submitted to IEEE Transactions on
  Wireless Communications</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05674</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Bit-Channel Reliability Computation for Multi-Mode Polar Code
  Encoders and Decoders</dc:title>
 <dc:creator>Condo, Carlo</dc:creator>
 <dc:creator>Hashemi, Seyyed Ali</dc:creator>
 <dc:creator>Gross, Warren J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Polar codes are a family of capacity-achieving error-correcting codes, and
they have been selected as part of the next generation wireless communication
standard. Each polar code bit-channel is assigned a reliability value, used to
determine which bits transmit information and which parity. Relative
reliabilities need to be known by both encoders and decoders: in case of
multi-mode systems, where multiple code lengths and code rates are supported,
the storage of relative reliabilities can lead to high implementation
complexity. In this work, observe patterns among code reliabilities. We propose
an approximate computation technique to easily represent the reliabilities of
multiple codes, through a limited set of variables and update rules. The
proposed method allows to tune the trade-off between reliability accuracy and
implementation complexity. An approximate computation architecture for encoders
and decoders is designed and implemented, showing 50.7% less area occupation
than storage-based solutions, with less than 0.05 dB error correction
performance degradation.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05677</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology reveals universal features for network comparison</dc:title>
 <dc:creator>Maugis, Pierre-Andr&#xe9; G.</dc:creator>
 <dc:creator>Olhede, Sofia C.</dc:creator>
 <dc:creator>Wolfe, Patrick J.</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  The topology of any complex system is key to understanding its structure and
function. Fundamentally, algebraic topology guarantees that any system
represented by a network can be understood through its closed paths. The length
of each path provides a notion of scale, which is vitally important in
characterizing dominant modes of system behavior. Here, by combining topology
with scale, we prove the existence of universal features which reveal the
dominant scales of any network. We use these features to compare several
canonical network types in the context of a social media discussion which
evolves through the sharing of rumors, leaks and other news. Our analysis
enables for the first time a universal understanding of the balance between
loops and tree-like structure across network scales, and an assessment of how
this balance interacts with the spreading of information online. Crucially, our
results allow networks to be quantified and compared in a purely model-free way
that is theoretically sound, fully automated, and inherently scalable.
</dc:description>
 <dc:description>Comment: 95 pages, 10 figures, 2 algorithms</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05681</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Warping Paths are unique for almost every pair of Time Series</dc:title>
 <dc:creator>Jain, Brijnesh J.</dc:creator>
 <dc:creator>Schultz, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  An optimal warping path between two time series is generally not unique. The
size and form of the set of pairs of time series with non-unique optimal
warping path is unknown. This article shows that optimal warping paths are
unique for almost every pair of time series in a measure-theoretic sense. All
pairs of time series with non-unique optimal warping path form a negligible set
and are geometrically the union of zero sets of quadratic forms. The result is
useful for analyzing and understanding adaptive learning methods in dynamic
time warping spaces.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05684</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A lightweight MapReduce framework for secure processing with SGX</dc:title>
 <dc:creator>Pires, Rafael</dc:creator>
 <dc:creator>Gavril, Daniel</dc:creator>
 <dc:creator>Felber, Pascal</dc:creator>
 <dc:creator>Onica, Emanuel</dc:creator>
 <dc:creator>Pasin, Marcelo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  MapReduce is a programming model used extensively for parallel data
processing in distributed environments. A wide range of algorithms were
implemented using MapReduce, from simple tasks like sorting and searching up to
complex clustering and machine learning operations. Many of these
implementations are part of services externalized to cloud infrastructures.
Over the past years, however, many concerns have been raised regarding the
security guarantees offered in such environments. Some solutions relying on
cryptography were proposed for countering threats but these typically imply a
high computational overhead. Intel, the largest manufacturer of commodity CPUs,
recently introduced SGX (software guard extensions), a set of hardware
instructions that support execution of code in an isolated secure environment.
In this paper, we explore the use of Intel SGX for providing privacy guarantees
for MapReduce operations, and based on our evaluation we conclude that it
represents a viable alternative to a cryptographic mechanism. We present
results based on the widely used k-means clustering algorithm, but our
implementation can be generalized to other applications that can be expressed
using MapReduce model.
</dc:description>
 <dc:description>Comment: 8 pages WACC@CCGRID International Workshop on Assured Cloud Computing
  and QoS aware Big Data</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05684</dc:identifier>
 <dc:identifier>2017 17th IEEE/ACM International Symposium on Cluster, Cloud and
  Grid Computing</dc:identifier>
 <dc:identifier>doi:10.1109/CCGRID.2017.129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05685</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Control of Camera Parameters for Object Detection Algorithms</dc:title>
 <dc:creator>Wu, Yulong</dc:creator>
 <dc:creator>Tsotsos, John</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>65D19</dc:subject>
 <dc:subject>I.4.8</dc:subject>
 <dc:description>  Camera parameters not only play an important role in determining the visual
quality of perceived images, but also affect the performance of vision
algorithms, for a vision-guided robot. By quantitatively evaluating four object
detection algorithms, with respect to varying ambient illumination, shutter
speed and voltage gain, it is observed that the performance of the algorithms
is highly dependent on these variables. From this observation, a novel active
control of camera parameters method is proposed, to make robot vision more
robust under different light conditions. Experimental results demonstrate the
effectiveness of our proposed approach, which improves the performance of
object detection algorithms, compared with the conventional auto-exposure
algorithm.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05688</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strider: A Hybrid Adaptive Distributed RDF Stream Processing Engine</dc:title>
 <dc:creator>Ren, Xiangnan</dc:creator>
 <dc:creator>Cur&#xe9;, Olivier</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Real-time processing of data streams emanating from sensors is becoming a
common task in Internet of Things scenarios. The key implementation goal
consists in efficiently handling massive incoming data streams and supporting
advanced data analytics services like anomaly detection. In an on-going,
industrial project, we found out that a 24/7 available stream processing engine
usually faces dynamically changing data and workload characteristics. These
changes impact the engine's performance and reliability. We propose Strider, a
hybrid adaptive distributed RDF Stream Processing engine that optimizes logical
query plan according to the state of data streams. Strider has been designed to
guarantee important industrial properties such as scalability, high
availability, fault-tolerant, high throughput and acceptable latency. These
guarantees are obtained by designing the engine's architecture with
state-of-the-art Apache components such as Spark and Kafka. We highlight the
efficiency (e.g., on a single machine machine, up to 60x gain on throughput
compared to state-of-the-art systems, a throughput of 3.1 million
triples/second on a 9 machines cluster, a major breakthrough in this system's
category) of Strider on real-world and synthetic data sets.
</dc:description>
 <dc:description>Comment: 16 pages, 9 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05690</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Long Short-Term Memory Recurrent Neural Network Framework for Network
  Traffic Matrix Prediction</dc:title>
 <dc:creator>Azzouni, Abdelhadi</dc:creator>
 <dc:creator>Pujolle, Guy</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Network Traffic Matrix (TM) prediction is defined as the problem of
estimating future network traffic from the previous and achieved network
traffic data. It is widely used in network planning, resource management and
network security. Long Short-Term Memory (LSTM) is a specific recurrent neural
network (RNN) architecture that is well-suited to learn from experience to
classify, process and predict time series with time lags of unknown size. LSTMs
have been shown to model temporal sequences and their long-range dependencies
more accurately than conventional RNNs. In this paper, we propose a LSTM RNN
framework for predicting short and long term Traffic Matrix (TM) in large
networks. By validating our framework on real-world data from GEANT network, we
show that our LSTM models converge quickly and give state of the art TM
prediction performance for relatively small sized models.
</dc:description>
 <dc:description>Comment: Submitted for peer review. arXiv admin note: text overlap with
  arXiv:1402.1128 by other authors</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05691</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cloudroid: A Cloud Framework for Transparent and QoS-aware Robotic
  Computation Outsourcing</dc:title>
 <dc:creator>Hu, Ben</dc:creator>
 <dc:creator>Wang, Huaimin</dc:creator>
 <dc:creator>Zhang, Pengfei</dc:creator>
 <dc:creator>Ding, Bo</dc:creator>
 <dc:creator>Che, Huimin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Many robotic tasks require heavy computation, which can easily exceed the
robot's onboard computer capability. A promising solution to address this
challenge is outsourcing the computation to the cloud. However, exploiting the
potential of cloud resources in robotic software is difficult, because it
involves complex code modification and extensive (re)configuration procedures.
Moreover, quality of service (QoS) such as timeliness, which is critical to
robot's behavior, have to be considered. In this paper, we propose a
transparent and QoS-aware software framework called Cloudroid for cloud robotic
applications. This framework supports direct deployment of existing robotic
software packages to the cloud, transparently transforming them into
Internet-accessible cloud services. And with the automatically generated
service stubs, robotic applications can outsource their computation to the
cloud without any code modification. Furthermore, the robot and the cloud can
cooperate to maintain the specific QoS property such as request response time,
even in a highly dynamic and resource-competitive environment. We evaluated
Cloudroid based on a group of typical robotic scenarios and a set of software
packages widely adopted in real-world robot practices. Results show that
robot's capability can be enhanced significantly without code modification and
specific QoS objectives can be guaranteed. In certain tasks, the &quot;cloud +
robot&quot; setup shows improved performance in orders of magnitude compared with
the robot native setup.
</dc:description>
 <dc:description>Comment: Accepted by 10th IEEE International Conference on Cloud Computing in
  2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05704</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Search with no Coordination</dc:title>
 <dc:creator>Korman, Amos</dc:creator>
 <dc:creator>Rodeh, Yoav</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider a parallel version of a classical Bayesian search problem. $k$
agents are looking for a treasure that is placed in one of the boxes indexed by
$\mathbb{N}^+$ according to a known distribution $p$. The aim is to minimize
the expected time until the first agent finds it. Searchers run in parallel
where at each time step each searcher can &quot;peek&quot; into a box. A basic family of
algorithms which are inherently robust is \emph{non-coordinating} algorithms.
Such algorithms act independently at each searcher, differing only by their
probabilistic choices. We are interested in the price incurred by employing
such algorithms when compared with the case of full coordination. We first show
that there exists a non-coordination algorithm, that knowing only the relative
likelihood of boxes according to $p$, has expected running time of at most
$10+4(1+\frac{1}{k})^2 T$, where $T$ is the expected running time of the best
fully coordinated algorithm. This result is obtained by applying a refined
version of the main algorithm suggested by Fraigniaud, Korman and Rodeh in
STOC'16, which was designed for the context of linear parallel search.We then
describe an optimal non-coordinating algorithm for the case where the
distribution $p$ is known. The running time of this algorithm is difficult to
analyse in general, but we calculate it for several examples. In the case where
$p$ is uniform over a finite set of boxes, then the algorithm just checks boxes
uniformly at random among all non-checked boxes and is essentially $2$ times
worse than the coordinating algorithm.We also show simple algorithms for Pareto
distributions over $M$ boxes. That is, in the case where $p(x) \sim 1/x^b$ for
$0&lt; b &lt; 1$, we suggest the following algorithm: at step $t$ choose uniformly
from the boxes unchecked in ${1, . . . ,min(M, \lfloor t/\sigma\rfloor)}$,
where $\sigma = b/(b + k - 1)$. It turns out this algorithm is asymptotically
optimal, and runs about $2+b$ times worse than the case of full coordination.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05704</dc:identifier>
 <dc:identifier>24th International Colloquium on Structural Information and
  Communication Complexity (SIROCCO), Jun 2017, Porquerolles, France</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05720</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subjective Knowledge Acquisition and Enrichment Powered By Crowdsourcing</dc:title>
 <dc:creator>Meng, Rui</dc:creator>
 <dc:creator>Xin, Hao</dc:creator>
 <dc:creator>Chen, Lei</dc:creator>
 <dc:creator>Song, Yangqiu</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Knowledge bases (KBs) have attracted increasing attention due to its great
success in various areas, such as Web and mobile search.Existing KBs are
restricted to objective factual knowledge, such as city population or fruit
shape, whereas,subjective knowledge, such as big city, which is commonly
mentioned in Web and mobile queries, has been neglected. Subjective knowledge
differs from objective knowledge in that it has no documented or observed
ground truth. Instead, the truth relies on people's dominant opinion. Thus, we
can use the crowdsourcing technique to get opinion from the crowd. In our work,
we propose a system, called crowdsourced subjective knowledge acquisition
(CoSKA),for subjective knowledge acquisition powered by crowdsourcing and
existing KBs. The acquired knowledge can be used to enrich existing KBs in the
subjective dimension which bridges the gap between existing objective knowledge
and subjective queries.The main challenge of CoSKA is the conflict between
large scale knowledge facts and limited crowdsourcing resource. To address this
challenge, in this work, we define knowledge inference rules and then select
the seed knowledge judiciously for crowdsourcing to maximize the inference
power under the resource constraint. Our experimental results on real knowledge
base and crowdsourcing platform verify the effectiveness of CoSKA system.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05727</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Scheme Implicit Force Control for a Flexible-Link Manipulator</dc:title>
 <dc:creator>Murrugarra, Cecilia</dc:creator>
 <dc:creator>De Castro, Osberth</dc:creator>
 <dc:creator>Grieco, Juan Carlos</dc:creator>
 <dc:creator>Fernandez, Gerardo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper we propose an implicit force control scheme for a one-link
flexible manipulator that interact with a compliant environment. The controller
was based in the mathematical model of the manipulator, considering the
dynamics of the beam flexible and the gravitational force. With this method,
the controller parameters are obtained from the structural parameters of the
beam (link) of the manipulator. This controller ensure the stability based in
the Lyapunov Theory. The controller proposed has two closed loops: the inner
loop is a tracking control with gravitational force and vibration frequencies
compensation and the outer loop is a implicit force control. To evaluate the
performance of the controller, we have considered to three different
manipulators (the length, the diameter were modified) and three environments
with compliance modified. The results obtained from simulations verify the
asymptotic tracking and regulated in position and force respectively and the
vibrations suppression of the beam in a finite time.
</dc:description>
 <dc:description>Comment: 16 pages, 14 figures</dc:description>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05735</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison-Based Choices</dc:title>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Mullainathan, Sendhil</dc:creator>
 <dc:creator>Ugander, Johan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A broad range of on-line behaviors are mediated by interfaces in which people
make choices among sets of options. A rich and growing line of work in the
behavioral sciences indicate that human choices follow not only from the
utility of alternatives, but also from the choice set in which alternatives are
presented. In this work we study comparison-based choice functions, a simple
but surprisingly rich class of functions capable of exhibiting so-called
choice-set effects. Motivated by the challenge of predicting complex choices,
we study the query complexity of these functions in a variety of settings. We
consider settings that allow for active queries or passive observation of a
stream of queries, and give analyses both at the granularity of individuals or
populations that might exhibit heterogeneous choice behavior. Our main result
is that any comparison-based choice function in one dimension can be inferred
as efficiently as a basic maximum or minimum choice function across many query
contexts, suggesting that choice-set effects need not entail any fundamental
algorithmic barriers to inference. We also introduce a class of choice
functions we call distance-comparison-based functions, and briefly discuss the
analysis of such functions. The framework we outline provides intriguing
connections between human choice behavior and a range of questions in the
theory of sorting.
</dc:description>
 <dc:description>Comment: 20 pages, 3 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05741</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion-Compensated Temporal Filtering for Critically-Sampled
  Wavelet-Encoded Images</dc:title>
 <dc:creator>Aydin, Vildan Atalay</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel motion estimation/compensation (ME/MC) method for
wavelet-based (in-band) motion compensated temporal filtering (MCTF), with
application to low-bitrate video coding. Unlike the conventional in-band MCTF
algorithms, which require redundancy to overcome the shift-variance problem of
critically sampled (complete) discrete wavelet transforms (DWT), we perform
ME/MC steps directly on DWT coefficients by avoiding the need of
shift-invariance. We omit upsampling, the inverse-DWT (IDWT), and the
calculation of redundant DWT coefficients, while achieving arbitrary subpixel
accuracy without interpolation, and high video quality even at very
low-bitrates, by deriving the exact relationships between DWT subbands of input
image sequences. Experimental results demonstrate the accuracy of the proposed
method, confirming that our model for ME/MC effectively improves video coding
quality.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1705.04433,
  arXiv:1705.04641</dc:description>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05742</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Know-Evolve: Deep Temporal Reasoning for Dynamic Knowledge Graphs</dc:title>
 <dc:creator>Trivedi, Rakshit</dc:creator>
 <dc:creator>Dai, Hanjun</dc:creator>
 <dc:creator>Wang, Yichen</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The availability of large scale event data with time stamps has given rise to
dynamically evolving knowledge graphs that contain temporal information for
each edge. Reasoning over time in such dynamic knowledge graphs is not yet well
understood. To this end, we present Know-Evolve, a novel deep evolutionary
knowledge network that learns non-linearly evolving entity representations over
time. The occurrence of a fact (edge) is modeled as a multivariate point
process whose intensity function is modulated by the score for that fact
computed based on the learned entity embeddings. We demonstrate significantly
improved performance over various relational learning approaches on two large
scale real-world datasets. Further, our method effectively predicts occurrence
or recurrence time of a fact which is novel compared to prior reasoning
approaches in multi-relational setting.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05745</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Volumetric Super-Resolution of Multispectral Data</dc:title>
 <dc:creator>Aydin, Vildan Atalay</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most multispectral remote sensors (e.g. QuickBird, IKONOS, and Landsat 7
ETM+) provide low-spatial high-spectral resolution multispectral (MS) or
high-spatial low-spectral resolution panchromatic (PAN) images, separately. In
order to reconstruct a high-spatial/high-spectral resolution multispectral
image volume, either the information in MS and PAN images are fused (i.e.
pansharpening) or super-resolution reconstruction (SRR) is used with only MS
images captured on different dates. Existing methods do not utilize temporal
information of MS and high spatial resolution of PAN images together to improve
the resolution. In this paper, we propose a multiframe SRR algorithm using
pansharpened MS images, taking advantage of both temporal and spatial
information available in multispectral imagery, in order to exceed spatial
resolution of given PAN images. We first apply pansharpening to a set of
multispectral images and their corresponding PAN images captured on different
dates. Then, we use the pansharpened multispectral images as input to the
proposed wavelet-based multiframe SRR method to yield full volumetric SRR. The
proposed SRR method is obtained by deriving the subband relations between
multitemporal MS volumes. We demonstrate the results on Landsat 7 ETM+ images
comparing our method to conventional techniques.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1705.01258</dc:description>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05755</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic k-Server: How Should Uber Work?</dc:title>
 <dc:creator>Dehghani, Sina</dc:creator>
 <dc:creator>Ehsani, Soheil</dc:creator>
 <dc:creator>HajiAghayi, MohammadTaghi</dc:creator>
 <dc:creator>Liaghat, Vahid</dc:creator>
 <dc:creator>Seddighin, Saeed</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study a stochastic variant of the celebrated k-server
problem. In the k-server problem, we are required to minimize the total
movement of k servers that are serving an online sequence of t requests in a
metric. In the stochastic setting we are given t independent distributions
&lt;P_1, P_2,..., P_t&gt; in advance, and at every time step i a request is drawn
from Pi. Designing the optimal online algorithm in such setting is NP-hard,
therefore the emphasis of our work is on designing an approximately optimal
online algorithm. We first show a structural characterization for a certain
class of non-adaptive online algorithms. We prove that in general metrics, the
best of such algorithms has a cost of no worse than three times that of the
optimal online algorithm. Next, we present an integer program that finds the
optimal algorithm of this class for any arbitrary metric. Finally, by rounding
the solution of the linear relaxation of this program, we present an online
algorithm for the stochastic k-server problem with the approximation factor of
3 in the line and circle metrics and O(log n) in a general metric of size n.
Moreover, we define the Uber problem, in which each demand consists of two
endpoints, a source and a destination. We show that given an a-approximation
algorithm for the k-server problem, we can obtain an (a+2)-approximation
algorithm for the Uber problem. Motivated by the fact that demands are usually
highly correlated with the time we study the stochastic Uber problem.
Furthermore, we extend our results to the correlated setting where the
probability of a request arriving at a certain point depends not only on the
time step but also on the previously arrived requests.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05755</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ICALP.2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05756</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>All-relevant feature selection using multidimensional filters with
  exhaustive search</dc:title>
 <dc:creator>Mnich, Krzysztof</dc:creator>
 <dc:creator>Rudnicki, Witold R.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper describes a method for identification of the informative variables
in the information system with discrete decision variables. It is targeted
specifically towards discovery of the variables that are non-informative when
considered alone, but are informative when the synergistic interactions between
multiple variables are considered. To this end, the mutual entropy of all
possible k-tuples of variables with decision variable is computed. Then, for
each variable the maximal information gain due to interactions with other
variables is obtained. For non-informative variables this quantity conforms to
the well known statistical distributions. This allows for discerning truly
informative variables from non-informative ones. For demonstration of the
approach, the method is applied to several synthetic datasets that involve
complex multidimensional interactions between variables. It is capable of
identifying most important informative variables, even in the case when the
dimensionality of the analysis is smaller than the true dimensionality of the
problem. What is more, the high sensitivity of the algorithm allows for
detection of the influence of nuisance variables on the response variable.
</dc:description>
 <dc:description>Comment: 27 pages, 11 figures, 3 tables</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05762</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Agent-based model for the origins of scaling in human language</dc:title>
 <dc:creator>Vera, Javier</dc:creator>
 <dc:creator>Urbina, Felipe</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  Background/Introduction: The Zipf's law establishes that if the words of a
(large) text are ordered by decreasing frequency, the frequency versus the rank
decreases as a power law with exponent close to -1. Previous work has stressed
that this pattern arises from a conflict of interests of the participants of
communication: speakers and hearers. Methods: The challenge here is to define a
computational language game on a population of agents, playing games mainly
based on a parameter that measures the relative participant's interests.
Results: Numerical simulations suggest that at critical values of the parameter
a human-like vocabulary, exhibiting scaling properties, seems to appear.
Conclusions: The appearance of an intermediate distribution of frequencies at
some critical values of the parameter suggests that on a population of
artificial agents the emergence of scaling partly arises as a self-organized
process only from local interactions between agents.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05765</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Article Ranking as a Constrained, Dynamic, Multi-Objective
  Optimization Problem</dc:title>
 <dc:creator>Balasubramanian, Jeya Balaji</dc:creator>
 <dc:creator>Soni, Akshay</dc:creator>
 <dc:creator>Mehdad, Yashar</dc:creator>
 <dc:creator>Laptev, Nikolay</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The content ranking problem in a social news website, is typically a function
that maximizes a scalar metric of interest like dwell-time. However, like in
most real-world applications we are interested in more than one metric---for
instance simultaneously maximizing click-through rate, monetization metrics,
dwell-time---and also satisfy the traffic requirements promised to different
publishers. All this needs to be done on online data and under the settings
where the objective function and the constraints can dynamically change; this
could happen if for instance new publishers are added, some contracts are
adjusted, or if some contracts are over.
  In this paper, we formulate this problem as a constrained, dynamic,
multi-objective optimization problem. We propose a novel framework that extends
a successful genetic optimization algorithm, NSGA-II, to solve this online,
data-driven problem. We design the modules of NSGA-II to suit our problem. We
evaluate optimization performance using Hypervolume and introduce a confidence
interval metric for assessing the practicality of a solution. We demonstrate
the application of this framework on a real-world Article Ranking problem. We
observe that we make considerable improvements in both time and performance
over a brute-force baseline technique that is currently in production.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05767</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RAE: The Rainforest Automation Energy Dataset for Smart Grid Meter Data
  Analysis</dc:title>
 <dc:creator>Makonin, Stephen</dc:creator>
 <dc:creator>Wang, Z. Jane</dc:creator>
 <dc:creator>Tumpach, Chris</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Datasets are important for researchers to build models and test how well
their machine learning algorithms perform. This paper presents the Rainforest
Automation Energy (RAE) dataset to help smart grid researchers test their
algorithms which make use of smart meter data. This initial release of RAE
contains 1Hz data (mains and sub-meters) from two a residential house. In
addition to power data, environmental and sensor data from the house's
thermostat is included. Sub-meter data from one of the houses includes heat
pump and rental suite captures which is of interest to power utilities. We also
show and energy breakdown of each house and show (by example) how RAE can be
used to test non-intrusive load monitoring (NILM) algorithms.
</dc:description>
 <dc:date>2017-05-14</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05769</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiobjective Programming for Type-2 Hierarchical Fuzzy Inference Trees</dc:title>
 <dc:creator>Ojha, Varun Kumar</dc:creator>
 <dc:creator>Snasel, Vaclav</dc:creator>
 <dc:creator>Abraham, Ajith</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper proposes a design of hierarchical fuzzy inference tree (HFIT). An
HFIT produces an optimum treelike structure, i.e., a natural hierarchical
structure that accommodates simplicity by combining several low-dimensional
fuzzy inference systems (FISs). Such a natural hierarchical structure provides
a high degree of approximation accuracy. The construction of HFIT takes place
in two phases. Firstly, a nondominated sorting based multiobjective genetic
programming (MOGP) is applied to obtain a simple tree structure (a low
complexity model) with a high accuracy. Secondly, the differential evolution
algorithm is applied to optimize the obtained tree's parameters. In the derived
tree, each node acquires a different input's combination, where the
evolutionary process governs the input's combination. Hence, HFIT nodes are
heterogeneous in nature, which leads to a high diversity among the rules
generated by the HFIT. Additionally, the HFIT provides an automatic feature
selection because it uses MOGP for the tree's structural optimization that
accepts inputs only relevant to the knowledge contained in data. The HFIT was
studied in the context of both type-1 and type-2 FISs, and its performance was
evaluated through six application problems. Moreover, the proposed
multiobjective HFIT was compared both theoretically and empirically with
recently proposed FISs methods from the literature, such as McIT2FIS,
TSCIT2FNN, SIT2FNN, RIT2FNS-WB, eT2FIS, MRIT2NFS, IT2FNN-SVR, etc. From the
obtained results, it was found that the HFIT provided less complex and highly
accurate models compared to the models produced by the most of other methods.
Hence, the proposed HFIT is an efficient and competitive alternative to the
other FISs for function approximation and feature selection.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05769</dc:identifier>
 <dc:identifier>IEEE Transactions on Fuzzy Systems 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TFUZZ.2017.2698399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05779</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New self-dual codes of length 72</dc:title>
 <dc:creator>Zhdanov, Alexandre</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we obtain at least 61 new singly even (Type I) binary
[72,36,12] self-dual codes as a quasi-cyclic codes with m=2 (tailbitting
convolutional codes) and at least 13 new doubly even (Type II) binary
[72,36,12] self-dual codes by replacing the first row in each circulant in a
double circulant code by &quot;all ones&quot; and &quot;all zeros&quot; vectors respectively.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05782</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Temporal Representation in Linear Reservoir Computing</dc:title>
 <dc:creator>Gallicchio, Claudio</dc:creator>
 <dc:creator>Micheli, Alessio</dc:creator>
 <dc:creator>Pedrelli, Luca</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently, studies on deep Reservoir Computing (RC) highlighted the role of
layering in deep recurrent neural networks (RNNs). In this paper, the use of
linear recurrent units allows us to bring more evidence on the intrinsic
hierarchical temporal representation in deep RNNs through frequency analysis
applied to the state signals. The potentiality of our approach is assessed on
the class of Multiple Superimposed Oscillator tasks. Furthermore, our
investigation provides useful insights to open a discussion on the main aspects
that characterize the deep learning framework in the temporal domain.
</dc:description>
 <dc:description>Comment: This is a pre-print of the paper submitted to the 27th Italian
  Workshop on Neural Networks, WIRN 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05783</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Algebraic Multiscale Solver for Compressible Flow in
  Heterogeneous Porous Media</dc:title>
 <dc:creator>Tene, Matei</dc:creator>
 <dc:creator>Wang, Yixuan</dc:creator>
 <dc:creator>Hajibeygi, Hadi</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  This paper presents the development of an Adaptive Algebraic Multiscale
Solver for Compressible flow (C-AMS) in heterogeneous porous media. Similar to
the recently developed AMS for incompressible (linear) flows [Wang et al., JCP,
2014], C-AMS operates by defining primal and dual-coarse blocks on top of the
fine-scale grid. These coarse grids facilitate the construction of a
conservative (finite volume) coarse-scale system and the computation of local
basis functions, respectively. However, unlike the incompressible (elliptic)
case, the choice of equations to solve for basis functions in compressible
problems is not trivial. Therefore, several basis function formulations
(incompressible and compressible, with and without accumulation) are considered
in order to construct an efficient multiscale prolongation operator. As for the
restriction operator, C-AMS allows for both multiscale finite volume (MSFV) and
finite element (MSFE) methods. Finally, in order to resolve high-frequency
errors, fine-scale (pre- and post-) smoother stages are employed. In order to
reduce computational expense, the C-AMS operators (prolongation, restriction,
and smoothers) are updated adaptively. In addition to this, the linear system
in the Newton-Raphson loop is infrequently updated. Systematic numerical
experiments are performed to determine the effect of the various options,
outlined above, on the C-AMS convergence behaviour. An efficient C-AMS strategy
for heterogeneous 3D compressible problems is developed based on overall CPU
times. Finally, C-AMS is compared against an industrial-grade Algebraic
MultiGrid (AMG) solver. Results of this comparison illustrate that the C-AMS is
quite efficient as a nonlinear solver, even when iterated to machine accuracy.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05783</dc:identifier>
 <dc:identifier>J. Comput. Phys. 300 (2015) 679-694</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2015.08.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05784</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic multiscale method for flow in heterogeneous porous media with
  embedded discrete fractures (F-AMS)</dc:title>
 <dc:creator>Tene, Matei</dc:creator>
 <dc:creator>Kobaisi, Mohammed Saad Al</dc:creator>
 <dc:creator>Hajibeygi, Hadi</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  This paper introduces an Algebraic MultiScale method for simulation of flow
in heterogeneous porous media with embedded discrete Fractures (F-AMS). First,
multiscale coarse grids are independently constructed for both porous matrix
and fracture networks. Then, a map between coarse- and fine-scale is obtained
by algebraically computing basis functions with local support. In order to
extend the localization assumption to the fractured media, four types of basis
functions are investigated: (1) Decoupled-AMS, in which the two media are
completely decoupled, (2) Frac-AMS and (3) Rock-AMS, which take into account
only one-way transmissibilities, and (4) Coupled-AMS, in which the matrix and
fracture interpolators are fully coupled. In order to ensure scalability, the
F-AMS framework permits full flexibility in terms of the resolution of the
fracture coarse grids. Numerical results are presented for two- and
three-dimensional heterogeneous test cases. During these experiments, the
performance of F-AMS, paired with ILU(0) as second-stage smoother in a
convergent iterative procedure, is studied by monitoring CPU times and
convergence rates. Finally, in order to investigate the scalability of the
method, an extensive benchmark study is conducted, where a commercial algebraic
multigrid solver is used as reference. The results show that, given an
appropriate coarsening strategy, F-AMS is insensitive to severe fracture and
matrix conductivity contrasts, as well as the length of the fracture networks.
Its unique feature is that a fine-scale mass conservative flux field can be
reconstructed after any iteration, providing efficient approximate solutions in
time-dependent simulations.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05784</dc:identifier>
 <dc:identifier>J. Comput. Phys. 321 (2016) 819-845</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2016.06.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05785</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demystifying Relational Latent Representations</dc:title>
 <dc:creator>Duman&#x10d;i&#x107;, Sebastijan</dc:creator>
 <dc:creator>Blockeel, Hendrik</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Latent features learned by deep learning approaches have proven to be a
powerful tool for machine learning. They serve as a data abstraction that makes
learning easier by capturing regularities in data explicitly. Their benefits
motivated their adaptation to relational learning context. In our previous
work, we introduce an approach that learns relational latent features by means
of clustering instances and their relations. The major drawback of latent
representations is that they are often black-box and difficult to interpret.
This work addresses these issues and shows that (1) latent features created by
clustering are interpretable and capture interesting properties of data; (2)
they identify local regions of instances that match well with the label, which
partially explains their benefit; and (3) although the number of latent
features generated by this approach is large, often many of them are highly
redundant and can be removed without hurting performance much.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures; accepted to ILP 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05786</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Characterization of Infinite LSP Words</dc:title>
 <dc:creator>Richomme, Gwena&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  G. Fici proved that a finite word has a minimal suffix automaton if and only
if all its left special factors occur as prefixes. He called LSP all finite and
infinite words having this latter property. We characterize here infinite LSP
words in terms of $S$-adicity. More precisely we provide a finite set of
morphisms $S$ and an automaton ${\cal A}$ such that an infinite word is LSP if
and only if it is $S$-adic and all its directive words are recognizable by
${\cal A}$.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05787</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Features for Offline Handwritten Signature Verification using
  Deep Convolutional Neural Networks</dc:title>
 <dc:creator>Hafemann, Luiz G.</dc:creator>
 <dc:creator>Sabourin, Robert</dc:creator>
 <dc:creator>Oliveira, Luiz S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Verifying the identity of a person using handwritten signatures is
challenging in the presence of skilled forgeries, where a forger has access to
a person's signature and deliberately attempt to imitate it. In offline
(static) signature verification, the dynamic information of the signature
writing process is lost, and it is difficult to design good feature extractors
that can distinguish genuine signatures and skilled forgeries. This reflects in
a relatively poor performance, with verification errors around 7% in the best
systems in the literature. To address both the difficulty of obtaining good
features, as well as improve system performance, we propose learning the
representations from signature images, in a Writer-Independent format, using
Convolutional Neural Networks. In particular, we propose a novel formulation of
the problem that includes knowledge of skilled forgeries from a subset of users
in the feature learning process, that aims to capture visual cues that
distinguish genuine signatures and forgeries regardless of the user. Extensive
experiments were conducted on four datasets: GPDS, MCYT, CEDAR and Brazilian
PUC-PR datasets. On GPDS-160, we obtained a large improvement in
state-of-the-art performance, achieving 1.72% Equal Error Rate, compared to
6.97% in the literature. We also verified that the features generalize beyond
the GPDS dataset, surpassing the state-of-the-art performance in the other
datasets, without requiring the representation to be fine-tuned to each
particular dataset.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05787</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2017.05.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05790</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting perfect matchings and the switch chain</dc:title>
 <dc:creator>Dyer, Martin</dc:creator>
 <dc:creator>M&#xfc;ller, Haiko</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C81 05C75</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We examine the problem of exactly or approximately counting all perfect
matchings in hereditary classes of nonbipartite graphs. In particular, we
consider the switch Markov chain of Diaconis, Graham and Holmes. We determine
the largest hereditary class for which the chain is ergodic, and define a large
new hereditary class of graphs for which it is rapidly mixing. We go on to show
that the chain has exponential mixing time for a slightly larger class. We also
examine the question of ergodicity of the switch chain in a arbitrary graph.
Finally, we give exact counting algorithms for three classes.
</dc:description>
 <dc:description>Comment: 34 pages, 26 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05798</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on &quot;Gang EDF Schedulability Analysis&quot;</dc:title>
 <dc:creator>Richard, Pascal</dc:creator>
 <dc:creator>Goossens, Jo&#xeb;l</dc:creator>
 <dc:creator>Kato, Shinpei</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  This short report raises a correctness issue in the schedulability test
presented in Kato et al., &quot;Gang EDF Scheduling of Parallel Task Systems&quot;, 30th
IEEE Real-Time Systems Symposium, 2009, pp. 459-468.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05804</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Incremental Multiresolution Matrix Factorization Algorithm</dc:title>
 <dc:creator>Ithapu, Vamsi K.</dc:creator>
 <dc:creator>Kondor, Risi</dc:creator>
 <dc:creator>Johnson, Sterling C.</dc:creator>
 <dc:creator>Singh, Vikas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multiresolution analysis and matrix factorization are foundational tools in
computer vision. In this work, we study the interface between these two
distinct topics and obtain techniques to uncover hierarchical block structure
in symmetric matrices -- an important aspect in the success of many vision
problems. Our new algorithm, the incremental multiresolution matrix
factorization, uncovers such structure one feature at a time, and hence scales
well to large matrices. We describe how this multiscale analysis goes much
farther than what a direct global factorization of the data can identify. We
evaluate the efficacy of the resulting factorizations for relative leveraging
within regression tasks using medical imaging data. We also use the
factorization on representations learned by popular deep networks, providing
evidence of their ability to infer semantic relationships even when they are
not explicitly trained to do so. We show that this algorithm can be used as an
exploratory tool to improve the network architecture, and within numerous other
settings in vision.
</dc:description>
 <dc:description>Comment: Computer Vision and Pattern Recognition (CVPR) 2017, 10 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05823</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Adaptive Image Compression</dc:title>
 <dc:creator>Rippel, Oren</dc:creator>
 <dc:creator>Bourdev, Lubomir</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a machine learning-based approach to lossy image compression which
outperforms all existing codecs, while running in real-time.
  Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG
2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets of
generic images across all quality levels. At the same time, our codec is
designed to be lightweight and deployable: for example, it can encode or decode
the Kodak dataset in around 10ms per image on GPU.
  Our architecture is an autoencoder featuring pyramidal analysis, an adaptive
coding module, and regularization of the expected codelength. We also
supplement our approach with adversarial training specialized towards use in a
compression setting: this enables us to produce visually pleasing
reconstructions for very low bitrates.
</dc:description>
 <dc:description>Comment: Published at ICML 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05824</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing Communication Overhead in Window-Based Parallel Complex Event
  Processing</dc:title>
 <dc:creator>Mayer, Ruben</dc:creator>
 <dc:creator>Tariq, Muhammad Adnan</dc:creator>
 <dc:creator>Rothermel, Kurt</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Distributed Complex Event Processing has emerged as a well-established
paradigm to detect situations of interest from basic sensor streams, building
an operator graph between sensors and applications. In order to detect event
patterns that correspond to situations of interest, each operator correlates
events on its incoming streams according to a sliding window mechanism. To
increase the throughput of an operator, different windows can be assigned to
different operator instances---i.e., identical operator copies---which process
them in parallel. This implies that events that are part of multiple
overlapping windows are replicated to different operator instances. The
communication overhead of replicating the events can be reduced by assigning
overlapping windows to the same operator instance. However, this imposes a
higher processing load on the single operator instance, possibly overloading
it. In this paper, we address the trade-off between processing load and
communication overhead when assigning overlapping windows to a single operator
instance. Controlling the trade-off is challenging and cannot be solved with
traditional reactive methods. To this end, we propose a model-based batch
scheduling controller building on prediction. Evaluations show that our
approach is able to significantly save bandwidth, while keeping a user-defined
latency bound in the operator instances.
</dc:description>
 <dc:description>Comment: In Proceedings of ACM International Conference on Distributed and
  Event-Based Systems, Barcelona, Spain, June 19 - 23, 2017 (DEBS '17), 12
  pages. DOI: http://dx.doi.org/10.1145/3093742.3093914</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05824</dc:identifier>
 <dc:identifier>doi:10.1145/3093742.3093914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05828</identifier>
 <datestamp>2017-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Co-contextual Type Checker for Featherweight Java (incl. Proofs)</dc:title>
 <dc:creator>Kuci, Edlira</dc:creator>
 <dc:creator>Erdweg, Sebastian</dc:creator>
 <dc:creator>Bra&#x10d;evac, Oliver</dc:creator>
 <dc:creator>Bejleri, Andi</dc:creator>
 <dc:creator>Mezini, Mira</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>68N15</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  This paper addresses compositional and incremental type checking for
object-oriented programming languages. Recent work achieved incremental type
checking for structurally typed functional languages through co-contextual
typing rules, a constraint-based formulation that removes any context
dependency for expression typings. However, that work does not cover key
features of object-oriented languages: Subtype polymorphism, nominal typing,
and implementation inheritance. Type checkers encode these features in the form
of class tables, an additional form of typing context inhibiting
incrementalization. In the present work, we demonstrate that an appropriate
co-contextual notion to class tables exists, paving the way to efficient
incremental type checkers for object-oriented languages. This yields a novel
formulation of Igarashi et al.'s Featherweight Java (FJ) type system, where we
replace class tables by the dual concept of class table requirements and class
table operations by dual operations on class table requirements. We prove the
equivalence of FJ's type system and our co-contextual formulation. Based on our
formulation, we implemented an incremental FJ type checker and compared its
performance against javac on a number of realistic example programs.
</dc:description>
 <dc:description>Comment: 54 pages, 10 figures, to appear in ECOOP 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05832</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Directions In Cellular Automata</dc:title>
 <dc:creator>Elnekiti, Abdulrhman</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:description>  We Propose A Novel Automaton Model which uses Arithmetic Operations as the
Evolving Rules, each cell has the states of the Natural Numbers k = (N), a
radius of r = 1/2 and operates on an arbitrary input size. The Automaton reads
an Arithmetic Expression as an input and outputs another Arithmetic Expression.
In Addition, we simulate a variety of One Dimensional Cellular Automata
Structures with different Dynamics including Elementary Cellular Automata.
</dc:description>
 <dc:description>Comment: Pre-print submission to Complex Systems journal</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05840</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge discovery through text-based similarity searches for astronomy
  literature</dc:title>
 <dc:creator>Kerzendorf, W. E.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  The increase in the number of researchers coupled with the ease of publishing
and distribution of scientific papers (due to technological advancements) has
resulted in a dramatic increase in astronomy literature. This has likely led to
the predicament that the body of the literature is too large for traditional
human consumption and that related and crucial knowledge is not discovered by
researchers. In addition to the increased production of astronomical
literature, recent decades have also brought several advancements in computer
linguistics. Especially, the machine aided processing of literature
dissemination might make it possible to convert this stream of papers into a
coherent knowledge set. In this paper, we present the application of computer
linguistics techniques on astronomy literature. In particular, we developed a
tool that will find similar articles purely based on text content from an input
paper. We find that our technique performs robustly in comparison with other
tools recommending articles given a reference paper (known as recommender
system). Our novel tool shows the great power in combining computer linguistics
with astronomy literature and suggests that additional research in this
endeavor will likely produce even better tools that will help researchers cope
with the vast amounts of knowledge being produced.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, subm., comments welcome</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05874</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-frequency or time-scale representation fission and fusion rules</dc:title>
 <dc:creator>Jonker, Coen</dc:creator>
 <dc:creator>Tijsma, Arryon D.</dc:creator>
 <dc:creator>van Elburg, Ronald A. J.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Time-frequency representations are important for the analysis of time series.
We have developed an online time-series analysis system and equipped it to
reliably handle re-alignment in the time-frequency plane. The system can deal
with issues like invalid regions in time-frequency representations and
discontinuities in data transmissions, making it suitable for on-line
processing in real-world situations. In retrospect the whole problem can be
considered to be a generalization of ideas present in overlap-and-add
filtering, but then for time-frequency representations and including the
calculation of non-causal features. Here we present our design for
time-frequency representation fission and fusion rules. We present these rules
in the context of two typical use cases, which facilitate understanding of the
underlying choices.
</dc:description>
 <dc:description>Comment: This paper is accompanying the release of libSoundAnnotator. The
  whole implementation is open sourced through GitHub:
  https://github.com/soundappraisal/libsoundannotator under the Apache License,
  Version 2.0. Both UseCases described are available as documented code through
  GitHub https://github.com/soundappraisal/soundannotatordemo under the Apache
  License, Version 2.0. 11 pages, 5 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05875</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small cities face greater impact from automation</dc:title>
 <dc:creator>Frank, Morgan R.</dc:creator>
 <dc:creator>Sun, Lijun</dc:creator>
 <dc:creator>Cebrian, Manuel</dc:creator>
 <dc:creator>Youn, Hyejin</dc:creator>
 <dc:creator>Rahwan, Iyad</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The city has proven to be the most successful form of human agglomeration and
provides wide employment opportunities for its dwellers. As advances in
robotics and artificial intelligence revive concerns about the impact of
automation on jobs, a question looms: How will automation affect employment in
cities? Here, we provide a comparative picture of the impact of automation
across U.S. urban areas. Small cities will undertake greater adjustments, such
as worker displacement and job content substitutions. We demonstrate that large
cities exhibit increased occupational and skill specialization due to increased
abundance of managerial and technical professions. These occupations are not
easily automatable, and, thus, reduce the potential impact of automation in
large cities. Our results pass several robustness checks including potential
errors in the estimation of occupational automation and sub-sampling of
occupations. Our study provides the first empirical law connecting two societal
forces: urban agglomeration and automation's impact on employment.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05884</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Static Gesture Recognition using Leap Motion</dc:title>
 <dc:creator>Toghiani-Rizi, Babak</dc:creator>
 <dc:creator>Lind, Christofer</dc:creator>
 <dc:creator>Svensson, Maria</dc:creator>
 <dc:creator>Windmark, Marcus</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In this report, an automated bartender system was developed for making orders
in a bar using hand gestures. The gesture recognition of the system was
developed using Machine Learning techniques, where the model was trained to
classify gestures using collected data. The final model used in the system
reached an average accuracy of 95%. The system raised ethical concerns both in
terms of user interaction and having such a system in a real world scenario,
but it could initially work as a complement to a real bartender.
</dc:description>
 <dc:description>Comment: Results based on a study conducted during the course Intelligent
  Interactive Systems at Uppsala University, spring 2016</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05885</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What's In A Patch, I: Tensors, Differential Geometry and Statistical
  Shading Analysis</dc:title>
 <dc:creator>Holtmann-Rice, Daniel Niels</dc:creator>
 <dc:creator>Kunsberg, Benjamin S.</dc:creator>
 <dc:creator>Zucker, Steven W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop a linear algebraic framework for the shape-from-shading problem,
because tensors arise when scalar (e.g. image) and vector (e.g. surface normal)
fields are differentiated multiple times. The work is in two parts. In this
first part we investigate when image derivatives exhibit invariance to changing
illumination by calculating the statistics of image derivatives under general
distributions on the light source. We computationally validate the hypothesis
that image orientations (derivatives) provide increased invariance to
illumination by showing (for a Lambertian model) that a shape-from-shading
algorithm matching gradients instead of intensities provides more accurate
reconstructions when illumination is incorrectly estimated under a flatness
prior.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05893</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computed Axial Lithography (CAL): Toward Single Step 3D Printing of
  Arbitrary Geometries</dc:title>
 <dc:creator>Kelly, Brett</dc:creator>
 <dc:creator>Bhattacharya, Indrasen</dc:creator>
 <dc:creator>Shusteff, Maxim</dc:creator>
 <dc:creator>Panas, Robert M.</dc:creator>
 <dc:creator>Taylor, Hayden K.</dc:creator>
 <dc:creator>Spadaccini, Christopher M.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.1</dc:subject>
 <dc:subject>I.3.3</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:subject>I.3.8</dc:subject>
 <dc:subject>I.4.0</dc:subject>
 <dc:description>  Most additive manufacturing processes today operate by printing voxels (3D
pixels) serially point-by-point to build up a 3D part. In some more
recently-developed techniques, for example optical printing methods such as
projection stereolithography [Zheng et al. 2012], [Tumbleston et al. 2015],
parts are printed layer-by-layer by curing full 2d (very thin in one dimension)
layers of the 3d part in each print step. There does not yet exist a technique
which is able to print arbitrarily-defined 3D geometries in a single print
step. If such a technique existed, it could be used to expand the range of
printable geometries in additive manufacturing and relax constraints on factors
such as overhangs in topology optimization. It could also vastly increase print
speed for 3D parts. In this work, we develop the principles for an approach for
single exposure 3D printing of arbitrarily defined geometries. The approach,
termed Computed Axial Lithgography (CAL), is based on tomographic
reconstruction, with mathematical optimization to generate a set of projections
to optically define an arbitrary dose distribution within a target volume. We
demonstrate the potential ability of the technique to print 3D parts using a
prototype CAL system based on sequential illumination from many angles. We also
propose new hardware designs which will help us to realize true single-shot
arbitrary-geometry 3D CAL.
</dc:description>
 <dc:description>Comment: 10 pages, 17 figure, ACM SIGGRAPH format</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05896</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completeness Theorems for Pomset Languages and Concurrent Kleene
  Algebras</dc:title>
 <dc:creator>Laurence, Michael R</dc:creator>
 <dc:creator>Struth, Georg</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Pomsets constitute one of the most basic models of concurrency. A pomset is a
generalisation of a word over an alphabet in that letters may be partially
ordered. A term $t$ using the bi-Kleene operations $0,1, +, \cdot\, ,^*,
\parallel, ^{(*)}$ defines a language $ \mathopen{[\![ } t \mathclose{]\!] } $
of pomsets in a natural way.
  We prove that every valid universal equality over pomset languages using
these operations is a consequence of the equational theory of regular languages
(in which parallel multiplication and iteration are undefined) plus that of the
commutative-regular languages (in which sequential multiplication and iteration
are undefined). We also show that the class of $\textit{rational}$ pomset
languages (that is, those languages generated from singleton pomsets using the
bi-Kleene operations) is closed under all Boolean operations.
  An $ \textit{ideal}$ of a pomset $p$ is a pomset using the letters of $p$,
but having an ordering at least as strict as $p$. A bi-Kleene term $t$ thus
defines the set $ \textbf{Id} (\mathopen{[\![ } t \mathclose{]\!] }) $ of
ideals of pomsets in $ \mathopen{[\![ } t \mathclose{]\!] } $. We prove that if
$t$ does not contain commutative iteration $^{(*)}$ (in our terminology, $t$ is
bw-rational) then $\textbf{Id} (\mathopen{[\![ } t \mathclose{]\!] }) \cap
\textbf{Pom}_{sp}$, where $ \textbf{Pom}_{sp}$ is the set of pomsets generated
from singleton pomsets using sequential and parallel multiplication ($ \cdot$
and $ \parallel$) is defined by a bw-rational term, and if two such terms
$t,t'$ define the same ideal language, then $t'=t$ is provable from the Kleene
axioms for $0,1, +, \cdot\, ,^*$ plus the commutative idempotent semiring
axioms for $0,1, +, \parallel$ plus the exchange law $ (u \parallel v)\cdot ( x
\parallel y) \le v \cdot y \parallel u \cdot x $.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05897</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Cryptographic Analysis of the Pedersen Commitment Scheme</dc:title>
 <dc:creator>Metere, Roberto</dc:creator>
 <dc:creator>Dong, Changyu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68-06</dc:subject>
 <dc:description>  Aiming for strong security assurance, recently there has been an increasing
interest in formal verification of cryptographic constructions. This paper
presents a mechanised formal verification of the popular Pedersen commitment
protocol, proving its security properties of correctness, perfect hiding, and
computational binding. To formally verify the protocol, we extended the theory
of EasyCrypt, a framework which allows for reasoning in the computational
model, to support the discrete logarithm and an abstraction of commitment
protocols. Commitments are building blocks of many cryptographic constructions,
for example, verifiable secret sharing, zero-knowledge proofs, and e-voting.
Our work paves the way for the verification of those more complex
constructions.
</dc:description>
 <dc:description>Comment: 12 pages, conference MMM-ACNS 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05899</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalability analysis of large-scale LoRaWAN networks in ns-3</dc:title>
 <dc:creator>Abeele, Floris Van den</dc:creator>
 <dc:creator>Haxhibeqiri, Jetmir</dc:creator>
 <dc:creator>Moerman, Ingrid</dc:creator>
 <dc:creator>Hoebeke, Jeroen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  As LoRaWAN networks are actively being deployed in the field, it is important
to comprehend the limitations of this Low Power Wide Area Network technology.
Previous work has raised questions in terms of the scalability and capacity of
LoRaWAN networks as the number of end devices grows to hundreds or thousands
per gateway. Some works have modeled LoRaWAN networks as pure ALOHA networks,
which fails to capture important characteristics such as the capture effect and
the effects of interference. Other works provide a more comprehensive model by
relying on empirical and stochastic techniques. This work uses a different
approach where a LoRa error model is constructed from extensive complex
baseband bit error rate simulations and used as an interference model. The
error model is combined with the LoRaWAN MAC protocol in an ns-3 module that
enables to study multi channel, multi spreading factor, multi gateway,
bi-directional LoRaWAN networks with thousands of end devices. Using the
lorawan ns-3 module, a scalability analysis of LoRaWAN shows the detrimental
impact of downstream traffic on the delivery ratio of confirmed upstream
traffic. The analysis shows that increasing gateway density can ameliorate but
not eliminate this effect, as stringent duty cycle requirements for gateways
continue to limit downstream opportunities.
</dc:description>
 <dc:description>Comment: 12 pages, submitted to the IEEE Internet of Things Journal</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05902</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What's In A Patch, II: Visualizing generic surfaces</dc:title>
 <dc:creator>Kunsberg, Benjamin S.</dc:creator>
 <dc:creator>Holtmann-Rice, Daniel Niels</dc:creator>
 <dc:creator>Zucker, Steven W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We continue the development of a linear algebraic framework for the
shape-from-shading problem, exploiting the manner in which tensors arise when
scalar (e.g. image) and vector (e.g. surface normal) fields are differentiated
multiple times. In this paper we apply that framework to develop Taylor
expansions of the normal field and build a boot-strapping algorithm to find
these polynomial surface solutions (under any light source) consistent with a
given patch to arbitrary order. A generic constraint on the image derivatives
restricts these solutions to a 2-D subspace, plus an unknown rotation matrix.
The parameters for the subspace and rotation matrix encapsulate the ambiguity
in the shading problem.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05904</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Motion-Compensated Autonomous Scanning for Tumour Localisation using
  Intraoperative Ultrasound</dc:title>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Ye, Menglong</dc:creator>
 <dc:creator>Giannarou, Stamatia</dc:creator>
 <dc:creator>Pratt, Philip</dc:creator>
 <dc:creator>Yang, Guang-Zhong</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Intraoperative ultrasound facilitates localisation of tumour boundaries
during minimally invasive procedures. Autonomous ultrasound scanning systems
have been recently proposed to improve scanning accuracy and reduce surgeons'
cognitive load. However, current methods mainly consider static scanning
environments typically with the probe pressing against the tissue surface. In
this work, a motion-compensated autonomous ultrasound scanning system using the
da Vinci Research Kit (dVRK) is proposed. An optimal scanning trajectory is
generated considering both the tissue surface shape and the ultrasound
transducer dimensions. A robust vision-based approach is proposed to learn the
underlying tissue motion characteristics. The learned motion model is then
incorporated into the visual servoing framework. The proposed system has been
validated with both phantom and ex vivo experiments using the ground truth
motion data for comparison.
</dc:description>
 <dc:description>Comment: Accepted by Medical Image Computing and Computer Assisted
  Interventions Conference (MICCAI) 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05908</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Collective Attention on Controversial Debates on Social
  Media</dc:title>
 <dc:creator>Garimella, Kiran</dc:creator>
 <dc:creator>Morales, Gianmarco De Francisci</dc:creator>
 <dc:creator>Gionis, Aristides</dc:creator>
 <dc:creator>Mathioudakis, Michael</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study the evolution of long-lived controversial debates as manifested on
Twitter from 2011 to 2016. Specifically, we explore how the structure of
interactions and content of discussion varies with the level of collective
attention, as evidenced by the number of users discussing a topic. Spikes in
the volume of users typically correspond to external events that increase the
public attention on the topic -- as, for instance, discussions about `gun
control' often erupt after a mass shooting.
  This work is the first to study the dynamic evolution of polarized online
debates at such scale. By employing a wide array of network and content
analysis measures, we find consistent evidence that increased collective
attention is associated with increased network polarization and network
concentration within each side of the debate; and overall more uniform lexicon
usage across all users.
</dc:description>
 <dc:description>Comment: accepted at ACM WebScience 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05917</identifier>
 <datestamp>2017-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A discussion about LNG Experiment: Irreversible or Reversible Generation
  of the OR Logic Gate?</dc:title>
 <dc:creator>Cattaneo, Gianpiero</dc:creator>
 <dc:creator>Leporini, Roberto</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In a recent paper M. Lopez-Suarez, I. Neri, and L. Gammaitoni (LNG) present a
concrete realization of the Boolean OR irreversible gate, but contrary to the
standard Landauer principle, with an arbitrary small dissipation of energy. A
Popperian good falsification! In this paper we discuss a theoretical
description of the LNG device which is indeed a 3in/3out self--reversible
realization of the involved OR gate, satisfying in this way the Landauer
principle of no dispersion of energy, contrary to the LNG conclusions. The
different point of view is due to a different interpretation of the two outputs
corresponding to the inputs 10 and 01, which are considered by LNG
indistinguishable so producing a non reversible realization of the standard
2in/1out gate. On the contrary, always considering these two outputs
indistinguishable, by a suitable normalization function of the cantilever
angles, the experimental results obtained by the LNG device coincide with the
OR connective obtained from the third output of the self-reversible 3in/3out CL
gate by the Inputs-Ancilla-&gt;Garbage-Output procedure. Thus, by the
self-reversibility this realization is without dissipation of energy according
to the Landauer principle. Furthermore, using the self-reversible Toffoli gate
it is possible to obtain from the LNG device the realization of the connective
AND adopting another normalization function on the cantilever angles. Finally,
by other suitable normalization procedures on cantilever angles it is possible
to obtain also the other logic NOR and NAND connectives, and in a more
sophisticated way the XOR and NXOR connectives in a self-reversible way. All
this leads to introduce a universal logic machine consisting of the LNG device
plus a memory containing all the necessary angle normalization functions to
produce in a self-reversible way, by choosing one of these latter, the logic
connectives now listed.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05919</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepGO: Predicting protein functions from sequence and interactions
  using a deep ontology-aware classifier</dc:title>
 <dc:creator>Kulmanov, Maxat</dc:creator>
 <dc:creator>Khan, Mohammed Asif</dc:creator>
 <dc:creator>Hoehndorf, Robert</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  A large number of protein sequences are becoming available through the
application of novel high-throughput sequencing technologies. Experimental
functional characterization of these proteins is time-consuming and expensive,
and is often only done rigorously for few selected model organisms.
Computational function prediction approaches have been suggested to fill this
gap. The functions of proteins are classified using the Gene Ontology (GO),
which contains over 40,000 classes. Additionally, proteins have multiple
functions, making function prediction a large-scale, multi-class, multi-label
problem.
  We have developed a novel method to predict protein function from sequence.
We use deep learning to learn features from protein sequences as well as a
cross-species protein-protein interaction network. Our approach specifically
outputs information in the structure of the GO and utilizes the dependencies
between GO classes as background information to construct a deep learning
model. We evaluate our method using the standards established by the
Computational Assessment of Function Annotation (CAFA) and demonstrate a
significant improvement over baseline methods such as BLAST, with significant
improvement for predicting cellular locations.
</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05919</dc:identifier>
 <dc:identifier>doi:10.1093/bioinformatics/btx624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05920</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path Cover and Path Pack Inequalities for the Capacitated Fixed-Charge
  Network Flow Problem</dc:title>
 <dc:creator>Atamturk, Alper</dc:creator>
 <dc:creator>Tezel, Birce</dc:creator>
 <dc:creator>Kucukyavuz, Simge</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Capacitated fixed-charge network flows are used to model a variety of
problems in telecommunication, facility location, production planning and
supply chain management. In this paper, we investigate capacitated path
substructures and derive strong and easy-to-compute \emph{path cover and path
pack inequalities}. These inequalities are based on an explicit
characterization of the submodular inequalities through a fast computation of
parametric minimum cuts on a path, and they generalize the well-known flow
cover and flow pack inequalities for the single-node relaxations of
fixed-charge flow models. We provide necessary and sufficient facet conditions.
Computational results demonstrate the effectiveness of the inequalities when
used as cuts in a branch-and-cut algorithm.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05922</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object
  Detection in Embedded Systems</dc:title>
 <dc:creator>Tripathi, Subarna</dc:creator>
 <dc:creator>Dane, Gokce</dc:creator>
 <dc:creator>Kang, Byeongkeun</dc:creator>
 <dc:creator>Bhaskaran, Vasudev</dc:creator>
 <dc:creator>Nguyen, Truong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep convolutional Neural Networks (CNN) are the state-of-the-art performers
for object detection task. It is well known that object detection requires more
computation and memory than image classification. Thus the consolidation of a
CNN-based object detection for an embedded system is more challenging. In this
work, we propose LCDet, a fully-convolutional neural network for generic object
detection that aims to work in embedded systems. We design and develop an
end-to-end TensorFlow(TF)-based model. Additionally, we employ 8-bit
quantization on the learned weights. We use face detection as a use case. Our
TF-Slim based network can predict different faces of different shapes and sizes
in a single forward pass. Our experimental results show that the proposed
method achieves comparative accuracy comparing with state-of-the-art CNN-based
face detection methods, while reducing the model size by 3x and memory-BW by
~4x comparing with one of the best real-time CNN-based object detector such as
YOLO. TF 8-bit quantized model provides additional 4x memory reduction while
keeping the accuracy as good as the floating point model. The proposed model
thus becomes amenable for embedded implementations.
</dc:description>
 <dc:description>Comment: Embedded Vision Workshop in CVPR</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05927</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lagrangian Reachabililty</dc:title>
 <dc:creator>Cyranka, Jacek</dc:creator>
 <dc:creator>Islam, Md. Ariful</dc:creator>
 <dc:creator>Byrne, Greg</dc:creator>
 <dc:creator>Jones, Paul</dc:creator>
 <dc:creator>Smolka, Scott A.</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:description>  We introduce LRT, a new Lagrangian-based ReachTube computation algorithm that
conservatively approximates the set of reachable states of a nonlinear
dynamical system. LRT makes use of the Cauchy-Green stretching factor (SF),
which is derived from an over-approximation of the gradient of the solution
flows. The SF measures the discrepancy between two states propagated by the
system solution from two initial states lying in a well-defined region, thereby
allowing LRT to compute a reachtube with a ball-overestimate in a metric where
the computed enclosure is as tight as possible. To evaluate its performance, we
implemented a prototype of LRT in C++/Matlab, and ran it on a set of
well-established benchmarks. Our results show that LRT compares very favorably
with respect to the CAPD and Flow* tools.
</dc:description>
 <dc:description>Comment: Accepted to CAV 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05933</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub-sampled Cubic Regularization for Non-convex Optimization</dc:title>
 <dc:creator>Kohler, Jonas Moritz</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the minimization of non-convex functions that typically arise in
machine learning. Specifically, we focus our attention on a variant of trust
region methods known as cubic regularization. This approach is particularly
attractive because it escapes strict saddle points and it provides stronger
convergence guarantees than first- and second-order as well as classical trust
region methods. However, it suffers from a high computational complexity that
makes it impractical for large-scale learning. Here, we propose a novel method
that uses sub-sampling to lower this computational cost. By the use of
concentration inequalities we provide a sampling scheme that gives sufficiently
accurate gradient and Hessian approximations to retain the strong global and
local convergence guarantees of cubically regularized methods. To the best of
our knowledge this is the first work that gives global convergence guarantees
for a sub-sampled variant of cubic regularization on non-convex functions.
Furthermore, we provide experimental results supporting our theory.
</dc:description>
 <dc:description>Comment: Proceedings of the 34th International Conference on Machine Learning</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05935</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rise of the humanbot</dc:title>
 <dc:creator>Sole, Ricard</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The accelerated path of technological development, particularly at the
interface between hardware and biology has been suggested as evidence for
future major technological breakthroughs associated to our potential to
overcome biological constraints. This includes the potential of becoming
immortal, having expanded cognitive capacities thanks to hardware implants or
the creation of intelligent machines. Here I argue that several relevant
evolutionary and structural constraints might prevent achieving most (if not
all) these innovations. Instead, the coming future will bring novelties that
will challenge many other aspects of our life and that can be seen as other
feasible singularities. One particularly important one has to do with the
evolving interactions between humans and non-intelligent robots capable of
learning and communication. Here I argue that a long term interaction can lead
to a new class of &quot;agent&quot; (the humanbot). The way shared memories get tangled
over time will inevitably have important consequences for both sides of the
pair, whose identity as separated entities might become blurred and ultimately
vanish. Understanding such hybrid systems requires a second-order neuroscience
approach while posing serious conceptual challenges, including the definition
of consciousness.
</dc:description>
 <dc:description>Comment: 3 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05937</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Engineering Record And Replay For Deployability: Extended Technical
  Report</dc:title>
 <dc:creator>O'Callahan, Robert</dc:creator>
 <dc:creator>Jones, Chris</dc:creator>
 <dc:creator>Froyd, Nathan</dc:creator>
 <dc:creator>Huey, Kyle</dc:creator>
 <dc:creator>Noll, Albert</dc:creator>
 <dc:creator>Partush, Nimrod</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The ability to record and replay program executions with low overhead enables
many applications, such as reverse-execution debugging, debugging of
hard-to-reproduce test failures, and &quot;black box&quot; forensic analysis of failures
in deployed systems. Existing record-and-replay approaches limit deployability
by recording an entire virtual machine (heavyweight), modifying the OS kernel
(adding deployment and maintenance costs), requiring pervasive code
instrumentation (imposing significant performance and complexity overhead), or
modifying compilers and runtime systems (limiting generality). We investigated
whether it is possible to build a practical record-and-replay system avoiding
all these issues. The answer turns out to be yes - if the CPU and operating
system meet certain non-obvious constraints. Fortunately modern Intel CPUs,
Linux kernels and user-space frameworks do meet these constraints, although
this has only become true recently. With some novel optimizations, our system
'rr' records and replays real-world low-parallelism workloads with low
overhead, with an entirely user-space implementation, using stock hardware,
compilers, runtimes and operating systems. &quot;rr&quot; forms the basis of an
open-source reverse-execution debugger seeing significant use in practice. We
present the design and implementation of 'rr', describe its performance on a
variety of workloads, and identify constraints on hardware and operating system
design required to support our approach.
</dc:description>
 <dc:description>Comment: This extended technical report is based on our previous arXiv paper
  arXiv:1610.02144 but contains much deeper technical detail and a &quot;lessons
  learned&quot; section</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05940</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subregular Complexity and Deep Learning</dc:title>
 <dc:creator>Avcu, Enes</dc:creator>
 <dc:creator>Shibata, Chihiro</dc:creator>
 <dc:creator>Heinz, Jeffrey</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper argues that the judicial use of formal language theory and
grammatical inference are invaluable tools in understanding how deep neural
networks can and cannot represent and learn long-term dependencies in temporal
sequences. Learning experiments were conducted with two types of Recurrent
Neural Networks (RNNs) on six formal languages drawn from the Strictly Local
(SL) and Strictly Piecewise (SP) classes. The networks were Simple RNNs
(s-RNNs) and Long Short-Term Memory RNNs (LSTMs) of varying sizes. The SL and
SP classes are among the simplest in a mathematically well-understood hierarchy
of subregular classes. They encode local and long-term dependencies,
respectively. The grammatical inference algorithm Regular Positive and Negative
Inference (RPNI) provided a baseline. According to earlier research, the LSTM
architecture should be capable of learning long-term dependencies and should
outperform s-RNNs. The results of these experiments challenge this narrative.
First, the LSTMs' performance was generally worse in the SP experiments than in
the SL ones. Second, the s-RNNs out-performed the LSTMs on the most complex SP
experiment and performed comparably to them on the others.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05942</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Multipath Fingerprinting for Millimeter Wave V2I Beam Alignment</dc:title>
 <dc:creator>Va, Vutha</dc:creator>
 <dc:creator>Choi, Junil</dc:creator>
 <dc:creator>Shimizu, Takayuki</dc:creator>
 <dc:creator>Bansal, Gaurav</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Efficient beam alignment is a crucial component in millimeter wave systems
with analog beamforming, especially in fast-changing vehicular settings. This
paper proposes a position-aided approach where the vehicle's position (e.g.,
available via GPS) is used to query the multipath fingerprint database, which
provides prior knowledge of potential pointing directions for reliable beam
alignment. The approach is the inverse of fingerprinting localization, where
the measured multipath signature is compared to the fingerprint database to
retrieve the most likely position. The power loss probability is introduced as
a metric to quantify misalignment accuracy and is used for optimizing candidate
beam selection. Two candidate beam selection methods are developed, where one
is a heuristic while the other minimizes the misalignment probability. The
proposed beam alignment is evaluated using realistic channels generated from a
commercial ray-tracing simulator. Using the generated channels, an extensive
investigation is provided, which includes the required measurement sample size
to build an effective fingerprint, the impact of measurement noise, the
sensitivity to changes in traffic density, and beam alignment overhead
comparison with IEEE 802.11ad as the baseline. Using the concept of beam
coherence time, which is the duration between two consecutive beam alignments,
and parameters of IEEE 802.11ad, the overhead is compared in the mobility
context. The results show that while the proposed approach provides increasing
rates with larger antenna arrays, IEEE 802.11ad has decreasing rates due to the
larger beam training overhead that eats up a large portion of the beam
coherence time, which becomes shorter with increasing mobility.
</dc:description>
 <dc:description>Comment: 16 pages, 19 figures, Submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-09-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05946</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal segmentation of directed graph and the minimum number of
  feedback arcs</dc:title>
 <dc:creator>Xu, Yi-Zhi</dc:creator>
 <dc:creator>Zhou, Hai-Jun</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The minimum feedback arc set problem asks to delete a minimum number of arcs
(directed edges) from a digraph (directed graph) to make it free of any
directed cycles. In this work we approach this fundamental cycle-constrained
optimization problem by considering a generalized task of dividing the digraph
into D layers of equal size. We solve the D-segmentation problem by the
replica-symmetric mean field theory and belief-propagation heuristic
algorithms. The minimum feedback arc density of a given random digraph ensemble
is then obtained by extrapolating the theoretical results to the limit of large
D. A divide-and-conquer algorithm (nested-BPR) is devised to solve the minimum
feedback arc set problem with very good performance and high efficiency.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05946</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1860-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05947</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Resource Allocation for Power-Efficient MC-NOMA with Imperfect
  Channel State Information</dc:title>
 <dc:creator>Wei, Zhiqiang</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:creator>Wang, Hui-Ming</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study power-efficient resource allocation for multicarrier
non-orthogonal multiple access (MC-NOMA) systems. The resource allocation
algorithm design is formulated as a non-convex optimization problem which
jointly designs the power allocation, rate allocation, user scheduling, and
successive interference cancellation (SIC) decoding policy for minimizing the
total transmit power. The proposed framework takes into account the
imperfection of channel state information at transmitter (CSIT) and quality of
service (QoS) requirements of users. To facilitate the design of optimal SIC
decoding policy on each subcarrier, we define a channel-to-noise ratio outage
threshold. Subsequently, the considered non-convex optimization problem is
recast as a generalized linear multiplicative programming problem, for which a
globally optimal solution is obtained via employing the branch-and-bound
approach. The optimal resource allocation policy serves as a system performance
benchmark due to its high computational complexity. To strike a balance between
system performance and computational complexity, we propose a suboptimal
iterative resource allocation algorithm based on difference of convex
programming. Simulation results demonstrate that the suboptimal scheme achieves
a close-to-optimal performance. Also, both proposed schemes provide significant
transmit power savings than that of conventional orthogonal multiple access
(OMA) schemes.
</dc:description>
 <dc:description>Comment: Accepted for publication, IEEE TCOM, May 17, 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05952</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Neural Network Model for Joint POS Tagging and Graph-based
  Dependency Parsing</dc:title>
 <dc:creator>Nguyen, Dat Quoc</dc:creator>
 <dc:creator>Dras, Mark</dc:creator>
 <dc:creator>Johnson, Mark</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a novel neural network model that learns POS tagging and
graph-based dependency parsing jointly. Our model uses bidirectional LSTMs to
learn feature representations shared for both POS tagging and dependency
parsing tasks, thus handling the feature-engineering problem. Our extensive
experiments, on 19 languages from the Universal Dependencies project, show that
our model outperforms the state-of-the-art neural network-based
Stack-propagation model for joint POS tagging and transition-based dependency
parsing, resulting in a new state of the art. Our code is open-source and
available together with pre-trained models at:
https://github.com/datquocnguyen/jPTDP
</dc:description>
 <dc:description>Comment: v2: also include universal POS tagging, UAS and LAS accuracies w.r.t
  gold-standard segmentation on Universal Dependencies 2.0 - CoNLL 2017 shared
  task test data; in CoNLL 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05952</dc:identifier>
 <dc:identifier>doi:10.18653/v1/K17-3014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05953</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LoRa Backscatter: Enabling The Vision of Ubiquitous Connectivity</dc:title>
 <dc:creator>Talla, Vamsi</dc:creator>
 <dc:creator>Hessar, Mehrdad</dc:creator>
 <dc:creator>Kellogg, Bryce</dc:creator>
 <dc:creator>Najafi, Ali</dc:creator>
 <dc:creator>Smith, Joshua R.</dc:creator>
 <dc:creator>Gollakota, Shyamnath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The vision of embedding connectivity into billions of everyday objects runs
into the reality of existing communication technologies --- there is no
existing wireless technology that can provide reliable and long-range
communication at tens of microwatts of power as well as cost less than a dime.
While backscatter is low-power and low-cost, it is known to be limited to short
ranges. This paper overturns this conventional wisdom about backscatter and
presents the first wide-area backscatter system. Our design can successfully
backscatter from any location between an RF source and receiver, separated by
475 m, while being compatible with commodity LoRa hardware. Further, when our
backscatter device is co-located with the RF source, the receiver can be as far
as 2.8 km away. We deploy our system in a 4,800 $ft^{2}$ (446 $m^{2}$) house
spread across three floors, a 13,024 $ft^{2}$ (1210 $m^{2}$) office area
covering 41 rooms, as well as a one-acre (4046 $m^{2}$) vegetable farm and show
that we can achieve reliable coverage, using only a single RF source and
receiver. We also build a contact lens prototype as well as a flexible
epidermal patch device attached to the human skin. We show that these devices
can reliably backscatter data across a 3,328 $ft^{2}$ (309 $m^{2}$) room.
Finally, we present a design sketch of a LoRa backscatter IC that shows that it
costs less than a dime at scale and consumes only 9.25 $\mu$W of power, which
is more than 1000x lower power than LoRa radio chipsets.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05954</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Results on Pulse Coupled Oscillator Protocols in Locally
  Connected Networks</dc:title>
 <dc:creator>Ferrari, Lorenzo</dc:creator>
 <dc:creator>Scaglione, Anna</dc:creator>
 <dc:creator>Gentz, Reinhard</dc:creator>
 <dc:creator>Hong, Yao-Win Peter</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This work provides new insights on the convergence of a locally connected
network of pulse coupled oscillator (PCOs) (i.e., a bio-inspired model for
communication networks) to synchronous and desynchronous states, and their
implication in terms of the decentralized synchronization and scheduling in
communication networks. Bio-inspired techniques have been advocated by many as
fault-tolerant and scalable alternatives to produce self-organization in
communication networks. The PCO dynamics in particular have been the source of
inspiration for many network synchronization and scheduling protocols. However,
their convergence properties, especially in locally connected networks, have
not been fully understood, prohibiting the migration into mainstream standards.
This work provides further results on the convergence of PCOs in locally
connected networks and the achievable convergence accuracy under propagation
delays. For synchronization, almost sure convergence is proved for $3$ nodes
and accuracy results are obtained for general locally connected networks
whereas, for scheduling (or desynchronization), results are derived for locally
connected networks with mild conditions on the overlapping set of maximal
cliques. These issues have not been fully addressed before in the literature.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05954</dc:identifier>
 <dc:identifier>IEEE/ACM Transactions on Networking ( Volume: 25, Issue: 2, April
  2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/TNET.2016.2611379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05957</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Release of Public Transport Data: The Opal Use
  Case</dc:title>
 <dc:creator>Asghar, Hassan Jameel</dc:creator>
 <dc:creator>Tyler, Paul</dc:creator>
 <dc:creator>Kaafar, Mohamed Ali</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This document describes the application of a differentially private algorithm
to release public transport usage data from Transport for New South Wales
(TfNSW), Australia. The data consists of two separate weeks of &quot;tap-on/tap-off&quot;
data of individuals who used any of the four different modes of public
transport from TfNSW: buses, light rail, train and ferries. These taps are
recorded through the smart ticketing system, known as Opal, available in the
state of New South Wales, Australia.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05960</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utility Maximizing Sequential Sensing Over a Finite Horizon</dc:title>
 <dc:creator>Ferrari, Lorenzo</dc:creator>
 <dc:creator>Zhao, Qing</dc:creator>
 <dc:creator>Scaglione, Anna</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the problem of optimally utilizing $N$ resources, each in an
unknown binary state. The state of each resource can be inferred from
state-dependent noisy measurements. Depending on its state, utilizing a
resource results in either a reward or a penalty per unit time. The objective
is a sequential strategy governing the decision of sensing and exploitation at
each time to maximize the expected utility (i.e., total reward minus total
penalty and sensing cost) over a finite horizon $L$. We formulate the problem
as a Partially Observable Markov Decision Process (POMDP) and show that the
optimal strategy is based on two time-varying thresholds for each resource and
an optimal selection rule for which resource to sense. Since a full
characterization of the optimal strategy is generally intractable, we develop a
low-complexity policy that is shown by simulations to offer near optimal
performance. This problem finds applications in opportunistic spectrum access,
marketing strategies and other sequential resource allocation problems.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05960</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing ( Volume: 65, Issue: 13,
  July1, 1 2017 )</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2692725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05976</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polar-Coded Non-Orthogonal Multiple Access</dc:title>
 <dc:creator>Dai, Jincheng</dc:creator>
 <dc:creator>Niu, Kai</dc:creator>
 <dc:creator>Si, Zhongwei</dc:creator>
 <dc:creator>Dong, Chao</dc:creator>
 <dc:creator>Lin, Jiaru</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-orthogonal multiple access (NOMA) is one of the key techniques to address
the high spectral efficiency and massive connectivity requirements for the
fifth generation (5G) wireless system. To efficiently realize NOMA, we propose
a joint design framework combining the polar coding and the NOMA transmission,
which deeply mines the generalized polarization effect among the users. In this
polar coded NOMA (PC-NOMA) framework, the original NOMA channel is decomposed
into multiple bit polarized channels by using a three-stage channel transform,
that is, user$\to$signal$\to$bit partitions. Specifically, for the first-stage
channel transform, we design two schemes, namely sequential user partition
(SUP) and parallel user partition (PUP). For the SUP, a joint successive
cancellation detecting and decoding scheme is developed, and a search algorithm
is proposed to schedule the NOMA detecting order which improves the system
performance by enhanced polarization among the user synthesized channels. The
&quot;worst-goes-first&quot; idea is employed in the scheduling strategy, and its
theoretic performance is analyzed by using the polarization principle. For the
PUP, a corresponding parallel detecting scheme is exploited to reduce the
latency. The block error ratio performances over the additive white Gaussian
noise channel and the Rayleigh fading channel indicate that the proposed
PC-NOMA obviously outperforms the state-of-the-art turbo coded NOMA scheme due
to the advantages of joint design between the polar coding and NOMA.
</dc:description>
 <dc:description>Comment: First version</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05981</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Continuous Opinion Dynamic Model in Co-evolving Networks--A Novel
  Group Decision Approach</dc:title>
 <dc:creator>Dong, Qingxing</dc:creator>
 <dc:creator>Zhou, Xin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Opinion polarization is a ubiquitous phenomenon in opinion dynamics. In
contrast to the traditional consensus oriented group decision making (GDM)
framework, this paper proposes a framework with the co-evolution of both
opinions and relationship networks to improve the potential consensus level of
a group and help the group reach a stable state. Taking the bound of confidence
and the degree of individual's persistence into consideration, the evolution of
the opinion is driven by the relationship among the group. Meanwhile, the
antagonism or cooperation of individuals presented by the network topology also
evolve according to the dynamic opinion distances. Opinions are convergent and
the stable state will be reached in this co-evolution mechanism. We further
explored this framework through simulation experiments. The simulation results
verify the influence of the level of persistence on the time cost and indicate
the influence of group size, the initial topology of networks and the bound of
confidence on the number of opinion clusters.
</dc:description>
 <dc:description>Comment: 24 pages, 3 figures</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05983</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AI, Native Supercomputing and The Revival of Moore's Law</dc:title>
 <dc:creator>Lu, Chien-Ping</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Based on Alan Turing's proposition on AI and computing machinery, which
shaped Computing as we know it today, the new AI computing machinery should
comprise a universal computer and a universal learning machine. The later
should understand linear algebra natively to overcome the slowdown of Moore's
law. In such a universal learnig machine, a computing unit does not need to
keep the legacy of a universal computing core. The data can be distributed to
the computing units, and the results can be collected from them through
Collective Streaming, reminiscent of Collective Communication in
Supercomputing. It is not necessary to use a GPU-like deep memory hierarchy,
nor a TPU-like fine-grain mesh.
</dc:description>
 <dc:description>Comment: 17 pages, 13 figures; to be published in IEEE APSIPA Transaction on
  Signal and Information Processing as an invited paper on Industrial
  Technology Advances</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05986</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>REMIX: Automated Exploration for Interactive Outlier Detection</dc:title>
 <dc:creator>Fu, Yanjie</dc:creator>
 <dc:creator>Aggarwal, Charu</dc:creator>
 <dc:creator>Parthasarathy, Srinivasan</dc:creator>
 <dc:creator>Turaga, Deepak S.</dc:creator>
 <dc:creator>Xiong, Hui</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Outlier detection is the identification of points in a dataset that do not
conform to the norm. Outlier detection is highly sensitive to the choice of the
detection algorithm and the feature subspace used by the algorithm. Extracting
domain-relevant insights from outliers needs systematic exploration of these
choices since diverse outlier sets could lead to complementary insights. This
challenge is especially acute in an interactive setting, where the choices must
be explored in a time-constrained manner. In this work, we present REMIX, the
first system to address the problem of outlier detection in an interactive
setting. REMIX uses a novel mixed integer programming (MIP) formulation for
automatically selecting and executing a diverse set of outlier detectors within
a time limit. This formulation incorporates multiple aspects such as (i) an
upper limit on the total execution time of detectors (ii) diversity in the
space of algorithms and features, and (iii) meta-learning for evaluating the
cost and utility of detectors. REMIX provides two distinct ways for the analyst
to consume its results: (i) a partitioning of the detectors explored by REMIX
into perspectives through low-rank non-negative matrix factorization; each
perspective can be easily visualized as an intuitive heatmap of experiments
versus outliers, and (ii) an ensembled set of outliers which combines outlier
scores from all detectors. We demonstrate the benefits of REMIX through
extensive empirical validation on real-world data.
</dc:description>
 <dc:description>Comment: To appear in KDD 2017</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05987</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Functional Gradient Path Planning in Occupancy Maps</dc:title>
 <dc:creator>Francis, Gilad</dc:creator>
 <dc:creator>Ott, Lionel</dc:creator>
 <dc:creator>Ramos, Fabio</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Planning safe paths is a major building block in robot autonomy. It has been
an active field of research for several decades, with a plethora of planning
methods. Planners can be generally categorised as either trajectory optimisers
or sampling-based planners. The latter is the predominant planning paradigm for
occupancy maps. Trajectory optimisation entails major algorithmic changes to
tackle contextual information gaps caused by incomplete sensor coverage of the
map. However, the benefits are substantial, as trajectory optimisers can reason
on the trade-off between path safety and efficiency.
  In this work, we improve our previous work on stochastic functional gradient
planners. We introduce a novel expressive path representation based on kernel
approximation, that allows cost effective model updates based on stochastic
samples. The main drawback of the previous stochastic functional gradient
planner was the cubic cost, stemming from its non-parametric path
representation. Our novel approximate kernel based model, on the other hand,
has a fixed linear cost that depends solely on the number of features used to
represent the path. We show that the stochasticity of the samples is crucial
for the planner and present comparisons to other state-of-the-art planning
methods in both simulation and with real occupancy data. The experiments
demonstrate the advantages of the stochastic approximate kernel method for path
planning in occupancy maps.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05988</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>IoT Stream Processing and Analytics in The Fog</dc:title>
 <dc:creator>Yang, Shusen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The emerging Fog paradigm has been attracting increasing interests from both
academia and industry, due to the low-latency, resilient, and cost-effective
services it can provide. Many Fog applications such as video mining and event
monitoring, rely on data stream processing and analytics, which are very
popular in the Cloud, but have not been comprehensively investigated in the
context of Fog architecture. In this article, we present the general models and
architecture of Fog data streaming, by analyzing the common properties of
several typical applications. We also analyze the design space of Fog streaming
with the consideration of four essential dimensions (system, data, human, and
optimization), where both new design challenges and the issues arise from
leveraging existing techniques are investigated, such as Cloud stream
processing, computer networks, and mobile computing.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05988</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05992</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frame Stacking and Retaining for Recurrent Neural Network Acoustic Model</dc:title>
 <dc:creator>Tian, Xu</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Ma, Zejun</dc:creator>
 <dc:creator>He, Yi</dc:creator>
 <dc:creator>Wei, Juan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Frame stacking is broadly applied in end-to-end neural network training like
connectionist temporal classification (CTC), and it leads to more accurate
models and faster decoding. However, it is not well-suited to conventional
neural network based on context-dependent state acoustic model, if the decoder
is unchanged. In this paper, we propose a novel frame retaining method which is
applied in decoding. The system which combined frame retaining with frame
stacking could reduces the time consumption of both training and decoding. Long
short-term memory (LSTM) recurrent neural networks (RNNs) using it achieve
almost linear training speedup and reduces relative 41\% real time factor
(RTF). At the same time, recognition performance is no degradation or improves
sightly on Shenma voice search dataset in Mandarin.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05994</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Hierarchical Latent-Variable Model of 3D Shapes</dc:title>
 <dc:creator>Liu, Shikun</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:creator>Ororbia II, Alexander G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose the Variational Shape Learner (VSL), a hierarchical
latent-variable model for 3D shape learning. VSL employs an unsupervised
approach to learning and inferring the underlying structure of voxelized 3D
shapes. Through the use of skip-connections, our model can successfully learn a
latent, hierarchical representation of objects. Furthermore, realistic 3D
objects can be easily generated by sampling the VSL's latent probabilistic
manifold. We show that our generative model can be trained end-to-end from 2D
images to perform single image 3D model retrieval. Experiments show, both
quantitatively and qualitatively, the improved performance of our proposed
model over a range of tasks.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures, 2 tables, submitted to CVPR</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05995</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and $\ell^2$-gain Analysis of Adaptive Control Systems with
  Event-triggered Try-once-discard Protocols</dc:title>
 <dc:creator>Wakaiki, Masashi</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the stability and $\ell^2$-gain analysis of adaptive
control systems with event-triggered try-once-discard protocols. At every
sampling time, an event trigger evaluates an error between the current value
and the last released value of each measurement and determines whether to
transmit the measurements and which measurements to transmit, based on the
try-once-discard protocol and given lower and upper thresholds. For
gain-scheduling controllers and switching controllers that are adaptive to the
maximum error of the measurements, we obtain sufficient conditions for the
practical stability and upper bounds on the $\ell^2$-gain of the closed-loop
system.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures. The ultimate bound in Theorem 3.1 is modified</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05995</dc:identifier>
 <dc:identifier>Published in: IEEE Control Systems Letters ( Volume: 2, Issue: 1,
  Jan. 2018 )</dc:identifier>
 <dc:identifier>doi:10.1109/LCSYS.2017.2777739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05996</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Trapping Sets and Stopping Sets</dc:title>
 <dc:creator>Price, Aiden</dc:creator>
 <dc:creator>Hall, Joanne</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  LDPC codes are used in many applications, however, their error correcting
capabilities are limited by the presence of stopping sets and trapping sets.
Trapping sets and stopping sets occur when specific low-wiehgt error patterns
cause a decoder to fail. Trapping sets were first discovered with investigation
of the error floor of the Margulis code. Possible solutions are constructions
which avoid creating trapping sets, such as progressive edge growth (PEG), or
methods which remove trapping sets from existing constructions, such as graph
covers. This survey examines trapping sets and stopping sets in LDPC codes over
channels such as BSC, BEC and AWGNC.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.05998</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Vertebra Labeling in Large-Scale 3D CT using Deep
  Image-to-Image Network with Message Passing and Sparsity Regularization</dc:title>
 <dc:creator>Yang, Dong</dc:creator>
 <dc:creator>Xiong, Tao</dc:creator>
 <dc:creator>Xu, Daguang</dc:creator>
 <dc:creator>Huang, Qiangui</dc:creator>
 <dc:creator>Liu, David</dc:creator>
 <dc:creator>Zhou, S. Kevin</dc:creator>
 <dc:creator>Xu, Zhoubing</dc:creator>
 <dc:creator>Park, JinHyeong</dc:creator>
 <dc:creator>Chen, Mingqing</dc:creator>
 <dc:creator>Tran, Trac D.</dc:creator>
 <dc:creator>Chin, Sang Peter</dc:creator>
 <dc:creator>Metaxas, Dimitris</dc:creator>
 <dc:creator>Comaniciu, Dorin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic localization and labeling of vertebra in 3D medical images plays an
important role in many clinical tasks, including pathological diagnosis,
surgical planning and postoperative assessment. However, the unusual conditions
of pathological cases, such as the abnormal spine curvature, bright visual
imaging artifacts caused by metal implants, and the limited field of view,
increase the difficulties of accurate localization. In this paper, we propose
an automatic and fast algorithm to localize and label the vertebra centroids in
3D CT volumes. First, we deploy a deep image-to-image network (DI2IN) to
initialize vertebra locations, employing the convolutional encoder-decoder
architecture together with multi-level feature concatenation and deep
supervision. Next, the centroid probability maps from DI2IN are iteratively
evolved with the message passing schemes based on the mutual relation of
vertebra centroids. Finally, the localization results are refined with sparsity
regularization. The proposed method is evaluated on a public dataset of 302
spine CT volumes with various pathologies. Our method outperforms other
state-of-the-art methods in terms of localization accuracy. The run time is
around 3 seconds on average per case. To further boost the performance, we
retrain the DI2IN on additional 1000+ 3D CT volumes from different patients. To
the best of our knowledge, this is the first time more than 1000 3D CT volumes
with expert annotation are adopted in experiments for the anatomic landmark
detection tasks. Our experimental results show that training with such a large
dataset significantly improves the performance and the overall identification
rate, for the first time by our knowledge, reaches 90 %.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.05998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06000</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Shot Joint Colocalization and Cosegmentation</dc:title>
 <dc:creator>Sharma, Abhishek</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a novel framework in which image cosegmentation and
colocalization are cast into a single optimization problem that integrates
information from low level appearance cues with that of high level localization
cues in a very weakly supervised manner. In contrast to multi-task learning
paradigm that learns similar tasks using a shared representation, the proposed
framework leverages two representations at different levels and simultaneously
discriminates between foreground and background at the bounding box and
superpixel level using discriminative clustering. We show empirically that
constraining the two problems at different scales enables the transfer of
semantic localization cues to improve cosegmentation output whereas local
appearance based segmentation cues help colocalization. The unified framework
outperforms strong baseline approaches, of learning the two problems
separately, by a large margin on four benchmark datasets. Furthermore, it
obtains competitive results compared to the state of the art for cosegmentation
on two benchmark datasets and second best result for colocalization on Pascal
VOC 2007.
</dc:description>
 <dc:description>Comment: 8 pages, Under Review</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06002</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attribute-based Encryption for Attribute-based Authentication,
  Authorization, Storage, and Transmission in Distributed Storage Systems</dc:title>
 <dc:creator>Alston, Aubrey</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Attribute-based encryption is a form of encryption which offers the capacity
to encrypt data such that it is only accessible to individuals holding a
satisfactory configuration of attributes. As cloud and distributed computing
become more pervasive in both private and public spheres, attribute-based
encryption holds potential to address the issue of achieving secure
authentication, authorization, and transmission in these environments where
performance must scale with security while also supporting fine-grained access
control among a massively large number of consumers. With this work, we offer
an example generic configurable stateless protocol for secure attribute-based
authentication, authorization, storage, and transmission in distributed storage
systems based upon ciphertext-policy attribute-based encryption (CP-ABE),
discuss the experience of implementing a distributed storage system around this
protocol, and present future avenues of work enabled by such a protocol. The
key contribution of this work is an illustration of a means by which any CP-ABE
system may be utilized in a black-box manner for attribute-based authentication
and cryptographically enforced attribute-based access control in distributed
storage systems.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06011</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PaMM: Pose-aware Multi-shot Matching for Improving Person
  Re-identification</dc:title>
 <dc:creator>Cho, Yeong-Jun</dc:creator>
 <dc:creator>Yoon, Kuk-Jin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Person re-identification is the problem of recognizing people across
different images or videos with non-overlapping views. Although there has been
much progress in person re-identification over the last decade, it remains a
challenging task because appearances of people can seem extremely different
across diverse camera viewpoints and person poses. In this paper, we propose a
novel framework for person re-identification by analyzing camera viewpoints and
person poses in a so-called Pose-aware Multi-shot Matching (PaMM), which
robustly estimates people's poses and efficiently conducts multi-shot matching
based on pose information. Experimental results using public person
re-identification datasets show that the proposed methods outperform
state-of-the-art methods and are promising for person re-identification from
diverse viewpoints and pose variances.
</dc:description>
 <dc:description>Comment: 12 pages, 12 figures, 4 tables</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06013</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How do Practitioners Perceive the Relevance of Requirements Engineering
  Research? An Ongoing Study</dc:title>
 <dc:creator>Franch, X.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, D. M&#xe9;ndez</dc:creator>
 <dc:creator>Oriol, M.</dc:creator>
 <dc:creator>Vogelsang, A.</dc:creator>
 <dc:creator>Heldal, R.</dc:creator>
 <dc:creator>Knauss, E.</dc:creator>
 <dc:creator>Travassos, G. Horta</dc:creator>
 <dc:creator>Carver, J. C.</dc:creator>
 <dc:creator>Dieste, O.</dc:creator>
 <dc:creator>Zimmermann, T.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The relevance of Requirements Engineering (RE) research to practitioners is a
prerequisite for problem-driven research in the area and key for a long-term
dissemination of research results to everyday practice. To better understand
how industry practitioners perceive the practical relevance of RE research, we
have initiated the RE-Pract project, an international collaboration conducting
an empirical study. This project opts for a replication of previous work done
in two different domains and relies on survey research. To this end, we have
designed a survey to be sent to several hundred industry practitioners at
various companies around the world and ask them to rate their perceived
practical relevance of the research described in a sample of 418 RE papers
published between 2010 and 2015 at the RE, ICSE, FSE, ESEC/FSE, ESEM and REFSQ
conferences. In this paper, we summarise our research protocol and present the
current status of our study and the planned future steps.
</dc:description>
 <dc:description>Comment: Accepted for the 25th International Requirements Engineering
  Conference, 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06020</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Gaussian Processes for Continuous-Time Trajectory Estimation on
  Matrix Lie Groups</dc:title>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:creator>Dellaert, Frank</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Continuous-time trajectory representations are a powerful tool that can be
used to address several issues in many practical simultaneous localization and
mapping (SLAM) scenarios, like continuously collected measurements distorted by
robot motion, or during with asynchronous sensor measurements. Sparse Gaussian
processes (GP) allow for a probabilistic non-parametric trajectory
representation that enables fast trajectory estimation by sparse GP regression.
However, previous approaches are limited to dealing with vector space
representations of state only. In this technical report we extend the work by
Barfoot et al. [1] to general matrix Lie groups, by applying constant-velocity
prior, and defining locally linear GP. This enables using sparse GP approach in
a large space of practical SLAM settings. In this report we give the theory and
leave the experimental evaluation in future publications.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06021</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact on the Usage of Wireless Sensor Networks in Healthcare Sector</dc:title>
 <dc:creator>Humayun, Ahsan</dc:creator>
 <dc:creator>Niaz, Muneeb</dc:creator>
 <dc:creator>Umar, Muhammad</dc:creator>
 <dc:creator>Mujahid, Muhammad</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Recent advancement in the wireless sensor networks has provided a platform to
numerous applications in healthcare sector. It has become an active research
area due to its large scale potential. This research focuses on the application
areas of wireless sensor networks specifically in the healthcare sector. In
this work, we have tried to explain the different challenges faced by the WSNs
in order to implement them. The different pros and cons of the WSNs in
healthcare sector are also discussed. Some important parameters which can be
used to evaluate the performance of the wireless sensor networks are also
presented in this work. Wireless sensor networks have a tremendous future and
it should be taken at its earliest because of the significant importance of the
healthcare issues.
</dc:description>
 <dc:description>Comment: 4 Pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06021</dc:identifier>
 <dc:identifier>IJCSNS International Journal of Computer Science and Network
  Security, VOL.17 No.4, April 2017 pp. 102-105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06024</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demand-Aware Network Designs of Bounded Degree</dc:title>
 <dc:creator>Avin, Chen</dc:creator>
 <dc:creator>Mondal, Kaushik</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Traditionally, networks such as datacenter interconnects are designed to
optimize worst-case performance under arbitrary traffic patterns. Such network
designs can however be far from optimal when considering the actual workloads
and traffic patterns which they serve. This insight led to the development of
demand-aware datacenter interconnects which can be reconfigured depending on
the workload.
  Motivated by these trends, this paper initiates the algorithmic study of
demand-aware networks (DANs) designs, and in particular the design of
bounded-degree networks. The inputs to the network design problem are a
discrete communication request distribution, D, defined over communicating
pairs from the node set V , and a bound, d, on the maximum degree. In turn, our
objective is to design an (undirected) demand-aware network N = (V,E) of
bounded-degree d, which provides short routing paths between frequently
communicating nodes distributed across N. In particular, the designed network
should minimize the expected path length on N (with respect to D), which is a
basic measure of the efficiency of the network.
  We show that this fundamental network design problem exhibits interesting
connections to several classic combinatorial problems and to information
theory. We derive a general lower bound based on the entropy of the
communication pattern D, and present asymptotically optimal network-aware
design algorithms for important distribution families, such as sparse
distributions and distributions of locally bounded doubling dimensions.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06031</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Identify Ambiguous and Misleading News Headlines</dc:title>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Wan, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Accuracy is one of the basic principles of journalism. However, it is
increasingly hard to manage due to the diversity of news media. Some editors of
online news tend to use catchy headlines which trick readers into clicking.
These headlines are either ambiguous or misleading, degrading the reading
experience of the audience. Thus, identifying inaccurate news headlines is a
task worth studying. Previous work names these headlines &quot;clickbaits&quot; and
mainly focus on the features extracted from the headlines, which limits the
performance since the consistency between headlines and news bodies is
underappreciated. In this paper, we clearly redefine the problem and identify
ambiguous and misleading headlines separately. We utilize class sequential
rules to exploit structure information when detecting ambiguous headlines. For
the identification of misleading headlines, we extract features based on the
congruence between headlines and bodies. To make use of the large unlabeled
data set, we apply a co-training method and gain an increase in performance.
The experiment results show the effectiveness of our methods. Then we use our
classifiers to detect inaccurate headlines crawled from different sources and
conduct a data analysis.
</dc:description>
 <dc:description>Comment: Accepted by IJCAI 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06037</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Hypergraph Products (Erratum)</dc:title>
 <dc:creator>Hellmuth, Marc</dc:creator>
 <dc:creator>Ostermeier, Lydia</dc:creator>
 <dc:creator>Stadler, Peter F.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A surprising diversity of different products of hypergraphs have been
discussed in the literature. Most of the hypergraph products can be viewed as
generalizations of one of the four standard graph products. The most widely
studied variant, the so-called square product, does not have this property,
however. Here we survey the literature on hypergraph products with an emphasis
on comparing the alternative generalizations of graph products and the
relationships among them. In this context the so-called 2-sections and
L2-sections are considered. These constructions are closely linked to related
colored graph structures that seem to be a useful tool for the prime factor
decompositions w.r.t.\ specific hypergraph products. We summarize the current
knowledge on the propagation of hypergraph invariants under the different
hypergraph multiplications. While the overwhelming majority of the material
concerns finite (undirected) hypergraphs, the survey also covers a summary of
the few results on products of infinite and directed hypergraphs.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06037</dc:identifier>
 <dc:identifier>doi:10.1007/s11786-012-0109-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06040</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Geometry Approach to Parameter Estimation in Hidden Markov
  Models</dc:title>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the estimation of hidden Markovian process by using information
geometry with respect to transition matrices. We consider the case when we use
only the histogram of $k$-memory data. Firstly, we focus on a partial
observation model with Markovian process and we show that the asymptotic
estimation error of this model is given as the inverse of projective Fisher
information of transition matrices. Next, we apply this result to the
estimation of hidden Markovian process. For this purpose, we define an
exponential family of ${\cal Y}$-valued transition matrices. We carefully
discuss the equivalence problem for hidden Markovian process on the tangent
space. Then, we propose a novel method to estimate hidden Markovian process.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06049</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on The Enumeration of Euclidean Self-Dual Skew-Cyclic Codes over
  Finite Fields</dc:title>
 <dc:creator>Irwansyah</dc:creator>
 <dc:creator>Muchtadi-Alamsyah, Intan</dc:creator>
 <dc:creator>Muchlis, Ahmad</dc:creator>
 <dc:creator>Barra, Aleams</dc:creator>
 <dc:creator>Suprijanto, Djoko</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we give the enumeration formulas for Euclidean self-dual
skew-cyclic codes over finite fields when $(n,|\theta|)=1$ and for some cases
when $(n,|\theta|)&gt;1,$ where $n$ is the length of the code and $|\theta|$ is
the order of automorphism $\theta.$
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06055</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Centric Mobile Crowdsensing</dc:title>
 <dc:creator>Jiang, Changkun</dc:creator>
 <dc:creator>Gao, Lin</dc:creator>
 <dc:creator>Duan, Lingjie</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Mobile crowdsensing (MCS) is a promising sensing paradigm that leverages the
diverse embedded sensors in massive mobile devices. A key objective in MCS is
to efficiently schedule mobile users to perform multiple sensing tasks. Prior
work mainly focused on interactions between the task-layer and the user-layer,
without considering tasks' similar data requirements and users' heterogeneous
sensing capabilities. In this work, we propose a three-layer data-centric MCS
model by introducing a new data-layer between tasks and users, enable different
tasks to reuse the same data items, hence effectively leverage both task
similarities and user heterogeneities. We formulate a joint task selection and
user scheduling problem based on the new framework, aiming at maximizing social
welfare. We first analyze the centralized optimization problem with the
statistical information of tasks and users, and show the bound of the social
welfare gain due to data reuse. Then we consider the two-sided information
asymmetry of selfish task-owners and users, and propose a decentralized market
mechanism for achieving the centralized social optimality. In particular,
considering the NP-hardness of the optimization, we propose a truthful
two-sided randomized auction mechanism that ensures computational efficiency
and a close-to-optimal performance. Simulations verify the effectiveness of our
proposed model and mechanism.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06056</identifier>
 <datestamp>2017-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Target Type Identification for Entity-Bearing Queries</dc:title>
 <dc:creator>Garigliotti, Dar&#xed;o</dc:creator>
 <dc:creator>Hasibi, Faegheh</dc:creator>
 <dc:creator>Balog, Krisztian</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Identifying the target types of entity-bearing queries can help improve
retrieval performance as well as the overall search experience. In this work,
we address the problem of automatically detecting the target types of a query
with respect to a type taxonomy. We propose a supervised learning approach with
a rich variety of features. Using a purpose-built test collection, we show that
our approach outperforms existing methods by a remarkable margin. This is an
extended version of the article published with the same title in the
Proceedings of SIGIR'17.
</dc:description>
 <dc:description>Comment: Extended version of SIGIR'17 short paper, 5 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06056</dc:identifier>
 <dc:identifier>doi:10.1145/3077136.3080659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06057</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Learning from Earth Observation and OpenStreetMap Data to Get
  Faster Better Semantic Maps</dc:title>
 <dc:creator>Audebert, Nicolas</dc:creator>
 <dc:creator>Saux, Bertrand Le</dc:creator>
 <dc:creator>Lef&#xe8;vre, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this work, we investigate the use of OpenStreetMap data for semantic
labeling of Earth Observation images. Deep neural networks have been used in
the past for remote sensing data classification from various sensors, including
multispectral, hyperspectral, SAR and LiDAR data. While OpenStreetMap has
already been used as ground truth data for training such networks, this
abundant data source remains rarely exploited as an input information layer. In
this paper, we study different use cases and deep network architectures to
leverage OpenStreetMap data for semantic labeling of aerial and satellite
images. Especially , we look into fusion based architectures and coarse-to-fine
segmentation to include the OpenStreetMap layer into multispectral-based deep
fully convolutional networks. We illustrate how these methods can be
successfully used on two public datasets: ISPRS Potsdam and DFC2017. We show
that OpenStreetMap data can efficiently be integrated into the vision-based
deep learning models and that it significantly improves both the accuracy
performance and the convergence speed of the networks.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06057</dc:identifier>
 <dc:identifier>EARTHVISION 2017 IEEE/ISPRS CVPR Workshop. Large Scale Computer
  Vision for Remote Sensing Imagery, Jul 2017, Honolulu, United States. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06058</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pitfalls and Best Practices in Algorithm Configuration</dc:title>
 <dc:creator>Eggensperger, Katharina</dc:creator>
 <dc:creator>Lindauer, Marius</dc:creator>
 <dc:creator>Hutter, Frank</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Good parameter settings are crucial to achieve high performance in many areas
of artificial intelligence (AI), such as satisfiability solving, AI planning,
scheduling, and machine learning (in particular deep learning). Automated
algorithm configuration methods have recently received much attention in the AI
community since they replace tedious, irreproducible and error-prone manual
parameter tuning and can lead to new state-of-the-art performance. However,
practical applications of algorithm configuration are prone to several (often
subtle) pitfalls in the experimental design that can render the procedure
ineffective. We identify several common issues and propose best practices for
avoiding them, including a tool called GenericWrapper4AC for preventing the
many possible problems in measuring the performance of the algorithm being
optimized by executing it in a standardized, controlled manner.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06070</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank 3 Inhabitation of Intersection Types Revisited (Extended Version)</dc:title>
 <dc:creator>Dudenhefner, Andrej</dc:creator>
 <dc:creator>Rehof, Jakob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We revisit the undecidability result of rank 3 intersection type inhabitation
(Urzyczyn 2009) in pursuit of two goals. First, we strengthen the previous
result by showing that intersection type inhabitation is undecidable for types
of rank 3 and order 3, i.e. it is not necessary to introduce new functional
dependencies (new instructions) during proof search. Second, we pinpoint the
principles necessary to simulate Turing machine computation directly, whereas
previous constructions used a highly parallel and non-deterministic computation
model. Since our construction is more concise than existing approaches taking
no detours, we believe that it is valuable for a better understanding of the
expressiveness of intersection type inhabitation.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06072</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Communications for Future Mobile Networks</dc:title>
 <dc:creator>Xiao, Ming</dc:creator>
 <dc:creator>Mumtaz, Shahid</dc:creator>
 <dc:creator>Huang, Yongming</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Yang, Kai</dc:creator>
 <dc:creator>Lin, Chih</dc:creator>
 <dc:creator>Ghosh, Amitava</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communications have recently attracted large
research interest, since the huge available bandwidth can potentially lead to
rates of multiple Gbps (gigabit per second) per user. Though mmWave can be
readily used in stationary scenarios such as indoor hotspots or backhaul, it is
challenging to use mmWave in mobile networks, where the transmitting/receiving
nodes may be moving, channels may have a complicated structure, and the
coordination among multiple nodes is difficult. To fully exploit the high
potential rates of mmWave in mobile networks, lots of technical problems must
be addressed. This paper presents a comprehensive survey of mmWave
communications for future mobile networks (5G and beyond). We first summarize
the recent channel measurement campaigns and modeling results. Then, we discuss
in detail recent progresses in multiple input multiple output (MIMO)
transceiver design for mmWave communications. After that, we provide an
overview of the solution for multiple access and backhauling, followed by
analysis of coverage and connectivity. Finally, the progresses in the
standardization and deployment of mmWave for mobile networks are discussed.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06073</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Superfast Line Spectral Estimation</dc:title>
 <dc:creator>Hansen, Thomas Lundgaard</dc:creator>
 <dc:creator>Fleury, Bernard Henri</dc:creator>
 <dc:creator>Rao, Bhaskar D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  A number of recent works have proposed to solve the line spectral estimation
problem by applying an off-the-grid ex- tension of sparse estimation
techniques. These methods are more advantageous than classical line spectral
estimation algorithms because they inherently estimate the model order.
However, they all have computation times which grow at least cubically in the
problem size, which limits their practical applicability for large problem
sizes. To alleviate this issue, we propose a low-complexity method for line
spectral estimation, which also draws on ideas from sparse estimation. Our
method is based on a probabilistic view of the problem. The signal covariance
matrix is shown to have Toeplitz structure, allowing superfast Toeplitz
inversion to be used. We demonstrate that our method achieves estimation
accuracy at least as good as current methods and that it does so while being
orders of magnitudes faster.
</dc:description>
 <dc:description>Comment: 13 pages, 4 figures, submitted to IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06086</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scratch iridescence: Wave-optical rendering of diffractive surface
  structure</dc:title>
 <dc:creator>Werner, Sebastian</dc:creator>
 <dc:creator>Velinov, Zdravko</dc:creator>
 <dc:creator>Jakob, Wenzel</dc:creator>
 <dc:creator>Hullin, Matthias B.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  The surface of metal, glass and plastic objects is often characterized by
microscopic scratches caused by manufacturing and/or wear. A closer look onto
such scratches reveals iridescent colors with a complex dependency on viewing
and lighting conditions. The physics behind this phenomenon is well understood;
it is caused by diffraction of the incident light by surface features on the
order of the optical wavelength. Existing analytic models are able to reproduce
spatially unresolved microstructure such as the iridescent appearance of
compact disks and similar materials. Spatially resolved scratches, on the other
hand, have proven elusive due to the highly complex wave-optical light
transport simulations needed to account for their appearance. In this paper, we
propose a wave-optical shading model based on non-paraxial scalar diffraction
theory to render this class of effects. Our model expresses surface roughness
as a collection of line segments. To shade a point on the surface, the
individual diffraction patterns for contributing scratch segments are computed
analytically and superimposed coherently. This provides natural transitions
from localized glint-like iridescence to smooth BRDFs representing the
superposition of many reflections at large viewing distances. We demonstrate
that our model is capable of recreating the overall appearance as well as
characteristic detail effects observed on real-world examples.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06091</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Registration of Gaussian Mixtures for Colour Transfer</dc:title>
 <dc:creator>Grogan, Mair&#xe9;ad</dc:creator>
 <dc:creator>Dahyot, Rozenn</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  We present a flexible approach to colour transfer inspired by techniques
recently proposed for shape registration. Colour distributions of the palette
and target images are modelled with Gaussian Mixture Models (GMMs) that are
robustly registered to infer a non linear parametric transfer function. We show
experimentally that our approach compares well to current techniques both
quantitatively and qualitatively. Moreover, our technique is computationally
the fastest and can take efficient advantage of parallel processing
architectures for recolouring images and videos. Our transfer function is
parametric and hence can be stored in memory for later usage and also combined
with other computed transfer functions to create interesting visual effects.
Overall this paper provides a fast user friendly approach to recolouring of
image and video materials.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06102</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient max-min and proportional fair constrained multiresource
  scheduling</dc:title>
 <dc:creator>Kesidis, George</dc:creator>
 <dc:creator>Shan, Yuquan</dc:creator>
 <dc:creator>Wang, Yujia</dc:creator>
 <dc:creator>Urgaonkar, Bhuvan</dc:creator>
 <dc:creator>Khamse-Ashari, Jalal</dc:creator>
 <dc:creator>Lambadaris, Ioanns</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We consider the problem of scheduling a group of heterogeneous, distributed
processes, with different relative priorities and service preferences, to a
group of heterogeneous virtual machines. Assuming linearly elastic IT resource
needs, we extend prior results on proportional fair and max-min fair scheduling
to a constrained multiresource case for a fam- ily of fairness criteria
(including our recently proposed Per- Server Dominant-Share Fairness).
Performance comparison is made by illustrative numerical example. We conclude
with a discussion of scheduling problems for a public cloud with heterogeneous
instances and servers.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06106</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unlabeled Data for Morphological Generation With Character-Based
  Sequence-to-Sequence Models</dc:title>
 <dc:creator>Kann, Katharina</dc:creator>
 <dc:creator>Sch&#xfc;tze, Hinrich</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a semi-supervised way of training a character-based
encoder-decoder recurrent neural network for morphological reinflection, the
task of generating one inflected word form from another. This is achieved by
using unlabeled tokens or random strings as training data for an autoencoding
task, adapting a network for morphological reinflection, and performing
multi-task training. We thus use limited labeled data more effectively,
obtaining up to 9.9% improvement over state-of-the-art baselines for 8
different languages.
</dc:description>
 <dc:description>Comment: Accepted at SCLeM 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06110</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Applied Evaluative Informetrics: Part 1</dc:title>
 <dc:creator>Moed, Henk F.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This manuscript is a preprint version of Part 1 (General Introduction and
Synopsis) of the book Applied Evaluative Informetrics, to be published by
Springer in the summer of 2017. This book presents an introduction to the field
of applied evaluative informetrics, and is written for interested scholars and
students from all domains of science and scholarship. It sketches the field's
history, recent achievements, and its potential and limits. It explains the
notion of multi-dimensional research performance, and discusses the pros and
cons of 28 citation-, patent-, reputation- and altmetrics-based indicators. In
addition, it presents quantitative research assessment as an evaluation
science, and focuses on the role of extra-informetric factors in the
development of indicators, and on the policy context of their application. It
also discusses the way forward, both for users and for developers of
informetric tools.
</dc:description>
 <dc:description>Comment: The posted version is a preprint (author copy) of Part 1 (General
  Introduction and Synopsis) of a book entitled Applied Evaluative
  Bibliometrics, to be published by Springer in the summer of 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06113</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Sum Secrecy Rate Optimization for MIMO Two-way Full Duplex
  Systems</dc:title>
 <dc:creator>Chu, Zheng</dc:creator>
 <dc:creator>Le, Tuan Anh</dc:creator>
 <dc:creator>Nguyen, Huan X.</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Karamanoglu, Mehmet</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers multiple-input multiple-output (MIMO) full-duplex (FD)
two-way secrecy systems. Specifically, both multi-antenna FD legitimate nodes
exchange their own confidential message in the presence of an eavesdropper.
Taking into account the imperfect channel state information (CSI) of the
eavesdropper, we formulate a robust sum secrecy rate maximization (RSSRM)
problem subject to the outage probability constraint of the achievable sum
secrecy rate and the transmit power constraint. Unlike other existing channel
uncertainty models, e.g., norm-bounded and Gaussian-distribution, we exploit a
moment-based random distributed CSI channel uncertainty model to recast our
formulate RSSRM problem into the convex optimization frameworks based on a
Markov's inequality and robust conic reformulation, i.e., semidefinite
programming (SDP). In addition, difference-of-concave (DC) approximation is
employed to iteratively tackle the transmit covariance matrices of these
legitimate nodes. Simulation results are provided to validate our proposed FD
approaches.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures, to appear in Proc. VTC Fall, Toronto, Canada,
  Sept. 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06113</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06123</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JCTC: A Large Job posting Corpus for Text Classification</dc:title>
 <dc:creator>Xu, Haoyu</dc:creator>
 <dc:creator>Gu, Chongyang</dc:creator>
 <dc:creator>Zhou, Han</dc:creator>
 <dc:creator>Kou, Sengpan</dc:creator>
 <dc:creator>Zhang, Junjie</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The absence of an appropriate text classification corpus makes the massive
amount of online job information unusable for labor market analysis. This paper
presents JCTC, a large job posting corpus for text classification. In JCTC
construction framework, a formal specification issued by the Chinese central
government is chosen as the classification standard. The unsupervised learning
(WE-cos), supervised learning algorithm (SVM) and human judgements are all used
in the construction process. JCTC has 102581 online job postings distributed in
465 categories. The method proposed here can not only ameliorate the high
demands on people's skill and knowledge, but reduce the subjective influences
as well. Besides, the method is not limited in Chinese. We benchmark five
state-of-the-art deep learning approaches on JCTC providing baseline results
for future studies. JCTC might be the first job posting corpus for text
classification and the largest one in Chinese. With the help of JCTC, related
organizations are able to monitor, analyze and predict the labor market in a
comprehensive, accurate and timely manner.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06125</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Sequence Similarity from Read Sets for Clustering
  Next-Generation Sequencing data</dc:title>
 <dc:creator>Ry&#x161;av&#xfd;, Petr</dc:creator>
 <dc:creator>&#x17d;elezn&#xfd;, Filip</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  To cluster sequences given only their read-set representations, one may try
to reconstruct each one from the corresponding read set, and then employ
conventional (dis)similarity measures such as the edit distance on the
assembled sequences. This approach is however problematic and we propose
instead to estimate the similarities directly from the read sets. Our approach
is based on an adaptation of the Monge-Elkan similarity known from the field of
databases. It avoids the NP-hard problem of sequence assembly. For low coverage
data it results in a better approximation of the true sequence similarities and
consequently in better clustering, in comparison to the
first-assemble-then-cluster approach.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06130</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and Performance of Coalitions of Prosumers Through
  Diversification in the Smart Grid</dc:title>
 <dc:creator>Gensollen, Nicolas</dc:creator>
 <dc:creator>Gauthier, Vincent</dc:creator>
 <dc:creator>Becker, Monique</dc:creator>
 <dc:creator>Marot, Michel</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Achieving a successful energetic transition through a smarter and greener
electricity grid is a major goal for the 21st century. It is assumed that such
smart grids will be characterized by bidirectional electricity flows coupled
with the use of small renewable generators and a proper efficient information
system. All these bricks might enable end users to take part in the grid
stability by injecting power, or by shaping their consumption against financial
compensation. In this paper, we propose an algorithm that forms coalitions of
agents, called prosumers, that both produce and consume. It is designed to be
used by aggregators that aim at selling the aggregated surplus of production of
the prosumers they control. We rely on real weather data sampled across
stations of a given territory in order to simulate realistic production and
consumption patterns for each prosumer. This approach enables us to capture
geographical correlations among the agents while preserving the diversity due
to different behaviors. As aggregators are bound to the grid operator by a
contract, they seek to maximize their offer while minimizing their risk. The
proposed graph based algorithm takes the underlying correlation structure of
the agents into account and outputs coalitions with both high productivity and
low variability. We show then that the resulting diversified coalitions are
able to generate higher benefits on a constrained energy market, and are more
resilient to random failures of the agents.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Smart Grid (2016)</dc:description>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06130</dc:identifier>
 <dc:identifier>doi:10.1109/TSG.2016.2572302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06134</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia
  Programming Language</dc:title>
 <dc:creator>Fieker, Claus</dc:creator>
 <dc:creator>Hart, William</dc:creator>
 <dc:creator>Hofmann, Tommy</dc:creator>
 <dc:creator>Johansson, Fredrik</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We introduce two new packages, Nemo and Hecke, written in the Julia
programming language for computer algebra and number theory. We demonstrate
that high performance generic algorithms can be implemented in Julia, without
the need to resort to a low-level C implementation. For specialised algorithms,
we use Julia's efficient native C interface to wrap existing C/C++ libraries
such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke
and Nemo and discuss some algorithms that we have implemented to provide high
performance basic arithmetic.
</dc:description>
 <dc:description>Comment: ISSAC '17, Kaiserslautern, Germany, July 25-28, 2017, 8 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06134</dc:identifier>
 <dc:identifier>doi:10.1145/3087604.3087611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06135</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Odyssey Approach for Optimizing Federated SPARQL Queries</dc:title>
 <dc:creator>Montoya, Gabriela</dc:creator>
 <dc:creator>Skaf-Molli, Hala</dc:creator>
 <dc:creator>Hose, Katja</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Answering queries over a federation of SPARQL endpoints requires combining
data from more than one data source. Optimizing queries in such scenarios is
particularly challenging not only because of (i) the large variety of possible
query execution plans that correctly answer the query but also because (ii)
there is only limited access to statistics about schema and instance data of
remote sources. To overcome these challenges, most federated query engines rely
on heuristics to reduce the space of possible query execution plans or on
dynamic programming strategies to produce optimal plans. Nevertheless, these
plans may still exhibit a high number of intermediate results or high execution
times because of heuristics and inaccurate cost estimations. In this paper, we
present Odyssey, an approach that uses statistics that allow for a more
accurate cost estimation for federated queries and therefore enables Odyssey to
produce better query execution plans. Our experimental results show that
Odyssey produces query execution plans that are better in terms of data
transfer and execution time than state-of-the-art optimizers. Our experiments
using the FedBench benchmark show execution time gains of at least 25 times on
average.
</dc:description>
 <dc:description>Comment: 16 pages, 10 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06135</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-68288-4_28</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06148</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DS++: A flexible, scalable and provably tight relaxation for matching
  problems</dc:title>
 <dc:creator>Dym, Nadav</dc:creator>
 <dc:creator>Maron, Haggai</dc:creator>
 <dc:creator>Lipman, Yaron</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Correspondence problems are often modelled as quadratic optimization problems
over permutations. Common scalable methods for approximating solutions of these
NP-hard problems are the spectral relaxation for non-convex energies and the
doubly stochastic (DS) relaxation for convex energies. Lately, it has been
demonstrated that semidefinite programming relaxations can have considerably
improved accuracy at the price of a much higher computational cost. We present
a convex quadratic programming relaxation which is provably stronger than both
DS and spectral relaxations, with the same scalability as the DS relaxation.
The derivation of the relaxation also naturally suggests a projection method
for achieving meaningful integer solutions which improves upon the standard
closest-permutation projection. Our method can be easily extended to
optimization over doubly stochastic matrices, partial or injective matching,
and problems with additional linear constraints. We employ recent advances in
optimization of linear-assignment type problems to achieve an efficient
algorithm for solving the convex relaxation.
  We present experiments indicating that our method is more accurate than local
minimization or competing relaxations for non-convex problems. We successfully
apply our algorithm to shape matching and to the problem of ordering images in
a grid, obtaining results which compare favorably with state of the art
methods. We believe our results indicate that our method should be considered
the method of choice for quadratic optimization over permutations.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06149</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel-in-Space-and-Time Simulation of the Three-Dimensional, Unsteady
  Navier-Stokes Equations for Incompressible Flow</dc:title>
 <dc:creator>Croce, Roberto</dc:creator>
 <dc:creator>Ruprecht, Daniel</dc:creator>
 <dc:creator>Krause, Rolf</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper we combine the Parareal parallel-in-time method together with
spatial parallelization and investigate this space-time parallel scheme by
means of solving the three-dimensional incompressible Navier-Stokes equations.
Parallelization of time stepping provides a new direction of parallelization
and allows to employ additional cores to further speed up simulations after
spatial parallelization has saturated. We report on numerical experiments
performed on a Cray XE6, simulating a driven cavity flow with and without
obstacles. Distributed memory parallelization is used in both space and time,
featuring up to 2,048 cores in total. It is confirmed that the
space-time-parallel method can provide speedup beyond the saturation of the
spatial parallelization.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06149</dc:identifier>
 <dc:identifier>Modeling, Simulation and Optimization of Complex Processes - HPSC
  2012, Springer International Publishing, pages 13-23, 2014</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-09063-4_2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06158</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Operational Framework for Specifying Memory Models using
  Instantaneous Instruction Execution</dc:title>
 <dc:creator>Zhang, Sizhuo</dc:creator>
 <dc:creator>Vijayaraghavan, Muralidaran</dc:creator>
 <dc:creator>Arvind</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  There has been great progress recently in formally specifying the memory
model of microprocessors like ARM and POWER. These specifications are, however,
too complicated for reasoning about program behaviors, verifying compilers
etc., because they involve microarchitectural details like the reorder buffer
(ROB), partial and speculative execution, instruction replay on speculation
failure, etc. In this paper we present a new Instantaneous Instruction
Execution (I2E) framework which allows us to specify weak memory models in the
same style as SC and TSO. Each instruction in I2E is executed instantaneously
and in-order such that the state of the processor is always correct. The effect
of instruction reordering is captured by the way data is moved between the
processors and the memory non-deterministically, using three conceptual
devices: invalidation buffers, timestamps and dynamic store buffers. We prove
that I2E models capture the behaviors of modern microarchitectures and
cache-coherent memory systems accurately, thus eliminating the need to think
about microarchitectural details.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1606.05416</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06158</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06173</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-stabilising Byzantine Clock Synchronisation is Almost as Easy as
  Consensus</dc:title>
 <dc:creator>Lenzen, Christoph</dc:creator>
 <dc:creator>Rybicki, Joel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We give fault-tolerant algorithms for establishing synchrony in distributed
systems in which each of the $n$ nodes has its own clock. Our algorithms
operate in a very strong fault model: we require self-stabilisation, i.e., the
initial state of the system may be arbitrary, and there can be up to $f&lt;n/3$
ongoing Byzantine faults, i.e., nodes that deviate from the protocol in an
arbitrary manner. Furthermore, we assume that the local clocks of the nodes may
progress at different speeds (clock drift) and communication has bounded delay.
In this model, we study the pulse synchronisation problem, where the task is to
guarantee that eventually all correct nodes generate well-separated local pulse
events (i.e., unlabelled logical clock ticks) in a synchronised manner.
  Compared to prior work, we achieve exponential improvements in stabilisation
time and the number of communicated bits, and give the first sublinear-time
algorithm for the problem:
  - In the deterministic setting, the state-of-the-art solutions stabilise in
time $\Theta(f)$ and have each node broadcast $\Theta(f \log f)$ bits per time
unit. We exponentially reduce the number of bits broadcasted per time unit to
$\Theta(\log f)$ while retaining the same stabilisation time.
  - In the randomised setting, the state-of-the-art solutions stabilise in time
$\Theta(f)$ and have each node broadcast $O(1)$ bits per time unit. We
exponentially reduce the stabilisation time to $\log^{O(1)} f$ while each node
broadcasts $\log^{O(1)} f$ bits per time unit.
  These results are obtained by means of a recursive approach reducing the
above task of self-stabilising pulse synchronisation in the bounded-delay model
to non-self-stabilising binary consensus in the synchronous model. In general,
our approach introduces at most logarithmic overheads in terms of stabilisation
time and broadcasted bits over the underlying consensus routine.
</dc:description>
 <dc:description>Comment: 56+2 pages, 12 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06173</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06180</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TSP With Locational Uncertainty: The Adversarial Model</dc:title>
 <dc:creator>Citovsky, Gui</dc:creator>
 <dc:creator>Mayer, Tyler</dc:creator>
 <dc:creator>Mitchell, Joseph S. B.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper we study a natural special case of the Traveling Salesman
Problem (TSP) with point-locational-uncertainty which we will call the {\em
adversarial TSP} problem (ATSP). Given a metric space $(X, d)$ and a set of
subsets $R = \{R_1, R_2, ... , R_n\} : R_i \subseteq X$, the goal is to devise
an ordering of the regions, $\sigma_R$, that the tour will visit such that when
a single point is chosen from each region, the induced tour over those points
in the ordering prescribed by $\sigma_R$ is as short as possible. Unlike the
classical locational-uncertainty-TSP problem, which focuses on minimizing the
expected length of such a tour when the point within each region is chosen
according to some probability distribution, here, we focus on the {\em
adversarial model} in which once the choice of $\sigma_R$ is announced, an
adversary selects a point from each region in order to make the resulting tour
as long as possible. In other words, we consider an offline problem in which
the goal is to determine an ordering of the regions $R$ that is optimal with
respect to the &quot;worst&quot; point possible within each region being chosen by an
adversary, who knows the chosen ordering. We give a $3$-approximation when $R$
is a set of arbitrary regions/sets of points in a metric space. We show how
geometry leads to improved constant factor approximations when regions are
parallel line segments of the same lengths, and a polynomial-time approximation
scheme (PTAS) for the important special case in which $R$ is a set of disjoint
unit disks in the plane.
</dc:description>
 <dc:description>Comment: To appear, International Symposium on Computational Geometry (SoCG
  2017)</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06180</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.SoCG.2017.32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06181</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum degeneracy and impact on extrapolation and sampling for
  functions on branching lines</dc:title>
 <dc:creator>Dokuchaev, Nikolai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>42A38, 93E10, 562M15, 42B30</dc:subject>
 <dc:description>  The paper studies functions defined on continuous branching lines connected
into a system. A notion of spectrum degeneracy for these functions is
introduced. This degeneracy is based on the properties of the Fourier
transforms for processes representing functions on the branches that are deemed
to be extended onto the real axis. This spectrum degeneracy ensures some
opportunities for extrapolation and sampling. The topology of the system is
taken into account via a restriction that these processes coincides on certain
parts of real axis. It is shown that processes with this spectrum degeneracy
are everywhere dense in the set of processes equivalent to functions on the
branching lines. Some applications to extrapolation and sampling are
considered.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06196</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Magnetic-Visual Sensor Fusion based Medical SLAM for Endoscopic Capsule
  Robot</dc:title>
 <dc:creator>Turan, Mehmet</dc:creator>
 <dc:creator>Almalioglu, Yasin</dc:creator>
 <dc:creator>Gilbert, Hunter</dc:creator>
 <dc:creator>Araujo, Helder</dc:creator>
 <dc:creator>Konukoglu, Ender</dc:creator>
 <dc:creator>Sitti, Metin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A reliable, real-time simultaneous localization and mapping (SLAM) method is
crucial for the navigation of actively controlled capsule endoscopy robots.
These robots are an emerging, minimally invasive diagnostic and therapeutic
technology for use in the gastrointestinal (GI) tract. In this study, we
propose a dense, non-rigidly deformable, and real-time map fusion approach for
actively controlled endoscopic capsule robot applications. The method combines
magnetic and vision based localization, and makes use of frame-to-model fusion
and model-to-model loop closure. The performance of the method is demonstrated
using an ex-vivo porcine stomach model. Across four trajectories of varying
speed and complexity, and across three cameras, the root mean square
localization errors range from 0.42 to 1.92 cm, and the root mean square
surface reconstruction errors range from 1.23 to 2.39 cm.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06201</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Cooperative Navigation in Dense Human Crowds</dc:title>
 <dc:creator>Vemula, Anirudh</dc:creator>
 <dc:creator>Muelling, Katharina</dc:creator>
 <dc:creator>Oh, Jean</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  For robots to be a part of our daily life, they need to be able to navigate
among crowds not only safely but also in a socially compliant fashion. This is
a challenging problem because humans tend to navigate by implicitly cooperating
with one another to avoid collisions, while heading toward their respective
destinations. Previous approaches have used hand-crafted functions based on
proximity to model human-human and human-robot interactions. However, these
approaches can only model simple interactions and fail to generalize for
complex crowded settings. In this paper, we develop an approach that models the
joint distribution over future trajectories of all interacting agents in the
crowd, through a local interaction model that we train using real human
trajectory data. The interaction model infers the velocity of each agent based
on the spatial orientation of other agents in his vicinity. During prediction,
our approach infers the goal of the agent from its past trajectory and uses the
learned model to predict its future trajectory. We demonstrate the performance
of our method against a state-of-the-art approach on a public dataset and show
that our model outperforms when predicting future trajectories for longer
horizons.
</dc:description>
 <dc:description>Comment: Accepted at ICRA 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06202</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Access for LIGO on the OSG</dc:title>
 <dc:creator>Weitzel, Derek</dc:creator>
 <dc:creator>Bockelman, Brian</dc:creator>
 <dc:creator>Brown, Duncan A.</dc:creator>
 <dc:creator>Couvares, Peter</dc:creator>
 <dc:creator>W&#xfc;rthwein, Frank</dc:creator>
 <dc:creator>Hernandez, Edgar Fajardo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:description>  During 2015 and 2016, the Laser Interferometer Gravitational-Wave Observatory
(LIGO) conducted a three-month observing campaign. These observations delivered
the first direct detection of gravitational waves from binary black hole
mergers. To search for these signals, the LIGO Scientific Collaboration uses
the PyCBC search pipeline. To deliver science results in a timely manner, LIGO
collaborated with the Open Science Grid (OSG) to distribute the required
computation across a series of dedicated, opportunistic, and allocated
resources. To deliver the petabytes necessary for such a large-scale
computation, our team deployed a distributed data access infrastructure based
on the XRootD server suite and the CernVM File System (CVMFS). This data access
strategy grew from simply accessing remote storage to a POSIX-based interface
underpinned by distributed, secure caches across the OSG.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, submitted to PEARC17</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06208</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical organization of H. Eugene Stanley scientific collaboration
  community in weighted network representation</dc:title>
 <dc:creator>Drozdz, Stanislaw</dc:creator>
 <dc:creator>Kulig, Andrzej</dc:creator>
 <dc:creator>Kwapien, Jaroslaw</dc:creator>
 <dc:creator>Niewiarowski, Artur</dc:creator>
 <dc:creator>Stanuszek, Marek</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Quantitative Finance - Computational Finance</dc:subject>
 <dc:description>  By mapping the most advanced elements of the contemporary social
interactions, the world scientific collaboration network develops an extremely
involved and heterogeneous organization. Selected characteristics of this
heterogeneity are studied here and identified by focusing on the scientific
collaboration community of H. Eugene Stanley - one of the most prolific world
scholars at the present time. Based on the Web of Science records as of March
28, 2016, several variants of networks are constructed. It is found that the
Stanley #1 network - this in analogy to the Erd\H{o}s # - develops a largely
consistent hierarchical organization and Stanley himself obeys rules of the
same hierarchy. However, this is seen exclusively in the weighted network
representation. When such a weighted network is evolving, an existing relevant
model indicates that the spread of weight gets stimulation to the
multiplicative bursts over the neighbouring nodes, which leads to a balanced
growth of interconnections among them. While not exclusive to Stanley, such a
behaviour is not a rule, however. Networks of other outstanding scholars
studied here more often develop a star-like form and the central hubs
constitute the outliers. This study is complemented by a spectral analysis of
the normalised Laplacian matrices derived from the weighted variants of the
corresponding networks and, among others, it points to the efficiency of such a
procedure for identifying the component communities and relations among them in
the complex weighted networks.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06208</dc:identifier>
 <dc:identifier>Journal of Informetrics 11, 1114-1127 (2017)</dc:identifier>
 <dc:identifier>doi:10.1016/j.joi.2017.09.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06211</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Investigation of Newton-Sketch and Subsampled Newton Methods</dc:title>
 <dc:creator>Berahas, Albert S.</dc:creator>
 <dc:creator>Bollapragada, Raghu</dc:creator>
 <dc:creator>Nocedal, Jorge</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The concepts of sketching and subsampling have recently received much
attention by the optimization and statistics communities. In this paper, we
study Newton-Sketch and Subsampled Newton (SSN) methods for the finite-sum
optimization problem. We consider practical versions of the two methods in
which the Newton equations are solved approximately using the conjugate
gradient (CG) method or a stochastic gradient iteration. We establish new
complexity results for the SSN-CG method that exploit the spectral properties
of CG. Controlled numerical experiments compare the relative strengths of
Newton-Sketch and SSN methods and show that for many finite-sum problems, they
are far more efficient than SVRG, a popular first-order method.
</dc:description>
 <dc:description>Comment: 29 pages, 26 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06214</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Characterization Theorem for a Modal Description Logic</dc:title>
 <dc:creator>Wild, Paul</dc:creator>
 <dc:creator>Schr&#xf6;der, Lutz</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>03B45, 03B42, 03B70, 03B10, 03C80</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  Modal description logics feature modalities that capture dependence of
knowledge on parameters such as time, place, or the information state of
agents. E.g., the logic S5-ALC combines the standard description logic ALC with
an S5-modality that can be understood as an epistemic operator or as
representing (undirected) change. This logic embeds into a corresponding modal
first-order logic S5-FOL. We prove a modal characterization theorem for this
embedding, in analogy to results by van Benthem and Rosen relating ALC to
standard first-order logic: We show that S5-ALC with only local roles is, both
over finite and over unrestricted models, precisely the bisimulation invariant
fragment of S5-FOL, thus giving an exact description of the expressive power of
S5-ALC with only local roles.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06215</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixing MACs: An Introduction to Hybrid Radio Wireless Virtualization</dc:title>
 <dc:creator>Bhanage, Gautam</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This study presents the design of the hybrid wireless virtualization HWV
controller based network architecture. Using a HWV controller, an unified
approach can be taken for provisioning and management of virtualized
heterogeneous radios, irrespective of their MAC and PHY layer mechanisms. It is
shown that the airtime occupancy by transmissions from different slices or
groups can be used as a single metric for tying these virtualized platforms.
The HWV controller can account and dynamically reprovision slice quotas, which
can be used for maximizing the revenue of the network operator or aggregate
system throughput performance. Results from simulations show that an HWV
controller based infrastructure is able to improve the revenue generated from a
single virtualized basestation and an AP by up to 40 percent under tested
conditions.
</dc:description>
 <dc:description>Comment: 6 pages, 7 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06216</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher-Order Constrained Horn Clauses and Refinement Types</dc:title>
 <dc:creator>Burn, Toby Cathcart</dc:creator>
 <dc:creator>Ong, C. -H. Luke</dc:creator>
 <dc:creator>Ramsay, Steven J.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Motivated by applications in automated verification of higher-order
functional programs, we develop a notion of constrained Horn clauses in
higher-order logic and a decision problem concerning their satisfiability. We
show that, although satisfiable systems of higher-order clauses do not
generally have least models, there is a notion of canonical model obtained
through a reduction to a problem concerning a kind of monotone logic program.
Following work in higher-order program verification, we develop a refinement
type system in order to reason about and automate the search for models. This
provides a sound but incomplete method for solving the decision problem.
Finally, we show that an extension of the decision problem in which refinement
types are used directly as guards on existential quantifiers can be reduced to
the original problem. This result can be used to show that properties of
higher-order functions that are definable using refinement types are also
expressible using higher-order constrained Horn clauses.
</dc:description>
 <dc:description>Comment: Completely rewritten Section 4.3 on the correspondence between models
  to improve the clarity of the exposition. Various other minor improvements</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06218</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stories From the Past Web</dc:title>
 <dc:creator>AlNoamany, Yasmin</dc:creator>
 <dc:creator>Weigle, Michele C.</dc:creator>
 <dc:creator>Nelson, Michael L.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Archiving Web pages into themed collections is a method for ensuring these
resources are available for posterity. Services such as Archive-It exists to
allow institutions to develop, curate, and preserve collections of Web
resources. Understanding the contents and boundaries of these archived
collections is a challenge for most people, resulting in the paradox of the
larger the collection, the harder it is to understand. Meanwhile, as the sheer
volume of data grows on the Web, &quot;storytelling&quot; is becoming a popular technique
in social media for selecting Web resources to support a particular narrative
or &quot;story&quot;. There are multiple stories that can be generated from an archived
collection with different perspectives about the collection. For example, a
user may want to see a story that is composed of the key events from a specific
Web site, a story that is composed of the key events of the story regardless of
the sources, or how a specific event at a specific point in time was covered by
different Web sites, etc. In this paper, we provide different case studies for
possible types of stories that can be extracted from a collection. We also
provide the definitions and models of these types of stories.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06224</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Processing of Mobile Sensor Data for Continual Deep Learning
  Predictions</dc:title>
 <dc:creator>Katevas, Kleomenis</dc:creator>
 <dc:creator>Leontiadis, Ilias</dc:creator>
 <dc:creator>Pielot, Martin</dc:creator>
 <dc:creator>Serr&#xe0;, Joan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present a practical approach for processing mobile sensor time series data
for continual deep learning predictions. The approach comprises data cleaning,
normalization, capping, time-based compression, and finally classification with
a recurrent neural network. We demonstrate the effectiveness of the approach in
a case study with 279 participants. On the basis of sparse sensor events, the
network continually predicts whether the participants would attend to a
notification within 10 minutes. Compared to a random baseline, the classifier
achieves a 40% performance increase (AUC of 0.702) on a withheld test set. This
approach allows to forgo resource-intensive, domain-specific, error-prone
feature engineering, which may drastically increase the applicability of
machine learning to mobile phone sensor data.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06224</dc:identifier>
 <dc:identifier>DeepMobile Workshop, MobileHCI 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3089801.3089802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06227</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design, analysis and implementation of electronic test for knowledge
  evaluation in the course of Information Technologies for pharmaceutical
  students</dc:title>
 <dc:creator>Manev, Hristo</dc:creator>
 <dc:creator>Manev, Mancho</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>97U50</dc:subject>
 <dc:description>  The increased usage of the information technologies in everyday life and
especially in education leads to demands for new forms of teaching, studying
and appropriate examination and evaluation of acquired knowledge and skills of
the students. Modern electronic educational systems use only those technologies
that improve the learning process and make it more effective. The interactive
education provides an opportunity to develop skills for independent literature
research and activation of the cognitive activity. In this work, it is shown
how a modern electronic education is implemented in the curriculum of English
language pharmaceutical students at the Medical University - Plovdiv in the
course of Information Technologies. It is developed a methodological approach
of a hybrid system, i.e. a compulsory attendance at lectures in combination
with two different types of conduction of the final test for comparison - a
paper-based test and a remote web-based one. The results received from the
parallel tests are processed and analysed and the conclusions are used to
enhance the quality of the developed test and the type of implementation.
Moreover, the examined students fill in an anonymous poll to show the authors
their thoughts for this type of hybrid educational system.
</dc:description>
 <dc:description>Comment: 6 pages, presented at CBU International Conference: Innovations in
  Science and Education, March 22-24, 2017, Prague, Czech Republic</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06227</dc:identifier>
 <dc:identifier>CBU International Conference Proceedings: Innovations in Science
  and Education, vol. 5 (2017), 705-709</dc:identifier>
 <dc:identifier>doi:10.12955/cbup.v5.1011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06242</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Range-Clustering Queries</dc:title>
 <dc:creator>Abrahamsen, Mikkel</dc:creator>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Buchin, Kevin</dc:creator>
 <dc:creator>Mehr, Mehran</dc:creator>
 <dc:creator>Mehrabi, Ali D.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  In a geometric $k$-clustering problem the goal is to partition a set of
points in $\mathbb{R}^d$ into $k$ subsets such that a certain cost function of
the clustering is minimized. We present data structures for orthogonal
range-clustering queries on a point set $S$: given a query box $Q$ and an
integer $k&gt;2$, compute an optimal $k$-clustering for $S\setminus Q$. We obtain
the following results. We present a general method to compute a
$(1+\epsilon)$-approximation to a range-clustering query, where $\epsilon&gt;0$ is
a parameter that can be specified as part of the query. Our method applies to a
large class of clustering problems, including $k$-center clustering in any
$L_p$-metric and a variant of $k$-center clustering where the goal is to
minimize the sum (instead of maximum) of the cluster sizes. We extend our
method to deal with capacitated $k$-clustering problems, where each of the
clusters should not contain more than a given number of points. For the special
cases of rectilinear $k$-center clustering in $\mathbb{R}^1$, and in
$\mathbb{R}^2$ for $k=2$ or 3, we present data structures that answer
range-clustering queries exactly.
</dc:description>
 <dc:description>Comment: 23 pages and 2 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06243</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Represent Haptic Feedback for Partially-Observable Tasks</dc:title>
 <dc:creator>Sung, Jaeyong</dc:creator>
 <dc:creator>Salisbury, J. Kenneth</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The sense of touch, being the earliest sensory system to develop in a human
body [1], plays a critical part of our daily interaction with the environment.
In order to successfully complete a task, many manipulation interactions
require incorporating haptic feedback. However, manually designing a feedback
mechanism can be extremely challenging. In this work, we consider manipulation
tasks that need to incorporate tactile sensor feedback in order to modify a
provided nominal plan. To incorporate partial observation, we present a new
framework that models the task as a partially observable Markov decision
process (POMDP) and learns an appropriate representation of haptic feedback
which can serve as the state for a POMDP model. The model, that is parametrized
by deep recurrent neural networks, utilizes variational Bayes methods to
optimize the approximate posterior. Finally, we build on deep Q-learning to be
able to select the optimal action in each state without access to a simulator.
We test our model on a PR2 robot for multiple tasks of turning a knob until it
clicks.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Robotics and Automation (ICRA), 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06247</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Ramp Schemes and Related Combinatorial Objects</dc:title>
 <dc:creator>Stinson, Douglas R.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>94A62 (Primary) 05B15 (Secondary)</dc:subject>
 <dc:description>  In 1996, Jackson and Martin proved that a strong ideal ramp scheme is
equivalent to an orthogonal array. However, there was no good characterization
of ideal ramp schemes that are not strong. Here we show the equivalence of
ideal ramp schemes to a new variant of orthogonal arrays that we term augmented
orthogonal arrays. We give some constructions for these new kinds of arrays,
and, as a consequence, we also provide parameter situations where ideal ramp
schemes exist but strong ideal ramp schemes do not exist.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06250</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape Classification using Spectral Graph Wavelets</dc:title>
 <dc:creator>Masoumi, Majid</dc:creator>
 <dc:creator>Hamza, A. Ben</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Spectral shape descriptors have been used extensively in a broad spectrum of
geometry processing applications ranging from shape retrieval and segmentation
to classification. In this pa- per, we propose a spectral graph wavelet
approach for 3D shape classification using the bag-of-features paradigm. In an
effort to capture both the local and global geometry of a 3D shape, we present
a three-step feature description framework. First, local descriptors are
extracted via the spectral graph wavelet transform having the Mexican hat
wavelet as a generating ker- nel. Second, mid-level features are obtained by
embedding lo- cal descriptors into the visual vocabulary space using the soft-
assignment coding step of the bag-of-features model. Third, a global descriptor
is constructed by aggregating mid-level fea- tures weighted by a geodesic
exponential kernel, resulting in a matrix representation that describes the
frequency of appearance of nearby codewords in the vocabulary. Experimental
results on two standard 3D shape benchmarks demonstrate the effective- ness of
the proposed classification approach in comparison with state-of-the-art
methods.
</dc:description>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06260</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A deep level set method for image segmentation</dc:title>
 <dc:creator>Tang, Min</dc:creator>
 <dc:creator>Valipour, Sepehr</dc:creator>
 <dc:creator>Zhang, Zichen Vincent</dc:creator>
 <dc:creator>Cobzas, Dana</dc:creator>
 <dc:creator>MartinJagersand</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel image segmentation approachthat integrates fully
convolutional networks (FCNs) with a level setmodel. Compared with a FCN, the
integrated method can incorporatesmoothing and prior information to achieve an
accurate segmentation.Furthermore, different than using the level set model as
a post-processingtool, we integrate it into the training phase to fine-tune the
FCN. Thisallows the use of unlabeled data during training in a
semi-supervisedsetting. Using two types of medical imaging data (liver CT and
left ven-tricle MRI data), we show that the integrated method achieves
goodperformance even when little training data is available, outperformingthe
FCN or the level set model alone.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06262</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utility of general and specific word embeddings for classifying
  translational stages of research</dc:title>
 <dc:creator>Major, Vincent</dc:creator>
 <dc:creator>Surkis, Alisa</dc:creator>
 <dc:creator>Aphinyanaphongs, Yindalon</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Conventional text classification models make a bag-of-words assumption
reducing text, fundamentally a sequence of words, into word occurrence counts
per document. Recent algorithms such as word2vec and fastText are capable of
learning semantic meaning and similarity between words in an entirely
unsupervised manner using a contextual window and doing so much faster than
previous methods. Each word is represented as a vector such that similar
meaning words such as 'strong' and 'powerful' are in the same general Euclidian
space. Open questions about these embeddings include their usefulness across
classification tasks and the optimal set of documents to build the embeddings.
In this work, we demonstrate the usefulness of embeddings for improving the
state of the art in classification for our tasks and demonstrate that specific
word embeddings built in the domain and for the tasks can improve performance
over general word embeddings (learnt on news articles, Wikipedia or PubMed).
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06264</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Diagnostics: Applying Convolutional Neural Networks for Vessels
  Defects Detection</dc:title>
 <dc:creator>Filippov, Stanislav</dc:creator>
 <dc:creator>Moiseev, Arsenii</dc:creator>
 <dc:creator>Andrey, Andronenko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Coronary angiography is considered to be a safe tool for the evaluation of
coronary artery disease and perform in approximately 12 million patients each
year worldwide. [1] In most cases, angiograms are manually analyzed by a
cardiologist. Actually, there are no clinical practice algorithms which could
improve and automate this work. Neural networks show high efficiency in tasks
of image analysis and they can be used for the analysis of angiograms and
facilitate diagnostics. We have developed an algorithm based on Convolutional
Neural Network and Neural Network U-Net [2] for vessels segmentation and
defects detection such as stenosis. For our research we used anonymized
angiography data obtained from one of the city's hospitals and augmented them
to improve learning efficiency. U-Net usage provided high quality segmentation
and the combination of our algorithm with an ensemble of classifiers shows a
good accuracy in the task of ischemia evaluation on test data. Subsequently,
this approach can be served as a basis for the creation of an analytical system
that could speed up the diagnosis of cardiovascular diseases and greatly
facilitate the work of a specialist.
</dc:description>
 <dc:description>Comment: Complaint to the article due to low research quality</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06266</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Parallel Solver for Graph Laplacians</dc:title>
 <dc:creator>Konolige, Tristan</dc:creator>
 <dc:creator>Brown, Jed</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Problems from graph drawing, spectral clustering, network flow and graph
parti- tioning all can be expressed as Laplacian matrices. Theoretically fast
approaches to solving these problems exist, but in practice these techniques
are slow. Three practical approaches have been proposed and work well in
serial. However, as problem sizes increase and single core speeds stagnate,
parallelism is essential to solve problems quickly. We present an unsmoothed
aggregation Multigrid method for solving graph Laplacians in distributed memory
setting. Our solver scales up to 64 compute nodes and achieves speedups of up
to 83x over the existing serial solutions.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06270</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review on Bilevel Optimization: From Classical to Evolutionary
  Approaches and Applications</dc:title>
 <dc:creator>Sinha, Ankur</dc:creator>
 <dc:creator>Malo, Pekka</dc:creator>
 <dc:creator>Deb, Kalyanmoy</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Bilevel optimization is defined as a mathematical program, where an
optimization problem contains another optimization problem as a constraint.
These problems have received significant attention from the mathematical
programming community. Only limited work exists on bilevel problems using
evolutionary computation techniques; however, recently there has been an
increasing interest due to the proliferation of practical applications and the
potential of evolutionary algorithms in tackling these problems. This paper
provides a comprehensive review on bilevel optimization from the basic
principles to solution strategies; both classical and evolutionary. A number of
potential application problems are also discussed. To offer the readers
insights on the prominent developments in the field of bilevel optimization, we
have performed an automated text-analysis of an extended list of papers
published on bilevel optimization to date. This paper should motivate
evolutionary computation researchers to pay more attention to this practical
yet challenging area.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06271</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Snapshottable Concurrent Braun Heaps</dc:title>
 <dc:creator>Dickerson, Thomas D.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:description>  This paper proposes a new concurrent heap algorithm, based on a stateless
shape property, which efficiently maintains balance during insert and removeMin
operations implemented with hand-over-hand locking. It also provides a O(1)
linearizable snapshot operation based on lazy copy-on-write semantics. Such
snapshots can be used to provide consistent views of the heap during iteration,
as well as to make speculative updates (which can later be dropped).
  The simplicity of the algorithm allows it to be easily proven correct, and
the choice of shape property provides priority queue performance which is
competitive with highly optimized skiplist implementations (and has stronger
bounds on worst-case time complexity).
  A Scala reference implementation is provided.
</dc:description>
 <dc:description>Comment: pre-print, submitted to DISC'17</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06273</identifier>
 <datestamp>2017-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning for Named-Entity Recognition with Neural Networks</dc:title>
 <dc:creator>Lee, Ji Young</dc:creator>
 <dc:creator>Dernoncourt, Franck</dc:creator>
 <dc:creator>Szolovits, Peter</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent approaches based on artificial neural networks (ANNs) have shown
promising results for named-entity recognition (NER). In order to achieve high
performances, ANNs need to be trained on a large labeled dataset. However,
labels might be difficult to obtain for the dataset on which the user wants to
perform NER: label scarcity is particularly pronounced for patient note
de-identification, which is an instance of NER. In this work, we analyze to
what extent transfer learning may address this issue. In particular, we
demonstrate that transferring an ANN model trained on a large labeled dataset
to another dataset with a limited number of labels improves upon the
state-of-the-art results on two different datasets for patient note
de-identification.
</dc:description>
 <dc:description>Comment: The first two authors contributed equally to this work</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06299</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised Machine Learning for Signals Having RRC Shaped Pulses</dc:title>
 <dc:creator>Bari, Mohammad</dc:creator>
 <dc:creator>Taher, Hussain</dc:creator>
 <dc:creator>Sherazi, Syed Saad</dc:creator>
 <dc:creator>Doroslovacki, Milos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Classification performances of the supervised machine learning techniques
such as support vector machines, neural networks and logistic regression are
compared for modulation recognition purposes. The simple and robust features
are used to distinguish continuous-phase FSK from QAM-PSK signals. Signals
having root-raised-cosine shaped pulses are simulated in extreme noisy
conditions having joint impurities of block fading, lack of symbol and sampling
synchronization, carrier offset, and additive white Gaussian noise. The
features are based on sample mean and sample variance of the imaginary part of
the product of two consecutive complex signal values.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06299</dc:identifier>
 <dc:identifier>2016 50th Asilomar Conference on Signals, Systems, and Computers</dc:identifier>
 <dc:identifier>doi:10.1109/ACSSC.2016.7869124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06300</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayer Demosaicking Using Optimized Mean Curvature over RGB channels</dc:title>
 <dc:creator>Chen, Rui</dc:creator>
 <dc:creator>Jia, Huizhu</dc:creator>
 <dc:creator>Wen, Xiange</dc:creator>
 <dc:creator>Xie, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Color artifacts of demosaicked images are often found at contours due to
interpolation across edges and cross-channel aliasing. To tackle this problem,
we propose a novel demosaicking method to reliably reconstruct color channels
of a Bayer image based on two different optimized mean-curvature (MC) models.
The missing pixel values in green (G) channel are first estimated by minimizing
a variational MC model. The curvatures of restored G-image surface are
approximated as a linear MC model which guides the initial reconstruction of
red (R) and blue (B) channels. Then a refinement process is performed to
interpolate accurate full-resolution R and B images. Experiments on benchmark
images have testified to the superiority of the proposed method in terms of
both the objective and subjective quality.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06303</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase transitions in integer linear problems</dc:title>
 <dc:creator>Colabrese, S.</dc:creator>
 <dc:creator>De Martino, D.</dc:creator>
 <dc:creator>Leuzzi, L.</dc:creator>
 <dc:creator>Marinari, E.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The resolution of linear system with positive integer variables is a basic
yet difficult computational problem with many applications. We consider sparse
uncorrelated random systems parametrised by the density $c$ and the ratio
$\alpha=N/M$ between number of variables $N$ and number of constraints $M$. By
means of ensemble calculations we show that the space of feasible solutions
endows a Van-Der-Waals phase diagram in the plane ($c$, $\alpha$). We give
numerical evidence that the associated computational problems become more
difficult across the critical point and in particular in the coexistence
region.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures, comments are welcome</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06303</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/aa85c3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06306</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic, Strategyproof, and Fair Cake Cutting</dc:title>
 <dc:creator>Menon, Vijay</dc:creator>
 <dc:creator>Larson, Kate</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the classic cake cutting problem from a mechanism design
perspective, in particular focusing on deterministic mechanisms that are
strategyproof and fair. We begin by looking at mechanisms that are non-wasteful
and primarily show that for even the restricted class of piecewise constant
valuations there exists no direct-revelation mechanism that is strategyproof
and even approximately proportional. Subsequently, we remove the non-wasteful
constraint and show another impossibility result stating that there is no
strategyproof and approximately proportional direct-revelation mechanism that
outputs contiguous allocations, again, for even the restricted class of
piecewise constant valuations. In addition to the above results, we also
present some negative results when considering an approximate notion of
strategyproofness, show a connection between direct-revelation mechanisms and
mechanisms in the Robertson-Webb model when agents have piecewise constant
valuations, and finally also present a (minor) modification to the well-known
Even-Paz algorithm that has better incentive-compatible properties for the
cases when there are two or three agents.
</dc:description>
 <dc:description>Comment: A shorter version of this paper will appear at IJCAI 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06312</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching Logic</dc:title>
 <dc:creator>Rosu, Grigore</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.1</dc:subject>
 <dc:subject>F.3</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:description>  This paper presents matching logic, a first-order logic (FOL) variant for
specifying and reasoning about structure by means of patterns and pattern
matching. Its sentences, the patterns, are constructed using variables,
symbols, connectives and quantifiers, but no difference is made between
function and predicate symbols. In models, a pattern evaluates into a power-set
domain (the set of values that match it), in contrast to FOL where functions
and predicates map into a regular domain. Matching logic uniformly generalizes
several logical frameworks important for program analysis, such as:
propositional logic, algebraic specification, FOL with equality, modal logic,
and separation logic. Patterns can specify separation requirements at any level
in any program configuration, not only in the heaps or stores, without any
special logical constructs for that: the very nature of pattern matching is
that if two structures are matched as part of a pattern, then they can only be
spatially separated. Like FOL, matching logic can also be translated into pure
predicate logic with equality, at the same time admitting its own sound and
complete proof system. A practical aspect of matching logic is that FOL
reasoning with equality remains sound, so off-the-shelf provers and SMT solvers
can be used for matching logic reasoning. Matching logic is particularly
well-suited for reasoning about programs in programming languages that have an
operational semantics, but it is not limited to this.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06312</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (December
  20, 2017) lmcs:4153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06315</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Ensemble Estimation of Density Functionals</dc:title>
 <dc:creator>Wisler, Alan</dc:creator>
 <dc:creator>Moon, Kevin</dc:creator>
 <dc:creator>Berisha, Visar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Estimating density functionals of analog sources is an important problem in
statistical signal processing and information theory. Traditionally, estimating
these quantities requires either making parametric assumptions about the
underlying distributions or using non-parametric density estimation followed by
integration. In this paper we introduce a direct nonparametric approach which
bypasses the need for density estimation by using the error rates of k-NN
classifiers asdata-driven basis functions that can be combined to estimate a
range of density functionals. However, this method is subject to a non-trivial
bias that dramatically slows the rate of convergence in higher dimensions. To
overcome this limitation, we develop an ensemble method for estimating the
value of the basis function which, under some minor constraints on the
smoothness of the underlying distributions, achieves the parametric rate of
convergence regardless of data dimension.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06319</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constrained Submodular Maximization via Greedy Local Search</dc:title>
 <dc:creator>Sarpatwar, Kanthi K.</dc:creator>
 <dc:creator>Schieber, Baruch</dc:creator>
 <dc:creator>Shachnai, Hadas</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We present a simple combinatorial $\frac{1 -e^{-2}}{2}$-approximation
algorithm for maximizing a monotone submodular function subject to a knapsack
and a matroid constraint.
  This classic problem is known to be hard to approximate within factor better
than $1 - 1/e$. We show that the algorithm can be extended to yield a ratio of
$\frac{1 - e^{-(k+1)}}{k+1}$ for the problem with a single knapsack and the
intersection of $k$ matroid constraints, for any fixed $k &gt; 1$.
  Our algorithms, which combine the greedy algorithm of [Khuller, Moss and
Naor, 1999] and [Sviridenko, 2004] with local search, show the power of this
natural framework in submodular maximization with combined constraints.
</dc:description>
 <dc:description>Comment: Title changed from &quot;Interleaved Algorithms for Constrained Submodular
  Function Maximization&quot;</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06326</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An exact upper bound on the size of minimal clique covers</dc:title>
 <dc:creator>McIntyre, Ryan</dc:creator>
 <dc:creator>Soltys, Michael</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Indeterminate strings have received considerable attention in the recent
past; see for example Christodoulakis et al 2015 and Helling et al 2017. This
attention is due to their applicability in bioinformatics, and to the natural
correspondence with undirected graphs. One aspect of this correspondence is the
fact that the minimal alphabet size of indeterminates representing any given
undirected graph corresponds to the size of the minimal clique cover of this
graph. This paper solves a related problem proposed in Helling et al 2017:
compute $\Theta_n(m)$, which is the size of the largest possible minimal clique
cover (i.e., an exact upper bound), and hence alphabet size of the
corresponding indeterminate, of any graph on $n$ vertices and $m$ edges.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06333</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CardiacNET: Segmentation of Left Atrium and Proximal Pulmonary Veins
  from MRI Using Multi-View CNN</dc:title>
 <dc:creator>Mortazi, Aliasghar</dc:creator>
 <dc:creator>Karim, Rashed</dc:creator>
 <dc:creator>Rhode, Kawal</dc:creator>
 <dc:creator>Burt, Jeremy</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Anatomical and biophysical modeling of left atrium (LA) and proximal
pulmonary veins (PPVs) is important for clinical management of several cardiac
diseases. Magnetic resonance imaging (MRI) allows qualitative assessment of LA
and PPVs through visualization. However, there is a strong need for an advanced
image segmentation method to be applied to cardiac MRI for quantitative
analysis of LA and PPVs. In this study, we address this unmet clinical need by
exploring a new deep learning-based segmentation strategy for quantification of
LA and PPVs with high accuracy and heightened efficiency. Our approach is based
on a multi-view convolutional neural network (CNN) with an adaptive fusion
strategy and a new loss function that allows fast and more accurate convergence
of the backpropagation based optimization. After training our network from
scratch by using more than 60K 2D MRI images (slices), we have evaluated our
segmentation strategy to the STACOM 2013 cardiac segmentation challenge
benchmark. Qualitative and quantitative evaluations, obtained from the
segmentation challenge, indicate that the proposed method achieved the
state-of-the-art sensitivity (90%), specificity (99%), precision (94%), and
efficiency levels (10 seconds in GPU, and 7.5 minutes in CPU).
</dc:description>
 <dc:description>Comment: The paper is accepted by MICCAI 2017 for publication</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06338</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Vector Representation Of Shopping Items, The Customer And
  Shopping Cart To Build A Three Fold Recommendation System</dc:title>
 <dc:creator>Behera, Bibek</dc:creator>
 <dc:creator>Joshi, Manoj</dc:creator>
 <dc:creator>KK, Abhilash</dc:creator>
 <dc:creator>Ismail, Mohammad Ansari</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The main idea of this paper is to represent shopping items through vectors
because these vectors act as the base for building em- beddings for customers
and shopping carts. Also, these vectors are input to the mathematical models
that act as either a recommendation engine or help in targeting potential
customers. We have used exponential family embeddings as the tool to construct
two basic vectors - product embeddings and context vectors. Using the basic
vectors, we build combined embeddings, trip embeddings and customer embeddings.
Combined embeddings mix linguistic properties of product names with their
shopping patterns. The customer embeddings establish an understand- ing of the
buying pattern of customers in a group and help in building customer profile.
For example a customer profile can represent customers frequently buying
pet-food. Identifying such profiles can help us bring out offers and discounts.
Similarly, trip embeddings are used to build trip profiles. People happen to
buy similar set of products in a trip and hence their trip embeddings can be
used to predict the next product they would like to buy. This is a novel
technique and the first of its kind to make recommendation using product, trip
and customer embeddings.
</dc:description>
 <dc:description>Comment: Cicling 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06342</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification and Off-Policy Learning of Multiple Objectives Using
  Adaptive Clustering</dc:title>
 <dc:creator>Karimpanal, Thommen George</dc:creator>
 <dc:creator>Wilhelm, Erik</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this work, we present a methodology that enables an agent to make
efficient use of its exploratory actions by autonomously identifying possible
objectives in its environment and learning them in parallel. The identification
of objectives is achieved using an online and unsupervised adaptive clustering
algorithm. The identified objectives are learned (at least partially) in
parallel using Q-learning. Using a simulated agent and environment, it is shown
that the converged or partially converged value function weights resulting from
off-policy learning can be used to accumulate knowledge about multiple
objectives without any additional exploration. We claim that the proposed
approach could be useful in scenarios where the objectives are initially
unknown or in real world scenarios where exploration is typically a time and
energy intensive process. The implications and possible extensions of this work
are also briefly discussed.
</dc:description>
 <dc:description>Comment: Accepted in Neurocomputing: Special Issue on Multiobjective
  Reinforcement Learning: Theory and Applications, 24 pages, 6 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06345</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Data Mining Applications in Oil and Gas Exploration:
  Structural Geology and Reservoir Property-Issues</dc:title>
 <dc:creator>Jahromi, Hamed Nikhalat</dc:creator>
 <dc:creator>Jorge, Alpio M.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Low oil prices have motivated energy executives to look into cost reduction
in their supply chains more seriously. To this end, a new technology that is
experimentally considered in hydrocarbon exploration is data mining. There are
two major categories of geoscientific problems in which data mining is applied:
structural geology and reservoir property-issues. This research overviews these
categories by considering a variety of interesting works in each of them. The
result is an understanding of the specific geoscientific problems studied in
the literature, along with the relative data mining methods. This way, this
work tries to lay the ground for a mutual understanding on oil and gas
exploration between the data miners and the geoscientists.
</dc:description>
 <dc:description>Comment: Part of DM4OG 2017 proceedings (arXiv:1705.03451)</dc:description>
 <dc:date>2017-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06350</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Information and Power Transfer over an AWGN channel:
  Nonlinearity and Asymmetric Gaussian Signaling</dc:title>
 <dc:creator>Varasteh, Morteza</dc:creator>
 <dc:creator>Rassouli, Borzoo</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simultaneous transmission of information and power over a point-to-point
flat-fading complex Additive White Gaussian Noise (AWGN) channel is studied. In
contrast with the literature that relies on an inaccurate linear model of the
energy harvester, an experimentally-validated nonlinear model is considered. A
general form of the delivered Direct Current (DC) power in terms of system
baseband parameters is derived, which demonstrates the dependency of the
delivered DC power on higher order statistics of the channel input
distribution. The optimization problem of maximizing Rate-Power (R-P) region is
studied. Assuming that the Channel gain is available at both the receiver and
the transmitter, and constraining to independent and identically distributed
(i.i.d.) channel inputs determined only by their first and second moment
statistics, an inner bound for the general problem is obtained. Notably, as a
consequence of the harvester nonlinearity, the studied inner bound exhibits a
tradeoff between the delivered power and the rate of received information. It
is shown that the tradeoff-characterizing input distribution is with mean zero
and with asymmetric power allocations to the real and imaginary dimensions.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06353</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Political Footprints: Political Discourse Analysis using Pre-Trained
  Word Vectors</dc:title>
 <dc:creator>Bruchansky, Christophe</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we discuss how machine learning could be used to produce a
systematic and more objective political discourse analysis. Political
footprints are vector space models (VSMs) applied to political discourse. Each
of their vectors represents a word, and is produced by training the English
lexicon on large text corpora. This paper presents a simple implementation of
political footprints, some heuristics on how to use them, and their application
to four cases: the U.N. Kyoto Protocol and Paris Agreement, and two U.S.
presidential elections. The reader will be offered a number of reasons to
believe that political footprints produce meaningful results, along with some
suggestions on how to improve their implementation.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06353</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06362</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing and Visualizing Deep Learning for Benign/Malignant
  Classification in Breast Tumors</dc:title>
 <dc:creator>Yi, Darvin</dc:creator>
 <dc:creator>Sawyer, Rebecca Lynn</dc:creator>
 <dc:creator>Cohn III, David</dc:creator>
 <dc:creator>Dunnmon, Jared</dc:creator>
 <dc:creator>Lam, Carson</dc:creator>
 <dc:creator>Xiao, Xuerong</dc:creator>
 <dc:creator>Rubin, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Breast cancer has the highest incidence and second highest mortality rate for
women in the US. Our study aims to utilize deep learning for benign/malignant
classification of mammogram tumors using a subset of cases from the Digital
Database of Screening Mammography (DDSM). Though it was a small dataset from
the view of Deep Learning (about 1000 patients), we show that currently state
of the art architectures of deep learning can find a robust signal, even when
trained from scratch. Using convolutional neural networks (CNNs), we are able
to achieve an accuracy of 85% and an ROC AUC of 0.91, while leading
hand-crafted feature based methods are only able to achieve an accuracy of 71%.
We investigate an amalgamation of architectures to show that our best result is
reached with an ensemble of the lightweight GoogLe Nets tasked with
interpreting both the coronal caudal view and the mediolateral oblique view,
simply averaging the probability scores of both views to make the final
prediction. In addition, we have created a novel method to visualize what
features the neural network detects for the benign/malignant classification,
and have correlated those features with well known radiological features, such
as spiculation. Our algorithm significantly improves existing classification
methods for mammography lesions and identifies features that correlate with
established clinical markers.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06366</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Goal Generation for Reinforcement Learning Agents</dc:title>
 <dc:creator>Held, David</dc:creator>
 <dc:creator>Geng, Xinyang</dc:creator>
 <dc:creator>Florensa, Carlos</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Reinforcement learning is a powerful technique to train an agent to perform a
task. However, an agent that is trained using reinforcement learning is only
capable of achieving the single task that is specified via its reward function.
Such an approach does not scale well to settings in which an agent needs to
perform a diverse set of tasks, such as navigating to varying positions in a
room or moving objects to varying locations. Instead, we propose a method that
allows an agent to automatically discover the range of tasks that it is capable
of performing. We use a generator network to propose tasks for the agent to try
to achieve, specified as goal states. The generator network is optimized using
adversarial training to produce tasks that are always at the appropriate level
of difficulty for the agent. Our method thus automatically produces a
curriculum of tasks for the agent to learn. We show that, by using this
framework, an agent can efficiently and automatically learn to perform a wide
set of tasks without requiring any prior knowledge of its environment. Our
method can also learn to achieve tasks with sparse rewards, which traditionally
pose significant challenges.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06368</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re3 : Real-Time Recurrent Regression Networks for Visual Tracking of
  Generic Objects</dc:title>
 <dc:creator>Gordon, Daniel</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Robust object tracking requires knowledge and understanding of the object
being tracked: its appearance, its motion, and how it changes over time. A
tracker must be able to modify its underlying model and adapt to new
observations. We present Re3, a real-time deep object tracker capable of
incorporating temporal information into its model. Rather than focusing on a
limited set of objects or training a model at test-time to track a specific
instance, we pretrain our generic tracker on a large variety of objects and
efficiently update on the fly; Re3 simultaneously tracks and updates the
appearance model with a single forward pass. This lightweight model is capable
of tracking objects at 150 FPS, while attaining competitive results on
challenging benchmarks. We also show that our method handles temporary
occlusion better than other comparable trackers using experiments that directly
measure performance on sequences with occlusion.
</dc:description>
 <dc:description>Comment: RA-L Submission</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-12-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06369</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding Sentiment from Distributed Representations of Sentences</dc:title>
 <dc:creator>Ponti, Edoardo Maria</dc:creator>
 <dc:creator>Vuli&#x107;, Ivan</dc:creator>
 <dc:creator>Korhonen, Anna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Distributed representations of sentences have been developed recently to
represent their meaning as real-valued vectors. However, it is not clear how
much information such representations retain about the polarity of sentences.
To study this question, we decode sentiment from unsupervised sentence
representations learned with different architectures (sensitive to the order of
words, the order of sentences, or none) in 9 typologically diverse languages.
Sentiment results from the (recursive) composition of lexical items and
grammatical strategies such as negation and concession. The results are
manifold: we show that there is no `one-size-fits-all' representation
architecture outperforming the others across the board. Rather, the top-ranking
architectures depend on the language and data at hand. Moreover, we find that
in several cases the additive composition model based on skip-gram word vectors
may surpass supervised state-of-art architectures such as bidirectional LSTMs.
Finally, we provide a possible explanation of the observed variation based on
the type of negative constructions in each language.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06369</dc:identifier>
 <dc:identifier>doi:10.18653/v1/S17-1003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06371</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum Margin Principal Components</dc:title>
 <dc:creator>Luo, Xianghui</dc:creator>
 <dc:creator>Durrant, Robert J.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>62-07, 62H25, 62H30</dc:subject>
 <dc:description>  Principal Component Analysis (PCA) is a very successful dimensionality
reduction technique, widely used in predictive modeling. A key factor in its
widespread use in this domain is the fact that the projection of a dataset onto
its first $K$ principal components minimizes the sum of squared errors between
the original data and the projected data over all possible rank $K$
projections. Thus, PCA provides optimal low-rank representations of data for
least-squares linear regression under standard modeling assumptions. On the
other hand, when the loss function for a prediction problem is not the
least-squares error, PCA is typically a heuristic choice of dimensionality
reduction -- in particular for classification problems under the zero-one loss.
In this paper we target classification problems by proposing a straightforward
alternative to PCA that aims to minimize the difference in margin distribution
between the original and the projected data. Extensive experiments show that
our simple approach typically outperforms PCA on any particular dataset, in
terms of classification error, though this difference is not always
statistically significant, and despite being a filter method is frequently
competitive with Partial Least Squares (PLS) and Lasso on a wide range of
datasets.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06379</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General auction method for real-valued optimal transport</dc:title>
 <dc:creator>Walsh III, J. D.</dc:creator>
 <dc:creator>Dieci, Luca</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>49M20, 90C08, 90C46</dc:subject>
 <dc:description>  The auction method developed by Bertsekas in the late 1970s is a relaxation
technique for solving integer-valued assignment problems. It resembles a
competitive bidding process, where unsatisfied persons (bidders) attempt to
claim the objects (lots) offering the best value. By transforming
integer-valued transport problems into assignment problems, the auction method
can be extended to compute optimal transport solutions. We propose a more
general auction method that can be applied directly to real-valued transport
problems. We prove termination and provide a priori error bounds for the
general auction method. Our numerical results indicate that the complexity of
the general auction is roughly comparable to that of the original auction
method, when the latter is applicable.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06390</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Exact Parent Sets Identification in Bayesian Networks Learning
  with Apache Spark</dc:title>
 <dc:creator>Karan, Subhadeep</dc:creator>
 <dc:creator>Zola, Jaroslaw</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In Machine Learning, the parent set identification problem is to find a set
of random variables that best explain selected variable given the data and some
predefined scoring function. This problem is a critical component to structure
learning of Bayesian networks and Markov blankets discovery, and thus has many
practical applications, ranging from fraud detection to clinical decision
support. In this paper, we introduce a new distributed memory approach to the
exact parent sets assignment problem. To achieve scalability, we derive
theoretical bounds to constraint the search space when MDL scoring function is
used, and we reorganize the underlying dynamic programming such that the
computational density is increased and fine-grain synchronization is
eliminated. We then design efficient realization of our approach in the Apache
Spark platform. Through experimental results, we demonstrate that the method
maintains strong scalability on a 500-core standalone Spark cluster, and it can
be used to efficiently process data sets with 70 variables, far beyond the
reach of the currently available solutions.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06391</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous parallel primal-dual block update methods</dc:title>
 <dc:creator>Xu, Yangyang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>90C06, 90C25, 68W40, 49M27</dc:subject>
 <dc:description>  Recent several years have witnessed the surge of asynchronous (async-)
parallel computing methods due to the extremely big data involved in many
modern applications and also the advancement of multi-core machines and
computer clusters. In optimization, most works about async-parallel methods are
on unconstrained problems or those with block separable constraints.
  In this paper, we propose an async-parallel method based on block coordinate
update (BCU) for solving convex problems with nonseparable linear constraint.
Running on a single node, the method becomes a novel randomized primal-dual BCU
with adaptive stepsize for multi-block affinely constrained problems. For these
problems, Gauss-Seidel cyclic primal-dual BCU needs strong convexity to have
convergence. On the contrary, merely assuming convexity, we show that the
objective value sequence generated by the proposed algorithm converges in
probability to the optimal value and also the constraint residual to zero. In
addition, we establish an ergodic $O(1/k)$ convergence result, where $k$ is the
number of iterations. Numerical experiments are performed to demonstrate the
efficiency of the proposed method and significantly better speed-up performance
than its sync-parallel counterpart.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06394</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fashion Forward: Forecasting Visual Style in Fashion</dc:title>
 <dc:creator>Al-Halah, Ziad</dc:creator>
 <dc:creator>Stiefelhagen, Rainer</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  What is the future of fashion? Tackling this question from a data-driven
vision perspective, we propose to forecast visual style trends before they
occur. We introduce the first approach to predict the future popularity of
styles discovered from fashion images in an unsupervised manner. Using these
styles as a basis, we train a forecasting model to represent their trends over
time. The resulting model can hypothesize new mixtures of styles that will
become popular in the future, discover style dynamics (trendy vs. classic), and
name the key visual attributes that will dominate tomorrow's fashion. We
demonstrate our idea applied to three datasets encapsulating 80,000 fashion
products sold across six years on Amazon. Results indicate that fashion
forecasting benefits greatly from visual analysis, much more than textual or
meta-data cues surrounding products.
</dc:description>
 <dc:description>Comment: ICCV 2017</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06397</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ground state entanglement entropy for discrete-time two coupled harmonic
  oscillators</dc:title>
 <dc:creator>Kantayasakun, Watcharanon</dc:creator>
 <dc:creator>Yoo-Kong, Sikarin</dc:creator>
 <dc:creator>Deesuwan, Tanapat</dc:creator>
 <dc:creator>Tanasittikosol, Monsit</dc:creator>
 <dc:creator>Liewrian, Watchara</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The ground state entanglement of the system, both in discrete-time and
continuous-time cases, is quantified through the linear entropy. The result
shows that the entanglement increases as the interaction between the particles
increases in both time scales. It is also found that the strength of the
harmonic potential affects the formation rate of the entanglement of the
system. The different feature of the entanglement between continuous-time and
discrete-time scales is that, for discrete-time entanglement, there is a
cut-off condition. This condition implies that the system can never be in a
maximally entangled state.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06397</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/901/1/012168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06400</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a bidirectional mapping between human whole-body motion and
  natural language using deep recurrent neural networks</dc:title>
 <dc:creator>Plappert, Matthias</dc:creator>
 <dc:creator>Mandery, Christian</dc:creator>
 <dc:creator>Asfour, Tamim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Linking human whole-body motion and natural language is of great interest for
the generation of semantic representations of observed human behaviors as well
as for the generation of robot behaviors based on natural language input. While
there has been a large body of research in this area, most approaches that
exist today require a symbolic representation of motions (e.g. in the form of
motion primitives), which have to be defined a-priori or require complex
segmentation algorithms. In contrast, recent advances in the field of neural
networks and especially deep learning have demonstrated that sub-symbolic
representations that can be learned end-to-end usually outperform more
traditional approaches, for applications such as machine translation. In this
paper we propose a generative model that learns a bidirectional mapping between
human whole-body motion and natural language using deep recurrent neural
networks (RNNs) and sequence-to-sequence learning. Our approach does not
require any segmentation or manual feature engineering and learns a distributed
representation, which is shared for all motions and descriptions. We evaluate
our approach on 2,846 human whole-body motions and 6,187 natural language
descriptions thereof from the KIT Motion-Language Dataset. Our results clearly
demonstrate the effectiveness of the proposed model: We show that our model
generates a wide variety of realistic motions only from descriptions thereof in
form of a single sentence. Conversely, our model is also capable of generating
correct and detailed natural language descriptions from human motions.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06401</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Robotically Supported Decommissioning of Nuclear Sites</dc:title>
 <dc:creator>Mascarich, Frank</dc:creator>
 <dc:creator>Wilson, Taylor</dc:creator>
 <dc:creator>Dang, Tung</dc:creator>
 <dc:creator>Khattak, Shehryar</dc:creator>
 <dc:creator>Papachristos, Christos</dc:creator>
 <dc:creator>Alexis, Kostas</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper overviews certain radiation detection, perception, and planning
challenges for nuclearized robotics that aim to support the waste management
and decommissioning mission. To enable the autonomous monitoring, inspection
and multi-modal characterization of nuclear sites, we discuss important
problems relevant to the tasks of navigation in degraded visual environments,
localizability-aware exploration and mapping without any prior knowledge of the
environment, as well as robotic radiation detection. Future contributions will
focus on each of the relevant problems, will aim to deliver a comprehensive
multi-modal mapping result, and will emphasize on extensive field evaluation
and system verification.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06412</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sample-Efficient Algorithms for Recovering Structured Signals from
  Magnitude-Only Measurements</dc:title>
 <dc:creator>Jagatap, Gauri</dc:creator>
 <dc:creator>Hegde, Chinmay</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of recovering a signal $\mathbf{x}^* \in
\mathbf{R}^n$, from magnitude-only measurements $y_i =
|\left\langle\mathbf{a}_i,\mathbf{x}^*\right\rangle|$ for $i=[m]$. Also called
the phase retrieval, this is a fundamental challenge in bio-,astronomical
imaging and speech processing. The problem above is ill-posed; additional
assumptions on the signal and/or the measurements are necessary. In this paper
we first study the case where the signal $\mathbf{x}^*$ is $s$-sparse. We
develop a novel algorithm that we call Compressive Phase Retrieval with
Alternating Minimization, or CoPRAM. Our algorithm is simple; it combines the
classical alternating minimization approach for phase retrieval with the CoSaMP
algorithm for sparse recovery. Despite its simplicity, we prove that CoPRAM
achieves a sample complexity of $O(s^2\log n)$ with Gaussian measurements
$\mathbf{a}_i$, matching the best known existing results; moreover, it
demonstrates linear convergence in theory and practice. Additionally, it
requires no extra tuning parameters other than signal sparsity $s$ and is
robust to noise. When the sorted coefficients of the sparse signal exhibit a
power law decay, we show that CoPRAM achieves a sample complexity of $O(s\log
n)$, which is close to the information-theoretic limit. We also consider the
case where the signal $\mathbf{x}^*$ arises from structured sparsity models. We
specifically examine the case of block-sparse signals with uniform block size
of $b$ and block sparsity $k=s/b$. For this problem, we design a recovery
algorithm Block CoPRAM that further reduces the sample complexity to $O(ks\log
n)$. For sufficiently large block lengths of $b=\Theta(s)$, this bound equates
to $O(s\log n)$. To our knowledge, this constitutes the first end-to-end
algorithm for phase retrieval where the Gaussian sample complexity has a
sub-quadratic dependence on the signal sparsity level.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06413</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Weight Distribution of Quasi-quadratic Residue Codes</dc:title>
 <dc:creator>Boston, Nigel</dc:creator>
 <dc:creator>Hao, Jing</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B15, 94B60, 11G20</dc:subject>
 <dc:description>  In this paper, we begin by reviewing some of the known properties of QQR
codes and proved that $PSL_2(p)$ acts on the extended QQR code when $p \equiv 3
\pmod 4$. Using this discovery, we then showed their weight polynomials satisfy
a strong divisibility condition, namely that they are divisible by $(x^2 +
y^2)^{d-1}$, where $d$ is the corresponding minimum distance. Using this
result, we were able to construct an efficient algorithm to compute weight
polynomials for QQR codes and correct errors in existing results on quadratic
residue codes.
  In the second half, we use the relation between the weight of codewords and
the number of points on hyperelliptic curves to prove that the symmetrized
distribution of a set of hyperelliptic curves is asymptotically normal.
</dc:description>
 <dc:description>Comment: submitted to AIMS</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06413</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06419</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SimpleSSD: Modeling Solid State Drives for Holistic System Simulation</dc:title>
 <dc:creator>Jung, Myoungsoo</dc:creator>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:creator>Abulila, Ahmed</dc:creator>
 <dc:creator>Kwon, Miryeong</dc:creator>
 <dc:creator>Shahidi, Narges</dc:creator>
 <dc:creator>Shalf, John</dc:creator>
 <dc:creator>Kim, Nam Sung</dc:creator>
 <dc:creator>Kandemir, Mahmut</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Existing solid state drive (SSD) simulators unfortunately lack hardware
and/or software architecture models. Consequently, they are far from capturing
the critical features of contemporary SSD devices. More importantly, while the
performance of modern systems that adopt SSDs can vary based on their numerous
internal design parameters and storage-level configurations, a full system
simulation with traditional SSD models often requires unreasonably long
runtimes and excessive computational resources. In this work, we propose
SimpleSSD, a highfidelity simulator that models all detailed characteristics of
hardware and software, while simplifying the nondescript features of storage
internals. In contrast to existing SSD simulators, SimpleSSD can easily be
integrated into publicly-available full system simulators. In addition, it can
accommodate a complete storage stack and evaluate the performance of SSDs along
with diverse memory technologies and microarchitectures. Thus, it facilitates
simulations that explore the full design space at different levels of system
abstraction.
</dc:description>
 <dc:description>Comment: This paper has been accepted at IEEE Computer Architecture Letters
  (CAL)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06419</dc:identifier>
 <dc:identifier>doi:10.1109/LCA.2017.2750658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06425</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layered graphs: a class that admits polynomial time solutions for some
  hard problems</dc:title>
 <dc:creator>Chitturi, Bhadrachalam</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C69, 05C75, 05C85, 90C35, 94C15</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The independent set on a graph $G=(V,E)$ is a subset of $V$ such that no two
vertices in the subset have an edge between them. The MIS problem on $G$ seeks
to identify an independent set with maximum cardinality, i.e. maximum
independent set or MIS. $V* \subseteq V$ is a vertex cover $G=(V,E)$ if every
edge in the graph is incident upon at least one vertex in $V*$. $V* \subseteq
V$ is dominating set of $G=(V,E)$ if forall $v \in V$ either $v \in V*$ or
$\exists u \in V*$ and $(u,v) \in E$. A connected dominating set, CDS, is a
dominating set that forms a single component in $G$. The MVC problem on $G$
seeks to identify a vertex cover with minimum cardinality, i.e. minimum vertex
cover or MVC. Likewise, CVC seeks a connected vertex cover (CVC) with minimum
cardinality. The problems MDS and CDS seek to identify a dominating set and a
connected dominating set respectively of minimum cardinalities. MVC, CVC, MDS,
and CDS on a general graph are known to be NP-complete. On certain classes of
graphs they can be computed in polynomial time. Such algorithms are known for
bipartite graphs, chordal graphs, cycle graphs, comparability graphs, claw-free
graphs, interval graphs and circular arc graphs for some of these problems. In
this article we introduce a new class of graphs called a layered graph and show
that if the number of vertices in a layer is $O(\log \mid V \mid)$ then MIS,
MVC, CVC, MDS and CDC can be computed in polynomial time. The restrictions that
are employed on graph classes that admit polynomial time solutions for hard
problems, e.g. lack of cycles, bipartiteness, planarity etc. are not applicable
for this class. \\ Key words: Independent set, vertex cover, dominating set,
dynamic programming, complexity, polynomial time algorithms.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure. A generic algorithm is given. It can be extended
  to handle a wide range of hard problems. Space complexity was incorrectly
  given as $O(k^2)$ for MIS (identical for MVC) in the earlier version instead
  of $O(k 2^k)$. The edges in $LLG$ are more clearly defined. For $ V_{it}$ the
  only permissible edges are $(V_{it}, V_{jt})$ where $j \in \{ i-1, i+1\}$</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06429</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A systematic mapping study on cross-project defect prediction</dc:title>
 <dc:creator>Herbold, Steffen</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Cross-Project-Defect Prediction as a sub-topic of defect prediction in
general has become a popular topic in research. In this article, we present a
systematic mapping study with the focus on CPDP, for which we found 50
publications. We summarize the approaches presented by each publication and
discuss the case study setups and results. We discovered a great amount of
heterogeneity in the way case studies are conducted, because of differences in
the data sets, classifiers, performance metrics, and baseline comparisons used.
Due to this, we could not compare the results of our review on a qualitative
basis, i.e., determine which approaches perform best for CPDP.
</dc:description>
 <dc:description>Comment: Under Review</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06430</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cyclic Datatypes modulo Bisimulation based on Second-Order Algebraic
  Theories</dc:title>
 <dc:creator>Hamana, Makoto</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Cyclic data structures, such as cyclic lists, in functional programming are
tricky to handle because of their cyclicity. This paper presents an
investigation of categorical, algebraic, and computational foundations of
cyclic datatypes. Our framework of cyclic datatypes is based on second-order
algebraic theories of Fiore et al., which give a uniform setting for syntax,
types, and computation rules for describing and reasoning about cyclic
datatypes. We extract the &quot;fold&quot; computation rules from the categorical
semantics based on iteration categories of Bloom and Esik. Thereby, the rules
are correct by construction. We prove strong normalisation using the General
Schema criterion for second-order computation rules. Rather than the fixed
point law, we particularly choose Bekic law for computation, which is a key to
obtaining strong normalisation. We also prove the property of &quot;Church-Rosser
modulo bisimulation&quot; for the computation rules. Combining these results, we
have a remarkable decidability result of the equational theory of cyclic data
and fold.
</dc:description>
 <dc:description>Comment: 38 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06430</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (November
  15, 2017) lmcs:4066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06431</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Routing with Drones</dc:title>
 <dc:creator>Daknama, Rami</dc:creator>
 <dc:creator>Kraus, Elisabeth</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We introduce a package service model where trucks as well as drones can
deliver packages. Drones can travel on trucks or fly; but while flying, drones
can only carry one package at a time and have to return to a truck to charge
after each delivery. We present a heuristic algorithm to solve the problem of
finding a good schedule for all drones and trucks. The algorithm is based on
two nested local searches, thus the definition of suitable neighbourhoods of
solutions is crucial for the algorithm. Empirical tests show that our algorithm
performs significantly better than a natural Greedy algorithm. Moreover, the
savings compared to solutions without drones turn out to be substantial,
suggesting that delivery systems might considerably benefit from using drones
in addition to trucks.
</dc:description>
 <dc:description>Comment: 24 pages, 15 figures</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06439</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the trade-off between labels and weights in quantitative bisimulation</dc:title>
 <dc:creator>Peressotti, Marco</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Reductions for transition systems have been recently introduced as a uniform
and principled method for comparing the expressiveness of system models with
respect to a range of properties, especially bisimulations. In this paper we
study the expressiveness (w.r.t. bisimulations) of models for quantitative
computations such as weighted labelled transition systems (WLTSs), uniform
labelled transition systems (ULTraSs), and state-to-function transition systems
(FuTSs). We prove that there is a trade-off between labels and weights: at one
extreme lays the class of (unlabelled) weighted transition systems where
information is presented using weights only; at the other lays the class of
labelled transition systems (LTSs) where information is shifted on labels.
These categories of systems cannot be further reduced in any significant way
and subsume all the aforementioned models.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06452</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delving into adversarial attacks on deep policies</dc:title>
 <dc:creator>Kos, Jernej</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adversarial examples have been shown to exist for a variety of deep learning
architectures. Deep reinforcement learning has shown promising results on
training agent policies directly on raw inputs such as image pixels. In this
paper we present a novel study into adversarial attacks on deep reinforcement
learning polices. We compare the effectiveness of the attacks using adversarial
examples vs. random noise. We present a novel method for reducing the number of
times adversarial examples need to be injected for a successful attack, based
on the value function. We further explore how re-training on random noise and
FGSM perturbations affects the resilience against adversarial examples.
</dc:description>
 <dc:description>Comment: ICLR 2017 Workshop</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06453</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elastic and Secure Energy Forecasting in Cloud Environments</dc:title>
 <dc:creator>Martin, Andr&#xe9;</dc:creator>
 <dc:creator>Britoy, Andrey</dc:creator>
 <dc:creator>Fetzer, Christof</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Although cloud computing offers many advantages with regards to adaption of
resources, we witness either a strong resistance or a very slow adoption to
those new offerings. One reason for the resistance is that (i) many
technologies such as stream processing systems still lack of appropriate
mechanisms for elasticity in order to fully harness the power of the cloud, and
(ii) do not provide mechanisms for secure processing of privacy sensitive data
such as when analyzing energy consumption data provided through smart plugs in
the context of smart grids. In this white paper, we present our vision and
approach for elastic and secure processing of streaming data. Our approach is
based on StreamMine3G, an elastic event stream processing system and Intel's
SGX technology that provides secure processing using enclaves. We highlight the
key aspects of our approach and research challenges when using Intel's SGX
technology.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06453</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06454</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Cyber-Physical Attacks in Additive Manufacturing using Digital
  Audio Signing</dc:title>
 <dc:creator>Belikovetsky, Sofia</dc:creator>
 <dc:creator>Solewicz, Yosef</dc:creator>
 <dc:creator>Yampolskiy, Mark</dc:creator>
 <dc:creator>Toh, Jinghui</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Additive Manufacturing (AM, or 3D printing) is a novel manufacturing
technology that is being adopted in industrial and consumer settings. However,
the reliance of this technology on computerization has raised various security
concerns. In this paper we address sabotage via tampering with the 3D printing
process. We present an object verification system using side-channel
emanations: sound generated by onboard stepper motors. The contributions of
this paper are following. We present two algorithms: one which generates a
master audio fingerprint for the unmodified printing process, and one which
computes the similarity between other print recordings and the master audio
fingerprint. We then evaluate the deviation due to tampering, focusing on the
detection of minimal tampering primitives. By detecting the deviation at the
time of its occurrence, we can stop the printing process for compromised
objects, thus save time and prevent material waste. We discuss impacts on the
method by aspects like background noise, or different audio recorder positions.
We further outline our vision with use cases incorporating our approach.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06457</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Density as a Factor for Variation in the Embedding of
  Relative Clauses</dc:title>
 <dc:creator>Speyer, Augustin</dc:creator>
 <dc:creator>Lemke, Robin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>94</dc:subject>
 <dc:description>  In German, relative clauses can be positioned in-situ or extraposed. A
potential factor for the variation might be information density. In this study,
this hypothesis is tested with a corpus of 17th century German funeral sermons.
For each referent in the relative clauses and their matrix clauses, the
attention state was determined (first calculation). In a second calculation,
for each word the surprisal values were determined, using a bi-gram language
model. In a third calculation, the surprisal values were accommodated as to
whether it is the first occurrence of the word in question or not. All three
calculations pointed in the same direction: With in-situ relative clauses, the
rate of new referents was lower and the average surprisal values were lower,
especially the accommodated surprisal values, than with extraposed relative
clauses. This indicated that in-formation density is a factor governing the
choice between in-situ and extraposed relative clauses. The study also sheds
light on the intrinsic relation-ship between the information theoretic concept
of information density and in-formation structural concepts such as givenness
which are used under a more linguistic perspective.
</dc:description>
 <dc:description>Comment: 10 pages. To be submitted in a German version to 'Sprachwissenschaft'</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06460</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving Ensemble Fuzzy Classifier</dc:title>
 <dc:creator>Pratama, Mahardhika</dc:creator>
 <dc:creator>Pedrycz, Witold</dc:creator>
 <dc:creator>Lughofer, Edwin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The concept of ensemble learning offers a promising avenue in learning from
data streams under complex environments because it addresses the bias and
variance dilemma better than its single model counterpart and features a
reconfigurable structure, which is well suited to the given context. While
various extensions of ensemble learning for mining non-stationary data streams
can be found in the literature, most of them are crafted under a static base
classifier and revisits preceding samples in the sliding window for a
retraining step. This feature causes computationally prohibitive complexity and
is not flexible enough to cope with rapidly changing environments. Their
complexities are often demanding because it involves a large collection of
offline classifiers due to the absence of structural complexities reduction
mechanisms and lack of an online feature selection mechanism. A novel evolving
ensemble classifier, namely Parsimonious Ensemble pENsemble, is proposed in
this paper. pENsemble differs from existing architectures in the fact that it
is built upon an evolving classifier from data streams, termed Parsimonious
Classifier pClass. pENsemble is equipped by an ensemble pruning mechanism,
which estimates a localized generalization error of a base classifier. A
dynamic online feature selection scenario is integrated into the pENsemble.
This method allows for dynamic selection and deselection of input features on
the fly. pENsemble adopts a dynamic ensemble structure to output a final
classification decision where it features a novel drift detection scenario to
grow the ensemble structure. The efficacy of the pENsemble has been numerically
demonstrated through rigorous numerical studies with dynamic and evolving data
streams where it delivers the most encouraging performance in attaining a
tradeoff between accuracy and complexity.
</dc:description>
 <dc:description>Comment: this paper is currently submitted for possible publication in IEEE</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06463</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Dependencies Parsing for Colloquial Singaporean English</dc:title>
 <dc:creator>Wang, Hongmin</dc:creator>
 <dc:creator>Zhang, Yue</dc:creator>
 <dc:creator>Chan, GuangYong Leonard</dc:creator>
 <dc:creator>Yang, Jie</dc:creator>
 <dc:creator>Chieu, Hai Leong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Singlish can be interesting to the ACL community both linguistically as a
major creole based on English, and computationally for information extraction
and sentiment analysis of regional social media. We investigate dependency
parsing of Singlish by constructing a dependency treebank under the Universal
Dependencies scheme, and then training a neural network model by integrating
English syntactic knowledge into a state-of-the-art parser trained on the
Singlish treebank. Results show that English knowledge can lead to 25% relative
error reduction, resulting in a parser of 84.47% accuracies. To the best of our
knowledge, we are the first to use neural stacking to improve cross-lingual
dependency parsing on low-resource languages. We make both our annotation and
parser available for further research.
</dc:description>
 <dc:description>Comment: Accepted by ACL 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06466</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Achievable Spectral Efficiency of Spatial Modulation Aided
  Downlink Non-Orthogonal Multiple Access</dc:title>
 <dc:creator>Wang, Xuesi</dc:creator>
 <dc:creator>Wang, Jintao</dc:creator>
 <dc:creator>He, Longzhuang</dc:creator>
 <dc:creator>Tang, Zihan</dc:creator>
 <dc:creator>Song, Jian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a novel spatial modulation aided non-orthogonal multiple
access (SM-NOMA) system is proposed. We use mutual information (MI) to
characterize the achievable spectral efficiency (SE) of the proposed SM-NOMA
system. Due to the finite-alphabet space-domain inputs employed by SM, the
expression of the corresponding MI lacks a closed-form formulation. Hence, a
lower bound is proposed to quantify the MI of the SM-NOMA system. Furthermore,
its asymptotic property is also theoretically investigated in both low and high
signal-to-noise ratio (SNR) regions. The SE performance and its analysis of our
proposed SM-NOMA system are confirmed by simulation results.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures, accepted by IEEE Communications Letters</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06466</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06476</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ParlAI: A Dialog Research Software Platform</dc:title>
 <dc:creator>Miller, Alexander H.</dc:creator>
 <dc:creator>Feng, Will</dc:creator>
 <dc:creator>Fisch, Adam</dc:creator>
 <dc:creator>Lu, Jiasen</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:creator>Bordes, Antoine</dc:creator>
 <dc:creator>Parikh, Devi</dc:creator>
 <dc:creator>Weston, Jason</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce ParlAI (pronounced &quot;par-lay&quot;), an open-source software platform
for dialog research implemented in Python, available at http://parl.ai. Its
goal is to provide a unified framework for sharing, training and testing of
dialog models, integration of Amazon Mechanical Turk for data collection, human
evaluation, and online/reinforcement learning; and a repository of machine
learning models for comparing with others' models, and improving upon existing
architectures. Over 20 tasks are supported in the first release, including
popular datasets such as SQuAD, bAbI tasks, MCTest, WikiQA, QACNN, QADailyMail,
CBT, bAbI Dialog, Ubuntu, OpenSubtitles and VQA. Several models are integrated,
including neural models such as memory networks, seq2seq and attentive LSTMs.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06477</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Protecting Against Untrusted Relays: An Information Self-encrypted
  Approach</dc:title>
 <dc:creator>Niu, Hao</dc:creator>
 <dc:creator>Sun, Yao</dc:creator>
 <dc:creator>Sezaki, Kaoru</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The reliability and transmission distance are generally limited for the
wireless communications due to the severe channel fading. As an effective way
to resist the channel fading, cooperative relaying is usually adopted in
wireless networks where neighbouring nodes act as relays to help the
transmission between the source and the destination. Most research works simply
regard these cooperative nodes trustworthy, which may be not practical in some
cases especially when transmitting confidential information. In this paper, we
consider the issue of untrusted relays in cooperative communications and
propose an information self-encrypted approach to protect against these relays.
Specifically, the original packets of the information are used to encrypt each
other as the secret keys such that the information cannot be recovered before
all of the encrypted packets have been received. The information is intercepted
only when the relays obtain all of these encrypted packets. It is proved that
the intercept probability is reduced to zero exponentially with the number of
the original packets. However, the security performance is still not
satisfactory for a large number of relays. Therefore, the combination of
destination-based jamming is further adopted to confuse the relays, which makes
the security performance acceptable even for a large number of relays. Finally,
the simulation results are provided to confirm the theoretical analysis and the
superiority of the proposed scheme.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06500</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-efficient 3D UAV-BS Placement Versus Mobile Users' Density and
  Circuit Power</dc:title>
 <dc:creator>Lu, Jiaxun</dc:creator>
 <dc:creator>Wan, Shuo</dc:creator>
 <dc:creator>Chen, Xuhong</dc:creator>
 <dc:creator>Fan, Pingyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Properly 3D placement of unmanned aerial vehicle mounted base stations
(UAV-BSs) can effectively prolong the life-time of the mobile ad hoc network,
since UAVs are usually powered by batteries. This paper involves the on-board
circuit consumption power and considers the optimal placement that minimizes
the UAV-recall-frequency (UAV-RF), which is defined to characterize the
life-time of this kind of network. Theoretical results show that the optimal
vertical and horizontal dimensions of UAV can be decoupled. That is, the
optimal hovering altitude is proportional to the coverage radius of UAVs, and
the slope is only determined by environment. Dense scattering environment may
greatly enlarge the needed hovering altitude. Also, the optimal coverage radius
is achieved when the transmit power equals to on-board circuit power, and hence
limiting on-board circuit power can effectively enlarge life-time of system. In
addition, our proposed 3D placement method only require the statistics of
mobile users' density and environment parameters, and hence it's a typical
on-line method and can be easily implemented. Also, it can be utilized in
scenarios with varying users' density.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, submitted to globecom 17</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06504</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TableQA: Question Answering on Tabular Data</dc:title>
 <dc:creator>Vakulenko, Svitlana</dc:creator>
 <dc:creator>Savenkov, Vadim</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Tabular data is difficult to analyze and to search through, yielding for new
tools and interfaces that would allow even non tech-savvy users to gain
insights from open datasets without resorting to specialized data analysis
tools or even without having to fully understand the dataset structure. The
goal of our demonstration is to showcase answering natural language questions
from tabular data, and to discuss related system configuration and model
training aspects. Our prototype is publicly available and open-sourced (see
https://svakulenko.ai.wu.ac.at/tableqa).
</dc:description>
 <dc:description>Comment: Full version of the demo paper accepted at SEMANTiCS 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06510</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropic selection of concepts in networks of similarity between
  documents</dc:title>
 <dc:creator>Martini, Andrea</dc:creator>
 <dc:creator>Cardillo, Alessio</dc:creator>
 <dc:creator>Rios, Paolo De Los</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Scientists have devoted many efforts to study the organization and evolution
of science by leveraging the textual information contained in the
title/abstract of scientific documents. However, only few studies focus on the
analysis of the whole body of a document. Using the whole text of documents
allows, instead, to unveil the organization of scientific knowledge using a
network of similarity between articles based on their characterizing concepts
which can be extracted, for instance, through the ScienceWISE platform.
However, such network has a remarkably high link density (36\%) hindering the
association of groups of documents to a given topic, because not all the
concepts are equally informative and useful to discriminate between articles.
The presence of &quot;generic concepts&quot; generates a large amount of spurious
connections in the system. To identify/remove these concepts, we introduce a
method to gauge their relevance according to an information-theoretic approach.
The significance of a concept $c$ is encoded by the distance between its
maximum entropy, $S_{\max}$, and the observed one, $S_c$. After removing
concepts within a certain distance from the maximum, we rebuild the similarity
network and analyze its topic structure. The consequences of pruning concepts
are twofold: the number of links decreases, as well as the noise present in the
strength of similarities between articles. Hence, the filtered network displays
a more refined community structure, where each community contains articles
related to a specific topic. Finally, the method can be applied to other kind
of documents and works also in a coarse-grained mode, allowing the study of a
corpus at different scales.
</dc:description>
 <dc:description>Comment: Main + SI. (8+27) pages, (3+15) figures, (1+7) tables. Submitted for
  publication</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06511</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In The Field Monitoring of Interactive Applications</dc:title>
 <dc:creator>Cornejo, Oscar</dc:creator>
 <dc:creator>Briola, Daniela</dc:creator>
 <dc:creator>Micucci, Daniela</dc:creator>
 <dc:creator>Mariani, Leonardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Monitoring techniques can extract accurate data about the behavior of
software systems. When used in the field, they can reveal how applications
behave in real-world contexts and how programs are actually exercised by their
users. Nevertheless, since monitoring might need significant storage and
computational resources, it may interfere with users activities degrading the
quality of the user experience. While the impact of monitoring has been
typically studied by measuring the overhead that it may introduce in a
monitored application, there is little knowledge about how monitoring solutions
may actually impact on the user experience and to what extent users may
recognize their presence. In this paper, we present our investigation on how
collecting data in the field may impact the quality of the user experience. Our
initial results show that non-trivial overhead can be tolerated by users,
depending on the kind of activity that is performed. This opens interesting
opportunities for research in monitoring solutions, which could be designed to
opportunistically
</dc:description>
 <dc:description>Comment: IEEE Copyright, Accepted for pubblication in ICSE 2017, Nier Track</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06516</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Combination of Noisy Points and Planes for RGB-D Odometry</dc:title>
 <dc:creator>Proen&#xe7;a, Pedro F.</dc:creator>
 <dc:creator>Gao, Yang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work proposes a visual odometry method that combines points and plane
primitives, extracted from a noisy depth camera. Depth measurement uncertainty
is modelled and propagated through the extraction of geometric primitives to
the frame-to-frame motion estimation, where pose is optimized by weighting the
residuals of 3D point and planes matches, according to their uncertainties.
Results on an RGB-D dataset show that the combination of points and planes,
through the proposed method, is able to perform well in poorly textured
environments, where point-based odometry is bound to fail.
</dc:description>
 <dc:description>Comment: Accepted to TAROS 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06521</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plane Formation by Synchronous Mobile Robots without Chirality</dc:title>
 <dc:creator>Tomita, Yusaku</dc:creator>
 <dc:creator>Yamauchi, Yukiko</dc:creator>
 <dc:creator>Kijima, Shuji</dc:creator>
 <dc:creator>Yamashita, Masafumi</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider a distributed system consisting of autonomous mobile computing
entities, called robots, moving in a specified space. The robots are anonymous,
oblivious, and have neither any access to the global coordinate system nor any
explicit communication medium. Each robot observes the positions of other
robots and moves in terms of its local coordinate system. To investigate the
self-organization power of robot systems, formation problems in the two
dimensional space (2D-space) have been extensively studied. Yamauchi et al.
(DISC 2015) introduced robot systems in the three dimensional space (3D-space).
While existing results for 3D-space assume that the robots agree on the
handedness of their local coordinate systems, we remove the assumption and
consider the robots without chirality. One of the most fundamental agreement
problems in 3D-space is the plane formation problem that requires the robots to
land on a common plane, that is not predefined. It has been shown that the
solvability of the plane formation problem by robots with chirality is
determined by the rotation symmetry of their initial local coordinate systems
because the robots cannot break it. We show that when the robots lack
chirality, the combination of rotation symmetry and reflection symmetry
determines the solvability of the plane formation problem because a set of
symmetric local coordinate systems without chirality is obtained by rotations
and reflections. This richer symmetry results in the increase of unsolvable
instances compared with robots with chirality and a flaw of existing plane
formation algorithm. In this paper, we give a characterization of initial
configurations from which the robots without chirality can form a plane and a
new plane formation algorithm for solvable instances.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06524</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fully dense and globally consistent 3D map reconstruction approach for
  GI tract to enhance therapeutic relevance of the endoscopic capsule robot</dc:title>
 <dc:creator>Turan, Mehmet</dc:creator>
 <dc:creator>Pilavci, Yusuf Yigit</dc:creator>
 <dc:creator>Jamiruddin, Redhwan</dc:creator>
 <dc:creator>Araujo, Helder</dc:creator>
 <dc:creator>Konukoglu, Ender</dc:creator>
 <dc:creator>Sitti, Metin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the gastrointestinal (GI) tract endoscopy field, ingestible wireless
capsule endoscopy is emerging as a novel, minimally invasive diagnostic
technology for inspection of the GI tract and diagnosis of a wide range of
diseases and pathologies. Since the development of this technology, medical
device companies and many research groups have made substantial progress in
converting passive capsule endoscopes to robotic active capsule endoscopes with
most of the functionality of current active flexible endoscopes. However,
robotic capsule endoscopy still has some challenges. In particular, the use of
such devices to generate a precise three-dimensional (3D) mapping of the entire
inner organ remains an unsolved problem. Such global 3D maps of inner organs
would help doctors to detect the location and size of diseased areas more
accurately and intuitively, thus permitting more reliable diagnoses. To our
knowledge, this paper presents the first complete pipeline for a complete 3D
visual map reconstruction of the stomach. The proposed pipeline is modular and
includes a preprocessing module, an image registration module, and a final
shape-from-shading-based 3D reconstruction module; the 3D map is primarily
generated by a combination of image stitching and shape-from-shading
techniques, and is updated in a frame-by-frame iterative fashion via capsule
motion inside the stomach. A comprehensive quantitative analysis of the
proposed 3D reconstruction method is performed using an esophagus gastro
duodenoscopy simulator, three different endoscopic cameras, and a 3D optical
scanner.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06526</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak Interactions Based System Partitioning Using Integer Linear
  Programming</dc:title>
 <dc:creator>Guicherd, Romain</dc:creator>
 <dc:creator>Trodden, Paul A.</dc:creator>
 <dc:creator>Mills, Andrew R.</dc:creator>
 <dc:creator>Kadirkamanathan, Visakan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The partitioning of a system model will condition the structure of the
controller as well as its design. In order to partition a system model, one has
to know what states and inputs to group together to define subsystem models.
For a given partitioning, the total magnitude of the interactions between
subsystem models is evaluated. Therefore, the partitioning problem seeking for
weak interactions can be posed as a minimization problem. Initially, the
problem is formulated as a non-linear integer minimization that is then relaxed
into a linear integer programming problem. It is shown within this paper that
cuts can be applied to the initial search space in order to find the least
interacting partitioning; only composed of controllable subsystems. Two
examples are given to demonstrate the methodology.
</dc:description>
 <dc:description>Comment: Accepted for IFAC World Congress 2017 (Toulouse, France)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06526</dc:identifier>
 <dc:identifier>doi:10.1016/j.ifacol.2017.08.709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06530</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fake it till you make it: Fishing for Catfishes</dc:title>
 <dc:creator>Magdy, Walid</dc:creator>
 <dc:creator>Elkhatib, Yehia</dc:creator>
 <dc:creator>Tyson, Gareth</dc:creator>
 <dc:creator>Joglekar, Sagar</dc:creator>
 <dc:creator>Sastry, Nishanth</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Many adult content websites incorporate social networking features. Although
these are popular, they raise significant challenges, including the potential
for users to &quot;catfish&quot;, i.e., to create fake profiles to deceive other users.
This paper takes an initial step towards automated catfish detection. We
explore the characteristics of the different age and gender groups, identifying
a number of distinctions. Through this, we train models based on user profiles
and comments, via the ground truth of specially verified profiles. Applying our
models for age and gender estimation of unverified profiles, we identify 38% of
profiles who are likely lying about their age, and 25% who are likely lying
about their gender. We find that women have a greater propensity to catfish
than men. Further, whereas women catfish select from a wide age range, men
consistently lie about being younger. Our work has notable implications on
operators of such online social networks, as well as users who may worry about
interacting with catfishes.
</dc:description>
 <dc:description>Comment: Paper to appear in IEEE/ACM ASONAM 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06556</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A data-driven workflow for predicting horizontal well production using
  vertical well logs</dc:title>
 <dc:creator>Guevara, Jorge</dc:creator>
 <dc:creator>Kormaksson, Matthias</dc:creator>
 <dc:creator>Zadrozny, Bianca</dc:creator>
 <dc:creator>Lu, Ligang</dc:creator>
 <dc:creator>Tolle, John</dc:creator>
 <dc:creator>Croft, Tyler</dc:creator>
 <dc:creator>Wu, Mingqi</dc:creator>
 <dc:creator>Limbeck, Jan</dc:creator>
 <dc:creator>Hohl, Detlef</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In recent work, data-driven sweet spotting technique for shale plays
previously explored with vertical wells has been proposed. Here, we extend this
technique to multiple formations and formalize a general data-driven workflow
to facilitate feature extraction from vertical well logs and predictive
modeling of horizontal well production. We also develop an experimental
framework that facilitates model selection and validation in a realistic
drilling scenario. We present some experimental results using this methodology
in a field with 90 vertical wells and 98 horizontal wells, showing that it can
achieve better results in terms of predictive ability than kriging of known
production values.
</dc:description>
 <dc:description>Comment: Part of DM4OG 2017 proceedings (arXiv:1705.03451)</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06558</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Chance-Constrained Optimization for Power-Efficient and Secure
  SWIPT Systems</dc:title>
 <dc:creator>Le, Tuan Anh</dc:creator>
 <dc:creator>Vien, Quoc-Tuan</dc:creator>
 <dc:creator>Nguyen, Huan X.</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose beamforming schemes to simultaneously transmit data
securely to multiple information receivers (IRs) while transferring power
wirelessly to multiple energy-harvesting receivers (ERs). Taking into account
the imperfection of the instantaneous channel state information (CSI), we
introduce a chance-constrained optimization problem to minimize the total
transmit power while guaranteeing data transmission reliability, data
transmission security, and power transfer reliability. As the proposed
optimization problem is non-convex due to the chance constraints, we propose
two robust reformulations of the original problem based on
safe-convex-approximation techniques. Subsequently, applying semidefinite
programming relaxation (SDR), the derived robust reformulations can be
effectively solved by standard convex optimization packages. We show that the
adopted SDR is tight and thus the globally optimal solutions of the
reformulated problems can be recovered. Simulation results confirm the
superiority of the proposed methods in guaranteeing transmission security
compared to a baseline scheme. Furthermore, the performance of proposed methods
can closely follow that of a benchmark scheme where perfect CSI is available
for resource allocation.
</dc:description>
 <dc:description>Comment: This paper has been accepted for publication at IEEE Transactions on
  Green Communications and Networking</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06558</dc:identifier>
 <dc:identifier>doi:10.1109/TGCN.2017.2706063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06559</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exemplar or Matching: Modeling DCJ Problems with Unequal Content Genome
  Data</dc:title>
 <dc:creator>Yin, Zhaoming</dc:creator>
 <dc:creator>Tang, Jijun</dc:creator>
 <dc:creator>Schaeffer, Stephen W.</dc:creator>
 <dc:creator>Bader, David A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  The edit distance under the DCJ model can be computed in linear time for
genomes with equal content or with Indels. But it becomes NP-Hard in the
presence of duplications, a problem largely unsolved especially when Indels are
considered. In this paper, we compare two mainstream methods to deal with
duplications and associate them with Indels: one by deletion, namely
DCJ-Indel-Exemplar distance; versus the other by gene matching, namely
DCJ-Indel-Matching distance. We design branch-and-bound algorithms with set of
optimization methods to compute exact distances for both. Furthermore, median
problems are discussed in alignment with both of these distance methods, which
are to find a median genome that minimizes distances between itself and three
given genomes. Lin-Kernighan (LK) heuristic is leveraged and powered up by
sub-graph decomposition and search space reduction technologies to handle
median computation. A wide range of experiments are conducted on synthetic data
sets and real data sets to show pros and cons of these two distance metrics per
se, as well as putting them in the median computation scenario.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06559</dc:identifier>
 <dc:identifier>Journal of Combinatorial Optimization, 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s10878-015-9940-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06560</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Agent-Centric Risk Assessment: Accident Anticipation and Risky Region
  Localization</dc:title>
 <dc:creator>Zeng, Kuo-Hao</dc:creator>
 <dc:creator>Chou, Shih-Han</dc:creator>
 <dc:creator>Chan, Fu-Hsiang</dc:creator>
 <dc:creator>Niebles, Juan Carlos</dc:creator>
 <dc:creator>Sun, Min</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For survival, a living agent must have the ability to assess risk (1) by
temporally anticipating accidents before they occur, and (2) by spatially
localizing risky regions in the environment to move away from threats. In this
paper, we take an agent-centric approach to study the accident anticipation and
risky region localization tasks. We propose a novel soft-attention Recurrent
Neural Network (RNN) which explicitly models both spatial and appearance-wise
non-linear interaction between the agent triggering the event and another agent
or static-region involved. In order to test our proposed method, we introduce
the Epic Fail (EF) dataset consisting of 3000 viral videos capturing various
accidents. In the experiments, we evaluate the risk assessment accuracy both in
the temporal domain (accident anticipation) and spatial domain (risky region
localization) on our EF dataset and the Street Accident (SA) dataset. Our
method consistently outperforms other baselines on both datasets.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06564</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stepwise Debugging of Answer-Set Programs</dc:title>
 <dc:creator>Oetsch, Johannes</dc:creator>
 <dc:creator>P&#xfc;hrer, J&#xf6;rg</dc:creator>
 <dc:creator>Tompits, Hans</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>68N17, 68T27</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:description>  We introduce a stepping methodology for answer-set programming (ASP) that
allows for debugging answer-set programs and is based on the stepwise
application of rules. Similar to debugging in imperative languages, where the
behaviour of a program is observed during a step-by-step execution, stepping
for ASP allows for observing the effects that rule applications have in the
computation of an answer set. While the approach is inspired from debugging in
imperative programming, it is conceptually different to stepping in other
paradigms due to non-determinism and declarativity that are inherent to ASP. In
particular, unlike statements in an imperative program that are executed
following a strict control flow, there is no predetermined order in which to
consider rules in ASP during a computation. In our approach, the user is free
to decide which rule to consider active in the next step following his or her
intuition. This way, one can focus on interesting parts of the debugging search
space. Bugs are detected during stepping by revealing differences between the
actual semantics of the program and the expectations of the user. As a solid
formal basis for stepping, we develop a framework of computations for
answer-set programs. For fully supporting different solver languages, we build
our framework on an abstract ASP language that is sufficiently general to
capture different solver languages. To this end, we make use of abstract
constraints as an established abstraction for popular language constructs such
as aggregates. Stepping has been implemented in SeaLion, an integrated
development environment for ASP. We illustrate stepping using an example
scenario and discuss the stepping plugin of SeaLion. Moreover, we elaborate on
methodological aspects and the embedding of stepping in the ASP development
process.
</dc:description>
 <dc:description>Comment: Under consideration in Theory and Practice of Logic Programming
  (TPLP)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06566</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Texture Manifolds with the Periodic Spatial GAN</dc:title>
 <dc:creator>Bergmann, Urs</dc:creator>
 <dc:creator>Jetchev, Nikolay</dc:creator>
 <dc:creator>Vollgraf, Roland</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper introduces a novel approach to texture synthesis based on
generative adversarial networks (GAN) (Goodfellow et al., 2014). We extend the
structure of the input noise distribution by constructing tensors with
different types of dimensions. We call this technique Periodic Spatial GAN
(PSGAN). The PSGAN has several novel abilities which surpass the current state
of the art in texture synthesis. First, we can learn multiple textures from
datasets of one or more complex large images. Second, we show that the image
generation with PSGANs has properties of a texture manifold: we can smoothly
interpolate between samples in the structured noise space and generate novel
samples, which lie perceptually between the textures of the original dataset.
In addition, we can also accurately learn periodical textures. We make multiple
experiments which show that PSGANs can flexibly handle diverse texture and
image data sources. Our method is highly scalable and it can generate output
images of arbitrary large size.
</dc:description>
 <dc:description>Comment: Proceedings of the 34th International Conference on Machine Learning,
  Sydney, Australia, 2017. JMLR: W&amp;CP. Copyright 2017 by the author(s)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06573</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online learnability of Statistical Relational Learning in anomaly
  detection</dc:title>
 <dc:creator>J&#xe4;ndel, Magnus</dc:creator>
 <dc:creator>Svenson, Pontus</dc:creator>
 <dc:creator>Wadstr&#xf6;mer, Niclas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Statistical Relational Learning (SRL) methods for anomaly detection are
introduced via a security-related application. Operational requirements for
online learning stability are outlined and compared to mathematical definitions
as applied to the learning process of a representative SRL method - Bayesian
Logic Programs (BLP). Since a formal proof of online stability appears to be
impossible, tentative common sense requirements are formulated and tested by
theoretical and experimental analysis of a simple and analytically tractable
BLP model. It is found that learning algorithms in initial stages of online
learning can lock on unstable false predictors that nevertheless comply with
our tentative stability requirements and thus masquerade as bona fide
solutions. The very expressiveness of SRL seems to cause significant stability
issues in settings with many variables and scarce data. We conclude that
reliable anomaly detection with SRL-methods requires monitoring by an
overarching framework that may involve a comprehensive context knowledge base
or human supervision.
</dc:description>
 <dc:description>Comment: 8 pages. Author contact xpontus@gmail.com</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06573</dc:identifier>
 <dc:identifier>Proc 15th Int Conf Information Fusion (2012)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06575</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sympiler: Transforming Sparse Matrix Codes by Decoupling Symbolic
  Analysis</dc:title>
 <dc:creator>Cheshmi, Kazem</dc:creator>
 <dc:creator>Kamil, Shoaib</dc:creator>
 <dc:creator>Strout, Michelle Mills</dc:creator>
 <dc:creator>Dehnavi, Maryam Mehri</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Sympiler is a domain-specific code generator that optimizes sparse matrix
computations by decoupling the symbolic analysis phase from the numerical
manipulation stage in sparse codes. The computation patterns in sparse
numerical methods are guided by the input sparsity structure and the sparse
algorithm itself. In many real-world simulations, the sparsity pattern changes
little or not at all. Sympiler takes advantage of these properties to
symbolically analyze sparse codes at compile-time and to apply inspector-guided
transformations that enable applying low-level transformations to sparse codes.
As a result, the Sympiler-generated code outperforms highly-optimized matrix
factorization codes from commonly-used specialized libraries, obtaining average
speedups over Eigen and CHOLMOD of 3.8X and 1.5X respectively.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06575</dc:identifier>
 <dc:identifier>in SC 2017, Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and Analysis</dc:identifier>
 <dc:identifier>doi:10.1145/3126908.3126936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06578</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An evidential Markov decision making model</dc:title>
 <dc:creator>He, Zichang</dc:creator>
 <dc:creator>Jiang, Wen</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  The sure thing principle and the law of total probability are basic laws in
classic probability theory. A disjunction fallacy leads to the violation of
these two classical laws. In this paper, an Evidential Markov (EM) decision
making model based on Dempster-Shafer (D-S) evidence theory and Markov
modelling is proposed to address this issue and model the real human
decision-making process. In an evidential framework, the states are extended by
introducing an uncertain state which represents the hesitance of a decision
maker. The classical Markov model can not produce the disjunction effect, which
assumes that a decision has to be certain at one time. However, the state is
allowed to be uncertain in the EM model before the final decision is made. An
extra uncertainty degree parameter is defined by a belief entropy, named Deng
entropy, to assignment the basic probability assignment of the uncertain state,
which is the key to predict the disjunction effect. A classical categorization
decision-making experiment is used to illustrate the effectiveness and validity
of EM model. The disjunction effect can be well predicted and the free
parameters are less compared with the existing models.
</dc:description>
 <dc:description>Comment: 38 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1703.02386</dc:description>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06586</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunities in Software Engineering Research for Web API Consumption</dc:title>
 <dc:creator>Wittern, Erik</dc:creator>
 <dc:creator>Ying, Annie</dc:creator>
 <dc:creator>Zheng, Yunhui</dc:creator>
 <dc:creator>Laredo, Jim A.</dc:creator>
 <dc:creator>Dolby, Julian</dc:creator>
 <dc:creator>Young, Christopher C.</dc:creator>
 <dc:creator>Slominski, Aleksander A.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Nowadays, invoking third party code increasingly involves calling web
services via their web APIs, as opposed to the more traditional scenario of
downloading a library and invoking the library's API. However, there are also
new challenges for developers calling these web APIs. In this paper, we
highlight a broad set of these challenges and argue for resulting opportunities
for software engineering research to support developers in consuming web APIs.
We outline two specific research threads in this context: (1) web API
specification curation, which enables us to know the signatures of web APIs,
and (2) static analysis that is capable of extracting URLs, HTTP methods etc.
of web API calls. Furthermore, we present new work on how we combine (1) and
(2) to provide IDE support for application developers consuming web APIs. As
web APIs are used broadly, research in supporting the consumption of web APIs
offers exciting opportunities.
</dc:description>
 <dc:description>Comment: Erik Wittern and Annie Ying are both first authors</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06597</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factors in Recommending Contrarian Content on Social Media</dc:title>
 <dc:creator>Garimella, Kiran</dc:creator>
 <dc:creator>Morales, Gianmarco De Francisci</dc:creator>
 <dc:creator>Gionis, Aristides</dc:creator>
 <dc:creator>Mathioudakis, Michael</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Polarization is a troubling phenomenon that can lead to societal divisions
and hurt the democratic process. It is therefore important to develop methods
to reduce it.
  We propose an algorithmic solution to the problem of reducing polarization.
The core idea is to expose users to content that challenges their point of
view, with the hope broadening their perspective, and thus reduce their
polarity. Our method takes into account several aspects of the problem, such as
the estimated polarity of the user, the probability of accepting the
recommendation, the polarity of the content, and popularity of the content
being recommended.
  We evaluate our recommendations via a large-scale user study on Twitter users
that were actively involved in the discussion of the US elections results.
Results shows that, in most cases, the factors taken into account in the
recommendation affect the users as expected, and thus capture the essential
features of the problem.
</dc:description>
 <dc:description>Comment: accepted as a short paper at ACM WebScience 2017. arXiv admin note:
  substantial text overlap with arXiv:1703.10934</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06599</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Localized LRR on Grassmann Manifolds: An Extrinsic View</dc:title>
 <dc:creator>Wang, Boyue</dc:creator>
 <dc:creator>Hu, Yongli</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Sun, Yanfeng</dc:creator>
 <dc:creator>Yin, Baocai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Subspace data representation has recently become a common practice in many
computer vision tasks. It demands generalizing classical machine learning
algorithms for subspace data. Low-Rank Representation (LRR) is one of the most
successful models for clustering vectorial data according to their subspace
structures. This paper explores the possibility of extending LRR for subspace
data on Grassmann manifolds. Rather than directly embedding the Grassmann
manifolds into the symmetric matrix space, an extrinsic view is taken to build
the LRR self-representation in the local area of the tangent space at each
Grassmannian point, resulting in a localized LRR method on Grassmann manifolds.
A novel algorithm for solving the proposed model is investigated and
implemented. The performance of the new clustering algorithm is assessed
through experiments on several real-world datasets including MNIST handwritten
digits, ballet video clips, SKIG action clips, DynTex++ dataset and highway
traffic video clips. The experimental results show the new method outperforms a
number of state-of-the-art clustering methods
</dc:description>
 <dc:description>Comment: IEEE Transactions on Circuits and Systems for Video Technology with
  Minor Revisions. arXiv admin note: text overlap with arXiv:1504.01807</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06604</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of the effectiveness of the truth-spreading strategy for
  inhibiting rumors</dc:title>
 <dc:creator>Yang, Lu-Xing</dc:creator>
 <dc:creator>Li, Pengdeng</dc:creator>
 <dc:creator>Yang, Xiaofan</dc:creator>
 <dc:creator>Wu, Yingbo</dc:creator>
 <dc:creator>Tang, Yuan Yan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Spreading truths is recognized as a feasible strategy for inhibiting rumors.
This paper is devoted to assessing the effectiveness of the truth-spreading
strategy. An individual-level rumor-truth spreading model (the generic URTU
model) is derived. Under the model, two criteria for the termination of a rumor
are presented. These criteria capture the influence of the network structures
on the effectiveness of the truth-spreading strategy. Extensive simulations
show that, when the rumor or the truth terminates, the dynamics of a simplified
URTU model (the linear URTU model) fits well with the actual rumor-truth
interplay process. Therefore, the generic URTU model forms a theoretical basis
for assessing the effectiveness of the truth-spreading strategy for restraining
rumors.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1705.04818</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06609</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the weak order ideal associated to linear codes</dc:title>
 <dc:creator>Borges-Quintana, M.</dc:creator>
 <dc:creator>Borges-Trenard, M. A.</dc:creator>
 <dc:creator>Martinez-Moro, E.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work we study a weak order ideal associated with the coset leaders of
a non-binary linear code. This set allows the incrementally computation of the
coset leaders and the definitions of the set of leader codewords. This set of
codewords has some nice properties related to the monotonicity of the weight
compatible order on the generalized support of a vector in $\mathbb F_q^n$
which allow us to describe a test set, a trial set and the set of zero
neighbours of a linear code in terms of the leader codewords.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1411.7493</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06614</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Bayesian inference as a gauge theory</dc:title>
 <dc:creator>Sengupta, Biswa</dc:creator>
 <dc:creator>Friston, Karl</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In a published paper [Sengupta, 2016], we have proposed that the brain (and
other self-organized biological and artificial systems) can be characterized
via the mathematical apparatus of a gauge theory. The picture that emerges from
this approach suggests that any biological system (from a neuron to an
organism) can be cast as resolving uncertainty about its external milieu,
either by changing its internal states or its relationship to the environment.
Using formal arguments, we have shown that a gauge theory for neuronal dynamics
-- based on approximate Bayesian inference -- has the potential to shed new
light on phenomena that have thus far eluded a formal description, such as
attention and the link between action and perception. Here, we describe the
technical apparatus that enables such a variational inference on manifolds.
Particularly, the novel contribution of this paper is an algorithm that utlizes
a Schild's ladder for parallel transport of sufficient statistics (means,
covariances, etc.) on a statistical manifold.
</dc:description>
 <dc:description>Comment: Extended version published in PLoS Biology, ICML 2017 Computational
  Biology Workshop (spotlight presentation)</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06614</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pbio.1002400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06616</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensor Array Design Through Submodular Optimization</dc:title>
 <dc:creator>Shulkind, Gal</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:creator>Wornell, Gregory W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of far-field sensing by means of a sensor array.
Traditional array geometry design techniques are agnostic to prior information
about the far-field scene. However, in many applications such priors are
available and may be utilized to design more efficient array topologies. We
formulate the problem of array geometry design with scene prior as one of
finding a sampling configuration that enables efficient inference, which turns
out to be a combinatorial optimization problem. While generic combinatorial
optimization problems are NP-hard and resist efficient solvers, we show how for
array design problems the theory of submodular optimization may be utilized to
obtain efficient algorithms that are guaranteed to achieve solutions within a
constant approximation factor from the optimum. We leverage the connection
between array design problems and submodular optimization and port several
results of interest. We demonstrate efficient methods for designing arrays with
constraints on the sensing aperture, as well as arrays respecting combinatorial
placement constraints. This novel connection between array design and
submodularity suggests the possibility for utilizing other insights and
techniques from the growing body of literature on submodular optimization in
the field of array design.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06623</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing Identical Items</dc:title>
 <dc:creator>Ezra, Tomer</dc:creator>
 <dc:creator>Feldman, Michal</dc:creator>
 <dc:creator>Roughgarden, Tim</dc:creator>
 <dc:creator>Suksompong, Warut</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study the power and limitations of posted prices in markets with identical
items, where agents arrive sequentially in an arbitrary order. We prove upper
and lower bounds on the largest fraction of the optimal social welfare that can
be guaranteed with posted prices, under a range of assumptions about the
designer's information and agents' valuations. For example, we prove
constant-factor guarantees for agents with (symmetric) subadditive valuations,
even in an incomplete-information setting and with uniform prices.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06628</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust tracking of respiratory rate in high-dynamic range scenes using
  mobile thermal imaging</dc:title>
 <dc:creator>Cho, Youngjun</dc:creator>
 <dc:creator>Julier, Simon J.</dc:creator>
 <dc:creator>Marquardt, Nicolai</dc:creator>
 <dc:creator>Bianchi-Berthouze, Nadia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  The ability to monitor respiratory rate is extremely important for medical
treatment, healthcare and fitness sectors. In many situations, mobile methods,
which allow users to undertake every day activities, are required. However,
current monitoring systems can be obtrusive, requiring users to wear
respiration belts or nasal probes. Recent advances in thermographic systems
have shrunk their size, weight and cost, to the point where it is possible to
create smart-phone based respiration rate monitoring devices that are not
affected by lighting conditions. However, mobile thermal imaging is challenged
in scenes with high thermal dynamic ranges. This challenge is further amplified
by general problems such as motion artifacts and low spatial resolution,
leading to unreliable breathing signals. In this paper, we propose a novel and
robust approach for respiration tracking which compensates for the negative
effects of variations in the ambient temperature and motion artifacts and can
accurately extract breathing rates in highly dynamic thermal scenes. It has
three main contributions. The first is a novel Optimal Quantization technique
which adaptively constructs a color mapping of absolute temperature to improve
segmentation, classification and tracking. The second is the Thermal Gradient
Flow method that computes thermal gradient magnitude maps to enhance accuracy
of the nostril region tracking. Finally, we introduce the Thermal Voxel method
to increase the reliability of the captured respiration signals compared to the
traditional averaging method. We demonstrate the extreme robustness of our
system to track the nostril-region and measure the respiratory rate in high
dynamic range scenes.
</dc:description>
 <dc:description>Comment: Vol. 8, No. 10, 1 Oct 2017, Biomedical Optics Express 4480 - Full
  abstract can be found in this journal article (due to limited word counts of
  'arXiv abstract')</dc:description>
 <dc:date>2017-05-08</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06628</dc:identifier>
 <dc:identifier>Biomedical Optics Express, 2017</dc:identifier>
 <dc:identifier>doi:10.1364/BOE.8.004480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06629</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who you gonna call? Analyzing Web Requests in Android Applications</dc:title>
 <dc:creator>Rapoport, Marianna</dc:creator>
 <dc:creator>Suter, Philippe</dc:creator>
 <dc:creator>Wittern, Erik</dc:creator>
 <dc:creator>Lhot&#xe1;k, Ond&#x159;ej</dc:creator>
 <dc:creator>Dolby, Julian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Relying on ubiquitous Internet connectivity, applications on mobile devices
frequently perform web requests during their execution. They fetch data for
users to interact with, invoke remote functionalities, or send user-generated
content or meta-data. These requests collectively reveal common practices of
mobile application development, like what external services are used and how,
and they point to possible negative effects like security and privacy
violations, or impacts on battery life. In this paper, we assess different ways
to analyze what web requests Android applications make. We start by presenting
dynamic data collected from running 20 randomly selected Android applications
and observing their network activity. Next, we present a static analysis tool,
Stringoid, that analyzes string concatenations in Android applications to
estimate constructed URL strings. Using Stringoid, we extract URLs from 30, 000
Android applications, and compare the performance with a simpler constant
extraction analysis. Finally, we present a discussion of the advantages and
limitations of dynamic and static analyses when extracting URLs, as we compare
the data extracted by Stringoid from the same 20 applications with the
dynamically collected data.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06631</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust randomized matchings</dc:title>
 <dc:creator>Matuschke, Jannik</dc:creator>
 <dc:creator>Skutella, Martin</dc:creator>
 <dc:creator>Soto, Jos&#xe9; A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The following game is played on a weighted graph: Alice selects a matching
$M$ and Bob selects a number $k$. Alice's payoff is the ratio of the weight of
the $k$ heaviest edges of $M$ to the maximum weight of a matching of size at
most $k$. If $M$ guarantees a payoff of at least $\alpha$ then it is called
$\alpha$-robust. In 2002, Hassin and Rubinstein gave an algorithm that returns
a $1/\sqrt{2}$-robust matching, which is best possible.
  We show that Alice can improve her payoff to $1/\ln(4)$ by playing a
randomized strategy. This result extends to a very general class of
independence systems that includes matroid intersection, b-matchings, and
strong 2-exchange systems. It also implies an improved approximation factor for
a stochastic optimization variant known as the maximum priority matching
problem and translates to an asymptotic robustness guarantee for deterministic
matchings, in which Bob can only select numbers larger than a given constant.
Moreover, we give a new LP-based proof of Hassin and Rubinstein's bound.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06640</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepXplore: Automated Whitebox Testing of Deep Learning Systems</dc:title>
 <dc:creator>Pei, Kexin</dc:creator>
 <dc:creator>Cao, Yinzhi</dc:creator>
 <dc:creator>Yang, Junfeng</dc:creator>
 <dc:creator>Jana, Suman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Deep learning (DL) systems are increasingly deployed in safety- and
security-critical domains including self-driving cars and malware detection,
where the correctness and predictability of a system's behavior for corner case
inputs are of great importance. Existing DL testing depends heavily on manually
labeled data and therefore often fails to expose erroneous behaviors for rare
inputs.
  We design, implement, and evaluate DeepXplore, the first whitebox framework
for systematically testing real-world DL systems. First, we introduce neuron
coverage for systematically measuring the parts of a DL system exercised by
test inputs. Next, we leverage multiple DL systems with similar functionality
as cross-referencing oracles to avoid manual checking. Finally, we demonstrate
how finding inputs for DL systems that both trigger many differential behaviors
and achieve high neuron coverage can be represented as a joint optimization
problem and solved efficiently using gradient-based search techniques.
  DeepXplore efficiently finds thousands of incorrect corner case behaviors
(e.g., self-driving cars crashing into guard rails and malware masquerading as
benign software) in state-of-the-art DL models with thousands of neurons
trained on five popular datasets including ImageNet and Udacity self-driving
challenge data. For all tested DL models, on average, DeepXplore generated one
test input demonstrating incorrect behavior within one second while running
only on a commodity laptop. We further show that the test inputs generated by
DeepXplore can also be used to retrain the corresponding DL model to improve
the model's accuracy by up to 3%.
</dc:description>
 <dc:description>Comment: To be published in SOSP'17</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-09-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06640</dc:identifier>
 <dc:identifier>doi:10.1145/3132747.3132785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06643</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetric Convex Sets with Minimal Gaussian Surface Area</dc:title>
 <dc:creator>Heilman, Steven</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:description>  Let $\Omega\subset\mathbb{R}^{n+1}$ have minimal Gaussian surface area among
all sets satisfying $\Omega=-\Omega$ with fixed Gaussian volume. Let $A=A_{x}$
be the second fundamental form of $\partial\Omega$ at $x$, i.e. $A$ is the
matrix of first order partial derivatives of the unit normal vector at
$x\in\partial\Omega$. For any $x=(x_{1},\ldots,x_{n+1})\in\mathbb{R}^{n+1}$,
let $\gamma_{n}(x)=(2\pi)^{-n/2}e^{-(x_{1}^{2}+\cdots+x_{n+1}^{2})/2}$. Let
$\|A\|^{2}$ be the sum of the squares of the entries of $A$, and let
$\|A\|_{2\to 2}$ denote the $\ell_{2}$ operator norm of $A$.
  It is shown that if $\Omega$ or $\Omega^{c}$ is convex, and if either
$$\int_{\partial\Omega}(\|A_{x}\|^{2}-1)\gamma_{n}(x)dx&gt;0\qquad\mbox{or}\qquad
\int_{\partial\Omega}\Big(\|A_{x}\|^{2}-1+2\sup_{y\in\partial\Omega}\|A_{y}\|_{2\to
2}^{2}\Big)\gamma_{n}(x)dx&lt;0,$$ then $\partial\Omega$ must be a round cylinder.
That is, except for the case that the average value of $\|A\|^{2}$ is slightly
less than $1$, we resolve the convex case of a question of Barthe from 2001.
  The main tool is the Colding-Minicozzi theory for Gaussian minimal surfaces,
which studies eigenfunctions of the Ornstein-Uhlenbeck type operator $L=
\Delta-\langle x,\nabla \rangle+\|A\|^{2}+1$ associated to the surface
$\partial\Omega$. A key new ingredient is the use of a randomly chosen degree 2
polynomial in the second variation formula for the Gaussian surface area. Our
actual results are a bit more general than the above statement. Also, some of
our results hold without the assumption of convexity.
</dc:description>
 <dc:description>Comment: 50 pages, typos corrected, new section added</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06659</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anomaly Detection in Business Process Runtime Behavior -- Challenges and
  Limitations</dc:title>
 <dc:creator>B&#xf6;hmer, Kristof</dc:creator>
 <dc:creator>Rinderle-Ma, Stefanie</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Anomaly detection is generally acknowledged as an important problem that has
already drawn attention to various domains and research areas, such as, network
security. For such &quot;classic&quot; application domains a wide range of surveys and
literature reviews exist already - which is not the case for the process
domain. Hence, this systematic literature review strives to provide an
organized holistic view on research related to business process runtime
behavior anomaly detection. For this the unique challenges of the process
domain are outlined along with the nature of the analyzed data and data
sources. Moreover, existing work is identified and categorized based on the
underlying fundamental technology applied by each work. Furthermore, this work
describes advantages and disadvantages of each identified approach. Based on
these information limitations and gaps in existing research are identified and
recommendations are proposed to tackle them. This work aims to foster the
understanding and development of the process anomaly detection domain.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06661</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spin Summations: A High-Performance Perspective</dc:title>
 <dc:creator>Springer, Paul</dc:creator>
 <dc:creator>Matthews, Devin</dc:creator>
 <dc:creator>Bientinesi, Paolo</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:description>  Besides tensor contractions, one of the most pronounced computational
bottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry
methods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and
CCSDT(Q)---are spin summations. At a first sight, spin summations are
operations similar to tensor transpositions; a closer look instead reveals
additional challenges to high-performance calculations, including temporal
locality as well as scattered memory accesses. This publication explores a
sequence of algorithmic solutions for spin summations, each exploiting
individual properties of either the underlying hardware (e.g. caches,
vectorization), or the problem itself (e.g. factorizability). The final
algorithm combines the advantages of all the solutions, while avoiding their
drawbacks; this algorithm, achieves high-performance through parallelization,
vectorization, and by exploiting the temporal locality inherent to spin
summations. Combined, these optimizations result in speedups between 2.4x and
5.5x over the NCC quantum chemistry software package. In addition to such a
performance boost, our algorithm can perform the spin summations in-place, thus
reducing the memory footprint by 2x over an out-of-place variant.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06662</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Term Hiding to Reduce Run-time Checking Overhead</dc:title>
 <dc:creator>Stulova, Nataliia</dc:creator>
 <dc:creator>Morales, Jos&#xe9; F.</dc:creator>
 <dc:creator>Hermenegildo, Manuel V.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.1</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  One of the most attractive features of untyped languages is the flexibility
in term creation and manipulation. However, with such power comes the
responsibility of ensuring the correctness of these operations. A solution is
adding run-time checks to the program via assertions, but this can introduce
overheads that are in many cases impractical. While static analysis can greatly
reduce such overheads, the gains depend strongly on the quality of the
information inferred. Reusable libraries, i.e., library modules that are
pre-compiled independently of the client, pose special challenges in this
context. We propose a technique which takes advantage of module systems which
can hide a selected set of functor symbols to significantly enrich the shape
information that can be inferred for reusable libraries, as well as an improved
run-time checking approach that leverages the proposed mechanisms to achieve
large reductions in overhead, closer to those of static languages, even in the
reusable-library context. While the approach is general and system-independent,
we present it for concreteness in the context of the Ciao assertion language
and combined static/dynamic checking framework. Our method maintains the full
expressiveness of the assertion language in this context. In contrast to other
approaches it does not introduce the need to switch the language to a (static)
type system, which is known to change the semantics in languages like Prolog.
We also study the approach experimentally and evaluate the overhead reduction
achieved in the run-time checks.
</dc:description>
 <dc:description>Comment: 26 pages, 10 figures, 2 tables; an extension of the paper version
  accepted to PADL'18 (includes proofs, extra figures and examples omitted due
  to space reasons)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06663</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Sustainable Traffic Steering for 5G Mobile Networks</dc:title>
 <dc:creator>Zhang, Shan</dc:creator>
 <dc:creator>Zhang, Ning</dc:creator>
 <dc:creator>Zhou, Sheng</dc:creator>
 <dc:creator>Gong, Jie</dc:creator>
 <dc:creator>Niu, Zhisheng</dc:creator>
 <dc:creator>Xuemin</dc:creator>
 <dc:creator>Shen</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Renewable energy harvesting (EH) technology is expected to be pervasively
utilized in the next generation (5G) mobile networks to support sustainable
network developments and operations. However, the renewable energy supply is
inherently random and intermittent, which could lead to energy outage, energy
overflow, quality of service (QoS) degradation, etc. Accordingly, how to
enhance renewable energy sustainability is a critical issue for green
networking. To this end, an energy-sustainable traffic steering framework is
proposed in this article, where the traffic load is dynamically adjusted to
match with energy distributions in both spatial and temporal domains by means
of inter- and intra-tier steering, caching and pushing. Case studies are
carried out, which demonstrate the proposed framework can reduce on-grid energy
demand while satisfying QoS requirements. Research topics and challenges of
energy-sustainable traffic steering are also discussed.
</dc:description>
 <dc:description>Comment: IEEE Communications Magazine (to appear)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06668</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introducing Geometric Algebra to Geometric Computing Software
  Developers: A Computational Thinking Approach</dc:title>
 <dc:creator>Eid, Ahmad Hosny</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems.
</dc:description>
 <dc:description>Comment: Tutorial, 43 pages, 3 figures</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06670</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilayer Codes for Synchronization from Deletions</dc:title>
 <dc:creator>Abroshan, Mahed</dc:creator>
 <dc:creator>Venkataramanan, Ramji</dc:creator>
 <dc:creator>Fabregas, Albert Guillen i</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider two remote nodes, each having a binary sequence. The sequence at one
node differs from the other by a small number of deletions. The node with the
shorter sequence wishes to reconstruct the longer sequence using minimal
information from the other node. In this paper, we devise a coding scheme for
this one-way synchronization model. The scheme is based on multiple layers of
Varshamov-Tenenglots codes combined with off-the-shelf linear error-correcting
codes.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06674</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wearable Health Monitoring Using Capacitive Voltage-Mode Human Body
  Communication</dc:title>
 <dc:creator>Maity, Shovan</dc:creator>
 <dc:creator>Das, Debayan</dc:creator>
 <dc:creator>Sen, Shreyas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Rapid miniaturization and cost reduction of computing, along with the
availability of wearable and implantable physiological sensors have led to the
growth of human Body Area Network (BAN) formed by a network of such sensors and
computing devices. One promising application of such a network is wearable
health monitoring where the collected data from the sensors would be
transmitted and analyzed to assess the health of a person. Typically, the
devices in a BAN are connected through wireless (WBAN), which suffers from
energy inefficiency due to the high-energy consumption of wireless
transmission. Human Body Communication (HBC) uses the relatively low loss human
body as the communication medium to connect these devices, promising order(s)
of magnitude better energy-efficiency and built-in security compared to WBAN.
In this paper, we demonstrate a health monitoring device and system built using
Commercial-Off-The- Shelf (COTS) sensors and components, that can collect data
from physiological sensors and transmit it through a) intra-body HBC to another
device (hub) worn on the body or b) upload health data through HBC-based
human-machine interaction to an HBC capable machine. The system design
constraints and signal transfer characteristics for the implemented HBC-based
wearable health monitoring system are measured and analyzed, showing reliable
connectivity with &gt;8x power savings compared to Bluetooth lowenergy (BTLE).
</dc:description>
 <dc:description>Comment: International Conference of the IEEE Engineering in Medicine and
  Biology Society (EMBC 17)</dc:description>
 <dc:date>2017-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06676</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MUTAN: Multimodal Tucker Fusion for Visual Question Answering</dc:title>
 <dc:creator>Ben-younes, Hedi</dc:creator>
 <dc:creator>Cadene, R&#xe9;mi</dc:creator>
 <dc:creator>Cord, Matthieu</dc:creator>
 <dc:creator>Thome, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Bilinear models provide an appealing framework for mixing and merging
information in Visual Question Answering (VQA) tasks. They help to learn high
level associations between question meaning and visual concepts in the image,
but they suffer from huge dimensionality issues. We introduce MUTAN, a
multimodal tensor-based Tucker decomposition to efficiently parametrize
bilinear interactions between visual and textual representations. Additionally
to the Tucker framework, we design a low-rank matrix-based decomposition to
explicitly constrain the interaction rank. With MUTAN, we control the
complexity of the merging scheme while keeping nice interpretable fusion
relations. We show how our MUTAN model generalizes some of the latest VQA
architectures, providing state-of-the-art results.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06681</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Regular Tree Grammars with Storage</dc:title>
 <dc:creator>F&#xfc;l&#xf6;p, Zolt&#xe1;n</dc:creator>
 <dc:creator>Herrmann, Luisa</dc:creator>
 <dc:creator>Vogler, Heiko</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  We introduce weighted regular tree grammars with storage as combination of
(a) regular tree grammars with storage and (b) weighted tree automata over
multioperator monoids. Each weighted regular tree grammar with storage
generates a weighted tree language, which is a mapping from the set of trees to
the multioperator monoid. We prove that, for multioperator monoids canonically
associated to particular strong bimonoids, the support of the generated
weighted tree languages can be generated by (unweighted) regular tree grammars
with storage. We characterize the class of all generated weighted tree
languages by the composition of three basic concepts. Moreover, we prove
results on the elimination of chain rules and of finite storage types, and we
characterize weighted regular tree grammars with storage by a new weighted
MSO-logic.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06687</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Target-Quality Image Compression with Recurrent, Convolutional Neural
  Networks</dc:title>
 <dc:creator>Covell, Michele</dc:creator>
 <dc:creator>Johnston, Nick</dc:creator>
 <dc:creator>Minnen, David</dc:creator>
 <dc:creator>Hwang, Sung Jin</dc:creator>
 <dc:creator>Shor, Joel</dc:creator>
 <dc:creator>Singh, Saurabh</dc:creator>
 <dc:creator>Vincent, Damien</dc:creator>
 <dc:creator>Toderici, George</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a stop-code tolerant (SCT) approach to training recurrent
convolutional neural networks for lossy image compression. Our methods
introduce a multi-pass training method to combine the training goals of
high-quality reconstructions in areas around stop-code masking as well as in
highly-detailed areas. These methods lead to lower true bitrates for a given
recursion count, both pre- and post-entropy coding, even using unstructured
LZ77 code compression. The pre-LZ77 gains are achieved by trimming stop codes.
The post-LZ77 gains are due to the highly unequal distributions of 0/1 codes
from the SCT architectures. With these code compressions, the SCT architecture
maintains or exceeds the image quality at all compression rates compared to
JPEG and to RNN auto-encoders across the Kodak dataset. In addition, the SCT
coding results in lower variance in image quality across the extent of the
image, a characteristic that has been shown to be important in human ratings of
image quality
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06691</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Dynamic Analysis of Android Apps Using Hybrid Test Input
  Generation</dc:title>
 <dc:creator>Alzaylaee, Mohammed K.</dc:creator>
 <dc:creator>Yerima, Suleiman Y.</dc:creator>
 <dc:creator>Sezer, Sakir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Android OS has become the most popular mobile operating system leading to
a significant increase in the spread of Android malware. Consequently, several
static and dynamic analysis systems have been developed to detect Android
malware. With dynamic analysis, efficient test input generation is needed in
order to trigger the potential run-time malicious behaviours. Most existing
dynamic analysis systems employ random-based input generation methods usually
built using the Android Monkey tool. Random-based input generation has several
shortcomings including limited code coverage, which motivates us to explore
combining it with a state-based method in order to improve efficiency. Hence,
in this paper, we present a novel hybrid test input generation approach
designed to improve dynamic analysis on real devices. We implemented the hybrid
system by integrating a random based tool (Monkey) with a state based tool
(DroidBot) in order to improve code coverage and potentially uncover more
malicious behaviours. The system is evaluated using 2,444 Android apps
containing 1222 benign and 1222 malware samples from the Android malware genome
project. Three scenarios, random only, state-based only, and our proposed
hybrid approach were investigated to comparatively evaluate their performances.
Our study shows that the hybrid approach significantly improved the amount of
dynamic features extracted from both benign and malware samples over the
state-based and commonly used random test input generation method.
</dc:description>
 <dc:description>Comment: International Conference On Cyber Security And Protection Of Digital
  Services (Cyber Security 2017)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06691</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06693</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limited-Memory Matrix Adaptation for Large Scale Black-box Optimization</dc:title>
 <dc:creator>Loshchilov, Ilya</dc:creator>
 <dc:creator>Glasmachers, Tobias</dc:creator>
 <dc:creator>Beyer, Hans-Georg</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a popular
method to deal with nonconvex and/or stochastic optimization problems when the
gradient information is not available. Being based on the CMA-ES, the recently
proposed Matrix Adaptation Evolution Strategy (MA-ES) provides a rather
surprising result that the covariance matrix and all associated operations
(e.g., potentially unstable eigendecomposition) can be replaced in the CMA-ES
by a updated transformation matrix without any loss of performance. In order to
further simplify MA-ES and reduce its $\mathcal{O}\big(n^2\big)$ time and
storage complexity to $\mathcal{O}\big(n\log(n)\big)$, we present the
Limited-Memory Matrix Adaptation Evolution Strategy (LM-MA-ES) for efficient
zeroth order large-scale optimization. The algorithm demonstrates
state-of-the-art performance on a set of established large-scale benchmarks. We
explore the algorithm on the problem of generating adversarial inputs for a
(non-smooth) random forest classifier, demonstrating a surprising vulnerability
of the classifier.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06693</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06694</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>I Probe, Therefore I Am: Designing a Virtual Journalist with Human
  Emotions</dc:title>
 <dc:creator>Bowden, Kevin K.</dc:creator>
 <dc:creator>Nilsson, Tommy</dc:creator>
 <dc:creator>Spencer, Christine P.</dc:creator>
 <dc:creator>Cengiz, Kubra</dc:creator>
 <dc:creator>Ghitulescu, Alexandru</dc:creator>
 <dc:creator>van Waterschoot, Jelte B.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>68T42</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.3.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  By utilizing different communication channels, such as verbal language,
gestures or facial expressions, virtually embodied interactive humans hold a
unique potential to bridge the gap between human-computer interaction and
actual interhuman communication. The use of virtual humans is consequently
becoming increasingly popular in a wide range of areas where such a natural
communication might be beneficial, including entertainment, education, mental
health research and beyond. Behind this development lies a series of
technological advances in a multitude of disciplines, most notably natural
language processing, computer vision, and speech synthesis. In this paper we
discuss a Virtual Human Journalist, a project employing a number of novel
solutions from these disciplines with the goal to demonstrate their viability
by producing a humanoid conversational agent capable of naturally eliciting and
reacting to information from a human user. A set of qualitative and
quantitative evaluation sessions demonstrated the technical feasibility of the
system whilst uncovering a number of deficits in its capacity to engage users
in a way that would be perceived as natural and emotionally engaging. We argue
that naturalness should not always be seen as a desirable goal and suggest that
deliberately suppressing the naturalness of virtual human interactions, such as
by altering its personality cues, might in some cases yield more desirable
results.
</dc:description>
 <dc:description>Comment: eNTERFACE16 proceedings</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06709</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Spatiotemporal Features for Infrared Action Recognition with 3D
  Convolutional Neural Networks</dc:title>
 <dc:creator>Jiang, Zhuolin</dc:creator>
 <dc:creator>Rozgic, Viktor</dc:creator>
 <dc:creator>Adali, Sancar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Infrared (IR) imaging has the potential to enable more robust action
recognition systems compared to visible spectrum cameras due to lower
sensitivity to lighting conditions and appearance variability. While the action
recognition task on videos collected from visible spectrum imaging has received
much attention, action recognition in IR videos is significantly less explored.
Our objective is to exploit imaging data in this modality for the action
recognition task. In this work, we propose a novel two-stream 3D convolutional
neural network (CNN) architecture by introducing the discriminative code layer
and the corresponding discriminative code loss function. The proposed network
processes IR image and the IR-based optical flow field sequences. We pretrain
the 3D CNN model on the visible spectrum Sports-1M action dataset and finetune
it on the Infrared Action Recognition (InfAR) dataset. To our best knowledge,
this is the first application of the 3D CNN to action recognition in the IR
domain. We conduct an elaborate analysis of different fusion schemes (weighted
average, single and double-layer neural nets) applied to different 3D CNN
outputs. Experimental results demonstrate that our approach can achieve
state-of-the-art average precision (AP) performances on the InfAR dataset: (1)
the proposed two-stream 3D CNN achieves the best reported 77.5% AP, and (2) our
3D CNN model applied to the optical flow fields achieves the best reported
single stream 75.42% AP.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06712</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based Catheter Segmentation in MRI-images</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Pernelle, Guillaume</dc:creator>
 <dc:creator>Barber, Lauren</dc:creator>
 <dc:creator>Pieper, Steve</dc:creator>
 <dc:creator>Fortmeier, Dirk</dc:creator>
 <dc:creator>Wells, Sandy</dc:creator>
 <dc:creator>Handels, Heinz</dc:creator>
 <dc:creator>Kapur, Tina</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate and reliable segmentation of catheters in MR-gui- ded interventions
remains a challenge, and a step of critical importance in clinical workflows.
In this work, under reasonable assumptions, me- chanical model based heuristics
guide the segmentation process allows correct catheter identification rates
greater than 98% (error 2.88 mm), and reduction in outliers to one-fourth
compared to the state of the art. Given distal tips, searching towards the
proximal ends of the catheters is guided by mechanical models that are
estimated on a per-catheter basis. Their bending characteristics are used to
constrain the image fea- ture based candidate points. The final catheter
trajectories are hybrid sequences of individual points, each derived from model
and image fea- tures. We evaluate the method on a database of 10 patient MRI
scans including 101 manually segmented catheters. The mean errors were 1.40 mm
and the median errors were 1.05 mm. The number of outliers devi- ating more
than 2 mm from the gold standard is 7, and the number of outliers deviating
more than 3 mm from the gold standard is just 2.
</dc:description>
 <dc:description>Comment: MICCAI 2015 conference IMIC session</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06715</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous Implicit Authentication for Mobile Devices based on Adaptive
  Neuro-Fuzzy Inference System</dc:title>
 <dc:creator>Yao, Feng</dc:creator>
 <dc:creator>Yerima, Suleiman Y.</dc:creator>
 <dc:creator>Kang, BooJoong</dc:creator>
 <dc:creator>Sezer, Sakir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  As mobile devices have become indispensable in modern life, mobile security
is becoming much more important. Traditional password or PIN-like
point-of-entry security measures score low on usability and are vulnerable to
brute force and other types of attacks. In order to improve mobile security, an
adaptive neuro-fuzzy inference system(ANFIS)-based implicit authentication
system is proposed in this paper to provide authentication in a continuous and
transparent manner.To illustrate the applicability and capability of ANFIS in
our implicit authentication system, experiments were conducted on behavioural
data collected for up to 12 weeks from different Android users. The ability of
the ANFIS-based system to detect an adversary is also tested with scenarios
involving an attacker with varying levels of knowledge. The results demonstrate
that ANFIS is a feasible and efficient approach for implicit authentication
with an average of 95% user recognition rate. Moreover, the use of ANFIS-based
system for implicit authentication significantly reduces manual tuning and
configuration tasks due to its selflearning capability.
</dc:description>
 <dc:description>Comment: International Conference on Cyber Security and Protection of Digital
  Services (Cyber Security 2017)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06730</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for $\ell_p$ Low Rank Approximation</dc:title>
 <dc:creator>Chierichetti, Flavio</dc:creator>
 <dc:creator>Gollapudi, Sreenivas</dc:creator>
 <dc:creator>Kumar, Ravi</dc:creator>
 <dc:creator>Lattanzi, Silvio</dc:creator>
 <dc:creator>Panigrahy, Rina</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the problem of approximating a given matrix by a low-rank matrix
so as to minimize the entrywise $\ell_p$-approximation error, for any $p \geq
1$; the case $p = 2$ is the classical SVD problem. We obtain the first provably
good approximation algorithms for this version of low-rank approximation that
work for every value of $p \geq 1$, including $p = \infty$. Our algorithms are
simple, easy to implement, work well in practice, and illustrate interesting
tradeoffs between the approximation quality, the running time, and the rank of
the approximating matrix.
</dc:description>
 <dc:description>Comment: To appear in ICML</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06738</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verifying Programs via Intermediate Interpretation</dc:title>
 <dc:creator>Lisitsa, Alexei P.</dc:creator>
 <dc:creator>Nemytykh, Andrei P.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We explore an approach to verification of programs via program transformation
applied to an interpreter of a programming language. A specialization technique
known as Turchin's supercompilation is used to specialize some interpreters
with respect to the program models. We show that several safety properties of
functional programs modeling a class of cache coherence protocols can be proved
by a supercompiler and compare the results with our earlier work on direct
verification via supercompilation not using intermediate interpretation.
  Our approach was in part inspired by an earlier work by De E. Angelis et al.
(2014-2015) where verification via program transformation and intermediate
interpretation was studied in the context of specialization of constraint logic
programs.
</dc:description>
 <dc:description>Comment: Fifth International Workshop on Verification and Program
  Transformation (VPT-2017), April 29th, 2017, Uppsala, Sweden, 37 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06753</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering the Graph Structure in the Clustering Results</dc:title>
 <dc:creator>Bauman, Evgeny</dc:creator>
 <dc:creator>Bauman, Konstantin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In a standard cluster analysis, such as k-means, in addition to clusters
locations and distances between them, it's important to know if they are
connected or well separated from each other. The main focus of this paper is
discovering the relations between the resulting clusters. We propose a new
method which is based on pairwise overlapping k-means clustering, that in
addition to means of clusters provides the graph structure of their relations.
The proposed method has a set of parameters that can be tuned in order to
control the sensitivity of the model and the desired relative size of the
pairwise overlapping interval between means of two adjacent clusters, i.e.,
level of overlapping. We present the exact formula for calculating that
parameter. The empirical study presented in the paper demonstrates that our
approach works well not only on toy data but also compliments standard
clustering results with a reasonable graph structure on real datasets, such as
financial indices and restaurants.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06755</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Model for Robust Tensor Factorization with Unknown Noise</dc:title>
 <dc:creator>Chen, Xi'ai</dc:creator>
 <dc:creator>Han, Zhi</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:creator>Zhao, Qian</dc:creator>
 <dc:creator>Meng, Deyu</dc:creator>
 <dc:creator>Lin, Lin</dc:creator>
 <dc:creator>Tang, Yandong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Because of the limitations of matrix factorization, such as losing spatial
structure information, the concept of low-rank tensor factorization (LRTF) has
been applied for the recovery of a low dimensional subspace from high
dimensional visual data. The low-rank tensor recovery is generally achieved by
minimizing the loss function between the observed data and the factorization
representation. The loss function is designed in various forms under different
noise distribution assumptions, like $L_1$ norm for Laplacian distribution and
$L_2$ norm for Gaussian distribution. However, they often fail to tackle the
real data which are corrupted by the noise with unknown distribution. In this
paper, we propose a generalized weighted low-rank tensor factorization method
(GWLRTF) integrated with the idea of noise modelling. This procedure treats the
target data as high-order tensor directly and models the noise by a Mixture of
Gaussians, which is called MoG GWLRTF. The parameters in the model are
estimated under the EM framework and through a new developed algorithm of
weighted low-rank tensor factorization. We provide two versions of the
algorithm with different tensor factorization operations, i.e., CP
factorization and Tucker factorization. Extensive experiments indicate the
respective advantages of this two versions in different applications and also
demonstrate the effectiveness of MoG GWLRTF compared with other competing
methods.
</dc:description>
 <dc:description>Comment: 13 pages, 8 figures</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06769</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Control as Intrinsic Motivation for Hierarchical Reinforcement
  Learning</dc:title>
 <dc:creator>Dilokthanakul, Nat</dc:creator>
 <dc:creator>Kaplanis, Christos</dc:creator>
 <dc:creator>Pawlowski, Nick</dc:creator>
 <dc:creator>Shanahan, Murray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The problem of sparse rewards is one of the hardest challenges in
contemporary reinforcement learning. Hierarchical reinforcement learning (HRL)
tackles this problem by using a set of temporally-extended actions, or options,
each of which has its own subgoal. These subgoals are normally handcrafted for
specific tasks. Here, though, we introduce a generic class of subgoals with
broad applicability in the visual domain. Underlying our approach (in common
with work using &quot;auxiliary tasks&quot;) is the hypothesis that the ability to
control aspects of the environment is an inherently useful skill to have. We
incorporate such subgoals in an end-to-end hierarchical reinforcement learning
system and test two variants of our algorithm on a number of games from the
Atari suite. We highlight the advantage of our approach in one of the hardest
games -- Montezuma's revenge -- for which the ability to handle sparse rewards
is key. Our agent learns several times faster than the current state-of-the-art
HRL agent in this game, reaching a similar level of performance. UPDATE
22/11/17: We found that a standard A3C agent with a simple shaped reward, i.e.
extrinsic reward + feature control intrinsic reward, has comparable performance
to our agent in Montezuma Revenge. In light of the new experiments performed,
the advantage of our HRL approach can be attributed more to its ability to
learn useful features from intrinsic rewards rather than its ability to explore
and reuse abstracted skills with hierarchical components. This has led us to a
new conclusion about the result.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06769</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06778</identifier>
 <datestamp>2017-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building effective deep neural network architectures one feature at a
  time</dc:title>
 <dc:creator>Mundt, Martin</dc:creator>
 <dc:creator>Weis, Tobias</dc:creator>
 <dc:creator>Konda, Kishore</dc:creator>
 <dc:creator>Ramesh, Visvanathan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Successful training of convolutional neural networks is often associated with
sufficiently deep architectures composed of high amounts of features. These
networks typically rely on a variety of regularization and pruning techniques
to converge to less redundant states. We introduce a novel bottom-up approach
to expand representations in fixed-depth architectures. These architectures
start from just a single feature per layer and greedily increase width of
individual layers to attain effective representational capacities needed for a
specific task. While network growth can rely on a family of metrics, we propose
a computationally efficient version based on feature time evolution and
demonstrate its potency in determining feature importance and a networks'
effective capacity. We demonstrate how automatically expanded architectures
converge to similar topologies that benefit from lesser amount of parameters or
improved accuracy and exhibit systematic correspondence in representational
complexity with the specified task. In contrast to conventional design patterns
with a typical monotonic increase in the amount of features with increased
depth, we observe that CNNs perform better when there is more learnable
parameters in intermediate, with falloffs to earlier and later layers.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06778</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06779</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why Noise and Dispersion may Seriously Hamper Nonlinear
  Frequency-Division Multiplexing</dc:title>
 <dc:creator>Civelli, Stella</dc:creator>
 <dc:creator>Forestieri, Enrico</dc:creator>
 <dc:creator>Secondini, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Applied Physics</dc:subject>
 <dc:description>  The performance of optical fiber systems based on nonlinear
frequency-division multiplexing (NFDM) or on more conventional transmission
techniques is compared through numerical simulations. Some critical issues
affecting NFDM systems-namely, the strict requirements needed to avoid burst
interaction due to signal dispersion and the unfavorable dependence of
performance on burst length-are investigated, highlighting their potentially
disruptive effect in terms of spectral efficiency. Two digital processing
techniques are finally proposed to halve the guard time between NFDM symbol
bursts and reduce the size of the processing window at the receiver, increasing
spectral efficiency and reducing computational complexity.
</dc:description>
 <dc:description>Comment: The manuscript has been submitted to Photonics Technology Letters for
  publication</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06779</dc:identifier>
 <dc:identifier>IEEE Photonics Technology Letters, vol. 29, no. 16, pp. 1332-1335,
  August 2017</dc:identifier>
 <dc:identifier>doi:10.1109/LPT.2017.2722040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06782</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive Modeling of Three-Phase Distribution Systems via the Bus
  Admittance Matrix</dc:title>
 <dc:creator>Bazrafshan, Mohammadhafez</dc:creator>
 <dc:creator>Gatsis, Nikolaos</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The theme of this paper is three-phase distribution system modeling suitable
for the Z-Bus load-flow. Detailed models of wye and delta constant-power,
constant-current, and constant-impedance loads are presented. Models of
transmission lines, voltage regulators, and transformers that build the bus
admittance matrix (Y-Bus) are laid out. The Z-Bus load-flow is then reviewed
and the singularity of the Y-Bus in case of certain transformer connections is
rigorously discussed. Based on realistic assumptions and conventional
modifications, the invertibility of the Y-Bus is proved. Last but not least,
the MATLAB scripts that construct the detailed component models for the IEEE
37-bus, IEEE 123-bus, and 8500-node feeders as well as the European 906-bus
low-voltage feeder are provided.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Trans. Power Syst</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06782</dc:identifier>
 <dc:identifier>doi:10.1109/TPWRS.2017.2728618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06784</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detect Kernel-Mode Rootkits via Real Time Logging &amp; Controlling Memory
  Access</dc:title>
 <dc:creator>Korkin, Igor</dc:creator>
 <dc:creator>Tanda, Satoshi</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern malware and spyware platforms attack existing antivirus solutions and
even Microsoft PatchGuard. To protect users and business systems new
technologies developed by Intel and AMD CPUs may be applied. To deal with the
new malware we propose monitoring and controlling access to the memory in real
time using Intel VT-x with EPT. We have checked this concept by developing
MemoryMonRWX, which is a bare-metal hypervisor. MemoryMonRWX is able to track
and trap all types of memory access: read, write, and execute. MemoryMonRWX
also has the following competitive advantages: fine-grained analysis, support
of multi-core CPUs and 64-bit Windows 10. MemoryMonRWX is able to protect
critical kernel memory areas even when PatchGuard has been disabled by malware.
Its main innovative features are as follows: guaranteed interception of every
memory access, resilience, and low performance degradation.
</dc:description>
 <dc:description>Comment: Proceedings of the 12th annual Conference on Digital Forensics,
  Security and Law (CDFSL), Embry-Riddle Aeronautical University, Daytona
  Beach, Florida, USA. May 15-16 2017. 31 pages, 14 figures, 3 tables, 101
  references</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06791</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Alignment with Power Splitting Relays in Multi-User
  Multi-Relay Networks</dc:title>
 <dc:creator>Chu, Man</dc:creator>
 <dc:creator>He, Biao</dc:creator>
 <dc:creator>Liao, Xuewen</dc:creator>
 <dc:creator>Gao, Zhenzhen</dc:creator>
 <dc:creator>Zhu, Shihua</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study a multi-user multi-relay interference-channel
network, where energy-constrained relays harvest energy from sources' radio
frequency (RF) signals and use the harvested energy to forward the information
to destinations. We adopt the interference alignment (IA) technique to address
the issue of interference, and propose a novel transmission scheme with the IA
at sources and the power splitting (PS) at relays. A distributed and iterative
algorithm to obtain the optimal PS ratios is further proposed, aiming at
maximizing the sum rate of the network. The analysis is then validated by
simulation results. Our results show that the proposed scheme with the optimal
design significantly improves the performance of the network.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures, to appear in Proc. VTC Fall, Toronto, Canada</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06796</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Being even slightly shallow makes life hard</dc:title>
 <dc:creator>Muzi, Irene</dc:creator>
 <dc:creator>O'Brien, Michael P.</dc:creator>
 <dc:creator>Reidl, Felix</dc:creator>
 <dc:creator>Sullivan, Blair D.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the computational complexity of identifying dense substructures,
namely $r/2$-shallow topological minors and $r$-subdivisions. Of particular
interest is the case when $r=1$, when these substructures correspond to very
localized relaxations of subgraphs. Since Densest Subgraph can be solved in
polynomial time, we ask whether these slight relaxations also admit efficient
algorithms.
  In the following, we provide a negative answer: Dense $r/2$-Shallow
Topological Minor and Dense $r$-Subdivsion are already NP-hard for $r = 1$ in
very sparse graphs. Further, they do not admit algorithms with running time
$2^{o(\mathbf{tw}^2)} n^{O(1)}$ when parameterized by the treewidth of the
input graph for $r \geq 2$ unless ETH fails.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06798</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotic Average Number of Different Categories of Trapping Sets,
  Absorbing Sets and Stopping Sets in Random Regular and Irregular LDPC Code
  Ensembles</dc:title>
 <dc:creator>Dehghan, Ali</dc:creator>
 <dc:creator>Banihashemi, Amir H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The performance of low-density parity-check (LDPC) codes in the error floor
region is closely related to some combinatorial structures of the code's Tanner
graph, collectively referred to as {\it trapping sets (TSs)}. In this paper, we
study the asymptotic average number of different types of trapping sets such as
{\em elementary TSs (ETS)}, {\em leafless ETSs (LETS)}, {\em absorbing sets
(ABS)}, {\em elementary ABSs (EABS)}, and {\em stopping sets (SS)}, in random
variable-regular and irregular LDPC code ensembles. We demonstrate that,
regardless of the type of the TS, as the code's length tends to infinity, the
average number of a given structure tends to infinity, to a positive constant,
or to zero, if the structure contains no cycle, only one cycle, or more than
one cycle, respectively. For the case where the structure contains a single
cycle, we obtain an estimate of the expected number of the structure through
the available approximations for the average number of its constituent cycle.
These estimates, which are independent of the block length and only depend on
the code's degree distributions, are shown to be accurate even for
finite-length codes.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06799</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Uplink and Downlink Coverage Analysis of Cellular-based RF-powered
  IoT Network</dc:title>
 <dc:creator>Kishk, Mustafa A.</dc:creator>
 <dc:creator>Dhillon, Harpreet S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Ambient radio frequency (RF) energy harvesting has emerged as a promising
solution for powering small devices and sensors in massive Internet of Things
(IoT) ecosystem due to its ubiquity and cost efficiency. In this paper, we
study joint uplink and downlink coverage of cellular-based ambient RF energy
harvesting IoT where the cellular network is assumed to be the only source of
RF energy. We consider a time division-based approach for power and information
transmission where each time-slot is partitioned into three sub-slots: (i)
charging sub-slot during which the cellular base stations (BSs) act as RF
chargers for the IoT devices, which then use the energy harvested in this
sub-slot for information transmission and/or reception during the remaining two
sub-slots, (ii) downlink sub-slot during which the IoT device receives
information from the associated BS, and (iii) uplink sub-slot during which the
IoT device transmits information to the associated BS. For this setup, we
characterize the joint coverage probability, which is the joint probability of
the events that the typical device harvests sufficient energy in the given time
slot and is under both uplink and downlink signal-to-interference-plus-noise
ratio (SINR) coverage with respect to its associated BS. This metric
significantly generalizes the prior art on energy harvesting communications,
which usually focused on downlink or uplink coverage separately. The key
technical challenge is in handling the correlation between the amount of energy
harvested in the charging sub-slot and the information signal quality (SINR) in
the downlink and uplink sub-slots. Dominant BS-based approach is developed to
derive tight approximation for this joint coverage probability. Several system
design insights including comparison with regularly powered IoT network and
throughput-optimal slot partitioning are also provided.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06804</identifier>
 <datestamp>2017-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Antenna Arrays for Line-of-Sight Massive MIMO: Half Wavelength is not
  Enough</dc:title>
 <dc:creator>Pinchera, Daniele</dc:creator>
 <dc:creator>Migliore, Marco Donald</dc:creator>
 <dc:creator>Schettino, Fulvio</dc:creator>
 <dc:creator>Panariello, Gaetano</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The aim of this paper is to analyze the array synthesis for 5 G massive MIMO
systems in the line-of-sight working condition. The main result of the
numerical investigation performed is that non-uniform arrays are the natural
choice in this kind of application. In particular, by using non-equispaced
arrays, we show that it is possible to achieve a better average condition
number of the channel matrix and a significantly higher spectral efficiency.
Furthermore, we verify that increasing the array size is beneficial also for
circular arrays, and we provide some useful rules-of-thumb for antenna array
design for massive MIMO applications. These results are in contrast to the
widely-accepted idea in the 5 G massive MIMO literature, in which the
half-wavelength linear uniform array is universally adopted.
</dc:description>
 <dc:description>Comment: updated version of the paper, that now includes additional results on
  the spectral efficiency</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-09-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06804</dc:identifier>
 <dc:identifier>Electronics 2017, 6, 57</dc:identifier>
 <dc:identifier>doi:10.3390/electronics6030057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06805</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Smart Home is No Castle: Privacy Vulnerabilities of Encrypted IoT
  Traffic</dc:title>
 <dc:creator>Apthorpe, Noah</dc:creator>
 <dc:creator>Reisman, Dillon</dc:creator>
 <dc:creator>Feamster, Nick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The increasing popularity of specialized Internet-connected devices and
appliances, dubbed the Internet-of-Things (IoT), promises both new conveniences
and new privacy concerns. Unlike traditional web browsers, many IoT devices
have always-on sensors that constantly monitor fine-grained details of users'
physical environments and influence the devices' network communications.
Passive network observers, such as Internet service providers, could
potentially analyze IoT network traffic to infer sensitive details about users.
Here, we examine four IoT smart home devices (a Sense sleep monitor, a Nest Cam
Indoor security camera, a WeMo switch, and an Amazon Echo) and find that their
network traffic rates can reveal potentially sensitive user interactions even
when the traffic is encrypted. These results indicate that a technological
solution is needed to protect IoT device owner privacy, and that IoT-specific
concerns must be considered in the ongoing policy debate around ISP data
collection and usage.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, appears in Workshop on Data and Algorithmic
  Transparency (DAT '16)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06809</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Closing the Blinds: Four Strategies for Protecting Smart Home Privacy
  from Network Observers</dc:title>
 <dc:creator>Apthorpe, Noah</dc:creator>
 <dc:creator>Reisman, Dillon</dc:creator>
 <dc:creator>Feamster, Nick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The growing market for smart home IoT devices promises new conveniences for
consumers while presenting novel challenges for preserving privacy within the
home. Specifically, Internet service providers or neighborhood WiFi
eavesdroppers can measure Internet traffic rates from smart home devices and
infer consumers' private in-home behaviors. Here we propose four strategies
that device manufacturers and third parties can take to protect consumers from
side-channel traffic rate privacy threats: 1) blocking traffic, 2) concealing
DNS, 3) tunneling traffic, and 4) shaping and injecting traffic. We hope that
these strategies, and the implementation nuances we discuss, will provide a
foundation for the future development of privacy-sensitive smart homes.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, appears in Workshop on Technology and Consumer
  Protection (ConPro '17)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06820</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pixel Deconvolutional Networks</dc:title>
 <dc:creator>Gao, Hongyang</dc:creator>
 <dc:creator>Yuan, Hao</dc:creator>
 <dc:creator>Wang, Zhengyang</dc:creator>
 <dc:creator>Ji, Shuiwang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deconvolutional layers have been widely used in a variety of deep models for
up-sampling, including encoder-decoder networks for semantic segmentation and
deep generative models for unsupervised learning. One of the key limitations of
deconvolutional operations is that they result in the so-called checkerboard
problem. This is caused by the fact that no direct relationship exists among
adjacent pixels on the output feature map. To address this problem, we propose
the pixel deconvolutional layer (PixelDCL) to establish direct relationships
among adjacent pixels on the up-sampled feature map. Our method is based on a
fresh interpretation of the regular deconvolution operation. The resulting
PixelDCL can be used to replace any deconvolutional layer in a plug-and-play
manner without compromising the fully trainable capabilities of original
models. The proposed PixelDCL may result in slight decrease in efficiency, but
this can be overcome by an implementation trick. Experimental results on
semantic segmentation demonstrate that PixelDCL can consider spatial features
such as edges and shapes and yields more accurate segmentation outputs than
deconvolutional layers. When used in image generation tasks, our PixelDCL can
largely overcome the checkerboard problem suffered by regular deconvolution
operations.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06821</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Variational Auto-Encoding via Matrix-Variate Normal
  Distributions</dc:title>
 <dc:creator>Wang, Zhengyang</dc:creator>
 <dc:creator>Yuan, Hao</dc:creator>
 <dc:creator>Ji, Shuiwang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The key idea of variational auto-encoders (VAEs) resembles that of
traditional auto-encoder models in which spatial information is supposed to be
explicitly encoded in the latent space. However, the latent variables in VAEs
are vectors, which are commonly interpreted as multiple feature maps of size
1x1. Such representations can only convey spatial information implicitly when
coupled with powerful decoders. In this work, we propose spatial VAEs that use
latent variables as feature maps of larger size to explicitly capture spatial
information. This is achieved by allowing the latent variables to be sampled
from matrix-variate normal (MVN) distributions whose parameters are computed
from the encoder network. To increase dependencies among locations on latent
feature maps and reduce the number of parameters, we further propose spatial
VAEs via low-rank MVN distributions. Experimental results show that the
proposed spatial VAEs outperform original VAEs in capturing rich structural and
spatial information.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06822</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Cayley-Dickson Construction in ACL2</dc:title>
 <dc:creator>Cowles, John</dc:creator>
 <dc:creator>Gamboa, Ruben</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The Cayley-Dickson Construction is a generalization of the familiar
construction of the complex numbers from pairs of real numbers. The complex
numbers can be viewed as two-dimensional vectors equipped with a
multiplication.
  The construction can be used to construct, not only the two-dimensional
Complex Numbers, but also the four-dimensional Quaternions and the
eight-dimensional Octonions. Each of these vector spaces has a vector
multiplication, v_1*v_2, that satisfies:
  1. Each nonzero vector has a multiplicative inverse.
  2. For the Euclidean length of a vector |v|, |v_1 * v_2| = |v_1| |v2|.
  Real numbers can also be viewed as (one-dimensional) vectors with the above
two properties.
  ACL2(r) is used to explore this question: Given a vector space, equipped with
a multiplication, satisfying the Euclidean length condition 2, given above.
Make pairs of vectors into &quot;new&quot; vectors with a multiplication. When do the
newly constructed vectors also satisfy condition 2?
</dc:description>
 <dc:description>Comment: In Proceedings ACL2Workshop 2017, arXiv:1705.00766</dc:description>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06822</dc:identifier>
 <dc:identifier>EPTCS 249, 2017, pp. 18-29</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.249.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06824</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Convolutional Text Representations for Visual Question
  Answering</dc:title>
 <dc:creator>Wang, Zhengyang</dc:creator>
 <dc:creator>Ji, Shuiwang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Visual question answering is a recently proposed artificial intelligence task
that requires a deep understanding of both images and texts. In deep learning,
images are typically modeled through convolutional neural networks, and texts
are typically modeled through recurrent neural networks. While the requirement
for modeling images is similar to traditional computer vision tasks, such as
object recognition and image classification, visual question answering raises a
different need for textual representation as compared to other natural language
processing tasks. In this work, we perform a detailed analysis on natural
language questions in visual question answering. Based on the analysis, we
propose to rely on convolutional neural networks for learning textual
representations. By exploring the various properties of convolutional neural
networks specialized for text data, such as width and depth, we present our
&quot;CNN Inception + Gate&quot; model. We show that our model improves question
representations and thus the overall accuracy of visual question answering
models. We also show that the text representation requirement in visual
question answering is more complicated and comprehensive than that in
conventional natural language processing tasks, making it a better task to
evaluate textual representation methods. Shallow models like fastText, which
can obtain comparable results with deep learning models in tasks like text
classification, are not suitable in visual question answering.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06830</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the structure of a real-time, arbitrary neural artistic
  stylization network</dc:title>
 <dc:creator>Ghiasi, Golnaz</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:creator>Kudlur, Manjunath</dc:creator>
 <dc:creator>Dumoulin, Vincent</dc:creator>
 <dc:creator>Shlens, Jonathon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a method which combines the flexibility of the
neural algorithm of artistic style with the speed of fast style transfer
networks to allow real-time stylization using any content/style image pair. We
build upon recent work leveraging conditional instance normalization for
multi-style transfer networks by learning to predict the conditional instance
normalization parameters directly from a style image. The model is successfully
trained on a corpus of roughly 80,000 paintings and is able to generalize to
paintings previously unobserved. We demonstrate that the learned embedding
space is smooth and contains a rich structure and organizes semantic
information associated with paintings in an entirely unsupervised manner.
</dc:description>
 <dc:description>Comment: Accepted as an oral presentation at British Machine Vision Conference
  (BMVC) 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06839</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep-LK for Efficient Adaptive Object Tracking</dc:title>
 <dc:creator>Wang, Chaoyang</dc:creator>
 <dc:creator>Galoogahi, Hamed Kiani</dc:creator>
 <dc:creator>Lin, Chen-Hsuan</dc:creator>
 <dc:creator>Lucey, Simon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present a new approach for efficient regression based object
tracking which we refer to as Deep- LK. Our approach is closely related to the
Generic Object Tracking Using Regression Networks (GOTURN) framework of Held et
al. We make the following contributions. First, we demonstrate that there is a
theoretical relationship between siamese regression networks like GOTURN and
the classical Inverse-Compositional Lucas &amp; Kanade (IC-LK) algorithm. Further,
we demonstrate that unlike GOTURN IC-LK adapts its regressor to the appearance
of the currently tracked frame. We argue that this missing property in GOTURN
can be attributed to its poor performance on unseen objects and/or viewpoints.
Second, we propose a novel framework for object tracking - which we refer to as
Deep-LK - that is inspired by the IC-LK framework. Finally, we show impressive
results demonstrating that Deep-LK substantially outperforms GOTURN.
Additionally, we demonstrate comparable tracking performance to current state
of the art deep-trackers whilst being an order of magnitude (i.e. 100 FPS)
computationally efficient.
</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06840</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Conference Paper Assignment Problem: Using Order Weighted Averages
  to Assign Indivisible Goods</dc:title>
 <dc:creator>Lian, Jing Wu</dc:creator>
 <dc:creator>Mattei, Nicholas</dc:creator>
 <dc:creator>Noble, Renee</dc:creator>
 <dc:creator>Walsh, Toby</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>91A80, 91B74</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Motivated by the common academic problem of allocating papers to referees for
conference reviewing we propose a novel mechanism for solving the assignment
problem when we have a two sided matching problem with preferences from one
side (the agents/reviewers) over the other side (the objects/papers) and both
sides have capacity constraints. The assignment problem is a fundamental
problem in both computer science and economics with application in many areas
including task and resource allocation. We draw inspiration from multi-criteria
decision making and voting and use order weighted averages (OWAs) to propose a
novel and flexible class of algorithms for the assignment problem. We show an
algorithm for finding a $\Sigma$-OWA assignment in polynomial time, in contrast
to the NP-hardness of finding an egalitarian assignment. Inspired by this
setting we observe an interesting connection between our model and the classic
proportional multi-winner election problem in social choice.
</dc:description>
 <dc:description>Comment: 3 Figure</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06846</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Predictive Account of Cafe Wall Illusions Using a Quantitative Model</dc:title>
 <dc:creator>Nematzadeh, Nasim</dc:creator>
 <dc:creator>Powers, David M. W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper explores the tilt illusion effect in the Cafe Wall pattern using a
classical Gaussian Receptive Field model. In this illusion, the mortar lines
are misperceived as diverging or converging rather than horizontal. We examine
the capability of a simple bioplausible filtering model to recognize different
degrees of tilt effect in the Cafe Wall illusion based on different
characteristics of the pattern. Our study employed a Difference of Gaussians
model of retinal to cortical ON center and/or OFF center receptive fields. A
wide range of parameters of the stimulus, for example mortar thickness,
luminance, tiles contrast, phase of the tile displacement, have been studied.
Our model constructs an edge map representation at multiple scales that reveals
tilt cues and clues involved in the illusory perception of the Cafe Wall
pattern. We present here that our model can not only detect the tilt in this
pattern, but also can predict the strength of the illusion and quantify the
degree of tilt. For the first time quantitative predictions of a model are
reported for this stimulus. The results of our simulations are consistent with
previous psychophysical findings across the full range of Cafe Wall variations
tested. Our results also suggest that the Difference of Gaussians mechanism is
the heart of the effects explained by, and the mechanisms proposed by the
Irradiation, Brightness Induction, and Bandpass Filtering models.
</dc:description>
 <dc:description>Comment: Submitted</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06846</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06847</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Syndrome-Coupled Rate-Compatible Error-Correcting Codes</dc:title>
 <dc:creator>Huang, Pengfei</dc:creator>
 <dc:creator>Liu, Yi</dc:creator>
 <dc:creator>Zhang, Xiaojie</dc:creator>
 <dc:creator>Siegel, Paul H.</dc:creator>
 <dc:creator>Haratsch, Erich F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Rate-compatible error-correcting codes (ECCs), which consist of a set of
extended codes, are of practical interest in both wireless communications and
data storage. In this work, we first study the lower bounds for rate-compatible
ECCs, thus proving the existence of good rate-compatible codes. Then, we
propose a general framework for constructing rate-compatible ECCs based on
cosets and syndromes of a set of nested linear codes. We evaluate our
construction from two points of view. From a combinatorial perspective, we show
that we can construct rate-compatible codes with increasing minimum distances.
From a probabilistic point of view, we prove that we are able to construct
capacity-achieving rate-compatible codes.
</dc:description>
 <dc:description>Comment: Submitted to ITW 2017</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06849</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Signature Verification using Recurrent Neural Network and
  Length-normalized Path Signature</dc:title>
 <dc:creator>Lai, Songxuan</dc:creator>
 <dc:creator>Jin, Lianwen</dc:creator>
 <dc:creator>Yang, Weixin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inspired by the great success of recurrent neural networks (RNNs) in
sequential modeling, we introduce a novel RNN system to improve the performance
of online signature verification. The training objective is to directly
minimize intra-class variations and to push the distances between skilled
forgeries and genuine samples above a given threshold. By back-propagating the
training signals, our RNN network produced discriminative features with desired
metrics. Additionally, we propose a novel descriptor, called the
length-normalized path signature (LNPS), and apply it to online signature
verification. LNPS has interesting properties, such as scale invariance and
rotation invariance after linear combination, and shows promising results in
online signature verification. Experiments on the publicly available SVC-2004
dataset yielded state-of-the-art performance of 2.37% equal error rate (EER).
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 5 tables</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06855</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using a Hamiltonian cycle problem algorithm to assist in solving
  difficult instances of Traveling Salesman Problem</dc:title>
 <dc:creator>Ejov, Vladimir</dc:creator>
 <dc:creator>Haythorpe, Michael</dc:creator>
 <dc:creator>Rossomakhine, Serguei</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>05C85, 05C45</dc:subject>
 <dc:description>  We describe a hybrid procedure for solving the traveling salesman problem
(TSP) to provable optimality. We first sparsify the instance, and then use a
hybrid algorithm that combines a branch-and-cut TSP solver with a Hamiltonian
cycle problem solver. We demonstrate that this procedure enables us to solve
difficult instances to optimality, including one which had remained unsolved
since its construction in 2002.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06860</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Massive-MIMO: The Potential of Positioning with Large Intelligent
  Surfaces</dc:title>
 <dc:creator>Hu, Sha</dc:creator>
 <dc:creator>Rusek, Fredrik</dc:creator>
 <dc:creator>Edfors, Ove</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the potential for positioning with a system where antenna arrays
are deployed as a large intelligent surface (LIS), which is a newly proposed
concept beyond massive-MIMO where future man-made structures are electronically
active with integrated electronics and wireless communication making the entire
environment \lq\lq{}intelligent\rq\rq{}. In a first step, we derive
Fisher-information and Cram\'{e}r-Rao lower bounds (CRLBs) in closed-form for
positioning a terminal located perpendicular to the center of the LIS, whose
location we refer to as being on the central perpendicular line (CPL) of the
LIS. For a terminal that is not on the CPL, closed-form expressions of the
Fisher-information and CRLB seem out of reach, and we alternatively find
approximations of them which are shown to be accurate. Under mild conditions,
we show that the CRLB for all three Cartesian dimensions ($x$, $y$ and $z$)
decreases quadratically in the surface-area of the LIS, except for a terminal
exactly on the CPL where the CRLB for the $z$-dimension (distance from the LIS)
decreases linearly in the same. In a second step, we analyze the CRLB for
positioning when there is an unknown phase $\varphi$ presented in the analog
circuits of the LIS. We then show that the CRLBs are dramatically increased for
all three dimensions but decrease in the third-order of the surface-area.
Moreover, with an infinitely large LIS the CRLB for the $z$-dimension with an
unknown $\varphi$ is 6 dB higher than the case without phase uncertainty, and
the CRLB for estimating $\varphi$ converges to a constant that is independent
of the wavelength $\lambda$. At last, we extensively discuss the impact of
centralized and distributed deployments of LIS, and show that a distributed
deployment of LIS can enlarge the coverage for terminal-positioning and improve
the overall positioning performance.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Trans. on Signal Processing on Apr. 2017; 30 pages;
  13 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06861</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Prediction of Sea Surface Temperature using Long Short-Term Memory</dc:title>
 <dc:creator>Zhang, Qin</dc:creator>
 <dc:creator>Wang, Hui</dc:creator>
 <dc:creator>Dong, Junyu</dc:creator>
 <dc:creator>Zhong, Guoqiang</dc:creator>
 <dc:creator>Sun, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This letter adopts long short-term memory(LSTM) to predict sea surface
temperature(SST), which is the first attempt, to our knowledge, to use
recurrent neural network to solve the problem of SST prediction, and to make
one week and one month daily prediction. We formulate the SST prediction
problem as a time series regression problem. LSTM is a special kind of
recurrent neural network, which introduces gate mechanism into vanilla RNN to
prevent the vanished or exploding gradient problem. It has strong ability to
model the temporal relationship of time series data and can handle the
long-term dependency problem well. The proposed network architecture is
composed of two kinds of layers: LSTM layer and full-connected dense layer.
LSTM layer is utilized to model the time series relationship. Full-connected
layer is utilized to map the output of LSTM layer to a final prediction. We
explore the optimal setting of this architecture by experiments and report the
accuracy of coastal seas of China to confirm the effectiveness of the proposed
method. In addition, we also show its online updated characteristics.
</dc:description>
 <dc:description>Comment: 5 page, 5 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06861</dc:identifier>
 <dc:identifier>doi:10.1109/LGRS.2017.2733548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06869</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ADMM-Net: A Deep Learning Approach for Compressive Sensing MRI</dc:title>
 <dc:creator>Yang, Yan</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:creator>Li, Huibin</dc:creator>
 <dc:creator>Xu, Zongben</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compressive sensing (CS) is an effective approach for fast Magnetic Resonance
Imaging (MRI). It aims at reconstructing MR images from a small number of
under-sampled data in k-space, and accelerating the data acquisition in MRI. To
improve the current MRI system in reconstruction accuracy and speed, in this
paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and
generalized versions. ADMM-Nets are defined over data flow graphs, which are
derived from the iterative procedures in Alternating Direction Method of
Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They
take the sampled k-space data as inputs and output reconstructed MR images.
Moreover, we extend our network to cope with complex-valued MR images. In the
training phase, all parameters of the nets, e.g., transforms, shrinkage
functions, etc., are discriminatively trained end-to-end. In the testing phase,
they have computational overhead similar to ADMM algorithm but use optimized
parameters learned from the data for CS-based reconstruction task. We
investigate different configurations in network structures and conduct
extensive experiments on MR image reconstruction under different sampling
rates. Due to the combination of the advantages in model-based approach and
deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction
accuracies with fast computational speed.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06869</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06870</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fiber Orientation Estimation Guided by a Deep Network</dc:title>
 <dc:creator>Ye, Chuyang</dc:creator>
 <dc:creator>Prince, Jerry L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Diffusion magnetic resonance imaging (dMRI) is currently the only tool for
noninvasively imaging the brain's white matter tracts. The fiber orientation
(FO) is a key feature computed from dMRI for fiber tract reconstruction.
Because the number of FOs in a voxel is usually small, dictionary-based sparse
reconstruction has been used to estimate FOs with a relatively small number of
diffusion gradients. However, accurate FO estimation in regions with complex FO
configurations in the presence of noise can still be challenging. In this work
we explore the use of a deep network for FO estimation in a dictionary-based
framework and propose an algorithm named Fiber Orientation Reconstruction
guided by a Deep Network (FORDN). FORDN consists of two steps. First, we use a
smaller dictionary encoding coarse basis FOs to represent the diffusion
signals. To estimate the mixture fractions of the dictionary atoms (and thus
coarse FOs), a deep network is designed specifically for solving the sparse
reconstruction problem. Here, the smaller dictionary is used to reduce the
computational cost of training. Second, the coarse FOs inform the final FO
estimation, where a larger dictionary encoding dense basis FOs is used and a
weighted l1-norm regularized least squares problem is solved to encourage FOs
that are consistent with the network output. FORDN was evaluated and compared
with state-of-the-art algorithms that estimate FOs using sparse reconstruction
on simulated and real dMRI data, and the results demonstrate the benefit of
using a deep network for FO estimation.
</dc:description>
 <dc:description>Comment: A shorter version is accepted by MICCAI 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06871</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Affine-Gradient Based Local Binary Pattern Descriptor for Texture
  Classiffication</dc:title>
 <dc:creator>Hao, You</dc:creator>
 <dc:creator>Li, Shirui</dc:creator>
 <dc:creator>Mo, Hanlin</dc:creator>
 <dc:creator>Li, Hua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a novel Affine-Gradient based Local Binary Pattern (AGLBP)
descriptor for texture classification. It is very hard to describe complicated
texture using single type information, such as Local Binary Pattern (LBP),
which just utilizes the sign information of the difference between the pixel
and its local neighbors. Our descriptor has three characteristics: 1) In order
to make full use of the information contained in the texture, the
Affine-Gradient, which is different from Euclidean-Gradient and invariant to
affine transformation is incorporated into AGLBP. 2) An improved method is
proposed for rotation invariance, which depends on the reference direction
calculating respect to local neighbors. 3) Feature selection method,
considering both the statistical frequency and the intraclass variance of the
training dataset, is also applied to reduce the dimensionality of descriptors.
Experiments on three standard texture datasets, Outex12, Outex10 and KTH-TIPS2,
are conducted to evaluate the performance of AGLBP. The results show that our
proposed descriptor gets better performance comparing to some state-of-the-art
rotation texture descriptors in texture classification.
</dc:description>
 <dc:description>Comment: 11 pages,4 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06879</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Complexity Iterative Algorithms for (Discrete) Compressed Sensing</dc:title>
 <dc:creator>Fischer, Robert F. H.</dc:creator>
 <dc:creator>Sparrer, Susanne</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider iterative (`turbo') algorithms for compressed sensing. First, a
unified exposition of the different approaches available in the literature is
given, thereby enlightening the general principles and main differences. In
particular we discuss i) the estimation step (matched filter vs. optimum MMSE
estimator), ii) the unbiasing operation (implicitly or explicitly done and
equivalent to the calculation of extrinsic information), and iii) thresholding
vs. the calculation of soft values. Based on these insights we propose a
low-complexity but well-performing variant utilizing a Krylov space
approximation of the optimum linear MMSE estimator. The derivations are valid
for any probability density of the signal vector. However, numerical results
are shown for the discrete case. The novel algorithms shows very good
performance and even slightly faster convergence compared to approximative
message passing.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06882</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QuickTalk: An Association-Free Communication Method for IoT Devices in
  Proximity</dc:title>
 <dc:creator>Ham, Seongmin</dc:creator>
 <dc:creator>Lee, Jihyung</dc:creator>
 <dc:creator>Lee, Kyunghan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  IoT devices are in general considered to be straightforward to use. However,
we find that there are a number of situations where the usability becomes poor.
The situations include but not limited to the followings: 1) when initializing
an IoT device, 2) when trying to control an IoT device which is initialized and
registered by another person, and 3) when trying to control an IoT device out
of many of the same type. We tackle these situations by proposing a new
association-free communication method, QuickTalk. QuickTalk lets a user device
such as a smartphone pinpoint and activate an IoT device with the help of an IR
transmitter and communicate with the pinpointed IoT device through the
broadcast channel of WiFi. By the nature of its association-free communication,
QuickTalk allows a user device to immediately give a command to a specific IoT
device in proximity even when the IoT device is uninitialized, unregistered to
the control interface of the user, or registered but being physically confused
with others. Our experiments of QuickTalk implemented on Raspberry Pi 2 devices
show that the end-to-end delay of QuickTalk is upper bounded by 2.5 seconds and
its median is only about 0.74 seconds. We further confirm that even when an IoT
device has ongoing data sessions, QuickTalk can still establish a reliable
communication channel to the IoT device with little impact to the ongoing
sessions.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures, IMWUT(Ubicomp) conference</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06884</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Framework for Stochastic Matrix Factorization via Variance
  Reduction</dc:title>
 <dc:creator>Zhao, Renbo</dc:creator>
 <dc:creator>Haskell, William B.</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a unified framework to speed up the existing stochastic matrix
factorization (SMF) algorithms via variance reduction. Our framework is general
and it subsumes several well-known SMF formulations in the literature. We
perform a non-asymptotic convergence analysis of our framework and derive
computational and sample complexities for our algorithm to converge to an
$\epsilon$-stationary point in expectation. In addition, extensive experiments
for a wide class of SMF formulations demonstrate that our framework
consistently yields faster convergence and a more accurate output dictionary
vis-\`a-vis state-of-the-art frameworks.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06891</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient Resource Allocation for Elastic Optical Networks using
  Convex Optimization</dc:title>
 <dc:creator>Hadi, Mohammad</dc:creator>
 <dc:creator>Pakravan, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose a two-stage algorithm for energy-efficient resource allocation
constrained to QoS and physical requirements in OFDM-based EONs. The first
stage deals with routing, grooming and traffic ordering and aims at minimizing
amplifier power consumption and number of active transponders. We provide a
heuristic procedure which yields an acceptable solution for the complex ILP
formulation of the routing and grooming. In the second stage, we optimize
transponder configuration including spectrum and transmit power parameters to
minimize transponder power consumption. We show how QoS and transponder power
consumption are represented by convex expressions and use the results to
formulate a convex problem for configuring transponders in which transmit
optical power is an optimization variable. Simulation results demonstrate that
the power consumption is reduced by 9% when the proposed routing and grooming
algorithm is applied to European Cost239 network with aggregate traffic 60
Tbps. It is shown that our convex formulation for transponder parameter
assignment is considerably faster than its MINLP counterpart and its ability to
optimize transmit optical power improves transponder power consumption by 8%
for aggregate traffic 60 Tbps. Furthermore, we investigate the effect of
adaptive modulation assignment and transponder capacity on inherent tradeoff
between network CAPEX and OPEX.
</dc:description>
 <dc:description>Comment: 28 pages, 11 figures, 4 tables</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06894</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Algorithms for Best-K Identification in Multi-Armed Bandits</dc:title>
 <dc:creator>Jiang, Haotian</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:creator>Qiao, Mingda</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In the Best-$K$ identification problem (Best-$K$-Arm), we are given $N$
stochastic bandit arms with unknown reward distributions. Our goal is to
identify the $K$ arms with the largest means with high confidence, by drawing
samples from the arms adaptively. This problem is motivated by various
practical applications and has attracted considerable attention in the past
decade. In this paper, we propose new practical algorithms for the Best-$K$-Arm
problem, which have nearly optimal sample complexity bounds (matching the lower
bound up to logarithmic factors) and outperform the state-of-the-art algorithms
for the Best-$K$-Arm problem (even for $K=1$) in practice.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06894</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06899</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CDS Rate Construction Methods by Machine Learning Techniques</dc:title>
 <dc:creator>Brummelhuis, Raymond</dc:creator>
 <dc:creator>Luo, Zhongmin</dc:creator>
 <dc:subject>Quantitative Finance - Statistical Finance</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Finance - Risk Management</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Regulators require financial institutions to estimate counterparty default
risks from liquid CDS quotes for the valuation and risk management of OTC
derivatives. However, the vast majority of counterparties do not have liquid
CDS quotes and need proxy CDS rates. Existing methods cannot account for
counterparty-specific default risks; we propose to construct proxy CDS rates by
associating to illiquid counterparty liquid CDS Proxy based on Machine Learning
Techniques. After testing 156 classifiers from 8 most popular classifier
families, we found that some classifiers achieve highly satisfactory accuracy
rates. Furthermore, we have rank-ordered the performances and investigated
performance variations amongst and within the 8 classifier families. This paper
is, to the best of our knowledge, the first systematic study of CDS Proxy
construction by Machine Learning techniques, and the first systematic
classifier comparison study based entirely on financial market data. Its
findings both confirm and contrast existing classifier performance literature.
Given the typically highly correlated nature of financial data, we investigated
the impact of correlation on classifier performance. The techniques used in
this paper should be of interest for financial institutions seeking a CDS Proxy
method, and can serve for proxy construction for other financial variables.
Some directions for future research are indicated.
</dc:description>
 <dc:description>Comment: 51 pages; 21 Figures; 15 Tables</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06900</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Shape Spectrum Analysis for 3D Facial Expression Recognition</dc:title>
 <dc:creator>Derkach, Dmytro</dc:creator>
 <dc:creator>Sukno, Federico M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We investigate the problem of facial expression recognition using 3D data.
Building from one of the most successful frameworks for facial analysis using
exclusively 3D geometry, we extend the analysis from a curve-based
representation into a spectral representation, which allows a complete
description of the underlying surface that can be further tuned to the desired
level of detail. Spectral representations are based on the decomposition of the
geometry in its spatial frequency components, much like a Fourier transform,
which are related to intrinsic characteristics of the surface. In this work, we
propose the use of Graph Laplacian Features (GLF), which results from the
projection of local surface patches into a common basis obtained from the Graph
Laplacian eigenspace. We test the proposed approach in the BU-3DFE database in
terms of expressions and Action Units recognition. Our results confirm that the
proposed GLF produces consistently higher recognition rates than the
curves-based approach, thanks to a more complete description of the surface,
while requiring a lower computational complexity. We also show that the GLF
outperform the most popular alternative approach for spectral representation,
Shape- DNA, which is based on the Laplace Beltrami Operator and cannot provide
a stable basis that guarantee that the extracted signatures for the different
patches are directly comparable.
</dc:description>
 <dc:description>Comment: 12th IEEE International Conference on Face and Gesture Recognition,
  Washington, DC, USA, 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06903</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Certificate Revocation List Distribution for Secure V2X
  Communications</dc:title>
 <dc:creator>Rigazzi, Giovanni</dc:creator>
 <dc:creator>Tassi, Andrea</dc:creator>
 <dc:creator>Piechocki, Robert J.</dc:creator>
 <dc:creator>Tryfonas, Theo</dc:creator>
 <dc:creator>Nix, Andrew</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The successful deployment of safe and trustworthy Connected and Autonomous
Vehicles (CAVs) will highly depend on the ability to devise robust and
effective security solutions to resist sophisticated cyber attacks and patch up
critical vulnerabilities. Pseudonym Public Key Infrastructure (PPKI) is a
promising approach to secure vehicular networks as well as ensure data and
location privacy, concealing the vehicles' real identities. Nevertheless,
pseudonym distribution and management affect PPKI scalability due to the
significant number of digital certificates required by a single vehicle. In
this paper, we focus on the certificate revocation process and propose a
versatile and low-complexity framework to facilitate the distribution of the
Certificate Revocation Lists (CRL) issued by the Certification Authority (CA).
CRL compression is achieved through optimized Bloom filters, which guarantee a
considerable overhead reduction with a configurable rate of false positives.
Our results show that the distribution of compressed CRLs can significantly
enhance the system scalability without increasing the complexity of the
revocation process.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE VTC Fall 2017 conference proceedings</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06904</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evidence for mixed rationalities in preference formation</dc:title>
 <dc:creator>B&#x103;beanu, Alexandru-Ionu&#x163;</dc:creator>
 <dc:creator>Garlaschelli, Diego</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Understanding the mechanisms underlying the formation of cultural traits,
such as preferences, opinions and beliefs is an open challenge. Trait formation
is intimately connected to cultural dynamics, which has been the focus of a
variety of quantitative models. Recently, some studies have emphasized the
importance of connecting those models to snapshots of cultural dynamics that
are empirically accessible. By analyzing data obtained from different sources,
it has been suggested that culture has properties that are universally present,
and that empirical cultural states differ systematically from randomized
counterparts. Hence, a question about the mechanism responsible for the
observed patterns naturally arises. This study proposes a stochastic structural
model for generating cultural states that retain those robust, empirical
properties. One ingredient of the model, already used in previous work, assumes
that every individual's set of traits is partly dictated by one of several,
universal &quot;rationalities&quot;, informally postulated by several social science
theories. The second, new ingredient taken from the same theories assumes that,
apart from a dominant rationality, each individual also has a certain exposure
to the other rationalities. It is shown that both ingredients are required for
reproducing the empirical regularities. This key result suggests that the
effects of cultural dynamics in the real world can be described as an interplay
of multiple, mixing rationalities, and thus provides indirect evidence for the
class of social science theories postulating such mixing. The model should be
seen as a static, effective description of culture, while a dynamical, more
fundamental description is left for future research.
</dc:description>
 <dc:description>Comment: 30 pages, 7 figures; compared tothe previous version, there are some
  minor additions in the text and some new citations</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06904</dc:identifier>
 <dc:identifier>doi:10.1155/2018/3615476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06907</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultra-Reliable and Low Latency Communication in mmWave-Enabled Massive
  MIMO Networks</dc:title>
 <dc:creator>Vu, Trung Kien</dc:creator>
 <dc:creator>Liu, Chen-Feng</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:creator>Latva-aho, Matti</dc:creator>
 <dc:creator>Hong, Choong Seon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:description>  Ultra-reliability and low-latency are two key components in 5G networks. In
this letter, we investigate the problem of ultra-reliable and low-latency
communication (URLLC) in millimeter wave (mmWave)-enabled massive
multiple-input multiple-output (MIMO) networks. The problem is cast as a
network utility maximization subject to probabilistic latency and reliability
constraints. To solve this problem, we resort to the Lyapunov technique whereby
a utility-delay control approach is proposed, which adapts to channel
variations and queue dynamics. Numerical results demonstrate that our proposed
approach ensures reliable communication with a guaranteed probability of
99.99%, and reduces latency by 28.41% and 77.11% as compared to baselines with
and without probabilistic latency constraints, respectively.
</dc:description>
 <dc:description>Comment: Accepted May 12, 2017 by IEEE Communications Letters. Topic is
  Ultra-Reliable and Low Latency Communication in 5G mmWave Networks</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06907</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2017.2705148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06908</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unbiased estimates for linear regression via volume sampling</dc:title>
 <dc:creator>Derezi&#x144;ski, Micha&#x142;</dc:creator>
 <dc:creator>Warmuth, Manfred K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For a full rank $n\times d$ matrix $X$ with $n\ge d$, consider the task of
solving the linear least squares problem, where we try to predict a response
value for each of the $n$ rows of $X$. Assume that obtaining the responses is
expensive and we can only afford to attain the responses for a small subset of
rows. We show that a good approximate solution to this least squares problem
can be obtained from just dimension $d$ many responses. Concretely, if the rows
are in general position and if a subset of $d$ rows is chosen proportional to
the squared volume spanned by those rows, then the expected total square loss
(on all $n$ rows) of the least squares solution found for the subset is exactly
$d+1$ times the minimum achievable total loss. We provide lower bounds showing
that the factor of $d+1$ is optimal, and any iid row sampling procedure
requires $\Omega(d\log d)$ responses to achieve a finite factor guarantee.
Moreover, the least squares solution obtained for the volume sampled subproblem
is an unbiased estimator of optimal solution based on all $n$ responses.
  Our methods lead to general matrix expectation formulas for volume sampling
which go beyond linear regression. In particular, we propose a matrix estimator
for the pseudoinverse $X^+$, computed from a small subset of rows of the matrix
$X$. The estimator is unbiased and surprisingly its covariance also has a
closed form: It equals a specific factor times $X^{+}X^{+\top}$. We believe
that these new formulas establish a fundamental connection between linear least
squares and volume sampling. Our analysis for computing matrix expectations is
based on reverse iterative volume sampling, a technique which also leads to a
new algorithm for volume sampling that is by a factor of $n^2$ faster than the
state-of-the-art.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06908</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06920</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperspectral Band Selection Using Unsupervised Non-Linear Deep Auto
  Encoder to Train External Classifiers</dc:title>
 <dc:creator>Ahmad, Muhammad</dc:creator>
 <dc:creator>Protasov, Stanislav</dc:creator>
 <dc:creator>Khan, Adil Mehmood</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In order to make hyperspectral image classification compu- tationally
tractable, it is often necessary to select the most informative bands instead
to process the whole data without losing the geometrical representation of
original data. To cope with said issue, an improved un- supervised non-linear
deep auto encoder (UDAE) based band selection method is proposed. The proposed
UDAE is able to select the most infor- mative bands in such a way that preserve
the key information but in the lower dimensions, where the hidden
representation is a non-linear trans- formation that maps the original space to
a space of lower dimensions. This work emphasizes to analyze what type of
information is needed to preserve the hierarchical UDAE representation while
selecting a sub- set from original space. Our experiments on publically
available hyper- spectral dataset demonstrate the effectiveness of UDAE method,
which equates favorably with other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06922</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral-graph Based Classifications: Linear Regression for
  Classification and Normalized Radial Basis Function Network</dc:title>
 <dc:creator>Hu, Zhenfang</dc:creator>
 <dc:creator>Pan, Gang</dc:creator>
 <dc:creator>Wu, Zhaohui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Spectral graph theory has been widely applied in unsupervised and
semi-supervised learning. In this paper, we find for the first time, to our
knowledge, that it also plays a concrete role in supervised classification. It
turns out that two classifiers are inherently related to the theory: linear
regression for classification (LRC) and normalized radial basis function
network (nRBFN), corresponding to linear and nonlinear kernel respectively. The
spectral graph theory provides us with a new insight into a fundamental aspect
of classification: the tradeoff between fitting error and overfitting risk.
With the theory, ideal working conditions for LRC and nRBFN are presented,
which ensure not only zero fitting error but also low overfitting risk. For
quantitative analysis, two concepts, the fitting error and the spectral risk
(indicating overfitting), have been defined. Their bounds for nRBFN and LRC are
derived. A special result shows that the spectral risk of nRBFN is lower
bounded by the number of classes and upper bounded by the size of radial basis.
When the conditions are not met exactly, the classifiers will pursue the
minimum fitting error, running into the risk of overfitting. It turns out that
$\ell_2$-norm regularization can be applied to control overfitting. Its effect
is explored under the spectral context. It is found that the two terms in the
$\ell_2$-regularized objective are one-one correspondent to the fitting error
and the spectral risk, revealing a tradeoff between the two quantities.
Concerning practical performance, we devise a basis selection strategy to
address the main problem hindering the applications of (n)RBFN. With the
strategy, nRBFN is easy to implement yet flexible. Experiments on 14 benchmark
data sets show the performance of nRBFN is comparable to that of SVM, whereas
the parameter tuning of nRBFN is much easier, leading to reduction of model
selection time.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06923</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MultiAmdahl: Optimal Resource Allocation in Heterogeneous Architectures</dc:title>
 <dc:creator>Yavits, Leonid</dc:creator>
 <dc:creator>Morad, Amir</dc:creator>
 <dc:creator>Weiser, Uri</dc:creator>
 <dc:creator>Ginosar, Ran</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Future multiprocessor chips will integrate many different units, each
tailored to a specific computation. When designing such a system, the chip
architect must decide how to distribute limited system resources such as area,
power, and energy among the computational units. We extend MultiAmdahl, an
analytical optimization technique for resource allocation in heterogeneous
architectures, for energy optimality under a variety of constant system power
scenarios. We conclude that reduction in constant system power should be met by
reallocating resources from general-purpose computing to heterogeneous
accelerator-dominated computing, to keep the overall energy consumption at a
minimum. We extend this conclusion to offer an intuition regarding
energy-optimal resource allocation in data center computing.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06926</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Study on Low Power Wide Area Networks (LPWAN) for Mobile
  Internet of Things</dc:title>
 <dc:creator>Patel, Dhaval</dc:creator>
 <dc:creator>Won, Myounggyu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the past decade, we have witnessed explosive growth in the number of
low-power embedded and Internet-connected devices, reinforcing the new
paradigm, Internet of Things (IoT). The low power wide area network (LPWAN),
due to its long-range, low-power and low-cost communication capability, is
actively considered by academia and industry as the future wireless
communication standard for IoT. However, despite the increasing popularity of
`mobile IoT', little is known about the suitability of LPWAN for those mobile
IoT applications in which nodes have varying degrees of mobility. To fill this
knowledge gap, in this paper, we conduct an experimental study to evaluate,
analyze, and characterize LPWAN in both indoor and outdoor mobile environments.
Our experimental results indicate that the performance of LPWAN is surprisingly
susceptible to mobility, even to minor human mobility, and the effect of
mobility significantly escalates as the distance to the gateway increases.
These results call for development of new mobility-aware LPWAN protocols to
support mobile IoT.
</dc:description>
 <dc:description>Comment: To appear at 2017 IEEE 85th Vehicular Technology Conference (VTC'17
  Spring)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06927</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Foundations of Declarative Data Analysis Using Limit Datalog Programs</dc:title>
 <dc:creator>Kaminski, Mark</dc:creator>
 <dc:creator>Grau, Bernardo Cuenca</dc:creator>
 <dc:creator>Kostylev, Egor V.</dc:creator>
 <dc:creator>Motik, Boris</dc:creator>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Motivated by applications in declarative data analysis, we study
$\mathit{Datalog}_{\mathbb{Z}}$---an extension of positive Datalog with
arithmetic functions over integers. This language is known to be undecidable,
so we propose two fragments. In $\mathit{limit}~\mathit{Datalog}_{\mathbb{Z}}$
predicates are axiomatised to keep minimal/maximal numeric values, allowing us
to show that fact entailment is coNExpTime-complete in combined, and
coNP-complete in data complexity. Moreover, an additional $\mathit{stability}$
requirement causes the complexity to drop to ExpTime and PTime, respectively.
Finally, we show that stable $\mathit{Datalog}_{\mathbb{Z}}$ can express many
useful data analysis tasks, and so our results provide a sound foundation for
the development of advanced information systems.
</dc:description>
 <dc:description>Comment: 23 pages; full version of a paper accepted at IJCAI-17; v2 fixes some
  typos and improves the acknowledgments</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06928</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Colourings of cubic graphs inducing isomorphic monochromatic subgraphs</dc:title>
 <dc:creator>Abreu, Marien</dc:creator>
 <dc:creator>Goedgebeur, Jan</dc:creator>
 <dc:creator>Labbate, Domenico</dc:creator>
 <dc:creator>Mazzuoccolo, Giuseppe</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A $k$-bisection of a bridgeless cubic graph $G$ is a $2$-colouring of its
vertex set such that the colour classes have the same cardinality and all
connected components in the two subgraphs induced by the colour classes
(monochromatic components in what follows) have order at most $k$. Ban and
Linial conjectured that every bridgeless cubic graph admits a $2$-bisection
except for the Petersen graph. A similar problem for the edge set of cubic
graphs has been studied: Wormald conjectured that every cubic graph $G$ with
$|E(G)| \equiv 0 \, \mod \, 2$ has a $2$-edge colouring such that the two
monochromatic subgraphs are isomorphic linear forests (i.e. a forest whose
components are paths). Finally, Ando conjectured that every cubic graph admits
a bisection such that the two induced monochromatic subgraphs are isomorphic.
  In this paper, we give a detailed insight into the conjectures of Ban-Linial
and Wormald and provide evidence of a strong relation of both of them with
Ando's conjecture. Furthermore, we also give computational and theoretical
evidence in their support. As a result, we pose some open problems stronger
than the above mentioned conjectures. Moreover, we prove Ban-Linial's
conjecture for cubic cycle permutation graphs.
  As a by-product of studying $2$-edge colourings of cubic graphs having linear
forests as monochromatic components, we also give a negative answer to a
problem posed by Jackson and Wormald about certain decompositions of cubic
graphs into linear forests.
</dc:description>
 <dc:description>Comment: 31 pages; submitted for publication</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06929</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MPC meets SNA: A Privacy Preserving Analysis of Distributed Sensitive
  Social Networks</dc:title>
 <dc:creator>Kukkala, Varsha Bhat</dc:creator>
 <dc:creator>Iyengar, S. R. S</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper, we formalize the notion of distributed sensitive social
networks (DSSNs), which encompasses networks like enmity networks, financial
transaction networks, supply chain networks and sexual relationship networks.
Compared to the well studied traditional social networks, DSSNs are often more
challenging to study, given the privacy concerns of the individuals on whom the
network is knit. In the current work, we envision the use of secure multiparty
tools and techniques for performing privacy preserving social network analysis
over DSSNs. As a step towards realizing this, we design efficient
data-oblivious algorithms for computing the K-shell decomposition and the
PageRank centrality measure for a given DSSN. The designed data-oblivious
algorithms can be translated into equivalent secure computation protocols. We
also list a string of challenges that are needed to be addressed, for employing
secure computation protocols as a practical solution for studying DSSNs.
</dc:description>
 <dc:description>Comment: 30 pages, 6 figues</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06932</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Look Mum, no VM Exits! (Almost)</dc:title>
 <dc:creator>Ramsauer, Ralf</dc:creator>
 <dc:creator>Kiszka, Jan</dc:creator>
 <dc:creator>Lohmann, Daniel</dc:creator>
 <dc:creator>Mauerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  Multi-core CPUs are a standard component in many modern embedded systems.
Their virtualisation extensions enable the isolation of services, and gain
popularity to implement mixed-criticality or otherwise split systems. We
present Jailhouse, a Linux-based, OS-agnostic partitioning hypervisor that uses
novel architectural approaches to combine Linux, a powerful general-purpose
system, with strictly isolated special-purpose components. Our design goals
favour simplicity over features, establish a minimal code base, and minimise
hypervisor activity.
  Direct assignment of hardware to guests, together with a deferred
initialisation scheme, offloads any complex hardware handling and bootstrapping
issues from the hypervisor to the general purpose OS. The hypervisor
establishes isolated domains that directly access physical resources without
the need for emulation or paravirtualisation. This retains, with negligible
system overhead, Linux's feature-richness in uncritical parts, while frugal
safety and real-time critical workloads execute in isolated, safe domains.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06936</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Atari games and Intel processors</dc:title>
 <dc:creator>Adamski, Robert</dc:creator>
 <dc:creator>Grel, Tomasz</dc:creator>
 <dc:creator>Klimek, Maciej</dc:creator>
 <dc:creator>Michalewski, Henryk</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The asynchronous nature of the state-of-the-art reinforcement learning
algorithms such as the Asynchronous Advantage Actor-Critic algorithm, makes
them exceptionally suitable for CPU computations. However, given the fact that
deep reinforcement learning often deals with interpreting visual information, a
large part of the train and inference time is spent performing convolutions. In
this work we present our results on learning strategies in Atari games using a
Convolutional Neural Network, the Math Kernel Library and TensorFlow 0.11rc0
machine learning framework. We also analyze effects of asynchronous
computations on the convergence of reinforcement learning algorithms.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06942</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Voltage-Driven Domain-Wall Motion based Neuro-Synaptic Devices for
  Dynamic On-line Learning</dc:title>
 <dc:creator>Jaiswal, Akhilesh</dc:creator>
 <dc:creator>Agrawal, Amogh</dc:creator>
 <dc:creator>Panda, Priyadarshini</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Conventional von-Neumann computing models have achieved remarkable feats for
the past few decades. However, they fail to deliver the required efficiency for
certain basic tasks like image and speech recognition when compared to
biological systems. As such, taking cues from biological systems, novel
computing paradigms are being explored for efficient hardware implementations
of recognition/classification tasks. The basic building blocks of such
neuromorphic systems are neurons and synapses. Towards that end, we propose a
leaky-integrate-fire (LIF) neuron and a programmable non-volatile synapse using
domain wall motion induced by magneto-electric effect. Due to a strong elastic
pinning between the ferro-magnetic domain wall (FM-DW) and the underlying
ferro-electric domain wall (FE-DW), the FM-DW gets dragged by the FE-DW on
application of a voltage pulse. The fact that FE materials are insulators
allows for pure voltage-driven FM-DW motion, which in turn can be used to mimic
the behaviors of biological spiking neurons and synapses. The voltage driven
nature of the proposed devices allows energy-efficient operation. A detailed
device to system level simulation framework based on micromagnetic simulations
has been developed to analyze the feasibility of the proposed neuro-synaptic
devices. We also demonstrate that the energy-efficient voltage-controlled
behavior of the proposed devices make them suitable for dynamic on-line and
lifelong learning in spiking neural networks (SNNs).
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06946</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Does Knowledge Come By?</dc:title>
 <dc:creator>Chhabra, Anamika</dc:creator>
 <dc:creator>Iyengar, S. R. S.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Although the amount of knowledge that the humans possess has been gradually
increasing, we still do not know the procedure and conditions that lead to the
creation of new knowledge. An understanding of the modus operandi for the
creation of knowledge may help in accelerating the existing pace of building
knowledge. Our state of ignorance regarding various aspects of the process of
knowledge building is highlighted by the existing literature in the domain. The
reason behind it has been our inability to acquire the underlying data of this
complex process. However, current time shows great promise of improvements in
the knowledge building domain due to the availability of several online
knowledge building portals. In this report, we emphasise that these portals act
as prototypes for universal knowledge building process. The analysis of big
data availed from these portals may equip the knowledge building researchers
with the much needed meta-knowledge.
</dc:description>
 <dc:description>Comment: 23 pages, 3 figures, 1 table</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06947</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Web Centipede: Understanding How Web Communities Influence Each
  Other Through the Lens of Mainstream and Alternative News Sources</dc:title>
 <dc:creator>Zannettou, Savvas</dc:creator>
 <dc:creator>Caulfield, Tristan</dc:creator>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:creator>Leontiadis, Ilias</dc:creator>
 <dc:creator>Sirivianos, Michael</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:creator>Blackburn, Jeremy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  As the number and the diversity of news outlets on the Web grow, so does the
opportunity for &quot;alternative&quot; sources of information to emerge. Using large
social networks like Twitter and Facebook, misleading, false, or agenda-driven
information can quickly and seamlessly spread online, deceiving people or
influencing their opinions. Also, the increased engagement of tightly knit
communities, such as Reddit and 4chan, further compounds the problem, as their
users initiate and propagate alternative information, not only within their own
communities, but also to different ones as well as various social media. In
fact, these platforms have become an important piece of the modern information
ecosystem, which, thus far, has not been studied as a whole.
  In this paper, we begin to fill this gap by studying mainstream and
alternative news shared on Twitter, Reddit, and 4chan. By analyzing millions of
posts around several axes, we measure how mainstream and alternative news flows
between these platforms. Our results indicate that alt-right communities within
4chan and Reddit can have a surprising level of influence on Twitter, providing
evidence that &quot;fringe&quot; communities often succeed in spreading alternative news
to mainstream social networks and the greater Web.
</dc:description>
 <dc:description>Comment: To appear in the 17th ACM Internet Measurement Conference (IMC 2017)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06950</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Kinetics Human Action Video Dataset</dc:title>
 <dc:creator>Kay, Will</dc:creator>
 <dc:creator>Carreira, Joao</dc:creator>
 <dc:creator>Simonyan, Karen</dc:creator>
 <dc:creator>Zhang, Brian</dc:creator>
 <dc:creator>Hillier, Chloe</dc:creator>
 <dc:creator>Vijayanarasimhan, Sudheendra</dc:creator>
 <dc:creator>Viola, Fabio</dc:creator>
 <dc:creator>Green, Tim</dc:creator>
 <dc:creator>Back, Trevor</dc:creator>
 <dc:creator>Natsev, Paul</dc:creator>
 <dc:creator>Suleyman, Mustafa</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We describe the DeepMind Kinetics human action video dataset. The dataset
contains 400 human action classes, with at least 400 video clips for each
action. Each clip lasts around 10s and is taken from a different YouTube video.
The actions are human focussed and cover a broad range of classes including
human-object interactions such as playing instruments, as well as human-human
interactions such as shaking hands. We describe the statistics of the dataset,
how it was collected, and give some baseline performance figures for neural
network architectures trained and tested for human action classification on
this dataset. We also carry out a preliminary analysis of whether imbalance in
the dataset leads to bias in the classifiers.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06959</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beam Design and User Scheduling for Non-Orthogonal Multiple Access with
  Multiple Antennas Based on Pareto-Optimality</dc:title>
 <dc:creator>Seo, Junyeong</dc:creator>
 <dc:creator>Sung, Youngchul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, an efficient transmit beam design and user scheduling method
is proposed for multi-user (MU) multiple-input single-output (MISO)
non-orthogonal multiple access (NOMA) downlink, based on Pareto-optimality. The
proposed beam design and user scheduling method groups simultaneously-served
users into multiple clusters with practical two users in each cluster, and then
applies spatical zeroforcing (ZF) across clusters to control inter-cluster
interference (ICI) and Pareto-optimal beam design with successive interference
cancellation (SIC) to two users in each cluster to remove interference to
strong users and leverage signal-to-interference-plus-noise ratios (SINRs) of
interference-experiencing weak users. The proposed method has flexibility to
control the rates of strong and weak users and numerical results show that the
proposed method yields good performance.
</dc:description>
 <dc:description>Comment: 29 pages, 8 figures, submitted to IEEE transaction on singal
  processing</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06960</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Report - MillimeterWave Communication in Vehicular Networks:
  Coverage and Connectivity Analysis</dc:title>
 <dc:creator>Giordani, Marco</dc:creator>
 <dc:creator>Zanella, Andrea</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this technical report (TR), we describe the mathematical model we
developed to carry out a preliminary coverage and connectivity analysis in an
automotive communication scenario based on mmWave links. The purpose is to
exemplify some of the complex and interesting tradeoffs that have to be
considered when designing solutions for mmWave automotive scenarios.
</dc:description>
 <dc:description>Comment: This document is a preliminary report which describes the
  mathematical model developed to carry out the results proposed in our work
  &quot;Millimeter Wave Communication in Vehicular Networks: Challenges and
  Opportunities&quot;, accepted to International Conference on Modern Circuits and
  Systems Technologies (MOCAST), 2017. A more updated version of this technical
  report will appear in the next weeks</dc:description>
 <dc:date>2017-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06963</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Neuromorphic Computing and Neural Networks in Hardware</dc:title>
 <dc:creator>Schuman, Catherine D.</dc:creator>
 <dc:creator>Potok, Thomas E.</dc:creator>
 <dc:creator>Patton, Robert M.</dc:creator>
 <dc:creator>Birdwell, J. Douglas</dc:creator>
 <dc:creator>Dean, Mark E.</dc:creator>
 <dc:creator>Rose, Garrett S.</dc:creator>
 <dc:creator>Plank, James S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Neuromorphic computing has come to refer to a variety of brain-inspired
computers, devices, and models that contrast the pervasive von Neumann computer
architecture. This biologically inspired approach has created highly connected
synthetic neurons and synapses that can be used to model neuroscience theories
as well as solve challenging machine learning problems. The promise of the
technology is to create a brain-like ability to learn and adapt, but the
technical challenges are significant, starting with an accurate neuroscience
model of how the brain works, to finding materials and engineering
breakthroughs to build devices to support these models, to creating a
programming framework so the systems can learn, to creating applications with
brain-like capabilities. In this work, we provide a comprehensive survey of the
research and motivations for neuromorphic computing over its history. We begin
with a 35-year review of the motivations and drivers of neuromorphic computing,
then look at the major research areas of the field, which we define as
neuro-inspired models, algorithms and learning approaches, hardware and
devices, supporting systems, and finally applications. We conclude with a broad
discussion on the major research topics that need to be addressed in the coming
years to see the promise of neuromorphic computing fulfilled. The goals of this
work are to provide an exhaustive review of the research conducted in
neuromorphic computing since the inception of the term, and to motivate further
work by illuminating gaps in the field where new research is needed.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06965</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GPU System Calls</dc:title>
 <dc:creator>Vesel&#xfd;, J&#xe1;n</dc:creator>
 <dc:creator>Basu, Arkaprava</dc:creator>
 <dc:creator>Bhattacharjee, Abhishek</dc:creator>
 <dc:creator>Loh, Gabriel</dc:creator>
 <dc:creator>Oskin, Mark</dc:creator>
 <dc:creator>Reinhardt, Steven K.</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>D.4.4</dc:subject>
 <dc:subject>D.4.7</dc:subject>
 <dc:description>  GPUs are becoming first-class compute citizens and are being tasked to
perform increasingly complex work. Modern GPUs increasingly support
programmability- enhancing features such as shared virtual memory and hardware
cache coherence, enabling them to run a wider variety of programs. But a key
aspect of general-purpose programming where GPUs are still found lacking is the
ability to invoke system calls. We explore how to directly invoke generic
system calls in GPU programs. We examine how system calls should be meshed with
prevailing GPGPU programming models where thousands of threads are organized in
a hierarchy of execution groups: Should a system call be invoked at the
individual GPU task, or at different execution group levels? What are
reasonable ordering semantics for GPU system calls across these hierarchy of
execution groups? To study these questions, we implemented GENESYS -- a
mechanism to allow GPU pro- grams to invoke system calls in the Linux operating
system. Numerous subtle changes to Linux were necessary, as the existing kernel
assumes that only CPUs invoke system calls. We analyze the performance of
GENESYS using micro-benchmarks and three applications that exercise the
filesystem, networking, and memory allocation subsystems of the kernel. We
conclude by analyzing the suitability of all of Linux's system calls for the
GPU.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06966</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameter Adaptation and Criticality in Particle Swarm Optimization</dc:title>
 <dc:creator>Cordero, Carlos Garcia</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Generality is one of the main advantages of heuristic algorithms, as such,
multiple parameters are exposed to the user with the objective of allowing them
to shape the algorithms to their specific needs. Parameter selection,
therefore, becomes an intrinsic problem of every heuristic algorithm. Selecting
good parameter values relies not only on knowledge related to the problem at
hand, but to the algorithms themselves. This research explores the usage of
self-organized criticality to reduce user interaction in the process of
selecting suitable parameters for particle swarm optimization (PSO) heuristics.
A particle swarm variant (named Adaptive PSO) with self-organized criticality
is developed and benchmarked against the standard PSO. Criticality is observed
in the dynamic behaviour of this swarm and excellent results are observed in
the long run. In contrast with the standard PSO, the Adaptive PSO does not
stagnate at any point in time, balancing the concepts of exploration and
exploitation better. A software platform for experimenting with particle
swarms, called PSO Laboratory, is also developed. This software is used to test
the standard PSO as well as all other PSO variants developed in the process of
creating the Adaptive PSO. As the software is intended to be of aid to future
and related research, special attention has been put in the development of a
friendly graphical user interface. Particle swarms are executed in real time,
allowing users to experiment by changing parameters on-the-fly.
</dc:description>
 <dc:description>Comment: 70 pages, MSc. Thesis in Artificial Intelligence, University of
  Edinburgh</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06968</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demo Abstract: CDMA-based IoT Services with Shared Band Operation of LTE
  in 5G</dc:title>
 <dc:creator>Mathur, Siddarth</dc:creator>
 <dc:creator>Sagari, Shweta S.</dc:creator>
 <dc:creator>Amin, Syed Obaid</dc:creator>
 <dc:creator>Ravindran, Ravishankar</dc:creator>
 <dc:creator>Saha, Dola</dc:creator>
 <dc:creator>Seskar, Ivan</dc:creator>
 <dc:creator>Raychaudhuri, Dipankar</dc:creator>
 <dc:creator>Wang, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With the vision of deployment of massive Internet-of-Things (IoTs) in 5G
network, existing 4G network and protocols are inefficient to handle sporadic
IoT traffic with requirements of low-latency, low control overhead and low
power. To suffice these requirements, we propose a design of a PHY/MAC layer
using Software Defined Radios (SDRs) that is backward compatible with existing
OFDM based LTE protocols and supports CDMA based transmissions for low power
IoT devices as well. This demo shows our implemented system based on that
design and the viability of the proposal under different network scenarios.
</dc:description>
 <dc:description>Comment: Accepted demo paper at IEEE Infocom 2017, link:
  http://infocom2017.ieee-infocom.org/program/demos-posters</dc:description>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06969</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realization of CDMA-based IoT Services with Shared Band Operation of LTE
  in 5G</dc:title>
 <dc:creator>Sagari, Shweta S.</dc:creator>
 <dc:creator>Mathur, Siddarth</dc:creator>
 <dc:creator>Saha, Dola</dc:creator>
 <dc:creator>Amin, Syed Obaid</dc:creator>
 <dc:creator>Ravindran, Ravishankar</dc:creator>
 <dc:creator>Seskar, Ivan</dc:creator>
 <dc:creator>Raychaudhuri, Dipankar</dc:creator>
 <dc:creator>Wang, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  5G network is envisioned to deploy a massive Internet-of-Things (IoTs) with
requirements of low-latency, low control overhead and low power. Current 4G
network is optimized for large bandwidth applications and inefficient to handle
short sporadic IoT messages. The challenge here spans multiple layer including
the radio access and the network layer. This paper focus on reusing CDMA access
for IoT devices considering event-driven and latency sensitive traffic profile.
We propose a PHY/MAC layer design for CDMA based communication for low power
IoT devices. We propose and evaluate coexisting operation of CDMA based IoT
network in presence of the exiting LTE network. Our proposed design will
integrate IoT traffic with legacy system by minimal modification at the edge
network, essentially eNodeB. We show that the underlay CDMA IoT network meets
IoT data traffic requirements with minimal degradation (3%) in the LTE
throughput. We also implement the proposed design using Software Defined Radios
and show the viability of the proposal under different network scenarios.
</dc:description>
 <dc:description>Comment: Accepted paper at ACM SIGCOMM 2017 Workshop on Mobile Edge
  Communications (MECOMM 2017) (Link:
  http://conferences.sigcomm.org/sigcomm/2017/workshop-mecomm.html)</dc:description>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06976</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LinkedIn Salary: A System for Secure Collection and Presentation of
  Structured Compensation Insights to Job Seekers</dc:title>
 <dc:creator>Kenthapadi, Krishnaram</dc:creator>
 <dc:creator>Chudhary, Ahsan</dc:creator>
 <dc:creator>Ambler, Stuart</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Online professional social networks such as LinkedIn have enhanced the
ability of job seekers to discover and assess career opportunities, and the
ability of job providers to discover and assess potential candidates. For most
job seekers, salary (or broadly compensation) is a crucial consideration in
choosing a new job. At the same time, job seekers face challenges in learning
the compensation associated with different jobs, given the sensitive nature of
compensation data and the dearth of reliable sources containing compensation
data. Towards the goal of helping the world's professionals optimize their
earning potential through salary transparency, we present LinkedIn Salary, a
system for collecting compensation information from LinkedIn members and
providing compensation insights to job seekers. We present the overall design
and architecture, and describe the key components needed for the secure
collection, de-identification, and processing of compensation data, focusing on
the unique challenges associated with privacy and security. We perform an
experimental study with more than one year of compensation submission history
data collected from over 1.5 million LinkedIn members, thereby demonstrating
the tradeoffs between privacy and modeling needs. We also highlight the lessons
learned from the production deployment of this system at LinkedIn.
</dc:description>
 <dc:description>Comment: Conference information: IEEE Symposium on Privacy-Aware Computing
  (IEEE PAC 2017)</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06979</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Cross-Modality Retrieval with CCA Projections and Pairwise
  Ranking Loss</dc:title>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:creator>Schl&#xfc;ter, Jan</dc:creator>
 <dc:creator>Vall, Andreu</dc:creator>
 <dc:creator>Korzeniowski, Filip</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Cross-modality retrieval encompasses retrieval tasks where the fetched items
are of a different type than the search query, e.g., retrieving pictures
relevant to a given text query. The state-of-the-art approach to cross-modality
retrieval relies on learning a joint embedding space of the two modalities,
where items from either modality are retrieved using nearest-neighbor search.
In this work, we introduce a neural network layer based on Canonical
Correlation Analysis (CCA) that learns better embedding spaces by analytically
computing projections that maximize correlation. In contrast to previous
approaches, the CCA layer allows us to combine existing objectives for
embedding space learning, such as pairwise ranking losses, with the optimal
projections of CCA. We show the effectiveness of our approach for
cross-modality retrieval on three datasets, surpassing both Deep CCA and a
multi-view network using freely learned projections optimized by a pairwise
ranking loss, especially when few training data is available.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06989</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Spectrum Sensing over Generalized Fading Channels Based on
  Energy Detection</dc:title>
 <dc:creator>Huang, He</dc:creator>
 <dc:creator>Yuan, Chaowei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>01A25</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  This paper analyzes the unified performance of energy detection (ED) of
spectrum sensing (SS) over generalized fading channels in cognitive radio (CR)
networks. The detective performance of SS schemes will be obviously affected by
fading channel between communication nodes, and ED has the advantages of fast
implementation, no requirement of priori received information and low
complexity, so it is meaningful to investigate ED that is performed over fading
channels such as Nakagami-m channel and Rice channel, or generalized fading
channels such as \k{appa}-{\mu} fading distribution and {\eta}-{\mu} fading
distribution. The {\alpha}-\k{appa}-{\mu} fading distribution is a generalized
fading model that represents the nonlinear and small-scale variation of fading
channels. The probability density function (p.d.f.) of instantaneous
signal-to-ratio (SNR) of {\alpha}-\k{appa}-{\mu} distribution is derived from
the envelope p.d.f. to evaluate energy efficiency for sensing systems. Next,
the probability of detection model with Marcum-Q function has been derived and
the close-form detective expressions with moment generating function (MGF)
method are deduced to achieve sensing communications over generalized fading
channels. Furthermore, novel and exact closed-form analytic expressions for
average area under the receiver operating characteristics curve also have been
deduced to analyze the performance characteristics of ED over
{\alpha}-\k{appa}-{\mu} fading channels. Besides, cooperative spectrum sensing
(CSS) with diversity reception has been applied to improve the detection
accuracy and mitigate the shadowed fading features with OR-rule. At last, the
results show that the detection capacity can be evidently affected by
{\alpha}-\k{appa}-{\mu} fading conditions, but appropriate channel parameters
will improve sensing performance.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06990</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of Energy Detection over Composite kappa-miu
  Shadowed Fading Channels</dc:title>
 <dc:creator>Huang, He</dc:creator>
 <dc:creator>al, et.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy detection is a reliable non-coherent signal processing technology of
spectrum sensing of cognitive radio networks, which thanks to its low
complexity, no requirement of priori received information and fast sensing
ability etc. Since the excellent performance of energy detection would be
actually affected by physical multipath fading, this paper is concentrating on
characteristics analysis of energy detection over composite shadowed fading
channels. The small-scale and line-of-sight fading distribution consists of
particular examples such as Rayleigh, Hoyt, Nakagami-m and one sided Gaussian
distributions. Based on this, we derive the probability density function of
signal envelope and signal-to-noise ratio of the composite shadowed fading
channels, which could accurately present the line-of-sight shadowed fading
characterization. Subsequently the exact close-form expressions with infinite
series formulation for the appropriate detection probability have been firstly
extended to estimate detection capacity of the above-mentioned model by
adopting Inverse Gaussian asymptotic distribution. In addition, the absolute
truncation error is deduced for evaluating minimum detection efficiency. The
established model can be also applied in detection estimation with non-integral
fading parameters. Last but not least, the analytical results and
quantification performance are approved by numerically evaluation with
MATHEMATICA and MATLAB as the power variables of dominant components changes.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06992</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative spectrum sensing with enhanced energy detection under
  GAUSSIAN noise uncertainty in cognitive radios</dc:title>
 <dc:creator>Huang, He</dc:creator>
 <dc:creator>al, et.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper presents optimization issues of energy detection (ED) thresholds
in cooperative spectrum sensing (CSS) with regard to general Gaussian noise.
Enhanced ED thresholds are proposed to overcome sensitivity of multiple noise
uncertainty. Two-steps decision pattern and convex samples thresholds have been
put forward under Gaussian noise uncertainty. Through deriving the probability
of detection (Pd) and the probability of false alarm (Pf ) for independent and
identical distribution (i.i.d.) SUs, we obtain lower total error rate (Qe) with
proposed ED thresholds at low signal-to-noise-ratio (SNR) condition.
Furthermore, simulation results show that proposed schemes outperform most
other noise uncertainty plans.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06995</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly second-order asymptotic optimality of sequential change-point
  detection with one-sample updates</dc:title>
 <dc:creator>Cao, Yang</dc:creator>
 <dc:creator>Xie, Liyan</dc:creator>
 <dc:creator>Xie, Yao</dc:creator>
 <dc:creator>Xu, Huan</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sequential change-point detection when the distribution parameters are
unknown is a fundamental problem in statistics and machine learning. When the
post-change parameters are unknown, we consider a set of detection procedures
based on sequential likelihood ratios with non-anticipating estimators
constructed using online convex optimization algorithms such as online mirror
descent, which provides a more versatile approach to tackle complex situations
where recursive maximum likelihood estimators cannot be found. When the
underlying distributions belong to a exponential family and the estimators
satisfy the logarithm regret property, we show that this approach is nearly
second-order asymptotically optimal. This means that the upper bound for the
false alarm rate of the algorithm (measured by the average-run-length) meets
the lower bound asymptotically up to a log-log factor when the threshold tends
to infinity. Our proof is achieved by making a connection between sequential
change-point and online convex optimization and leveraging the logarithmic
regret bound property of online mirror descent algorithm. Numerical and real
data examples validate our theory.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.06996</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A lower bound on the positive semidefinite rank of convex bodies</dc:title>
 <dc:creator>Fawzi, Hamza</dc:creator>
 <dc:creator>Din, Mohab Safey El</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  The positive semidefinite rank of a convex body $C$ is the size of its
smallest positive semidefinite formulation. We show that the positive
semidefinite rank of any convex body $C$ is at least $\sqrt{\log d}$ where $d$
is the smallest degree of a polynomial that vanishes on the boundary of the
polar of $C$. This improves on the existing bound which relies on results from
quantifier elimination. The proof relies on the B\'ezout bound applied to the
Karush-Kuhn-Tucker conditions of optimality. We discuss the connection with the
algebraic degree of semidefinite programming and show that the bound is tight
(up to constant factor) for random spectrahedra of suitable dimension.
</dc:description>
 <dc:description>Comment: v2: 14 pages - minor changes following comments by referees; v1: 13
  pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.06996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07001</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A High-Performance Algorithm for Identifying Frequent Items in Data
  Streams</dc:title>
 <dc:creator>Anderson, Daniel</dc:creator>
 <dc:creator>Bevan, Pryce</dc:creator>
 <dc:creator>Lang, Kevin</dc:creator>
 <dc:creator>Liberty, Edo</dc:creator>
 <dc:creator>Rhodes, Lee</dc:creator>
 <dc:creator>Thaler, Justin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Estimating frequencies of items over data streams is a common building block
in streaming data measurement and analysis. Misra and Gries introduced their
seminal algorithm for the problem in 1982, and the problem has since been
revisited many times due its practicality and applicability. We describe a
highly optimized version of Misra and Gries' algorithm that is suitable for
deployment in industrial settings. Our code is made public via an open source
library called DataSketches that is already used by several companies and
production systems.
  Our algorithm improves on two theoretical and practical aspects of prior
work. First, it handles weighted updates in amortized constant time, a common
requirement in practice. Second, it uses a simple and fast method for merging
summaries that asymptotically improves on prior work even for unweighted
streams. We describe experiments confirming that our algorithms are more
efficient than prior proposals.
</dc:description>
 <dc:description>Comment: Typo corrections</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07008</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lightweight Regression Method to Infer Psycholinguistic Properties for
  Brazilian Portuguese</dc:title>
 <dc:creator>Santos, Leandro B. dos</dc:creator>
 <dc:creator>Duran, Magali S.</dc:creator>
 <dc:creator>Hartmann, Nathan S.</dc:creator>
 <dc:creator>Candido Jr., Arnaldo</dc:creator>
 <dc:creator>Paetzold, Gustavo H.</dc:creator>
 <dc:creator>Aluisio, Sandra M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Psycholinguistic properties of words have been used in various approaches to
Natural Language Processing tasks, such as text simplification and readability
assessment. Most of these properties are subjective, involving costly and
time-consuming surveys to be gathered. Recent approaches use the limited
datasets of psycholinguistic properties to extend them automatically to large
lexicons. However, some of the resources used by such approaches are not
available to most languages. This study presents a method to infer
psycholinguistic properties for Brazilian Portuguese (BP) using regressors
built with a light set of features usually available for less resourced
languages: word length, frequency lists, lexical databases composed of school
dictionaries and word embedding models. The correlations between the properties
inferred are close to those obtained by related works. The resulting resource
contains 26,874 words in BP annotated with concreteness, age of acquisition,
imageability and subjective frequency.
</dc:description>
 <dc:description>Comment: Paper accepted for TSD2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07010</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental mode exact schemes for unsteady problems</dc:title>
 <dc:creator>Vabishchevich, Petr N.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65J08, 65M06, 65M12</dc:subject>
 <dc:description>  The problem of increasing the accuracy of an approximate solution is
considered for boundary value problems for parabolic equations. For ordinary
differential equations (ODEs), nonstandard finite difference schemes are in
common use for this problem. They are based on a modification of standard
discretizations of time derivatives and, in some cases, allow to obtain the
exact solution of problems. For multidimensional problems, we can consider the
problem of increasing the accuracy only for the most important components of
the approximate solution. In the present work, new unconditionally stable
schemes for parabolic problems are constructed, which are exact for the
fundamental mode. Such two-level schemes are designed via a modification of
standard schemes with weights using Pad\'{e} approximations. Numerical results
obtained for a model problem demonstrate advantages of the proposed fundamental
mode exact schemes.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07011</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievable Information Rates for Coded Modulation with Hard Decision
  Decoding for Coherent Fiber-Optic Systems</dc:title>
 <dc:creator>Sheikh, Alireza</dc:creator>
 <dc:creator>Amat, Alexandre Graell i</dc:creator>
 <dc:creator>Liva, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We analyze the achievable information rates (AIRs) for coded modulation
schemes with QAM constellations with both bit-wise and symbol-wise decoders,
corresponding to the case where a binary code is used in combination with a
higher-order modulation using the bit-interleaved coded modulation (BICM)
paradigm and to the case where a nonbinary code over a field matched to the
constellation size is used, respectively. In particular, we consider hard
decision decoding, which is the preferable option for fiber-optic communication
systems where decoding complexity is a concern. Recently, Liga \emph{et al.}
analyzed the AIRs for bit-wise and symbol-wise decoders considering what the
authors called \emph{hard decision decoder} which, however, exploits \emph{soft
information} of the transition probabilities of discrete-input discrete-output
channel resulting from the hard detection. As such, the complexity of the
decoder is essentially the same as the complexity of a soft decision decoder.
In this paper, we analyze instead the AIRs for the standard hard decision
decoder, commonly used in practice, where the decoding is based on the Hamming
distance metric. We show that if standard hard decision decoding is used,
bit-wise decoders yield significantly higher AIRs than symbol-wise decoders. As
a result, contrary to the conclusion by Liga \emph{et al.}, binary decoders
together with the BICM paradigm are preferable for spectrally-efficient
fiber-optic systems. We also design binary and nonbinary staircase codes and
show that, in agreement with the AIRs, binary codes yield better performance.
</dc:description>
 <dc:description>Comment: Published in IEEE/OSA Journal of Lightwave Technology, 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07011</dc:identifier>
 <dc:identifier>doi:10.1109/JLT.2017.2766978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07015</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmentation of 3D High-frequency Ultrasound Images of Human Lymph Nodes
  Using Graph Cut with Energy Functional Adapted to Local Intensity
  Distribution</dc:title>
 <dc:creator>Kuo, Jen-wei</dc:creator>
 <dc:creator>Mamou, Jonathan</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:creator>Saegusa-Beecroft, Emi</dc:creator>
 <dc:creator>Machi, Junji</dc:creator>
 <dc:creator>Feleppa, Ernest J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Previous studies by our group have shown that three-dimensional
high-frequency quantitative ultrasound methods have the potential to
differentiate metastatic lymph nodes from cancer-free lymph nodes dissected
from human cancer patients. To successfully perform these methods inside the
lymph node parenchyma, an automatic segmentation method is highly desired to
exclude the surrounding thin layer of fat from quantitative ultrasound
processing and accurately correct for ultrasound attenuation. In high-frequency
ultrasound images of lymph nodes, the intensity distribution of lymph node
parenchyma and fat varies spatially because of acoustic attenuation and
focusing effects. Thus, the intensity contrast between two object regions
(e.g., lymph node parenchyma and fat) is also spatially varying. In our
previous work, nested graph cut demonstrated its ability to simultaneously
segment lymph node parenchyma, fat, and the outer phosphate-buffered saline
bath even when some boundaries are lost because of acoustic attenuation and
focusing effects. This paper describes a novel approach called graph cut with
locally adaptive energy to further deal with spatially varying distributions of
lymph node parenchyma and fat caused by inhomogeneous acoustic attenuation. The
proposed method achieved Dice similarity coefficients of 0.937+-0.035 when
compared to expert manual segmentation on a representative dataset consisting
of 115 three-dimensional lymph node images obtained from colorectal cancer
patients.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07018</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Packet Scheduling with Adversarial Jamming and Speedup</dc:title>
 <dc:creator>B&#xf6;hm, Martin</dc:creator>
 <dc:creator>Je&#x17c;, &#x141;ukasz</dc:creator>
 <dc:creator>Sgall, Ji&#x159;&#xed;</dc:creator>
 <dc:creator>Vesel&#xfd;, Pavel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In Packet Scheduling with Adversarial Jamming packets of arbitrary sizes
arrive over time to be transmitted over a channel in which instantaneous
jamming errors occur at times chosen by the adversary and not known to the
algorithm. The transmission taking place at the time of jamming is corrupt, and
the algorithm learns this fact immediately. An online algorithm maximizes the
total size of packets it successfully transmits and the goal is to develop an
algorithm with the lowest possible asymptotic competitive ratio, where the
additive constant may depend on packet sizes.
  Our main contribution is a universal algorithm that works for any speedup and
packet sizes and, unlike previous algorithms for the problem, it does not need
to know these properties in advance. We show that this algorithm guarantees
1-competitiveness with speedup 4, making it the first known algorithm to
maintain 1-competitiveness with a moderate speedup for arbitrary packet sizes.
We also prove a lower bound of $\phi+1\approx 2.618$ on the speedup of any
1-competitive deterministic algorithm, showing that our algorithm is close to
the optimum.
  Additionally, we formulate a general framework for analyzing our algorithm
locally and use it to show upper bounds on its competitive ratio for speedups
in $[1,4)$ and for several special cases, recovering some previously known
results, each of which had a dedicated proof. In particular, our algorithm is
3-competitive without speedup, matching the algorithm and the lower bound of
Jurdzinski et al.
  We use this framework also for the case of divisible packet sizes in which
the size of a packet divides the size of any larger packet, to show that a
slight modification of our algorithm is 1-competitive with speedup 2 and it
achieves the optimal competitive ratio of 2 without speedup, again matching the
algorithm and the lower bound of Jurdzinski et al.
</dc:description>
 <dc:description>Comment: To appear in Proc. of the 15th Workshop on Approximation and Online
  Algorithms (WAOA 2017)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07024</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal prevention with possibilistic and mixed background risk</dc:title>
 <dc:creator>Georgescu, Irina</dc:creator>
 <dc:creator>Casademunt, Ana Maria Lucia</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this paper the effect of posibilistic or mixed background risk on the
level of optimal prevention is studied. In the framework of five purely
possibilistic or mixed models, necessary and sufficient conditions are found
such that the level of optimal saving decreases or increases as a result of the
actions of various types of background risk. This way our results complete
those obtained by Courbage and Rey for some prevention models with
probabilistic background risk.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07025</identifier>
 <datestamp>2017-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Effective Representations from Clinical Notes</dc:title>
 <dc:creator>Dubois, Sebastien</dc:creator>
 <dc:creator>Romano, Nathanael</dc:creator>
 <dc:creator>Kale, David C.</dc:creator>
 <dc:creator>Shah, Nigam</dc:creator>
 <dc:creator>Jung, Kenneth</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clinical notes are a rich source of information about patient state. However,
using them effectively presents many challenges. In this work we present two
methods for summarizing clinical notes into patient-level representations. The
resulting representations are evaluated on a range of prediction tasks and
cohort sizes. The new representations offer significant predictive performance
gains over the common baselines of Bag of Words and topic model representations
across all tested tasks and cohort sizes.
</dc:description>
 <dc:description>Comment: Under review for the Machine Learning for Healthcare Conference 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07038</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Landscape of Deep Learning Algorithms</dc:title>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper studies the landscape of empirical risk of deep neural networks by
theoretically analyzing its convergence behavior to the population risk as well
as its stationary points and properties. For an $l$-layer linear neural
network, we prove its empirical risk uniformly converges to its population risk
at the rate of $\mathcal{O}(r^{2l}\sqrt{d\log(l)}/\sqrt{n})$ with training
sample size of $n$, the total weight dimension of $d$ and the magnitude bound
$r$ of weight of each layer. We then derive the stability and generalization
bounds for the empirical risk based on this result. Besides, we establish the
uniform convergence of gradient of the empirical risk to its population
counterpart. We prove the one-to-one correspondence of the non-degenerate
stationary points between the empirical and population risks with convergence
guarantees, which describes the landscape of deep neural networks. In addition,
we analyze these properties for deep nonlinear neural networks with sigmoid
activation functions. We prove similar results for convergence behavior of
their empirical risks as well as the gradients and analyze properties of their
non-degenerate stationary points.
  To our best knowledge, this work is the first one theoretically
characterizing landscapes of deep learning algorithms. Besides, our results
provide the sample complexity of training a good deep neural network. We also
provide theoretical understanding on how the neural network depth $l$, the
layer width, the network size $d$ and parameter magnitude determine the neural
network landscapes.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07041</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Posterior sampling for reinforcement learning: worst-case regret bounds</dc:title>
 <dc:creator>Agrawal, Shipra</dc:creator>
 <dc:creator>Jia, Randy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an algorithm based on posterior sampling (aka Thompson sampling)
that achieves near-optimal worst-case regret bounds when the underlying Markov
Decision Process (MDP) is communicating with a finite, though unknown,
diameter. Our main result is a high probability regret upper bound of
$\tilde{O}(D\sqrt{SAT})$ for any communicating MDP with $S$ states, $A$ actions
and diameter $D$, when $T\ge S^5A$. Here, regret compares the total reward
achieved by the algorithm to the total expected reward of an optimal
infinite-horizon undiscounted average reward policy, in time horizon $T$. This
result improves over the best previously known upper bound of
$\tilde{O}(DS\sqrt{AT})$ achieved by any algorithm in this setting, and matches
the dependence on $S$ in the established lower bound of $\Omega(\sqrt{DSAT})$
for this problem. Our techniques involve proving some novel results about the
anti-concentration of Dirichlet distribution, which may be of independent
interest.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07047</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faceted classification: management and use</dc:title>
 <dc:creator>Slavic, Aida</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The paper discusses issues related to the use of faceted classifications in
an online environment. The author argues that knowledge organization systems
can be fully utilized in information retrieval only if they are exposed and
made available for machine processing. The experience with classification
automation to date may be used to speed up and ease the conversion of existing
faceted schemes or the creation of management tools for new systems. The author
suggests that it is possible to agree on a set of functional requirements for
supporting faceted classifications online that are equally relevant for the
maintenance of classifications, the creation of classification indexing tools,
or the management of classifications in an authority file. It is suggested that
a set of requirements for analytico-synthetic classifications may be put
forward to improve standards for the use and exchange of knowledge organization
systems.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07047</dc:identifier>
 <dc:identifier>Axiomathes, 18 (2), pp. 257-71 (2008)</dc:identifier>
 <dc:identifier>doi:10.1007/s10516-007-9030-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07048</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear regression without correspondence</dc:title>
 <dc:creator>Hsu, Daniel</dc:creator>
 <dc:creator>Shi, Kevin</dc:creator>
 <dc:creator>Sun, Xiaorui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This article considers algorithmic and statistical aspects of linear
regression when the correspondence between the covariates and the responses is
unknown. First, a fully polynomial-time approximation scheme is given for the
natural least squares optimization problem in any constant dimension. Next, in
an average-case and noise-free setting where the responses exactly correspond
to a linear function of i.i.d. draws from a standard multivariate normal
distribution, an efficient algorithm based on lattice basis reduction is shown
to exactly recover the unknown linear function in arbitrary dimension. Finally,
lower bounds on the signal-to-noise ratio are established for approximate
recovery of the unknown linear function by any estimator.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07049</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What are the Receptive, Effective Receptive, and Projective Fields of
  Neurons in Convolutional Neural Networks?</dc:title>
 <dc:creator>Le, Hung</dc:creator>
 <dc:creator>Borji, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we explain in detail how receptive fields, effective receptive
fields, and projective fields of neurons in different layers, convolution or
pooling, of a Convolutional Neural Network (CNN) are calculated. While our
focus here is on CNNs, the same operations, but in the reverse order, can be
used to calculate these quantities for deconvolutional neural networks. These
are important concepts, not only for better understanding and analyzing
convolutional and deconvolutional networks, but also for optimizing their
performance in real-world applications.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07051</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speeding up Memory-based Collaborative Filtering with Landmarks</dc:title>
 <dc:creator>Lima, Gustavo R.</dc:creator>
 <dc:creator>Mello, Carlos E.</dc:creator>
 <dc:creator>Zimbrao, Geraldo</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>H.4.0</dc:subject>
 <dc:description>  Recommender systems play an important role in many scenarios where users are
overwhelmed with too many choices to make. In this context, Collaborative
Filtering (CF) arises by providing a simple and widely used approach for
personalized recommendation. Memory-based CF algorithms mostly rely on
similarities between pairs of users or items, which are posteriorly employed in
classifiers like k-Nearest Neighbor (kNN) to generalize for unknown ratings. A
major issue regarding this approach is to build the similarity matrix.
Depending on the dimensionality of the rating matrix, the similarity
computations may become computationally intractable. To overcome this issue, we
propose to represent users by their distances to preselected users, namely
landmarks. This procedure allows to drastically reduce the computational cost
associated with the similarity matrix. We evaluated our proposal on two
distinct distinguishing databases, and the results showed our method has
consistently and considerably outperformed eight CF algorithms (including both
memory-based and model-based) in terms of computational performance.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07057</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Masked Autoregressive Flow for Density Estimation</dc:title>
 <dc:creator>Papamakarios, George</dc:creator>
 <dc:creator>Pavlakou, Theo</dc:creator>
 <dc:creator>Murray, Iain</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Autoregressive models are among the best performing neural density
estimators. We describe an approach for increasing the flexibility of an
autoregressive model, based on modelling the random numbers that the model uses
internally when generating data. By constructing a stack of autoregressive
models, each modelling the random numbers of the next model in the stack, we
obtain a type of normalizing flow suitable for density estimation, which we
call Masked Autoregressive Flow. This type of flow is closely related to
Inverse Autoregressive Flow and is a generalization of Real NVP. Masked
Autoregressive Flow achieves state-of-the-art performance in a range of
general-purpose density estimation tasks.
</dc:description>
 <dc:description>Comment: accepted as oral at NIPS 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2018-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07058</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification revisited: a web of knowledge</dc:title>
 <dc:creator>Slavic, Aida</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The vision of the Semantic Web (SW) is gradually unfolding and taking shape
through a web of linked data, a part of which is built by capturing semantics
stored in existing knowledge organization systems (KOS), subject metadata and
resource metadata. The content of vast bibliographic collections is currently
categorized by some widely used bibliographic classification and we may soon
see them being mined for information and linked in a meaningful way across the
Web. Bibliographic classifications are designed for knowledge mediation which
offers both a rich terminology and different ways in which concepts can be
categorized and related to each other in the universe of knowledge. From
1990-2010 they have been used in various resource discovery services on the Web
and continue to be used to support information integration in a number of
international digital library projects. In this chapter we will revisit some of
the ways in which universal classifications, as language independent concept
schemes, can assist humans and computers in structuring and presenting
information and formulating queries. Most importantly, we highlight issues
important to understanding bibliographic classifications, both in terms of
their unused potential and technical limitations.
</dc:description>
 <dc:description>Comment: Aida Slavic (2011) Classification revisited: a web of knowledge. In:
  Innovations in information retrieval: perspectives for theory and practice.
  Eds. Allen Foster and Pauline Rafferty. London: Facet, pp. 23-48</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07062</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MRI-PET Registration with Automated Algorithm in Pre-clinical Studies</dc:title>
 <dc:creator>Baisa, Nathanael L.</dc:creator>
 <dc:creator>Bricq, St&#xe9;phanie</dc:creator>
 <dc:creator>Lalande, Alain</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET)
automatic 3-D registration is implemented and validated for small animal image
volumes so that the high-resolution anatomical MRI information can be fused
with the low spatial resolution of functional PET information for the
localization of lesion that is currently in high demand in the study of tumor
of cancer (oncology) and its corresponding preparation of pharmaceutical drugs.
Though many registration algorithms are developed and applied on human brain
volumes, these methods may not be as efficient on small animal datasets due to
lack of intensity information and often the high anisotropy in voxel
dimensions. Therefore, a fully automatic registration algorithm which can
register not only assumably rigid small animal volumes such as brain but also
deformable organs such as kidney, cardiac and chest is developed using a
combination of global affine and local B-spline transformation models in which
mutual information is used as a similarity criterion. The global affine
registration uses a multi-resolution pyramid on image volumes of 3 levels
whereas in local B-spline registration, a multi-resolution scheme is applied on
the B-spline grid of 2 levels on the finest resolution of the image volumes in
which only the transform itself is affected rather than the image volumes.
Since mutual information lacks sufficient spatial information, PCA is used to
inject it by estimating initial translation and rotation parameters. It is
computationally efficient since it is implemented using C++ and ITK library,
and is qualitatively and quantitatively shown that this PCA-initialized global
registration followed by local registration is in close agreement with expert
manual registration and outperforms the one without PCA initialization tested
on small animal brain and kidney.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07065</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Privacy Breaches in the Aircraft Communications Addressing and
  Reporting System (ACARS)</dc:title>
 <dc:creator>Smith, Matthew</dc:creator>
 <dc:creator>Moser, Daniel</dc:creator>
 <dc:creator>Strohmeier, Martin</dc:creator>
 <dc:creator>Lenders, Vincent</dc:creator>
 <dc:creator>Martinovic, Ivan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The manner in which Aircraft Communications, Addressing and Reporting System
(ACARS) is being used has significantly changed over time. Whilst originally
used by commercial airliners to track their flights and provide automated
timekeeping on crew, today it serves as a multi-purpose air-ground data link
for many aviation stakeholders including private jet owners, state actors and
military. Since ACARS messages are still mostly sent in the clear over a
wireless channel, any sensitive information sent with ACARS can potentially
lead to a privacy breach for users. Naturally, different stakeholders consider
different types of data sensitive. In this paper we propose a privacy framework
matching aviation stakeholders to a range of sensitive information types and
assess the impact for each. Based on more than one million ACARS messages,
collected over several months, we then demonstrate that current ACARS usage
systematically breaches privacy for all stakeholder groups. We further support
our findings with a number of cases of significant privacy issues for each
group and analyze the impact of such leaks. While it is well-known that ACARS
messages are susceptible to eavesdropping attacks, this work is the first to
quantify the extent and impact of privacy leakage in the real world for the
relevant aviation stakeholders.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07069</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CacheShuffle: An Oblivious Shuffle Algorithm Using Caches</dc:title>
 <dc:creator>Patel, Sarvar</dc:creator>
 <dc:creator>Persiano, Giuseppe</dc:creator>
 <dc:creator>Yeo, Kevin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider Oblivious Shuffling and K-Oblivious Shuffling, a refinement
thereof. We provide efficient algorithms for both and discuss their application
to the design of Oblivious RAM. The task of K-Oblivious Shuffling is to
obliviously shuffle N encrypted blocks that have been randomly allocated on the
server in such a way that an adversary learns nothing about the new allocation
of blocks. The security guarantee should hold also with respect to an adversary
that has learned the initial position of K touched blocks out of the N blocks.
The classical notion of Oblivious Shuffling is obtained for K = N.
  We present a family of algorithms for Oblivious Shuffling. Our first
construction, CacheShuffleRoot, is tailored for clients with $O(\sqrt{N})$
blocks of memory and uses $(4+\epsilon)N$ blocks of bandwidth, for every
$\epsilon &gt; 0$. CacheShuffleRoot is a 4.5x improvement over previous best known
results on practical sizes of N. We also present CacheShuffle that obliviously
shuffles using O(S) blocks of client memory with $O(N\log_S N)$ blocks of
bandwidth.
  We then turn to K-Oblivious Shuffling and give algorithms that require 2N +
f(K) blocks of bandwidth, for some function f. That is, any extra bandwidth
above the 2N lower bound depends solely on K. We present KCacheShuffleBasic
that uses O(K) client storage and exactly 2N blocks of bandwidth. For smaller
client storage requirements, we show KCacheShuffle, which uses O(S) client
storage and requires $2N+(1+\epsilon)O(K\log_S K)$ blocks of bandwidth.
  Finally, we consider the case in which, in addition to the N blocks, the
server stores D dummy blocks whose content is is irrelevant but still their
positions must be hidden by the shuffling. For this case, we design algorithm
KCacheShuffleDummy that, for N + D blocks and K touched blocks, uses O(K)
client storage and $D+(2+\epsilon)N$ blocks of bandwidth.
</dc:description>
 <dc:description>Comment: 29 pages, 4 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07070</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EE-Grad: Exploration and Exploitation for Cost-Efficient Mini-Batch SGD</dc:title>
 <dc:creator>Donmez, Mehmet A.</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:creator>Singer, Andrew C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a generic framework for trading off fidelity and cost in computing
stochastic gradients when the costs of acquiring stochastic gradients of
different quality are not known a priori. We consider a mini-batch oracle that
distributes a limited query budget over a number of stochastic gradients and
aggregates them to estimate the true gradient. Since the optimal mini-batch
size depends on the unknown cost-fidelity function, we propose an algorithm,
{\it EE-Grad}, that sequentially explores the performance of mini-batch oracles
and exploits the accumulated knowledge to estimate the one achieving the best
performance in terms of cost-efficiency. We provide performance guarantees for
EE-Grad with respect to the optimal mini-batch oracle, and illustrate these
results in the case of strongly convex objectives. We also provide a simple
numerical example that corroborates our theoretical findings.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07077</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What do We Learn by Semantic Scene Understanding for Remote Sensing
  imagery in CNN framework?</dc:title>
 <dc:creator>Li, Haifeng</dc:creator>
 <dc:creator>Peng, Jian</dc:creator>
 <dc:creator>Tao, Chao</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:creator>Deng, Min</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently, deep convolutional neural network (DCNN) achieved increasingly
remarkable success and rapidly developed in the field of natural image
recognition. Compared with the natural image, the scale of remote sensing image
is larger and the scene and the object it represents are more macroscopic. This
study inquires whether remote sensing scene and natural scene recognitions
differ and raises the following questions: What are the key factors in remote
sensing scene recognition? Is the DCNN recognition mechanism centered on object
recognition still applicable to the scenarios of remote sensing scene
understanding? We performed several experiments to explore the influence of the
DCNN structure and the scale of remote sensing scene understanding from the
perspective of scene complexity. Our experiment shows that understanding a
complex scene depends on an in-depth network and multiple-scale perception.
Using a visualization method, we qualitatively and quantitatively analyze the
recognition mechanism in a complex remote sensing scene and demonstrate the
importance of multi-objective joint semantic support.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07077</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07080</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bitwise Operations of Cellular Automaton on Gray-scale Images</dc:title>
 <dc:creator>Mangalam, Karttikeya</dc:creator>
 <dc:creator>Venkatesh, K S</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cellular Automata (CA) theory is a discrete model that represents the state
of each of its cells from a finite set of possible values which evolve in time
according to a pre-defined set of transition rules. CA have been applied to a
number of image processing tasks such as Convex Hull Detection, Image Denoising
etc. but mostly under the limitation of restricting the input to binary images.
In general, a gray-scale image may be converted to a number of different binary
images which are finally recombined after CA operations on each of them
individually. We have developed a multinomial regression based weighed
summation method to recombine binary images for better performance of CA based
Image Processing algorithms. The recombination algorithm is tested for the
specific case of denoising Salt and Pepper Noise to test against standard
benchmark algorithms such as the Median Filter for various images and noise
levels. The results indicate several interesting invariances in the application
of the CA, such as the particular noise realization and the choice of
sub-sampling of pixels to determine recombination weights. Additionally, it
appears that simpler algorithms for weight optimization which seek local minima
work as effectively as those that seek global minima such as Simulated
Annealing.
</dc:description>
 <dc:description>Comment: 5 Pages. The code is available at :
  https://github.com/karttikeya/Bitwise-CA-Opeartions/</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07081</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Computation of Randomized Functions: Further Results</dc:title>
 <dc:creator>Data, Deepesh</dc:creator>
 <dc:creator>Prabhakaran, Vinod M.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider secure computation of randomized functions between two users,
where both the users (Alice and Bob) have inputs, Alice sends a message to Bob
over a rate-limited, noise-free link, and then Bob produces the output. We
study two cases: (i) when privacy condition is required only against Bob, who
tries to learn more about Alice's input from the message than what can be
inferred by his own input and output, and (ii) when there is no privacy
requirement. For both the problems, we give single-letter expressions for the
optimal rates. For the first problem, we also explicitly characterize securely
computable randomized functions when input has full support, which leads to a
much simpler expression for the optimal rate. Recently, Data (ISIT 2016)
studied the remaining two cases (first, when privacy conditions are against
both the users; and second, when privacy condition is only against Alice) and
obtained single-letter expressions for optimal rates in both the scenarios.
</dc:description>
 <dc:description>Comment: This is an extended version of a submission to ITW, 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07086</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating Accuracy from Unlabeled Data: A Probabilistic Logic Approach</dc:title>
 <dc:creator>Platanios, Emmanouil A.</dc:creator>
 <dc:creator>Poon, Hoifung</dc:creator>
 <dc:creator>Mitchell, Tom M.</dc:creator>
 <dc:creator>Horvitz, Eric</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose an efficient method to estimate the accuracy of classifiers using
only unlabeled data. We consider a setting with multiple classification
problems where the target classes may be tied together through logical
constraints. For example, a set of classes may be mutually exclusive, meaning
that a data instance can belong to at most one of them. The proposed method is
based on the intuition that: (i) when classifiers agree, they are more likely
to be correct, and (ii) when the classifiers make a prediction that violates
the constraints, at least one classifier must be making an error. Experiments
on four real-world data sets produce accuracy estimates within a few percent of
the true accuracy, using solely unlabeled data. Our models also outperform
existing state-of-the-art solutions in both estimating accuracies, and
combining multiple classifier outputs. The results emphasize the utility of
logical constraints in estimating accuracy, thus validating our intuition.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07091</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CNN-Based Joint Clustering and Representation Learning with Feature
  Drift Compensation for Large-Scale Image Data</dc:title>
 <dc:creator>Hsu, Chih-Chung</dc:creator>
 <dc:creator>Lin, Chia-Wen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given a large unlabeled set of images, how to efficiently and effectively
group them into clusters based on extracted visual representations remains a
challenging problem. To address this problem, we propose a convolutional neural
network (CNN) to jointly solve clustering and representation learning in an
iterative manner. In the proposed method, given an input image set, we first
randomly pick k samples and extract their features as initial cluster centroids
using the proposed CNN with an initial model pre-trained from the ImageNet
dataset. Mini-batch k-means is then performed to assign cluster labels to
individual input samples for a mini-batch of images randomly sampled from the
input image set until all images are processed. Subsequently, the proposed CNN
simultaneously updates the parameters of the proposed CNN and the centroids of
image clusters iteratively based on stochastic gradient descent. We also
proposed a feature drift compensation scheme to mitigate the drift error caused
by feature mismatch in representation learning. Experimental results
demonstrate the proposed method outperforms start-of-the-art clustering schemes
in terms of accuracy and storage complexity on large-scale image sets
containing millions of images.
</dc:description>
 <dc:description>Comment: 9 pages to appear in IEEE Transactions on Multimedia (Special Issue
  on Large-Scale Multimedia Data Retrieval, Classification, and Understanding)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07095</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Induction of Interpretable Possibilistic Logic Theories from Relational
  Data</dc:title>
 <dc:creator>Kuzelka, Ondrej</dc:creator>
 <dc:creator>Davis, Jesse</dc:creator>
 <dc:creator>Schockaert, Steven</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The field of Statistical Relational Learning (SRL) is concerned with learning
probabilistic models from relational data. Learned SRL models are typically
represented using some kind of weighted logical formulas, which make them
considerably more interpretable than those obtained by e.g. neural networks. In
practice, however, these models are often still difficult to interpret
correctly, as they can contain many formulas that interact in non-trivial ways
and weights do not always have an intuitive meaning. To address this, we
propose a new SRL method which uses possibilistic logic to encode relational
models. Learned models are then essentially stratified classical theories,
which explicitly encode what can be derived with a given level of certainty.
Compared to Markov Logic Networks (MLNs), our method is faster and produces
considerably more interpretable models.
</dc:description>
 <dc:description>Comment: Longer version of a paper appearing in IJCAI 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07099</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning for classification and quantification of monoclonal
  antibody preparations for cancer therapy</dc:title>
 <dc:creator>Le, Laetitia</dc:creator>
 <dc:creator>Marini, Camille</dc:creator>
 <dc:creator>Gramfort, Alexandre</dc:creator>
 <dc:creator>Nguyen, David</dc:creator>
 <dc:creator>Cherti, Mehdi</dc:creator>
 <dc:creator>Tfaili, Sana</dc:creator>
 <dc:creator>Tfayli, Ali</dc:creator>
 <dc:creator>Baillet-Guffroy, Arlette</dc:creator>
 <dc:creator>Prognon, Patrice</dc:creator>
 <dc:creator>Chaminade, Pierre</dc:creator>
 <dc:creator>Caudron, Eric</dc:creator>
 <dc:creator>K&#xe9;gl, Bal&#xe1;zs</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Monoclonal antibodies constitute one of the most important strategies to
treat patients suffering from cancers such as hematological malignancies and
solid tumors. In order to guarantee the quality of those preparations prepared
at hospital, quality control has to be developed. The aim of this study was to
explore a noninvasive, nondestructive, and rapid analytical method to ensure
the quality of the final preparation without causing any delay in the process.
We analyzed four mAbs (Inlfiximab, Bevacizumab, Ramucirumab and Rituximab)
diluted at therapeutic concentration in chloride sodium 0.9% using Raman
spectroscopy. To reduce the prediction errors obtained with traditional
chemometric data analysis, we explored a data-driven approach using statistical
machine learning methods where preprocessing and predictive models are jointly
optimized. We prepared a data analytics workflow and submitted the problem to a
collaborative data challenge platform called Rapid Analytics and Model
Prototyping (RAMP). This allowed to use solutions from about 300 data
scientists during five days of collaborative work. The prediction of the four
mAbs samples was considerably improved with a misclassification rate and the
mean error rate of 0.8% and 4%, respectively.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07104</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Learning of Harmonic Priors for Pitch Detection in Polyphonic
  Music</dc:title>
 <dc:creator>Alvarado, Pablo A.</dc:creator>
 <dc:creator>Stowell, Dan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Automatic music transcription (AMT) aims to infer a latent symbolic
representation of a piece of music (piano-roll), given a corresponding observed
audio recording. Transcribing polyphonic music (when multiple notes are played
simultaneously) is a challenging problem, due to highly structured overlapping
between harmonics. We study whether the introduction of physically inspired
Gaussian process (GP) priors into audio content analysis models improves the
extraction of patterns required for AMT. Audio signals are described as a
linear combination of sources. Each source is decomposed into the product of an
amplitude-envelope, and a quasi-periodic component process. We introduce the
Mat\'ern spectral mixture (MSM) kernel for describing frequency content of
singles notes. We consider two different regression approaches. In the sigmoid
model every pitch-activation is independently non-linear transformed. In the
softmax model several activation GPs are jointly non-linearly transformed. This
introduce cross-correlation between activations. We use variational Bayes for
approximate inference. We empirically evaluate how these models work in
practice transcribing polyphonic music. We demonstrate that rather than
encourage dependency between activations, what is relevant for improving pitch
detection is to learnt priors that fit the frequency content of the sound
events to detect.
</dc:description>
 <dc:description>Comment: 13 pages, 3 figures, paper submitted to WASPAA 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07105</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Bag Semantics of Ontology-Based Data Access</dc:title>
 <dc:creator>Nikolaou, Charalampos</dc:creator>
 <dc:creator>Kostylev, Egor V.</dc:creator>
 <dc:creator>Konstantinidis, George</dc:creator>
 <dc:creator>Kaminski, Mark</dc:creator>
 <dc:creator>Grau, Bernardo Cuenca</dc:creator>
 <dc:creator>Horrocks, Ian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Ontology-based data access (OBDA) is a popular approach for integrating and
querying multiple data sources by means of a shared ontology. The ontology is
linked to the sources using mappings, which assign views over the data to
ontology predicates. Motivated by the need for OBDA systems supporting
database-style aggregate queries, we propose a bag semantics for OBDA, where
duplicate tuples in the views defined by the mappings are retained, as is the
case in standard databases. We show that bag semantics makes conjunctive query
answering in OBDA coNP-hard in data complexity. To regain tractability, we
consider a rather general class of queries and show its rewritability to a
generalisation of the relational calculus to bags.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07107</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Estimators for Implicit Models</dc:title>
 <dc:creator>Li, Yingzhen</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Implicit models, which allow for the generation of samples but not for
point-wise evaluation of probabilities, are omnipresent in real-world problems
tackled by machine learning and a hot topic of current research. Some examples
include data simulators that are widely used in engineering and scientific
research, generative adversarial networks (GANs) for image synthesis, and
hot-off-the-press approximate inference techniques relying on implicit
distributions. The majority of existing approaches to learning implicit models
rely on approximating the intractable distribution or optimisation objective
for gradient-based optimisation, which is liable to produce inaccurate updates
and thus poor models. This paper alleviates the need for such approximations by
proposing the Stein gradient estimator, which directly estimates the score
function of the implicitly defined distribution. The efficacy of the proposed
estimator is empirically demonstrated by examples that include meta-learning
for approximate inference, and entropy regularised GANs that provide improved
sample diversities.
</dc:description>
 <dc:description>Comment: v2 adds a new non-parametric estimator comparing to v1</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07108</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Snapshot Difference Imaging using Time-of-Flight Sensors</dc:title>
 <dc:creator>Callenberg, Clara</dc:creator>
 <dc:creator>Heide, Felix</dc:creator>
 <dc:creator>Wetzstein, Gordon</dc:creator>
 <dc:creator>Hullin, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Computational photography encompasses a diversity of imaging techniques, but
one of the core operations performed by many of them is to compute image
differences. An intuitive approach to computing such differences is to capture
several images sequentially and then process them jointly. Usually, this
approach leads to artifacts when recording dynamic scenes. In this paper, we
introduce a snapshot difference imaging approach that is directly implemented
in the sensor hardware of emerging time-of-flight cameras. With a variety of
examples, we demonstrate that the proposed snapshot difference imaging
technique is useful for direct-global illumination separation, for direct
imaging of spatial and temporal image gradients, for direct depth edge imaging,
and more.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07109</identifier>
 <datestamp>2017-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep adversarial neural decoding</dc:title>
 <dc:creator>G&#xfc;&#xe7;l&#xfc;t&#xfc;rk, Ya&#x11f;mur</dc:creator>
 <dc:creator>G&#xfc;&#xe7;l&#xfc;, Umut</dc:creator>
 <dc:creator>Seeliger, Katja</dc:creator>
 <dc:creator>Bosch, Sander</dc:creator>
 <dc:creator>van Lier, Rob</dc:creator>
 <dc:creator>van Gerven, Marcel</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Here, we present a novel approach to solve the problem of reconstructing
perceived stimuli from brain responses by combining probabilistic inference
with deep learning. Our approach first inverts the linear transformation from
latent features to brain responses with maximum a posteriori estimation and
then inverts the nonlinear transformation from perceived stimuli to latent
features with adversarial training of convolutional neural networks. We test
our approach with a functional magnetic resonance imaging experiment and show
that it can generate state-of-the-art reconstructions of perceived faces from
brain activations.
</dc:description>
 <dc:description>Comment: Added appendix and updated figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07112</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Singular Value Shrinkage with Chebyshev Polynomial Approximation
  Based on Signal Sparsity</dc:title>
 <dc:creator>Onuki, Masaki</dc:creator>
 <dc:creator>Ono, Shunsuke</dc:creator>
 <dc:creator>Shirai, Keiichiro</dc:creator>
 <dc:creator>Tanaka, Yuichi</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose an approximation method for thresholding of singular values using
Chebyshev polynomial approximation (CPA). Many signal processing problems
require iterative application of singular value decomposition (SVD) for
minimizing the rank of a given data matrix with other cost functions and/or
constraints, which is called matrix rank minimization. In matrix rank
minimization, singular values of a matrix are shrunk by hard-thresholding,
soft-thresholding, or weighted soft-thresholding. However, the computational
cost of SVD is generally too expensive to handle high dimensional signals such
as images; hence, in this case, matrix rank minimization requires enormous
computation time. In this paper, we leverage CPA to (approximately) manipulate
singular values without computing singular values and vectors. The thresholding
of singular values is expressed by a multiplication of certain matrices, which
is derived from a characteristic of CPA. The multiplication is also efficiently
computed using the sparsity of signals. As a result, the computational cost is
significantly reduced. Experimental results suggest the effectiveness of our
method through several image processing applications based on matrix rank
minimization with nuclear norm relaxation in terms of computation time and
approximation precision.
</dc:description>
 <dc:description>Comment: This is a journal paper</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07112</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2745444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07114</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud
  Auto-Scaling</dc:title>
 <dc:creator>Arabnejad, Hamid</dc:creator>
 <dc:creator>Pahl, Claus</dc:creator>
 <dc:creator>Jamshidi, Pooyan</dc:creator>
 <dc:creator>Estrada, Giovani</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A goal of cloud service management is to design self-adaptable auto-scaler to
react to workload fluctuations and changing the resources assigned. The key
problem is how and when to add/remove resources in order to meet agreed
service-level agreements. Reducing application cost and guaranteeing
service-level agreements (SLAs) are two critical factors of dynamic controller
design. In this paper, we compare two dynamic learning strategies based on a
fuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A
self-adaptive fuzzy logic controller is combined with two reinforcement
learning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy
Q-learning (FQL). As an off-policy approach, Q-learning learns independent of
the policy currently followed, whereas SARSA as an on-policy always
incorporates the actual agent's behavior and leads to faster learning. Both
approaches are implemented and compared in their advantages and disadvantages,
here in the OpenStack cloud platform. We demonstrate that both auto-scaling
approaches can handle various load traffic situations, sudden and periodic, and
delivering resources on demand while reducing operating costs and preventing
SLA violations. The experimental results demonstrate that FSL and FQL have
acceptable performance in terms of adjusted number of virtual machine targeted
to optimize SLA compliance and response time.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07115</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry
  and Semantics</dc:title>
 <dc:creator>Kendall, Alex</dc:creator>
 <dc:creator>Gal, Yarin</dc:creator>
 <dc:creator>Cipolla, Roberto</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Numerous deep learning applications benefit from multi-task learning with
multiple regression and classification objectives. In this paper we make the
observation that the performance of such systems is strongly dependent on the
relative weighting between each task's loss. Tuning these weights by hand is a
difficult and expensive process, making multi-task learning prohibitive in
practice. We propose a principled approach to multi-task deep learning which
weighs multiple loss functions by considering the homoscedastic uncertainty of
each task. This allows us to simultaneously learn various quantities with
different units or scales in both classification and regression settings. We
demonstrate our model learning per-pixel depth regression, semantic and
instance segmentation from a monocular input image. Perhaps surprisingly, we
show our model can learn multi-task weightings and outperform separate models
trained individually on each task.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07115</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07117</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning as a Tool to Predict Flow Patterns in Two-Phase Flow</dc:title>
 <dc:creator>Ezzatabadipour, Mohammadmehdi</dc:creator>
 <dc:creator>Singh, Parth</dc:creator>
 <dc:creator>Robinson, Melvin D.</dc:creator>
 <dc:creator>Guillen-Rondon, Pablo</dc:creator>
 <dc:creator>Torres, Carlos</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order to better model complex real-world data such as multiphase flow, one
approach is to develop pattern recognition techniques and robust features that
capture the relevant information. In this paper, we use deep learning methods,
and in particular employ the multilayer perceptron, to build an algorithm that
can predict flow pattern in twophase flow from fluid properties and pipe
conditions. The preliminary results show excellent performance when compared
with classical methods of flow pattern prediction.
</dc:description>
 <dc:description>Comment: Part of DM4OG 2017 proceedings (arXiv:1705.03451)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07118</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluation of Direct Haptic 4D Volume Rendering of Partially Segmented
  Data for Liver Puncture Simulation</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Fortmeier, Dirk</dc:creator>
 <dc:creator>Handels, Heinz</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  This work presents an evaluation study using a force feedback evaluation
framework for a novel direct needle force volume rendering concept in the
context of liver puncture simulation. PTC/PTCD puncture interventions targeting
the bile ducts have been selected to illustrate this concept. The haptic
algorithms of the simulator system are based on (1) partially segmented patient
image data and (2) a non-linear spring model effective at organ borders. The
primary aim is to quantitatively evaluate force errors caused by our patient
modeling approach, in comparison to haptic force output obtained from using
gold-standard, completely manually-segmented data. The evaluation of the force
algorithms compared to a force output from fully manually segmented
gold-standard patient models, yields a low mean of 0.12 N root mean squared
force error and up to 1.6 N for systematic maximum absolute errors. Force
errors were evaluated on 31,222 preplanned test paths from 10 patients. Only
twelve percent of the emitted forces along these paths were affected by errors.
This is the first study evaluating haptic algorithms with deformable virtual
patients in silico. We prove haptic rendering plausibility on a very high
number of test paths. Important errors are below just noticeable differences
for the hand-arm system.
</dc:description>
 <dc:description>Comment: 15 pages, 16 figures, 1 tables, 11 equations, 39 references</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07118</dc:identifier>
 <dc:identifier>Nature - Scientific Reports, Nature Publishing Group (NPG),
  7(671), 2017</dc:identifier>
 <dc:identifier>doi:10.1038/s41598-017-00746-z</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07120</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VAE with a VampPrior</dc:title>
 <dc:creator>Tomczak, Jakub M.</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many different methods to train deep generative models have been introduced
in the past. In this paper, we propose to extend the variational auto-encoder
(VAE) framework with a new type of prior which we call &quot;Variational Mixture of
Posteriors&quot; prior, or VampPrior for short. The VampPrior consists of a mixture
distribution (e.g., a mixture of Gaussians) with components given by
variational posteriors conditioned on learnable pseudo-inputs. We further
extend this prior to a two layer hierarchical model and show that this
architecture with a coupled prior and posterior, learns significantly better
models. The model also avoids the usual local optima issues related to useless
latent dimensions that plague VAEs. We provide empirical studies on six
datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes,
Frey Faces and Histopathology patches, and show that applying the hierarchical
VampPrior delivers state-of-the-art results on all datasets in the unsupervised
permutation invariant setting and the best results or comparable to SOTA
methods for the approach with convolutional networks.
</dc:description>
 <dc:description>Comment: 16 pages, new and corrected results comparing to the previous version
  + the text was re-organized and re-written in some parts</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07121</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BAMHealthCloud: A Biometric Authentication and Data Management System
  for Healthcare Data in Cloud</dc:title>
 <dc:creator>Shakil, Kashish A.</dc:creator>
 <dc:creator>Zareen, Farhana J.</dc:creator>
 <dc:creator>Alam, Mansaf</dc:creator>
 <dc:creator>Jabin, Suraiya</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Advancements in healthcare industry with new technology and population growth
has given rise to security threat to our most personal data. The healthcare
data management system consists of records in different formats such as text,
numeric, pictures and videos leading to data which is big and unstructured.
Also, hospitals have several branches at different locations throughout a
country and overseas. In view of these requirements a cloud based healthcare
management system can be an effective solution for efficient health care data
management. One of the major concerns of a cloud based healthcare system is the
security aspect. It includes theft to identity, tax fraudulence, insurance
frauds, medical frauds and defamation of high profile patients. Hence, a secure
data access and retrieval is needed in order to provide security of critical
medical records in health care management system. Biometric authentication
mechanism is suitable in this scenario since it overcomes the limitations of
token theft and forgetting passwords in conventional token id-password
mechanism used for providing security. It also has high accuracy rate for
secure data access and retrieval. In this paper we propose BAMHealthCloud which
is a cloud based system for management of healthcare data, it ensures security
of data through biometric authentication. It has been developed after
performing a detailed case study on healthcare sector in a developing country.
Training of the signature samples for authentication purpose has been performed
in parallel on hadoop MapReduce framework using Resilient Backpropagation
neural network. From rigorous experiments it can be concluded that it achieves
a speedup of 9x, Equal error rate (EER) of 0.12, sensitivity of 0.98 and
specificity of 0.95 as compared to other approaches existing in literature.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07136</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Softmax Q-Distribution Estimation for Structured Prediction: A
  Theoretical Interpretation for RAML</dc:title>
 <dc:creator>Ma, Xuezhe</dc:creator>
 <dc:creator>Yin, Pengcheng</dc:creator>
 <dc:creator>Liu, Jingzhou</dc:creator>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Reward augmented maximum likelihood (RAML), a simple and effective learning
framework to directly optimize towards the reward function in structured
prediction tasks, has led to a number of impressive empirical successes. RAML
incorporates task-specific reward by performing maximum-likelihood updates on
candidate outputs sampled according to an exponentiated payoff distribution,
which gives higher probabilities to candidates that are close to the reference
output. While RAML is notable for its simplicity, efficiency, and its
impressive empirical successes, the theoretical properties of RAML, especially
the behavior of the exponentiated payoff distribution, has not been examined
thoroughly. In this work, we introduce softmax Q-distribution estimation, a
novel theoretical interpretation of RAML, which reveals the relation between
RAML and Bayesian decision theory. The softmax Q-distribution can be regarded
as a smooth approximation of the Bayes decision boundary, and the Bayes
decision rule is achieved by decoding with this Q-distribution. We further show
that RAML is equivalent to approximately estimating the softmax Q-distribution,
with the temperature $\tau$ controlling approximation error. We perform two
experiments, one on synthetic data of multi-class classification and one on
real data of image captioning, to demonstrate the relationship between RAML and
the proposed softmax Q-distribution estimation method, verifying our
theoretical analysis. Additional experiments on three structured prediction
tasks with rewards defined on sequential (named entity recognition), tree-based
(dependency parsing) and irregular (machine translation) structures show
notable improvements over maximum likelihood baselines.
</dc:description>
 <dc:description>Comment: Under Review of ICLR 2018</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07137</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep De-Aliasing for Fast Compressive Sensing MRI</dc:title>
 <dc:creator>Yu, Simiao</dc:creator>
 <dc:creator>Dong, Hao</dc:creator>
 <dc:creator>Yang, Guang</dc:creator>
 <dc:creator>Slabaugh, Greg</dc:creator>
 <dc:creator>Dragotti, Pier Luigi</dc:creator>
 <dc:creator>Ye, Xujiong</dc:creator>
 <dc:creator>Liu, Fangde</dc:creator>
 <dc:creator>Arridge, Simon</dc:creator>
 <dc:creator>Keegan, Jennifer</dc:creator>
 <dc:creator>Firmin, David</dc:creator>
 <dc:creator>Guo, Yike</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fast Magnetic Resonance Imaging (MRI) is highly in demand for many clinical
applications in order to reduce the scanning cost and improve the patient
experience. This can also potentially increase the image quality by reducing
the motion artefacts and contrast washout. However, once an image field of view
and the desired resolution are chosen, the minimum scanning time is normally
determined by the requirement of acquiring sufficient raw data to meet the
Nyquist-Shannon sampling criteria. Compressive Sensing (CS) theory has been
perfectly matched to the MRI scanning sequence design with much less required
raw data for the image reconstruction. Inspired by recent advances in deep
learning for solving various inverse problems, we propose a conditional
Generative Adversarial Networks-based deep learning framework for de-aliasing
and reconstructing MRI images from highly undersampled data with great promise
to accelerate the data acquisition process. By coupling an innovative content
loss with the adversarial loss our de-aliasing results are more realistic.
Furthermore, we propose a refinement learning procedure for training the
generator network, which can stabilise the training with fast convergence and
less parameter tuning. We demonstrate that the proposed framework outperforms
state-of-the-art CS-MRI methods, in terms of reconstruction error and
perceptual image quality. In addition, our method can reconstruct each image in
0.22ms--0.37ms, which is promising for real-time applications.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07142</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Multiple Surface Segmentation Using Deep Learning</dc:title>
 <dc:creator>Shah, Abhay</dc:creator>
 <dc:creator>Abramoff, Michael</dc:creator>
 <dc:creator>Wu, Xiaodong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The task of automatically segmenting 3-D surfaces representing boundaries of
objects is important for quantitative analysis of volumetric images, and plays
a vital role in biomedical image analysis. Recently, graph-based methods with a
global optimization property have been developed and optimized for various
medical imaging applications. Despite their widespread use, these require human
experts to design transformations, image features, surface smoothness priors,
and re-design for a different tissue, organ or imaging modality. Here, we
propose a Deep Learning based approach for segmentation of the surfaces in
volumetric medical images, by learning the essential features and
transformations from training data, without any human expert intervention. We
employ a regional approach to learn the local surface profiles. The proposed
approach was evaluated on simultaneous intraretinal layer segmentation of
optical coherence tomography (OCT) images of normal retinas and retinas
affected by age related macular degeneration (AMD). The proposed approach was
validated on 40 retina OCT volumes including 20 normal and 20 AMD subjects. The
experiments showed statistically significant improvement in accuracy for our
approach compared to state-of-the-art graph based optimal surface segmentation
with convex priors (G-OSC). A single Convolution Neural Network (CNN) was used
to learn the surfaces for both normal and diseased images. The mean unsigned
surface positioning errors obtained by G-OSC method 2.31 voxels (95% CI
2.02-2.60 voxels) was improved to $1.27$ voxels (95% CI 1.14-1.40 voxels) using
our new approach. On average, our approach takes 94.34 s, requiring 95.35 MB
memory, which is much faster than the 2837.46 s and 6.87 GB memory required by
the G-OSC method on the same computer system.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07142</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67558-9_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07143</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New 3D Segmentation Methodology for Lumbar Vertebral Bodies for the
  Measurement of BMD and Geometry</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Engelke, Klaus</dc:creator>
 <dc:creator>Kalender, Willi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper a new technique is presented that extracts the geometry of
lumbar vertebral bodies from spiral CT scans. Our new multi-step segmentation
approach yields highly accurate and precise measurement of the bone mineral
density (BMD) in different volumes of interest which are defined relative to a
local anatomical coordinate systems. The approach also enables the analysis of
the geometry of the relevant vertebrae. Intra- and inter operator precision for
segmentation, BMD measurement and position of the coordinate system are below
1.5% in patient data, accuracy errors are below 1.5% for BMD and below 4% for
volume in phantom data. The long-term goal of the approach is to improve
fracture prediction in osteoporosis.
</dc:description>
 <dc:description>Comment: 4 pages,2 figures, MIUA05 conference</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07144</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Coding on Stereo Video for Object Detection</dc:title>
 <dc:creator>Lundquist, Sheng Y.</dc:creator>
 <dc:creator>Mitchell, Melanie</dc:creator>
 <dc:creator>Kenyon, Garrett T.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Convolutional Neural Networks (DCNN) require millions of labeled
training examples for image classification and object detection tasks, which
restrict these models to domains where such datasets are available. In this
paper, we explore the use of unsupervised sparse coding applied to stereo-video
data to help alleviate the need for large amounts of labeled data. We show that
replacing a typical supervised convolutional layer with an unsupervised
sparse-coding layer within a DCNN allows for better performance on a car
detection task when only a limited number of labeled training examples is
available. Furthermore, the network that incorporates sparse coding allows for
more consistent performance over varying initializations and ordering of
training examples when compared to a fully supervised DCNN. Finally, we compare
activations between the unsupervised sparse-coding layer and the supervised
convolutional layer, and show that the sparse representation exhibits an
encoding that is depth selective, whereas encodings from the convolutional
layer do not exhibit such selectivity. These result indicates promise for using
unsupervised sparse-coding approaches in real-world computer vision tasks in
domains with limited labeled training data.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07146</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New 3D Method to Segment the Lumbar Vertebral Bodies and to Determine
  Bone Mineral Density and Geometry</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Engelke, Klaus</dc:creator>
 <dc:creator>Meller, Sebastian</dc:creator>
 <dc:creator>Kalender, Willi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present a new 3D segmentation approach for the vertebrae of
the lower thoracic and the lumbar spine in spiral computed tomography datasets.
We implemented a multi-step procedure. Its main components are deformable
models, volume growing, and morphological operations. The performance analysis
that included an evaluation of accuracy using the European Spine Phantom, and
of intra-operator precision using clinical CT datasets from 10 patients
highlight the potential for clinical use. The intra-operator precision of the
segmentation procedure was better than 1% for Bone Mineral Density (BMD) and
better than 1.8% for volume. The long-term goal of this work is to enable
better fracture prediction and improved patient monitoring in the field of
osteoporosis. A true 3D segmentation also enables an accurate measurement of
geometrical parameters that can augment the classical measurement of BMD.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, 1 table, MICCAI 2005 workshop paper</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07149</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Information with Feedback Perturbation Suffices for Dictionary
  Learning in Neural Circuits</dc:title>
 <dc:creator>Lin, Tsung-Han</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  While the sparse coding principle can successfully model information
processing in sensory neural systems, it remains unclear how learning can be
accomplished under neural architectural constraints. Feasible learning rules
must rely solely on synaptically local information in order to be implemented
on spatially distributed neurons. We describe a neural network with spiking
neurons that can address the aforementioned fundamental challenge and solve the
L1-minimizing dictionary learning problem, representing the first model able to
do so. Our major innovation is to introduce feedback synapses to create a
pathway to turn the seemingly non-local information into local ones. The
resulting network encodes the error signal needed for learning as the change of
network steady states caused by feedback, and operates akin to the classical
stochastic gradient descent method.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07150</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Complexity of Reversals of Deterministic Finite Automata with
  Output</dc:title>
 <dc:creator>Davies, Sylvie</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We investigate the worst-case state complexity of reversals of deterministic
finite automata with output (DFAOs). In these automata, each state is assigned
some output value, rather than simply being labelled final or non-final. This
directly generalizes the well-studied problem of determining the worst-case
state complexity of reversals of ordinary deterministic finite automata. If a
DFAO has $n$ states and $k$ possible output values, there is a known upper
bound of $k^n$ for the state complexity of reversal. We show this bound can be
reached with a ternary input alphabet. We conjecture it cannot be reached with
a binary input alphabet except when $k = 2$, and give a lower bound for the
case $3 \le k &lt; n$. We prove that the state complexity of reversal depends
solely on the transition monoid of the DFAO and the mapping that assigns output
values to states.
</dc:description>
 <dc:description>Comment: 18 pages, 3 tables. Added missing affiliation/funding information</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07150</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07154</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Demonstration of a quantum key distribution network in urban fibre-optic
  communication lines</dc:title>
 <dc:creator>Kiktenko, E. O.</dc:creator>
 <dc:creator>Pozhar, N. O.</dc:creator>
 <dc:creator>Duplinskiy, A. V.</dc:creator>
 <dc:creator>Kanapin, A. A.</dc:creator>
 <dc:creator>Sokolov, A. S.</dc:creator>
 <dc:creator>Vorobey, S. S.</dc:creator>
 <dc:creator>Miller, A. V.</dc:creator>
 <dc:creator>Ustimchik, V. E.</dc:creator>
 <dc:creator>Anufriev, M. N.</dc:creator>
 <dc:creator>Trushechkin, A. S.</dc:creator>
 <dc:creator>Yunusov, R. R.</dc:creator>
 <dc:creator>Kurochkin, V. L.</dc:creator>
 <dc:creator>Kurochkin, Y. V.</dc:creator>
 <dc:creator>Fedorov, A. K.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We report the results of the implementation of a quantum key distribution
(QKD) network using standard fibre communication lines in Moscow. The developed
QKD network is based on the paradigm of trusted repeaters and allows a common
secret key to be generated between users via an intermediate trusted node. The
main feature of the network is the integration of the setups using two types of
encoding, i.e. polarisation encoding and phase encoding. One of the possible
applications of the developed QKD network is the continuous key renewal in
existing symmetric encryption devices with a key refresh time of up to 14 s.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07154</dc:identifier>
 <dc:identifier>Quantum Electron. 47, 798 (2017)</dc:identifier>
 <dc:identifier>doi:10.1070/QEL16469</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07157</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering under Local Stability: Bridging the Gap between Worst-Case
  and Beyond Worst-Case Analysis</dc:title>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>White, Colin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recently, there has been substantial interest in clustering research that
takes a beyond worst-case approach to the analysis of algorithms. The typical
idea is to design a clustering algorithm that outputs a near-optimal solution,
provided the data satisfy a natural stability notion. For example, Bilu and
Linial (2010) and Awasthi et al. (2012) presented algorithms that output
near-optimal solutions, assuming the optimal solution is preserved under small
perturbations to the input distances. A drawback to this approach is that the
algorithms are often explicitly built according to the stability assumption and
give no guarantees in the worst case; indeed, several recent algorithms output
arbitrarily bad solutions even when just a small section of the data does not
satisfy the given stability notion.
  In this work, we address this concern in two ways. First, we provide
algorithms that inherit the worst-case guarantees of clustering approximation
algorithms, while simultaneously guaranteeing near-optimal solutions when the
data is stable. Our algorithms are natural modifications to existing
state-of-the-art approximation algorithms. Second, we initiate the study of
local stability, which is a property of a single optimal cluster rather than an
entire optimal solution. We show our algorithms output all optimal clusters
which satisfy stability locally. Specifically, we achieve strong positive
results in our local framework under recent stability notions including metric
perturbation resilience (Angelidakis et al. 2017) and robust perturbation
resilience (Balcan and Liang 2012) for the $k$-median, $k$-means, and
symmetric/asymmetric $k$-center objectives.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07161</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical physics of human cooperation</dc:title>
 <dc:creator>Perc, Matjaz</dc:creator>
 <dc:creator>Jordan, Jillian J.</dc:creator>
 <dc:creator>Rand, David G.</dc:creator>
 <dc:creator>Wang, Zhen</dc:creator>
 <dc:creator>Boccaletti, Stefano</dc:creator>
 <dc:creator>Szolnoki, Attila</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:description>  Extensive cooperation among unrelated individuals is unique to humans, who
often sacrifice personal benefits for the common good and work together to
achieve what they are unable to execute alone. The evolutionary success of our
species is indeed due, to a large degree, to our unparalleled other-regarding
abilities. Yet, a comprehensive understanding of human cooperation remains a
formidable challenge. Recent research in social science indicates that it is
important to focus on the collective behavior that emerges as the result of the
interactions among individuals, groups, and even societies. Non-equilibrium
statistical physics, in particular Monte Carlo methods and the theory of
collective behavior of interacting particles near phase transition points, has
proven to be very valuable for understanding counterintuitive evolutionary
outcomes. By studying models of human cooperation as classical spin models, a
physicist can draw on familiar settings from statistical physics. However,
unlike pairwise interactions among particles that typically govern solid-state
physics systems, interactions among humans often involve group interactions,
and they also involve a larger number of possible states even for the most
simplified description of reality. The complexity of solutions therefore often
surpasses that observed in physical systems. Here we review experimental and
theoretical research that advances our understanding of human cooperation,
focusing on spatial pattern formation, on the spatiotemporal dynamics of
observed solutions, and on self-organization that may either promote or hinder
socially favorable states.
</dc:description>
 <dc:description>Comment: 48 two-column pages, 35 figures; Review accepted for publication in
  Physics Reports</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07161</dc:identifier>
 <dc:identifier>Phys. Rep. 687 (2017) 1-51</dc:identifier>
 <dc:identifier>doi:10.1016/j.physrep.2017.05.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07162</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Lightweight Approach for On-the-Fly Reflectance Estimation</dc:title>
 <dc:creator>Kim, Kihwan</dc:creator>
 <dc:creator>Gu, Jinwei</dc:creator>
 <dc:creator>Tyree, Stephen</dc:creator>
 <dc:creator>Molchanov, Pavlo</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Estimating surface reflectance (BRDF) is one key component for complete 3D
scene capture, with wide applications in virtual reality, augmented reality,
and human computer interaction. Prior work is either limited to controlled
environments (\eg gonioreflectometers, light stages, or multi-camera domes), or
requires the joint optimization of shape, illumination, and reflectance, which
is often computationally too expensive (\eg hours of running time) for
real-time applications. Moreover, most prior work requires HDR images as input
which further complicates the capture process. In this paper, we propose a
lightweight approach for surface reflectance estimation directly from $8$-bit
RGB images in real-time, which can be easily plugged into any 3D
scanning-and-fusion system with a commodity RGBD sensor. Our method is
learning-based, with an inference time of less than 90ms per scene and a model
size of less than 340K bytes. We propose two novel network architectures,
HemiCNN and Grouplet, to deal with the unstructured input data from multiple
viewpoints under unknown illumination. We further design a loss function to
resolve the color-constancy and scale ambiguity. In addition, we have created a
large synthetic dataset, SynBRDF, which comprises a total of $500$K RGBD images
rendered with a physically-based ray tracer under a variety of natural
illumination, covering $5000$ materials and $5000$ shapes. SynBRDF is the first
large-scale benchmark dataset for reflectance estimation. Experiments on both
synthetic data and real data show that the proposed method effectively recovers
surface reflectance, and outperforms prior work for reflectance estimation in
uncontrolled environments.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07163</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Communication-Aware Robust Topologies</dc:title>
 <dc:creator>Avin, Chen</dc:creator>
 <dc:creator>Hercules, Alexandr</dc:creator>
 <dc:creator>Loukas, Andreas</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We currently witness the emergence of interesting new network topologies
optimized towards the traffic matrices they serve, such as demand-aware
datacenter interconnects (e.g., ProjecToR) and demand-aware overlay networks
(e.g., SplayNets). This paper introduces a formal framework and approach to
reason about and design such topologies. We leverage a connection between the
communication frequency of two nodes and the path length between them in the
network, which depends on the entropy of the communication matrix. Our main
contribution is a novel robust, yet sparse, family of network topologies which
guarantee an expected path length that is proportional to the entropy of the
communication patterns.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07164</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxed Wasserstein with Applications to GANs</dc:title>
 <dc:creator>Guo, Xin</dc:creator>
 <dc:creator>Hong, Johnny</dc:creator>
 <dc:creator>Lin, Tianyi</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel class of statistical divergences called \textit{Relaxed
Wasserstein} (RW) divergence. RW divergence generalizes Wasserstein distance
and is parametrized by strictly convex, differentiable functions. We establish
for RW several key probabilistic properties, which are critical for the success
of Wasserstein distances. In particular, we show that RW is dominated by Total
Variation (TV) and Wasserstein-$L^2$ distance, and establish continuity,
differentiability, and duality representation of RW divergence. Finally, we
provide a non-asymptotic moment estimate and a concentration inequality for RW
divergence.
  Our experiments on image generation problems show that RWGANs with
Kullback-Leibler (KL) divergence provide competitive performance compared with
many state-of-the-art approaches. Empirically, we show that RWGANs possess
better convergence properties than WGANs, with competitive inception scores. In
comparison to the existing literature in GANs, which are ad-hoc in the choices
of cost functions, this new conceptual framework not only provides great
flexibility in designing general cost functions, e.g., for applications to
GANs, but also allows different cost functions implemented and compared under a
unified mathematical framework.
</dc:description>
 <dc:description>Comment: 27 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07171</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nestrov's Acceleration For Second Order Method</dc:title>
 <dc:creator>Ye, Haishan</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Optimization plays a key role in machine learning. Recently, stochastic
second-order methods have attracted much attention due to their low
computational cost in each iteration. However, these algorithms might perform
poorly especially if it is hard to approximate the Hessian well and
efficiently. As far as we know, there is no effective way to handle this
problem. In this paper, we resort to Nestrov's acceleration technique to
improve the convergence performance of a class of second-order methods called
approximate Newton. We give a theoretical analysis that Nestrov's acceleration
technique can improve the convergence performance for approximate Newton just
like for first-order methods. We accordingly propose an accelerated regularized
sub-sampled Newton. Our accelerated algorithm performs much better than the
original regularized sub-sampled Newton in experiments, which validates our
theory empirically. Besides, the accelerated regularized sub-sampled Newton has
good performance comparable to or even better than state-of-art algorithms.
</dc:description>
 <dc:description>Comment: Have an important typo in title. Superseded by arXiv:1710.08496</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07175</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Espresso: Efficient Forward Propagation for BCNNs</dc:title>
 <dc:creator>Pedersoli, Fabrizio</dc:creator>
 <dc:creator>Tzanetakis, George</dc:creator>
 <dc:creator>Tagliasacchi, Andrea</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>62M45</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  There are many applications scenarios for which the computational performance
and memory footprint of the prediction phase of Deep Neural Networks (DNNs)
needs to be optimized. Binary Neural Networks (BDNNs) have been shown to be an
effective way of achieving this objective. In this paper, we show how
Convolutional Neural Networks (CNNs) can be implemented using binary
representations. Espresso is a compact, yet powerful library written in C/CUDA
that features all the functionalities required for the forward propagation of
CNNs, in a binary file less than 400KB, without any external dependencies.
Although it is mainly designed to take advantage of massive GPU parallelism,
Espresso also provides an equivalent CPU implementation for CNNs. Espresso
provides special convolutional and dense layers for BCNNs, leveraging
bit-packing and bit-wise computations for efficient execution. These techniques
provide a speed-up of matrix-multiplication routines, and at the same time,
reduce memory usage when storing parameters and activations. We experimentally
show that Espresso is significantly faster than existing implementations of
optimized binary neural networks ($\approx$ 2 orders of magnitude). Espresso is
released under the Apache 2.0 license and is available at
http://github.com/fpeder/espresso.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07175</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07177</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-Based Planning in Discrete Action Spaces</dc:title>
 <dc:creator>Henaff, Mikael</dc:creator>
 <dc:creator>Whitney, William F.</dc:creator>
 <dc:creator>LeCun, Yann</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Planning actions using learned and differentiable forward models of the world
is a general approach which has a number of desirable properties, including
improved sample complexity over model-free RL methods, reuse of learned models
across different tasks, and the ability to perform efficient gradient-based
optimization in continuous action spaces. However, this approach does not apply
straightforwardly when the action space is discrete, which may have limited its
adoption. In this work, we introduce two discrete planning tasks inspired by
existing question-answering datasets and show that it is in fact possible to
effectively perform planning via backprop in discrete action spaces using two
simple yet principled modifications. Our experiments show that this approach
can significantly outperform model-free RL based methods and supervised
imitation learners.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07183</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large System Analysis of Power Normalization Techniques in Massive MIMO</dc:title>
 <dc:creator>Sadeghi, Meysam</dc:creator>
 <dc:creator>Sanguinetti, Luca</dc:creator>
 <dc:creator>Couillet, Romain</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear precoding has been widely studied in the context of Massive
multiple-input-multiple-output (MIMO) together with two common power
normalization techniques, namely, matrix normalization (MN) and vector
normalization (VN). Despite this, their effect on the performance of Massive
MIMO systems has not been thoroughly studied yet. The aim of this paper is to
fulfill this gap by using large system analysis. Considering a system model
that accounts for channel estimation, pilot contamination, arbitrary pathloss,
and per-user channel correlation, we compute tight approximations for the
signal-to-interference-plus-noise ratio and the rate of each user equipment in
the system while employing maximum ratio transmission (MRT), zero forcing (ZF),
and regularized ZF precoding under both MN and VN techniques. Such
approximations are used to analytically reveal how the choice of power
normalization affects the performance of MRT and ZF under uncorrelated fading
channels. It turns out that ZF with VN resembles a sum rate maximizer while it
provides a notion of fairness under MN. Numerical results are used to validate
the accuracy of the asymptotic analysis and to show that in Massive MIMO,
non-coherent interference and noise, rather than pilot contamination, are often
the major limiting factors of the considered precoding schemes.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, Accepted for publication in the IEEE
  Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07183</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2017.2704112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07185</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Ties that Bind Networks: Weak Ties Facilitate the Emergence of
  Collective Memories</dc:title>
 <dc:creator>Momennejad, Ida</dc:creator>
 <dc:creator>Duker, Ajua</dc:creator>
 <dc:creator>Coman, Alin</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  From families to nations, what binds individuals in social groups is the
degree to which they share beliefs, norms, and memories. While local clusters
of communicating individuals can sustain shared memories and norms, communities
characterized by isolated cliques are susceptible to information fragmentation
and polarization dynamics. We employ experimental manipulations in lab-created
communities to investigate how the temporal dynamics of conversational
interactions can shape the formation of collective memories. We show that when
individuals that bridge cliques (i.e., weak ties) communicate early on in a
series of networked interactions, the community reaches higher mnemonic
convergence compared to when individuals first interact within cliques (i.e.,
strong ties). This, we find, is due to the tradeoffs between information
diversity and accumulated overlap over time. By using data calibrated models,
we extend these findings to a larger and more complex network structure. Our
approach offers a framework to analyze and design interventions in
communication networks that optimize shared remembering and diminish the
likelihood of information bubbles and polarization.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07199</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The High-Dimensional Geometry of Binary Neural Networks</dc:title>
 <dc:creator>Anderson, Alexander G.</dc:creator>
 <dc:creator>Berg, Cory P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent research has shown that one can train a neural network with binary
weights and activations at train time by augmenting the weights with a
high-precision continuous latent variable that accumulates small changes from
stochastic gradient descent. However, there is a dearth of theoretical analysis
to explain why we can effectively capture the features in our data with binary
weights and activations. Our main result is that the neural networks with
binary weights and activations trained using the method of Courbariaux, Hubara
et al. (2016) work because of the high-dimensional geometry of binary vectors.
In particular, the ideal continuous vectors that extract out features in the
intermediate representations of these BNNs are well-approximated by binary
vectors in the sense that dot products are approximately preserved. Compared to
previous research that demonstrated the viability of such BNNs, our work
explains why these BNNs work in terms of the HD geometry. Our theory serves as
a foundation for understanding not only BNNs but a variety of methods that seek
to compress traditional neural networks. Furthermore, a better understanding of
multilayer binary neural networks serves as a starting point for generalizing
BNNs to other neural network architectures such as recurrent neural networks.
</dc:description>
 <dc:description>Comment: 12 pages, 4 Figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07200</identifier>
 <datestamp>2017-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoothed and Average-case Approximation Ratios of Mechanisms: Beyond the
  Worst-case Analysis</dc:title>
 <dc:creator>Deng, Xiaotie</dc:creator>
 <dc:creator>Gao, Yansong</dc:creator>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The approximation ratio has become one of the dominant measures in mechanism
design problems. In light of analysis of algorithms, we define the
\emph{smoothed approximation ratio} to compare the performance of the optimal
mechanism and a truthful mechanism when the inputs are subject to random
perturbations of the worst-case inputs, and define the \emph{average-case
approximation ratio} to compare the performance of these two mechanisms when
the inputs follow a distribution. For the one-sided matching problem,
\citet{FFZ:14} show that, amongst all truthful mechanisms, \emph{random
priority} achieves the tight approximation ratio bound of $\Theta(\sqrt{n})$.
We prove that, despite of this worst-case bound, random priority has a
\emph{constant smoothed approximation ratio}. This is, to our limited
knowledge, the first work that asymptotically differentiates the smoothed
approximation ratio from the worst-case approximation ratio for mechanism
design problems. For the average-case, we show that our approximation ratio can
be improved to $1+e$. These results partially explain why random priority has
been successfully used in practice, although in the worst case the optimal
social welfare is $\Theta(\sqrt{n})$ times of what random priority achieves.
These results also pave the way for further studies of smoothed and
average-case analysis for approximate mechanism design problems, beyond the
worst-case analysis.
</dc:description>
 <dc:description>Comment: This paper is to appear in the 42nd International Symposium on
  Mathematical Foundations of Computer Science (MFCS 2017)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07202</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image
  Generation</dc:title>
 <dc:creator>Cai, Lei</dc:creator>
 <dc:creator>Gao, Hongyang</dc:creator>
 <dc:creator>Ji, Shuiwang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Variational auto-encoder (VAE) is a powerful unsupervised learning framework
for image generation. One drawback of VAE is that it generates blurry images
due to its Gaussianity assumption and thus L2 loss. To allow the generation of
high quality images by VAE, we increase the capacity of decoder network by
employing residual blocks and skip connections, which also enable efficient
optimization. To overcome the limitation of L2 loss, we propose to generate
images in a multi-stage manner from coarse to fine. In the simplest case, the
proposed multi-stage VAE divides the decoder into two components in which the
second component generates refined images based on the course images generated
by the first component. Since the second component is independent of the VAE
model, it can employ other loss functions beyond the L2 loss and different
model architectures. The proposed framework can be easily generalized to
contain more than two components. Experiment results on the MNIST and CelebA
datasets demonstrate that the proposed multi-stage VAE can generate sharper
images as compared to those from the original VAE.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07204</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Adversarial Training: Attacks and Defenses</dc:title>
 <dc:creator>Tram&#xe8;r, Florian</dc:creator>
 <dc:creator>Kurakin, Alexey</dc:creator>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>Boneh, Dan</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning models are vulnerable to adversarial examples, inputs
maliciously perturbed to mislead the model. These inputs transfer between
models, thus enabling black-box attacks against deployed models. Adversarial
training increases robustness to attacks by injecting adversarial examples into
training data.
  Surprisingly, we find that although adversarially trained models exhibit
strong robustness to some white-box attacks (i.e., with knowledge of the model
parameters), they remain highly vulnerable to transferred adversarial examples
crafted on other models. We show that the reason for this vulnerability is the
model's decision surface exhibiting sharp curvature in the vicinity of the data
points, thus hindering attacks based on first-order approximations of the
model's loss, but permitting black-box attacks that use adversarial examples
transferred from another model.
  We harness this observation in two ways: First, we propose a simple yet
powerful novel attack that first applies a small random perturbation to an
input, before finding the optimal perturbation under a first-order
approximation. Our attack outperforms prior &quot;single-step&quot; attacks on models
trained with or without adversarial training.
  Second, we propose Ensemble Adversarial Training, an extension of adversarial
training that additionally augments training data with perturbed inputs
transferred from a number of fixed pre-trained models. On MNIST and ImageNet,
ensemble adversarial training vastly improves robustness to black-box attacks.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07205</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine learning modeling for time series problem: Predicting flight
  ticket prices</dc:title>
 <dc:creator>Lu, Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning has been used in all kinds of fields. In this article, we
introduce how machine learning can be applied into time series problem.
Especially, we use the airline ticket prediction problem as our specific
problem. Airline companies use many different variables to determine the flight
ticket prices: indicator whether the travel is during the holidays, the number
of free seats in the plane etc. Some of the variables are observed, but some of
them are hidden. Based on the data over a 103 day period, we trained our
models, getting the best model - which is AdaBoost-Decision Tree
Classification. This algorithm has best performance over the observed 8 routes
which has 61.35$\%$ better performance than the random purchase strategy, and
relatively small variance over these routes. And we also considered the
situation that we cannot get too much historical datas for some routes (for
example the route is new and does not have historical data) or we do not want
to train historical data to predict to buy or wait quickly, in which problem,
we used HMM Sequence Classification based AdaBoost-Decision Tree Classification
to perform our prediction on 12 new routes. Finally, we got 31.71$\%$ better
performance than the random purchase strategy.
</dc:description>
 <dc:description>Comment: 17 pages, 19 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07206</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Real World Human Parsing: Multiple-Human Parsing in the Wild</dc:title>
 <dc:creator>Li, Jianshu</dc:creator>
 <dc:creator>Zhao, Jian</dc:creator>
 <dc:creator>Wei, Yunchao</dc:creator>
 <dc:creator>Lang, Congyan</dc:creator>
 <dc:creator>Li, Yidong</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The recent progress of human parsing techniques has been largely driven by
the availability of rich data resources. In this work, we demonstrate some
critical discrepancies between the current benchmark datasets and the real
world human parsing scenarios. For instance, all the human parsing datasets
only contain one person per image, while usually multiple persons appear
simultaneously in a realistic scene. It is more practically demanded to
simultaneously parse multiple persons, which presents a greater challenge to
modern human parsing methods. Unfortunately, absence of relevant data resources
severely impedes the development of multiple-human parsing methods.
  To facilitate future human parsing research, we introduce the Multiple-Human
Parsing (MHP) dataset, which contains multiple persons in a real world scene
per single image. The MHP dataset contains various numbers of persons (from 2
to 16) per image with 18 semantic classes for each parsing annotation. Persons
appearing in the MHP images present sufficient variations in pose, occlusion
and interaction. To tackle the multiple-human parsing problem, we also propose
a novel Multiple-Human Parser (MH-Parser), which considers both the global
context and local cues for each person in the parsing process. The model is
demonstrated to outperform the naive &quot;detect-and-parse&quot; approach by a large
margin, which will serve as a solid baseline and help drive the future research
in real world human parsing.
</dc:description>
 <dc:description>Comment: The first two authors are with equal contribution</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07207</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Driver-in-the Loop Fuel Economic Control Strategy for Connected
  Vehicles in Urban Roads</dc:title>
 <dc:creator>HomChaudhuri, Baisravan</dc:creator>
 <dc:creator>Pisu, Pierluigi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, we focus on developing driver-in-the loop fuel economic
control strategy for multiple connected vehicles. The control strategy is
considered to work in a driver assistance framework where the controller gives
command to a driver to follow while considering the ability of the driver in
following control commands. Our proposed method uses vehicle-to-vehicle (V2V)
communication, exploits traffic lights' Signal Phase and Timing (SPAT)
information, models driver error injection with Markov chain, and employs
scenario tree based stochastic model predictive control to improve vehicle fuel
economy and traffic mobility. The proposed strategy is decentralized in nature
as every vehicle evaluates its own strategy using only local information.
Simulation results show the effect of consideration of driver error injection
when synthesizing fuel economic controllers in a driver assistance fashion.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07208</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PixColor: Pixel Recursive Colorization</dc:title>
 <dc:creator>Guadarrama, Sergio</dc:creator>
 <dc:creator>Dahl, Ryan</dc:creator>
 <dc:creator>Bieber, David</dc:creator>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Shlens, Jonathon</dc:creator>
 <dc:creator>Murphy, Kevin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel approach to automatically produce multiple colorized
versions of a grayscale image. Our method results from the observation that the
task of automated colorization is relatively easy given a low-resolution
version of the color image. We first train a conditional PixelCNN to generate a
low resolution color for a given grayscale image. Then, given the generated
low-resolution color image and the original grayscale image as inputs, we train
a second CNN to generate a high-resolution colorization of an image. We
demonstrate that our approach produces more diverse and plausible colorizations
than existing methods, as judged by human raters in a &quot;Visual Turing Test&quot;.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07210</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-temperature logistic regression based on the Tsallis divergence</dc:title>
 <dc:creator>Amid, Ehsan</dc:creator>
 <dc:creator>Warmuth, Manfred K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop a variant of multiclass logistic regression that achieves three
properties: i) We minimize a non-convex surrogate loss which makes the method
robust to outliers, ii) our method allows transitioning between non-convex and
convex losses by the choice of the parameters, iii) the surrogate loss is Bayes
consistent, even in the non-convex case. The algorithm has one weight vector
per class and the surrogate loss is a function of the linear activations (one
per class). The surrogate loss of an example with linear activation vector
$\mathbf{a}$ and class $c$ has the form $-\log_{t_1} \exp_{t_2} (a_c -
G_{t_2}(\mathbf{a}))$ where the two temperatures $t_1$ and $t_2$ &quot;temper&quot; the
$\log$ and $\exp$, respectively, and $G_{t_2}$ is a generalization of the
log-partition function. We motivate this loss using the Tsallis divergence. As
the temperature of the logarithm becomes smaller than the temperature of the
exponential, the surrogate loss becomes &quot;more quasi-convex&quot;. Various tunings of
the temperatures recover previous methods and tuning the degree of
non-convexity is crucial in the experiments. The choice $t_1&lt;1$ and $t_2&gt;1$
performs best experimentally. We explain this by showing that $t_1 &lt; 1$ caps
the surrogate loss and $t_2 &gt;1$ makes the predictive distribution have a heavy
tail.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07211</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum versus classical simultaneity in communication complexity</dc:title>
 <dc:creator>Gavinsky, Dmitry</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We present a bipartite partial function, whose communication complexity is
$O((\log n)^2)$ in the model of quantum simultaneous message passing and
$\tilde\Omega(\sqrt n)$ in the model of randomised simultaneous message
passing.
  In fact, our function has a poly-logarithmic protocol even in the
(restricted) model of quantum simultaneous message passing without shared
randomness, thus witnessing the possibility of qualitative advantage of this
model over randomised simultaneous message passing with shared randomness. This
can be interpreted as the strongest known $-$ as of today $-$ example of
&quot;super-classical&quot; capabilities of the weakest studied model of quantum
communication.
</dc:description>
 <dc:description>Comment: More detailed discussion (relational separations added to the
  summarising overview). The technical content has not been changed</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07212</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space Complexity of Fault Tolerant Register Emulations</dc:title>
 <dc:creator>Chockler, Gregory</dc:creator>
 <dc:creator>Spiegelman, Alexander</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>D.4.7</dc:subject>
 <dc:description>  Driven by the rising popularity of cloud storage, the costs associated with
implementing reliable storage services from a collection of fault-prone servers
have recently become an actively studied question. The well-known ABD result
shows that an f-tolerant register can be emulated using a collection of 2f + 1
fault-prone servers each storing a single read-modify-write object type, which
is known to be optimal. In this paper we generalize this bound: we investigate
the inherent space complexity of emulating reliable multi-writer registers as a
fucntion of the type of the base objects exposed by the underlying servers, the
number of writers to the emulated register, the number of available servers,
and the failure threshold. We establish a sharp separation between registers,
and both max-registers (the base object types assumed by ABD) and CAS in terms
of the resources (i.e., the number of base objects of the respective types)
required to support the emulation; we show that no such separation exists
between max-registers and CAS. Our main technical contribution is lower and
upper bounds on the resources required in case the underlying base objects are
fault-prone read/write registers. We show that the number of required registers
is directly proportional to the number of writers and inversely proportional to
the number of servers.
</dc:description>
 <dc:description>Comment: Conference version appears in Proceedings of PODC '17</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07213</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MTDeep: Boosting the Security of Deep Neural Nets Against Adversarial
  Attacks with Moving Target Defense</dc:title>
 <dc:creator>Sengupta, Sailik</dc:creator>
 <dc:creator>Chakraborti, Tathagata</dc:creator>
 <dc:creator>Kambhampati, Subbarao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Recent works on gradient-based attacks and universal perturbations can
adversarially modify images to bring down the accuracy of state-of-the-art
classification techniques based on deep neural networks to as low as 10\% on
popular datasets like MNIST and ImageNet. The design of general defense
strategies against a wide range of such attacks remains a challenging problem.
In this paper, we derive inspiration from recent advances in the fields of
cybersecurity and multi-agent systems and propose to use the concept of Moving
Target Defense (MTD) for increasing the robustness of a set of deep networks
against such adversarial attacks. To this end, we formalize and exploit the
notion of differential immunity of an ensemble of networks to specific attacks.
To classify an input image, a trained network is picked from this set of
networks by formulating the interaction between a Defender (who hosts the
classification networks) and their (Legitimate and Malicious) Users as a
repeated Bayesian Stackelberg Game (BSG). We empirically show that our
approach, MTDeep reduces misclassification on perturbed images for MNIST and
ImageNet datasets while maintaining high classification accuracy on legitimate
test images. Lastly, we demonstrate that our framework can be used in
conjunction with any existing defense mechanism to provide more resilience to
adversarial attacks than those defense mechanisms by themselves.
</dc:description>
 <dc:description>Comment: 9 page, 5 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07215</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Convergence and Stability of GANs</dc:title>
 <dc:creator>Kodali, Naveen</dc:creator>
 <dc:creator>Abernethy, Jacob</dc:creator>
 <dc:creator>Hays, James</dc:creator>
 <dc:creator>Kira, Zsolt</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose studying GAN training dynamics as regret minimization, which is in
contrast to the popular view that there is consistent minimization of a
divergence between real and generated distributions. We analyze the convergence
of GAN training from this new point of view to understand why mode collapse
happens. We hypothesize the existence of undesirable local equilibria in this
non-convex game to be responsible for mode collapse. We observe that these
local equilibria often exhibit sharp gradients of the discriminator function
around some real data points. We demonstrate that these degenerate local
equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show
that DRAGAN enables faster training, achieves improved stability with fewer
mode collapses, and leads to generator networks with better modeling
performance across a variety of architectures and objective functions.
</dc:description>
 <dc:description>Comment: Analysis of convergence and mode collapse by studying GAN training
  process as regret minimization. Some new results</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07216</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Families of vectors without antipodal pairs</dc:title>
 <dc:creator>Frankl, Peter</dc:creator>
 <dc:creator>Kupavskii, Andrey</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Some Erd\H{o}s-Ko-Rado type extremal properties of families of vectors from
$\{-1,0,1\}^n$ are considered.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2018-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07219</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GAR: An efficient and scalable Graph-based Activity Regularization for
  semi-supervised learning</dc:title>
 <dc:creator>Kilinc, Ozsel</dc:creator>
 <dc:creator>Uysal, Ismail</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose a novel graph-based approach for semi-supervised
learning problems, which considers an adaptive adjacency of the examples
throughout the unsupervised portion of the training. Adjacency of the examples
is inferred using the predictions of a neural network model which is first
initialized by a supervised pretraining. These predictions are then updated
according to a novel unsupervised objective which regularizes another
adjacency, now linking the output nodes. Regularizing the adjacency of the
output nodes, inferred from the predictions of the network, creates an easier
optimization problem and ultimately provides that the predictions of the
network turn into the optimal embedding. Ultimately, the proposed framework
provides an effective and scalable graph-based solution which is natural to the
operational mechanism of deep neural networks. Our results show
state-of-the-art performance within semi-supervised learning with the highest
accuracies reported to date in the literature for SVHN and NORB datasets.
</dc:description>
 <dc:description>Comment: Submitted to 31st Conference on Neural Information Processing Systems
  (NIPS 2017)</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07222</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quadruplet Network with One-Shot Learning for Visual Tracking</dc:title>
 <dc:creator>Dong, Xingping</dc:creator>
 <dc:creator>Shen, Jianbing</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As a discriminative method of one-shot learning, Siamese deep network allows
recognizing an object from a single exemplar with the same class label.
However, it does not take the advantage of the underlying structure and
relationship among a multitude of instances since it only relies on pairs of
instances for training. In this paper, we propose a quadruplet deep network to
examine the potential connections among the training instances, aiming to
achieve a more powerful representation. We design four shared networks that
receive multi-tuple of instances as inputs and are connected by a novel loss
function consisting of pair-loss and triplet-loss. According to the similarity
metric, we select the most similar and the most dissimilar instances as the
positive and negative inputs of triplet loss from each multi-tuple. We show
that this scheme improves the training performance and convergence speed.
Furthermore, we introduce a new weighted pair loss for an additional
acceleration of the convergence. We demonstrate promising results for
model-free tracking-by-detection of objects from a single initial exemplar in
the Visual Object Tracking benchmark.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07224</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AIDE: An algorithm for measuring the accuracy of probabilistic inference
  algorithms</dc:title>
 <dc:creator>Cusumano-Towner, Marco F.</dc:creator>
 <dc:creator>Mansinghka, Vikash K.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Approximate probabilistic inference algorithms are central to many fields.
Examples include sequential Monte Carlo inference in robotics, variational
inference in machine learning, and Markov chain Monte Carlo inference in
statistics. A key problem faced by practitioners is measuring the accuracy of
an approximate inference algorithm on a specific data set. This paper
introduces the auxiliary inference divergence estimator (AIDE), an algorithm
for measuring the accuracy of approximate inference algorithms. AIDE is based
on the observation that inference algorithms can be treated as probabilistic
models and the random variables used within the inference algorithm can be
viewed as auxiliary variables. This view leads to a new estimator for the
symmetric KL divergence between the approximating distributions of two
inference algorithms. The paper illustrates application of AIDE to algorithms
for inference in regression, hidden Markov, and Dirichlet process mixture
models. The experiments show that AIDE captures the qualitative behavior of a
broad class of inference algorithms and can detect failure modes of inference
algorithms that are missed by standard heuristics.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07226</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RankPL: A Qualitative Probabilistic Programming Language</dc:title>
 <dc:creator>Rienstra, Tjitze</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In this paper we introduce RankPL, a modeling language that can be thought of
as a qualitative variant of a probabilistic programming language with a
semantics based on Spohn's ranking theory. Broadly speaking, RankPL can be used
to represent and reason about processes that exhibit uncertainty expressible by
distinguishing &quot;normal&quot; from&quot; surprising&quot; events. RankPL allows (iterated)
revision of rankings over alternative program states and supports various types
of reasoning, including abduction and causal inference. We present the
language, its denotational semantics, and a number of practical examples. We
also discuss an implementation of RankPL that is available for download.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07228</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Verified Algorithm Enumerating Event Structures</dc:title>
 <dc:creator>Bowles, Juliana</dc:creator>
 <dc:creator>Caminati, Marco B.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  An event structure is a mathematical abstraction modeling concepts as
causality, conflict and concurrency between events. While many other
mathematical structures, including groups, topological spaces, rings, abound
with algorithms and formulas to generate, enumerate and count particular sets
of their members, no algorithm or formulas are known to generate or count all
the possible event structures over a finite set of events. We present an
algorithm to generate such a family, along with a functional implementation
verified using Isabelle/HOL. As byproducts, we obtain a verified enumeration of
all possible preorders and partial orders. While the integer sequences counting
preorders and partial orders are already listed on OEIS (On-line Encyclopedia
of Integer Sequences), the one counting event structures is not. We therefore
used our algorithm to submit a formally verified addition, which has been
successfully reviewed and is now part of the OEIS.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07231</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adapting Low-Cost Platforms for Robotics Research</dc:title>
 <dc:creator>Karimpanal, Thommen George</dc:creator>
 <dc:creator>Chamanbaz, Mohammadreza</dc:creator>
 <dc:creator>Li, Wenzheng</dc:creator>
 <dc:creator>Jeruzalski, Timothy</dc:creator>
 <dc:creator>Gupta, Abhishek</dc:creator>
 <dc:creator>Wilhelm, Erik</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Validation of robotics theory on real-world hardware platforms is important
to prove the practical feasibility of algorithms. This paper discusses some of
the lessons learned while adapting the EvoBot, a low-cost robotics platform
that we designed and prototyped, for research in diverse areas in robotics. The
EvoBot platform was designed to be a low cost, open source, general purpose
robotics platform intended to enable testing and validation of algorithms from
a wide variety of sub-fields of robotics. Throughout the paper, we outline and
discuss some common failures, practical limitations and inconsistencies between
theory and practice that one may encounter while adapting such low-cost
platforms for robotics research. We demonstrate these aspects through four
representative common robotics tasks- localization, real-time control, swarm
consensus and path planning applications, performed using the EvoBots. We also
propose some potential solutions to the encountered problems and try to
generalize them.
</dc:description>
 <dc:description>Comment: FinE-r@IROS, 2015, 7 pages, 5 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07231</dc:identifier>
 <dc:identifier>FinE-R@IROS, volume 1484 of CEUR Workshop Proceedings, page 16-26.
  CEUR-WS.org, (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07237</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coexistence of RF-powered IoT and a Primary Wireless Network with
  Secrecy Guard Zones</dc:title>
 <dc:creator>Kishk, Mustafa A.</dc:creator>
 <dc:creator>Dhillon, Harpreet S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the secrecy performance of a wireless network (primary
network) overlaid with an ambient RF energy harvesting IoT network (secondary
network). The nodes in the secondary network are assumed to be solely powered
by ambient RF energy harvested from the transmissions of the primary network.
We assume that the secondary nodes can eavesdrop on the primary transmissions
due to which the primary network uses secrecy guard zones. The primary
transmitter goes silent if any secondary receiver is detected within its guard
zone. Using tools from stochastic geometry, we derive the probability of
successful connection of the primary network as well as the probability of
secure communication. Two conditions must be jointly satisfied in order to
ensure successful connection: (i) the SINR at the primary receiver is above a
predefined threshold, and (ii) the primary transmitter is not silent. In order
to ensure secure communication, the SINR value at each of the secondary nodes
should be less than a predefined threshold. Clearly, when more secondary nodes
are deployed, more primary transmitters will remain silent for a given guard
zone radius, thus impacting the amount of energy harvested by the secondary
network. Our results concretely show the existence of an optimal deployment
density for the secondary network that maximizes the density of nodes that are
able to harvest sufficient amount of energy. Furthermore, we show the
dependence of this optimal deployment density on the guard zone radius of the
primary network. In addition, we show that the optimal guard zone radius
selected by the primary network is a function of the deployment density of the
secondary network. This interesting coupling between the two networks is
studied using tools from game theory. Overall, this work is one of the few
concrete works that symbiotically merge tools from stochastic geometry and game
theory.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07238</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Scene Parsing with Perspective Understanding in the Loop</dc:title>
 <dc:creator>Kong, Shu</dc:creator>
 <dc:creator>Fowlkes, Charless</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Objects may appear at arbitrary scales in perspective images of a scene,
posing a challenge for recognition systems that process images at a fixed
resolution. We propose a depth-aware gating module that adaptively selects the
pooling field size in a convolutional network architecture according to the
object scale (inversely proportional to the depth) so that small details are
preserved for distant objects while larger receptive fields are used for those
nearby. The depth gating signal is provided by stereo disparity or estimated
directly from monocular input. We integrate this depth-aware gating into a
recurrent convolutional neural network to perform semantic segmentation. Our
recurrent module iteratively refines the segmentation results, leveraging the
depth and semantic predictions from the previous iterations.
  Through extensive experiments on four popular large-scale RGB-D datasets, we
demonstrate this approach achieves competitive semantic segmentation
performance with a model which is substantially more compact. We carry out
extensive analysis of this architecture including variants that operate on
monocular RGB but use depth as side-information during training, unsupervised
gating as a generic attentional mechanism, and multi-resolution gating. We find
that gated pooling for joint semantic segmentation and depth yields
state-of-the-art results for quantitative monocular depth estimation.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07241</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion-based neuromodulation can eliminate catastrophic forgetting in
  simple neural networks</dc:title>
 <dc:creator>Velez, Roby</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A long-term goal of AI is to produce agents that can learn a diversity of
skills throughout their lifetimes and continuously improve those skills via
experience. A longstanding obstacle towards that goal is catastrophic
forgetting, which is when learning new information erases previously learned
information. Catastrophic forgetting occurs in artificial neural networks
(ANNs), which have fueled most recent advances in AI. A recent paper proposed
that catastrophic forgetting in ANNs can be reduced by promoting modularity,
which can limit forgetting by isolating task information to specific clusters
of nodes and connections (functional modules). While the prior work did show
that modular ANNs suffered less from catastrophic forgetting, it was not able
to produce ANNs that possessed task-specific functional modules, thereby
leaving the main theory regarding modularity and forgetting untested. We
introduce diffusion-based neuromodulation, which simulates the release of
diffusing, neuromodulatory chemicals within an ANN that can modulate (i.e. up
or down regulate) learning in a spatial region. On the simple diagnostic
problem from the prior work, diffusion-based neuromodulation 1) induces
task-specific learning in groups of nodes and connections (task-specific
localized learning), which 2) produces functional modules for each subtask, and
3) yields higher performance by eliminating catastrophic forgetting. Overall,
our results suggest that diffusion-based neuromodulation promotes task-specific
localized learning and functional modularity, which can help solve the
challenging, but important problem of catastrophic forgetting.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07249</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-end Planning of Fixed Millimeter-Wave Networks</dc:title>
 <dc:creator>Danford, Tim</dc:creator>
 <dc:creator>Filiz, Onur</dc:creator>
 <dc:creator>Huang, Jing</dc:creator>
 <dc:creator>Karrer, Brian</dc:creator>
 <dc:creator>Paluri, Manohar</dc:creator>
 <dc:creator>Pang, Guan</dc:creator>
 <dc:creator>Ponnampalam, Vish</dc:creator>
 <dc:creator>Stier-Moses, Nicolas</dc:creator>
 <dc:creator>Tezel, Birce</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This article discusses a framework to support the design and end-to-end
planning of fixed millimeter-wave networks. Compared to traditional techniques,
the framework allows an organization to quickly plan a deployment in a
cost-effective way. We start by using LiDAR data---basically, a 3D point cloud
captured from a city---to estimate potential sites to deploy antennas and
whether there is line-of-sight between them. With that data on hand, we use
combinatorial optimization techniques to determine the optimal set of locations
and how they should communicate with each other, to satisfy engineering (e.g.,
latency, polarity), design (e.g., reliability) and financial (e.g., total cost
of operation) constraints. The primary goal is to connect as many people as
possible to the network. Our methodology can be used for strategic planning
when an organization is in the process of deciding whether to adopt a
millimeter-wave technology or choosing between locations, or for operational
planning when conducting a detailed design of the actual network to be deployed
in a selected location.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07250</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speedup from a different parametrization within the Neural Network
  algorithm</dc:title>
 <dc:creator>Zimmer, Michael F.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:description>  A different parametrization of the hyperplanes is used in the neural network
algorithm. As demonstrated on several autoencoder examples it significantly
outperforms the usual parametrization, reaching lower training error values
with only a fraction of the number of epochs. It's argued that it makes it
easier to understand and initialize the parameters.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07251</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling spatial social complex networks for dynamical processes</dc:title>
 <dc:creator>Wickramasinghe, Shandeepa</dc:creator>
 <dc:creator>Onyerikwu, Onyekachukwu</dc:creator>
 <dc:creator>Sun, Jie</dc:creator>
 <dc:creator>ben-Avraham, Daniel</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  The study of social networks --- where people are located, geographically,
and how they might be connected to one another --- is a current hot topic of
interest, because of its immediate relevance to important applications, from
devising efficient immunization techniques for the arrest of epidemics, to the
design of better transportation and city planning paradigms, to the
understanding of how rumors and opinions spread and take shape over time. We
develop a spatial social complex network (SSCN) model that captures not only
essential connectivity features of real-life social networks, including a
heavy-tailed degree distribution and high clustering, but also the spatial
location of individuals, reproducing Zipf's law for the distribution of city
populations as well as other observed hallmarks. We then simulate Milgram's
Small-World experiment on our SSCN model, obtaining good qualitative agreement
with the known results and shedding light on the role played by various network
attributes and the strategies used by the players in the game. This
demonstrates the potential of the SSCN model for the simulation and study of
the many social processes mentioned above, where both connectivity and
geography play a role in the dynamics.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07252</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SVM via Saddle Point Optimization: New Bounds and Distributed Algorithms</dc:title>
 <dc:creator>Jin, Yifei</dc:creator>
 <dc:creator>Huang, Lingxiao</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Support Vector Machine is one of the most classical approaches for
classification and regression. Despite being studied for decades, obtaining
practical algorithms for SVM is still an active research problem in machine
learning. In this paper, we propose a new perspective for SVM via saddle point
optimization. We provide an algorithm which achieves
$(1-\epsilon)$-approximations with running time $\tilde{O}(nd+n\sqrt{d /
\epsilon})$ for both separable (hard margin SVM) and non-separable cases
($\nu$-SVM ), where $n$ is the number of points and $d$ is the dimensionality.
To the best of our knowledge, the current best algorithm for hard margin SVM
achieved by Gilbert algorithm~\cite{gartner2009coresets} requires $O(nd /
\epsilon )$ time. Our algorithm improves the running time by a factor of
$\sqrt{d}/\sqrt{\epsilon}$. For $\nu$-SVM, besides the well known quadratic
programming approach which requires $\Omega(n^2 d)$
time~\cite{joachims1998making,platt199912}, no better algorithm is known. In
the paper, we provide the first nearly linear time algorithm for $\nu$-SVM. We
also consider the distributed settings and provide distributed algorithms with
low communication cost via saddle point optimization. Our algorithms require
$\tilde{O}(k(d +\sqrt{d/\epsilon}))$ communication cost where $k$ is the number
of clients, almost matching the theoretical lower bound.
</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07254</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BRPL: Backpressure RPL for High-throughput and Mobile IoTs</dc:title>
 <dc:creator>Tahir, Yad</dc:creator>
 <dc:creator>Yang, Shusen</dc:creator>
 <dc:creator>McCann, Julie</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  RPL, an IPv6 routing protocol for Low power Lossy Networks (LLNs), is
considered to be the de facto routing standard for the Internet of Things
(IoT). However, more and more experimental results demonstrate that RPL
performs poorly when it comes to throughput and adaptability to network
dynamics. This significantly limits the application of RPL in many practical
IoT scenarios, such as an LLN with high-speed sensor data streams and mobile
sensing devices. To address this issue, we develop BRPL, an extension of RPL,
providing a practical approach that allows users to smoothly combine any RPL
Object Function (OF) with backpressure routing. BRPL uses two novel algorithms,
QuickTheta and QuickBeta, to support time-varying data traffic loads and node
mobility respectively. We implement BRPL on Contiki OS, an open-source
operating system for the Internet of Things. We conduct an extensive evaluation
using both real-world experiments based on the FIT IoT-LAB testbed and
large-scale simulations using Cooja over 18 virtual servers on the Cloud. The
evaluation results demonstrate that BRPL not only is fully backward compatible
with RPL (i.e. devices running RPL and BRPL can work together seamlessly), but
also significantly improves network throughput and adaptability to changes in
network topologies and data traffic loads. The observed packet loss reduction
in mobile networks is, at a minimum, 60% and up to 1000% can be seen in extreme
cases.
</dc:description>
 <dc:description>Comment: 14 pages, to appear in IEEE Transactions on Mobile Computing, 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07256</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Feature Nonlinearities with Non-Convex Regularized Binned
  Regression</dc:title>
 <dc:creator>Oymak, Samet</dc:creator>
 <dc:creator>Mahdavi, Mehrdad</dc:creator>
 <dc:creator>Chen, Jiasi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For various applications, the relations between the dependent and independent
variables are highly nonlinear. Consequently, for large scale complex problems,
neural networks and regression trees are commonly preferred over linear models
such as Lasso. This work proposes learning the feature nonlinearities by
binning feature values and finding the best fit in each quantile using
non-convex regularized linear regression. The algorithm first captures the
dependence between neighboring quantiles by enforcing smoothness via
piecewise-constant/linear approximation and then selects a sparse subset of
good features. We prove that the proposed algorithm is statistically and
computationally efficient. In particular, it achieves linear rate of
convergence while requiring near-minimal number of samples. Evaluations on
synthetic and real datasets demonstrate that algorithm is competitive with
current state-of-the-art and accurately learns feature nonlinearities. Finally,
we explore an interesting connection between the binning stage of our algorithm
and sparse Johnson-Lindenstrauss matrices.
</dc:description>
 <dc:description>Comment: 22 pages, 7 figures</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07258</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PrivMin: Differentially Private MinHash for Jaccard Similarity
  Computation</dc:title>
 <dc:creator>Yan, Ziqi</dc:creator>
 <dc:creator>Liu, Jiqiang</dc:creator>
 <dc:creator>Li, Gang</dc:creator>
 <dc:creator>Han, Zhen</dc:creator>
 <dc:creator>Qiu, Shuo</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In many industrial applications of big data, the Jaccard Similarity
Computation has been widely used to measure the distance between two profiles
or sets respectively owned by two users. Yet, one semi-honest user with
unpredictable knowledge may also deduce the private or sensitive information
(e.g., the existence of a single element in the original sets) of the other
user via the shared similarity. In this paper, we aim at solving the privacy
issues in Jaccard similarity computation with strict differential privacy
guarantees. To achieve this, we first define the Conditional $\epsilon$-DPSO, a
relaxed differential privacy definition regarding set operations, and prove
that the MinHash-based Jaccard Similarity Computation (MH-JSC) satisfies this
definition. Then for achieving strict differential privacy in MH-JSC, we
propose the PrivMin algorithm, which consists of two private operations: 1) the
Private MinHash Value Generation that works by introducing the Exponential
noise to the generation of MinHash signature. 2) the Randomized MinHashing
Steps Selection that works by adopting Randomized Response technique to
privately select several steps within the MinHashing phase that are deployed
with the Exponential mechanism. Experiments on real datasets demonstrate that
the proposed PrivMin algorithm can successfully retain the utility of the
computed similarity while preserving privacy.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures, 4 tables</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07261</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Recursive Gradient Algorithm for Nonconvex Optimization</dc:title>
 <dc:creator>Nguyen, Lam M.</dc:creator>
 <dc:creator>Liu, Jie</dc:creator>
 <dc:creator>Scheinberg, Katya</dc:creator>
 <dc:creator>Tak&#xe1;&#x10d;, Martin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we study and analyze the mini-batch version of StochAstic
Recursive grAdient algoritHm (SARAH), a method employing the stochastic
recursive gradient, for solving empirical loss minimization for the case of
nonconvex losses. We provide a sublinear convergence rate (to stationary
points) for general nonconvex functions and a linear convergence rate for
gradient dominated functions, both of which have some advantages compared to
other modern stochastic gradient algorithms for nonconvex losses.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07262</identifier>
 <datestamp>2018-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batch Reinforcement Learning on the Industrial Benchmark: First
  Experiences</dc:title>
 <dc:creator>Hein, Daniel</dc:creator>
 <dc:creator>Udluft, Steffen</dc:creator>
 <dc:creator>Tokic, Michel</dc:creator>
 <dc:creator>Hentschel, Alexander</dc:creator>
 <dc:creator>Runkler, Thomas A.</dc:creator>
 <dc:creator>Sterzing, Volkmar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The Particle Swarm Optimization Policy (PSO-P) has been recently introduced
and proven to produce remarkable results on interacting with academic
reinforcement learning benchmarks in an off-policy, batch-based setting. To
further investigate the properties and feasibility on real-world applications,
this paper investigates PSO-P on the so-called Industrial Benchmark (IB), a
novel reinforcement learning (RL) benchmark that aims at being realistic by
including a variety of aspects found in industrial applications, like
continuous state and action spaces, a high dimensional, partially observable
state space, delayed effects, and complex stochasticity. The experimental
results of PSO-P on IB are compared to results of closed-form control policies
derived from the model-based Recurrent Control Neural Network (RCNN) and the
model-free Neural Fitted Q-Iteration (NFQ). Experiments show that PSO-P is not
only of interest for academic benchmarks, but also for real-world industrial
applications, since it also yielded the best performing policy in our IB
setting. Compared to other well established RL techniques, PSO-P produced
outstanding results in performance and robustness, requiring only a relatively
low amount of effort in finding adequate parameters or making complex design
decisions.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-07-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07262</dc:identifier>
 <dc:identifier>2017 International Joint Conference on Neural Networks (IJCNN),
  Anchorage, AK, 2017, pp. 4214-4221</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN.2017.7966389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07263</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection
  Methods</dc:title>
 <dc:creator>Carlini, Nicholas</dc:creator>
 <dc:creator>Wagner, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Neural networks are known to be vulnerable to adversarial examples: inputs
that are close to natural inputs but classified incorrectly. In order to better
understand the space of adversarial examples, we survey ten recent proposals
that are designed for detection and compare their efficacy. We show that all
can be defeated by constructing new loss functions. We conclude that
adversarial examples are significantly harder to detect than previously
appreciated, and the properties believed to be intrinsic to adversarial
examples are in fact not. Finally, we propose several simple guidelines for
evaluating future proposed defenses.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-11-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07267</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search Engine Guided Non-Parametric Neural Machine Translation</dc:title>
 <dc:creator>Gu, Jiatao</dc:creator>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Li, Victor O. K.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we extend an attention-based neural machine translation (NMT)
model by allowing it to access an entire training set of parallel sentence
pairs even after training. The proposed approach consists of two stages. In the
first stage--retrieval stage--, an off-the-shelf, black-box search engine is
used to retrieve a small subset of sentence pairs from a training set given a
source sentence. These pairs are further filtered based on a fuzzy matching
score based on edit distance. In the second stage--translation stage--, a novel
translation model, called translation memory enhanced NMT (TM-NMT), seamlessly
uses both the source sentence and a set of retrieved sentence pairs to perform
the translation. Empirical evaluation on three language pairs (En-Fr, En-De,
and En-Es) shows that the proposed approach significantly outperforms the
baseline approach and the improvement is more significant when more relevant
sentence pairs were retrieved.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07269</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Factor Policies and Action-Value Functions: Factored Action
  Space Representations for Deep Reinforcement learning</dc:title>
 <dc:creator>Sharma, Sahil</dc:creator>
 <dc:creator>Suresh, Aravind</dc:creator>
 <dc:creator>Ramesh, Rahul</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep Reinforcement Learning (DRL) methods have performed well in an
increasing numbering of high-dimensional visual decision making domains. Among
all such visual decision making problems, those with discrete action spaces
often tend to have underlying compositional structure in the said action space.
Such action spaces often contain actions such as go left, go up as well as go
diagonally up and left (which is a composition of the former two actions). The
representations of control policies in such domains have traditionally been
modeled without exploiting this inherent compositional structure in the action
spaces. We propose a new learning paradigm, Factored Action space
Representations (FAR) wherein we decompose a control policy learned using a
Deep Reinforcement Learning Algorithm into independent components, analogous to
decomposing a vector in terms of some orthogonal basis vectors. This
architectural modification of the control policy representation allows the
agent to learn about multiple actions simultaneously, while executing only one
of them. We demonstrate that FAR yields considerable improvements on top of two
DRL algorithms in Atari 2600: FARA3C outperforms A3C (Asynchronous Advantage
Actor Critic) in 9 out of 14 tasks and FARAQL outperforms AQL (Asynchronous
n-step Q-Learning) in 9 out of 13 tasks.
</dc:description>
 <dc:description>Comment: 11 pages + 7 pages appendix</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07272</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Linear Phase-Shifting of Haar Wavelets for Run-Time All-Frequency
  Lighting</dc:title>
 <dc:creator>Alnasser, Mais</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focuses on real-time all-frequency image-based rendering using an
innovative solution for run-time computation of light transport. The approach
is based on new results derived for non-linear phase shifting in the Haar
wavelet domain. Although image-based methods for real-time rendering of dynamic
glossy objects have been proposed, they do not truly scale to all possible
frequencies and high sampling rates without trading storage, glossiness, or
computational time, while varying both lighting and viewpoint. This is due to
the fact that current approaches are limited to precomputed radiance transfer
(PRT), which is prohibitively expensive in terms of memory requirements and
real-time rendering when both varying light and viewpoint changes are required
together with high sampling rates for high frequency lighting of glossy
material. On the other hand, current methods cannot handle object rotation,
which is one of the paramount issues for all PRT methods using wavelets. This
latter problem arises because the precomputed data are defined in a global
coordinate system and encoded in the wavelet domain, while the object is
rotated in a local coordinate system. At the root of all the above problems is
the lack of efficient run-time solution to the nontrivial problem of rotating
wavelets (a non-linear phase-shift), which we solve in this paper.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07273</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Responsive Action-based Video Synthesis</dc:title>
 <dc:creator>Ilisescu, Corneliu</dc:creator>
 <dc:creator>Kanaci, Halil Aytac</dc:creator>
 <dc:creator>Romagnoli, Matteo</dc:creator>
 <dc:creator>Campbell, Neill D. F.</dc:creator>
 <dc:creator>Brostow, Gabriel J.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  We propose technology to enable a new medium of expression, where video
elements can be looped, merged, and triggered, interactively. Like audio, video
is easy to sample from the real world but hard to segment into clean reusable
elements. Reusing a video clip means non-linear editing and compositing with
novel footage. The new context dictates how carefully a clip must be prepared,
so our end-to-end approach enables previewing and easy iteration.
  We convert static-camera videos into loopable sequences, synthesizing them in
response to simple end-user requests. This is hard because a) users want
essentially semantic-level control over the synthesized video content, and b)
automatic loop-finding is brittle and leaves users limited opportunity to work
through problems. We propose a human-in-the-loop system where adding effort
gives the user progressively more creative control. Artists help us evaluate
how our trigger interfaces can be used for authoring of videos and
video-performances.
</dc:description>
 <dc:description>Comment: 10 pages, 12 figures, 1 table, accepted and published in Proceedings
  of the 2017 CHI Conference on Human Factors in Computing Systems</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07273</dc:identifier>
 <dc:identifier>doi:10.1145/3025453.3025880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07275</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polar Coding for Parallel Gaussian Channel</dc:title>
 <dc:creator>Tse, David</dc:creator>
 <dc:creator>Li, Bin</dc:creator>
 <dc:creator>Chen, Kai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a Polar coding scheme for parallel Gaussian
channels. The encoder knows the sum rate of the parallel channels but does not
know the rate of any channel. By using the nesting property of Polar code, we
design a coding/decoding scheme to achieve the sum rates.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07278</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Belief Updating of Spatiotemporal Seizure Dynamics</dc:title>
 <dc:creator>Cooray, Gerald K</dc:creator>
 <dc:creator>Rosch, Richard</dc:creator>
 <dc:creator>Baldeweg, Torsten</dc:creator>
 <dc:creator>Lemieux, Louis</dc:creator>
 <dc:creator>Friston, Karl</dc:creator>
 <dc:creator>Sengupta, Biswa</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Epileptic seizure activity shows complicated dynamics in both space and time.
To understand the evolution and propagation of seizures spatially extended sets
of data need to be analysed. We have previously described an efficient
filtering scheme using variational Laplace that can be used in the Dynamic
Causal Modelling (DCM) framework [Friston, 2003] to estimate the temporal
dynamics of seizures recorded using either invasive or non-invasive electrical
recordings (EEG/ECoG). Spatiotemporal dynamics are modelled using a partial
differential equation -- in contrast to the ordinary differential equation used
in our previous work on temporal estimation of seizure dynamics [Cooray, 2016].
We provide the requisite theoretical background for the method and test the
ensuing scheme on simulated seizure activity data and empirical invasive ECoG
data. The method provides a framework to assimilate the spatial and temporal
dynamics of seizure activity, an aspect of great physiological and clinical
importance.
</dc:description>
 <dc:description>Comment: ICML 2017 Time Series Workshop</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07278</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07279</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and simple algorithms for computing both $LCS_{k}$ and $LCS_{k+}$</dc:title>
 <dc:creator>Paveti&#x107;, Filip</dc:creator>
 <dc:creator>Katani&#x107;, Ivan</dc:creator>
 <dc:creator>Matula, Gustav</dc:creator>
 <dc:creator>&#x17d;u&#x17e;i&#x107;, Goran</dc:creator>
 <dc:creator>&#x160;iki&#x107;, Mile</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Longest Common Subsequence ($LCS$) deals with the problem of measuring
similarity of two strings. While this problem has been analyzed for decades,
the recent interest stems from a practical observation that considering single
characters is often too simplistic. Therefore, recent works introduce the
variants of $LCS$ based on shared substrings of length exactly or at least $k$
($LCS_{k}$ and $LCS_{k+}$ respectively). The main drawback of the
state-of-the-art algorithms for computing $LCS_{k}$ and $LCS_{k+}$ is that they
work well only in a limited setting: they either solve the average case well
while being suboptimal in the pathological situations or they achieve a good
worst-case performance, but fail to exploit the input data properties to speed
up the computation. Furthermore, these algorithms are based on non-trivial data
structures which is not ideal from a practitioner's point of view. We present a
single algorithm to compute both $LCS_{k}$ and $LCS_{k+}$ which outperforms the
state-of-the art algorithms in terms of runtime complexity and requires only
basic data structures. In addition, we describe an algorithm to reconstruct the
solution which offers significant improvement in terms of memory consumption.
Our empirical validation shows that we save around 1000x of memory on human
genome data.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07280</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Effect of Temperature on Amdahl Law in 3D Multicore Era</dc:title>
 <dc:creator>Yavits, Leonid</dc:creator>
 <dc:creator>Morad, Amir</dc:creator>
 <dc:creator>Ginosar, Ran</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  This work studies the influence of temperature on performance and scalability
of 3D Chip Multiprocessors (CMP) from Amdahl law perspective. We find that 3D
CMP may reach its thermal limit before reaching its maximum power. We show that
a high level of parallelism may lead to high peak temperatures even in small
scale 3D CMPs, thus limiting 3D CMP scalability and calling for different,
in-memory computing architectures.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07281</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cache Hierarchy Optimization</dc:title>
 <dc:creator>Yavits, Leonid</dc:creator>
 <dc:creator>Morad, Amir</dc:creator>
 <dc:creator>Ginosar, Ran</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Power consumption, off-chip memory bandwidth, chip area and Network on Chip
(NoC) capacity are among main chip resources limiting the scalability of Chip
Multiprocessors (CMP). A closed form analytical solution for optimizing the CMP
cache hierarchy and optimally allocating area among hierarchy levels under such
constrained resources is developed. The optimization framework is extended by
incorporating the impact of data sharing on cache miss rate. An analytical
model for cache access time as a function of cache size is proposed and
verified using CACTI simulation.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07282</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse Matrix Multiplication On An Associative Processor</dc:title>
 <dc:creator>Yavits, L.</dc:creator>
 <dc:creator>Morad, A.</dc:creator>
 <dc:creator>Ginosar, R.</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Sparse matrix multiplication is an important component of linear algebra
computations. Implementing sparse matrix multiplication on an associative
processor (AP) enables high level of parallelism, where a row of one matrix is
multiplied in parallel with the entire second matrix, and where the execution
time of vector dot product does not depend on the vector size. Four sparse
matrix multiplication algorithms are explored in this paper, combining AP and
baseline CPU processing to various levels. They are evaluated by simulation on
a large set of sparse matrices. The computational complexity of sparse matrix
multiplication on AP is shown to be an O(nnz) where nnz is the number of
nonzero elements. The AP is found to be especially efficient in binary sparse
matrix multiplication. AP outperforms conventional solutions in power
efficiency.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07284</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gaze Distribution Analysis and Saliency Prediction Across Age Groups</dc:title>
 <dc:creator>Krishna, Onkar</dc:creator>
 <dc:creator>Aizawa, Kiyoharu</dc:creator>
 <dc:creator>Helo, Andrea</dc:creator>
 <dc:creator>Pia, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Knowledge of the human visual system helps to develop better computational
models of visual attention. State-of-the-art models have been developed to
mimic the visual attention system of young adults that, however, largely ignore
the variations that occur with age. In this paper, we investigated how visual
scene processing changes with age and we propose an age-adapted framework that
helps to develop a computational model that can predict saliency across
different age groups. Our analysis uncovers how the explorativeness of an
observer varies with age, how well saliency maps of an age group agree with
fixation points of observers from the same or different age groups, and how age
influences the center bias. We analyzed the eye movement behavior of 82
observers belonging to four age groups while they explored visual scenes.
Explorativeness was quantified in terms of the entropy of a saliency map, and
area under the curve (AUC) metrics was used to quantify the agreement analysis
and the center bias. These results were used to develop age adapted saliency
models. Our results suggest that the proposed age-adapted saliency model
outperforms existing saliency models in predicting the regions of interest
across age groups.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07285</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality of orders one to three and beyond: characterization and
  evaluation complexity in constrained nonconvex optimization</dc:title>
 <dc:creator>Cartis, C.</dc:creator>
 <dc:creator>Gould, N. I. M.</dc:creator>
 <dc:creator>Toint, Ph. L.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>90C26, 90C46, 90C30</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Necessary conditions for high-order optimality in smooth nonlinear
constrained optimization are explored and their inherent intricacy discussed. A
two-phase minimization algorithm is proposed which can achieve approximate
first-, second- and third-order criticality and its evaluation complexity is
analyzed as a function of the choice (among existing methods) of an inner
algorithm for solving subproblems in each of the two phases. The relation
between high-order criticality and penalization techniques is finally
considered, showing that standard algorithmic approaches will fail if
approximate constrained high-order critical points are sought.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2018-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07286</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Evaluation of Optimal Radio Access Technology Selection
  Algorithms for LTE-WiFi Network</dc:title>
 <dc:creator>Roy, Arghyadip</dc:creator>
 <dc:creator>Chaporkar, Prasanna</dc:creator>
 <dc:creator>Karandikar, Abhay</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A Heterogeneous Network (HetNet) comprises of multiple Radio Access
Technologies (RATs) allowing a user to associate with a specific RAT and steer
to other RATs in a seamless manner. To cope up with the unprecedented growth of
data traffic, mobile data can be offloaded to Wireless Fidelity (WiFi) in a
Long Term Evolution (LTE) based HetNet. In this paper, an optimal RAT selection
problem is considered to maximize the total system throughput in an LTE-WiFi
system with offload capability. Another formulation is also developed where
maximizing the total system throughput is subject to a constraint on the voice
user blocking probability. It is proved that the optimal policies for the
association and offloading of voice/data users contain threshold structures.
Based on the threshold structures, we propose algorithms for the association
and offloading of users in LTE-WiFi HetNet. Simulation results are presented to
demonstrate the voice user blocking probability and the total system throughput
performance of the proposed algorithms in comparison to another benchmark
algorithm.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07289</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leaky Cauldron on the Dark Land: Understanding Memory Side-Channel
  Hazards in SGX</dc:title>
 <dc:creator>Wang, Wenhao</dc:creator>
 <dc:creator>Chen, Guoxing</dc:creator>
 <dc:creator>Pan, Xiaorui</dc:creator>
 <dc:creator>Zhang, Yinqian</dc:creator>
 <dc:creator>Wang, XiaoFeng</dc:creator>
 <dc:creator>Bindschaedler, Vincent</dc:creator>
 <dc:creator>Tang, Haixu</dc:creator>
 <dc:creator>Gunter, Carl A.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Side-channel risks of Intel's SGX have recently attracted great attention.
Under the spotlight is the newly discovered page-fault attack, in which an
OS-level adversary induces page faults to observe the page-level access
patterns of a protected process running in an SGX enclave. With almost all
proposed defense focusing on this attack, little is known about whether such
efforts indeed raise the bar for the adversary, whether a simple variation of
the attack renders all protection ineffective, not to mention an in-depth
understanding of other attack surfaces in the SGX system. In the paper, we
report the first step toward systematic analyses of side-channel threats that
SGX faces, focusing on the risks associated with its memory management. Our
research identifies 8 potential attack vectors, ranging from TLB to DRAM
modules. More importantly, we highlight the common misunderstandings about SGX
memory side channels, demonstrating that high frequent AEXs can be avoided when
recovering EdDSA secret key through a new page channel and fine-grained
monitoring of enclave programs (at the level of 64B) can be done through
combining both cache and cross-enclave DRAM channels. Our findings reveal the
gap between the ongoing security research on SGX and its side-channel
weaknesses, redefine the side-channel threat model for secure enclaves, and can
provoke a discussion on when to use such a system and how to use it securely.
</dc:description>
 <dc:description>Comment: Accepted to ACM CCS 2017</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07289</dc:identifier>
 <dc:identifier>doi:10.1145/3133956.3134038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07290</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Sparse Coding Using Optimized Linear Expansion of Thresholds</dc:title>
 <dc:creator>Mahapatra, Debabrata</dc:creator>
 <dc:creator>Mukherjee, Subhadip</dc:creator>
 <dc:creator>Seelamantula, Chandra Sekhar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We address the problem of reconstructing sparse signals from noisy and
compressive measurements using a feed-forward deep neural network (DNN) with an
architecture motivated by the iterative shrinkage-thresholding algorithm
(ISTA). We maintain the weights and biases of the network links as prescribed
by ISTA and model the nonlinear activation function using a linear expansion of
thresholds (LET), which has been very successful in image denoising and
deconvolution. The optimal set of coefficients of the parametrized activation
is learned over a training dataset containing measurement-sparse signal pairs,
corresponding to a fixed sensing matrix. For training, we develop an efficient
second-order algorithm, which requires only matrix-vector product computations
in every training epoch (Hessian-free optimization) and offers superior
convergence performance than gradient-descent optimization. Subsequently, we
derive an improved network architecture inspired by FISTA, a faster version of
ISTA, to achieve similar signal estimation performance with about 50% of the
number of layers. The resulting architecture turns out to be a deep residual
network, which has recently been shown to exhibit superior performance in
several visual recognition tasks. Numerical experiments demonstrate that the
proposed DNN architectures lead to 3 to 4 dB improvement in the reconstruction
signal-to-noise ratio (SNR), compared with the state-of-the-art sparse coding
algorithms.
</dc:description>
 <dc:description>Comment: Submission date: November 11, 2016. 19 pages; 9 figures</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07290</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07291</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Cell Discovery in mm-wave 5G Networks with Context Information</dc:title>
 <dc:creator>Filippini, Ilario</dc:creator>
 <dc:creator>Sciancalepore, Vincenzo</dc:creator>
 <dc:creator>Devoti, Francesco</dc:creator>
 <dc:creator>Capone, Antonio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The exploitation of mm-wave bands is one of the key-enabler for 5G mobile
radio networks. However, the introduction of mm-wave technologies in cellular
networks is not straightforward due to harsh propagation conditions that limit
the mm-wave access availability. Mm-wave technologies require high-gain antenna
systems to compensate for high path loss and limited power. As a consequence,
directional transmissions must be used for cell discovery and synchronization
processes: this can lead to a non-negligible access delay caused by the
exploration of the cell area with multiple transmissions along different
directions.
  The integration of mm-wave technologies and conventional wireless access
networks with the objective of speeding up the cell search process requires new
5G network architectural solutions. Such architectures introduce a functional
split between C-plane and U-plane, thereby guaranteeing the availability of a
reliable signaling channel through conventional wireless technologies that
provides the opportunity to collect useful context information from the network
edge.
  In this article, we leverage the context information related to user
positions to improve the directional cell discovery process. We investigate
fundamental trade-offs of this process and the effects of the context
information accuracy on the overall system performance. We also cope with
obstacle obstructions in the cell area and propose an approach based on a
geo-located context database where information gathered over time is stored to
guide future searches. Analytic models and numerical results are provided to
validate proposed strategies.
</dc:description>
 <dc:description>Comment: 14 pages, submitted to IEEE Transaction on Mobile Computing</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07300</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contract Design for Energy Demand Response</dc:title>
 <dc:creator>Meir, Reshef</dc:creator>
 <dc:creator>Ma, Hongyao</dc:creator>
 <dc:creator>Robu, Valentin</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Power companies such as Southern California Edison (SCE) uses Demand Response
(DR) contracts to incentivize consumers to reduce their power consumption
during periods when demand forecast exceeds supply. Current mechanisms in use
offer contracts to consumers independent of one another, do not take into
consideration consumers' heterogeneity in consumption profile or reliability,
and fail to achieve high participation.
  We introduce DR-VCG, a new DR mechanism that offers a flexible set of
contracts (which may include the standard SCE contracts) and uses VCG pricing.
We prove that DR-VCG elicits truthful bids, incentivizes honest preparation
efforts, enables efficient computation of allocation and prices. With simple
fixed-penalty contracts, the optimization goal of the mechanism is an upper
bound on probability that the reduction target is missed. Extensive simulations
show that compared to the current mechanism deployed in by SCE, the DR-VCG
mechanism achieves higher participation, increased reliability, and
significantly reduced total expenses.
</dc:description>
 <dc:description>Comment: full version of paper accepted to IJCAI'17</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07305</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-Triggered Algorithms for Leader-Follower Consensus of Networked
  Euler-Lagrange Agents</dc:title>
 <dc:creator>Liu, Qingchen</dc:creator>
 <dc:creator>Ye, Mengbin</dc:creator>
 <dc:creator>Qin, Jiahu</dc:creator>
 <dc:creator>Yu, Changbin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  This paper proposes three different distributed event-triggered control
algorithms to achieve leader-follower consensus for a network of Euler-Lagrange
agents. We firstly propose two model-independent algorithms for a subclass of
Euler-Lagrange agents without the vector of gravitational potential forces. By
model-independent, we mean that each agent can execute its algorithm with no
knowledge of the agent self-dynamics. A variable-gain algorithm is employed
when the sensing graph is undirected; algorithm parameters are selected in a
fully distributed manner with much greater flexibility compared to all previous
work concerning event-triggered consensus problems. When the sensing graph is
directed, a constant-gain algorithm is employed. The control gains must be
centrally designed to exceed several lower bounding inequalities which require
limited knowledge of bounds on the matrices describing the agent dynamics,
bounds on network topology information and bounds on the initial conditions.
When the Euler-Lagrange agents have dynamics which include the vector of
gravitational potential forces, an adaptive algorithm is proposed which
requires more information about the agent dynamics but can estimate uncertain
agent parameters.
  For each algorithm, a trigger function is proposed to govern the event update
times. At each event, the controller is updated, which ensures that the control
input is piecewise constant and saves energy resources. We analyse each
controllers and trigger function and exclude Zeno behaviour. Extensive
simulations show 1) the advantages of our proposed trigger function as compared
to those in existing literature, and 2) the effectiveness of our proposed
controllers.
</dc:description>
 <dc:description>Comment: Extended manuscript of journal submission, containing omitted proofs
  and simulations</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07310</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Quantum Monad on Relational Structures</dc:title>
 <dc:creator>Abramsky, Samson</dc:creator>
 <dc:creator>Barbosa, Rui Soares</dc:creator>
 <dc:creator>de Silva, Nadish</dc:creator>
 <dc:creator>Zapata, Octavio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Homomorphisms between relational structures play a central role in finite
model theory, constraint satisfaction and database theory. A central theme in
quantum computation is to show how quantum resources can be used to gain
advantage in information processing tasks. In particular, non-local games have
been used to exhibit quantum advantage in boolean constraint satisfaction, and
to obtain quantum versions of graph invariants such as the chromatic number. We
show how quantum strategies for homomorphism games between relational
structures can be viewed as Kleisli morphisms for a quantum monad on the
(classical) category of relational structures and homomorphisms. We show a
general connection between these notions and state-independent quantum
realizations of strong contextuality in the Abramsky-Brandenburger formulation
of contextuality. We use these results to exhibit a wide range of examples of
contextuality-powered quantum advantage, and to unify several apparently
diverse strands of previous work.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07311</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personalized Ranking for Context-Aware Venue Suggestion</dc:title>
 <dc:creator>Aliannejadi, Mohammad</dc:creator>
 <dc:creator>Mele, Ida</dc:creator>
 <dc:creator>Crestani, Fabio</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Making personalized and context-aware suggestions of venues to the users is
very crucial in venue recommendation. These suggestions are often based on
matching the venues' features with the users' preferences, which can be
collected from previously visited locations. In this paper we present a novel
user-modeling approach which relies on a set of scoring functions for making
personalized suggestions of venues based on venues content and reviews as well
as users context. Our experiments, conducted on the dataset of the TREC
Contextual Suggestion Track, prove that our methodology outperforms
state-of-the-art approaches by a significant margin.
</dc:description>
 <dc:description>Comment: The 32nd ACM SIGAPP Symposium On Applied Computing (SAC), Marrakech,
  Morocco, April 4-6, 2017</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07312</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bound On the Computational Complexity of Discounted Markov
  Decision Problems</dc:title>
 <dc:creator>Chen, Yichen</dc:creator>
 <dc:creator>Wang, Mengdi</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the computational complexity of the infinite-horizon
discounted-reward Markov Decision Problem (MDP) with a finite state space
$|\mathcal{S}|$ and a finite action space $|\mathcal{A}|$. We show that any
randomized algorithm needs a running time at least
$\Omega(|\mathcal{S}|^2|\mathcal{A}|)$ to compute an $\epsilon$-optimal policy
with high probability. We consider two variants of the MDP where the input is
given in specific data structures, including arrays of cumulative probabilities
and binary trees of transition probabilities. For these cases, we show that the
complexity lower bound reduces to $\Omega\left( \frac{|\mathcal{S}|
|\mathcal{A}|}{\epsilon} \right)$. These results reveal a surprising
observation that the computational complexity of the MDP depends on the data
structure of input.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07313</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formalization of the Process Algebra CCS in HOL4</dc:title>
 <dc:creator>Tian, Chun</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  An old formalization of the Process Algebra CCS (no value passing, with
explicit relabeling operator) on has been ported from HOL88 theorem prover to
HOL4 (Kananaskis-11 and later). Transitions between CCS processes are defined
by SOS (Structured Operational Semantics) inference rules, then all algebaric
laws (including the expansion theorem) were proved upon SOS transition rules.
  We have used HOL4's new co-inductive relation support to re-define strong and
weak bisimulation equivalances, and shows that the new definitions are
equivalent with old ones. Finally, there's decision procedure for automatic
detection of CCS transitions. The aim is to provide an up-to-date sound and
effective tool to support verification and reasoning about CCS, and to provide
a formal logic basis for further theoretical developments in Concurrency
Theory.
</dc:description>
 <dc:description>Comment: 26 pages</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07318</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalized Lambek Calculus in Higher Order Logic (HOL4)</dc:title>
 <dc:creator>Tian, Chun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.2.4, I.2.7</dc:subject>
 <dc:description>  In this project, a rather complete proof-theoretical formalization of Lambek
Calculus (non-associative with arbitrary extensions) has been ported from Coq
proof assistent to HOL4 theorem prover, with some improvements and new
theorems.
  Three deduction systems (Syntactic Calculus, Natural Deduction and Sequent
Calculus) of Lambek Calculus are defined with many related theorems proved. The
equivalance between these systems are formally proved. Finally, a formalization
of Sequent Calculus proofs (where Coq has built-in supports) has been designed
and implemented in HOL4. Some basic results including the sub-formula
properties of the so-called &quot;cut-free&quot; proofs are formally proved.
  This work can be considered as the preliminary work towards a language parser
based on category grammars which is not multimodal but still has ability to
support context-sensitive languages through customized extensions.
</dc:description>
 <dc:description>Comment: 37 pages</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07325</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Change Point Detection on Dynamic Social Networks</dc:title>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Chakrabarti, Aniket</dc:creator>
 <dc:creator>Sivakoff, David</dc:creator>
 <dc:creator>Parthasarathy, Srinivasan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A number of real world problems in many domains (e.g. sociology, biology,
political science and communication networks) can be modeled as dynamic
networks with nodes representing entities of interest and edges representing
interactions among the entities at different points in time. A common
representation for such models is the snapshot model - where a network is
defined at logical time-stamps. An important problem under this model is change
point detection. In this work we devise an effective and efficient
three-step-approach for detecting change points in dynamic networks under the
snapshot model. Our algorithm achieves up to 9X speedup over the
state-of-the-art while improving quality on both synthetic and real world
networks.
</dc:description>
 <dc:description>Comment: IJCAI'17</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07327</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Analysis of the Arrow Distributed Directory Protocol in General
  Networks</dc:title>
 <dc:creator>Ghodselahi, Abdolhamid</dc:creator>
 <dc:creator>Kuhn, Fabian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The Arrow protocol is a simple and elegant protocol to coordinate exclusive
access to a shared object in a network. The protocol solves the underlying
distributed queueing problem by using path reversal on a pre-computed spanning
tree (or any other tree topology simulated on top of the given network).
  It is known that the Arrow protocol solves the problem with a competitive
ratio of O(log D) on trees of diameter D. This implies a distributed queueing
algorithm with competitive ratio O(s*log D) for general networks with a
spanning tree of diameter D and stretch s. In this work we show that when
running the Arrow protocol on top of the well-known probabilistic tree
embedding of Fakcharoenphol, Rao, and Talwar [STOC 03], we obtain a randomized
distributed queueing algorithm with a competitive ratio of O(log n) even on
general network topologies. The result holds even if the queueing requests
occur in an arbitrarily dynamic and concurrent fashion and even if
communication is asynchronous. From a technical point of view, the main of the
paper shows that the competitive ratio of the Arrow protocol is constant on a
special family of tree topologies, known as hierarchically well separated
trees.
</dc:description>
 <dc:description>Comment: 31 pages, 3 figures</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07328</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forecasting Hands and Objects in Future Frames</dc:title>
 <dc:creator>Fan, Chenyou</dc:creator>
 <dc:creator>Lee, Jangwon</dc:creator>
 <dc:creator>Ryoo, Michael S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an approach to forecast future presence and location of
human hands and objects. Given an image frame, the goal is to predict what
objects will appear in the future frame (e.g., 5 seconds later) and where they
will be located at, even when they are not visible in the current frame. The
key idea is that (1) an intermediate representation of a convolutional object
recognition model abstracts scene information in its frame and that (2) we can
predict (i.e., regress) such representations corresponding to the future frames
based on that of the current frame. We design a new two-stream convolutional
neural network (CNN) architecture for videos by extending the state-of-the-art
convolutional object detection network, and present a new fully convolutional
regression network for predicting future scene representations. Our experiments
confirm that combining the regressed future representation with our detection
network allows reliable estimation of future hands and objects in videos. We
obtain much higher accuracy compared to the state-of-the-art future object
presence forecast method on a public dataset.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07329</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Contours: An Invariant Linking Image Flow with Salient Surface
  Organization</dc:title>
 <dc:creator>Kunsberg, Benjamin S.</dc:creator>
 <dc:creator>Zucker, Steven W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We exploit a key result from visual psychophysics -- that individuals
perceive shape qualitatively -- to develop a geometrical/topological invariant
(the Morse-Smale complex) relating image structure with surface structure.
Differences across individuals are minimal near certain configurations such as
ridges and boundaries, and it is these configurations that are often
represented in line drawings. In particular, we introduce a method for
inferring qualitative 3D shape from shading patterns that link the
shape-from-shading inference with shape-from-contour. For a given shape,
certain shading patches become &quot;line drawings&quot; in a well-defined limit. Under
this limit, and invariantly, these shading patterns provide a topological
description of the surface. We further show that, under this model, the
contours partition the surface into meaningful parts using the Morse-Smale
complex. Critical contours are the (perceptually) stable parts of this complex
and are invariant over a wide class of rendering models. Intuitively, our main
result shows that critical contours partition smooth surfaces into bumps and
valleys, in effect providing a scaffold on the image from which a full surface
can be interpolated.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07337</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Bidirectional Secure Communications under Perfect and
  Distributionally Ambiguous Eavesdropper's CSI</dc:title>
 <dc:creator>Li, Qiang</dc:creator>
 <dc:creator>Zhang, Ying</dc:creator>
 <dc:creator>Lin, Jingran</dc:creator>
 <dc:creator>Wu, Sissi Xiaoxiao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Consider a full-duplex (FD) bidirectional secure communication system, where
two communication nodes, named Alice and Bob, simultaneously transmit and
receive confidential information from each other, and an eavesdropper, named
Eve, overhears the transmissions. Our goal is to maximize the sum secrecy rate
(SSR) of the bidirectional transmissions by optimizing the transmit covariance
matrices at Alice and Bob. To tackle this SSR maximization (SSRM) problem, we
develop an alternating difference-of-concave (ADC) programming approach to
alternately optimize the transmit covariance matrices at Alice and Bob. We show
that the ADC iteration has a semi-closed-form beamforming solution, and is
guaranteed to converge to a stationary solution of the SSRM problem. Besides
the SSRM design, this paper also deals with a robust SSRM transmit design under
a moment-based random channel state information (CSI) model, where only some
roughly estimated first and second-order statistics of Eve's CSI are available,
but the exact distribution or other high-order statistics is not known. This
moment-based error model is new and different from the widely used
bounded-sphere error model and the Gaussian random error model. Under the
consider CSI error model, the robust SSRM is formulated as an outage
probability-constrained SSRM problem. By leveraging the Lagrangian duality
theory and DC programming, a tractable safe solution to the robust SSRM problem
is derived. The effectiveness and the robustness of the proposed designs are
demonstrated through simulations.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions Signal Procesing, 14 pages, 10 figures</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07337</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2709270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07338</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Effective Exact Algorithms for the Maximum Balanced Biclique
  Problem</dc:title>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Rossi, Andr&#xe9;</dc:creator>
 <dc:creator>Hao, Jin-Kao</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The Maximum Balanced Biclique Problem (MBBP) is a prominent model with
numerous applications. Yet, the problem is NP-hard and thus computationally
challenging. We propose novel ideas for designing effective exact algorithms
for MBBP. Firstly, we introduce an Upper Bound Propagation procedure to
pre-compute an upper bound involving each vertex. Then we extend an existing
branch-and-bound algorithm by integrating the pre-computed upper bounds. We
also present a set of new valid inequalities induced from the upper bounds to
tighten an existing mathematical formulation for MBBP. Lastly, we investigate
another exact algorithm scheme which enumerates a subset of balanced bicliques
based on our upper bounds. Experiments show that compared to existing
approaches, the proposed algorithms and formulations are more efficient in
solving a set of random graphs and large real-life instances.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07339</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining tabu search and graph reduction to solve the maximum balanced
  biclique problem</dc:title>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Hao, Jin-Kao</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The Maximum Balanced Biclique Problem is a well-known graph model with
relevant applications in diverse domains. This paper introduces a novel
algorithm, which combines an effective constraint-based tabu search procedure
and two dedicated graph reduction techniques. We verify the effectiveness of
the algorithm on 30 classical random benchmark graphs and 25 very large
real-life sparse graphs from the popular Koblenz Network Collection (KONECT).
The results show that the algorithm improves the best-known results (new lower
bounds) for 10 classical benchmarks and obtains the optimal solutions for 14
KONECT instances.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07340</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Phase-Shifting Separable Haar Wavelets and Applications</dc:title>
 <dc:creator>Alnasser, Mais</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a new approach for tackling the shift-invariance problem
in the discrete Haar domain, without trading off any of its desirable
properties, such as compression, separability, orthogonality, and symmetry. The
paper presents several key theoretical contributions. First, we derive closed
form expressions for phase shifting in the Haar domain both in partially
decimated and fully decimated transforms. Second, it is shown that the wavelet
coefficients of the shifted signal can be computed solely by using the
coefficients of the original transformed signal. Third, we derive closed-form
expressions for non-integer shifts, which have not been previously reported in
the literature. Fourth, we establish the complexity of the proposed phase
shifting approach using the derived analytic expressions. As an application
example of these results, we apply the new formulae to image rotation and
interpolation, and evaluate its performance against standard methods.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07343</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why You Should Charge Your Friends for Borrowing Your Stuff</dc:title>
 <dc:creator>Shin, Kijung</dc:creator>
 <dc:creator>Lee, Euiwoong</dc:creator>
 <dc:creator>Eswaran, Dhivya</dc:creator>
 <dc:creator>Procaccia, Ariel D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider goods that can be shared with k-hop neighbors (i.e., the set of
nodes within k hops from an owner) on a social network. We examine incentives
to buy such a good by devising game-theoretic models where each node decides
whether to buy the good or free ride. First, we find that social inefficiency,
specifically excessive purchase of the good, occurs in Nash equilibria. Second,
the social inefficiency decreases as k increases and thus a good can be shared
with more nodes. Third, and most importantly, the social inefficiency can also
be significantly reduced by charging free riders an access cost and paying it
to owners, leading to the conclusion that organizations and system designers
should impose such a cost. These findings are supported by our theoretical
analysis in terms of the price of anarchy and the price of stability; and by
simulations based on synthetic and real social networks.
</dc:description>
 <dc:description>Comment: to be published in 26th International Joint Conference on Artificial
  Intelligence (IJCAI-17)</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07347</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Sampling</dc:title>
 <dc:creator>Lu, Xiuyuan</dc:creator>
 <dc:creator>Van Roy, Benjamin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Thompson sampling has emerged as an effective heuristic for a broad range of
online decision problems. In its basic form, the algorithm requires computing
and sampling from a posterior distribution over models, which is tractable only
for simple special cases. This paper develops ensemble sampling, which aims to
approximate Thompson sampling while maintaining tractability even in the face
of complex models such as neural networks. Ensemble sampling dramatically
expands on the range of applications for which Thompson sampling is viable. We
establish a theoretical basis that supports the approach and present
computational results that offer further insight.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07347</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07349</identifier>
 <datestamp>2017-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\left( \beta, \varpi \right)$-stability for cross-validation and the
  choice of the number of folds</dc:title>
 <dc:creator>Xu, Ning</dc:creator>
 <dc:creator>Hong, Jian</dc:creator>
 <dc:creator>Fisher, Timothy C. G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this paper, we introduce a new concept of stability for cross-validation,
called the $\left( \beta, \varpi \right)$-stability, and use it as a new
perspective to build the general theory for cross-validation. The $\left(
\beta, \varpi \right)$-stability mathematically connects the generalization
ability and the stability of the cross-validated model via the Rademacher
complexity. Our result reveals mathematically the effect of cross-validation
from two sides: on one hand, cross-validation picks the model with the best
empirical generalization ability by validating all the alternatives on test
sets; on the other hand, cross-validation may compromise the stability of the
model selection by causing subsampling error. Moreover, the difference between
training and test errors in q\textsuperscript{th} round, sometimes referred to
as the generalization error, might be autocorrelated on q. Guided by the ideas
above, the $\left( \beta, \varpi \right)$-stability help us derivd a new class
of Rademacher bounds, referred to as the one-round/convoluted Rademacher
bounds, for the stability of cross-validation in both the i.i.d.\ and
non-i.i.d.\ cases. For both light-tail and heavy-tail losses, the new bounds
quantify the stability of the one-round/average test error of the
cross-validated model in terms of its one-round/average training error, the
sample sizes $n$, number of folds $K$, the tail property of the loss (encoded
as Orlicz-$\Psi_\nu$ norms) and the Rademacher complexity of the model class
$\Lambda$. The new class of bounds not only quantitatively reveals the
stability of the generalization ability of the cross-validated model, it also
shows empirically the optimal choice for number of folds $K$, at which the
upper bound of the one-round/average test error is lowest, or, to put it in
another way, where the test error is most stable.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07354</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Meaning of Memory Safety</dc:title>
 <dc:creator>de Amorim, Arthur Azevedo</dc:creator>
 <dc:creator>Hritcu, Catalin</dc:creator>
 <dc:creator>Pierce, Benjamin C.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose a rigorous characterization of what it means for a programming
language to be memory safe, capturing the intuition that memory safety supports
local reasoning about state. We formalize this principle in two different ways.
First, we show how a small memory-safe imperative language validates a
noninterference property: parts of the state that are not reachable from a
given part of the program can neither affect nor be affected by its execution.
Second, we show how to take advantage of memory safety to extend separation
logic, a framework for reasoning about heap-manipulating programs, with a
variant of its frame rule. Our new rule is stronger because it applies even
when parts of the program are buggy or malicious, but also weaker because it
requires a stricter form of separation between parts of the program state. We
also consider a number of pragmatically motivated variations of memory safety
and the reasoning principles they support. As an application of our
characterization, we evaluate the security of a previously proposed dynamic
monitor for memory safety of heap-allocated data.
</dc:description>
 <dc:description>Comment: EuroS&amp;P'18 submission</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07355</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Capacity of Noncoherent MIMO with Asymmetric Link Strengths</dc:title>
 <dc:creator>Sebastian, J.</dc:creator>
 <dc:creator>Sengupta, A.</dc:creator>
 <dc:creator>Diggavi, S. N.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the generalized degrees of freedom (gDoF) of the block-fading
noncoherent MIMO channel with asymmetric distributions of link strengths, and a
coherence time of $T$ symbol durations. We first derive the optimal signaling
structure for communication over this channel, which is distinct from that for
the i.i.d MIMO setting. We prove that for $T=1$, the gDoF is zero for MIMO
channels with arbitrary link strength distributions, extending the result for
MIMO with i.i.d links. We then show that selecting the statistically best
antenna is gDoF-optimal for both Multiple Input Single Output (MISO) and Single
Input Multiple Output (SIMO) channels. We also derive the gDoF for the
$2\times2$ MIMO channel with different exponents in the direct and cross links.
In this setting, we show that it is always necessary to use both antennas to
achieve the optimal gDoF, in contrast to the results for $2\times2$ MIMO with
identical link distributions.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07356</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Compression of Convolutional Neural Networks Based on Greedy
  Filter Pruning</dc:title>
 <dc:creator>Abbasi-Asl, Reza</dc:creator>
 <dc:creator>Yu, Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNNs) have state-of-the-art performance on
many problems in machine vision. However, networks with superior performance
often have millions of weights so that it is difficult or impossible to use
CNNs on computationally limited devices or to humanly interpret them. A myriad
of CNN compression approaches have been proposed and they involve pruning and
compressing the weights and filters. In this article, we introduce a greedy
structural compression scheme that prunes filters in a trained CNN. We define a
filter importance index equal to the classification accuracy reduction (CAR) of
the network after pruning that filter (similarly defined as RAR for
regression). We then iteratively prune filters based on the CAR index. This
algorithm achieves substantially higher classification accuracy in AlexNet
compared to other structural compression schemes that prune filters. Pruning
half of the filters in the first or second layer of AlexNet, our CAR algorithm
achieves 26% and 20% higher classification accuracies respectively, compared to
the best benchmark filter pruning scheme. Our CAR algorithm, combined with
further weight pruning and compressing, reduces the size of first or second
convolutional layer in AlexNet by a factor of 42, while achieving close to
original classification accuracy through retraining (or fine-tuning) network.
Finally, we demonstrate the interpretability of CAR-compressed CNNs by showing
that our algorithm prunes filters with visually redundant functionalities. In
fact, out of top 20 CAR-pruned filters in AlexNet, 17 of them in the first
layer and 14 of them in the second layer are color-selective filters as opposed
to shape-selective filters. To our knowledge, this is the first reported result
on the connection between compression and interpretability of CNNs.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07358</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible In-The-Field Monitoring</dc:title>
 <dc:creator>Cornejo, Oscar</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Fully assessing the robustness of a software application in-house is
infeasible, especially considering the huge variety of hardly predictable
stimuli, environments, and configurations that applications must handle in the
field. For this reason, modern testing and analysis techniques can often
process data extracted from the field, such as crash reports and profile data,
or can even be executed directly in the field, for instance to diagnose and
correct problems. In all these cases, collection, processing, and distribution
of field data must be done seamlessly and unobstrusively while users interact
with their applications. To limit the intrusiveness of in-the-field monitoring
a common approach is to reduce the amount of collected data (e.g., to rare
events and to crash dumps), which, however, may severely affect the
effectiveness of the techniques that exploit field data. The objective of this
Ph.D. thesis is to define solutions for collecting field data in a cost
effective way without affecting the quality of the user experience. This result
can enable a new range of testing and analysis solutions that extensively
exploit field data.
</dc:description>
 <dc:description>Comment: 2 pages, no figures, conference article</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07358</dc:identifier>
 <dc:identifier>doi:10.1109/ICSE-C.2017.37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07359</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Field Testing of Software Applications</dc:title>
 <dc:creator>Gazzola, Luca</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  When interacting with their software systems, users may have to deal with
problems like crashes, failures, and program instability. Faulty software
running in the field is not only the consequence of ineffective in-house
verification and validation techniques, but it is also due to the complexity
and diversity of the interactions between an application and its environment.
Many of these interactions can be hardly predicted at testing time, and even
when they could be predicted, often there are so many cases to be tested that
they cannot be all feasibly addressed before the software is released.
  This Ph.D. thesis investigates the idea of addressing the faults that cannot
be effectively addressed in house directly in the field, exploiting the field
itself as testbed for running the test cases. An enormous number of diverse
environments would then be available for testing, giving the possibility to run
many test cases in many different situations, timely revealing the many
failures that would be hard to detect otherwise.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07364</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizing Adversarial Nets With Prediction Methods</dc:title>
 <dc:creator>Yadav, Abhay</dc:creator>
 <dc:creator>Shah, Sohil</dc:creator>
 <dc:creator>Xu, Zheng</dc:creator>
 <dc:creator>Jacobs, David</dc:creator>
 <dc:creator>Goldstein, Tom</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Adversarial neural networks solve many important problems in data science,
but are notoriously difficult to train. These difficulties come from the fact
that optimal weights for adversarial nets correspond to saddle points, and not
minimizers, of the loss function. The alternating stochastic gradient methods
typically used for such problems do not reliably converge to saddle points, and
when convergence does happen it is often highly sensitive to learning rates. We
propose a simple modification of stochastic gradient descent that stabilizes
adversarial networks. We show, both in theory and practice, that the proposed
method reliably converges to saddle points. This makes adversarial networks
less likely to &quot;collapse&quot;, and enables faster training with larger learning
rates.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07366</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Forward Thinking: Building Deep Random Forests</dc:title>
 <dc:creator>Miller, Kevin</dc:creator>
 <dc:creator>Hettinger, Chris</dc:creator>
 <dc:creator>Humpherys, Jeffrey</dc:creator>
 <dc:creator>Jarvis, Tyler</dc:creator>
 <dc:creator>Kartchner, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The success of deep neural networks has inspired many to wonder whether other
learners could benefit from deep, layered architectures. We present a general
framework called forward thinking for deep learning that generalizes the
architectural flexibility and sophistication of deep neural networks while also
allowing for (i) different types of learning functions in the network, other
than neurons, and (ii) the ability to adaptively deepen the network as needed
to improve results. This is done by training one layer at a time, and once a
layer is trained, the input data are mapped forward through the layer to create
a new learning problem. The process is then repeated, transforming the data
through multiple layers, one at a time, rendering a new dataset, which is
expected to be better behaved, and on which a final output layer can achieve
good performance. In the case where the neurons of deep neural nets are
replaced with decision trees, we call the result a Forward Thinking Deep Random
Forest (FTDRF). We demonstrate a proof of concept by applying FTDRF on the
MNIST dataset. We also provide a general mathematical formulation that allows
for other types of deep learning problems to be considered.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07368</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixed Membership Word Embeddings for Computational Social Science</dc:title>
 <dc:creator>Foulds, James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Word embeddings improve the performance of NLP systems by revealing the
hidden structural relationships between words. These models have recently risen
in popularity due to the performance of scalable algorithms trained in the big
data setting. Despite their success, word embeddings have seen very little use
in computational social science NLP tasks, presumably due to their reliance on
big data, and to a lack of interpretability. I propose a probabilistic
model-based word embedding method which can recover interpretable embeddings,
without big data. The key insight is to leverage the notion of mixed membership
modeling, in which global representations are shared, but individual entities
(i.e. dictionary words) are free to use these representations to uniquely
differing degrees. Leveraging connections to topic models, I show how to train
these models in high dimensions using a combination of state-of-the-art
techniques for word embeddings and topic modeling. Experimental results show an
improvement in predictive performance of up to 63% in MRR over the skip-gram on
small datasets. The models are interpretable, as embeddings of topics are used
to encode embeddings for words (and hence, documents) in a model-based way. I
illustrate this with two computational social science case studies, on NIPS
articles and State of the Union addresses.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07369</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Broadcasting in Noisy Radio Networks</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Haeupler, Bernhard</dc:creator>
 <dc:creator>Hershkowitz, D. Ellis</dc:creator>
 <dc:creator>Zuzic, Goran</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The widely-studied radio network model [Chlamtac and Kutten, 1985] is a
graph-based description that captures the inherent impact of collisions in
wireless communication. In this model, the strong assumption is made that node
$v$ receives a message from a neighbor if and only if exactly one of its
neighbors broadcasts.
  We relax this assumption by introducing a new noisy radio network model in
which random faults occur at senders or receivers. Specifically, for a constant
noise parameter $p \in [0,1)$, either every sender has probability $p$ of
transmitting noise or every receiver of a single transmission in its
neighborhood has probability $p$ of receiving noise.
  We first study single-message broadcast algorithms in noisy radio networks
and show that the Decay algorithm [Bar-Yehuda et al., 1992] remains robust in
the noisy model while the diameter-linear algorithm of Gasieniec et al., 2007
does not. We give a modified version of the algorithm of Gasieniec et al., 2007
that is robust to sender and receiver faults, and extend both this modified
algorithm and the Decay algorithm to robust multi-message broadcast algorithms.
  We next investigate the extent to which (network) coding improves throughput
in noisy radio networks. We address the previously perplexing result of Alon et
al. 2014 that worst case coding throughput is no better than worst case routing
throughput up to constants: we show that the worst case throughput performance
of coding is, in fact, superior to that of routing -- by a $\Theta(\log(n))$
gap -- provided receiver faults are introduced. However, we show that any
coding or routing scheme for the noiseless setting can be transformed to be
robust to sender faults with only a constant throughput overhead. These
transformations imply that the results of Alon et al., 2014 carry over to noisy
radio networks with sender faults.
</dc:description>
 <dc:description>Comment: Principles of Distributed Computing 2017</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07369</dc:identifier>
 <dc:identifier>doi:10.1145/3087801.3087808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07371</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spelling Correction as a Foreign Language</dc:title>
 <dc:creator>Zhou, Yingbo</dc:creator>
 <dc:creator>Porwal, Utkarsh</dc:creator>
 <dc:creator>Konow, Roberto</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we reformulated the spell correction problem as a machine
translation task under the encoder-decoder framework. This reformulation
enabled us to use a single model for solving the problem that is traditionally
formulated as learning a language model and an error model. This model employs
multi-layer recurrent neural networks as an encoder and a decoder. We
demonstrate the effectiveness of this model using an internal dataset, where
the training data is automatically obtained from user logs. The model offers
competitive performance as compared to the state of the art methods but does
not require any feature engineering nor hand tuning between models.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07375</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Recycled Commodity SoCs: Exploiting Aging-Induced SRAM PUF
  Unreliability</dc:title>
 <dc:creator>Gao, Yansong</dc:creator>
 <dc:creator>Ma, Hua</dc:creator>
 <dc:creator>Al-Sarawi, Said F.</dc:creator>
 <dc:creator>Abbott, Derek</dc:creator>
 <dc:creator>Ranasinghe, Damith C.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A physical unclonable function (PUF), analogous to a human fingerprint, has
gained an enormous amount of attention from both academia and industry. SRAM
PUF is among one of the popular silicon PUF constructions that exploits random
initial power-up states from SRAM cells to extract hardware intrinsic secrets
for identification and key generation applications. The advantage of SRAM PUFs
is that they are widely embedded into commodity devices, thus such a PUF is
obtained without a custom design and virtually free of implementation costs. A
phenomenon known as `aging' alters the consistent
reproducibility---reliability---of responses that can be extracted from a
readout of a set of SRAM PUF cells. Similar to how a PUF exploits undesirable
manufacturing randomness for generating a hardware intrinsic fingerprint, SRAM
PUF unreliability induced by aging can be exploited to detect recycled
commodity devices requiring no additional cost to the device. In this context,
the SRAM PUF itself acts as an aging sensor by exploiting responses sensitive
to aging. We use SRAMs available in pervasively deployed commercial
off-the-shelf micro-controllers for experimental validations, which complements
recent work demonstrated in FPGA platforms, and we present a simplified
detection methodology along experimental results. We show that less than 1,000
SRAM responses are adequate to guarantee that both false acceptance rate and
false rejection rate are no more than 0.001.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07377</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instrument-Armed Bandits</dc:title>
 <dc:creator>Kallus, Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We extend the classic multi-armed bandit (MAB) model to the setting of
noncompliance, where the arm pull is a mere instrument and the treatment
applied may differ from it, which gives rise to the instrument-armed bandit
(IAB) problem. The IAB setting is relevant whenever the experimental units are
human since free will, ethics, and the law may prohibit unrestricted or forced
application of treatment. In particular, the setting is relevant in bandit
models of dynamic clinical trials and other controlled trials on human
interventions. Nonetheless, the setting has not been fully investigate in the
bandit literature. We show that there are various and divergent notions of
regret in this setting, all of which coincide only in the classic MAB setting.
We characterize the behavior of these regrets and analyze standard MAB
algorithms. We argue for a particular kind of regret that captures the causal
effect of treatments but show that standard MAB algorithms cannot achieve
sublinear control on this regret. Instead, we develop new algorithms for the
IAB problem, prove new regret bounds for them, and compare them to standard MAB
algorithms in numerical examples.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07381</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalizing the Role of Determinization in Probabilistic Planning</dc:title>
 <dc:creator>Pineda, Luis</dc:creator>
 <dc:creator>Zilberstein, Shlomo</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The stochastic shortest path problem (SSP) is a highly expressive model for
probabilistic planning. The computational hardness of SSPs has sparked interest
in determinization-based planners that can quickly solve large problems.
However, existing methods employ a simplistic approach to determinization. In
particular, they ignore the possibility of tailoring the determinization to the
specific characteristics of the target domain. In this work we examine this
question, by showing that learning a good determinization for a planning domain
can be done efficiently and can improve performance. Moreover, we show how to
directly incorporate probabilistic reasoning into the planning problem when a
good determinization is not sufficient by itself. Based on these insights, we
introduce a planner, FF-LAO*, that outperforms state-of-the-art probabilistic
planners on several well-known competition benchmarks.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07383</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Depth into both CNN and CRF for Indoor Semantic
  Segmentation</dc:title>
 <dc:creator>Jiang, Jindong</dc:creator>
 <dc:creator>Zhang, Zhijun</dc:creator>
 <dc:creator>Huang, Yongqian</dc:creator>
 <dc:creator>Zheng, Lunan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To improve segmentation performance, a novel neural network architecture
(termed DFCN-DCRF) is proposed, which combines an RGB-D fully convolutional
neural network (DFCN) with a depth-sensitive fully-connected conditional random
field (DCRF). First, a DFCN architecture which fuses depth information into the
early layers and applies dilated convolution for later contextual reasoning is
designed. Then, a depth-sensitive fully-connected conditional random field
(DCRF) is proposed and combined with the previous DFCN to refine the
preliminary result. Comparative experiments show that the proposed DFCN-DCRF
has the best performance compared with most state-of-the-art methods.
</dc:description>
 <dc:description>Comment: Accepted by IEEE ICSESS</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07384</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced Policy Evaluation and Learning</dc:title>
 <dc:creator>Kallus, Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a new approach to the problems of evaluating and learning
personalized decision policies from observational data of past contexts,
decisions, and outcomes. Only the outcome of the enacted decision is available
and the historical policy is unknown. These problems arise in personalized
medicine using electronic health records and in internet advertising. Existing
approaches use inverse propensity weighting (or, doubly robust versions) to
make historical outcome (or, residual) data look like it were generated by a
new policy being evaluated or learned. But this relies on a plug-in approach
that rejects data points with a decision that disagrees with the new policy,
leading to high variance estimates and ineffective learning. We propose a new,
balance-based approach that too makes the data look like the new policy but
does so directly by finding weights that optimize for balance between the
weighted data and the target policy in the given, finite sample, which is
equivalent to minimizing worst-case or posterior conditional mean square error.
Our policy learner proceeds as a two-level optimization problem over policies
and weights. We demonstrate that this approach markedly outperforms existing
ones both in evaluation and learning, which is unsurprising given the wider
support of balance-based weights. We establish extensive theoretical
consistency guarantees and regret bounds that support this empirical success.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07386</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepMasterPrint: Generating Fingerprints for Presentation Attacks</dc:title>
 <dc:creator>Bontrager, Philip</dc:creator>
 <dc:creator>Roy, Aditi</dc:creator>
 <dc:creator>Togelius, Julian</dc:creator>
 <dc:creator>Memon, Nasir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present two related methods for creating MasterPrints, synthetic
fingerprints that are capable of spoofing multiple people's fingerprints. These
methods achieve results that advance the state-of-the-art for single
MasterPrint attack accuracy while being the first methods capable of creating
MasterPrints at the image level. Both of the methods presented in this paper
start with training a Generative Adversarial Network (GAN) on a set of real
fingerprint images. The generator network is then used to search for
fingerprints that maximize the probability of matching with most subjects in a
dataset. The first method uses evolutionary search in the space of latent
variables, and the second method uses gradient-based optimization. The unique
combination of evolution and GANs is able to design a MasterPrint that a
commercial fingerprint system matches to 23% of all users in a strict security
setting, and 77% of all users at a looser security setting.
</dc:description>
 <dc:description>Comment: 7 pages; added more domain context and references</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07393</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recurrent Additive Networks</dc:title>
 <dc:creator>Lee, Kenton</dc:creator>
 <dc:creator>Levy, Omer</dc:creator>
 <dc:creator>Zettlemoyer, Luke</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce recurrent additive networks (RANs), a new gated RNN which is
distinguished by the use of purely additive latent state updates. At every time
step, the new state is computed as a gated component-wise sum of the input and
the previous state, without any of the non-linearities commonly used in RNN
transition dynamics. We formally show that RAN states are weighted sums of the
input vectors, and that the gates only contribute to computing the weights of
these sums. Despite this relatively simple functional form, experiments
demonstrate that RANs perform on par with LSTMs on benchmark language modeling
problems. This result shows that many of the non-linear computations in LSTMs
and related networks are not essential, at least for the problems we consider,
and suggests that the gates are doing more of the computational work than
previously understood.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07400</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MITHRIL: Mining Sporadic Associations for Cache Prefetching</dc:title>
 <dc:creator>Yang, Juncheng</dc:creator>
 <dc:creator>Karimi, Reza</dc:creator>
 <dc:creator>S&#xe6;mundsson, Trausti</dc:creator>
 <dc:creator>Wildani, Avani</dc:creator>
 <dc:creator>Vigfusson, Ymir</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:description>  The growing pressure on cloud application scalability has accentuated storage
performance as a critical bottle- neck. Although cache replacement algorithms
have been extensively studied, cache prefetching - reducing latency by
retrieving items before they are actually requested remains an underexplored
area. Existing approaches to history-based prefetching, in particular, provide
too few benefits for real systems for the resources they cost. We propose
MITHRIL, a prefetching layer that efficiently exploits historical patterns in
cache request associations. MITHRIL is inspired by sporadic association rule
mining and only relies on the timestamps of requests. Through evaluation of 135
block-storage traces, we show that MITHRIL is effective, giving an average of a
55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain
over AMP at reasonable cost. We further show that MITHRIL can supplement any
cache replacement algorithm and be readily integrated into existing systems.
Furthermore, we demonstrate the improvement comes from MITHRIL being able to
capture mid-frequency blocks.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07404</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CrossNets : A New Approach to Complex Learning</dc:title>
 <dc:creator>Agarwal, Chirag</dc:creator>
 <dc:creator>Sharifzhadeh, Mehdi</dc:creator>
 <dc:creator>Klobusicky, Joe</dc:creator>
 <dc:creator>Schonfeld, Dan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel neural network structure called CrossNets, which considers
architectures on directed acyclic graphs. This structure builds on previous
generalizations of feed forward models, such as ResNets, by allowing for all
forward cross connections between layers (both adjacent and non-adjacent). The
addition of cross connections among the network increases information flow
across the whole network, leading to better training and testing performances.
The superior performance of the network is tested against four benchmark
datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN. We conclude with a proof of
convergence for Crossnets to a local minimum for error, where weights for
connections are chosen through backpropagation with momentum.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07410</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding $K$ Contingency List in Power Networks using a New Model of
  Dependency</dc:title>
 <dc:creator>Banerjee, Joydeep</dc:creator>
 <dc:creator>Pal, Anamitra</dc:creator>
 <dc:creator>Basu, Kaustav</dc:creator>
 <dc:creator>Padhee, Malhar</dc:creator>
 <dc:creator>Sen, Arunabha</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Smart grid systems are composed of power and communication network
components. The components in either network exhibit complex dependencies on
components in its own as well as the other network to drive their
functionality. Existing, models fail to capture these complex dependencies. In
this paper, we restrict to the dependencies in the power network and propose
the Multi-scale Implicative Interdependency Relation (MIIR) model that address
the existing limitations. A formal description of the model along with its
working dynamics and a brief validation with respect to the 2011 Southwest
blackout are provided. Utilizing the MIIR model, the $K$ Contingency List
problem is proposed. For a given time instant, the problem solves for a set of
$K$ entities in a power network which when failed at that time instant would
cause the maximum number of entities to fail eventually. Owing to the problem
being NP-complete we devised a Mixed Integer Program (MIP) to obtain the
optimal solution and a polynomial time sub-optimal heuristic. The efficacy of
the heuristic with respect to the MIP is compared by using different bus system
data. In general, the heuristic is shown to provide near optimal solution at a
much faster time than the MIP.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07413</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the impact of quantum computing technology on future developments in
  high-performance scientific computing</dc:title>
 <dc:creator>M&#xf6;ller, Matthias</dc:creator>
 <dc:creator>Vuik, Cornelis</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>65Y10</dc:subject>
 <dc:description>  Quantum computing technologies have become a hot topic in academia and
industry receiving much attention and financial support from all sides.
Building a quantum computer that can be used practically is in itself an
outstanding challenge that has become the 'new race to the moon'. Next to
researchers and vendors of future computing technologies, national authorities
are showing strong interest in maturing this technology due to its known
potential to break many of today's encryption techniques, which would have
significant impact on our society. It is however quite likely that quantum
computing has beneficial impact on many computational disciplines.
  In this article we describe our vision of future developments in scientific
computing that would be enabled by the advent of software-programmable quantum
computers. We thereby assume that quantum computers will form part of a hybrid
accelerated computing platform like GPUs and co-processor cards do today. In
particular, we address the potential of quantum algorithms to bring major
breakthroughs in applied mathematics and its applications. Finally, we give
several examples that demonstrate the possible impact of quantum-accelerated
scientific computing on society.
</dc:description>
 <dc:description>Comment: 25 pages, 2 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07413</dc:identifier>
 <dc:identifier>doi:10.1007/s10676-017-9438-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07414</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unfolding Hidden Barriers by Active Enhanced Sampling</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Chen, Ming</dc:creator>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Collective variable (CV) or order parameter based enhanced sampling
algorithms have achieved great success due to their ability to efficiently
explore the rough potential energy landscapes of complex systems. However, the
degeneracy of microscopic configurations, originating from the orthogonal space
perpendicular to the CVs, is likely to shadow &quot;hidden barriers&quot; and greatly
reduce the efficiency of CV-based sampling. Here we demonstrate that systematic
machine learning CV, through enhanced sampling, can iteratively lift such
degeneracies on the fly. We introduce an active learning scheme that consists
of a parametric CV learner based on deep neural network and a CV-based enhanced
sampler. Our active enhanced sampling (AES) algorithm is capable of identifying
the least informative regions based on a historical sample, forming a positive
feedback loop between the CV learner and sampler. This approach is able to
globally preserve kinetic characteristics by incrementally enhancing both
sample completeness and CV quality.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07420</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Classification of Structured Objects using a CRF with Deep
  Class Embedding</dc:title>
 <dc:creator>Goldman, Eran</dc:creator>
 <dc:creator>Goldberger, Jacob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a novel deep learning architecture to classify structured
objects in datasets with a large number of visually similar categories. We
model sequences of images as linear-chain CRFs, and jointly learn the
parameters from both local-visual features and neighboring classes. The visual
features are computed by convolutional layers, and the class embeddings are
learned by factorizing the CRF pairwise potential matrix. This forms a highly
nonlinear objective function which is trained by optimizing a local likelihood
approximation with batch-normalization. This model overcomes the difficulties
of existing CRF methods to learn the contextual relationships thoroughly when
there is a large number of classes and the data is sparse. The performance of
the proposed method is illustrated on a huge dataset that contains images of
retail-store product displays, taken in varying settings and viewpoints, and
shows significantly improved results compared to linear CRF modeling and
unnormalized likelihood optimization.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07422</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Partition Networks for Multi-Person Pose Estimation</dc:title>
 <dc:creator>Nie, Xuecheng</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Xing, Junliang</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new Generative Partition Network (GPN) to address the
challenging multi-person pose estimation problem. Different from existing
models that are either completely top-down or bottom-up, the proposed GPN
introduces a novel strategy--it generates partitions for multiple persons from
their global joint candidates and infers instance-specific joint configurations
simultaneously. The GPN is favorably featured by low complexity and high
accuracy of joint detection and re-organization. In particular, GPN designs a
generative model that performs one feed-forward pass to efficiently generate
robust person detections with joint partitions, relying on dense regressions
from global joint candidates in an embedding space parameterized by centroids
of persons. In addition, GPN formulates the inference procedure for joint
configurations of human poses as a graph partition problem, and conducts local
optimization for each person detection with reliable global affinity cues,
leading to complexity reduction and performance improvement. GPN is implemented
with the Hourglass architecture as the backbone network to simultaneously learn
joint detector and dense regressor. Extensive experiments on benchmarks MPII
Human Pose Multi-Person, extended PASCAL-Person-Part, and WAF, show the
efficiency of GPN with new state-of-the-art performance.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07425</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Semantic Relatedness From Human Feedback Using Metric Learning</dc:title>
 <dc:creator>Niebler, Thomas</dc:creator>
 <dc:creator>Becker, Martin</dc:creator>
 <dc:creator>P&#xf6;litz, Christian</dc:creator>
 <dc:creator>Hotho, Andreas</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Assessing the degree of semantic relatedness between words is an important
task with a variety of semantic applications, such as ontology learning for the
Semantic Web, semantic search or query expansion. To accomplish this in an
automated fashion, many relatedness measures have been proposed. However, most
of these metrics only encode information contained in the underlying corpus and
thus do not directly model human intuition. To solve this, we propose to
utilize a metric learning approach to improve existing semantic relatedness
measures by learning from additional information, such as explicit human
feedback. For this, we argue to use word embeddings instead of traditional
high-dimensional vector representations in order to leverage their semantic
density and to reduce computational cost. We rigorously test our approach on
several domains including tagging data as well as publicly available embeddings
based on Wikipedia texts and navigation. Human feedback about semantic
relatedness for learning and evaluation is extracted from publicly available
datasets such as MEN or WS-353. We find that our method can significantly
improve semantic relatedness measures by learning from additional information,
such as explicit human feedback. For tagging data, we are the first to generate
and study embeddings. Our results are of special interest for ontology and
recommendation engineers, but also for any other researchers and practitioners
of Semantic Web techniques.
</dc:description>
 <dc:description>Comment: Under review at ISWC 2017</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07426</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Do's and Don'ts for CNN-based Face Verification</dc:title>
 <dc:creator>Bansal, Ankan</dc:creator>
 <dc:creator>Castillo, Carlos</dc:creator>
 <dc:creator>Ranjan, Rajeev</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While the research community appears to have developed a consensus on the
methods of acquiring annotated data, design and training of CNNs, many
questions still remain to be answered. In this paper, we explore the following
questions that are critical to face recognition research: (i) Can we train on
still images and expect the systems to work on videos? (ii) Are deeper datasets
better than wider datasets? (iii) Does adding label noise lead to improvement
in performance of deep networks? (iv) Is alignment needed for face recognition?
We address these questions by training CNNs using CASIA-WebFace, UMDFaces, and
a new video dataset and testing on YouTube- Faces, IJB-A and a disjoint portion
of UMDFaces datasets. Our new data set, which will be made publicly available,
has 22,075 videos and 3,735,476 human annotated frames extracted from them.
</dc:description>
 <dc:description>Comment: 10 pages including references, added more experiments on deeper vs
  wider dataset (section 3.2)</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07429</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sketched Answer Set Programming</dc:title>
 <dc:creator>Paramonov, Sergey</dc:creator>
 <dc:creator>Bessiere, Christian</dc:creator>
 <dc:creator>Dries, Anton</dc:creator>
 <dc:creator>De Raedt, Luc</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Answer Set Programming (ASP) is a powerful modeling formalism for
combinatorial problems. However, writing ASP models is not trivial. We propose
a novel method, called Sketched Answer Set Programming (SkASP), aiming at
supporting the user in resolving this issue. The user writes an ASP program
while marking uncertain parts open with question marks. In addition, the user
provides a number of positive and negative examples of the desired program
behaviour. The sketched model is rewritten into another ASP program, which is
solved by traditional methods. As a result, the user obtains a functional and
reusable ASP program modelling her problem. We evaluate our approach on 21 well
known puzzles and combinatorial problems inspired by Karp's 21 NP-complete
problems and demonstrate a use-case for a database application based on ASP.
</dc:description>
 <dc:description>Comment: 15 pages, 11 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07443</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Streaming Wasserstein Barycenters</dc:title>
 <dc:creator>Staib, Matthew</dc:creator>
 <dc:creator>Claici, Sebastian</dc:creator>
 <dc:creator>Solomon, Justin</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Efficiently aggregating data from different sources is a challenging problem,
particularly when samples from each source are distributed differently. These
differences can be inherent to the inference task or present for other reasons:
sensors in a sensor network may be placed far apart, affecting their individual
measurements. Conversely, it is computationally advantageous to split Bayesian
inference tasks across subsets of data, but data need not be identically
distributed across subsets. One principled way to fuse probability
distributions is via the lens of optimal transport: the Wasserstein barycenter
is a single distribution that summarizes a collection of input measures while
respecting their geometry. However, computing the barycenter scales poorly and
requires discretization of all input distributions and the barycenter itself.
Improving on this situation, we present a scalable, communication-efficient,
parallel algorithm for computing the Wasserstein barycenter of arbitrary
distributions. Our algorithm can operate directly on continuous input
distributions and is optimized for streaming data. Our method is even robust to
nonstationary input distributions and produces a barycenter estimate that
tracks the input measures over time. The algorithm is semi-discrete, needing to
discretize only the barycenter estimate. To the best of our knowledge, we also
provide the first bounds on the quality of the approximate barycenter as the
discretization becomes finer. Finally, we demonstrate the practical
effectiveness of our method, both in tracking moving distributions on a sphere,
as well as in a large-scale Bayesian inference task.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07445</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Mix n-Step Returns: Generalizing lambda-Returns for Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Sharma, Sahil</dc:creator>
 <dc:creator>J, Girish Raguvir</dc:creator>
 <dc:creator>Ramesh, Srivatsan</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reinforcement Learning (RL) can model complex behavior policies for
goal-directed sequential decision making tasks. A hallmark of RL algorithms is
Temporal Difference (TD) learning: value function for the current state is
moved towards a bootstrapped target that is estimated using next state's value
function. $\lambda$-returns generalize beyond 1-step returns and strike a
balance between Monte Carlo and TD learning methods. While lambda-returns have
been extensively studied in RL, they haven't been explored a lot in Deep RL.
This paper's first contribution is an exhaustive benchmarking of
lambda-returns. Although mathematically tractable, the use of exponentially
decaying weighting of n-step returns based targets in lambda-returns is a
rather ad-hoc design choice. Our second major contribution is that we propose a
generalization of lambda-returns called Confidence-based Autodidactic Returns
(CAR), wherein the RL agent learns the weighting of the n-step returns in an
end-to-end manner. This allows the agent to learn to decide how much it wants
to weigh the n-step returns based targets. In contrast, lambda-returns restrict
RL agents to use an exponentially decaying weighting scheme. Autodidactic
returns can be used for improving any RL algorithm which uses TD learning. We
empirically demonstrate that using sophisticated weighted mixtures of
multi-step returns (like CAR and lambda-returns) considerably outperforms the
use of n-step returns. We perform our experiments on the Asynchronous Advantage
Actor Critic (A3C) algorithm in the Atari 2600 domain.
</dc:description>
 <dc:description>Comment: 10 pages + 9 page appendix</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07450</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Segmentation by Iterative Inference from Conditional Score
  Estimation</dc:title>
 <dc:creator>Romero, Adriana</dc:creator>
 <dc:creator>Drozdzal, Michal</dc:creator>
 <dc:creator>Erraqabi, Akram</dc:creator>
 <dc:creator>J&#xe9;gou, Simon</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Inspired by the combination of feedforward and iterative computations in the
virtual cortex, and taking advantage of the ability of denoising autoencoders
to estimate the score of a joint distribution, we propose a novel approach to
iterative inference for capturing and exploiting the complex joint distribution
of output variables conditioned on some input variables. This approach is
applied to image pixel-wise segmentation, with the estimated conditional score
used to perform gradient ascent towards a mode of the estimated conditional
distribution. This extends previous work on score estimation by denoising
autoencoders to the case of a conditional distribution, with a novel use of a
corrupted feedforward predictor replacing Gaussian corruption. An advantage of
this approach over more classical ways to perform iterative inference for
structured outputs, like conditional random fields (CRFs), is that it is not
any more necessary to define an explicit energy function linking the output
variables. To keep computations tractable, such energy function
parametrizations are typically fairly constrained, involving only a few
neighbors of each of the output variables in each clique. We experimentally
find that the proposed iterative inference from conditional score estimation by
conditional denoising autoencoders performs better than comparable models based
on CRFs or those not using any explicit modeling of the conditional joint
distribution of outputs.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07460</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experience enrichment based task independent reward model</dc:title>
 <dc:creator>Xu, Min</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  For most reinforcement learning approaches, the learning is performed by
maximizing an accumulative reward that is expectedly and manually defined for
specific tasks. However, in real world, rewards are emergent phenomena from the
complex interactions between agents and environments. In this paper, we propose
an implicit generic reward model for reinforcement learning. Unlike those
rewards that are manually defined for specific tasks, such implicit reward is
task independent. It only comes from the deviation from the agents' previous
experiences.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07461</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shallow Updates for Deep Reinforcement Learning</dc:title>
 <dc:creator>Levine, Nir</dc:creator>
 <dc:creator>Zahavy, Tom</dc:creator>
 <dc:creator>Mankowitz, Daniel J.</dc:creator>
 <dc:creator>Tamar, Aviv</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep reinforcement learning (DRL) methods such as the Deep Q-Network (DQN)
have achieved state-of-the-art results in a variety of challenging,
high-dimensional domains. This success is mainly attributed to the power of
deep neural networks to learn rich domain representations for approximating the
value function or policy. Batch reinforcement learning methods with linear
representations, on the other hand, are more stable and require less hyper
parameter tuning. Yet, substantial feature engineering is necessary to achieve
good results. In this work we propose a hybrid approach -- the Least Squares
Deep Q-Network (LS-DQN), which combines rich feature representations learned by
a DRL algorithm with the stability of a linear least squares method. We do this
by periodically re-training the last hidden layer of a DRL network with a batch
least squares update. Key to our approach is a Bayesian regularization term for
the least squares update, which prevents over-fitting to the more recent data.
We tested LS-DQN on five Atari games and demonstrate significant improvement
over vanilla DQN and Double-DQN. We also investigated the reasons for the
superior performance of our method. Interestingly, we found that the
performance improvement can be attributed to the large batch size used by the
LS method when optimizing the last layer.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07463</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Controlled Relay Beamforming: $2$-Stage Optimal Policies</dc:title>
 <dc:creator>Kalogerias, Dionysios S.</dc:creator>
 <dc:creator>Petropulu, Athina P.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  The problem of enhancing Quality-of-Service (QoS) in power constrained,
mobile relay beamforming networks, by optimally and dynamically controlling the
motion of the relaying nodes, is considered, in a dynamic channel environment.
We assume a time slotted system, where the relays update their positions before
the beginning of each time slot. Modeling the wireless channel as a Gaussian
spatiotemporal stochastic field, we propose a novel $2$-stage stochastic
programming problem formulation for optimally specifying the positions of the
relays at each time slot, such that the expected QoS of the network is
maximized, based on causal Channel State Information (CSI) and under a total
relay transmit power budget. This results in a schema where, at each time slot,
the relays, apart from optimally beamforming to the destination, also
optimally, predictively decide their positions at the next time slot, based on
causally accumulated experience. Exploiting either the Method of Statistical
Differentials, or the multidimensional Gauss-Hermite Quadrature Rule, the
stochastic program considered is shown to be approximately equivalent to a set
of simple subproblems, which are solved in a distributed fashion, one at each
relay. Optimality and performance of the proposed spatially controlled system
are also effectively assessed, under a rigorous technical framework; strict
optimality is rigorously demonstrated via the development of a version of the
Fundamental Lemma of Stochastic Control, and, performance-wise, it is shown
that, quite interestingly, the optimal average network QoS exhibits an
increasing trend across time slots, despite our myopic problem formulation.
Numerical simulations are presented, experimentally corroborating the success
of the proposed approach and the validity of our theoretical predictions.
</dc:description>
 <dc:description>Comment: 68 pages, 10 figures, this work constitutes an extended
  preprint/version of a two part paper (soon to be) submitted for publication
  to the IEEE Transactions on Signal Processing in Spring/Summer 2017</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07465</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Schemes for Implementation of Arithmetic Operations with Complex
  Numbers Using Squaring Units</dc:title>
 <dc:creator>Cariow, Aleksandr</dc:creator>
 <dc:creator>Cariowa, Galina</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>15A23, 65Y20, 65F30</dc:subject>
 <dc:subject>F.2.1, G.1.0, I.1.2</dc:subject>
 <dc:description>  In this paper, new schemes for a squarer, multiplier and divider of complex
numbers are proposed. Traditional structural solutions for each of these
operations require the presence some number of general-purpose binary
multipliers. The advantage of our solutions is a removing of multiplications
through replacing them by less costly squarers. We use Logan's trick and
quarter square technique, which propose to replace the calculation of the
product of two real numbers by summing the squares. Replacing usual multipliers
on digital squares implies reducing power consumption as well as decreases
hardware circuit complexity. The squarer requiring less area and power as
compared to general-purpose multiplier, it is interesting to assess the use of
squarers to implementation of complex arithmetic.
</dc:description>
 <dc:description>Comment: 3 pages. 3 figures, 2 tables</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07465</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07474</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nice latent variable models have log-rank</dc:title>
 <dc:creator>Udell, Madeleine</dc:creator>
 <dc:creator>Townsend, Alex</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Matrices of low rank are pervasive in big data, appearing in recommender
systems, movie preferences, topic models, medical records, and genomics. While
there is a vast literature on how to exploit low rank structure in these
datasets, there is less attention on explaining why the low rank structure
appears in the first place. We explain the abundance of low rank matrices in
big data by proving that certain latent variable models associated to piecewise
analytic functions are of log-rank. A large matrix from such a latent variable
model can be approximated, up to a small error, by a low rank matrix.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07476</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Stackelberg Mixed Strategies</dc:title>
 <dc:creator>Conitzer, Vincent</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  It is sometimes the case that one solution concept in game theory is
equivalent to applying another solution concept to a modified version of the
game. In such cases, does it make sense to study the former separately (as it
applies to the original representation of the game), or should we entirely
subordinate it to the latter? The answer probably depends on the particular
circumstances, and indeed the literature takes different approaches in
different cases. In this article, I consider the specific example of
Stackelberg mixed strategies. I argue that, even though a Stackelberg mixed
strategy can also be seen as a subgame perfect Nash equilibrium of a
corresponding extensive-form game, there remains significant value in studying
it separately. The analysis of this special case may have implications for
other solution concepts.
</dc:description>
 <dc:description>Comment: This paper appears in Synthese, Volume 193, Issue 3, pp. 689-703,
  March 2016. The final publication is available at Springer via
  http://dx.doi.org/10.1007/s11229-015-0927-6</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07476</dc:identifier>
 <dc:identifier>Synthese, Volume 193, Issue 3, pp. 689-703, March 2016</dc:identifier>
 <dc:identifier>doi:10.1007/s11229-015-0927-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07477</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical inference using SGD</dc:title>
 <dc:creator>Li, Tianyang</dc:creator>
 <dc:creator>Liu, Liu</dc:creator>
 <dc:creator>Kyrillidis, Anastasios</dc:creator>
 <dc:creator>Caramanis, Constantine</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present a novel method for frequentist statistical inference in
$M$-estimation problems, based on stochastic gradient descent (SGD) with a
fixed step size: we demonstrate that the average of such SGD sequences can be
used for statistical inference, after proper scaling. An intuitive analysis
using the Ornstein-Uhlenbeck process suggests that such averages are
asymptotically normal. From a practical perspective, our SGD-based inference
procedure is a first order method, and is well-suited for large scale problems.
To show its merits, we apply it to both synthetic and real datasets, and
demonstrate that its accuracy is comparable to classical statistical methods,
while requiring potentially far less computation.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2018</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07478</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Report of the HPC Correctness Summit, Jan 25--26, 2017, Washington, DC</dc:title>
 <dc:creator>Gopalakrishnan, Ganesh</dc:creator>
 <dc:creator>Hovland, Paul D.</dc:creator>
 <dc:creator>Iancu, Costin</dc:creator>
 <dc:creator>Krishnamoorthy, Sriram</dc:creator>
 <dc:creator>Laguna, Ignacio</dc:creator>
 <dc:creator>Lethin, Richard A.</dc:creator>
 <dc:creator>Sen, Koushik</dc:creator>
 <dc:creator>Siegel, Stephen F.</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Maintaining leadership in HPC requires the ability to support simulations at
large scales and fidelity. In this study, we detail one of the most significant
productivity challenges in achieving this goal, namely the increasing
proclivity to bugs, especially in the face of growing hardware and software
heterogeneity and sheer system scale. We identify key areas where timely new
research must be proactively begun to address these challenges, and create new
correctness tools that must ideally play a significant role even while ramping
up toward exacale. We close with the proposal for a two-day workshop in which
the problems identified in this report can be more broadly discussed, and
specific plans to launch these new research thrusts identified.
</dc:description>
 <dc:description>Comment: 57 pages</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07483</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TuRF: Fast Data Collection for Fingerprint-based Indoor Localization</dc:title>
 <dc:creator>Li, Chenhe</dc:creator>
 <dc:creator>Xu, Qiang</dc:creator>
 <dc:creator>Gong, Zhe</dc:creator>
 <dc:creator>Zheng, Rong</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Many infrastructure-free indoor positioning systems rely on fine-grained
location-dependent fingerprints to train models for localization. The site
survey process to collect fingerprints is laborious and is considered one of
the major obstacles to deploying such systems. In this paper, we propose TuRF,
a fast path-based fingerprint collection mechanism for site survey. We
demonstrate the feasibility to collect fingerprints for indoor localization
during walking along predefined paths. A step counter is utilized to
accommodate the variations in walking speed. Approximate location labels
inferred from the steps are then used to train a Gaussian Process regression
model. Extensive experiments show that TuRF can significantly reduce the
required time for site survey, without compromising the localization
performance.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07485</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shake-Shake regularization</dc:title>
 <dc:creator>Gastaldi, Xavier</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The method introduced in this paper aims at helping deep learning
practitioners faced with an overfit problem. The idea is to replace, in a
multi-branch network, the standard summation of parallel branches with a
stochastic affine combination. Applied to 3-branch residual networks,
shake-shake regularization improves on the best single shot published results
on CIFAR-10 and CIFAR-100 by reaching test errors of 2.86% and 15.85%.
Experiments on architectures without skip connections or Batch Normalization
show encouraging results and open the door to a large set of applications. Code
is available at https://github.com/xgastaldi/shake-shake
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07485</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07490</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MindDesktop: a general purpose brain computer interface</dc:title>
 <dc:creator>Ossmy, Ori</dc:creator>
 <dc:creator>Tam, Ofir</dc:creator>
 <dc:creator>Puzis, Rami</dc:creator>
 <dc:creator>Rokach, Lior</dc:creator>
 <dc:creator>Inbar, Ohad</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Recent advances in electroencephalography (EEG) and electromyography (EMG)
enable communication for people with severe disabilities. In this paper we
present a system that enables the use of regular computers using an
off-the-shelf EEG/EMG headset, providing a pointing device and virtual keyboard
that can be used to operate any Windows based system, minimizing the user
effort required for interacting with a personal computer. Effectiveness of the
proposed system is evaluated by a usability study, indicating decreasing
learning curve for completing various tasks. The proposed system is available
in the link provided.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07492</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel and in-process compilation of individuals for genetic
  programming on GPU</dc:title>
 <dc:creator>Ayral, Hakan</dc:creator>
 <dc:creator>Albayrak, Song&#xfc;l</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Three approaches to implement genetic programming on GPU hardware are
compilation, interpretation and direct generation of machine code. The compiled
approach is known to have a prohibitive overhead compared to other two. This
paper investigates methods to accelerate compilation of individuals for genetic
programming on GPU hardware. We apply in-process compilation to minimize the
compilation overhead at each generation; and we investigate ways to parallelize
in-process compilation. In-process compilation doesn't lend itself to trivial
parallelization with threads; we propose a multiprocess parallelization using
memory sharing and operating systems interprocess communication primitives.
With parallelized compilation we achieve further reductions on compilation
overhead. Another contribution of this work is the code framework we built in
C# for the experiments. The framework makes it possible to build arbitrary
grammatical genetic programming experiments that run on GPU with minimal extra
coding effort, and is available as open source.
</dc:description>
 <dc:description>Comment: Submitted to PeerJ Computer Science</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07505</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Annealed Generative Adversarial Networks</dc:title>
 <dc:creator>Mehrjou, Arash</dc:creator>
 <dc:creator>Sch&#xf6;lkopf, Bernhard</dc:creator>
 <dc:creator>Saremi, Saeed</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a novel framework for adversarial training where the target
distribution is annealed between the uniform distribution and the data
distribution. We posited a conjecture that learning under continuous annealing
in the nonparametric regime is stable irrespective of the divergence measures
in the objective function and proposed an algorithm, dubbed {\ss}-GAN, in
corollary. In this framework, the fact that the initial support of the
generative network is the whole ambient space combined with annealing are key
to balancing the minimax game. In our experiments on synthetic data, MNIST, and
CelebA, {\ss}-GAN with a fixed annealing schedule was stable and did not suffer
from mode collapse.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07511</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ARABIS: an Asynchronous Acoustic Indoor Positioning System for Mobile
  Devices</dc:title>
 <dc:creator>Wang, Yu-Ting</dc:creator>
 <dc:creator>Li, Jun</dc:creator>
 <dc:creator>Zheng, Rong</dc:creator>
 <dc:creator>Zhao, Dongmei</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Acoustic ranging based indoor positioning solutions have the advantage of
higher ranging accuracy and better compatibility with commercial-off-the-self
consumer devices. However, similar to other time-domain based approaches using
Time-of-Arrival and Time-Difference-of-Arrival, they suffer from performance
degradation in presence of multi-path propagation and low received
signal-to-noise ratio (SNR) in indoor environments. In this paper, we improve
upon our previous work on asynchronous acoustic indoor positioning and develop
ARABIS, a robust and low-cost acoustic positioning system (IPS) for mobile
devices. We develop a low-cost acoustic board custom-designed to support large
operational ranges and extensibility. To mitigate the effects of low SNR and
multi-path propagation, we devise a robust algorithm that iteratively removes
possible outliers by taking advantage of redundant TDoA estimates. Experiments
have been carried in two testbeds of sizes 10.67m*7.76m and 15m*15m, one in an
academic building and one in a convention center. The proposed system achieves
average and 95% quantile localization errors of 7.4cm and 16.0cm in the first
testbed with 8 anchor nodes and average and 95% quantile localization errors of
20.4cm and 40.0cm in the second testbed with 4 anchor nodes only.
</dc:description>
 <dc:description>Comment: 8 pages, 13 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07512</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pyramid: Enhancing Selectivity in Big Data Protection with Count
  Featurization</dc:title>
 <dc:creator>Lecuyer, Mathias</dc:creator>
 <dc:creator>Spahn, Riley</dc:creator>
 <dc:creator>Geambasu, Roxana</dc:creator>
 <dc:creator>Huang, Tzu-Kuo</dc:creator>
 <dc:creator>Sen, Siddhartha</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Protecting vast quantities of data poses a daunting challenge for the growing
number of organizations that collect, stockpile, and monetize it. The ability
to distinguish data that is actually needed from data collected &quot;just in case&quot;
would help these organizations to limit the latter's exposure to attack. A
natural approach might be to monitor data use and retain only the working-set
of in-use data in accessible storage; unused data can be evicted to a highly
protected store. However, many of today's big data applications rely on machine
learning (ML) workloads that are periodically retrained by accessing, and thus
exposing to attack, the entire data store. Training set minimization methods,
such as count featurization, are often used to limit the data needed to train
ML workloads to improve performance or scalability. We present Pyramid, a
limited-exposure data management system that builds upon count featurization to
enhance data protection. As such, Pyramid uniquely introduces both the idea and
proof-of-concept for leveraging training set minimization methods to instill
rigor and selectivity into big data management. We integrated Pyramid into
Spark Velox, a framework for ML-based targeting and personalization. We
evaluate it on three applications and show that Pyramid approaches
state-of-the-art models while training on less than 1% of the raw data.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07520</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rewriting Context-free Families of String Diagrams</dc:title>
 <dc:creator>Zamdzhiev, Vladimir Nikolaev</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  String diagrams provide a convenient graphical framework which may be used
for equational reasoning about morphisms of monoidal categories. However,
unlike term rewriting, rewriting string diagrams results in shorter equational
proofs, because the string diagrammatic representation allows us to formally
establish equalities modulo any rewrite steps which follow from the monoidal
structure.
  Manipulating string diagrams by hand is a time-consuming and error-prone
process, especially for large string diagrams. This can be ameliorated by using
software proof assistants, such as Quantomatic.
  However, reasoning about concrete string diagrams may be limiting and in some
scenarios it is necessary to reason about entire (infinite) families of string
diagrams. When doing so, we face the same problems as for manipulating concrete
string diagrams, but in addition, we risk making further mistakes if we are not
precise enough about the way we represent (infinite) families of string
diagrams.
  The primary goal of this thesis is to design a mathematical framework for
equational reasoning about infinite families of string diagrams which is
amenable to computer automation. We will be working with context-free families
of string diagrams and we will represent them using context-free graph
grammars. We will model equations between infinite families of diagrams using
rewrite rules between context-free grammars. Our framework represents
equational reasoning about concrete string diagrams and context-free families
of string diagrams using double-pushout rewriting on graphs and context-free
graph grammars respectively. We will prove that our representation is sound by
showing that it respects the concrete semantics of string diagrammatic
reasoning and we will show that our framework is appropriate for software
implementation by proving important decidability properties.
</dc:description>
 <dc:description>Comment: PhD Thesis. Successfully defended in August 2016. See PDF for full
  abstract</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07522</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification and Retrieval of Digital Pathology Scans: A New Dataset</dc:title>
 <dc:creator>Babaie, Morteza</dc:creator>
 <dc:creator>Kalra, Shivam</dc:creator>
 <dc:creator>Sriram, Aditya</dc:creator>
 <dc:creator>Mitcheltree, Christopher</dc:creator>
 <dc:creator>Zhu, Shujin</dc:creator>
 <dc:creator>Khatami, Amin</dc:creator>
 <dc:creator>Rahnamayan, Shahryar</dc:creator>
 <dc:creator>Tizhoosh, H. R.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we introduce a new dataset, \textbf{Kimia Path24}, for image
classification and retrieval in digital pathology. We use the whole scan images
of 24 different tissue textures to generate 1,325 test patches of size
1000$\times$1000 (0.5mm$\times$0.5mm). Training data can be generated according
to preferences of algorithm designer and can range from approximately 27,000 to
over 50,000 patches if the preset parameters are adopted. We propose a compound
patch-and-scan accuracy measurement that makes achieving high accuracies quite
challenging. In addition, we set the benchmarking line by applying LBP,
dictionary approach and convolutional neural nets (CNNs) and report their
results. The highest accuracy was 41.80\% for CNN.
</dc:description>
 <dc:description>Comment: Accepted for presentation at Workshop for Computer Vision for
  Microscopy Image Analysis (CVMI 2017) @ CVPR 2017, Honolulu, Hawaii</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07524</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EDOS: Edge Assisted Offloading System for Mobile Devices</dc:title>
 <dc:creator>Harvey, Hank H.</dc:creator>
 <dc:creator>Mao, Ying</dc:creator>
 <dc:creator>Hou, Yantian</dc:creator>
 <dc:creator>Sheng, Bo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Offloading resource-intensive jobs to the cloud and nearby users is a
promising approach to enhance mobile devices. This paper investigates a hybrid
offloading system that takes both infrastructure-based networks and Ad-hoc
networks into the scope. Specifically, we propose EDOS, an edge assisted
offloading system that consists of two major components, an Edge Assistant (EA)
and Offload Agent (OA). EA runs on the routers/towers to manage registered
remote cloud servers and local service providers and OA operates on the users'
devices to discover the services in proximity. We present the system with a
suite of protocols to collect the potential service providers and algorithms to
allocate tasks according to user-specified constraints. To evaluate EDOS, we
prototype it on commercial mobile devices and evaluate it with both experiments
on a small-scale testbed and simulations. The results show that EDOS is
effective and efficient for offloading jobs.
</dc:description>
 <dc:description>Comment: The 26th International Conference on Computer Communications and
  Networks (ICCCN 2017)</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07531</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Corrupted Sensing with Sub-Gaussian Measurements</dc:title>
 <dc:creator>Chen, Jinchi</dc:creator>
 <dc:creator>Liu, Yulong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper studies the problem of accurately recovering a structured signal
from a small number of corrupted sub-Gaussian measurements. We consider three
different procedures to reconstruct signal and corruption when different kinds
of prior knowledge are available. In each case, we provide conditions for
stable signal recovery from structured corruption with added unstructured
noise. The key ingredient in our analysis is an extended matrix deviation
inequality for isotropic sub-Gaussian matrices.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of IEEE International Symposium on
  Information Theory 2017</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07531</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07532</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persistent Flows and Non-Reciprocal Interactions in Deterministic
  Networks</dc:title>
 <dc:creator>Xia, Weiguo</dc:creator>
 <dc:creator>Shi, Guodong</dc:creator>
 <dc:creator>Meng, Ziyang</dc:creator>
 <dc:creator>Cao, Ming</dc:creator>
 <dc:creator>Johansson, Karl Henrik</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies deterministic consensus networks with discrete-time
dynamics under persistent flows and non-reciprocal agent interactions. An arc
describing the interaction strength between two agents is said to be persistent
if its weight function has an infinite $l_1$ norm. We discuss two balance
conditions on the interactions between agents which generalize the arc-balance
and cut-balance conditions in the literature respectively. The proposed
conditions require that such a balance should be satisfied over each time
window of a fixed length instead of at each time instant. We prove that in both
cases global consensus is reached if and only if the persistent graph, which
consists of all the persistent arcs, contains a directed spanning tree. The
convergence rates of the system to consensus are also provided in terms of the
interactions between agents having taken place. The results are obtained under
a weak condition without assuming the existence of a positive lower bound of
all the nonzero weights of arcs and are compared with the existing results.
Illustrative examples are provided to show the critical importance of the
nontrivial lower boundedness of the self-confidence of the agents.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07533</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on the Information-Theoretic-(in)Security of Fading Generated
  Secret Keys</dc:title>
 <dc:creator>Malaney, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In this work we explore the security of secret keys generated via the
electromagnetic reciprocity of the wireless fading channel. Identifying a new
sophisticated colluding attack, we explore the information-theoretic-security
for such keys in the presence of an all-powerful adversary constrained only by
the laws of quantum mechanics. Specifically, we calculate the reduction in the
conditional mutual information between transmitter and receiver that can occur
when an adversary with unlimited computational and communication resources
places directional antenna interceptors at chosen locations. Such locations, in
principal, can be arbitrarily far from the intended receiver yet still
influence the secret key rate.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07535</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evading Classifiers by Morphing in the Dark</dc:title>
 <dc:creator>Dang, Hung</dc:creator>
 <dc:creator>Huang, Yue</dc:creator>
 <dc:creator>Chang, Ee-Chien</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Learning-based systems have been shown to be vulnerable to evasion through
adversarial data manipulation. These attacks have been studied under
assumptions that the adversary has certain knowledge of either the target model
internals, its training dataset or at least classification scores it assigns to
input samples. In this paper, we investigate a much more constrained and
realistic attack scenario wherein the target classifier is minimally exposed to
the adversary, revealing on its final classification decision (e.g., reject or
accept an input sample). Moreover, the adversary can only manipulate malicious
samples using a blackbox morpher. That is, the adversary has to evade the
target classifier by morphing malicious samples &quot;in the dark&quot;. We present a
scoring mechanism that can assign a real-value score which reflects evasion
progress to each sample based on the limited information available. Leveraging
on such scoring mechanism, we propose an evasion method -- EvadeHC -- and
evaluate it against two PDF malware detectors, namely PDFRate and Hidost. The
experimental evaluation demonstrates that the proposed evasion attacks are
effective, attaining $100\%$ evasion rate on the evaluation dataset.
Interestingly, EvadeHC outperforms the known classifier evasion technique that
operates based on classification scores output by the classifiers. Although our
evaluations are conducted on PDF malware classifier, the proposed approaches
are domain-agnostic and is of wider application to other learning-based
systems.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07535</dc:identifier>
 <dc:identifier>doi:10.1145/3133956.3133978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07538</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infrastructure for Usable Machine Learning: The Stanford DAWN Project</dc:title>
 <dc:creator>Bailis, Peter</dc:creator>
 <dc:creator>Olukotun, Kunle</dc:creator>
 <dc:creator>Re, Christopher</dc:creator>
 <dc:creator>Zaharia, Matei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite incredible recent advances in machine learning, building machine
learning applications remains prohibitively time-consuming and expensive for
all but the best-trained, best-funded engineering organizations. This expense
comes not from a need for new and improved statistical models but instead from
a lack of systems and tools for supporting end-to-end machine learning
application development, from data preparation and labeling to
productionization and monitoring. In this document, we outline opportunities
for infrastructure supporting usable, end-to-end machine learning applications
in the context of the nascent DAWN (Data Analytics for What's Next) project at
Stanford.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07538</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07539</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Phase Transition of Corrupted Sensing</dc:title>
 <dc:creator>Zhang, Huan</dc:creator>
 <dc:creator>Liu, Yulong</dc:creator>
 <dc:creator>Lei, Hong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In \cite{FOY2014}, a sharp phase transition has been numerically observed
when a constrained convex procedure is used to solve the corrupted sensing
problem. In this paper, we present a theoretical analysis for this phenomenon.
Specifically, we establish the threshold below which this convex procedure
fails to recover signal and corruption with high probability. Together with the
work in \cite{FOY2014}, we prove that a sharp phase transition occurs around
the sum of the squares of spherical Gaussian widths of two tangent cones.
Numerical experiments are provided to demonstrate the correctness and sharpness
of our results.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of IEEE International Symposium on
  Information Theory 2017</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07540</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Massive MIMO Research at the University of Bristol</dc:title>
 <dc:creator>Harris, Paul</dc:creator>
 <dc:creator>Hasan, Wael Boukley</dc:creator>
 <dc:creator>Brice, Henry</dc:creator>
 <dc:creator>Chitambira, Benny</dc:creator>
 <dc:creator>Beach, Mark</dc:creator>
 <dc:creator>Mellios, Evangelos</dc:creator>
 <dc:creator>Nix, Andrew</dc:creator>
 <dc:creator>Armour, Simon</dc:creator>
 <dc:creator>Doufexi, Angela</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive MIMO has rapidly gained popularity as a technology crucial to the
capacity advances required for 5G wireless systems. Since its theoretical
conception six years ago, research activity has grown exponentially, and there
is now a developing industrial interest to commercialise the technology. For
this to happen effectively, we believe it is crucial that further pragmatic
research is conducted with a view to establish how reality differs from
theoretical ideals. This paper presents an overview of the massive MIMO
research activities occurring within the Communication Systems &amp; Networks Group
at the University of Bristol centred around our 128-antenna real-time testbed,
which has been developed through the BIO programmable city initiative in
collaboration with NI and Lund University. Through recent preliminary trials,
we achieved a world first spectral efficiency of 79.4 bits/s/Hz, and
subsequently demonstrated that this could be increased to 145.6 bits/s/Hz. We
provide a summary of this work here along with some of our ongoing research
directions such as large-scale array wave-front analysis, optimised power
control and localisation techniques.
</dc:description>
 <dc:description>Comment: Presented at the IET Radio Propagation and Technologies for 5G
  Conference (2016). 5 pages</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07540</dc:identifier>
 <dc:identifier>doi:10.1049/ic.2016.0064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07541</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from Complementary Labels</dc:title>
 <dc:creator>Ishida, Takashi</dc:creator>
 <dc:creator>Niu, Gang</dc:creator>
 <dc:creator>Hu, Weihua</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Collecting labeled data is costly and thus a critical bottleneck in
real-world classification tasks. To mitigate this problem, we propose a novel
setting, namely learning from complementary labels for multi-class
classification. A complementary label specifies a class that a pattern does not
belong to. Collecting complementary labels would be less laborious than
collecting ordinary labels, since users do not have to carefully choose the
correct class from a long list of candidate classes. However, complementary
labels are less informative than ordinary labels and thus a suitable approach
is needed to better learn from them. In this paper, we show that an unbiased
estimator to the classification risk can be obtained only from complementarily
labeled data, if a loss function satisfies a particular symmetric condition. We
derive estimation error bounds for the proposed method and prove that the
optimal parametric convergence rate is achieved. We further show that learning
from complementary labels can be easily combined with learning from ordinary
labels (i.e., ordinary supervised learning), providing a highly practical
implementation of the proposed method. Finally, we experimentally demonstrate
the usefulness of the proposed methods.
</dc:description>
 <dc:description>Comment: NIPS 2017 camera-ready version</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07543</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Emotional Machines: Recognizing Image Emotions through Deep
  Neural Networks</dc:title>
 <dc:creator>Kim, Hye-Rin</dc:creator>
 <dc:creator>Kim, Yeong-Seok</dc:creator>
 <dc:creator>Kim, Seon Joo</dc:creator>
 <dc:creator>Lee, In-Kwon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  An image is a very effective tool for conveying emotions. Many researchers
have investigated in computing the image emotions by using various features
extracted from images. In this paper, we focus on two high level features, the
object and the background, and assume that the semantic information of images
is a good cue for predicting emotion. An object is one of the most important
elements that define an image, and we find out through experiments that there
is a high correlation between the object and the emotion in images. Even with
the same object, there may be slight difference in emotion due to different
backgrounds, and we use the semantic information of the background to improve
the prediction performance. By combining the different levels of features, we
build an emotion based feed forward deep neural network which produces the
emotion values of a given image. The output emotion values in our framework are
continuous values in the 2-dimensional space (Valence and Arousal), which are
more effective than using a few number of emotion categories in describing
emotions. Experiments confirm the effectiveness of our network in predicting
the emotion of images.
</dc:description>
 <dc:description>Comment: 11 pages, 15 figures</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07551</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Complexity of the List Coloring Reconfiguration Problem
  with Graph Parameters</dc:title>
 <dc:creator>Hatanaka, Tatsuhiko</dc:creator>
 <dc:creator>Ito, Takehiro</dc:creator>
 <dc:creator>Zhou, Xiao</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $G$ be a graph such that each vertex has its list of available colors,
and assume that each list is a subset of the common set consisting of $k$
colors. For two given list colorings of $G$, we study the problem of
transforming one into the other by changing only one vertex color assignment at
a time, while at all times maintaining a list coloring. This problem is known
to be PSPACE-complete even for bounded bandwidth graphs and a fixed constant
$k$. In this paper, we study the fixed-parameter tractability of the problem
when parameterized by several graph parameters. We first give a fixed-parameter
algorithm for the problem when parameterized by $k$ and the modular-width of an
input graph. We next give a fixed-parameter algorithm for the shortest variant
when parameterized by $k$ and the size of a minimum vertex cover of an input
graph. As corollaries, we show that the problem for cographs and the shortest
variant for split graphs are fixed-parameter tractable even when only $k$ is
taken as a parameter. On the other hand, we prove that the problem is W[1]-hard
when parameterized only by the size of a minimum vertex cover of an input
graph.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07556</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting the accuracy of multi-spectral image pan-sharpening by learning
  a deep residual network</dc:title>
 <dc:creator>Wei, Yancong</dc:creator>
 <dc:creator>Yuan, Qiangqiang</dc:creator>
 <dc:creator>Shen, Huanfeng</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the field of fusing multi-spectral and panchromatic images
(Pan-sharpening), the impressive effectiveness of deep neural networks has been
recently employed to overcome the drawbacks of traditional linear models and
boost the fusing accuracy. However, to the best of our knowledge, existing
research works are mainly based on simple and flat networks with relatively
shallow architecture, which severely limited their performances. In this paper,
the concept of residual learning has been introduced to form a very deep
convolutional neural network to make a full use of the high non-linearity of
deep learning models. By both quantitative and visual assessments on a large
number of high quality multi-spectral images from various sources, it has been
supported that our proposed model is superior to all mainstream algorithms
included in the comparison, and achieved the highest spatial-spectral unified
accuracy.
</dc:description>
 <dc:description>Comment: 5 pages,5 figures, 1 table</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07556</dc:identifier>
 <dc:identifier>doi:10.1109/LGRS.2017.2736020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07558</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Note on Evolution and Forecasting of Requirements: Communications
  Example</dc:title>
 <dc:creator>Levin, Mark Sh.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T20, 68M10, 90B18, 90B50, 90C30, 90C27</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>G.2.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>J.6</dc:subject>
 <dc:description>  Combinatorial evolution and forecasting of system requirements is examined.
The morphological model is used for a hierarchical requirements system (i.e.,
system parts, design alternatives for the system parts, ordinal estimates for
the alternatives). A set of system changes involves changes of the system
structure, component alternatives and their estimates. The composition process
of the forecast is based on combinatorial synthesis (knapsack problem, multiple
choice problem, hierarchical morphological design). An illustrative numerical
example for four-phase evolution and forecasting of requirements to
communications is described.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures, 9 tables</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07561</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection Estimation and Grid matching of Multiple Targets with Single
  Snapshot Measurements</dc:title>
 <dc:creator>Jagannath, Rakshith</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we explore the problems of detecting the number of narrow-band,
far-field targets and estimating their corresponding directions from single
snapshot measurements. The principles of sparse signal recovery (SSR) are used
for the single snapshot detection and estimation of multiple targets. In the
SSR framework, the DoA estimation problem is grid based and can be posed as the
lasso optimization problem. However, the SSR framework for DoA estimation gives
rise to the grid mismatch problem, when the unknown targets (sources) are not
matched with the estimation grid chosen for the construction of the array
steering matrix at the receiver. The block sparse recovery framework is known
to mitigate the grid mismatch problem by jointly estimating the targets and
their corresponding offsets from the estimation grid using the group lasso
estimator. The corresponding detection problem reduces to estimating the
optimal regularization parameter ($\tau$) of the lasso (in case of perfect
grid-matching) or group-lasso estimation problem for achieving the required
probability of correct detection ($P_c$). We propose asymptotic and finite
sample test statistics for detecting the number of sources with the required
$P_c$ at moderate to high signal to noise ratios. Once the number of sources
are detected, or equivalently the optimal $\hat{\tau}$ is estimated, the
corresponding estimation and grid matching of the DoAs can be performed by
solving the lasso or group-lasso problem at $\hat{\tau}$
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07562</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Batch Size Matters: A Diffusion Approximation Framework on Nonconvex
  Stochastic Gradient Descent</dc:title>
 <dc:creator>Li, Chris Junchi</dc:creator>
 <dc:creator>Li, Lei</dc:creator>
 <dc:creator>Qian, Junyang</dc:creator>
 <dc:creator>Liu, Jian-Guo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study the stochastic gradient descent method in analyzing
nonconvex statistical optimization problems from a diffusion approximation
point of view. Using the theory of large deviation of random dynamical system,
we prove in the small stepsize regime and the presence of omnidirectional noise
the following: starting from a local minimizer (resp.~saddle point) the SGD
iteration escapes in a number of iteration that is exponentially
(resp.~linearly) dependent on the inverse stepsize. We take the deep neural
network as an example to study this phenomenon. Based on a new analysis of the
mixing rate of multidimensional Ornstein-Uhlenbeck processes, our theory
substantiate a very recent empirical results by \citet{keskar2016large},
suggesting that large batch sizes in training deep learning for synchronous
optimization leads to poor generalization error.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07563</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Rank Using Localized Geometric Mean Metrics</dc:title>
 <dc:creator>Su, Yuxin</dc:creator>
 <dc:creator>King, Irwin</dc:creator>
 <dc:creator>Lyu, Michael</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Many learning-to-rank (LtR) algorithms focus on query-independent model, in
which query and document do not lie in the same feature space, and the rankers
rely on the feature ensemble about query-document pair instead of the
similarity between query instance and documents. However, existing algorithms
do not consider local structures in query-document feature space, and are
fragile to irrelevant noise features. In this paper, we propose a novel
Riemannian metric learning algorithm to capture the local structures and
develop a robust LtR algorithm. First, we design a concept called \textit{ideal
candidate document} to introduce metric learning algorithm to query-independent
model. Previous metric learning algorithms aiming to find an optimal metric
space are only suitable for query-dependent model, in which query instance and
documents belong to the same feature space and the similarity is directly
computed from the metric space. Then we extend the new and extremely fast
global Geometric Mean Metric Learning (GMML) algorithm to develop a localized
GMML, namely L-GMML. Based on the combination of local learned metrics, we
employ the popular Normalized Discounted Cumulative Gain~(NDCG) scorer and
Weighted Approximate Rank Pairwise (WARP) loss to optimize the \textit{ideal
candidate document} for each query candidate set. Finally, we can quickly
evaluate all candidates via the similarity between the \textit{ideal candidate
document} and other candidates. By leveraging the ability of metric learning
algorithms to describe the complex structural information, our approach gives
us a principled and efficient way to perform LtR tasks. The experiments on
real-world datasets demonstrate that our proposed L-GMML algorithm outperforms
the state-of-the-art metric learning to rank methods and the stylish
query-independent LtR algorithms regarding accuracy and computational
efficiency.
</dc:description>
 <dc:description>Comment: To appear in SIGIR'17</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07563</dc:identifier>
 <dc:identifier>doi:10.1145/3077136.3080828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07565</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain
  Surgeon</dc:title>
 <dc:creator>Dong, Xin</dc:creator>
 <dc:creator>Chen, Shangyu</dc:creator>
 <dc:creator>Pan, Sinno Jialin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  How to develop slim and accurate deep neural networks has become crucial for
real- world applications, especially for those employed in embedded systems.
Though previous work along this research line has shown some promising results,
most existing methods either fail to significantly compress a well-trained deep
network or require a heavy retraining process for the pruned deep network to
re-boost its prediction performance. In this paper, we propose a new layer-wise
pruning method for deep neural networks. In our proposed method, parameters of
each individual layer are pruned independently based on second order
derivatives of a layer-wise error function with respect to the corresponding
parameters. We prove that the final prediction performance drop after pruning
is bounded by a linear combination of the reconstructed errors caused at each
layer. Therefore, there is a guarantee that one only needs to perform a light
retraining process on the pruned network to resume its original prediction
performance. We conduct extensive experiments on benchmark datasets to
demonstrate the effectiveness of our pruning method compared with several
state-of-the-art baseline methods.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07574</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Fulfilling Signal of an Endogenous State in Network Congestion
  Games</dc:title>
 <dc:creator>Iwase, Tatsuya</dc:creator>
 <dc:creator>Tadokoro, Yukihiro</dc:creator>
 <dc:creator>Fukuda, Daisuke</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the problem of coordination via signaling in network congestion
games to improve social welfare deteriorated by incomplete information about
traffic flow. Traditional studies on signaling, which focus on exogenous
factors of congestion and ignore congestion externalities, fail to discuss the
oscillations of traffic flow. To address this gap, we formulate a problem of
designing a coordination signal on endogenous information about traffic flow
and introduce a it self-fulfilling characteristic of a signal that guarantees
an outcome flow consistent with the signal itself without causing the unwanted
oscillation. An instance of the self-fulfilling signal is shown in the case of
a Gaussian signal distribution. In addition, we show simple numerical examples.
The results reveal how a self-fulfilling signal suppresses the oscillation and
simultaneously improves social welfare through improved network efficiency.
</dc:description>
 <dc:description>Comment: The final publication is available at Springer via
  http://dx.doi.org/10.1007/s11067-017-9351-4</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07574</dc:identifier>
 <dc:identifier>doi:10.1007/s11067-017-9351-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07575</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mira: A Framework for Static Performance Analysis</dc:title>
 <dc:creator>Meng, Kewen</dc:creator>
 <dc:creator>Norris, Boyana</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The performance model of an application can pro- vide understanding about its
runtime behavior on particular hardware. Such information can be analyzed by
developers for performance tuning. However, model building and analyzing is
frequently ignored during software development until perfor- mance problems
arise because they require significant expertise and can involve many
time-consuming application runs. In this paper, we propose a fast, accurate,
flexible and user-friendly tool, Mira, for generating performance models by
applying static program analysis, targeting scientific applications running on
supercomputers. We parse both the source code and binary to estimate
performance attributes with better accuracy than considering just source or
just binary code. Because our analysis is static, the target program does not
need to be executed on the target architecture, which enables users to perform
analysis on available machines instead of conducting expensive exper- iments on
potentially expensive resources. Moreover, statically generated models enable
performance prediction on non-existent or unavailable architectures. In
addition to flexibility, because model generation time is significantly reduced
compared to dynamic analysis approaches, our method is suitable for rapid
application performance analysis and improvement. We present several scientific
application validation results to demonstrate the current capabilities of our
approach on small benchmarks and a mini application.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07576</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk</dc:title>
 <dc:creator>Hand, Paul</dc:creator>
 <dc:creator>Voroninski, Vladislav</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We examine the theoretical properties of enforcing priors provided by
generative deep neural networks via empirical risk minimization. In particular
we consider two models, one in which the task is to invert a generative neural
network given access to its last layer and another which entails recovering a
latent code in the domain of a generative neural network from compressive
linear observations of its last layer. We establish that in both cases, in
suitable regimes of network layer sizes and a randomness assumption on the
network weights, that the non-convex objective function given by empirical risk
minimization does not have any spurious stationary points. That is, we
establish that with high probability, at any point away from small
neighborhoods around two scalar multiples of the desired solution, there is a
descent direction. These results constitute the first theoretical guarantees
which establish the favorable global geometry of these non-convex optimization
problems, and bridge the gap between the empirical success of deep learning and
a rigorous understanding of non-linear inverse problems.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07589</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eye Tracker Accuracy: Quantitative Evaluation of the Invisible Eye
  Center Location</dc:title>
 <dc:creator>Wyder, Stephan</dc:creator>
 <dc:creator>Cattin, Philippe C.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Purpose. We present a new method to evaluate the accuracy of an eye tracker
based eye localization system. Measuring the accuracy of an eye tracker's
primary intention, the estimated point of gaze, is usually done with volunteers
and a set of fixation points used as ground truth. However, verifying the
accuracy of the location estimate of a volunteer's eye center in 3D space is
not easily possible. This is because the eye center is an intangible point
hidden by the iris. Methods. We evaluate the eye location accuracy by using an
eye phantom instead of eyes of volunteers. For this, we developed a testing
stage with a realistic artificial eye and a corresponding kinematic model,
which we trained with {\mu}CT data. This enables us to precisely evaluate the
eye location estimate of an eye tracker. Results. We show that the proposed
testing stage with the corresponding kinematic model is suitable for such a
validation. Further, we evaluate a particular eye tracker based navigation
system and show that this system is able to successfully determine the eye
center with sub-millimeter accuracy. Conclusions. We show the suitability of
the evaluated eye tracker for eye interventions, using the proposed testing
stage and the corresponding kinematic model. The results further enable
specific enhancement of the navigation system to potentially get even better
results.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07594</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robust Object Recognition Using Composed Scenes from Generative
  Models</dc:title>
 <dc:creator>Wang, Hao</dc:creator>
 <dc:creator>Lin, Xingyu</dc:creator>
 <dc:creator>Zhang, Yimeng</dc:creator>
 <dc:creator>Lee, Tai Sing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recurrent feedback connections in the mammalian visual system have been
hypothesized to play a role in synthesizing input in the theoretical framework
of analysis by synthesis. The comparison of internally synthesized
representation with that of the input provides a validation mechanism during
perceptual inference and learning. Inspired by these ideas, we proposed that
the synthesis machinery can compose new, unobserved images by imagination to
train the network itself so as to increase the robustness of the system in
novel scenarios. As a proof of concept, we investigated whether images composed
by imagination could help an object recognition system to deal with occlusion,
which is challenging for the current state-of-the-art deep convolutional neural
networks. We fine-tuned a network on images containing objects in various
occlusion scenarios, that are imagined or self-generated through a deep
generator network. Trained on imagined occluded scenarios under the object
persistence constraint, our network discovered more subtle and localized image
features that were neglected by the original network for object classification,
obtaining better separability of different object classes in the feature space.
This leads to significant improvement of object recognition under occlusion for
our network relative to the original network trained only on un-occluded
images. In addition to providing practical benefits in object recognition under
occlusion, this work demonstrates the use of self-generated composition of
visual scenes through the synthesis loop, combined with the object persistence
constraint, can provide opportunities for neural networks to discover new
relevant patterns in the data, and become more flexible in dealing with novel
situations.
</dc:description>
 <dc:description>Comment: Accepted by 14th Conference on Computer and Robot Vision</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07594</dc:identifier>
 <dc:identifier>doi:10.1109/CRV.2017.42</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07600</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification Using Proximity Catch Digraphs (Technical Report)</dc:title>
 <dc:creator>Manukyan, Art&#xfc;r</dc:creator>
 <dc:creator>Ceyhan, Elvan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We employ random geometric digraphs to construct semi-parametric classifiers.
These data-random digraphs are from parametrized random digraph families called
proximity catch digraphs (PCDs). A related geometric digraph family, class
cover catch digraph (CCCD), has been used to solve the class cover problem by
using its approximate minimum dominating set. CCCDs showed relatively good
performance in the classification of imbalanced data sets, and although CCCDs
have a convenient construction in $\mathbb{R}^d$, finding minimum dominating
sets is NP-hard and its probabilistic behaviour is not mathematically tractable
except for $d=1$. On the other hand, a particular family of PCDs, called
\emph{proportional-edge} PCDs (PE-PCDs), has mathematical tractable minimum
dominating sets in $\mathbb{R}^d$; however their construction in higher
dimensions may be computationally demanding. More specifically, we show that
the classifiers based on PE-PCDs are prototype-based classifiers such that the
exact minimum number of prototypes (equivalent to minimum dominating sets) are
found in polynomial time on the number of observations. We construct two types
of classifiers based on PE-PCDs. One is a family of hybrid classifiers depend
on the location of the points of the training data set, and another type is a
family of classifiers solely based on class covers. We assess the
classification performance of our PE-PCD based classifiers by extensive Monte
Carlo simulations, and compare them with that of other commonly used
classifiers. We also show that, similar to CCCD classifiers, our classifiers
are relatively better in classification in the presence of class imbalance.
</dc:description>
 <dc:description>Comment: 41 pages, 16 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07603</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-output Polynomial Networks and Factorization Machines</dc:title>
 <dc:creator>Blondel, Mathieu</dc:creator>
 <dc:creator>Niculae, Vlad</dc:creator>
 <dc:creator>Otsuka, Takuma</dc:creator>
 <dc:creator>Ueda, Naonori</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Factorization machines and polynomial networks are supervised polynomial
models based on an efficient low-rank decomposition. We extend these models to
the multi-output setting, i.e., for learning vector-valued functions, with
application to multi-class or multi-task problems. We cast this as the problem
of learning a 3-way tensor whose slices share a common basis and propose a
convex formulation of that problem. We then develop an efficient conditional
gradient algorithm and prove its global convergence, despite the fact that it
involves a non-convex basis selection step. On classification tasks, we show
that our algorithm achieves excellent accuracy with much sparser models than
existing methods. On recommendation system tasks, we show how to combine our
algorithm with a reduction from ordinal regression to multi-output
classification and show that the resulting algorithm outperforms simple
baselines in terms of ranking accuracy.
</dc:description>
 <dc:description>Comment: Published at NIPS 2017. 17 pages, including appendix</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07603</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07609</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>View-Invariant Recognition of Action Style Self-Dissimilarity</dc:title>
 <dc:creator>Shen, Yuping</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Self-similarity was recently introduced as a measure of inter-class
congruence for classification of actions. Herein, we investigate the dual
problem of intra-class dissimilarity for classification of action styles. We
introduce self-dissimilarity matrices that discriminate between same actions
performed by different subjects regardless of viewing direction and camera
parameters. We investigate two frameworks using these invariant style
dissimilarity measures based on Principal Component Analysis (PCA) and Fisher
Discriminant Analysis (FDA). Extensive experiments performed on IXMAS dataset
indicate remarkably good discriminant characteristics for the proposed
invariant measures for gender recognition from video data.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07615</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AIXIjs: A Software Demo for General Reinforcement Learning</dc:title>
 <dc:creator>Aslanides, John</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Reinforcement learning is a general and powerful framework with which to
study and implement artificial intelligence. Recent advances in deep learning
have enabled RL algorithms to achieve impressive performance in restricted
domains such as playing Atari video games (Mnih et al., 2015) and, recently,
the board game Go (Silver et al., 2016). However, we are still far from
constructing a generally intelligent agent. Many of the obstacles and open
questions are conceptual: What does it mean to be intelligent? How does one
explore and learn optimally in general, unknown environments? What, in fact,
does it mean to be optimal in the general sense? The universal Bayesian agent
AIXI (Hutter, 2005) is a model of a maximally intelligent agent, and plays a
central role in the sub-field of general reinforcement learning (GRL).
Recently, AIXI has been shown to be flawed in important ways; it doesn't
explore enough to be asymptotically optimal (Orseau, 2010), and it can perform
poorly with certain priors (Leike and Hutter, 2015). Several variants of AIXI
have been proposed to attempt to address these shortfalls: among them are
entropy-seeking agents (Orseau, 2011), knowledge-seeking agents (Orseau et al.,
2013), Bayes with bursts of exploration (Lattimore, 2013), MDL agents (Leike,
2016a), Thompson sampling (Leike et al., 2016), and optimism (Sunehag and
Hutter, 2015). We present AIXIjs, a JavaScript implementation of these GRL
agents. This implementation is accompanied by a framework for running
experiments against various environments, similar to OpenAI Gym (Brockman et
al., 2016), and a suite of interactive demos that explore different properties
of the agents, similar to REINFORCEjs (Karpathy, 2015). We use AIXIjs to
present numerous experiments illustrating fundamental properties of, and
differences between, these agents.
</dc:description>
 <dc:description>Comment: Masters thesis. Australian National University, October 2016. 97 pp</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07632</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer vision-based food calorie estimation: dataset, method, and
  experiment</dc:title>
 <dc:creator>Liang, Yanchao</dc:creator>
 <dc:creator>Li, Jianhua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computer vision has been introduced to estimate calories from food images.
But current food image data sets don't contain volume and mass records of
foods, which leads to an incomplete calorie estimation. In this paper, we
present a novel food image data set with volume and mass records of foods, and
a deep learning method for food detection, to make a complete calorie
estimation. Our data set includes 2978 images, and every image contains
corresponding each food's annotation, volume and mass records, as well as a
certain calibration reference. To estimate calorie of food in the proposed data
set, a deep learning method using Faster R-CNN first is put forward to detect
the food. And the experiment results show our method is effective to estimate
calories and our data set contains adequate information for calorie estimation.
Our data set is the first released food image data set which can be used to
evaluate computer vision-based calorie estimation methods.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07637</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinodynamic Planning on Constraint Manifolds</dc:title>
 <dc:creator>Bordalba, Ricard</dc:creator>
 <dc:creator>Ros, Llu&#xed;s</dc:creator>
 <dc:creator>Porta, Josep M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a motion planner for systems subject to kinematic and
dynamic constraints. The former appear when kinematic loops are present in the
system, such as in parallel manipulators, in robots that cooperate to achieve a
given task, or in situations involving contacts with the environment. The
latter are necessary to obtain realistic trajectories, taking into account the
forces acting on the system. The kinematic constraints make the state space
become an implicitly-defined manifold, which complicates the application of
common motion planning techniques. To address this issue, the planner
constructs an atlas of the state space manifold incrementally, and uses this
atlas both to generate random states and to dynamically simulate the steering
of the system towards such states. The resulting tools are then exploited to
construct a rapidly-exploring random tree (RRT) over the state space. To the
best of our knowledge, this is the first randomized kinodynamic planner for
implicitly-defined state spaces. The test cases presented in this paper
validate the approach in significantly-complex systems.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07640</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamics Based 3D Skeletal Hand Tracking</dc:title>
 <dc:creator>Melax, Stan</dc:creator>
 <dc:creator>Keselman, Leonid</dc:creator>
 <dc:creator>Orsten, Sterling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:description>  Tracking the full skeletal pose of the hands and fingers is a challenging
problem that has a plethora of applications for user interaction. Existing
techniques either require wearable hardware, add restrictions to user pose, or
require significant computation resources. This research explores a new
approach to tracking hands, or any articulated model, by using an augmented
rigid body simulation. This allows us to phrase 3D object tracking as a linear
complementarity problem with a well-defined solution. Based on a depth sensor's
samples, the system generates constraints that limit motion orthogonal to the
rigid body model's surface. These constraints, along with prior motion,
collision/contact constraints, and joint mechanics, are resolved with a
projected Gauss-Seidel solver. Due to camera noise properties and attachment
errors, the numerous surface constraints are impulse capped to avoid
overpowering mechanical constraints. To improve tracking accuracy, multiple
simulations are spawned at each frame and fed a variety of heuristics,
constraints and poses. A 3D error metric selects the best-fit simulation,
helping the system handle challenging hand motions. Such an approach enables
real-time, robust, and accurate 3D skeletal tracking of a user's hand on a
variety of depth cameras, while only utilizing a single x86 CPU core for
processing.
</dc:description>
 <dc:description>Comment: Published in Graphics Interface 2013</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07643</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Feasible Stable Matchings with Budget Constraints</dc:title>
 <dc:creator>Kawase, Yasushi</dc:creator>
 <dc:creator>Iwasaki, Atsushi</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper examines two-sided matching with budget constraints where one side
(a firm or hospital) can make monetary transfers (offer wages) to the other (a
worker or doctor). In a standard model, while multiple doctors can be matched
to a single hospital, a hospital has a {\em maximum quota}, thus, the number of
doctors assigned to that hospital cannot exceed a certain limit. In our model,
in contrast, a hospital instead has a {\em fixed budget}, that is, the total
amount of wages allocated by each hospital to the doctors is constrained. With
budget constraints, stable matchings may fail to exist and checking for the
existence is hard. To deal with the nonexistence of stable matchings, we extend
the &quot;matching with contracts&quot; model of Hatfield and Milgrom, so that it deals
with \textit{near-feasible} matchings that exceed each hospital budget by a
certain amount. We then propose two novel mechanisms that efficiently return
such a near-feasible matching that is stable with respect to the actual amount
of wages allocated by each hospital. Specifically, by sacrificing
strategy-proofness, our second mechanism achieves the best possible bound of
budget excess.
</dc:description>
 <dc:description>Comment: Accepted for the 26th International Joint Conference on Artificial
  Intelligence (IJCAI2017)</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07661</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Binary Sketching based on Subspace Tracking and Diagonal
  Uniformization</dc:title>
 <dc:creator>Morvan, Anne</dc:creator>
 <dc:creator>Souloumiac, Antoine</dc:creator>
 <dc:creator>Gouy-Pailler, C&#xe9;dric</dc:creator>
 <dc:creator>Atif, Jamal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we address the problem of learning compact
similarity-preserving embeddings for massive high-dimensional streams of data
in order to perform efficient similarity search. We present a new method for
computing binary compressed representations -\textit{sketches}- of
high-dimensional real feature vectors. Given an expected code length $c$ and
high-dimensional input data points, our algorithm provides a binary code of $c$
bits aiming at preserving the distance between the points from the original
high-dimensional space. Our offline version of the algorithm outperforms the
offline state-of-the-art methods regarding their computation time complexity
and have a similar quality of the sketches. It also provides convergence
guarantees. Moreover, our algorithm can be straightforwardly used in the
streaming context by not requiring neither the storage of the whole dataset nor
a chunk. We demonstrate the quality of our binary sketches through extensive
experiments on real data for the nearest neighbors search task in the offline
and online settings.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07663</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LOGAN: Evaluating Privacy Leakage of Generative Models Using Generative
  Adversarial Networks</dc:title>
 <dc:creator>Hayes, Jamie</dc:creator>
 <dc:creator>Melis, Luca</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative models are increasingly used to artificially generate various
kinds of data, including high-quality images and videos. These models are used
to estimate the underlying distribution of a dataset and randomly generate
realistic samples according to their estimated distribution. However, the data
used to train these models is often sensitive, thus prompting the need to
evaluate information leakage from producing synthetic samples with generative
models---specifically, whether an adversary can infer information about the
data used to train the models. In this paper, we present the first membership
inference attack on generative models. To mount the attack, we train a
Generative Adversarial Network (GAN), which combines a discriminative and a
generative model, to detect overfitting and recognize inputs that are part of
training datasets by relying on the discriminator's capacity to learn
statistical differences in distributions. We present attacks based on both
white-box and black-box access to the target model, and show how to improve the
latter using limited auxiliary knowledge of dataset samples. We test our
attacks on several state-of-the-art models, such as Deep Convolutional GAN
(DCGAN), Boundary Equilibrium GAN (BEGAN), and the combination of DCGAN with a
Variational Autoencoder (DCGAN+VAE), using datasets consisting of complex
representations of faces (LFW), objects (CIFAR-10), and medical images
(Diabetic Retinopathy). The white-box attacks are 100% successful at inferring
which samples were used to train the target model, and the black-box ones
succeeds with 80% accuracy. Finally, we discuss the sensitivity of our attacks
to different training parameters, and their robustness against mitigation
strategies, finding that successful defenses often result in significant worse
performances of the generative models in terms of training stability and/or
sample quality.
</dc:description>
 <dc:description>Comment: Compared to v2, among other things, this version presents an
  evaluation of the sensitivity of the attacks to training set size and to
  prediction ordering, as well as of their robustness to different mitigation
  strategies, including Machine Learning Regularizers and Differentially
  Private Generative Adversarial Networks</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07663</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07664</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CayleyNets: Graph Convolutional Neural Networks with Complex Rational
  Spectral Filters</dc:title>
 <dc:creator>Levie, Ron</dc:creator>
 <dc:creator>Monti, Federico</dc:creator>
 <dc:creator>Bresson, Xavier</dc:creator>
 <dc:creator>Bronstein, Michael M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The rise of graph-structured data such as social networks, regulatory
networks, citation graphs, and functional brain networks, in combination with
resounding success of deep learning in various applications, has brought the
interest in generalizing deep learning models to non-Euclidean domains. In this
paper, we introduce a new spectral domain convolutional architecture for deep
learning on graphs. The core ingredient of our model is a new class of
parametric rational complex functions (Cayley polynomials) allowing to
efficiently compute localized regular filters on graphs that specialize on
frequency bands of interest. Our model scales linearly with the size of the
input data for sparsely-connected graphs, can handle different constructions of
Laplacian operators, and typically requires less parameters than previous
models. Extensive experimental results show the superior performance of our
approach on various graph learning problems.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07666</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Goal Clustering: VNS based heuristics</dc:title>
 <dc:creator>Martins, Pedro</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>62H30, 90C59 (Primary), 90C27, 05C70 (Secondary)</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Given a set V of n elements on m attributes, we want to find a partition of V
on the minimum number of clusters such that the associated R-squared ratio is
at least a given threshold. We denote this problem as Goal Clustering (GC).
This problem represents a new perspective, characterizing a different
methodology within unsupervised non-hierarchical clustering. In effect, while
in the k-means we set the number of clusters in advance and then test the
associated R-squared ratio; in the GC we set an R-squared threshold lower limit
in advance and minimize k. We present two Variable Neighborhood Search (VNS)
based heuristics for the GC problem. The two heuristics use different
methodologies to start the VNS algorithms. One is based on the Ward's
construction and the other one resorts to the k-means method. Computational
tests are conducted over a set of large sized instances in order to show the
performance of the two proposed heuristics.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07668</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A decoding algorithm for Twisted Gabidulin codes</dc:title>
 <dc:creator>Randrianarisoa, Tovohery</dc:creator>
 <dc:creator>Rosenthal, Joachim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we modify the decoding algorithm for subspace codes by Koetter
and Kschischang to get a decoding algorithm for (generalized) twisted Gabidulin
codes. The decoding algorithm we present applies to cases where the code is
linear over the base field $\mathbb{F}_q$ but not linear over
$\mathbb{F}_{q^n}$.
</dc:description>
 <dc:description>Comment: This paper was submitted to ISIT 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07668</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07673</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear-Time Kernel Goodness-of-Fit Test</dc:title>
 <dc:creator>Jitkrittum, Wittawat</dc:creator>
 <dc:creator>Xu, Wenkai</dc:creator>
 <dc:creator>Szabo, Zoltan</dc:creator>
 <dc:creator>Fukumizu, Kenji</dc:creator>
 <dc:creator>Gretton, Arthur</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>46E22, 62G10</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We propose a novel adaptive test of goodness-of-fit, with computational cost
linear in the number of samples. We learn the test features that best indicate
the differences between observed samples and a reference model, by minimizing
the false negative rate. These features are constructed via Stein's method,
meaning that it is not necessary to compute the normalising constant of the
model. We analyse the asymptotic Bahadur efficiency of the new test, and prove
that under a mean-shift alternative, our test always has greater relative
efficiency than a previous linear-time kernel test, regardless of the choice of
parameters for that test. In experiments, the performance of our method exceeds
that of the earlier linear-time test, and matches or exceeds the power of a
quadratic-time kernel test. In high dimensions and where model structure may be
exploited, our goodness of fit test performs far better than a quadratic-time
two-sample test based on the Maximum Mean Discrepancy, with samples drawn from
the model.
</dc:description>
 <dc:description>Comment: Accepted to NIPS 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07674</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individualized Risk Prognosis for Critical Care Patients: A Multi-task
  Gaussian Process Model</dc:title>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>Yoon, Jinsung</dc:creator>
 <dc:creator>Hu, Scott</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We report the development and validation of a data-driven real-time risk
score that provides timely assessments for the clinical acuity of ward patients
based on their temporal lab tests and vital signs, which allows for timely
intensive care unit (ICU) admissions. Unlike the existing risk scoring
technologies, the proposed score is individualized; it uses the electronic
health record (EHR) data to cluster the patients based on their static
covariates into subcohorts of similar patients, and then learns a separate
temporal, non-stationary multi-task Gaussian Process (GP) model that captures
the physiology of every subcohort. Experiments conducted on data from a
heterogeneous cohort of 6,094 patients admitted to the Ronald Reagan UCLA
medical center show that our risk score significantly outperforms the
state-of-the-art risk scoring technologies, such as the Rothman index and MEWS,
in terms of timeliness, true positive rate (TPR), and positive predictive value
(PPV). In particular, the proposed score increases the AUC with 20% and 38% as
compared to Rothman index and MEWS respectively, and can predict ICU admissions
8 hours before clinicians at a PPV of 35% and a TPR of 50%. Moreover, we show
that the proposed risk score allows for better decisions on when to discharge
clinically stable patients from the ward, thereby improving the efficiency of
hospital resource utilization.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07678</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Imperative Functional Programs that Explain their Work</dc:title>
 <dc:creator>Ricciotti, Wilmer</dc:creator>
 <dc:creator>Stolarek, Jan</dc:creator>
 <dc:creator>Perera, Roly</dc:creator>
 <dc:creator>Cheney, James</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Program slicing provides explanations that illustrate how program outputs
were produced from inputs. We build on an approach introduced in prior work by
Perera et al., where dynamic slicing was defined for pure higher-order
functional programs as a Galois connection between lattices of partial inputs
and partial outputs. We extend this approach to imperative functional programs
that combine higher-order programming with references and exceptions. We
present proofs of correctness and optimality of our approach and a
proof-of-concept implementation and experimental evaluation.
</dc:description>
 <dc:description>Comment: Full version of ICFP 2017 paper, with appendices</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07678</dc:identifier>
 <dc:identifier>doi:10.1145/3110258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07681</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clique-Width for Graph Classes Closed under Complementation</dc:title>
 <dc:creator>Blanch&#xe9;, Alexandre</dc:creator>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Johnson, Matthew</dc:creator>
 <dc:creator>Lozin, Vadim V.</dc:creator>
 <dc:creator>Paulusma, Dani&#xeb;l</dc:creator>
 <dc:creator>Zamaraev, Viktor</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C75</dc:subject>
 <dc:description>  Clique-width is an important graph parameter due to its algorithmic and
structural properties. A graph class is hereditary if it can be characterized
by a (not necessarily finite) set ${\cal H}$ of forbidden induced subgraphs. We
initiate a systematic study into the boundedness of clique-width of hereditary
graph classes closed under complementation. First, we extend the known
classification for the $|{\cal H}|=1$ case by classifying the boundedness of
clique-width for every set ${\cal H}$ of self-complementary graphs. We then
completely settle the $|{\cal H}|=2$ case. In particular, we determine one new
class of $(H,\overline{H})$-free graphs of bounded clique-width (as a side
effect, this leaves only six classes of $(H_1,H_2)$-free graphs, for which it
is not known whether their clique-width is bounded). Once we have obtained the
classification of the $|{\cal H}|=2$ case, we research the effect of forbidding
self-complementary graphs on the boundedness of clique-width. Surprisingly, we
show that for a set ${\cal F}$ of self-complementary graphs on at least five
vertices, the classification of the boundedness of clique-width for
$(\{H,\overline{H}\}\cup {\cal F})$-free graphs coincides with the one for the
$|{\cal H}|=2$ case if and only if ${\cal F}$ does not include the bull (the
only non-empty self-complementary graphs on fewer than five vertices are $P_1$
and $P_4$, and $P_4$-free graphs have clique-width at most $2$). Finally, we
discuss the consequences of our results for the Colouring problem.
</dc:description>
 <dc:description>Comment: 39 pages, 7 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07686</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the computational complexity of dynamic slicing problems for program
  schemas</dc:title>
 <dc:creator>Danicic, Sebastian</dc:creator>
 <dc:creator>Hierons, Robert M.</dc:creator>
 <dc:creator>Laurence, Michael R.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Given a program, a quotient can be obtained from it by deleting zero or more
statements. The field of program slicing is concerned with computing a quotient
of a program which preserves part of the behaviour of the original program. All
program slicing algorithms take account of the structural properties of a
program such as control dependence and data dependence rather than the
semantics of its functions and predicates, and thus work, in effect, with
program schemas. The dynamic slicing criterion of Korel and Laski requires only
that program behaviour is preserved in cases where the original program follows
a particular path, and that the slice/quotient follows this path. In this paper
we formalise Korel and Laski's definition of a dynamic slice as applied to
linear schemas, and also formulate a less restrictive definition in which the
path through the original program need not be preserved by the slice. The less
restrictive definition has the benefit of leading to smaller slices. For both
definitions, we compute complexity bounds for the problems of establishing
whether a given slice of a linear schema is a dynamic slice and whether a
linear schema has a non-trivial dynamic slice and prove that the latter problem
is NP-hard in both cases. We also give an example to prove that minimal dynamic
slices (whether or not they preserve the original path) need not be unique.
</dc:description>
 <dc:description>Comment: 26 pages, already published</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07686</dc:identifier>
 <dc:identifier>Mathematical Structures in Computer Science, vol. 21, pp.
  1339-1362, 2011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07687</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>W2VLDA: Almost Unsupervised System for Aspect Based Sentiment Analysis</dc:title>
 <dc:creator>Garc&#xed;a-Pablos, Aitor</dc:creator>
 <dc:creator>Cuadros, Montse</dc:creator>
 <dc:creator>Rigau, German</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  With the increase of online customer opinions in specialised websites and
social networks, the necessity of automatic systems to help to organise and
classify customer reviews by domain-specific aspect/categories and sentiment
polarity is more important than ever. Supervised approaches to Aspect Based
Sentiment Analysis obtain good results for the domain/language their are
trained on, but having manually labelled data for training supervised systems
for all domains and languages are usually very costly and time consuming. In
this work we describe W2VLDA, an almost unsupervised system based on topic
modelling, that combined with some other unsupervised methods and a minimal
configuration, performs aspect/category classifiation,
aspect-terms/opinion-words separation and sentiment polarity classification for
any given domain and language. We evaluate the performance of the aspect and
sentiment classification in the multilingual SemEval 2016 task 5 (ABSA)
dataset. We show competitive results for several languages (English, Spanish,
French and Dutch) and domains (hotels, restaurants, electronic-devices).
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07692</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Softmax Loss for Zero-Shot Learning</dc:title>
 <dc:creator>Ji, Zhong</dc:creator>
 <dc:creator>Sun, Yunxin</dc:creator>
 <dc:creator>Yu, Yulong</dc:creator>
 <dc:creator>Guo, Jichang</dc:creator>
 <dc:creator>Pang, Yanwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A typical pipeline for Zero-Shot Learning (ZSL) is to integrate the visual
features and the class semantic descriptors into a multimodal framework with a
linear or bilinear model. However, the visual features and the class semantic
descriptors locate in different structural spaces, a linear or bilinear model
can not capture the semantic interactions between different modalities well. In
this letter, we propose a nonlinear approach to impose ZSL as a multi-class
classification problem via a Semantic Softmax Loss by embedding the class
semantic descriptors into the softmax layer of multi-class classification
network. To narrow the structural differences between the visual features and
semantic descriptors, we further use an L2 normalization constraint to the
differences between the visual features and visual prototypes reconstructed
with the semantic descriptors. The results on three benchmark datasets, i.e.,
AwA, CUB and SUN demonstrate the proposed approach can boost the performances
steadily and achieve the state-of-the-art performance for both zero-shot
classification and zero-shot retrieval.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07695</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Sensing with Prior Information via Maximizing Correlation</dc:title>
 <dc:creator>Zhang, Xu</dc:creator>
 <dc:creator>Cui, Wei</dc:creator>
 <dc:creator>Liu, Yulong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Compressed sensing (CS) with prior information concerns the problem of
reconstructing a sparse signal with the aid of a similar signal which is known
beforehand. We consider a new approach to integrate the prior information into
CS via maximizing the correlation between the prior knowledge and the desired
signal. We then present a geometric analysis for the proposed method under
sub-Gaussian measurements. Our results reveal that if the prior information is
good enough, then the proposed approach can improve the performance of the
standard CS. Simulations are provided to verify our results.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of IEEE International Symposium on
  Information Theory 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07704</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Regularized Framework for Sparse and Structured Neural Attention</dc:title>
 <dc:creator>Niculae, Vlad</dc:creator>
 <dc:creator>Blondel, Mathieu</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Modern neural networks are often augmented with an attention mechanism, which
tells the network where to focus within the input. We propose in this paper a
new framework for sparse and structured attention, building upon a smoothed max
operator. We show that the gradient of this operator defines a mapping from
real values to probabilities, suitable as an attention mechanism. Our framework
includes softmax and a slight generalization of the recently-proposed sparsemax
as special cases. However, we also show how our framework can incorporate
modern structured penalties, resulting in more interpretable attention
mechanisms, that focus on entire segments or groups of an input. We derive
efficient algorithms to compute the forward and backward passes of our
attention mechanisms, enabling their use in a neural network trained with
backpropagation. To showcase their potential as a drop-in replacement for
existing ones, we evaluate our attention mechanisms on three large-scale tasks:
textual entailment, machine translation, and sentence summarization. Our
attention mechanisms improve interpretability without sacrificing performance;
notably, on textual entailment and summarization, we outperform the standard
attention mechanisms based on softmax and sparsemax.
</dc:description>
 <dc:description>Comment: Published in NIPS 2017. 23 pages, including appendix</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07706</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Out-of-the-box Full-network Embedding for Convolutional Neural
  Networks</dc:title>
 <dc:creator>Garcia-Gasulla, Dario</dc:creator>
 <dc:creator>Vilalta, Armand</dc:creator>
 <dc:creator>Par&#xe9;s, Ferran</dc:creator>
 <dc:creator>Moreno, Jonatan</dc:creator>
 <dc:creator>Ayguad&#xe9;, Eduard</dc:creator>
 <dc:creator>Labarta, Jesus</dc:creator>
 <dc:creator>Cort&#xe9;s, Ulises</dc:creator>
 <dc:creator>Suzumura, Toyotaro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Transfer learning for feature extraction can be used to exploit deep
representations in contexts where there is very few training data, where there
are limited computational resources, or when tuning the hyper-parameters needed
for training is not an option. While previous contributions to feature
extraction propose embeddings based on a single layer of the network, in this
paper we propose a full-network embedding which successfully integrates
convolutional and fully connected features, coming from all layers of a deep
convolutional neural network. To do so, the embedding normalizes features in
the context of the problem, and discretizes their values to reduce noise and
regularize the embedding space. Significantly, this also reduces the
computational cost of processing the resultant representations. The proposed
method is shown to outperform single layer embeddings on several image
classification tasks, while also being more robust to the choice of the
pre-trained model used for obtaining the initial features. The performance gap
in classification accuracy between thoroughly tuned solutions and the
full-network embedding is also reduced, which makes of the proposed approach a
competitive solution for a large set of applications.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07728</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved method for finding optimal formulae for bilinear maps in a
  finite field</dc:title>
 <dc:creator>Covanov, Svyatoslav</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  In 2012, Barbulescu, Detrey, Estibals and Zimmermann proposed a new framework
to exhaustively search for optimal formulae for evaluating bilinear maps, such
as Strassen or Karatsuba formulae. The main contribution of this work is a new
criterion to aggressively prune useless branches in the exhaustive search, thus
leading to the computation of new optimal formulae, in particular for the short
product modulo $X^5$ and the circulant product modulo $(X^5 - 1)$. Moreover ,
we are able to prove that there is essentially only one optimal decomposition
of the product of $3 \times 2$ by $2 \times 3$ matrices up to the action of
some group of automorphisms.
</dc:description>
 <dc:date>2017-05-09</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07730</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Application of the Computer Capacity to the Analysis of Processors
  Evolution</dc:title>
 <dc:creator>Ryabko, Boris</dc:creator>
 <dc:creator>Rakitskiy, Anton</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>B.0</dc:subject>
 <dc:description>  The notion of computer capacity was proposed in 2012, and this quantity has
been estimated for computers of different kinds.
  In this paper we show that, when designing new processors, the manufacturers
change the parameters that affect the computer capacity. This allows us to
predict the values of parameters of future processors. As the main example we
use Intel processors, due to the accessibility of detailed description of all
their technical characteristics.
</dc:description>
 <dc:date>2017-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07746</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Taming Near Repeat Calculation for Crime Analysis via Cohesive Subgraph
  Computing</dc:title>
 <dc:creator>Yin, Zhaoming</dc:creator>
 <dc:creator>Shi, Xuan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Near repeat (NR) is a well known phenomenon in crime analysis assuming that
crime events exhibit cor- relations within a given time and space frame.
Traditional NR calculation generates 2 event pairs if 2 events happened within
a given space and time limit. When the number of events is large, however, NR
calculation is time consuming and how these pairs are organized are not yet
explored. In this paper, we designed a new approach to calculate clusters of NR
events efficiently. To begin with, R-tree is utilized to index crime events, a
single event is represented by a vertex whereas edges are constructed by range
querying the vertex in R-tree, and a graph is formed. Cohesive subgraph
approaches are applied to identify the event chains. k-clique, k-truss, k- core
plus DBSCAN algorithms are implemented in sequence with respect to their varied
range of ability to find cohesive subgraphs. Real world crime data in Chicago,
New York and Washington DC are utilized to conduct experiments. The experiment
confirmed that near repeat is a solid effect in real big crime data by
conducting Mapreduce empowered knox tests. The performance of 4 different
algorithms are validated, while the quality of the algorithms are gauged by the
distribution of number of cohesive subgraphs and their clustering coefficients.
The proposed framework is the first to process the real crime data of million
record scale, and is the first to detect NR events with size of more than 2.
</dc:description>
 <dc:description>Comment: To appear, 14th International Symposium on Pervasive Systems,
  Algorithms, and Networks (I-SPAN 2017)</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07747</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What does it all mean? Capturing Semantics of Surgical Data and
  Algorithms with Ontologies</dc:title>
 <dc:creator>Kati&#x107;, Darko</dc:creator>
 <dc:creator>Maleshkova, Maria</dc:creator>
 <dc:creator>Engelhardt, Sandy</dc:creator>
 <dc:creator>Wolf, Ivo</dc:creator>
 <dc:creator>M&#xe4;rz, Keno</dc:creator>
 <dc:creator>Maier-Hein, Lena</dc:creator>
 <dc:creator>Nolden, Marco</dc:creator>
 <dc:creator>Wagner, Martin</dc:creator>
 <dc:creator>Kenngott, Hannes</dc:creator>
 <dc:creator>M&#xfc;ller-Stich, Beat Peter</dc:creator>
 <dc:creator>Dillmann, R&#xfc;diger</dc:creator>
 <dc:creator>Speidel, Stefanie</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Every year approximately 234 million major surgeries are performed, leading
to plentiful, highly diverse data. This is accompanied by a matching number of
novel algorithms for the surgical domain. To garner all benefits of surgical
data science it is necessary to have an unambiguous, shared understanding of
algorithms and data. This includes inputs and outputs of algorithms and thus
their function, but also the semantic content, i.e. meaning of data such as
patient parameters. We therefore propose the establishment of a new ontology
for data and algorithms in surgical data science. Such an ontology can be used
to provide common data sets for the community, encouraging sharing of knowledge
and comparison of algorithms on common data. We hold that this is a necessary
foundation towards new methods for applications such as semantic-based content
retrieval and similarity measures and that it is overall vital for the future
of surgical data science.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, Surgical Data Science Workshop, Heidelberg, June
  20th, 2016</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07750</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</dc:title>
 <dc:creator>Carreira, Joao</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The paucity of videos in current action classification datasets (UCF-101 and
HMDB-51) has made it difficult to identify good video architectures, as most
methods obtain similar performance on existing small-scale benchmarks. This
paper re-evaluates state-of-the-art architectures in light of the new Kinetics
Human Action Video dataset. Kinetics has two orders of magnitude more data,
with 400 human action classes and over 400 clips per class, and is collected
from realistic, challenging YouTube videos. We provide an analysis on how
current architectures fare on the task of action classification on this dataset
and how much performance improves on the smaller benchmark datasets after
pre-training on Kinetics.
  We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on
2D ConvNet inflation: filters and pooling kernels of very deep image
classification ConvNets are expanded into 3D, making it possible to learn
seamless spatio-temporal feature extractors from video while leveraging
successful ImageNet architecture designs and even their parameters. We show
that, after pre-training on Kinetics, I3D models considerably improve upon the
state-of-the-art in action classification, reaching 80.7% on HMDB-51 and 98.0%
on UCF-101.
</dc:description>
 <dc:description>Comment: Added results on the full Kinetics dataset test set. Fixed typo in
  table 4</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07750</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07755</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving classification accuracy of feedforward neural networks for
  spiking neuromorphic chips</dc:title>
 <dc:creator>Yepes, Antonio Jimeno</dc:creator>
 <dc:creator>Tang, Jianbin</dc:creator>
 <dc:creator>Mashford, Benjamin Scott</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Neural Networks (DNN) achieve human level performance in many image
analytics tasks but DNNs are mostly deployed to GPU platforms that consume a
considerable amount of power. New hardware platforms using lower precision
arithmetic achieve drastic reductions in power consumption. More recently,
brain-inspired spiking neuromorphic chips have achieved even lower power
consumption, on the order of milliwatts, while still offering real-time
processing.
  However, for deploying DNNs to energy efficient neuromorphic chips the
incompatibility between continuous neurons and synaptic weights of traditional
DNNs, discrete spiking neurons and synapses of neuromorphic chips need to be
overcome. Previous work has achieved this by training a network to learn
continuous probabilities, before it is deployed to a neuromorphic architecture,
such as IBM TrueNorth Neurosynaptic System, by random sampling these
probabilities.
  The main contribution of this paper is a new learning algorithm that learns a
TrueNorth configuration ready for deployment. We achieve this by training
directly a binary hardware crossbar that accommodates the TrueNorth axon
configuration constrains and we propose a different neuron model.
  Results of our approach trained on electroencephalogram (EEG) data show a
significant improvement with previous work (76% vs 86% accuracy) while
maintaining state of the art performance on the MNIST handwritten data set.
</dc:description>
 <dc:description>Comment: IJCAI-2017. arXiv admin note: text overlap with arXiv:1605.07740</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07756</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the BWT and LCP array of a Set of Strings in External Memory</dc:title>
 <dc:creator>Bonizzoni, Paola</dc:creator>
 <dc:creator>Della Vedova, Gianluca</dc:creator>
 <dc:creator>Pirola, Yuri</dc:creator>
 <dc:creator>Previtali, Marco</dc:creator>
 <dc:creator>Rizzi, Raffaella</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Indexing very large collections of strings, such as those produced by the
widespread next generation sequencing technologies, heavily relies on
multi-string generalization of the Burrows-Wheeler Transform (BWT): recent
developments in this field have resulted in external memory algorithms,
motivated by the large requirements of in-memory approaches.
  The related problem of computing the Longest Common Prefix (LCP) array of a
set of strings is often instrumental in several algorithms: for example, to
compute the suffix-prefix overlaps among strings, which is an essential step
for many genome assembly algorithms.
  In this paper we propose a new external memory method to simultaneously build
the BWT and the LCP array on a collection of $m$ strings of length $k$ with
$O(mkl)$ time and I/O complexity, using $O(k + m)$ main memory, where $l$ is
the maximum value in the LCP array.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1607.08342</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07767</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The language of Stratified Sets is confluent and strongly normalising</dc:title>
 <dc:creator>Gabbay, Murdoch J.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study the properties of the language of Stratified Sets (first-order logic
with $\in$ and a stratification condition) as used in TST, TZT, and (with
stratifiability instead of stratification) in Quine's NF. We find that the
syntax forms a nominal algebra for substitution and that stratification and
stratifiability imply confluence and strong normalisation under rewrites
corresponding naturally to $\beta$-conversion.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07768</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Associate Words and Images Using a Large-scale Graph</dc:title>
 <dc:creator>Ya, Heqing</dc:creator>
 <dc:creator>Sun, Haonan</dc:creator>
 <dc:creator>Helt, Jeffrey</dc:creator>
 <dc:creator>Lee, Tai Sing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop an approach for unsupervised learning of associations between
co-occurring perceptual events using a large graph. We applied this approach to
successfully solve the image captcha of China's railroad system. The approach
is based on the principle of suspicious coincidence. In this particular
problem, a user is presented with a deformed picture of a Chinese phrase and
eight low-resolution images. They must quickly select the relevant images in
order to purchase their train tickets. This problem presents several
challenges: (1) the teaching labels for both the Chinese phrases and the images
were not available for supervised learning, (2) no pre-trained deep
convolutional neural networks are available for recognizing these Chinese
phrases or the presented images, and (3) each captcha must be solved within a
few seconds. We collected 2.6 million captchas, with 2.6 million deformed
Chinese phrases and over 21 million images. From these data, we constructed an
association graph, composed of over 6 million vertices, and linked these
vertices based on co-occurrence information and feature similarity between
pairs of images. We then trained a deep convolutional neural network to learn a
projection of the Chinese phrases onto a 230-dimensional latent space. Using
label propagation, we computed the likelihood of each of the eight images
conditioned on the latent space projection of the deformed phrase for each
captcha. The resulting system solved captchas with 77% accuracy in 2 seconds on
average. Our work, in answering this practical challenge, illustrates the power
of this class of unsupervised association learning techniques, which may be
related to the brain's general strategy for associating language stimuli with
visual objects on the principle of suspicious coincidence.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, 14th Conference on Computer and Robot Vision 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07768</dc:identifier>
 <dc:identifier>doi:10.1109/CRV.2017.52</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07771</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation Experiment of BCI Based on Imagined Speech EEG Decoding</dc:title>
 <dc:creator>Wang, Kang</dc:creator>
 <dc:creator>Wang, Xueqian</dc:creator>
 <dc:creator>Li, Gang</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Brain Computer Interface (BCI) can help patients of neuromuscular diseases
restore parts of the movement and communication abilities that they have lost.
Most of BCIs rely on mapping brain activities to device instructions, but
limited number of brain activities decides the limited abilities of BCIs. To
deal with the problem of limited ablility of BCI, this paper verified the
feasibility of constructing BCI based on decoding imagined speech
electroencephalography (EEG). As sentences decoded from EEG can have rich
meanings, BCIs based on EEG decoding can achieve numerous control instructions.
By combining a modified EEG feature extraction mehtod with connectionist
temporal classification (CTC), this paper simulated decoding imagined speech
EEG using synthetic EEG data without help of speech signal. The performance of
decoding model over synthetic data to a certain extent demonstrated the
feasibility of constructing BCI based on imagined speech brain signal.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07772</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Networks with MuxOut Layers as Multi-rate Systems for
  Image Upscaling</dc:title>
 <dc:creator>Michelini, Pablo Navarrete</dc:creator>
 <dc:creator>Liu, Hanwen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We interpret convolutional networks as adaptive filters and combine them with
so-called MuxOut layers to efficiently upscale low resolution images. We
formalize this interpretation by deriving a linear and space-variant structure
of a convolutional network when its activations are fixed. We introduce general
purpose algorithms to analyze a network and show its overall filter effect for
each given location. We use this analysis to evaluate two types of image
upscalers: deterministic upscalers that target the recovery of details from
original content; and second, a new generation of upscalers that can sample the
distribution of upscale aliases (images that share the same downscale version)
that look like real content.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07774</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Follow the Signs for Robust Stochastic Optimization</dc:title>
 <dc:creator>Balles, Lukas</dc:creator>
 <dc:creator>Hennig, Philipp</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic noise on gradients is now a common feature in machine learning. It
complicates the design of optimization algorithms, and its effect can be
unintuitive: We show that in some settings, particularly those of low
signal-to-noise ratio, it can be helpful to discard all but the signs of
stochastic gradient elements. In fact, we argue that three popular existing
methods already approximate this very paradigm. We devise novel stochastic
optimization algorithms that explicitly follow stochastic sign estimates while
appropriately accounting for their uncertainty. These methods favorably compare
to the state of the art on a number of benchmark problems.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07774</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07777</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Localized Multi-view Subspace Clustering</dc:title>
 <dc:creator>Fan, Yanbo</dc:creator>
 <dc:creator>Liang, Jian</dc:creator>
 <dc:creator>He, Ran</dc:creator>
 <dc:creator>Hu, Bao-Gang</dc:creator>
 <dc:creator>Lyu, Siwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In multi-view clustering, different views may have different confidence
levels when learning a consensus representation. Existing methods usually
address this by assigning distinctive weights to different views. However, due
to noisy nature of real-world applications, the confidence levels of samples in
the same view may also vary. Thus considering a unified weight for a view may
lead to suboptimal solutions. In this paper, we propose a novel localized
multi-view subspace clustering model that considers the confidence levels of
both views and samples. By assigning weight to each sample under each view
properly, we can obtain a robust consensus representation via fusing the
noiseless structures among views and samples. We further develop a regularizer
on weight parameters based on the convex conjugacy theory, and samples weights
are determined in an adaptive manner. An efficient iterative algorithm is
developed with a convergence guarantee. Experimental results on four benchmarks
demonstrate the correctness and effectiveness of the proposed model.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07779</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cost-Performance Tradeoffs in Fusing Unreliable Computational Units</dc:title>
 <dc:creator>Donmez, Mehmet A.</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:creator>Singer, Andrew C.</dc:creator>
 <dc:creator>Varshney, Lav R.</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  We investigate fusing several unreliable computational units that perform the
same task. We model an unreliable computational outcome as an additive
perturbation to its error-free result in terms of its fidelity and cost. We
analyze performance of repetition-based strategies that distribute cost across
several unreliable units and fuse their outcomes. When the cost is a convex
function of fidelity, the optimal repetition-based strategy in terms of
incurred cost while achieving a target mean-square error (MSE) performance may
fuse several computational units. For concave and linear costs, a single more
reliable unit incurs lower cost compared to fusion of several lower cost and
less reliable units while achieving the same MSE performance. We show how our
results give insight into problems from theoretical neuroscience, circuits, and
crowdsourcing.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07785</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An improvement of the asymptotic Elias bound for non-binary codes</dc:title>
 <dc:creator>Kaipa, Krishna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For non-binary codes the Elias bound is a good upper bound for the asymptotic
information rate at low relative minimum distance, where as the Plotkin bound
is better at high relative minimum distance. In this work, we obtain a hybrid
of these bounds which improves both. This in turn is based on the anticode
bound which is a hybrid of the Hamming and Singleton bounds and improves both
bounds.
  The question of convexity of the asymptotic rate function is an important
open question. We conjecture a much weaker form of the convexity, and we show
that our bounds follow immediately if we assume the conjecture.
</dc:description>
 <dc:description>Comment: revised version. changes mainly in appendix</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07788</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>StegIbiza: Steganography in Club Music Implemented in Python</dc:title>
 <dc:creator>Szczypiorski, Krzysztof</dc:creator>
 <dc:creator>Zydecki, Wojciech</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper introduces the implementation of steganography method called
StegIbiza, which uses tempo modulation as hidden message carrier. With the use
of Python scripting language, a bit string was encoded and decoded using WAV
and MP3 files. Once the message was hidden into a music files, an internet
radio was created to evaluate broadcast possibilities. No dedicated music or
signal processing equipment was used in this StegIbiza implementation
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, 1 table</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07795</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep Networks without Learning Rates Through Coin Betting</dc:title>
 <dc:creator>Orabona, Francesco</dc:creator>
 <dc:creator>Tommasi, Tatiana</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning methods achieve state-of-the-art performance in many
application scenarios. Yet, these methods require a significant amount of
hyperparameters tuning in order to achieve the best results. In particular,
tuning the learning rates in the stochastic optimization process is still one
of the main bottlenecks. In this paper, we propose a new stochastic gradient
descent procedure for deep networks that does not require any learning rate
setting. Contrary to previous methods, we do not adapt the learning rates nor
we make use of the assumed curvature of the objective function. Instead, we
reduce the optimization process to a game of betting on a coin and propose a
learning-rate-free optimal algorithm for this scenario. Theoretical convergence
is proven for convex and quasi-convex functions and empirical evidence shows
the advantage of our algorithm over popular stochastic gradient algorithms.
</dc:description>
 <dc:description>Comment: Camera-ready version for NIPS 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07795</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07798</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A unified view of entropy-regularized Markov decision processes</dc:title>
 <dc:creator>Neu, Gergely</dc:creator>
 <dc:creator>Jonsson, Anders</dc:creator>
 <dc:creator>G&#xf3;mez, Vicen&#xe7;</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a general framework for entropy-regularized average-reward
reinforcement learning in Markov decision processes (MDPs). Our approach is
based on extending the linear-programming formulation of policy optimization in
MDPs to accommodate convex regularization functions. Our key result is showing
that using the conditional entropy of the joint state-action distributions as
regularization yields a dual optimization problem closely resembling the
Bellman optimality equations. This result enables us to formalize a number of
state-of-the-art entropy-regularized reinforcement learning algorithms as
approximate variants of Mirror Descent or Dual Averaging, and thus to argue
about the convergence properties of these methods. In particular, we show that
the exact version of the TRPO algorithm of Schulman et al. (2015) actually
converges to the optimal policy, while the entropy-regularized policy gradient
methods of Mnih et al. (2016) may fail to converge to a fixed point. Finally,
we illustrate empirically the effects of using various regularization
techniques on learning performance in a simple reinforcement learning setup.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07807</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use Privacy in Data-Driven Systems: Theory and Experiments with Machine
  Learnt Programs</dc:title>
 <dc:creator>Datta, Anupam</dc:creator>
 <dc:creator>Fredrikson, Matthew</dc:creator>
 <dc:creator>Ko, Gihyuk</dc:creator>
 <dc:creator>Mardziel, Piotr</dc:creator>
 <dc:creator>Sen, Shayak</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents an approach to formalizing and enforcing a class of use
privacy properties in data-driven systems. In contrast to prior work, we focus
on use restrictions on proxies (i.e. strong predictors) of protected
information types. Our definition relates proxy use to intermediate
computations that occur in a program, and identify two essential properties
that characterize this behavior: 1) its result is strongly associated with the
protected information type in question, and 2) it is likely to causally affect
the final output of the program. For a specific instantiation of this
definition, we present a program analysis technique that detects instances of
proxy use in a model, and provides a witness that identifies which parts of the
corresponding program exhibit the behavior. Recognizing that not all instances
of proxy use of a protected information type are inappropriate, we make use of
a normative judgment oracle that makes this inappropriateness determination for
a given witness. Our repair algorithm uses the witness of an inappropriate
proxy use to transform the model into one that provably does not exhibit proxy
use, while avoiding changes that unduly affect classification accuracy. Using a
corpus of social datasets, our evaluation shows that these algorithms are able
to detect proxy use instances that would be difficult to find using existing
techniques, and subsequently remove them while maintaining acceptable
classification performance.
</dc:description>
 <dc:description>Comment: extended CCS 2017 camera-ready: several new discussions, and
  complexity results added to appendix</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07809</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-theoretic analysis of generalization capability of learning
  algorithms</dc:title>
 <dc:creator>Xu, Aolin</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We derive upper bounds on the generalization error of a learning algorithm in
terms of the mutual information between its input and output. The bounds
provide an information-theoretic understanding of generalization in learning
problems, and give theoretical guidelines for striking the right balance
between data fit and generalization by controlling the input-output mutual
information. We propose a number of methods for this purpose, among which are
algorithms that regularize the ERM algorithm with relative entropy or with
random noise. Our work extends and leads to nontrivial improvements on the
recent results of Russo and Zou.
</dc:description>
 <dc:description>Comment: Final version, accepted to NIPS 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07815</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimax Statistical Learning and Domain Adaptation with Wasserstein
  Distances</dc:title>
 <dc:creator>Lee, Jaeho</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As opposed to standard empirical risk minimization (ERM), distributionally
robust optimization aims to minimize the worst-case risk over a larger
ambiguity set containing the original empirical distribution of the training
data. In this work, we describe a minimax framework for statistical learning
with ambiguity sets given by balls in Wasserstein space. In particular, we
prove a generalization bound that involves the covering number properties of
the original ERM problem. As an illustrative example, we provide generalization
guarantees for domain adaptation problems where the Wasserstein distance
between the source and target domain distributions can be reliably estimated
from unlabeled samples.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07817</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sparse hierarchical interaction learning with epigraphical projection</dc:title>
 <dc:creator>Jiu, Mingyuan</dc:creator>
 <dc:creator>Pustelnik, Nelly</dc:creator>
 <dc:creator>Janaqi, Stefan</dc:creator>
 <dc:creator>Chebre, Meriam</dc:creator>
 <dc:creator>Ricoux, Philippe</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This work focus on regression optimization problem with hierarchical
interactions between variables, which is beyond the additive models in the
traditional linear regression. We investigate more specifically two different
fashions encountered in the literature to deal with this problem: &quot;hierNet&quot; and
structural-sparsity regularization, and study their connections. We propose a
primal-dual proximal algorithm based on epigraphical projection to optimize a
general formulation of this learning problem. The experimental setting first
highlights the improvement of the proposed procedure compared to
state-of-the-art methods based on fast iterative shrinkage-thresholding
algorithm (i.e. FISTA) or alternating direction method of multipliers (i.e.
ADMM) and second we provide fair comparisons between the different hierarchical
penalizations. The experiments are conducted both on the synthetic and real
data, and they clearly show that the proposed primal-dual proximal algorithm
based on epigraphical projection is efficient and effective to solve and
investigate the question of the hierarchical interaction learning problem.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07818</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for
  Video Action Segmentation</dc:title>
 <dc:creator>Ding, Li</dc:creator>
 <dc:creator>Xu, Chenliang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action segmentation as a milestone towards building automatic systems to
understand untrimmed videos has received considerable attention in the recent
years. It is typically being modeled as a sequence labeling problem but
contains intrinsic and sufficient differences than text parsing or speech
processing. In this paper, we introduce a novel hybrid temporal convolutional
and recurrent network (TricorNet), which has an encoder-decoder architecture:
the encoder consists of a hierarchy of temporal convolutional kernels that
capture the local motion changes of different actions; the decoder is a
hierarchy of recurrent neural networks that are able to learn and memorize
long-term action dependencies after the encoding stage. Our model is simple but
extremely effective in terms of video sequence labeling. The experimental
results on three public action segmentation datasets have shown that the
proposed model achieves superior performance over the state of the art.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07819</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularizing deep networks using efficient layerwise adversarial
  training</dc:title>
 <dc:creator>Sankaranarayanan, Swami</dc:creator>
 <dc:creator>Jain, Arpit</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:creator>Lim, Ser Nam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adversarial training has been shown to regularize deep neural networks in
addition to increasing their robustness to adversarial examples. However, its
impact on very deep state of the art networks has not been fully investigated.
In this paper, we present an efficient approach to perform adversarial training
by perturbing intermediate layer activations and study the use of such
perturbations as a regularizer during training. We use these perturbations to
train very deep models such as ResNets and show improvement in performance both
on adversarial and original test data. Our experiments highlight the benefits
of perturbing intermediate layer activations compared to perturbing only the
inputs. The results on CIFAR-10 and CIFAR-100 datasets show the merits of the
proposed adversarial training approach. Additional results on WideResNets show
that our approach provides significant improvement in classification accuracy
for a given base model, outperforming dropout and other base models of larger
size.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07823</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On deep holes of generalized projective Reed-Solomon codes</dc:title>
 <dc:creator>Xu, Xiaofan</dc:creator>
 <dc:creator>Hong, Shaofang</dc:creator>
 <dc:creator>Xu, Yongchao</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Determining deep holes is an important topic in decoding Reed-Solomon codes.
Let $l\ge 1$ be an integer and $a_1,\ldots,a_l$ be arbitrarily given $l$
distinct elements of the finite field ${\bf F}_q$ of $q$ elements with the odd
prime number $p$ as its characteristic. Let $D={\bf
F}_q\backslash\{a_1,\ldots,a_l\}$ and $k$ be an integer such that $2\le k\le
q-l-1$. In this paper, we study the deep holes of generalized projective
Reed-Solomon code ${\rm GPRS}_q(D, k)$ of length $q-l+1$ and dimension $k$ over
${\bf F}_q$. For any $f(x)\in {\bf F}_q[x]$, we let
$f(D)=(f(y_1),\ldots,f(y_{q-l}))$ if $D=\{y_1, ..., y_{q-l}\}$ and
$c_{k-1}(f(x))$ be the coefficient of $x^{k-1}$ of $f(x)$. By using D\&quot;ur's
theorem on the relation between the covering radius and minimum distance of
${\rm GPRS}_q(D, k)$, we show that if $u(x)\in {\bf F}_q[x]$ with $\deg
(u(x))=k$, then the received codeword $(u(D), c_{k-1}(u(x)))$ is a deep hole of
${\rm GPRS}_q(D, k)$ if and only if the sum $\sum\limits_{y\in I}y$ is nonzero
for any subset $I\subseteq D$ with $\#(I)=k$. We show also that if $j$ is an
integer with $1\leq j\leq l$ and $u_j(x):= \lambda_j(x-a_j)^{q-2}+\nu_j
x^{k-1}+f_{\leq k-2}^{(j)}(x)$ with $\lambda_j\in {\bf F}_q^*$, $\nu_j\in {\bf
F}_q$ and $f_{\leq{k-2}}^{(j)}(x)\in{\bf F}_q[x]$ being a polynomial of degree
at most $k-2$, then $(u_j(D), c_{k-1}(u_j(x)))$ is a deep hole of ${\rm
GPRS}_q(D, k)$ if and only if the sum
$\binom{q-2}{k-1}(-a_j)^{q-1-k}\prod\limits_{y\in I}(a_j-y)+e$ is nonzero for
any subset $I\subseteq D$ with $\#(I)=k$, where $e$ is the identity of the
group ${\bf F}_q^*$. This implies that $(u_j(D), c_{k-1}(u_j(x)))$ is a deep
hole of ${\rm GPRS}_q(D, k)$ if $p|k$.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07826</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Machine Learning for Output Tracking</dc:title>
 <dc:creator>Devasia, Santosh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article develops iterative machine learning (IML) for output tracking.
The input-output data generated during iterations to develop the model used in
the iterative update. The main contribution of this article to propose the use
of kernel-based machine learning to iteratively update both the model and the
model-inversion-based input simultaneously. Additionally, augmented inputs with
persistency of excitation are proposed to promote learning of the model during
the iteration process. The proposed approach is illustrated with a simulation
example.
</dc:description>
 <dc:description>Comment: 8 figures, Submitted to Journal</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07826</dc:identifier>
 <dc:identifier>IEEE Transactions on Control Systems Technology, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TCST.2017.2772807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07830</identifier>
 <datestamp>2017-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ask the Right Questions: Active Question Reformulation with
  Reinforcement Learning</dc:title>
 <dc:creator>Buck, Christian</dc:creator>
 <dc:creator>Bulian, Jannis</dc:creator>
 <dc:creator>Ciaramita, Massimiliano</dc:creator>
 <dc:creator>Gajewski, Wojciech</dc:creator>
 <dc:creator>Gesmundo, Andrea</dc:creator>
 <dc:creator>Houlsby, Neil</dc:creator>
 <dc:creator>Wang, Wei</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We frame Question Answering as a Reinforcement Learning task, an approach
that we call Active Question Answering. We propose an agent that sits between
the user and a black box question-answering system an which learns to
reformulate questions to elicit the best possible answers. The agent probes the
system with, potentially many, natural language reformulations of an initial
question and aggregates the returned evidence to yield the best answer. The
reformulation system is trained end-to-end to maximize answer quality using
policy gradient. We evaluate on SearchQA, a dataset of complex questions
extracted from Jeopardy!. Our agent improves F1 by 11% over a state-of-the-art
base model that uses the original question/answer pairs.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07831</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizing GAN Training with Multiple Random Projections</dc:title>
 <dc:creator>Neyshabur, Behnam</dc:creator>
 <dc:creator>Bhojanapalli, Srinadh</dc:creator>
 <dc:creator>Chakrabarti, Ayan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training generative adversarial networks is unstable in high-dimensions when
the true data distribution lies on a lower-dimensional manifold. The
discriminator is then easily able to separate nearly all generated samples
leaving the generator without meaningful gradients. We propose training a
single generator simultaneously against an array of discriminators, each of
which looks at a different random low-dimensional projection of the data. We
show that individual discriminators then provide stable gradients to the
generator, and that the generator learns to produce samples consistent with the
full data distribution to satisfy all discriminators. We demonstrate the
practical utility of this approach experimentally, and show that it is able to
produce image samples with higher quality than traditional training with a
single discriminator.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07834</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Information Gathering via Imitation Learning</dc:title>
 <dc:creator>Choudhury, Sanjiban</dc:creator>
 <dc:creator>Kapoor, Ashish</dc:creator>
 <dc:creator>Ranade, Gireeja</dc:creator>
 <dc:creator>Scherer, Sebastian</dc:creator>
 <dc:creator>Dey, Debadeepta</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In the adaptive information gathering problem, a policy is required to select
an informative sensing location using the history of measurements acquired thus
far. While there is an extensive amount of prior work investigating effective
practical approximations using variants of Shannon's entropy, the efficacy of
such policies heavily depends on the geometric distribution of objects in the
world. On the other hand, the principled approach of employing online POMDP
solvers is rendered impractical by the need to explicitly sample online from a
posterior distribution of world maps.
  We present a novel data-driven imitation learning framework to efficiently
train information gathering policies. The policy imitates a clairvoyant oracle
- an oracle that at train time has full knowledge about the world map and can
compute maximally informative sensing locations. We analyze the learnt policy
by showing that offline imitation of a clairvoyant oracle is implicitly
equivalent to online oracle execution in conjunction with posterior sampling.
This observation allows us to obtain powerful near-optimality guarantees for
information gathering problems possessing an adaptive sub-modularity property.
As demonstrated on a spectrum of 2D and 3D exploration problems, the trained
policies enjoy the best of both worlds - they adapt to different world map
distributions while being computationally inexpensive to evaluate.
</dc:description>
 <dc:description>Comment: Robotics Science and Systems, 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07839</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on QoE-oriented Wireless Resources Scheduling</dc:title>
 <dc:creator>Sousa, Ivo</dc:creator>
 <dc:creator>Queluz, Maria Paula</dc:creator>
 <dc:creator>Rodrigues, Ant&#xf3;nio</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Future wireless systems are expected to provide a wide range of services to
more and more users. Advanced scheduling strategies thus arise not only to
perform efficient radio resource management, but also to provide fairness among
the users. On the other hand, the users' perceived quality, i.e., Quality of
Experience (QoE), is becoming one of the main drivers within the schedulers
design. In this context, this paper starts by providing a comprehension of what
is QoE and an overview of the evolution of wireless scheduling techniques.
Afterwards, a survey on the most recent QoE-based scheduling strategies for
wireless systems is presented, highlighting the application/service of the
different approaches reported in the literature, as well as the parameters that
were taken into account for QoE optimization. Therefore, this paper aims at
helping readers interested in learning the basic concepts of QoE-oriented
wireless resources scheduling, as well as getting in touch with the present
time research frontier.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07844</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DepthCut: Improved Depth Edge Estimation Using Multiple Unreliable
  Channels</dc:title>
 <dc:creator>Guerrero, Paul</dc:creator>
 <dc:creator>Winnem&#xf6;ller, Holger</dc:creator>
 <dc:creator>Li, Wilmot</dc:creator>
 <dc:creator>Mitra, Niloy J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the context of scene understanding, a variety of methods exists to
estimate different information channels from mono or stereo images, including
disparity, depth, and normals. Although several advances have been reported in
the recent years for these tasks, the estimated information is often imprecise
particularly near depth discontinuities or creases. Studies have however shown
that precisely such depth edges carry critical cues for the perception of
shape, and play important roles in tasks like depth-based segmentation or
foreground selection. Unfortunately, the currently extracted channels often
carry conflicting signals, making it difficult for subsequent applications to
effectively use them. In this paper, we focus on the problem of obtaining
high-precision depth edges (i.e., depth contours and creases) by jointly
analyzing such unreliable information channels. We propose DepthCut, a
data-driven fusion of the channels using a convolutional neural network trained
on a large dataset with known depth. The resulting depth edges can be used for
segmentation, decomposing a scene into depth layers with relatively flat depth,
or improving the accuracy of the depth estimate near depth edges by
constraining its gradients to agree with these edges. Quantitatively, we
compare against 15 variants of baselines and demonstrate that our depth edges
result in an improved segmentation performance and an improved depth estimate
near depth edges compared to data-agnostic channel fusion. Qualitatively, we
demonstrate that the depth edges result in superior segmentation and depth
orderings.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07848</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Testbed for Experimenting Internet of Things Applications</dc:title>
 <dc:creator>Patel, Parthkumar</dc:creator>
 <dc:creator>Dave, Jayraj</dc:creator>
 <dc:creator>Dalal, Shreedhar</dc:creator>
 <dc:creator>Patel, Pankesh</dc:creator>
 <dc:creator>Chaudhary, Sanjay</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The idea of IoT world has grown to multiple dimensions enclosing different
technologies and standards which can provide solutions and goal oriented
intelligence to the widespread things via network or internet. In spite of
different advancement in technology, challenges related to assessment of IoT
solutions under real scenarios and empirical deployments still hinder their
evolvement and significant expansion. To design a system that can adequately
bolster substantial range of applications and be compliant with superfluity of
divergent requirements and also integrating heterogeneous technologies is a
difficult task. Thus, simulations and testing to design robust applications
becomes paramount elements of a development process. For this, there rises a
need of a tool or a methodology to test and manage the applications. This paper
presents a novel approach by proposing a testbed for experimenting Internet of
Things (IoT) applications. An idea of an open source test bed helps in
developing an exploited and sustainable smart system. In order to validate the
idea of such testbed we have also implemented two use cases.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07853</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric Online Regression while Learning the Metric</dc:title>
 <dc:creator>Kuzborskij, Ilja</dc:creator>
 <dc:creator>Cesa-Bianchi, Nicol&#xf2;</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study algorithms for online nonparametric regression that learn the
directions along which the regression function is smoother. Our algorithm
learns the Mahalanobis metric based on the gradient outer product matrix
$\boldsymbol{G}$ of the regression function (automatically adapting to the
effective rank of this matrix), while simultaneously bounding the regret ---on
the same data sequence--- in terms of the spectrum of $\boldsymbol{G}$. As a
preliminary step in our analysis, we extend a nonparametric online learning
algorithm by Hazan and Megiddo enabling it to compete against functions whose
Lipschitzness is measured with respect to an arbitrary Mahalanobis metric.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07853</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07860</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-the-fly Operation Batching in Dynamic Computation Graphs</dc:title>
 <dc:creator>Neubig, Graham</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Dynamic neural network toolkits such as PyTorch, DyNet, and Chainer offer
more flexibility for implementing models that cope with data of varying
dimensions and structure, relative to toolkits that operate on statically
declared computations (e.g., TensorFlow, CNTK, and Theano). However, existing
toolkits - both static and dynamic - require that the developer organize the
computations into the batches necessary for exploiting high-performance
algorithms and hardware. This batching task is generally difficult, but it
becomes a major hurdle as architectures become complex. In this paper, we
present an algorithm, and its implementation in the DyNet toolkit, for
automatically batching operations. Developers simply write minibatch
computations as aggregations of single instance computations, and the batching
algorithm seamlessly executes them, on the fly, using computationally efficient
batched operations. On a variety of tasks, we obtain throughput similar to that
obtained with manual batches, as well as comparable speedups over
single-instance learning on architectures that are impractical to batch
manually.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07861</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetry Breaking in the Congest Model: Time- and Message-Efficient
  Algorithms for Ruling Sets</dc:title>
 <dc:creator>Pai, Shreyas</dc:creator>
 <dc:creator>Pandurangan, Gopal</dc:creator>
 <dc:creator>Pemmaraju, Sriram V.</dc:creator>
 <dc:creator>Riaz, Talal</dc:creator>
 <dc:creator>Robinson, Peter</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study local symmetry breaking problems in the CONGEST model, focusing on
ruling set problems, which generalize the fundamental Maximal Independent Set
(MIS) problem. A $\beta$-ruling set is an independent set such that every node
in the graph is at most $\beta$ hops from a node in the independent set. Our
work is motivated by the following central question: can we break the
$\Theta(\log n)$ time complexity barrier and the $\Theta(m)$ message complexity
barrier in the CONGEST model for MIS or closely-related symmetry breaking
problems? We present the following results:
  - Time Complexity: We show that we can break the $O(\log n)$ &quot;barrier&quot; for 2-
and 3-ruling sets. We compute 3-ruling sets in $O\left(\frac{\log n}{\log \log
n}\right)$ rounds with high probability (whp). More generally we show that
2-ruling sets can be computed in $O\left(\log \Delta \cdot (\log n)^{1/2 +
\varepsilon} + \frac{\log n}{\log\log n}\right)$ rounds for any $\varepsilon &gt;
0$, which is $o(\log n)$ for a wide range of $\Delta$ values (e.g., $\Delta =
2^{(\log n)^{1/2-\varepsilon}}$). These are the first 2- and 3-ruling set
algorithms to improve over the $O(\log n)$-round complexity of Luby's algorithm
in the CONGEST model.
  - Message Complexity: We show an $\Omega(n^2)$ lower bound on the message
complexity of computing an MIS (i.e., 1-ruling set) which holds also for
randomized algorithms and present a contrast to this by showing a randomized
algorithm for 2-ruling sets that, whp, uses only $O(n \log^2 n)$ messages and
runs in $O(\Delta \log n)$ rounds. This is the first message-efficient
algorithm known for ruling sets, which has message complexity nearly linear in
$n$ (which is optimal up to a polylogarithmic factor).
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07862</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nucleus: A Pilot Project</dc:title>
 <dc:creator>Finnell, Joshua</dc:creator>
 <dc:creator>Klein, Martin</dc:creator>
 <dc:creator>Cain, Brian J.</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Early in 2016, an environmental scan was conducted by the Research Library
Data Working Group for three purposes:
  1.) Perform a survey of the data management landscape at Los Alamos National
Laboratory in order to identify local gaps in data management services.
  2.) Conduct an environmental scan of external institutions to benchmark
budgets, infrastructure, and personnel dedicated to data management.
  3.) Draft a research data infrastructure model that aligns with the current
workflow and classification restrictions at Los Alamos National Laboratory.
  This report is a summary of those activities and the draft for a pilot data
management project.
</dc:description>
 <dc:description>Comment: 13 pages, report</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07863</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finite Blocklength Rates over a Fading Channel with CSIT and CSIR</dc:title>
 <dc:creator>K, Deekshith P</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we obtain lower and upper bounds on the maximal transmission
rate at a given codeword length $n$, average probability of error $\epsilon$
and power constraint $\bar{P}$, over a finite valued, block fading additive
white Gaussian noise (AWGN) channel with channel state information (CSI) at the
transmitter and the receiver. These bounds characterize deviation of the finite
blocklength coding rates from the channel capacity which is in turn achieved by
the water filling power allocation across time. The bounds obtained also
characterize the rate enhancement possible due to the CSI at the transmitter in
the finite blocklength regime. The results are further elucidated via numerical
examples.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, results for finite valued fading states, typos
  corrected, proofs elaborated, lower bound under short term power constraint
  improved</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07867</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SmartPaste: Learning to Adapt Source Code</dc:title>
 <dc:creator>Allamanis, Miltiadis</dc:creator>
 <dc:creator>Brockschmidt, Marc</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Deep Neural Networks have been shown to succeed at a range of natural
language tasks such as machine translation and text summarization. While tasks
on source code (ie, formal languages) have been considered recently, most work
in this area does not attempt to capitalize on the unique opportunities offered
by its known syntax and structure. In this work, we introduce SmartPaste, a
first task that requires to use such information. The task is a variant of the
program repair problem that requires to adapt a given (pasted) snippet of code
to surrounding, existing source code. As first solutions, we design a set of
deep neural models that learn to represent the context of each variable
location and variable usage in a data flow-sensitive way. Our evaluation
suggests that our models can learn to solve the SmartPaste task in many cases,
achieving 58.6% accuracy, while learning meaningful representation of variable
usages.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07871</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facial Expression Recognition Using Enhanced Deep 3D Convolutional
  Neural Networks</dc:title>
 <dc:creator>Hasani, Behzad</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Neural Networks (DNNs) have shown to outperform traditional methods in
various visual recognition tasks including Facial Expression Recognition (FER).
In spite of efforts made to improve the accuracy of FER systems using DNN,
existing methods still are not generalizable enough in practical applications.
This paper proposes a 3D Convolutional Neural Network method for FER in videos.
This new network architecture consists of 3D Inception-ResNet layers followed
by an LSTM unit that together extracts the spatial relations within facial
images as well as the temporal relations between different frames in the video.
Facial landmark points are also used as inputs to our network which emphasize
on the importance of facial components rather than the facial regions that may
not contribute significantly to generating facial expressions. Our proposed
method is evaluated using four publicly available databases in
subject-independent and cross-database tasks and outperforms state-of-the-art
methods.
</dc:description>
 <dc:description>Comment: To appear in 2017 IEEE Conference on Computer Vision and Pattern
  Recognition Workshops (CVPRW)</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07874</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Approach to Interpreting Model Predictions</dc:title>
 <dc:creator>Lundberg, Scott</dc:creator>
 <dc:creator>Lee, Su-In</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Understanding why a model makes a certain prediction can be as crucial as the
prediction's accuracy in many applications. However, the highest accuracy for
large modern datasets is often achieved by complex models that even experts
struggle to interpret, such as ensemble or deep learning models, creating a
tension between accuracy and interpretability. In response, various methods
have recently been proposed to help users interpret the predictions of complex
models, but it is often unclear how these methods are related and when one
method is preferable over another. To address this problem, we present a
unified framework for interpreting predictions, SHAP (SHapley Additive
exPlanations). SHAP assigns each feature an importance value for a particular
prediction. Its novel components include: (1) the identification of a new class
of additive feature importance measures, and (2) theoretical results showing
there is a unique solution in this class with a set of desirable properties.
The new class unifies six existing methods, notable because several recent
methods in the class lack the proposed desirable properties. Based on insights
from this unification, we present new methods that show improved computational
performance and/or better consistency with human intuition than previous
approaches.
</dc:description>
 <dc:description>Comment: To appear in NIPS 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07877</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Block building programming for symbolic regression</dc:title>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Luo, Changtong</dc:creator>
 <dc:creator>Jiang, Zonglin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Symbolic regression that aims to detect underlying data-driven models has
become increasingly important for industrial data analysis. For most existing
algorithms such as genetic programming (GP), the convergence speed might be too
slow for large-scale problems with a large number of variables. This situation
may become even worse with increasing problem size. The aforementioned
difficulty makes symbolic regression limited in practical applications.
Fortunately, in many engineering problems, the independent variables in target
models are separable or partially separable. This feature inspires us to
develop a new approach, block building programming (BBP). BBP divides the
original target function into several blocks, and further into factors. The
factors are then modeled by an optimization engine (e.g. GP). Under such
circumstances, BBP can make large reductions to the search space. The partition
of separability is based on a special method, block and factor detection. Two
different optimization engines are applied to test the performance of BBP on a
set of symbolic regression problems. Numerical results show that BBP has a good
capability of structure and coefficient optimization with high computational
efficiency.
</dc:description>
 <dc:description>Comment: Accepted for publication in Neurocomputing</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07878</identifier>
 <datestamp>2018-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep
  Learning</dc:title>
 <dc:creator>Wen, Wei</dc:creator>
 <dc:creator>Xu, Cong</dc:creator>
 <dc:creator>Yan, Feng</dc:creator>
 <dc:creator>Wu, Chunpeng</dc:creator>
 <dc:creator>Wang, Yandan</dc:creator>
 <dc:creator>Chen, Yiran</dc:creator>
 <dc:creator>Li, Hai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  High network communication cost for synchronizing gradients and parameters is
the well-known bottleneck of distributed training. In this work, we propose
TernGrad that uses ternary gradients to accelerate distributed deep learning in
data parallelism. Our approach requires only three numerical levels {-1,0,1},
which can aggressively reduce the communication time. We mathematically prove
the convergence of TernGrad under the assumption of a bound on gradients.
Guided by the bound, we propose layer-wise ternarizing and gradient clipping to
improve its convergence. Our experiments show that applying TernGrad on AlexNet
does not incur any accuracy loss and can even improve accuracy. The accuracy
loss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a
performance model is proposed to study the scalability of TernGrad. Experiments
show significant speed gains for various deep neural networks. Our source code
is available.
</dc:description>
 <dc:description>Comment: NIPS 2017 Oral</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07879</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancement of Epidemiological Models for Dengue Fever Based on Twitter
  Data</dc:title>
 <dc:creator>Albinati, Julio</dc:creator>
 <dc:creator>Meira Jr., Wagner</dc:creator>
 <dc:creator>Pappa, Gisele L.</dc:creator>
 <dc:creator>Teixeira, Mauro</dc:creator>
 <dc:creator>Marques-Toledo, Cecilia</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Epidemiological early warning systems for dengue fever rely on up-to-date
epidemiological data to forecast future incidence. However, epidemiological
data typically requires time to be available, due to the application of
time-consuming laboratorial tests. This implies that epidemiological models
need to issue predictions with larger antecedence, making their task even more
difficult. On the other hand, online platforms, such as Twitter or Google,
allow us to obtain samples of users' interaction in near real-time and can be
used as sensors to monitor current incidence. In this work, we propose a
framework to exploit online data sources to mitigate the lack of up-to-date
epidemiological data by obtaining estimates of current incidence, which are
then explored by traditional epidemiological models. We show that the proposed
framework obtains more accurate predictions than alternative approaches, with
statistically better results for delays greater or equal to 4 weeks.
</dc:description>
 <dc:description>Comment: ACM Digital Health 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07881</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Factorization and Partition of Complex Networks From Random Walks</dc:title>
 <dc:creator>Yang, Lin F.</dc:creator>
 <dc:creator>Braverman, Vladimir</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:creator>Wang, Mengdi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Finding the reduced-dimensional structure is critical to understanding
complex networks. Existing approaches such as spectral clustering are
applicable only when the full network is explicitly observed. In this paper, we
focus on the online factorization and partition of implicit large-scale
networks based on observations from an associated random walk. We formulate
this into a nonconvex stochastic factorization problem and propose an efficient
and scalable stochastic generalized Hebbian algorithm. The algorithm is able to
process dependent state-transition data dynamically generated by the underlying
network and learn a low-dimensional representation for each vertex. By applying
a diffusion approximation analysis, we show that the continuous-time limiting
process of the stochastic algorithm converges globally to the &quot;principal
components&quot; of the Markov chain and achieves a nearly optimal sample
complexity. Once given the learned low-dimensional representations, we further
apply clustering techniques to recover the network partition. We show that when
the associated Markov process is lumpable, one can recover the partition
exactly with high probability. We apply the proposed approach to model the
traffic flow of Manhattan as city-wide random walks. By using our algorithm to
analyze the taxi trip data, we discover a latent partition of the Manhattan
city that closely matches the traffic dynamics.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07884</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Facial Affect Estimation in the Wild Using Deep Residual and
  Convolutional Networks</dc:title>
 <dc:creator>Hasani, Behzad</dc:creator>
 <dc:creator>Mahoor, Mohammad H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automated affective computing in the wild is a challenging task in the field
of computer vision. This paper presents three neural network-based methods
proposed for the task of facial affect estimation submitted to the First
Affect-in-the-Wild challenge. These methods are based on Inception-ResNet
modules redesigned specifically for the task of facial affect estimation. These
methods are: Shallow Inception-ResNet, Deep Inception-ResNet, and
Inception-ResNet with LSTMs. These networks extract facial features in
different scales and simultaneously estimate both the valence and arousal in
each frame. Root Mean Square Error (RMSE) rates of 0.4 and 0.3 are achieved for
the valence and arousal respectively with corresponding Concordance Correlation
Coefficient (CCC) rates of 0.04 and 0.29 using Deep Inception-ResNet method.
</dc:description>
 <dc:description>Comment: To appear in 2017 IEEE Conference on Computer Vision and Pattern
  Recognition Workshops (CVPRW)</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07904</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantically Decomposing the Latent Spaces of Generative Adversarial
  Networks</dc:title>
 <dc:creator>Donahue, Chris</dc:creator>
 <dc:creator>Lipton, Zachary C.</dc:creator>
 <dc:creator>Balsubramani, Akshay</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new algorithm for training generative adversarial networks that
jointly learns latent codes for both identities (e.g. individual humans) and
observations (e.g. specific photographs). By fixing the identity portion of the
latent codes, we can generate diverse images of the same subject, and by fixing
the observation portion, we can traverse the manifold of subjects while
maintaining contingent aspects such as lighting and pose. Our algorithm
features a pairwise training scheme in which each sample from the generator
consists of two images with a common identity code. Corresponding samples from
the real dataset consist of two distinct photographs of the same subject. In
order to fool the discriminator, the generator must produce pairs that are
photorealistic, distinct, and appear to depict the same individual. We augment
both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate
pairwise training. Experiments with human judges and an off-the-shelf face
verification system demonstrate our algorithm's ability to generate convincing,
identity-matched photographs.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07940</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Uplink/Downlink Resource Allocation and Data Offloading in
  OFDMA-Based Wireless Powered HetNets</dc:title>
 <dc:creator>Rezvani, Sepehr</dc:creator>
 <dc:creator>Mokari, Nader</dc:creator>
 <dc:creator>Javan, Mohammad R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>90C11</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  This paper considers joint uplink/downlink of an orthogonal frequency
division multiple access (OFDMA)-based heterogeneous network (HetNet)
consisting of a single macro base station (MBS), multiple femto base stations
(FBSs) and access points (APs) where base stations (BSs) can offload data to
APs and each mobile user (MU) is able to harvest the received energy using the
simultaneous wireless information and power transfer (SWIPT) technique. We also
suppose that the harvested energy of MUs are used for their uplink information
transmission. We devise a radio resource allocation (RRA) algorithm to maximize
the uplink sum data rate of MUs subject to a minimum required downlink data
rate of each MU and maximum allowable transmit power of each BS, AP, and MU.
More specifically, both the frequency division duplex (FDD) and time division
duplex (TDD) schemes are investigated. The proposed non-convex optimization
problems are solved using an iterative algorithm. It is also proved that the
proposed algorithm converges to a near-optimal solution. Simulation results
illustrate that the TDD scheme improves the performance compared to the FDD
scheme. In addition, it is shown that utilizing the data offloading technique
improves the uplink sum data rate of MUs compared to the scenario without any
AP.
</dc:description>
 <dc:description>Comment: 36 pages, 11 figures, Submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07951</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tourists' digital footprint in cities: comparing big data sources</dc:title>
 <dc:creator>Salas-Olmedo, Maria Henar</dc:creator>
 <dc:creator>Garcia-Palomares, Juan Carlos</dc:creator>
 <dc:creator>Gutierrez, Javier</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  There is little knowledge available on the spatial behaviour of urban
tourists, and yet tourists generate an enormous quantity of data (Big Data)
when they visit cities. These data sources can be used to track their presence
through their activities. The aim of this paper is to analyse the digital
footprint of urban tourists through Big Data. Unlike other papers that use a
single data source, this article examines three sources of data to reflect
different tourism activities in cities: Panoramio (sightseeing), Foursquare
(consumption), and Twitter (being connected). Tourist density in the three data
sources is compared via maps, correlation analysis (OLS) and spatial
self-correlation analysis (Global Moran's I statistic and LISA). Finally the
data are integrated using cluster analysis and combining the spatial clusters
identified in the LISA analysis in the different data sources. The results show
that the data from the three activities are partly spatially redundant and
partly complementary, and allow the characterisation of multifunction tourist
spaces (with several activities) and spaces specialising in one or various
activities (for example, sightseeing and consumption). The case study analysed
(Madrid) reveals a significant presence of tourists in the city centre, and
increasing specialisation from the centre outwards towards the periphery. The
main conclusion of the paper is that it is not sufficient to use one data
source to analyse the presence of tourists in cities; several must be used in a
complementary manner.
</dc:description>
 <dc:description>Comment: 20 pages,8 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07956</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The pulse of the city through Twitter: relationships between land use
  and spatiotemporal demographics</dc:title>
 <dc:creator>Garcia-Palomares, Juan Carlos</dc:creator>
 <dc:creator>Salas-Olmedo, Maria Henar</dc:creator>
 <dc:creator>Moya-Gomez, Borja</dc:creator>
 <dc:creator>Condeco-Melhorado, Ana</dc:creator>
 <dc:creator>Gutierrrez, Javier</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Social network data offer interesting opportunities in urban studies. In this
study, we used Twitter data to analyse city dynamics over the course of the
day. Users of this social network were grouped according to city zone and time
slot in order to analyse the daily dynamics of the city and the relationship
between this and land use. First, daytime activity in each zone was compared
with activity at night in order to determine which zones showed increased
activity in each of the time slots. Then, typical Twitter activity profiles
were obtained based on the predominant land use in each zone, indicating how
land uses linked to activities were activated during the day, but at different
rates depending on the type of land use. Lastly, a multiple regression analysis
was performed to determine the influence of the different land uses on each of
the major time slots (morning, afternoon, evening and night) through their
changing coefficients. Activity tended to decrease throughout the day for most
land uses (e.g. offices, education, health and transport), but remained
constant in parks and increased in retail and residential zones. Our results
show that social network data can be used to improve our understanding of the
link between land use and urban dynamics.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07957</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large Scale Empirical Risk Minimization via Truncated Adaptive Newton
  Method</dc:title>
 <dc:creator>Eisen, Mark</dc:creator>
 <dc:creator>Mokhtari, Aryan</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider large scale empirical risk minimization (ERM) problems, where
both the problem dimension and variable size is large. In these cases, most
second order methods are infeasible due to the high cost in both computing the
Hessian over all samples and computing its inverse in high dimensions. In this
paper, we propose a novel adaptive sample size second-order method, which
reduces the cost of computing the Hessian by solving a sequence of ERM problems
corresponding to a subset of samples and lowers the cost of computing the
Hessian inverse using a truncated eigenvalue decomposition. We show that while
we geometrically increase the size of the training set at each stage, a single
iteration of the truncated Newton method is sufficient to solve the new ERM
within its statistical accuracy. Moreover, for a large number of samples we are
allowed to double the size of the training set at each stage, and the proposed
method subsequently reaches the statistical accuracy of the full training set
approximately after two effective passes. In addition to this theoretical
result, we show empirically on a number of well known data sets that the
proposed truncated adaptive sample size algorithm outperforms stochastic
alternatives for solving ERM problems.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07957</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07961</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compatible extensions and consistent closures: a fuzzy approach</dc:title>
 <dc:creator>Georgescu, Irina</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper $\ast$--compatible extensions of fuzzy relations are studied,
generalizing some results obtained by Duggan in case of crisp relations. From
this general result are obtained as particular cases fuzzy versions of some
important extension theorems for crisp relations (Szpilrajn, Hansson,
Suzumura). Two notions of consistent closure of a fuzzy relation are
introduced.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07962</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>pix2code: Generating Code from a Graphical User Interface Screenshot</dc:title>
 <dc:creator>Beltramelli, Tony</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>68T45</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Transforming a graphical user interface screenshot created by a designer into
computer code is a typical task conducted by a developer in order to build
customized software, websites, and mobile applications. In this paper, we show
that deep learning methods can be leveraged to train a model end-to-end to
automatically generate code from a single input image with over 77% of accuracy
for three different platforms (i.e. iOS, Android and web-based technologies).
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07972</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal 3D Wearable Fingerprint Targets: Advancing Fingerprint Reader
  Evaluations</dc:title>
 <dc:creator>Engelsma, Joshua J.</dc:creator>
 <dc:creator>Arora, Sunpreet S.</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:creator>Paulter Jr, Nicholas G.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present the design and manufacturing of high fidelity universal 3D
fingerprint targets, which can be imaged on a variety of fingerprint sensing
technologies, namely capacitive, contact-optical, and contactless-optical.
Universal 3D fingerprint targets enable, for the first time, not only a
repeatable and controlled evaluation of fingerprint readers, but also the
ability to conduct fingerprint reader interoperability studies. Fingerprint
reader interoperability refers to how robust fingerprint recognition systems
are to variations in the images acquired by different types of fingerprint
readers. To build universal 3D fingerprint targets, we adopt a molding and
casting framework consisting of (i) digital mapping of fingerprint images to a
negative mold, (ii) CAD modeling a scaffolding system to hold the negative
mold, (iii) fabricating the mold and scaffolding system with a high resolution
3D printer, (iv) producing or mixing a material with similar electrical,
optical, and mechanical properties to that of the human finger, and (v)
fabricating a 3D fingerprint target using controlled casting. Our experiments
conducted with PIV and Appendix F certified optical (contact and contactless)
and capacitive fingerprint readers demonstrate the usefulness of universal 3D
fingerprint targets for controlled and repeatable fingerprint reader
evaluations and also fingerprint reader interoperability studies.
</dc:description>
 <dc:description>Comment: 14 pages, 14 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07980</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting stock market movements using network science: An information
  theoretic approach</dc:title>
 <dc:creator>Kim, Minjun</dc:creator>
 <dc:creator>Sayama, Hiroki</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  A stock market is considered as one of the highly complex systems, which
consists of many components whose prices move up and down without having a
clear pattern. The complex nature of a stock market challenges us on making a
reliable prediction of its future movements. In this paper, we aim at building
a new method to forecast the future movements of Standard &amp; Poor's 500 Index
(S&amp;P 500) by constructing time-series complex networks of S&amp;P 500 underlying
companies by connecting them with links whose weights are given by the mutual
information of 60-minute price movements of the pairs of the companies with the
consecutive 5,340 minutes price records. We showed that the changes in the
strength distributions of the networks provide an important information on the
network's future movements. We built several metrics using the strength
distributions and network measurements such as centrality, and we combined the
best two predictors by performing a linear combination. We found that the
combined predictor and the changes in S&amp;P 500 show a quadratic relationship,
and it allows us to predict the amplitude of the one step future change in S&amp;P
500. The result showed significant fluctuations in S&amp;P 500 Index when the
combined predictor was high. In terms of making the actual index predictions,
we built ARIMA models. We found that adding the network measurements into the
ARIMA models improves the model accuracy. These findings are useful for
financial market policy makers as an indicator based on which they can
interfere with the markets before the markets make a drastic change, and for
quantitative investors to improve their forecasting models.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07983</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Liquid Cloud Storage</dc:title>
 <dc:creator>Luby, Michael G.</dc:creator>
 <dc:creator>Padovani, Roberto</dc:creator>
 <dc:creator>Richardson, Thomas J.</dc:creator>
 <dc:creator>Minder, Lorenz</dc:creator>
 <dc:creator>Aggarwal, Pooja</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A liquid system provides durable object storage based on spreading
redundantly generated data across a network of hundreds to thousands of
potentially unreliable storage nodes. A liquid system uses a combination of a
large code, lazy repair, and a flow storage organization. We show that a liquid
system can be operated to enable flexible and essentially optimal combinations
of storage durability, storage overhead, repair bandwidth usage, and access
performance.
</dc:description>
 <dc:description>Comment: 44 pages, 21 figures, 1 table</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07993</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair Allocation based on Diminishing Differences</dc:title>
 <dc:creator>Segal-Halevi, Erel</dc:creator>
 <dc:creator>Aziz, Haris</dc:creator>
 <dc:creator>Hassidim, Avinatan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Ranking alternatives is a natural way for humans to explain their
preferences. It is being used in many settings, such as school choice (NY,
Boston), course allocations, and the Israeli medical lottery. In some cases
(such as the latter two), several &quot;items&quot; are given to each participant.
Without having any information on the underlying cardinal utilities, arguing
about fairness of allocation requires extending the ordinal item ranking to
ordinal bundle ranking. The most commonly used such extension is stochastic
dominance (SD), where a bundle X is preferred over a bundle Y if its score is
better according to all additive score functions. SD is a very conservative
extension, by which few allocations are necessarily fair while many allocations
are possibly fair.
  We propose to make a natural assumption on the underlying cardinal utilities
of the players, namely that the difference between two items at the top is at
least as large as the difference between two items down the list. This
assumption implies a preference extension which we call diminishing differences
(DD), where a X is preferred over Y if its score is better according to all
additive score functions satisfying the DD assumption.
  We give a full characterization of allocations that are
necessarily-proportional or possibly-proportional according to this assumption.
Based on this characterization, we present a polynomial-time algorithm for
finding a necessarily-DD-proportional allocation if it exists. Simulations
based on a simple random model show that with high probability, a
necessarily-proportional allocation does not exist but a
necessarily-DD-proportional allocation exists. Moreover, that allocation is
proportional according to the underlying cardinal utilities.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07993</dc:identifier>
 <dc:identifier>doi:10.24963/ijcai.2017/174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07996</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Living Together: Mind and Machine Intelligence</dc:title>
 <dc:creator>Lawrence, Neil D.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we consider the nature of the machine intelligences we have
created in the context of our human intelligence. We suggest that the
fundamental difference between human and machine intelligence comes down to
\emph{embodiment factors}. We define embodiment factors as the ratio between an
entity's ability to communicate information vs compute information. We
speculate on the role of embodiment factors in driving our own intelligence and
consciousness. We briefly review dual process models of cognition and cast
machine intelligence within that framework, characterising it as a dominant
System Zero, which can drive behaviour through interfacing with us
subconsciously. Driven by concerns about the consequence of such a system we
suggest prophylactic courses of action that could be considered. Our main
conclusion is that it is \emph{not} sentient intelligence we should fear but
\emph{non-sentient} intelligence.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07997</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Permutation Tests for Infection Graphs</dc:title>
 <dc:creator>Khim, Justin</dc:creator>
 <dc:creator>Loh, Po-Ling</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We formulate and analyze a hypothesis testing problem for inferring the edge
structure of an infection graph. Our model is as follows: A disease spreads
over a network via contagion and random infection, where uninfected nodes
contract the disease at a time corresponding to an independent exponential
random variable and infected nodes transmit the disease to uninfected neighbors
according to independent exponential random variables with an unknown rate
parameter. A subset of nodes is also censored, meaning the infection statuses
of the nodes are unobserved. Given the statuses of all nodes in the network,
the goal is to determine the underlying graph. Our procedure consists of a
permutation test, and we derive a condition in terms of automorphism groups of
the graphs corresponding to the null and alternative hypotheses that ensures
the validity of our test. Notably, the permutation test does not involve
estimating unknown parameters governing the infection process; instead, it
leverages differences in the topologies of the null and alternative graphs. We
derive risk bounds for our testing procedure in settings of interest; provide
extensions to situations involving relaxed versions of the algebraic condition;
and discuss multiple observations of infection spreads. We conclude with
experiments validating our results.
</dc:description>
 <dc:description>Comment: 28 pages, 5 figures, 1 table</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.07999</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GP-Unet: Lesion Detection from Weak Labels with a 3D Regression Network</dc:title>
 <dc:creator>Dubost, Florian</dc:creator>
 <dc:creator>Bortsova, Gerda</dc:creator>
 <dc:creator>Adams, Hieab</dc:creator>
 <dc:creator>Ikram, Arfan</dc:creator>
 <dc:creator>Niessen, Wiro</dc:creator>
 <dc:creator>Vernooij, Meike</dc:creator>
 <dc:creator>De Bruijne, Marleen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel convolutional neural network for lesion detection from
weak labels. Only a single, global label per image - the lesion count - is
needed for training. We train a regression network with a fully convolutional
architecture combined with a global pooling layer to aggregate the 3D output
into a scalar indicating the lesion count. When testing on unseen images, we
first run the network to estimate the number of lesions. Then we remove the
global pooling layer to compute localization maps of the size of the input
image. We evaluate the proposed network on the detection of enlarged
perivascular spaces in the basal ganglia in MRI. Our method achieves a
sensitivity of 62% with on average 1.5 false positives per image. Compared with
four other approaches based on intensity thresholding, saliency and class maps,
our method has a 20% higher sensitivity.
</dc:description>
 <dc:description>Comment: Article published in MICCAI 2017. We corrected a few errors from the
  first version: padding, loss, typos and update of the DOI number</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.07999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08000</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concurrent Channel Probing and Data Transmission in Full-duplex MIMO
  Systems</dc:title>
 <dc:creator>Qian, Zhenzhi</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Zheng, Zizhan</dc:creator>
 <dc:creator>Srinivasan, Kannan</dc:creator>
 <dc:creator>Shroff, Ness B.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An essential step for achieving multiplexing gain in MIMO downlink systems is
to collect accurate channel state information (CSI) from the users.
Traditionally, CSIs have to be collected before any data can be transmitted.
Such a sequential scheme incurs a large feedback overhead, which substantially
limits the multiplexing gain especially in a network with a large number of
users. In this paper, we propose a novel approach to mitigate the feedback
overhead by leveraging the recently developed Full-duplex radios. Our approach
is based on the key observation that using Full-duplex radios, when the
base-station (BS) is collecting CSI of one user through the uplink channel, it
can use the downlink channel to simultaneously transmit data to other
(non-interfering) users for which CSIs are already known. By allowing
concurrent channel probing and data transmission, our scheme can potentially
achieve a higher throughput compared to traditional schemes using Half-duplex
radios. The new flexibility introduced by our scheme, however, also leads to
fundamental challenges in achieving throughout optimal scheduling. In this
paper, we make an initial effort to this important problem by considering a
simplified group interference model. We develop a throughput optimal scheduling
policy with complexity $O((N/I)^I)$, where $N$ is the number of users and $I$
is the number of user groups. To further reduce the complexity, we propose a
greedy policy with complexity $O(N\log N)$ that not only achieves at least 2/3
of the optimal throughput region, but also outperforms any feasible Half-duplex
solutions. We derive the throughput gain offered by Full-duplex under different
system parameters and show the advantage of our algorithms through numerical
studies.
</dc:description>
 <dc:description>Comment: Technical report</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08009</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Low-Power Accelerator for Deep Neural Networks with Enlarged Near-Zero
  Sparsity</dc:title>
 <dc:creator>Huan, Yuxiang</dc:creator>
 <dc:creator>Qin, Yifan</dc:creator>
 <dc:creator>You, Yantian</dc:creator>
 <dc:creator>Zheng, Lirong</dc:creator>
 <dc:creator>Zou, Zhuo</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  It remains a challenge to run Deep Learning in devices with stringent power
budget in the Internet-of-Things. This paper presents a low-power accelerator
for processing Deep Neural Networks in the embedded devices. The power
reduction is realized by avoiding multiplications of near-zero valued data. The
near-zero approximation and a dedicated Near-Zero Approximation Unit (NZAU) are
proposed to predict and skip the near-zero multiplications under certain
thresholds. Compared with skipping zero-valued computations, our design
achieves 1.92X and 1.51X further reduction of the total multiplications in
LeNet-5 and Alexnet respectively, with negligible lose of accuracy. In the
proposed accelerator, 256 multipliers are grouped into 16 independent
Processing Lanes (PL) to support up to 16 neuron activations simultaneously.
With the help of data pre-processing and buffering in each PL, multipliers can
be clock-gated in most of the time even the data is excessively streaming in.
Designed and simulated in UMC 65 nm process, the accelerator operating at 500
MHz is $&gt;$ 4X faster than the mobile GPU Tegra K1 in processing the
fully-connected layer FC8 of Alexnet, while consuming 717X less energy.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08010</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Motion Planning for Aerial Surveillance on a Fixed-Wing UAV</dc:title>
 <dc:creator>Darbari, Vaibhav</dc:creator>
 <dc:creator>Gupta, Saksham</dc:creator>
 <dc:creator>Verma, Om Prakash</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present an efficient path planning algorithm for an Unmanned Aerial
Vehicle surveying a cluttered urban landscape. A special emphasis is on
maximizing area surveyed while adhering to constraints of the UAV and partially
known and updating environment. A Voronoi bias is introduced in the
probabilistic roadmap building phase to identify certain critical milestones
for maximal surveillance of the search space. A kinematically feasible but
coarse tour connecting these milestones is generated by the global path
planner. A local path planner then generates smooth motion primitives between
consecutive nodes of the global path based on UAV as a Dubins vehicle and
taking into account any impending obstacles. A Markov Decision Process (MDP)
models the control policy for the UAV and determines the optimal action to be
undertaken for evading the obstacles in the vicinity with minimal deviation
from current path. The efficacy of the proposed algorithm is evaluated in an
updating simulation environment with dynamic and static obstacles.
</dc:description>
 <dc:description>Comment: Accepted at International Conference on Unmanned Aircraft Systems
  2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08011</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Batch Normalization for Deep Neural Nets</dc:title>
 <dc:creator>Ma, Yintai</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Batch normalization (BN) is very effective in accelerating the convergence of
a neural network training phase that it has become a common practice. We
propose a generalization of BN, the diminishing batch normalization (DBN)
algorithm. We provide an analysis of the convergence of the DBN algorithm that
converges to a stationary point with respect to trainable parameters. We
analyze a two layer model with linear activation. The main challenge of the
analysis is the fact that some parameters are updated by gradient while others
are not. In the numerical experiments, we use models with more layers and ReLU
activation. We observe that DBN outperforms the original BN algorithm on MNIST,
NI and CIFAR-10 datasets with reasonable complex FNN and CNN models.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08012</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensing discomfort of standing passengers in public rail transportation
  systems using a smart phone</dc:title>
 <dc:creator>George, Thommen Karimpanal</dc:creator>
 <dc:creator>Gadhia, Harit Maganlal</dc:creator>
 <dc:creator>Sukumar, Ruben S/O</dc:creator>
 <dc:creator>Cabibihan, John-John</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This paper aims to investigate the effect of acceleration on the discomfort
of standing passengers. The acceleration levels from different public rail
transport lines such as the mass rapid transits (MRTs) and light rail transits
(LRTs) of Singapore, as well as the associated qualitative data indicating the
discomfort of standing passengers were collected and analyzed. Based on a
logistic regression model to analyze the data, a discomfort index was
introduced, which can be used to compare various rail lines based on ride
comfort. A method for predicting the discomfort of passengers based on the
acceleration values was proposed for any given train line.
</dc:description>
 <dc:description>Comment: Document prepared for IEEE International Conference on Control and
  Automation (ICCA), 2013, 5 pages, 8 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08012</dc:identifier>
 <dc:identifier>10th IEEE International Conference on Control &amp; Automation (IEEE
  ICCA 2013), HangZhou China, June 12-14, 2013, pp. 1509-1513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08014</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training Deep Convolutional Neural Networks with Resistive Cross-Point
  Devices</dc:title>
 <dc:creator>Gokmen, Tayfun</dc:creator>
 <dc:creator>Onen, O. Murat</dc:creator>
 <dc:creator>Haensch, Wilfried</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In a previous work we have detailed the requirements to obtain a maximal
performance benefit by implementing fully connected deep neural networks (DNN)
in form of arrays of resistive devices for deep learning. This concept of
Resistive Processing Unit (RPU) devices we extend here towards convolutional
neural networks (CNNs). We show how to map the convolutional layers to RPU
arrays such that the parallelism of the hardware can be fully utilized in all
three cycles of the backpropagation algorithm. We find that the noise and bound
limitations imposed due to analog nature of the computations performed on the
arrays effect the training accuracy of the CNNs. Noise and bound management
techniques are presented that mitigate these problems without introducing any
additional complexity in the analog circuits and can be addressed by the
digital circuits. In addition, we discuss digitally programmable update
management and device variability reduction techniques that can be used
selectively for some of the layers in a CNN. We show that combination of all
those techniques enables a successful application of the RPU concept for
training CNNs. The techniques discussed here are more general and can be
applied beyond CNN architectures and therefore enables applicability of RPU
approach for large class of neural network architectures.
</dc:description>
 <dc:description>Comment: 22 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08016</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training with Confusion for Fine-Grained Visual Classification</dc:title>
 <dc:creator>Dubey, Abhimanyu</dc:creator>
 <dc:creator>Gupta, Otkrist</dc:creator>
 <dc:creator>Guo, Pei</dc:creator>
 <dc:creator>Raskar, Ramesh</dc:creator>
 <dc:creator>Farrell, Ryan</dc:creator>
 <dc:creator>Naik, Nikhil</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Research in Fine-Grained Visual Classification has focused on tackling the
variations in pose, lighting, and viewpoint using sophisticated localization
and segmentation techniques, and the usage of robust texture features to
improve performance. In this work, we look at the fundamental optimization of
neural network training for fine-grained classification tasks with minimal
inter-class variance, and attempt to learn features with increased
generalization to prevent overfitting. We introduce Training-with-Confusion, an
optimization procedure for fine-grained classification tasks that regularizes
training by introducing confusion in activations. Our method can be generalized
to any fine-tuning task; it is robust to the presence of small training sets
and label noise; and adds no overhead to the prediction time. We find that
Training-with-Confusion improves the state-of-the-art on all major fine-grained
classification datasets.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08018</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use of Knowledge Graph in Rescoring the N-Best List in Automatic Speech
  Recognition</dc:title>
 <dc:creator>Kumar, Ashwini Jaya</dc:creator>
 <dc:creator>Morales, Camilo</dc:creator>
 <dc:creator>Vidal, Maria-Esther</dc:creator>
 <dc:creator>Schmidt, Christoph</dc:creator>
 <dc:creator>Auer, S&#xf6;ren</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  With the evolution of neural network based methods, automatic speech
recognition (ASR) field has been advanced to a level where building an
application with speech interface is a reality. In spite of these advances,
building a real-time speech recogniser faces several problems such as low
recognition accuracy, domain constraint, and out-of-vocabulary words. The low
recognition accuracy problem is addressed by improving the acoustic model,
language model, decoder and by rescoring the N-best list at the output of the
decoder. We are considering the N-best list rescoring approach to improve the
recognition accuracy. Most of the methods in the literature use the
grammatical, lexical, syntactic and semantic connection between the words in a
recognised sentence as a feature to rescore. In this paper, we have tried to
see the semantic relatedness between the words in a sentence to rescore the
N-best list. Semantic relatedness is computed using
TransE~\cite{bordes2013translating}, a method for low dimensional embedding of
a triple in a knowledge graph. The novelty of the paper is the application of
semantic web to automatic speech recognition.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08019</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ParaExp using Leapfrog as Integrator for High-Frequency Electromagnetic
  Simulations</dc:title>
 <dc:creator>Merkel, Melina</dc:creator>
 <dc:creator>Niyonzima, Innocent</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>78A40, 74F15, 65M06, 65Y05</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  Recently, ParaExp was proposed for the time integration of linear hyperbolic
problems. It splits the time interval of interest into sub-intervals and
computes the solution on each sub-interval in parallel. The overall solution is
decomposed into a particular solution defined on each sub-interval with zero
initial conditions and a homogeneous solution propagated by the matrix
exponential applied to the initial conditions. The efficiency of the method
depends on fast approximations of this matrix exponential based on recent
results from numerical linear algebra. This paper deals with the application of
ParaExp in combination with Leapfrog to electromagnetic wave problems in
time-domain. Numerical tests are carried out for a simple toy problem and a
realistic spiral inductor model discretized by the Finite Integration
Technique.
</dc:description>
 <dc:description>Comment: Corrected typos. arXiv admin note: text overlap with arXiv:1607.00368</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08030</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Stochastic Gradient Descent with Sound Combiners</dc:title>
 <dc:creator>Maleki, Saeed</dc:creator>
 <dc:creator>Musuvathi, Madanlal</dc:creator>
 <dc:creator>Mytkowicz, Todd</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Stochastic gradient descent (SGD) is a well known method for regression and
classification tasks. However, it is an inherently sequential algorithm at each
step, the processing of the current example depends on the parameters learned
from the previous examples. Prior approaches to parallelizing linear learners
using SGD, such as HOGWILD! and ALLREDUCE, do not honor these dependencies
across threads and thus can potentially suffer poor convergence rates and/or
poor scalability. This paper proposes SYMSGD, a parallel SGD algorithm that, to
a first-order approximation, retains the sequential semantics of SGD. Each
thread learns a local model in addition to a model combiner, which allows local
models to be combined to produce the same result as what a sequential SGD would
have produced. This paper evaluates SYMSGD's accuracy and performance on 6
datasets on a shared-memory machine shows upto 11x speedup over our heavily
optimized sequential baseline on 16 cores and 2.2x, on average, faster than
HOGWILD!.
</dc:description>
 <dc:description>Comment: 16 pages, 4 figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08033</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Everyone Benefit from Social Integration?</dc:title>
 <dc:creator>Ortega, Josue</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A12</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  We study the integration of stable marriage problems (SMPs) of equal sizes
into an extended society. We show that it is impossible to make every agent
weakly better off by merging all SMPs if the matching that occurs before and
after integration is stable. We show that integration always weakly benefits at
least one-half of the society, which implies that it can be implemented by
majority voting.
  A stronger pro-integration condition requires that no agent is hurt whenever
any number of SMPs merge sequentially. This property, that we call integration
monotonicity, is even incompatible with Pareto efficiency.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08037</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Temporal Effects of Mobile Blockers in Urban Millimeter-Wave
  Cellular Scenarios</dc:title>
 <dc:creator>Gapeyenko, Margarita</dc:creator>
 <dc:creator>Samuylov, Andrey</dc:creator>
 <dc:creator>Gerasimenko, Mikhail</dc:creator>
 <dc:creator>Moltchanov, Dmitri</dc:creator>
 <dc:creator>Singh, Sarabjot</dc:creator>
 <dc:creator>Akdeniz, Mustafa Riza</dc:creator>
 <dc:creator>Aryafar, Ehsan</dc:creator>
 <dc:creator>Himayat, Nageen</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Millimeter-wave (mmWave) propagation is known to be severely affected by the
blockage of the line-of-sight (LoS) path. In contrast to microwave systems, at
shorter mmWave wavelengths such blockage can be caused by human bodies, where
their mobility within environment makes wireless channel alternate between the
blocked and non-blocked LoS states. Following the recent 3GPP requirements on
modeling the dynamic blockage as well as the temporal consistency of the
channel at mmWave frequencies, in this paper a new model for predicting the
state of a user in the presence of mobile blockers for representative 3GPP
scenarios is developed: urban micro cell (UMi) street canyon and
park/stadium/square. It is demonstrated that the blockage effects produce an
alternating renewal process with exponentially distributed non-blocked
intervals, and blocked durations that follow the general distribution. The
following metrics are derived (i) the mean and the fraction of time spent in
blocked/non-blocked state, (ii) the residual blocked/non-blocked time, and
(iii) the time-dependent conditional probability of having blockage/no blockage
at time t1 given that there was blockage/no blockage at time t0. The latter is
a function of the arrival rate (intensity), width, and height of moving
blockers, distance to the mmWave access point (AP), as well as the heights of
the AP and the user device. The proposed model can be used for system-level
characterization of mmWave cellular communication systems. For example, the
optimal height and the maximum coverage radius of the mmWave APs are derived,
while satisfying the required mean data rate constraint. The system-level
simulations corroborate that the use of the proposed method considerably
reduces the modeling complexity.
</dc:description>
 <dc:description>Comment: Accepted, IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:date>2017-09-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08038</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Human Traits in the Language of Social Media: An Open-Vocabulary
  Approach</dc:title>
 <dc:creator>Kulkarni, Vivek</dc:creator>
 <dc:creator>Kern, Margaret L.</dc:creator>
 <dc:creator>Stillwell, David</dc:creator>
 <dc:creator>Kosinski, Michal</dc:creator>
 <dc:creator>Matz, Sandra</dc:creator>
 <dc:creator>Ungar, Lyle</dc:creator>
 <dc:creator>Skiena, Steven</dc:creator>
 <dc:creator>Schwartz, H. Andrew</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Over the past century, personality theory and research has successfully
identified core sets of characteristics that consistently describe and explain
fundamental differences in the way people think, feel and behave. Such
characteristics were derived through theory, dictionary analyses, and survey
research using explicit self-reports. The availability of social media data
spanning millions of users now makes it possible to automatically derive
characteristics from language use -- at large scale. Taking advantage of
linguistic information available through Facebook, we study the process of
inferring a new set of potential human traits based on unprompted language use.
We subject these new traits to a comprehensive set of evaluations and compare
them with a popular five factor model of personality. We find that our
language-based trait construct is often more generalizable in that it often
predicts non-questionnaire-based outcomes better than questionnaire-based
traits (e.g. entities someone likes, income and intelligence quotient), while
the factors remain nearly as stable as traditional factors. Our approach
suggests a value in new constructs of personality derived from everyday human
language use.
</dc:description>
 <dc:description>Comment: In submission to PLOS One</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08039</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Poincar\'e Embeddings for Learning Hierarchical Representations</dc:title>
 <dc:creator>Nickel, Maximilian</dc:creator>
 <dc:creator>Kiela, Douwe</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Representation learning has become an invaluable approach for learning from
symbolic data such as text and graphs. However, while complex symbolic datasets
often exhibit a latent hierarchical structure, state-of-the-art methods
typically learn embeddings in Euclidean vector spaces, which do not account for
this property. For this purpose, we introduce a new approach for learning
hierarchical representations of symbolic data by embedding them into hyperbolic
space -- or more precisely into an n-dimensional Poincar\'e ball. Due to the
underlying hyperbolic geometry, this allows us to learn parsimonious
representations of symbolic data by simultaneously capturing hierarchy and
similarity. We introduce an efficient algorithm to learn the embeddings based
on Riemannian optimization and show experimentally that Poincar\'e embeddings
outperform Euclidean embeddings significantly on data with latent hierarchies,
both in terms of representation capacity and in terms of generalization
ability.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08040</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of Molecular Channels with Imperfect Particle-Intensity
  Modulation and Detection</dc:title>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Rose, Christopher</dc:creator>
 <dc:creator>M&#xe9;dard, Muriel</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  This work introduces the particle-intensity channel (PIC) as a model for
molecular communication systems and characterizes the properties of the optimal
input distribution and the capacity limits for this system. In the PIC, the
transmitter encodes information, in symbols of a given duration, based on the
number of particles released, and the receiver detects and decodes the message
based on the number of particles detected during the symbol interval. In this
channel, the transmitter may be unable to control precisely the number of
particles released, and the receiver may not detect all the particles that
arrive. We demonstrate that the optimal input distribution for this channel
always has mass points at zero and the maximum number of particles that can be
released. We then consider diffusive particle transport, derive the capacity
expression when the input distribution is binary, and show conditions under
which the binary input is capacity-achieving. In particular, we demonstrate
that when the transmitter cannot generate particles at a high rate, the optimal
input distribution is binary.
</dc:description>
 <dc:description>Comment: Accepted at IEEE International Symposium on Information Theory (ISIT)</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08041</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unrolled Optimization with Deep Priors</dc:title>
 <dc:creator>Diamond, Steven</dc:creator>
 <dc:creator>Sitzmann, Vincent</dc:creator>
 <dc:creator>Heide, Felix</dc:creator>
 <dc:creator>Wetzstein, Gordon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A broad class of problems at the core of computational imaging, sensing, and
low-level computer vision reduces to the inverse problem of extracting latent
images that follow a prior distribution, from measurements taken under a known
physical image formation model. Traditionally, hand-crafted priors along with
iterative optimization methods have been used to solve such problems. In this
paper we present unrolled optimization with deep priors, a principled framework
for infusing knowledge of the image formation into deep networks that solve
inverse problems in imaging, inspired by classical iterative methods. We show
that instances of the framework outperform the state-of-the-art by a
substantial margin for a wide variety of imaging problems, such as denoising,
deblurring, and compressed sensing magnetic resonance imaging (MRI). Moreover,
we conduct experiments that explain how the framework is best used and why it
outperforms previous methods.
</dc:description>
 <dc:description>Comment: First two authors contributed equally</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08042</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral Simplicity of Apparent Complexity, Part I: The
  Nondiagonalizable Metadynamics of Prediction</dc:title>
 <dc:creator>Riechers, Paul M.</dc:creator>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  Virtually all questions that one can ask about the behavioral and structural
complexity of a stochastic process reduce to a linear algebraic framing of a
time evolution governed by an appropriate hidden-Markov process generator. Each
type of question---correlation, predictability, predictive cost, observer
synchronization, and the like---induces a distinct generator class. Answers are
then functions of the class-appropriate transition dynamic. Unfortunately,
these dynamics are generically nonnormal, nondiagonalizable, singular, and so
on. Tractably analyzing these dynamics relies on adapting the recently
introduced meromorphic functional calculus, which specifies the spectral
decomposition of functions of nondiagonalizable linear operators, even when the
function poles and zeros coincide with the operator's spectrum. Along the way,
we establish special properties of the projection operators that demonstrate
how they capture the organization of subprocesses within a complex system.
Circumventing the spurious infinities of alternative calculi, this leads in the
sequel, Part II, to the first closed-form expressions for complexity measures,
couched either in terms of the Drazin inverse (negative-one power of a singular
operator) or the eigenvalues and projection operators of the appropriate
transition dynamic.
</dc:description>
 <dc:description>Comment: 24 pages, 3 figures, 4 tables; current version always at
  http://csc.ucdavis.edu/~cmg/compmech/pubs/sdscpt1.htm</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08044</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection Algorithms for Communication Systems Using Deep Learning</dc:title>
 <dc:creator>Farsad, Nariman</dc:creator>
 <dc:creator>Goldsmith, Andrea</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The design and analysis of communication systems typically rely on the
development of mathematical models that describe the underlying communication
channel, which dictates the relationship between the transmitted and the
received signals. However, in some systems, such as molecular communication
systems where chemical signals are used for transfer of information, it is not
possible to accurately model this relationship. In these scenarios, because of
the lack of mathematical channel models, a completely new approach to design
and analysis is required. In this work, we focus on one important aspect of
communication systems, the detection algorithms, and demonstrate that by
borrowing tools from deep learning, it is possible to train detectors that
perform well, without any knowledge of the underlying channel models. We
evaluate these algorithms using experimental data that is collected by a
chemical communication platform, where the channel model is unknown and
difficult to model analytically. We show that deep learning algorithms perform
significantly better than a simple detector that was used in previous works,
which also did not assume any knowledge of the channel.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08045</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning multiple visual domains with residual adapters</dc:title>
 <dc:creator>Rebuffi, Sylvestre-Alvise</dc:creator>
 <dc:creator>Bilen, Hakan</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There is a growing interest in learning data representations that work well
for many different types of problems and data. In this paper, we look in
particular at the task of learning a single visual representation that can be
successfully utilized in the analysis of very different types of images, from
dog breeds to stop signs and digits. Inspired by recent work on learning
networks that predict the parameters of another, we develop a tunable deep
network architecture that, by means of adapter residual modules, can be steered
on the fly to diverse visual domains. Our method achieves a high degree of
parameter sharing while maintaining or even improving the accuracy of
domain-specific representations. We also introduce the Visual Decathlon
Challenge, a benchmark that evaluates the ability of representations to capture
simultaneously ten very different visual domains and measures their ability to
recognize well uniformly.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08049</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Memory Architectures for Autonomous Robot Navigation</dc:title>
 <dc:creator>Chen, Steven W</dc:creator>
 <dc:creator>Atanasov, Nikolay</dc:creator>
 <dc:creator>Khan, Arbaaz</dc:creator>
 <dc:creator>Karydis, Konstantinos</dc:creator>
 <dc:creator>Lee, Daniel D.</dc:creator>
 <dc:creator>Kumar, Vijay</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper highlights the significance of including memory structures in
neural networks when the latter are used to learn perception-action loops for
autonomous robot navigation. Traditional navigation approaches rely on global
maps of the environment to overcome cul-de-sacs and plan feasible motions. Yet,
maintaining an accurate global map may be challenging in real-world settings. A
possible way to mitigate this limitation is to use learning techniques that
forgo hand-engineered map representations and infer appropriate control
responses directly from sensed information. An important but unexplored aspect
of such approaches is the effect of memory on their performance. This work is a
first thorough study of memory structures for deep-neural-network-based robot
navigation, and offers novel tools to train such networks from supervision and
quantify their ability to generalize to unseen scenarios. We analyze the
separation and generalization abilities of feedforward, long short-term memory,
and differentiable neural computer networks. We introduce a new method to
evaluate the generalization ability by estimating the VC-dimension of networks
with a final linear readout layer. We validate that the VC estimates are good
predictors of actual test performance. The reported method can be applied to
deep learning problems beyond robotics.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08051</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wasserstein Learning of Deep Generative Point Process Models</dc:title>
 <dc:creator>Xiao, Shuai</dc:creator>
 <dc:creator>Farajtabar, Mehrdad</dc:creator>
 <dc:creator>Ye, Xiaojing</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Point processes are becoming very popular in modeling asynchronous sequential
data due to their sound mathematical foundation and strength in modeling a
variety of real-world phenomena. Currently, they are often characterized via
intensity function which limits model's expressiveness due to unrealistic
assumptions on its parametric form used in practice. Furthermore, they are
learned via maximum likelihood approach which is prone to failure in
multi-modal distributions of sequences. In this paper, we propose an
intensity-free approach for point processes modeling that transforms nuisance
processes to a target one. Furthermore, we train the model using a
likelihood-free leveraging Wasserstein distance between point processes.
Experiments on various synthetic and real-world data substantiate the
superiority of the proposed point process model over conventional ones.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08052</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressing Recurrent Neural Network with Tensor Train</dc:title>
 <dc:creator>Tjandra, Andros</dc:creator>
 <dc:creator>Sakti, Sakriani</dc:creator>
 <dc:creator>Nakamura, Satoshi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent Neural Network (RNN) are a popular choice for modeling temporal and
sequential tasks and achieve many state-of-the-art performance on various
complex problems. However, most of the state-of-the-art RNNs have millions of
parameters and require many computational resources for training and predicting
new data. This paper proposes an alternative RNN model to reduce the number of
parameters significantly by representing the weight parameters based on Tensor
Train (TT) format. In this paper, we implement the TT-format representation for
several RNN architectures such as simple RNN and Gated Recurrent Unit (GRU). We
compare and evaluate our proposed RNN model with uncompressed RNN model on
sequence classification and sequence prediction tasks. Our proposed RNNs with
TT-format are able to preserve the performance while reducing the number of RNN
parameters significantly up to 40 times smaller.
</dc:description>
 <dc:description>Comment: Accepted at IJCNN 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08052</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN.2017.7966420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08055</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically optimal codebooks based on generalized Jacobi sums</dc:title>
 <dc:creator>Heng, Ziling</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Codebooks with small inner-product correlation are applied in many practical
applications including direct spread code division multiple access
communications, space-time codes and compressed sensing. It is extremely
difficult to construct codebooks achieving the Welch or Levenshtein bound. In
this paper, we firstly generalize Jacobi sums over finite fields and secondly
obtain asymptotically optimal codebooks with respect to the Welch or
Levenshtein bound. Our main results generalize those in [11] and the codebooks
in this paper have more flexible parameters than those in [11].
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08056</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ambiguity set and learning via Bregman and Wasserstein</dc:title>
 <dc:creator>Guo, Xin</dc:creator>
 <dc:creator>Hong, Johnny</dc:creator>
 <dc:creator>Yang, Nan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Construction of ambiguity set in robust optimization relies on the choice of
divergences between probability distributions. In distribution learning,
choosing appropriate probability distributions based on observed data is
critical for approximating the true distribution. To improve the performance of
machine learning models, there has recently been interest in designing
objective functions based on Lp-Wasserstein distance rather than the classical
Kullback-Leibler (KL) divergence. In this paper, we derive concentration and
asymptotic results using Bregman divergence. We propose a novel asymmetric
statistical divergence called Wasserstein-Bregman divergence as a
generalization of L2-Wasserstein distance. We discuss how these results can be
applied to the construction of ambiguity set in robust optimization.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08061</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A divide and conquer method for symbolic regression</dc:title>
 <dc:creator>Luo, Changtong</dc:creator>
 <dc:creator>Chen, Chen</dc:creator>
 <dc:creator>Jiang, Zonglin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Symbolic regression aims to find a function that best explains the
relationship between independent variables and the objective value based on a
given set of sample data. Genetic programming (GP) is usually considered as an
appropriate method for the problem since it can optimize functional structure
and coefficients simultaneously. However, the convergence speed of GP might be
too slow for large scale problems that involve a large number of variables.
Fortunately, in many applications, the target function is separable or
partially separable. This feature motivated us to develop a new method, divide
and conquer (D&amp;C), for symbolic regression, in which the target function is
divided into a number of sub-functions and the sub-functions are then
determined by any of a GP algorithm. The separability is probed by a new
proposed technique, Bi-Correlation test (BiCT). D&amp;C powered GP has been tested
on some real-world applications, and the study shows that D&amp;C can help GP to
get the target function much more rapidly.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08063</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextualizing Citations for Scientific Summarization using Word
  Embeddings and Domain Knowledge</dc:title>
 <dc:creator>Cohan, Arman</dc:creator>
 <dc:creator>Goharian, Nazli</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Citation texts are sometimes not very informative or in some cases inaccurate
by themselves; they need the appropriate context from the referenced paper to
reflect its exact contributions. To address this problem, we propose an
unsupervised model that uses distributed representation of words as well as
domain knowledge to extract the appropriate context from the reference paper.
Evaluation results show the effectiveness of our model by significantly
outperforming the state-of-the-art. We furthermore demonstrate how an effective
contextualization method results in improving citation-based summarization of
the scientific articles.
</dc:description>
 <dc:description>Comment: SIGIR 2017</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08063</dc:identifier>
 <dc:identifier>doi:10.1145/3077136.3080740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08064</identifier>
 <datestamp>2017-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Controllable Abundance Of Saturated-input Linear Discrete Systems</dc:title>
 <dc:creator>Zhao, Mingwang</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Several theorems on the volume computing of the polyhedron spanned by a
n-dimensional vector set with the finite-interval parameters are presented and
proved firstly, and then are used in the analysis of the controllable regions
of the linear discrete time-invariant systems with saturated inputs. A new
concept and continuous measure on the control ability, control efficiency of
the input variables, and the diversity of the control laws, named as the
controllable abundance, is proposed based on the volume computing of the
regions and is applied to the actuator placing and configuring problems, the
optimizing problems of dynamics and kinematics of the controlled plants, etc..
The numerical experiments show the effectiveness of the new concept and methods
for investigating and optimizing the control ability and efficiency.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, 3 tables</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08066</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Images Recovery Using a Single Affine Transformation</dc:title>
 <dc:creator>Jiang, Bo</dc:creator>
 <dc:creator>Ding, Chris</dc:creator>
 <dc:creator>Luo, Bin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In many real-world applications, image data often come with noises,
corruptions or large errors. One approach to deal with noise image data is to
use data recovery techniques which aim to recover the true uncorrupted signals
from the observed noise images. In this paper, we first introduce a novel
corruption recovery transformation (CRT) model which aims to recover multiple
(or a collection of) corrupted images using a single affine transformation.
Then, we show that the introduced CRT can be efficiently constructed through
learning from training data. Once CRT is learned, we can recover the true
signals from the new incoming/test corrupted images explicitly. As an
application, we apply our CRT to image recognition task. Experimental results
on six image datasets demonstrate that the proposed CRT model is effective in
recovering noise image data and thus leads to better recognition results.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08076</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning from partial correction</dc:title>
 <dc:creator>Dasgupta, Sanjoy</dc:creator>
 <dc:creator>Luby, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a new model of interactive learning in which an expert examines
the predictions of a learner and partially fixes them if they are wrong.
Although this kind of feedback is not i.i.d., we show statistical
generalization bounds on the quality of the learned model.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08078</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Patchnet: Interpretable Neural Networks for Image Classification</dc:title>
 <dc:creator>Radhakrishnan, Adityanarayanan</dc:creator>
 <dc:creator>Durham, Charles</dc:creator>
 <dc:creator>Soylemezoglu, Ali</dc:creator>
 <dc:creator>Uhler, Caroline</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The ability to visually understand and interpret learned features from
complex predictive models is crucial for their acceptance in sensitive areas
such as health care. To move closer to this goal of truly interpretable complex
models, we present PatchNet, a network that restricts global context for image
classification tasks in order to easily provide visual representations of
learned texture features on a predetermined local scale. We demonstrate how
PatchNet provides visual heatmap representations of the learned features, and
we mathematically analyze the behavior of the network during convergence. We
also present a version of PatchNet that is particularly well suited for
lowering false positive rates in image classification tasks. We apply PatchNet
to the classification of textures from the Describable Textures Dataset and to
the ISBI-ISIC 2016 melanoma classification challenge.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08080</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Semantic Planning using Deep Successor Representations</dc:title>
 <dc:creator>Zhu, Yuke</dc:creator>
 <dc:creator>Gordon, Daniel</dc:creator>
 <dc:creator>Kolve, Eric</dc:creator>
 <dc:creator>Fox, Dieter</dc:creator>
 <dc:creator>Fei-Fei, Li</dc:creator>
 <dc:creator>Gupta, Abhinav</dc:creator>
 <dc:creator>Mottaghi, Roozbeh</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  A crucial capability of real-world intelligent agents is their ability to
plan a sequence of actions to achieve their goals in the visual world. In this
work, we address the problem of visual semantic planning: the task of
predicting a sequence of actions from visual observations that transform a
dynamic environment from an initial state to a goal state. Doing so entails
knowledge about objects and their affordances, as well as actions and their
preconditions and effects. We propose learning these through interacting with a
visual and dynamic environment. Our proposed solution involves bootstrapping
reinforcement learning with imitation learning. To ensure cross task
generalization, we develop a deep predictive model based on successor
representations. Our experimental results show near optimal results across a
wide range of tasks in the challenging THOR environment.
</dc:description>
 <dc:description>Comment: ICCV 2017 camera ready</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08086</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universal Style Transfer via Feature Transforms</dc:title>
 <dc:creator>Li, Yijun</dc:creator>
 <dc:creator>Fang, Chen</dc:creator>
 <dc:creator>Yang, Jimei</dc:creator>
 <dc:creator>Wang, Zhaowen</dc:creator>
 <dc:creator>Lu, Xin</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Universal style transfer aims to transfer arbitrary visual styles to content
images. Existing feed-forward based methods, while enjoying the inference
efficiency, are mainly limited by inability of generalizing to unseen styles or
compromised visual quality. In this paper, we present a simple yet effective
method that tackles these limitations without training on any pre-defined
styles. The key ingredient of our method is a pair of feature transforms,
whitening and coloring, that are embedded to an image reconstruction network.
The whitening and coloring transforms reflect a direct matching of feature
covariance of the content image to a given style image, which shares similar
spirits with the optimization of Gram matrix based cost in neural style
transfer. We demonstrate the effectiveness of our algorithm by generating
high-quality stylized images with comparisons to a number of recent methods. We
also analyze our method by visualizing the whitened features and synthesizing
textures via simple feature coloring.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08091</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Monotonic Attention Mechanism for End-to-End Speech and Language
  Processing</dc:title>
 <dc:creator>Tjandra, Andros</dc:creator>
 <dc:creator>Sakti, Sakriani</dc:creator>
 <dc:creator>Nakamura, Satoshi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently, encoder-decoder neural networks have shown impressive performance
on many sequence-related tasks. The architecture commonly uses an attentional
mechanism which allows the model to learn alignments between the source and the
target sequence. Most attentional mechanisms used today is based on a global
attention property which requires a computation of a weighted summarization of
the whole input sequence generated by encoder states. However, it is
computationally expensive and often produces misalignment on the longer input
sequence. Furthermore, it does not fit with monotonous or left-to-right nature
in several tasks, such as automatic speech recognition (ASR),
grapheme-to-phoneme (G2P), etc. In this paper, we propose a novel attention
mechanism that has local and monotonic properties. Various ways to control
those properties are also explored. Experimental results on ASR, G2P and
machine translation between two languages with similar sentence structures,
demonstrate that the proposed encoder-decoder model with local monotonic
attention could achieve significant performance improvements and reduce the
computational complexity in comparison with the one that used the standard
global attention architecture.
</dc:description>
 <dc:description>Comment: Accepted at IJCNLP 2017 --- (V2: added more experiments on G2P &amp; MT)</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08092</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Secretive Coded Caching Scheme exploiting Common Demands</dc:title>
 <dc:creator>C, Hari Hara Suthan</dc:creator>
 <dc:creator>Chugh, Ishani</dc:creator>
 <dc:creator>Krishnan, Prasad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Coded caching schemes on broadcast networks with user caches help to offload
traffic from peak times to off-peak times by prefetching information from the
server to the users during off-peak times and thus serving the users more
efficiently during peak times using coded transmissions. We consider the
problem of secretive coded caching which was proposed recently, in which a user
should not be able to decode any information about any file that the user has
not demanded. We propose a new secretive coded caching scheme which has a lower
average rate compared to the existing state-of-the-art scheme, for the same
memory available at the users. The proposed scheme is based on exploiting the
presence of common demands between multiple users.
</dc:description>
 <dc:description>Comment: Added an example to illustrate the scheme efficiently</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08094</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TwiInsight: Discovering Topics and Sentiments from Social Media Datasets</dc:title>
 <dc:creator>Wang, Zhengkui</dc:creator>
 <dc:creator>Bai, Guangdong</dc:creator>
 <dc:creator>Chowdhury, Soumyadeb</dc:creator>
 <dc:creator>Xu, Quanqing</dc:creator>
 <dc:creator>Seow, Zhi Lin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Social media platforms contain a great wealth of information which provides
opportunities for us to explore hidden patterns or unknown correlations, and
understand people's satisfaction with what they are discussing. As one
showcase, in this paper, we present a system, TwiInsight which explores the
insight of Twitter data. Different from other Twitter analysis systems,
TwiInsight automatically extracts the popular topics under different categories
(e.g., healthcare, food, technology, sports and transport) discussed in Twitter
via topic modeling and also identifies the correlated topics across different
categories. Additionally, it also discovers the people's opinions on the tweets
and topics via the sentiment analysis. The system also employs an intuitive and
informative visualization to show the uncovered insight. Furthermore, we also
develop and compare six most popular algorithms - three for sentiment analysis
and three for topic modeling.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08094</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08101</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards seamless multi-view scene analysis from satellite to
  street-level</dc:title>
 <dc:creator>Lef&#xe8;vre, S&#xe9;bastien</dc:creator>
 <dc:creator>Tuia, Devis</dc:creator>
 <dc:creator>Wegner, Jan Dirk</dc:creator>
 <dc:creator>Produit, Timoth&#xe9;e</dc:creator>
 <dc:creator>Nassar, Ahmed Samy</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we discuss and review how combined multi-view imagery from
satellite to street-level can benefit scene analysis. Numerous works exist that
merge information from remote sensing and images acquired from the ground for
tasks like land cover mapping, object detection, or scene understanding. What
makes the combination of overhead and street-level images challenging, is the
strongly varying viewpoint, different scale, illumination, sensor modality and
time of acquisition. Direct (dense) matching of images on a per-pixel basis is
thus often impossible, and one has to resort to alternative strategies that
will be discussed in this paper. We review recent works that attempt to combine
images taken from the ground and overhead views for purposes like scene
registration, reconstruction, or classification. Three methods that represent
the wide range of potential methods and applications (change detection, image
orientation, and tree cataloging) are described in detail. We show that
cross-fertilization between remote sensing, computer vision and machine
learning is very valuable to make the best of geographic data available from
Earth Observation sensors and ground imagery. Despite its challenges, we
believe that integrating these complementary data sources will lead to major
breakthroughs in Big GeoData.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08101</dc:identifier>
 <dc:identifier>Proceedings of the IEEE, 105, pp. 1884-1899, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/JPROC.2017.2684300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08106</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Stream 3D Convolutional Neural Network for Skeleton-Based Action
  Recognition</dc:title>
 <dc:creator>Liu, Hong</dc:creator>
 <dc:creator>Tu, Juanhui</dc:creator>
 <dc:creator>Liu, Mengyuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It remains a challenge to efficiently extract spatialtemporal information
from skeleton sequences for 3D human action recognition. Although most recent
action recognition methods are based on Recurrent Neural Networks which present
outstanding performance, one of the shortcomings of these methods is the
tendency to overemphasize the temporal information. Since 3D convolutional
neural network(3D CNN) is a powerful tool to simultaneously learn features from
both spatial and temporal dimensions through capturing the correlations between
three dimensional signals, this paper proposes a novel two-stream model using
3D CNN. To our best knowledge, this is the first application of 3D CNN in
skeleton-based action recognition. Our method consists of three stages. First,
skeleton joints are mapped into a 3D coordinate space and then encoding the
spatial and temporal information, respectively. Second, 3D CNN models are
seperately adopted to extract deep features from two streams. Third, to enhance
the ability of deep features to capture global relationships, we extend every
stream into multitemporal version. Extensive experiments on the SmartHome
dataset and the large-scale NTU RGB-D dataset demonstrate that our method
outperforms most of RNN-based methods, which verify the complementary property
between spatial and temporal information and the robustness to noise.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, 3 tabels</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08110</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Semi-Bandits with Knapsacks</dc:title>
 <dc:creator>Sankararaman, Karthik Abinav</dc:creator>
 <dc:creator>Slivkins, Aleksandrs</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We unify two prominent lines of work on multi-armed bandits: bandits with
knapsacks (BwK) and combinatorial semi-bandits. The former concerns limited
&quot;resources&quot; consumed by the algorithm, e.g., limited supply in dynamic pricing.
The latter allows a huge number of actions but assumes combinatorial structure
and additional feedback to make the problem tractable. We define a common
generalization, support it with several motivating examples, and design an
algorithm for it. Our regret bounds are comparable with those for BwK and
combinatorial semi- bandits.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08111</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-Armed Bandit to Smartly Select a Training Set from Big Medical
  Data</dc:title>
 <dc:creator>Guti&#xe9;rrez, Benjam&#xed;n</dc:creator>
 <dc:creator>Peter, Lo&#xef;c</dc:creator>
 <dc:creator>Klein, Tassilo</dc:creator>
 <dc:creator>Wachinger, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  With the availability of big medical image data, the selection of an adequate
training set is becoming more important to address the heterogeneity of
different datasets. Simply including all the data does not only incur high
processing costs but can even harm the prediction. We formulate the smart and
efficient selection of a training dataset from big medical image data as a
multi-armed bandit problem, solved by Thompson sampling. Our method assumes
that image features are not available at the time of the selection of the
samples, and therefore relies only on meta information associated with the
images. Our strategy simultaneously exploits data sources with high chances of
yielding useful samples and explores new data regions. For our evaluation, we
focus on the application of estimating the age from a brain MRI. Our results on
7,250 subjects from 10 datasets show that our approach leads to higher accuracy
while only requiring a fraction of the training data.
</dc:description>
 <dc:description>Comment: MICCAI 2017 Proceedings</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08112</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Synthesis for Parameterized Temporal Logics</dc:title>
 <dc:creator>Jacobs, Swen</dc:creator>
 <dc:creator>Tentrup, Leander</dc:creator>
 <dc:creator>Zimmermann, Martin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We consider the synthesis of distributed implementations for specifications
in parameterized temporal logics such as PROMPT-LTL, which extends LTL by
temporal operators equipped with parameters that bound their scope. For single
process synthesis it is well-established that such parametric extensions do not
increase worst-case complexities. For synchronous distributed systems we show
that, despite being more powerful, the realizability problem for PROMPT-LTL is
not harder than its LTL counterpart. For asynchronous systems we have to
express scheduling assumptions and therefore consider an assume-guarantee
synthesis problem. As asynchronous distributed synthesis is already undecidable
for LTL, we give a semi-decision procedure for the PROMPT-LTL assume-guarantee
synthesis problem based on bounded synthesis. Finally, we show that our results
extend to the stronger logics PLTL and PLDL.
</dc:description>
 <dc:description>Comment: Extended version of arXiv:1509.05144. Preprint submitted to
  Information and Computation</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08118</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent Multitask Learning with Nonlinear Output Relations</dc:title>
 <dc:creator>Ciliberto, Carlo</dc:creator>
 <dc:creator>Rudi, Alessandro</dc:creator>
 <dc:creator>Rosasco, Lorenzo</dc:creator>
 <dc:creator>Pontil, Massimiliano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Key to multitask learning is exploiting relationships between different tasks
to improve prediction performance. If the relations are linear, regularization
approaches can be used successfully. However, in practice assuming the tasks to
be linearly related might be restrictive, and allowing for nonlinear structures
is a challenge. In this paper, we tackle this issue by casting the problem
within the framework of structured prediction. Our main contribution is a novel
algorithm for learning multiple tasks which are related by a system of
nonlinear equations that their joint outputs need to satisfy. We show that the
algorithm is consistent and can be efficiently implemented. Experimental
results show the potential of the proposed method.
</dc:description>
 <dc:description>Comment: 25 pages, 1 figure, 2 tables</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08131</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Black-Box Attacks against RNN based Malware Detection Algorithms</dc:title>
 <dc:creator>Hu, Weiwei</dc:creator>
 <dc:creator>Tan, Ying</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recent researches have shown that machine learning based malware detection
algorithms are very vulnerable under the attacks of adversarial examples. These
works mainly focused on the detection algorithms which use features with fixed
dimension, while some researchers have begun to use recurrent neural networks
(RNN) to detect malware based on sequential API features. This paper proposes a
novel algorithm to generate sequential adversarial examples, which are used to
attack a RNN based malware detection system. It is usually hard for malicious
attackers to know the exact structures and weights of the victim RNN. A
substitute RNN is trained to approximate the victim RNN. Then we propose a
generative RNN to output sequential adversarial examples from the original
sequential malware inputs. Experimental results showed that RNN based malware
detection algorithms fail to detect most of the generated malicious adversarial
examples, which means the proposed model is able to effectively bypass the
detection algorithms.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08131</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08135</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kinetostatic Analysis and Solution Classification of a Planar Tensegrity
  Mechanism</dc:title>
 <dc:creator>Wenger, P</dc:creator>
 <dc:creator>Chablat, Damien</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Tensegrity mechanisms have several interesting properties that make them
suitable for a number of applications. Their analysis is generally challenging
because the static equilibrium conditions often result in complex equations. A
class of planar one-degree-of-freedom (dof) tensegrity mechanisms with three
linear springs is analyzed in detail in this paper. The kinetostatic equations
are derived and solved under several loading and geometric conditions. It is
shown that these mechanisms exhibit up to six equilibrium configurations, of
which one or two are stable. Discriminant varieties and cylindrical algebraic
decomposition combined with Groebner base elimination are used to classify
solutions as function of the input parameters.
</dc:description>
 <dc:description>Comment: 7th IFToMM International Workshop on Computational Kinematics, May
  2017, Poitiers, France. 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08142</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning what to share between loosely related tasks</dc:title>
 <dc:creator>Ruder, Sebastian</dc:creator>
 <dc:creator>Bingel, Joachim</dc:creator>
 <dc:creator>Augenstein, Isabelle</dc:creator>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Multi-task learning is motivated by the observation that humans bring to bear
what they know about related problems when solving new ones. Similarly, deep
neural networks can profit from related tasks by sharing parameters with other
networks. However, humans do not consciously decide to transfer knowledge
between tasks. In Natural Language Processing (NLP), it is hard to predict if
sharing will lead to improvements, particularly if tasks are only loosely
related. To overcome this, we introduce Sluice Networks, a general framework
for multi-task learning where trainable parameters control the amount of
sharing. Our framework generalizes previous proposals in enabling sharing of
all combinations of subspaces, layers, and skip connections. We perform
experiments on three task pairs, and across seven different domains, using data
from OntoNotes 5.0, and achieve up to 15% average error reductions over common
approaches to multi-task learning. We show that a) label entropy is predictive
of gains in sluice networks, confirming findings for hard parameter sharing and
b) while sluice networks easily fit noise, they are robust across domains in
practice.
</dc:description>
 <dc:description>Comment: 12 pages, 3 figures, 6 tables</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08148</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity Outer Bound and Degrees of Freedom of Wiener Phase Noise
  Channels with Oversampling</dc:title>
 <dc:creator>Barletta, Luca</dc:creator>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The discrete-time Wiener phase noise channel with an integrate-and-dump
multi-sample receiver is studied.
  A novel outer bound on the capacity with an average input power constraint is
derived as a function of the oversampling factor.
  This outer bound yields the degrees of freedom for the scenario in which the
oversampling factor grows with the transmit power $P$ as $P^{\alpha}$.
  The result shows, perhaps surprisingly, that the largest pre-log that can be
attained with phase modulation at high signal-to-noise ratio is at most $1/4$.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, Submitted to Intern. Workshop Inf. Theory (ITW)
  2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08151</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on some algebraic trapdoors for block ciphers</dc:title>
 <dc:creator>Calderini, Marco</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We provide sufficient conditions to guarantee that a translation based cipher
is not vulnerable with respect to the partition-based trapdoor. This trapdoor
has been introduced, recently, by Bannier et al. (2016) and it generalizes that
introduced by Paterson in 1999. Moreover, we discuss the fact that studying the
group generated by the round functions of a block cipher may not be sufficient
to guarantee security against these trapdoors for the cipher.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08153</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What does an LSTM look for in classifying heartbeats?</dc:title>
 <dc:creator>van der Westhuizen, Jos</dc:creator>
 <dc:creator>Lasenby, Joan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Long short-term memory (LSTM) recurrent neural networks are renowned for
being uninterpretable &quot;black boxes&quot;. In the medical domain where LSTMs have
shown promise, this is specifically concerning because it is imperative to
understand the decisions made by machine learning models in such acute
situations. This study employs techniques used in the convolutional neural
network domain to elucidate the inputs that are important when LSTMs classify
electrocardiogram signals. Of the various techniques available to determine
input feature saliency, it was found that learning an occlusion mask is the
most effective.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08154</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reference String Extraction Using Line-Based Conditional Random Fields</dc:title>
 <dc:creator>K&#xf6;rner, Martin</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The extraction of individual reference strings from the reference section of
scientific publications is an important step in the citation extraction
pipeline. Current approaches divide this task into two steps by first detecting
the reference section areas and then grouping the text lines in such areas into
reference strings. We propose a classification model that considers every line
in a publication as a potential part of a reference string. By applying
line-based conditional random fields rather than constructing the graphical
model based on the individual words, dependencies and patterns that are typical
in reference sections provide strong features while the overall complexity of
the model is reduced.
</dc:description>
 <dc:description>Comment: 5 pages, preprint</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08161</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Methods for Path-based Robust Flows</dc:title>
 <dc:creator>Mies, Fabian</dc:creator>
 <dc:creator>Peis, Britta</dc:creator>
 <dc:creator>Wierz, Andreas</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Real world networks are often subject to severe uncertainties which need to
be addressed by any reliable prescriptive model. In the context of the maximum
flow problem subject to arc failure, robust models have gained particular
attention. For a path-based model, the resulting optimization problem is
assumed to be difficult in the literature, yet the complexity status is widely
unknown. We present a computational approach to solve the robust flow problem
to optimality by simultaneous primal and dual separation, the practical
efficacy of which is shown by a computational study.
  Furthermore, we introduce a novel model of robust flows which provides a
compromise between stochastic and robust optimization by assigning
probabilities to groups of scenarios. The new model can be solved by the same
computational techniques as the robust model. A bound on the generalization
error is proven for the case that the probabilities are determined empirically.
The suggested model as well as the computational approach extend to linear
optimization problems more general than robust flows.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08164</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Sensing: Cooperative Spectrum Sensing Based on Convolutional Neural
  Networks</dc:title>
 <dc:creator>Lee, Woongsup</dc:creator>
 <dc:creator>Kim, Minhoe</dc:creator>
 <dc:creator>Cho, Dong-Ho</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68T99</dc:subject>
 <dc:description>  In this paper, we investigate cooperative spectrum sensing (CSS) in a
cognitive radio network (CRN) where multiple secondary users (SUs) cooperate in
order to detect a primary user (PU) which possibly occupies multiple bands
simultaneously. Deep cooperative sensing (DCS), which constitutes the first CSS
framework based on a convolutional neural network (CNN), is proposed. In DCS,
instead of the explicit mathematical modeling of CSS which is hard to compute
and also hard to use in practice, the strategy for combining the individual
sensing results of the SUs is learned with a CNN using training sensing
samples. Accordingly, an environment-specific CSS which considers both spectral
and spatial correlation of individual sensing outcomes, is found in an adaptive
manner regardless of whether the individual sensing results are quantized or
not. Through simulation, we show that the performance of CSS can be improved by
the proposed DCS with low complexity even when the number of training samples
is moderate.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08168</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Look, Listen and Learn</dc:title>
 <dc:creator>Arandjelovi&#x107;, Relja</dc:creator>
 <dc:creator>Zisserman, Andrew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the question: what can be learnt by looking at and listening to a
large number of unlabelled videos? There is a valuable, but so far untapped,
source of information contained in the video itself -- the correspondence
between the visual and the audio streams, and we introduce a novel
&quot;Audio-Visual Correspondence&quot; learning task that makes use of this. Training
visual and audio networks from scratch, without any additional supervision
other than the raw unconstrained videos themselves, is shown to successfully
solve this task, and, more interestingly, result in good visual and audio
representations. These features set the new state-of-the-art on two sound
classification benchmarks, and perform on par with the state-of-the-art
self-supervised approaches on ImageNet classification. We also demonstrate that
the network is able to localize objects in both modalities, as well as perform
fine-grained recognition tasks.
</dc:description>
 <dc:description>Comment: Appears in: IEEE International Conference on Computer Vision (ICCV)
  2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08169</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transformation of Python Applications into Function-as-a-Service
  Deployments</dc:title>
 <dc:creator>Spillner, Josef</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.1</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  New cloud programming and deployment models pose challenges to software
application engineers who are looking, often in vain, for tools to automate any
necessary code adaptation and transformation. Function-as-a-Service interfaces
are particular non-trivial targets when considering that most cloud
applications are implemented in non-functional languages. Among the most widely
used of these languages is Python. This starting position calls for an
automated approach to transform monolithic Python code into modular FaaS units
by partially automated decomposition. Hence, this paper introduces and
evaluates Lambada, a Python module to dynamically decompose, convert and deploy
unmodified Python code into AWS Lambda functions. Beyond the tooling in the
form of a measured open source prototype implementation, the paper contributes
a description of the algorithms and code rewriting rules as blueprints for
transformations of other scripting languages.
</dc:description>
 <dc:description>Comment: 14 pages, 2 tables, 5 figures, repeatable, unreviewed</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08173</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multilevel Monte Carlo Simulation of the Eddy Current Problem With
  Random Parameters</dc:title>
 <dc:creator>Galetzka, Armin</dc:creator>
 <dc:creator>Bontinck, Zeger</dc:creator>
 <dc:creator>R&#xf6;mer, Ulrich</dc:creator>
 <dc:creator>Sch&#xf6;ps, Sebastian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The multilevel Monte Carlo method is applied to an academic example in the
field of electromagnetism. The method exhibits a reduced variance by assigning
the samples to multiple models with a varying spatial resolution. For the given
example it is found that the main costs of the method are spent on the coarsest
level.
</dc:description>
 <dc:description>Comment: Applied Computational Electromagnetics Society Symposium - Italy
  (ACES), 2017 International, http://ieeexplore.ieee.org/document/7916062/</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08173</dc:identifier>
 <dc:identifier>doi:10.23919/ROPACES.2017.7916062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08174</identifier>
 <datestamp>2017-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Testing of Conductance</dc:title>
 <dc:creator>Fichtenberger, Hendrik</dc:creator>
 <dc:creator>Vasudev, Yadu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of testing conductance in the setting of distributed
computing and give a two-sided tester that takes $\mathcal{O}(\log(n) /
(\epsilon \Phi^2))$ rounds to decide if a graph has conductance at least $\Phi$
or is $\epsilon$-far from having conductance at least $\Phi^2 / 1000$ in the
distributed CONGEST model. We also show that $\Omega(\log n)$ rounds are
necessary for testing conductance even in the LOCAL model. In the case of a
connected graph, we show that we can perform the test even when the number of
vertices in the graph is not known a priori. This is the first two-sided tester
in the distributed model we are aware of. A key observation is that one can
perform a polynomial number of random walks from a small set of vertices if it
is sufficient to track only some small statistics of the walks. This greatly
reduces the congestion on the edges compared to tracking each walk
individually.
</dc:description>
 <dc:description>Comment: revised introduction and some fixes</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08180</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlation Alignment by Riemannian Metric for Domain Adaptation</dc:title>
 <dc:creator>Morerio, Pietro</dc:creator>
 <dc:creator>Murino, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation techniques address the problem of reducing the sensitivity
of machine learning methods to the so-called domain shift, namely the
difference between source (training) and target (test) data distributions. In
particular, unsupervised domain adaptation assumes no labels are available in
the target domain. To this end, aligning second order statistics (covariances)
of target and source domains have proven to be an effective approach ti fill
the gap between the domains. However, covariance matrices do not form a
subspace of the Euclidean space, but live in a Riemannian manifold with
non-positive curvature, making the usual Euclidean metric suboptimal to measure
distances. In this paper, we extend the idea of training a neural network with
a constraint on the covariances of the hidden layer features, by rigorously
accounting for the curved structure of the manifold of symmetric positive
definite matrices. The resulting loss function exploits a theoretically sound
geodesic distance on such manifold. Results show indeed the suboptimal nature
of the Euclidean distance. This makes us able to perform better than previous
approaches on the standard Office dataset, a benchmark for domain adaptation
techniques.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08182</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unmasking the abnormal events in video</dc:title>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:creator>Smeureanu, Sorina</dc:creator>
 <dc:creator>Alexe, Bogdan</dc:creator>
 <dc:creator>Popescu, Marius</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel framework for abnormal event detection in video that
requires no training sequences. Our framework is based on unmasking, a
technique previously used for authorship verification in text documents, which
we adapt to our task. We iteratively train a binary classifier to distinguish
between two consecutive video sequences while removing at each step the most
discriminant features. Higher training accuracy rates of the intermediately
obtained classifiers represent abnormal events. To the best of our knowledge,
this is the first work to apply unmasking for a computer vision task. We
compare our method with several state-of-the-art supervised and unsupervised
methods on four benchmark data sets. The empirical results indicate that our
abnormal event detection framework can achieve state-of-the-art results, while
running in real-time at 20 frames per second.
</dc:description>
 <dc:description>Comment: Accepted at the 2017 International Conference on Computer Vision
  (ICCV 2017)</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08182</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08184</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite
  Dimensions</dc:title>
 <dc:creator>Kontorovich, Aryeh</dc:creator>
 <dc:creator>Sabato, Sivan</dc:creator>
 <dc:creator>Weiss, Roi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We examine the Bayes-consistency of a recently proposed
1-nearest-neighbor-based multiclass learning algorithm. This algorithm is
derived from sample compression bounds and enjoys the statistical advantages of
tight, fully empirical generalization bounds, as well as the algorithmic
advantages of a faster runtime and memory savings. We prove that this algorithm
is strongly Bayes-consistent in metric spaces with finite doubling dimension
--- the first consistency result for an efficient nearest-neighbor sample
compression scheme. Rather surprisingly, we discover that this algorithm
continues to be Bayes-consistent even in a certain infinite-dimensional
setting, in which the basic measure-theoretic conditions on which classic
consistency proofs hinge are violated. This is all the more surprising, since
it is known that $k$-NN is not Bayes-consistent in this setting. We pose
several challenging open problems for future research.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08184</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08197</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Succeed while Teaching to Fail: Privacy in Closed Machine
  Learning Systems</dc:title>
 <dc:creator>Sokolic, Jure</dc:creator>
 <dc:creator>Qiu, Qiang</dc:creator>
 <dc:creator>Rodrigues, Miguel R. D.</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Security, privacy, and fairness have become critical in the era of data
science and machine learning. More and more we see that achieving universally
secure, private, and fair systems is practically impossible. We have seen for
example how generative adversarial networks can be used to learn about the
expected private training data; how the exploitation of additional data can
reveal private information in the original one; and how what looks like
unrelated features can teach us about each other. Confronted with this
challenge, in this paper we open a new line of research, where the security,
privacy, and fairness is learned and used in a closed environment. The goal is
to ensure that a given entity (e.g., the company or the government), trusted to
infer certain information with our data, is blocked from inferring protected
information from it. For example, a hospital might be allowed to produce
diagnosis on the patient (the positive task), without being able to infer the
gender of the subject (negative task). Similarly, a company can guarantee that
internally it is not using the provided data for any undesired task, an
important goal that is not contradicting the virtually impossible challenge of
blocking everybody from the undesired task. We design a system that learns to
succeed on the positive task while simultaneously fail at the negative one, and
illustrate this with challenging cases where the positive task is actually
harder than the negative one being blocked. Fairness, to the information in the
negative task, is often automatically obtained as a result of this proposed
approach. The particular framework and examples open the door to security,
privacy, and fairness in very important closed scenarios, ranging from private
data accumulation companies like social networks to law-enforcement and
hospitals.
</dc:description>
 <dc:description>Comment: 14 pages, 1 figure</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08200</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logical Learning Through a Hybrid Neural Network with Auxiliary Inputs</dc:title>
 <dc:creator>Wan, Fang</dc:creator>
 <dc:creator>Song, Chaoyang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The human reasoning process is seldom a one-way process from an input leading
to an output. Instead, it often involves a systematic deduction by ruling out
other possible outcomes as a self-checking mechanism. In this paper, we
describe the design of a hybrid neural network for logical learning that is
similar to the human reasoning through the introduction of an auxiliary input,
namely the indicators, that act as the hints to suggest logical outcomes. We
generate these indicators by digging into the hidden information buried
underneath the original training data for direct or indirect suggestions. We
used the MNIST data to demonstrate the design and use of these indicators in a
convolutional neural network. We trained a series of such hybrid neural
networks with variations of the indicators. Our results show that these hybrid
neural networks are very robust in generating logical outcomes with inherently
higher prediction accuracy than the direct use of the original input and output
in apparent models. Such improved predictability with reassured logical
confidence is obtained through the exhaustion of all possible indicators to
rule out all illogical outcomes, which is not available in the apparent models.
Our logical learning process can effectively cope with the unknown unknowns
using a full exploitation of all existing knowledge available for learning. The
design and implementation of the hints, namely the indicators, become an
essential part of artificial intelligence for logical learning. We also
introduce an ongoing application setup for this hybrid neural network in an
autonomous grasping robot, namely as_DeepClaw, aiming at learning an optimized
grasping pose through logical learning.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures, 4 tables</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08207</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Salient Object Detection with Semantic Priors</dc:title>
 <dc:creator>Nguyen, Tam V.</dc:creator>
 <dc:creator>Liu, Luoqi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Salient object detection has increasingly become a popular topic in cognitive
and computational sciences, including computer vision and artificial
intelligence research. In this paper, we propose integrating \textit{semantic
priors} into the salient object detection process. Our algorithm consists of
three basic steps. Firstly, the explicit saliency map is obtained based on the
semantic segmentation refined by the explicit saliency priors learned from the
data. Next, the implicit saliency map is computed based on a trained model
which maps the implicit saliency priors embedded into regional features with
the saliency values. Finally, the explicit semantic map and the implicit map
are adaptively fused to form a pixel-accurate saliency map which uniformly
covers the objects of interest. We further evaluate the proposed framework on
two challenging datasets, namely, ECSSD and HKUIS. The extensive experimental
results demonstrate that our method outperforms other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: accepted to IJCAI 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08209</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unbiasing Truncated Backpropagation Through Time</dc:title>
 <dc:creator>Tallec, Corentin</dc:creator>
 <dc:creator>Ollivier, Yann</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Truncated Backpropagation Through Time (truncated BPTT) is a widespread
method for learning recurrent computational graphs. Truncated BPTT keeps the
computational benefits of Backpropagation Through Time (BPTT) while relieving
the need for a complete backtrack through the whole data sequence at every
step. However, truncation favors short-term dependencies: the gradient estimate
of truncated BPTT is biased, so that it does not benefit from the convergence
guarantees from stochastic gradient theory. We introduce Anticipated Reweighted
Truncated Backpropagation (ARTBP), an algorithm that keeps the computational
benefits of truncated BPTT, while providing unbiasedness. ARTBP works by using
variable truncation lengths together with carefully chosen compensation factors
in the backpropagation equation. We check the viability of ARTBP on two tasks.
First, a simple synthetic task where careful balancing of temporal dependencies
at different scales is needed: truncated BPTT displays unreliable performance,
and in worst case scenarios, divergence, while ARTBP converges reliably.
Second, on Penn Treebank character-level language modelling, ARTBP slightly
outperforms truncated BPTT.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08209</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08210</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Accelerated Vector Similarity Calculations for Genomics
  Applications</dc:title>
 <dc:creator>Joubert, Wayne</dc:creator>
 <dc:creator>Nance, James</dc:creator>
 <dc:creator>Weighill, Deborah</dc:creator>
 <dc:creator>Jacobson, Daniel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The surge in availability of genomic data holds promise for enabling
determination of genetic causes of observed individual traits, with
applications to problems such as discovery of the genetic roots of phenotypes,
be they molecular phenotypes such as gene expression or metabolite
concentrations, or complex phenotypes such as diseases. However, the growing
sizes of these datasets and the quadratic, cubic or higher scaling
characteristics of the relevant algorithms pose a serious computational
challenge necessitating use of leadership scale computing. In this paper we
describe a new approach to performing vector similarity metrics calculations,
suitable for parallel systems equipped with graphics processing units (GPUs) or
Intel Xeon Phi processors. Our primary focus is the Proportional Similarity
metric applied to Genome Wide Association Studies (GWAS) and Phenome Wide
Association Studies (PheWAS). We describe the implementation of the algorithms
on accelerated processors, methods used for eliminating redundant calculations
due to symmetries, and techniques for efficient mapping of the calculations to
many-node parallel systems. Results are presented demonstrating high per-node
performance and parallel scalability with rates of more than five quadrillion
elementwise comparisons achieved per second on the ORNL Titan system. In a
companion paper we describe corresponding techniques applied to calculations of
the Custom Correlation Coefficient for comparative genomics applications.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08213</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Accelerated Custom Correlation Coefficient Calculations for
  Genomics Applications</dc:title>
 <dc:creator>Joubert, Wayne</dc:creator>
 <dc:creator>Nance, James</dc:creator>
 <dc:creator>Climer, Sharlee</dc:creator>
 <dc:creator>Weighill, Deborah</dc:creator>
 <dc:creator>Jacobson, Daniel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The massive quantities of genomic data being made available through gene
sequencing techniques are enabling breakthroughs in genomic science in many
areas such as medical advances in the diagnosis and treatment of diseases.
Analyzing this data, however, is a computational challenge insofar as the
computational costs of the relevant algorithms can grow with quadratic, cubic
or higher complexity--leading to the need for leadership scale computing. In
this paper we describe a new approach to calculations of the Custom Correlation
Coefficient (CCC) between Single Nucleotide Polymorphisms (SNPs) across a
population, suitable for parallel systems equipped with graphics processing
units (GPUs) or Intel Xeon Phi processors. We describe the mapping of the
algorithms to accelerated processors, techniques used for eliminating redundant
calculations due to symmetries, and strategies for efficient mapping of the
calculations to many-node parallel systems. Results are presented demonstrating
high per-node performance and near-ideal parallel scalability with rates of
more than four quadrillion elementwise comparisons achieved per second on the
ORNL Titan system. In a companion paper we describe corresponding techniques
applied to calculations of the Proportional Similarity metric for comparative
genomics applications.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08214</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ridiculously Fast Shot Boundary Detection with Fully Convolutional
  Neural Networks</dc:title>
 <dc:creator>Gygli, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Shot boundary detection (SBD) is an important component of many video
analysis tasks, such as action recognition, video indexing, summarization and
editing. Previous work typically used a combination of low-level features like
color histograms, in conjunction with simple models such as SVMs. Instead, we
propose to learn shot detection end-to-end, from pixels to final shot
boundaries. For training such a model, we rely on our insight that all shot
boundaries are generated. Thus, we create a dataset with one million frames and
automatically generated transitions such as cuts, dissolves and fades. In order
to efficiently analyze hours of videos, we propose a Convolutional Neural
Network (CNN) which is fully convolutional in time, thus allowing to use a
large temporal context without the need to repeatedly processing frames. With
this architecture our method obtains state-of-the-art results while running at
an unprecedented speed of more than 120x real-time.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08218</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>XOR-Sampling for Network Design with Correlated Stochastic Events</dc:title>
 <dc:creator>Wu, Xiaojian</dc:creator>
 <dc:creator>Xue, Yexiang</dc:creator>
 <dc:creator>Selman, Bart</dc:creator>
 <dc:creator>Gomes, Carla P.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Many network optimization problems can be formulated as stochastic network
design problems in which edges are present or absent stochastically.
Furthermore, protective actions can guarantee that edges will remain present.
We consider the problem of finding the optimal protection strategy under a
budget limit in order to maximize some connectivity measurements of the
network. Previous approaches rely on the assumption that edges are independent.
In this paper, we consider a more realistic setting where multiple edges are
not independent due to natural disasters or regional events that make the
states of multiple edges stochastically correlated. We use Markov Random Fields
to model the correlation and define a new stochastic network design framework.
We provide a novel algorithm based on Sample Average Approximation (SAA)
coupled with a Gibbs or XOR sampler. The experimental results on real road
network data show that the policies produced by SAA with the XOR sampler have
higher quality and lower variance compared to SAA with Gibbs sampler.
</dc:description>
 <dc:description>Comment: In Proceedings of the Twenty-sixth International Joint Conference on
  Artificial Intelligence (IJCAI-17). The first two authors contribute equally</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08228</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sensitivity Properties of Intermittent Control</dc:title>
 <dc:creator>Gawthrop, Peter J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  The sensitivity properties of intermittent control are analysed and the
conditions for a limit cycle derived theoretically and verified by simulation.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08229</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tools for improving resilience of electric distribution systems with
  networked microgrids</dc:title>
 <dc:creator>Barnes, Arthur</dc:creator>
 <dc:creator>Nagarajan, Harsha</dc:creator>
 <dc:creator>Yamangil, Emre</dc:creator>
 <dc:creator>Bent, Russell</dc:creator>
 <dc:creator>Backhaus, Scott</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In the electrical grid, the distribution system is themost vulnerable to
severe weather events. Well-placed and coordinatedupgrades, such as the
combination of microgrids, systemhardening and additional line redundancy, can
greatly reduce thenumber of electrical outages during extreme events. Indeed,
ithas been suggested that resilience is one of the primary benefitsof networked
microgrids. We formulate a resilient distributiongrid design problem as a
two-stage stochastic program andmake use of decomposition-based heuristic
algorithms to scaleto problems of practical size. We demonstrate the
feasibilityof a resilient distribution design tool on a model of an
actualdistribution network. We vary the study parameters, i.e., thecapital cost
of microgrid generation relative to system hardeningand target system
resilience metrics, and find regions in thisparametric space corresponding to
different distribution systemarchitectures, such as individual microgrids,
hardened networks,and a transition region that suggests the benefits of
microgridsnetworked via hardened circuit segments.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08230</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Blockchain-based Auditable Storage and Sharing of IoT Data</dc:title>
 <dc:creator>Shafagh, Hossein</dc:creator>
 <dc:creator>Burkhalter, Lukas</dc:creator>
 <dc:creator>Hithnawi, Anwar</dc:creator>
 <dc:creator>Duquennoy, Simon</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Today the cloud plays a central role in storing, processing, and distributing
data. Despite contributing to the rapid development of IoT applications, the
current IoT cloud-centric architecture has led into a myriad of isolated data
silos that hinders the full potential of holistic data-driven analytics within
the IoT. In this paper, we present a blockchain-based design for the IoT that
brings a distributed access control and data management. We depart from the
current trust model that delegates access control of our data to a centralized
trusted authority and instead empower the users with data ownership. Our design
is tailored for IoT data streams and enables secure data sharing. We enable a
secure and resilient access control management, by utilizing the blockchain as
an auditable and distributed access control layer to the storage layer. We
facilitate the storage of time-series IoT data at the edge of the network via a
locality-aware decentralized storage system that is managed with the blockchain
technology. Our system is agnostic of the physical storage nodes and supports
as well utilization of cloud storage resources as storage nodes.
</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08230</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08241</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loose Graph Simulations</dc:title>
 <dc:creator>Mansutti, Alessio</dc:creator>
 <dc:creator>Miculan, Marino</dc:creator>
 <dc:creator>Peressotti, Marco</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We introduce loose graph simulations (LGS), a new notion about labelled
graphs which subsumes in an intuitive and natural way subgraph isomorphism
(SGI), regular language pattern matching (RLPM) and graph simulation (GS).
Being a unification of all these notions, LGS allows us to express directly
also problems which are &quot;mixed&quot; instances of previous ones, and hence which
would not fit easily in any of them. After the definition and some examples, we
show that the problem of finding loose graph simulations is NP-complete, we
provide formal translation of SGI, RLPM, and GS into LGSs, and we give the
representation of a problem which extends both SGI and RLPM. Finally, we
identify a subclass of the LGS problem that is polynomial.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08242</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Composable Coresets for Matching and Vertex Cover</dc:title>
 <dc:creator>Assadi, Sepehr</dc:creator>
 <dc:creator>Khanna, Sanjeev</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  A common approach for designing scalable algorithms for massive data sets is
to distribute the computation across, say $k$, machines and process the data
using limited communication between them. A particularly appealing framework
here is the simultaneous communication model whereby each machine constructs a
small representative summary of its own data and one obtains an
approximate/exact solution from the union of the representative summaries. If
the representative summaries needed for a problem are small, then this results
in a communication-efficient and round-optimal protocol. While many fundamental
graph problems admit efficient solutions in this model, two prominent problems
are notably absent from the list of successes, namely, the maximum matching
problem and the minimum vertex cover problem. Indeed, it was shown recently
that for both these problems, even achieving a polylog$(n)$ approximation
requires essentially sending the entire input graph from each machine.
  The main insight of our work is that the intractability of matching and
vertex cover in the simultaneous communication model is inherently connected to
an adversarial partitioning of the underlying graph across machines. We show
that when the underlying graph is randomly partitioned across machines, both
these problems admit randomized composable coresets of size $\widetilde{O}(n)$
that yield an $\widetilde{O}(1)$-approximate solution. This results in an
$\widetilde{O}(1)$-approximation simultaneous protocol for these problems with
$\widetilde{O}(nk)$ total communication when the input is randomly partitioned
across $k$ machines. We further prove the optimality of our results. Finally,
by a standard application of composable coresets, our results also imply
MapReduce algorithms with the same approximation guarantee in one or two rounds
of communication
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08244</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the mathematics of beauty: beautiful images</dc:title>
 <dc:creator>Khalili, A. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we will study the simplest kind of beauty that can be found in
a simple visual pattern and can be appreciated universally. The proposed model
suggest that there is a link between beautiful pattern and a deeper
optimisation process between randomness and regularity. Then we show that
beautiful patterns need to satisfy a more fundamental law that seeks to deliver
the highest amount of information using the same amount of energy. The proposed
model is used to classify and generate beautiful patterns.
</dc:description>
 <dc:date>2017-05-13</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08245</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhanced Experience Replay Generation for Efficient Reinforcement
  Learning</dc:title>
 <dc:creator>Huang, Vincent</dc:creator>
 <dc:creator>Ley, Tobias</dc:creator>
 <dc:creator>Vlachou-Konchylaki, Martha</dc:creator>
 <dc:creator>Hu, Wenfeng</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Applying deep reinforcement learning (RL) on real systems suffers from slow
data sampling. We propose an enhanced generative adversarial network (EGAN) to
initialize an RL agent in order to achieve faster learning. The EGAN utilizes
the relation between states and actions to enhance the quality of data samples
generated by a GAN. Pre-training the agent with the EGAN shows a steeper
learning curve with a 20% improvement of training time in the beginning of
learning, compared to no pre-training, and an improvement compared to training
with GAN by about 5% with smaller variations. For real time systems with sparse
and slow data sampling the EGAN could be used to speed up the early phases of
the training process.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08252</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Algorithms for Feature Extraction Off-loading in
  Multi-Camera Visual Sensor Networks</dc:title>
 <dc:creator>Eriksson, Emil</dc:creator>
 <dc:creator>D&#xe1;n, Gy&#xf6;rgy</dc:creator>
 <dc:creator>Fodor, Viktoria</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time visual analysis tasks, like tracking and recognition, require swift
execution of computationally intensive algorithms. Visual sensor networks can
be enabled to perform such tasks by augmenting the sensor network with
processing nodes and distributing the computational burden in a way that the
cameras contend for the processing nodes while trying to minimize their task
completion times. In this paper, we formulate the problem of minimizing the
completion time of all camera sensors as an optimization problem. We propose
algorithms for fully distributed optimization, analyze the existence of
equilibrium allocations, evaluate the effect of the network topology and of the
video characteristics, and the benefits of central coordination. Our results
demonstrate that with sufficient information available, distributed
optimization can provide low completion times, moreover predictable and stable
performance can be achieved with additional, sparse central coordination.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures, submitted to Transactions on Circuits and
  Systems for Video Technology</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08255</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microphone Subset Selection for MVDR Beamformer Based Noise Reduction</dc:title>
 <dc:creator>Zhang, Jie</dc:creator>
 <dc:creator>Chepuri, Sundeep Prabhakar</dc:creator>
 <dc:creator>Hendriks, Richard C.</dc:creator>
 <dc:creator>Heusdens, Richard</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  In large-scale wireless acoustic sensor networks (WASNs), many of the sensors
will only have a marginal contribution to a certain estimation task. Involving
all sensors increases the energy budget unnecessarily and decreases the
lifetime of the WASN. Using microphone subset selection, also termed as sensor
selection, the most informative sensors can be chosen from a set of candidate
sensors to achieve a prescribed inference performance. In this paper, we
consider microphone subset selection for minimum variance distortionless
response (MVDR) beamformer based noise reduction. The best subset of sensors is
determined by minimizing the transmission cost while constraining the output
noise power (or signal-to-noise ratio). Assuming the statistical information on
correlation matrices of the sensor measurements is available, the sensor
selection problem for this model-driven scheme is first solved by utilizing
convex optimization techniques. In addition, to avoid estimating the statistics
related to all the candidate sensors beforehand, we also propose a data-driven
approach to select the best subset using a greedy strategy. The performance of
the greedy algorithm converges to that of the model-driven method, while it
displays advantages in dynamic scenarios as well as on computational
complexity. Compared to a sparse MVDR or radius-based beamformer, experiments
show that the proposed methods can guarantee the desired performance with
significantly less transmission costs.
</dc:description>
 <dc:date>2017-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08260</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Supervised Siamese Learning on Stereo Image Pairs for Depth
  Estimation in Robotic Surgery</dc:title>
 <dc:creator>Ye, Menglong</dc:creator>
 <dc:creator>Johns, Edward</dc:creator>
 <dc:creator>Handa, Ankur</dc:creator>
 <dc:creator>Zhang, Lin</dc:creator>
 <dc:creator>Pratt, Philip</dc:creator>
 <dc:creator>Yang, Guang-Zhong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic surgery has become a powerful tool for performing minimally invasive
procedures, providing advantages in dexterity, precision, and 3D vision, over
traditional surgery. One popular robotic system is the da Vinci surgical
platform, which allows preoperative information to be incorporated into live
procedures using Augmented Reality (AR). Scene depth estimation is a
prerequisite for AR, as accurate registration requires 3D correspondences
between preoperative and intraoperative organ models. In the past decade, there
has been much progress on depth estimation for surgical scenes, such as using
monocular or binocular laparoscopes [1,2]. More recently, advances in deep
learning have enabled depth estimation via Convolutional Neural Networks (CNNs)
[3], but training requires a large image dataset with ground truth depths.
Inspired by [4], we propose a deep learning framework for surgical scene depth
estimation using self-supervision for scalable data acquisition. Our framework
consists of an autoencoder for depth prediction, and a differentiable spatial
transformer for training the autoencoder on stereo image pairs without ground
truth depths. Validation was conducted on stereo videos collected in robotic
partial nephrectomy.
</dc:description>
 <dc:description>Comment: A two-page short report to be presented at the Hamlyn Symposium on
  Medical Robotics 2017. An extension of this work is on progress</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08262</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verification of a lazy cache coherence protocol against a weak memory
  model</dc:title>
 <dc:creator>Banks, Christopher J.</dc:creator>
 <dc:creator>Elver, Marco</dc:creator>
 <dc:creator>Hoffmann, Ruth</dc:creator>
 <dc:creator>Sarkar, Susmit</dc:creator>
 <dc:creator>Jackson, Paul</dc:creator>
 <dc:creator>Nagarajan, Vijay</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>B.1.4</dc:subject>
 <dc:subject>B.3.2</dc:subject>
 <dc:subject>B.3.3</dc:subject>
 <dc:description>  In this paper we verify a modern lazy cache coherence protocol, TSO-CC,
against the memory consistency model it was designed for, TSO. We achieve this
by first showing a weak simulation relation between TSO-CC (with a fixed number
of processors) and a novel finite-state operational model which exhibits the
laziness of TSO-CC and satisfies TSO. We then extend this by an existing
parameterisation technique, allowing verification for an unlimited number of
processors. The approach is executed entirely within a model checker, no
external tool is required and very little in-depth knowledge of formal
verification methods is required of the verifier.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08264</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Isomorphism between Differential and Moment Invariants under Affine
  Transform</dc:title>
 <dc:creator>Li, Erbo</dc:creator>
 <dc:creator>Li, Hua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The invariant is one of central topics in science, technology and
engineering. The differential invariant is essential in understanding or
describing some important phenomena or procedures in mathematics, physics,
chemistry, biology or computer science etc. The derivation of differential
invariants is usually difficult or complicated. This paper reports a discovery
that under the affine transform, differential invariants have similar
structures with moment invariants up to a scalar function of transform
parameters. If moment invariants are known, relative differential invariants
can be obtained by the substitution of moments by derivatives with the same
order. Whereas moment invariants can be calculated by multiple integrals, this
method provides a simple way to derive differential invariants without the need
to resolve any equation system. Since the definition of moments on different
manifolds or in different dimension of spaces is well established, differential
invariants on or in them will also be well defined. Considering that moments
have a strong background in mathematics and physics, this technique offers a
new view angle to the inner structure of invariants. Projective differential
invariants can also be found in this way with a screening process.
</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08266</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Discrete Wavelet Transforms on GPUs</dc:title>
 <dc:creator>Barina, David</dc:creator>
 <dc:creator>Kula, Michal</dc:creator>
 <dc:creator>Matysek, Michal</dc:creator>
 <dc:creator>Zemcik, Pavel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The two-dimensional discrete wavelet transform has a huge number of
applications in image-processing techniques. Until now, several papers compared
the performance of such transform on graphics processing units (GPUs). However,
all of them only dealt with lifting and convolution computation schemes. In
this paper, we show that corresponding horizontal and vertical lifting parts of
the lifting scheme can be merged into non-separable lifting units, which halves
the number of steps. We also discuss an optimization strategy leading to a
reduction in the number of arithmetic operations. The schemes were assessed
using the OpenCL and pixel shaders. The proposed non-separable lifting scheme
outperforms the existing schemes in many cases, irrespective of its higher
complexity.
</dc:description>
 <dc:description>Comment: preprint submitted to ICIP 2017. arXiv admin note: substantial text
  overlap with arXiv:1704.08657</dc:description>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08270</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Pascal triangle for binomial coefficients of words</dc:title>
 <dc:creator>Leroy, Julien</dc:creator>
 <dc:creator>Rigo, Michel</dc:creator>
 <dc:creator>Stipulanti, Manon</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>28A80 (primary), and 28A78, 11B85, 68R15 (secondary)</dc:subject>
 <dc:description>  We introduce a generalization of Pascal triangle based on binomial
coefficients of finite words. These coefficients count the number of times a
word appears as a subsequence of another finite word. Similarly to the
Sierpi\'nski gasket that can be built as the limit set, for the Hausdorff
distance, of a convergent sequence of normalized compact blocks extracted from
Pascal triangle modulo $2$, we describe and study the first properties of the
subset of $[0, 1] \times [0, 1]$ associated with this extended Pascal triangle
modulo a prime $p$.
</dc:description>
 <dc:description>Comment: 20 pages, 15 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08270</dc:identifier>
 <dc:identifier>Adv. Appl. Math. 80 (2016) 24-27</dc:identifier>
 <dc:identifier>doi:10.1016/j.aam.2016.04.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08272</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matching neural paths: transfer from recognition to correspondence
  search</dc:title>
 <dc:creator>Savinov, Nikolay</dc:creator>
 <dc:creator>Ladicky, Lubor</dc:creator>
 <dc:creator>Pollefeys, Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Many machine learning tasks require finding per-part correspondences between
objects. In this work we focus on low-level correspondences - a highly
ambiguous matching problem. We propose to use a hierarchical semantic
representation of the objects, coming from a convolutional neural network, to
solve this ambiguity. Training it for low-level correspondence prediction
directly might not be an option in some domains where the ground-truth
correspondences are hard to obtain. We show how transfer from recognition can
be used to avoid such training. Our idea is to mark parts as &quot;matching&quot; if
their features are close to each other at all the levels of convolutional
feature hierarchy (neural paths). Although the overall number of such paths is
exponential in the number of layers, we propose a polynomial algorithm for
aggregating all of them in a single backward pass. The empirical validation is
done on the task of stereo correspondence and demonstrates that we achieve
competitive results among the methods which do not use labeled target domain
data.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2017</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08273</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New 3D Segmentation Technique for QCT Scans of the Lumbar Spine to
  Determine BMD and Vertebral Geometry</dc:title>
 <dc:creator>Mastmeyer, Andre</dc:creator>
 <dc:creator>Engelke, Klaus</dc:creator>
 <dc:creator>Fuchs, Christina</dc:creator>
 <dc:creator>Kalender, Willi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quantitative computed tomography (QCT) is a standard method to determine bone
mineral density (BMD) in the spine. Traditionally single 8 - 10 mm thick slices
have been analyzed only. Current spiral CT scanners provide true 3D acquisition
schemes allowing for a more differential BMD analysis and an assessment of
geometric parameters, which may improve fracture prediction. We developed a
novel 3D segmentation approach that combines deformable balloons, multi seeded
volume growing, and dedicated morphological operations to extract the vertebral
bodies. An anatomy-oriented coordinate system attached automatically to each
vertebra is used to define volumes of interest. We analyzed intra-operator
precision of the segmentation procedure using abdominal scans from 10 patients
(60 mAs, 120 kV, slice thickness 1mm, B40s, Siemens Sensation 16). Our new
segmentation method shows excellent precision errors in the order of &lt; 1 % for
BMD and &lt; 2 % for volume.
</dc:description>
 <dc:description>Comment: 2 pages, 2 figures, International Congress of Medical Physics 2005</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08275</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Calidad en repositorios digitales en Argentina, estudio comparativo y
  cualitativo</dc:title>
 <dc:creator>Medrano, J. Federico</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Numerous institutions and organizations need not only to preserve the
material and publications they produce, but also have as their task (although
it would be desirable it was an obligation) to publish, disseminate and make
publicly available all the results of the research and any other
scientific/academic material. The Open Archives Initiative (OAI) and the
introduction of Open Archives Initiative Protocol for Metadata Harvesting
(OAI-PMH), make this task much easier. The main objective of this work is to
make a comparative and qualitative study of the data -metadata specifically-
contained in the whole set of Argentine repositories listed in the ROAR portal,
focusing on the functional perspective of the quality of this metadata. Another
objective is to offer an overview of the status of these repositories, in an
attempt to detect common failures and errors institutions incur when storing
the metadata of the resources contained in these repositories, and thus be able
to suggest measures to be able to improve the load and further retrieval
processes. It was found that the eight most used Dublin Core fields are:
identifier, type, title, date, subject, creator, language and description. Not
all repositories fill all the fields, and the lack of normalization, or the
excessive use of fields like language, type, format and subject is somewhat
striking, and in some cases even alarming
</dc:description>
 <dc:description>Comment: BIREDIAL-ISTEC 2017, in Spanish</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08275</dc:identifier>
 <dc:language>es</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08277</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization in large graphs: Toward a better future?</dc:title>
 <dc:creator>Leyman, Pieter</dc:creator>
 <dc:creator>De Causmaecker, Patrick</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Finding groups of connected individuals in large graphs with tens of
thousands or more nodes has received considerable attention in academic
research. In this paper, we analyze three main issues with respect to the
recent influx of papers on community detection in (large) graphs, highlight the
specific problems with the current research avenues, and propose a first step
towards a better approach.
  First, in spite of the strong interest in community detection, a strong
conceptual and theoretical foundation of connectedness in large graphs is
missing. Yet, it is crucial to be able to determine the specific feats that we
aim to analyze in large networks, to avoid a purely black-or-white view.
  Second, in literature commonly employed (meta)heuristic frameworks are
applied for the large graph problems. Currently, it is, however, unclear
whether these techniques are even viable options, and what the added value of
the constituting parts is. Additionally, the manner in which different
algorithms are compared is also ambiguous.
  Finally, no analyses of the impact of data parameters on the reported
clusters is done. Nonetheless, it would be interesting to evaluate which
characteristics lead to which type of communities and what their effect is on
computational difficulty.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08279</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Countermeasure against Side-Channel Attack in Shared Memory of TrustZone</dc:title>
 <dc:creator>Ahn, Na-Young</dc:creator>
 <dc:creator>Lee, Dong Hoon</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  In this paper we introduced countermeasures against side-channel attacks in
the shared memory of TrustZone. We proposed zero-contention cache memory or
policy between REE and TEE to prevent from TruSpy attacks in TrustZone. And we
suggested that delay time of data path of REE is equal or similar to that of
data path of TEE to prevent timing side-channel attacks. Also, we proposed
security information flow control based on the Clark-Wilson model, and built
the information flow control mechanism using Authentication Tokenization
Program (ATP). Accordingly we can expect the improved integrity of the
information content between REE and TEE on mobile devices.
</dc:description>
 <dc:description>Comment: 13 pages, 16 figures, PLOSONE 2017. arXiv admin note: text overlap
  with arXiv:1212.1651 by other authors</dc:description>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08280</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How hard can it be? Estimating the difficulty of visual search in an
  image</dc:title>
 <dc:creator>Ionescu, Radu Tudor</dc:creator>
 <dc:creator>Alexe, Bogdan</dc:creator>
 <dc:creator>Leordeanu, Marius</dc:creator>
 <dc:creator>Popescu, Marius</dc:creator>
 <dc:creator>Papadopoulos, Dim P.</dc:creator>
 <dc:creator>Ferrari, Vittorio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We address the problem of estimating image difficulty defined as the human
response time for solving a visual search task. We collect human annotations of
image difficulty for the PASCAL VOC 2012 data set through a crowd-sourcing
platform. We then analyze what human interpretable image properties can have an
impact on visual search difficulty, and how accurate are those properties for
predicting difficulty. Next, we build a regression model based on deep features
learned with state of the art convolutional neural networks and show better
results for predicting the ground-truth visual search difficulty scores
produced by human annotators. Our model is able to correctly rank about 75%
image pairs according to their difficulty score. We also show that our
difficulty predictor generalizes well to new classes not seen during training.
Finally, we demonstrate that our predicted difficulty scores are useful for
weakly supervised object localization (8% improvement) and semi-supervised
object classification (1% improvement).
</dc:description>
 <dc:description>Comment: Published at CVPR 2016</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08280</dc:identifier>
 <dc:identifier>In Proceedings of CVPR, pp. 2157-2166, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08282</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms and hardness results for happy coloring problems</dc:title>
 <dc:creator>Aravind, N. R.</dc:creator>
 <dc:creator>Kalyanasundaram, Subrahmanyam</dc:creator>
 <dc:creator>Kare, Anjeneya Swami</dc:creator>
 <dc:creator>Lauri, Juho</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In a vertex-colored graph, an edge is happy if its endpoints have the same
color. Similarly, a vertex is happy if all its incident edges are happy.
Motivated by the computation of homophily in social networks, we consider the
algorithmic aspects of the following Maximum Happy Edges (k-MHE) problem: given
a partially k-colored graph G, find an extended full k-coloring of G maximizing
the number of happy edges. When we want to maximize the number of happy
vertices, the problem is known as Maximum Happy Vertices (k-MHV). We further
study the complexity of the problems and their weighted variants. For instance,
we prove that for every k &gt;= 3, both problems are NP-complete for bipartite
graphs and k-MHV remains hard for split graphs. In terms of exact algorithms,
we show both problems can be solved in time O*(2^n), and give an even faster
O*(1.89^n)-time algorithm when k = 3. From a parameterized perspective, we give
a linear vertex kernel for Weighted k-MHE, where edges are weighted and the
goal is to obtain happy edges of at least a specified total weight. Finally, we
prove both problems are solvable in polynomial-time when the graph has bounded
treewidth or bounded neighborhood diversity.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08283</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Music Playlist Continuation by Learning from Hand-Curated Examples and
  Song Features: Alleviating the Cold-Start Problem for Rare and Out-of-Set
  Songs</dc:title>
 <dc:creator>Vall, Andreu</dc:creator>
 <dc:creator>Eghbal-zadeh, Hamid</dc:creator>
 <dc:creator>Dorfer, Matthias</dc:creator>
 <dc:creator>Schedl, Markus</dc:creator>
 <dc:creator>Widmer, Gerhard</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Automated music playlist generation is a specific form of music
recommendation. Generally stated, the user receives a set of song suggestions
defining a coherent listening session. We hypothesize that the best way to
convey such playlist coherence to new recommendations is by learning it from
actual curated examples, in contrast to imposing ad hoc constraints.
Collaborative filtering methods can be used to capture underlying patterns in
hand-curated playlists. However, the scarcity of thoroughly curated playlists
and the bias towards popular songs result in the vast majority of songs
occurring in very few playlists and thus being poorly recommended. To overcome
this issue, we propose an alternative model based on a song-to-playlist
classifier, which learns the underlying structure from actual playlists while
leveraging song features derived from audio, social tags and independent
listening logs. Experiments on two datasets of hand-curated playlists show
competitive performance compared to collaborative filtering when sufficient
training data is available and more robust performance when recommending rare
and out-of-set songs. For example, both approaches achieve a recall@100 of
roughly 35% for songs occurring in 5 or more training playists, whereas the
proposed model achieves a recall@100 of roughly 15% for songs occurring in 4 or
less training playlists, compared to the 3% achieved by collaborative
filtering.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08283</dc:identifier>
 <dc:identifier>doi:10.1145/3125486.3125494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08286</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Efficient Tensor Representations with Ring Structure Networks</dc:title>
 <dc:creator>Zhao, Qibin</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:creator>Cichocki, Andrzej</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Tensor train (TT) decomposition is a powerful representation for high-order
tensors, which has been successfully applied to various machine learning tasks
in recent years. However, since the tensor product is not commutative,
permutation of data dimensions makes solutions and TT-ranks of TT decomposition
inconsistent. To alleviate this problem, we propose a permutation symmetric
network structure by employing circular multilinear products over a sequence of
low-order core tensors. This network structure can be graphically interpreted
as a cyclic interconnection of tensors, and thus we call it tensor ring (TR)
representation. We develop several efficient algorithms to learn TR
representation with adaptive TR-ranks by employing low-rank approximations.
Furthermore, mathematical properties are investigated, which enables us to
perform basic operations in a computationally efficiently way by using TR
representations. Experimental results on synthetic signals and real-world
datasets demonstrate that the proposed TR network is more expressive and
consistently informative than existing TT networks.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1606.05535</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08292</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Marginal Value of Adaptive Gradient Methods in Machine Learning</dc:title>
 <dc:creator>Wilson, Ashia C.</dc:creator>
 <dc:creator>Roelofs, Rebecca</dc:creator>
 <dc:creator>Stern, Mitchell</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:creator>Recht, Benjamin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Adaptive optimization methods, which perform local optimization with a metric
constructed from the history of iterates, are becoming increasingly popular for
training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We
show that for simple overparameterized problems, adaptive methods often find
drastically different solutions than gradient descent (GD) or stochastic
gradient descent (SGD). We construct an illustrative binary classification
problem where the data is linearly separable, GD and SGD achieve zero test
error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to
half. We additionally study the empirical generalization capability of adaptive
methods on several state-of-the-art deep learning models. We observe that the
solutions found by adaptive methods generalize worse (often significantly
worse) than SGD, even when these solutions have better training performance.
These results suggest that practitioners should reconsider the use of adaptive
methods to train neural networks.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08293</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Invariant Model of the Significance of Different Body Parts in
  Recognizing Different Actions</dc:title>
 <dc:creator>Shen, Yuping</dc:creator>
 <dc:creator>Foroosh, Hassan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we show that different body parts do not play equally
important roles in recognizing a human action in video data. We investigate to
what extent a body part plays a role in recognition of different actions and
hence propose a generic method of assigning weights to different body points.
The approach is inspired by the strong evidence in the applied perception
community that humans perform recognition in a foveated manner, that is they
recognize events or objects by only focusing on visually significant aspects.
An important contribution of our method is that the computation of the weights
assigned to body parts is invariant to viewing directions and camera parameters
in the input data. We have performed extensive experiments to validate the
proposed approach and demonstrate its significance. In particular, results show
that considerable improvement in performance is gained by taking into account
the relative importance of different body parts as defined by our approach.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1705.04641,
  arXiv:1705.05741, arXiv:1705.04433</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08302</identifier>
 <datestamp>2017-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anatomically Constrained Neural Networks (ACNN): Application to Cardiac
  Image Enhancement and Segmentation</dc:title>
 <dc:creator>Oktay, Ozan</dc:creator>
 <dc:creator>Ferrante, Enzo</dc:creator>
 <dc:creator>Kamnitsas, Konstantinos</dc:creator>
 <dc:creator>Heinrich, Mattias</dc:creator>
 <dc:creator>Bai, Wenjia</dc:creator>
 <dc:creator>Caballero, Jose</dc:creator>
 <dc:creator>Cook, Stuart</dc:creator>
 <dc:creator>de Marvao, Antonio</dc:creator>
 <dc:creator>Dawes, Timothy</dc:creator>
 <dc:creator>O'Regan, Declan</dc:creator>
 <dc:creator>Kainz, Bernhard</dc:creator>
 <dc:creator>Glocker, Ben</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Incorporation of prior knowledge about organ shape and location is key to
improve performance of image analysis approaches. In particular, priors can be
useful in cases where images are corrupted and contain artefacts due to
limitations in image acquisition. The highly constrained nature of anatomical
objects can be well captured with learning based techniques. However, in most
recent and promising techniques such as CNN based segmentation it is not
obvious how to incorporate such prior knowledge. State-of-the-art methods
operate as pixel-wise classifiers where the training objectives do not
incorporate the structure and inter-dependencies of the output. To overcome
this limitation, we propose a generic training strategy that incorporates
anatomical prior knowledge into CNNs through a new regularisation model, which
is trained end-to-end. The new framework encourages models to follow the global
anatomical properties of the underlying anatomy (e.g. shape, label structure)
via learned non-linear representations of the shape. We show that the proposed
approach can be easily adapted to different analysis tasks (e.g. image
enhancement, segmentation) and improve the prediction accuracy of the
state-of-the-art models. The applicability of our approach is shown on
multi-modal cardiac datasets and public benchmarks. Additionally, we
demonstrate how the learned deep models of 3D shapes can be interpreted and
used as biomarkers for classification of cardiac pathologies.
</dc:description>
 <dc:description>Comment: Published in IEEE Transactions on Medical Imaging (Aug 2017)</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08302</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2017.2743464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08304</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Optimal Routing for the Uplink in LPWANs Using
  Similarity-enhanced epsilon-greedy</dc:title>
 <dc:creator>Barrachina-Mu&#xf1;oz, Sergio</dc:creator>
 <dc:creator>Bellalta, Boris</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Despite being a relatively new communication technology, Low-Power Wide Area
Networks (LPWANs) have shown their suitability to empower a major part of
Internet of Things applications. Nonetheless, most LPWAN solutions are built on
star topology (or single-hop) networks, often causing lifetime shortening in
stations located far from the gateway. In this respect, recent studies show
that multi-hop routing for uplink communications can reduce LPWANs' energy
consumption significantly. However, it is a troublesome task to identify such
energetically optimal routings through trial-and-error brute-force approaches
because of time and, especially, energy consumption constraints. In this work
we show the benefits of facing this exploration/exploitation problem by running
centralized variations of the multi-arm bandit's epsilon-greedy, a well-known
online decision-making method that combines best known action selection and
knowledge expansion. Important energy savings are achieved when proper
randomness parameters are set, which are often improved when conveniently
applying similarity, a concept introduced in this work that allows harnessing
the gathered knowledge by sporadically selecting unexplored routing
combinations akin to the best known one.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1611.08703</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08304</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08314</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Multi-Detector Fusion Framework for Multi-Object Tracking</dc:title>
 <dc:creator>Henschel, Roberto</dc:creator>
 <dc:creator>Leal-Taix&#xe9;, Laura</dc:creator>
 <dc:creator>Cremers, Daniel</dc:creator>
 <dc:creator>Rosenhahn, Bodo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In order to track all persons in a scene, the tracking-by-detection paradigm
has proven to be a very effective approach. Yet, relying solely on a single
detector is also a major limitation, as useful image information might be
ignored. This work demonstrates how to incorporate several detectors into a
tracking system, using a novel multi-object tracking formulation. We cast
tracking as a weighted graph labeling problem, resulting in a binary quadratic
program. As such problems are NP-hard, the solution can only be approximated.
Based on the Frank-Wolfe algorithm, we present a new solver that is crucial to
handle such difficult problems. As a result, the tracker can take information
from many frames and different detectors holistically into account. When
applied with head and full-body detections, the fusion helps to recover heavily
occluded persons and to reduce false positives. Evaluation on pedestrian
tracking is provided for multiple scenarios, showing superior results over
single detector tracking and standard QP-solvers. Finally, our tracker performs
state-of-the-art on the MOT16 benchmark and is the winner of the MOT17
challenge.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures; Winner of the MOT17 challenge</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08317</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Cloud-based Service for Real-Time Performance Evaluation of NoSQL
  Databases</dc:title>
 <dc:creator>Almootassem, Omar</dc:creator>
 <dc:creator>Husain, Syed Hamza</dc:creator>
 <dc:creator>Parthipan, Denesh</dc:creator>
 <dc:creator>Mahmoud, Qusay H.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We have created a cloud-based service that allows the end users to run tests
on multiple different databases to find which databases are most suitable for
their project. From our research, we could not find another application that
enables the user to test several databases to gauge the difference between
them. This application allows the user to choose which type of test to perform
and which databases to target. The application also displays the results of
different tests that were run by other users previously. There is also a map to
show the location where all the tests are run to give the user an estimate of
the location. Unlike the orthodox static tests and reports conducted to
evaluate NoSQL databases, we have created a web application to run and analyze
these tests in real time. This web application evaluates the performance of
several NoSQL databases. The databases covered are MongoDB, DynamoDB, CouchDB,
and Firebase. The web service is accessible from: nosqldb.nextproject.ca.
</dc:description>
 <dc:description>Comment: 5 pages, 4 tables</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08320</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Explaining Transition Systems through Program Induction</dc:title>
 <dc:creator>Penkov, Svetlin</dc:creator>
 <dc:creator>Ramamoorthy, Subramanian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Explaining and reasoning about processes which underlie observed black-box
phenomena enables the discovery of causal mechanisms, derivation of suitable
abstract representations and the formulation of more robust predictions. We
propose to learn high level functional programs in order to represent abstract
models which capture the invariant structure in the observed data. We introduce
the $\pi$-machine (program-induction machine) -- an architecture able to induce
interpretable LISP-like programs from observed data traces. We propose an
optimisation procedure for program learning based on backpropagation, gradient
descent and A* search. We apply the proposed method to three problems: system
identification of dynamical systems, explaining the behaviour of a DQN agent
and learning by demonstration in a human-robot interaction scenario. Our
experimental results show that the $\pi$-machine can efficiently induce
interpretable programs from individual data traces.
</dc:description>
 <dc:description>Comment: submitted to Neural Information Processing Systems 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08321</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Increasing Papers' Discoverability with Precise Semantic Labeling: the
  sci.AI Platform</dc:title>
 <dc:creator>Gurinovich, Roman</dc:creator>
 <dc:creator>Pashuk, Alexander</dc:creator>
 <dc:creator>Petrovskiy, Yuriy</dc:creator>
 <dc:creator>Dmitrievskij, Alex</dc:creator>
 <dc:creator>Kuryan, Oleg</dc:creator>
 <dc:creator>Scerbacov, Alexei</dc:creator>
 <dc:creator>Tiggre, Antonia</dc:creator>
 <dc:creator>Moroz, Elena</dc:creator>
 <dc:creator>Nikolsky, Yuri</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The number of published findings in biomedicine increases continually. At the
same time, specifics of the domain's terminology complicates the task of
relevant publications retrieval. In the current research, we investigate
influence of terms' variability and ambiguity on a paper's likelihood of being
retrieved. We obtained statistics that demonstrate significance of the issue
and its challenges, followed by presenting the sci.AI platform, which allows
precise terms labeling as a resolution.
</dc:description>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08322</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavior of digital sequences through exotic numeration systems</dc:title>
 <dc:creator>Leroy, Julien</dc:creator>
 <dc:creator>Rigo, Michel</dc:creator>
 <dc:creator>Stipulanti, Manon</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>11A63, 11B85, 41A60</dc:subject>
 <dc:description>  Many digital functions studied in the literature, e.g., the summatory
function of the base-$k$ sum-of-digits function, have a behavior showing some
periodic fluctuation. Such functions are usually studied using techniques from
analytic number theory or linear algebra. In this paper we develop a method
based on exotic numeration systems and we apply it on two examples motivated by
the study of generalized Pascal triangles and binomial coefficients of words.
</dc:description>
 <dc:description>Comment: 32 pages, 27 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08322</dc:identifier>
 <dc:identifier>Electron. J. Combin. 24 (2017), no. 1, Paper 1.44, 36 pp</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08338</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Colonel Blotto Game for Interdependence-Aware Cyber-Physical Systems
  Security in Smart Cities</dc:title>
 <dc:creator>Ferdowsi, Aidin</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Maham, Behrouz</dc:creator>
 <dc:creator>Mandayam, Narayan B.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Smart cities must integrate a number of interdependent cyber-physical systems
that operate in a coordinated manner to improve the well-being of the city's
residents. A cyber-physical system (CPS) is a system of computational elements
controlling physical entities. Large-scale CPSs are more vulnerable to attacks
due to the cyber-physical interdependencies that can lead to cascading failures
which can have a significant detrimental effect on a city. In this paper, a
novel approach is proposed for analyzing the problem of allocating security
resources, such as firewalls and anti-malware, over the various cyber
components of an interdependent CPS to protect the system against imminent
attacks. The problem is formulated as a Colonel Blotto game in which the
attacker seeks to allocate its resources to compromise the CPS, while the
defender chooses how to distribute its resources to defend against potential
attacks. To evaluate the effects of defense and attack, various CPS factors are
considered including human-CPS interactions as well as physical and topological
characteristics of a CPS such as flow and capacity of interconnections and
minimum path algorithms. Results show that, for the case in which the attacker
is not aware of the CPS interdependencies, the defender can have a higher
payoff, compared to the case in which the attacker has complete information.
The results also show that, in the case of more symmetric nodes, due to
interdependencies, the defender achieves its highest payoff at the equilibrium
compared to the case with independent, asymmetric nodes.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08338</dc:identifier>
 <dc:identifier>doi:10.1145/3063386.3063765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08339</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Precoding Systems in Multi-Gateway Multibeam Satellites:
  Regularization and Coarse Beamforming</dc:title>
 <dc:creator>Mosquera, Carlos</dc:creator>
 <dc:creator>Lopez-Valcarce, Roberto</dc:creator>
 <dc:creator>Joroughi, Vahid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper deals with the problem of beamforming design in a multibeam
satellite, which is shared by different groups of terminals -clusters-, each
served by an Earth station or gateway. Each gateway precodes the symbols
addressed to its respective users; the design follows an MMSE criterion, and a
regularization factor judiciously chosen allows to account for the presence of
mutually interfering clusters, extending more classical results applicable to
one centralized station. More importantly, channel statistics can be used
instead of instantaneous channel state information, avoiding the exchange of
information among gateways through backhaul links. The on-board satellite
beamforming weights are designed to exploit the degrees of freedom of the
satellite antennas to minimize the noise impact and the interference to some
specific users. On-ground beamforming results are provided as a reference to
compare the joint performance of MMSE precoders and on-board beamforming
network. A non-adaptive design complements the results and makes them more
amenable to practical use by designing a coarse beamforming network.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08343</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting the number of non-zero coefficients in rows of generalized
  Pascal triangles</dc:title>
 <dc:creator>Leroy, Julien</dc:creator>
 <dc:creator>Rigo, Michel</dc:creator>
 <dc:creator>Stipulanti, Manon</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  This paper is about counting the number of distinct (scattered) subwords
occurring in a given word. More precisely, we consider the generalization of
the Pascal triangle to binomial coefficients of words and the sequence
$(S(n))_{n\ge 0}$ counting the number of positive entries on each row. By
introducing a convenient tree structure, we provide a recurrence relation for
$(S(n))_{n\ge 0}$. This leads to a connection with the $2$-regular Stern-Brocot
sequence and the sequence of denominators occurring in the Farey tree. Then we
extend our construction to the Zeckendorf numeration system based on the
Fibonacci sequence. Again our tree structure permits us to obtain recurrence
relations for and the F-regularity of the corresponding sequence.
</dc:description>
 <dc:description>Comment: 28 pages, 10 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08343</dc:identifier>
 <dc:identifier>Discrete Math. 340 (2017) 862-881</dc:identifier>
 <dc:identifier>doi:10.1016/j.disc.2017.01.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08350</identifier>
 <datestamp>2017-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding Cache Miss Costs of Multithreaded Computations Under General
  Schedulers</dc:title>
 <dc:creator>Cole, Richard</dc:creator>
 <dc:creator>Ramachandran, Vijaya</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We analyze the caching overhead incurred by a class of multithreaded
algorithms when scheduled by an arbitrary scheduler. We obtain bounds that
match or improve upon the well-known $O(Q+S \cdot (M/B))$ caching cost for the
randomized work stealing (RWS) scheduler, where $S$ is the number of steals,
$Q$ is the sequential caching cost, and $M$ and $B$ are the cache size and
block (or cache line) size respectively.
</dc:description>
 <dc:description>Comment: Extended abstract in Proceedings of ACM Symp. on Parallel Alg. and
  Architectures (SPAA) 2017, pp. 339-350. This revision has a few small updates
  including a missing citation and the replacement of some big Oh terms with
  precise constants</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08360</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient and principled score estimation with Nystr\&quot;om kernel
  exponential families</dc:title>
 <dc:creator>Sutherland, Dougal J.</dc:creator>
 <dc:creator>Strathmann, Heiko</dc:creator>
 <dc:creator>Arbel, Michael</dc:creator>
 <dc:creator>Gretton, Arthur</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We propose a fast method with statistical guarantees for learning an
exponential family density model where the natural parameter is in a
reproducing kernel Hilbert space, and may be infinite-dimensional. The model is
learned by fitting the derivative of the log density, the score, thus avoiding
the need to compute a normalization constant. Our approach improves the
computational efficiency of an earlier solution by using a low-rank,
Nystr\&quot;om-like solution. The new solution retains the consistency and
convergence rates of the full-rank solution (exactly in Fisher distance, and
nearly in other distances), with guarantees on the degree of cost and storage
reduction. We evaluate the method in experiments on density estimation and in
the construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an
existing score learning approach using a denoising autoencoder, our estimator
is empirically more data-efficient when estimating the score, runs faster, and
has fewer parameters (which can be tuned in a principled and interpretable
way), in addition to providing statistical guarantees.
</dc:description>
 <dc:description>Comment: v4: support subsampling dimensions, many other small improvements</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08362</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Coalgebraic Partition Refinement</dc:title>
 <dc:creator>Dorsch, Ulrich</dc:creator>
 <dc:creator>Milius, Stefan</dc:creator>
 <dc:creator>Schr&#xf6;der, Lutz</dc:creator>
 <dc:creator>Wi&#xdf;mann, Thorsten</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present a generic partition refinement algorithm that quotients
coalgebraic systems by behavioural equivalence, an important task in reactive
verification; coalgebraic generality implies in particular that we cover not
only classical relational systems but also various forms of weighted systems.
Under assumptions on the type functor that allow representing its finite
coalgebras in terms of nodes and edges, our algorithm runs in time
$\mathcal{O}(m\cdot \log n)$ where $n$ and $m$ are the numbers of nodes and
edges, respectively. Instances of our generic algorithm thus match the runtime
of the best known algorithms for unlabelled transition systems, Markov chains,
and deterministic automata (with fixed alphabets), and improve the best known
algorithms for Segala systems.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08362</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08369</identifier>
 <datestamp>2017-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Her2 Challenge Contest: A Detailed Assessment of Automated Her2 Scoring
  Algorithms in Whole Slide Images of Breast Cancer Tissues</dc:title>
 <dc:creator>Qaiser, Talha</dc:creator>
 <dc:creator>Mukherjee, Abhik</dc:creator>
 <dc:creator>Pb, Chaitanya Reddy</dc:creator>
 <dc:creator>Munugoti, Sai Dileep</dc:creator>
 <dc:creator>Tallam, Vamsi</dc:creator>
 <dc:creator>Pitk&#xe4;aho, Tomi</dc:creator>
 <dc:creator>Lehtim&#xe4;ki, Taina</dc:creator>
 <dc:creator>Naughton, Thomas</dc:creator>
 <dc:creator>Berseth, Matt</dc:creator>
 <dc:creator>Pedraza, An&#xed;bal</dc:creator>
 <dc:creator>Mukundan, Ramakrishnan</dc:creator>
 <dc:creator>Smith, Matthew</dc:creator>
 <dc:creator>Bhalerao, Abhir</dc:creator>
 <dc:creator>Rodner, Erik</dc:creator>
 <dc:creator>Simon, Marcel</dc:creator>
 <dc:creator>Denzler, Joachim</dc:creator>
 <dc:creator>Huang, Chao-Hui</dc:creator>
 <dc:creator>Bueno, Gloria</dc:creator>
 <dc:creator>Snead, David</dc:creator>
 <dc:creator>Ellis, Ian</dc:creator>
 <dc:creator>Ilyas, Mohammad</dc:creator>
 <dc:creator>Rajpoot, Nasir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Evaluating expression of the Human epidermal growth factor receptor 2 (Her2)
by visual examination of immunohistochemistry (IHC) on invasive breast cancer
(BCa) is a key part of the diagnostic assessment of BCa due to its recognised
importance as a predictive and prognostic marker in clinical practice. However,
visual scoring of Her2 is subjective and consequently prone to inter-observer
variability. Given the prognostic and therapeutic implications of Her2 scoring,
a more objective method is required. In this paper, we report on a recent
automated Her2 scoring contest, held in conjunction with the annual PathSoc
meeting held in Nottingham in June 2016, aimed at systematically comparing and
advancing the state-of-the-art Artificial Intelligence (AI) based automated
methods for Her2 scoring. The contest dataset comprised of digitised whole
slide images (WSI) of sections from 86 cases of invasive breast carcinoma
stained with both Haematoxylin &amp; Eosin (H&amp;E) and IHC for Her2. The contesting
algorithms automatically predicted scores of the IHC slides for an unseen
subset of the dataset and the predicted scores were compared with the 'ground
truth' (a consensus score from at least two experts). We also report on a
simple Man vs Machine contest for the scoring of Her2 and show that the
automated methods could beat the pathology experts on this contest dataset.
This paper presents a benchmark for comparing the performance of automated
algorithms for scoring of Her2. It also demonstrates the enormous potential of
automated algorithms in assisting the pathologist with objective IHC scoring.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08369</dc:identifier>
 <dc:identifier>doi:10.1111/his.13333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08374</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Aerial Photogrammetric 3D Point Clouds</dc:title>
 <dc:creator>Becker, Carlos</dc:creator>
 <dc:creator>H&#xe4;ni, Nicolai</dc:creator>
 <dc:creator>Rosinskaya, Elena</dc:creator>
 <dc:creator>d'Angelo, Emmanuel</dc:creator>
 <dc:creator>Strecha, Christoph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a powerful method to extract per-point semantic class labels from
aerialphotogrammetry data. Labeling this kind of data is important for tasks
such as environmental modelling, object classification and scene understanding.
Unlike previous point cloud classification methods that rely exclusively on
geometric features, we show that incorporating color information yields a
significant increase in accuracy in detecting semantic classes. We test our
classification method on three real-world photogrammetry datasets that were
generated with Pix4Dmapper Pro, and with varying point densities. We show that
off-the-shelf machine learning techniques coupled with our new features allow
us to train highly accurate classifiers that generalize well to unseen data,
processing point clouds containing 10 million points in less than 3 minutes on
a desktop computer.
</dc:description>
 <dc:description>Comment: ISPRS 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08378</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Adversarial Examples in Deep Networks with Adaptive Noise
  Reduction</dc:title>
 <dc:creator>Liang, Bin</dc:creator>
 <dc:creator>Li, Hongcheng</dc:creator>
 <dc:creator>Su, Miaoqiang</dc:creator>
 <dc:creator>Li, Xirong</dc:creator>
 <dc:creator>Shi, Wenchang</dc:creator>
 <dc:creator>Wang, Xiaofeng</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) play a key role in many applications.
Unsurprisingly, they also became a potential attack target of adversaries. Some
studies have demonstrated DNN classifiers can be fooled by the adversarial
example, which is crafted via introducing some perturbations into an original
sample. Accordingly, some powerful defense techniques were proposed against
adversarial examples. However, existing defense techniques require modifying
the target model or depend on the prior knowledge of attack techniques to
different degrees. In this paper, we propose a straightforward method for
detecting adversarial image examples. It doesn't require any prior knowledge of
attack techniques and can be directly deployed into unmodified off-the-shelf
DNN models. Specifically, we consider the perturbation to images as a kind of
noise and introduce two classical image processing techniques, scalar
quantization and smoothing spatial filter, to reduce its effect. The image
two-dimensional entropy is employed as a metric to implement an adaptive noise
reduction for different kinds of images. As a result, the adversarial example
can be effectively detected by comparing the classification results of a given
sample and its denoised version. Thousands of adversarial examples against some
state-of-the-art DNN models are used to evaluate the proposed method, which are
crafted with different attack techniques. The experiment shows that our
detection method can achieve an overall recall of 93.73% and an overall
precision of 95.47% without referring to any prior knowledge of attack
techniques.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08379</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect Edge Domination: Hard and Solvable Cases</dc:title>
 <dc:creator>Lin, Min Chih</dc:creator>
 <dc:creator>Lozin, Vadim</dc:creator>
 <dc:creator>Moyano, Veronica A.</dc:creator>
 <dc:creator>Szwarcfiter, Jayme L.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Let $G$ be an undirected graph. An edge of $G$ dominates itself and all edges
adjacent to it. A subset $E'$ of edges of $G$ is an edge dominating set of $G$,
if every edge of the graph is dominated by some edge of $E'$. We say that $E'$
is a perfect edge dominating set of $G$, if every edge not in $E'$ is dominated
by exactly one edge of $E'$. The perfect edge dominating problem is to
determine a least cardinality perfect edge dominating set of $G$. For this
problem, we describe two NP-completeness proofs, for the classes of claw-free
graphs of degree at most 3, and for bounded degree graphs, of maximum degree at
most $d \geq 3$ and large girth. In contrast, we prove that the problem admits
an $O(n)$ time solution, for cubic claw-free graphs. In addition, we prove a
complexity dichotomy theorem for the perfect edge domination problem, based on
the results described in the paper. Finally, we describe a linear time
algorithm for finding a minimum weight perfect edge dominating set of a
$P_5$-free graph. The algorithm is robust, in the sense that, given an
arbitrary graph $G$, either it computes a minimum weight perfect edge
dominating set of $G$, or it exhibits an induced subgraph of $G$, isomorphic to
a $P_5$.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08380</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An evolutionary strategy for DeltaE - E identification</dc:title>
 <dc:creator>Schmidt, Katarzyna</dc:creator>
 <dc:creator>Wyszynski, Oskar</dc:creator>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Nuclear Experiment</dc:subject>
 <dc:description>  In this article we present an automatic method for charge and mass
identification of charged nuclear fragments produced in heavy ion collisions at
intermediate energies. The algorithm combines a generative model of DeltaE - E
relation and a Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES). The
CMA-ES is a stochastic and derivative-free method employed to search parameter
space of the model by means of a fitness function. The article describes
details of the method along with results of an application on simulated labeled
data.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08380</dc:identifier>
 <dc:identifier>doi:10.1088/1748-0221/12/09/P09007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08382</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitoring Information Quality within Web Service Composition and
  Execution</dc:title>
 <dc:creator>Thi, Thanh Thoa Pham</dc:creator>
 <dc:creator>Helfert, Markus</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The composition of web services is a promising approach enabling flexible and
loose integration of business applications. Numerous approaches related to web
services composition have been developed usually following three main phases:
the service discovery is based on the semantic description of advertised
services, i.e. the functionality of the service, meanwhile the service
selection is based on non- functional quality dimensions of service, and
finally the service composition aims to support an underlying process. Most of
those approaches explore techniques of static or dynamic design for an optimal
service composition. One important aspect so far is mostly neglected, focusing
on the output produced of composite web services. In this paper, in contrast to
many prominent approaches we introduce a data quality perspective on web
services. Based on a data quality management approach, we propose a framework
for analyzing data produced by the composite service execution. Utilising
process information together with data in service logs, our approach allows
identifying problems in service composition and execution. Analyzing the
service execution history our approach helps to improve common approaches of
service selection and composition.
</dc:description>
 <dc:description>Comment: International Conference on Information Systems Development, ISD
  2011, Springer</dc:description>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08382</dc:identifier>
 <dc:identifier>doi:10.1007/978-1-4614-4951-5_47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08386</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Text Understanding Through Image-To-Text Transfer</dc:title>
 <dc:creator>Kurach, Karol</dc:creator>
 <dc:creator>Gelly, Sylvain</dc:creator>
 <dc:creator>Jastrzebski, Michal</dc:creator>
 <dc:creator>Haeusser, Philip</dc:creator>
 <dc:creator>Teytaud, Olivier</dc:creator>
 <dc:creator>Vincent, Damien</dc:creator>
 <dc:creator>Bousquet, Olivier</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generic text embeddings are successfully used in a variety of tasks. However,
they are often learnt by capturing the co-occurrence structure from pure text
corpora, resulting in limitations of their ability to generalize. In this
paper, we explore models that incorporate visual information into the text
representation. Based on comprehensive ablation studies, we propose a
conceptually simple, yet well performing architecture. It outperforms previous
multimodal approaches on a set of well established benchmarks. We also improve
the state-of-the-art results for image-related text datasets, using orders of
magnitude less data.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08391</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponential error rates of SDP for block models: Beyond Grothendieck's
  inequality</dc:title>
 <dc:creator>Fei, Yingjie</dc:creator>
 <dc:creator>Chen, Yudong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this paper we consider the cluster estimation problem under the Stochastic
Block Model. We show that the semidefinite programming (SDP) formulation for
this problem achieves an error rate that decays exponentially in the
signal-to-noise ratio. The error bound implies weak recovery in the sparse
graph regime with bounded expected degrees, as well as exact recovery in the
dense regime. An immediate corollary of our results yields error bounds under
the Censored Block Model. Moreover, these error bounds are robust, continuing
to hold under heterogeneous edge probabilities and a form of the so-called
monotone attack.
  Significantly, this error rate is achieved by the SDP solution itself without
any further pre- or post-processing, and improves upon existing
polynomially-decaying error bounds proved using the Grothendieck\textquoteright
s inequality. Our analysis has two key ingredients: (i) showing that the graph
has a well-behaved spectrum, even in the sparse regime, after discounting an
exponentially small number of edges, and (ii) an order-statistics argument that
governs the final error rate. Both arguments highlight the implicit
regularization effect of the SDP formulation.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08392</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decidable Confluence Test for Cognitive Models in ACT-R</dc:title>
 <dc:creator>Gall, Daniel</dc:creator>
 <dc:creator>Fr&#xfc;hwirth, Thom</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Computational cognitive modeling investigates human cognition by building
detailed computational models for cognitive processes. Adaptive Control of
Thought - Rational (ACT-R) is a rule-based cognitive architecture that offers a
widely employed framework to build such models. There is a sound and complete
embedding of ACT-R in Constraint Handling Rules (CHR). Therefore analysis
techniques from CHR can be used to reason about computational properties of
ACT-R models. For example, confluence is the property that a program yields the
same result for the same input regardless of the rules that are applied.
  In ACT-R models, there are often cognitive processes that should always yield
the same result while others e.g. implement strategies to solve a problem that
could yield different results. In this paper, a decidable confluence criterion
for ACT-R is presented. It allows to identify ACT-R rules that are not
confluent. Thereby, the modeler can check if his model has the desired
behavior.
  The sound and complete translation of ACT-R to CHR from prior work is used to
come up with a suitable invariant-based confluence criterion from the CHR
literature. Proper invariants for translated ACT-R models are identified and
proven to be decidable. The presented method coincides with confluence of the
original ACT-R models.
</dc:description>
 <dc:description>Comment: To appear in Stefania Costantini, Enrico Franconi, William Van
  Woensel, Roman Kontchakov, Fariba Sadri, and Dumitru Roman: &quot;Proceedings of
  RuleML+RR 2017&quot;. Springer LNCS</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08394</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information Theoretic Principles of Universal Discrete Denoising</dc:title>
 <dc:creator>N&#xf6;tzel, Janis</dc:creator>
 <dc:creator>Winter, Andreas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Today, the internet makes tremendous amounts of data widely available. Often,
the same information is behind multiple different available data sets. This
lends growing importance to latent variable models that try to learn the hidden
information from the available imperfect versions. For example, social media
platforms can contain an abundance of pictures of the same person or object,
yet all of which are taken from different perspectives. In a simplified
scenario, one may consider pictures taken from the same perspective, which are
distorted by noise. This latter application allows for a rigorous mathematical
treatment, which is the content of this contribution. We apply a recently
developed method of dependent component analysis to image denoising when
multiple distorted copies of one and the same image are available, each being
corrupted by a different and unknown noise process. In a simplified scenario,
we assume that the distorted image is corrupted by noise that acts
independently on each pixel. We answer completely the question of how to
perform optimal denoising, when at least three distorted copies are available:
First we define optimality of an algorithm in the presented scenario, and then
we describe an aymptotically optimal universal discrete denoising algorithm
(UDDA). In the case of binary data and binary symmetric noise, we develop a
simplified variant of the algorithm, dubbed BUDDA, which we prove to attain
universal denoising uniformly.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08395</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continual Learning in Generative Adversarial Nets</dc:title>
 <dc:creator>Seff, Ari</dc:creator>
 <dc:creator>Beatson, Alex</dc:creator>
 <dc:creator>Suo, Daniel</dc:creator>
 <dc:creator>Liu, Han</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Developments in deep generative models have allowed for tractable learning of
high-dimensional data distributions. While the employed learning procedures
typically assume that training data is drawn i.i.d. from the distribution of
interest, it may be desirable to model distinct distributions which are
observed sequentially, such as when different classes are encountered over
time. Although conditional variations of deep generative models permit multiple
distributions to be modeled by a single network in a disentangled fashion, they
are susceptible to catastrophic forgetting when the distributions are
encountered sequentially. In this paper, we adapt recent work in reducing
catastrophic forgetting to the task of training generative adversarial networks
on a sequence of distinct distributions, enabling continual generative
modeling.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08399</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Timed k-Tail: Automatic Inference of Timed Automata</dc:title>
 <dc:creator>Pastore, Fabrizio</dc:creator>
 <dc:creator>Micucci, Daniela</dc:creator>
 <dc:creator>Mariani, Leonardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Accurate and up-to-date models describing the be- havior of software systems
are seldom available in practice. To address this issue, software engineers may
use specification mining techniques, which can automatically derive models that
capture the behavior of the system under analysis. So far, most specification
mining techniques focused on the functional behavior of the systems, with
specific emphasis on models that represent the ordering of operations, such as
tempo- ral rules and finite state models. Although useful, these models are
inherently partial. For instance, they miss the timing behavior, which is
extremely relevant for many classes of systems and com- ponents, such as shared
libraries and user-driven applications. Mining specifications that include both
the functional and the timing aspects can improve the applicability of many
testing and analysis solutions. This paper addresses this challenge by
presenting the Timed k-Tail (TkT) specification mining technique that can mine
timed automata from program traces. Since timed automata can effectively
represent the interplay between the functional and the timing behavior of a
system, TkT could be exploited in those contexts where time-related information
is relevant. Our empirical evaluation shows that TkT can efficiently and
effectively mine accurate models. The mined models have been used to identify
executions with anomalous timing. The evaluation shows that most of the
anomalous executions have been correctly identified while producing few false
positives.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08409</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ridesourcing Car Detection by Transfer Learning</dc:title>
 <dc:creator>Wang, Leye</dc:creator>
 <dc:creator>Geng, Xu</dc:creator>
 <dc:creator>Ke, Jintao</dc:creator>
 <dc:creator>Peng, Chen</dc:creator>
 <dc:creator>Ma, Xiaojuan</dc:creator>
 <dc:creator>Zhang, Daqing</dc:creator>
 <dc:creator>Yang, Qiang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Ridesourcing platforms like Uber and Didi are getting more and more popular
around the world. However, unauthorized ridesourcing activities taking
advantages of the sharing economy can greatly impair the healthy development of
this emerging industry. As the first step to regulate on-demand ride services
and eliminate black market, we design a method to detect ridesourcing cars from
a pool of cars based on their trajectories. Since licensed ridesourcing car
traces are not openly available and may be completely missing in some cities
due to legal issues, we turn to transferring knowledge from public transport
open data, i.e, taxis and buses, to ridesourcing detection among ordinary
vehicles. We propose a two-stage transfer learning framework. In Stage 1, we
take taxi and bus data as input to learn a random forest (RF) classifier using
trajectory features shared by taxis/buses and ridesourcing/other cars. Then, we
use the RF to label all the candidate cars. In Stage 2, leveraging the subset
of high confident labels from the previous stage as input, we further learn a
convolutional neural network (CNN) classifier for ridesourcing detection, and
iteratively refine RF and CNN, as well as the feature set, via a co-training
process. Finally, we use the resulting ensemble of RF and CNN to identify the
ridesourcing cars in the candidate pool. Experiments on real car, taxi and bus
traces show that our transfer learning framework, with no need of a pre-labeled
ridesourcing dataset, can achieve similar accuracy as the supervised learning
methods.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08417</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning with a Corrupted Reward Channel</dc:title>
 <dc:creator>Everitt, Tom</dc:creator>
 <dc:creator>Krakovna, Victoria</dc:creator>
 <dc:creator>Orseau, Laurent</dc:creator>
 <dc:creator>Hutter, Marcus</dc:creator>
 <dc:creator>Legg, Shane</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  No real-world reward function is perfect. Sensory errors and software bugs
may result in RL agents observing higher (or lower) rewards than they should.
For example, a reinforcement learning agent may prefer states where a sensory
error gives it the maximum reward, but where the true reward is actually small.
We formalise this problem as a generalised Markov Decision Problem called
Corrupt Reward MDP. Traditional RL methods fare poorly in CRMDPs, even under
strong simplifying assumptions and when trying to compensate for the possibly
corrupt rewards. Two ways around the problem are investigated. First, by giving
the agent richer data, such as in inverse reinforcement learning and
semi-supervised reinforcement learning, reward corruption stemming from
systematic sensory errors may sometimes be completely managed. Second, by using
randomisation to blunt the agent's optimisation, reward corruption can be
partially managed under some assumptions.
</dc:description>
 <dc:description>Comment: A shorter version of this report was accepted to IJCAI 2017 AI and
  Autonomy track</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08418</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Analysis of Regression Problems in Industrial Systems:
  Challenges and Solutions</dc:title>
 <dc:creator>Pastore, Fabrizio</dc:creator>
 <dc:creator>Mariani, Leonardo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents the result of our experience with the ap- plication of
runtime verification, testing and static analysis techniques to several
industrial projects. We discuss the eight most relevant challenges that we
experienced, and the strategies that we elaborated to face them.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08418</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-47169-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08421</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>AVA: A Video Dataset of Spatio-temporally Localized Atomic Visual
  Actions</dc:title>
 <dc:creator>Gu, Chunhui</dc:creator>
 <dc:creator>Sun, Chen</dc:creator>
 <dc:creator>Ross, David A.</dc:creator>
 <dc:creator>Vondrick, Carl</dc:creator>
 <dc:creator>Pantofaru, Caroline</dc:creator>
 <dc:creator>Li, Yeqing</dc:creator>
 <dc:creator>Vijayanarasimhan, Sudheendra</dc:creator>
 <dc:creator>Toderici, George</dc:creator>
 <dc:creator>Ricco, Susanna</dc:creator>
 <dc:creator>Sukthankar, Rahul</dc:creator>
 <dc:creator>Schmid, Cordelia</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a video dataset of spatio-temporally localized Atomic
Visual Actions (AVA). The AVA dataset densely annotates 80 atomic visual
actions in 192 15-minute video clips, where actions are localized in space and
time, resulting in 740k action labels with multiple labels per person occurring
frequently. The key characteristics of our dataset are: (1) the definition of
atomic visual actions, rather than composite actions; (2) precise
spatio-temporal annotations with possibly multiple annotations for each person;
(3) exhaustive annotation of these atomic actions over 15-minute video clips;
(4) people temporally linked across consecutive segments; and (5) using movies
to gather a varied set of action representations. This departs from existing
datasets for spatio-temporal action recognition, which typically provide sparse
annotations for composite actions in short video clips. We will release the
dataset publicly.
  AVA, with its realistic scene and action complexity, exposes the intrinsic
difficulty of action recognition. To benchmark this, we present a novel
approach for action localization that builds upon the current state-of-the-art
methods, and demonstrates better performance on JHMDB and UCF101-24 categories.
While setting a new state of the art on existing datasets, the overall results
on AVA are low at 16.2% mAP, underscoring the need for developing new
approaches for video understanding.
</dc:description>
 <dc:description>Comment: 15 pages. Check dataset page https://research.google.com/ava/ for
  details</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08422</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous State-Space Models for Optimal Sepsis Treatment - a Deep
  Reinforcement Learning Approach</dc:title>
 <dc:creator>Raghu, Aniruddh</dc:creator>
 <dc:creator>Komorowski, Matthieu</dc:creator>
 <dc:creator>Celi, Leo Anthony</dc:creator>
 <dc:creator>Szolovits, Peter</dc:creator>
 <dc:creator>Ghassemi, Marzyeh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Sepsis is a leading cause of mortality in intensive care units (ICUs) and
costs hospitals billions annually. Treating a septic patient is highly
challenging, because individual patients respond very differently to medical
interventions and there is no universally agreed-upon treatment for sepsis.
Understanding more about a patient's physiological state at a given time could
hold the key to effective treatment policies. In this work, we propose a new
approach to deduce optimal treatment policies for septic patients by using
continuous state-space models and deep reinforcement learning. Learning
treatment policies over continuous spaces is important, because we retain more
of the patient's physiological information. Our model is able to learn
clinically interpretable treatment policies, similar in important aspects to
the treatment policies of physicians. Evaluating our algorithm on past ICU
patient data, we find that our model could reduce patient mortality in the
hospital by up to 3.6% over observed clinical policies, from a baseline
mortality of 13.7%. The learned treatment policies could be used to aid
intensive care clinicians in medical decision making and improve the likelihood
of patient survival.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08426</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic LTLf Synthesis</dc:title>
 <dc:creator>Zhu, Shufang</dc:creator>
 <dc:creator>Tabajara, Lucas M.</dc:creator>
 <dc:creator>Li, Jianwen</dc:creator>
 <dc:creator>Pu, Geguang</dc:creator>
 <dc:creator>Vardi, Moshe Y.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  LTLf synthesis is the process of finding a strategy that satisfies a linear
temporal specification over finite traces. An existing solution to this problem
relies on a reduction to a DFA game. In this paper, we propose a symbolic
framework for LTLf synthesis based on this technique, by performing the
computation over a representation of the DFA as a boolean formula rather than
as an explicit graph. This approach enables strategy generation by utilizing
the mechanism of boolean synthesis. We implement this symbolic synthesis method
in a tool called Syft, and demonstrate by experiments on scalable benchmarks
that the symbolic approach scales better than the explicit one.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08430</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Submultiplicative Glivenko-Cantelli and Uniform Convergence of Revenues</dc:title>
 <dc:creator>Alon, Noga</dc:creator>
 <dc:creator>Babaioff, Moshe</dc:creator>
 <dc:creator>Gonczarowski, Yannai A.</dc:creator>
 <dc:creator>Mansour, Yishay</dc:creator>
 <dc:creator>Moran, Shay</dc:creator>
 <dc:creator>Yehudayoff, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this work we derive a variant of the classic Glivenko-Cantelli Theorem,
which asserts uniform convergence of the empirical Cumulative Distribution
Function (CDF) to the CDF of the underlying distribution. Our variant allows
for tighter convergence bounds for extreme values of the CDF.
  We apply our bound in the context of revenue learning, which is a
well-studied problem in economics and algorithmic game theory. We derive
sample-complexity bounds on the uniform convergence rate of the empirical
revenues to the true revenues, assuming a bound on the $k$th moment of the
valuations, for any (possibly fractional) $k&gt;1$.
  For uniform convergence in the limit, we give a complete characterization and
a zero-one law: if the first moment of the valuations is finite, then uniform
convergence almost surely occurs; conversely, if the first moment is infinite,
then uniform convergence almost never occurs.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08432</identifier>
 <datestamp>2017-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Question-Answering with Grammatically-Interpretable Representations</dc:title>
 <dc:creator>Palangi, Hamid</dc:creator>
 <dc:creator>Smolensky, Paul</dc:creator>
 <dc:creator>He, Xiaodong</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce an architecture, the Tensor Product Recurrent Network (TPRN). In
our application of TPRN, internal representations learned by end-to-end
optimization in a deep neural network performing a textual question-answering
(QA) task can be interpreted using basic concepts from linguistic theory. No
performance penalty need be paid for this increased interpretability: the
proposed model performs comparably to a state-of-the-art system on the SQuAD QA
task. The internal representation which is interpreted is a Tensor Product
Representation: for each input word, the model selects a symbol to encode the
word, and a role in which to place the symbol, and binds the two together. The
selection is via soft attention. The overall interpretation is built from
interpretations of the symbols, as recruited by the trained model, and
interpretations of the roles as used by the model. We find support for our
initial hypothesis that symbols can be interpreted as lexical-semantic word
meanings, while roles can be interpreted as approximations of grammatical roles
(or categories) such as subject, wh-word, determiner, etc. Fine-grained
analysis reveals specific correspondences between the learned roles and parts
of speech as assigned by a standard tagger (Toutanova et al. 2003), and finds
several discrepancies in the model's favor. In this sense, the model learns
significant aspects of grammar, after having been exposed solely to
linguistically unannotated text, questions, and answers: no prior linguistic
knowledge is given to the model. What is given is the means to build
representations using symbols and roles, with an inductive bias favoring use of
these in an approximately discrete manner.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08435</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Differentially Private Algorithms for Decentralized
  Collaborative Machine Learning</dc:title>
 <dc:creator>Bellet, Aur&#xe9;lien</dc:creator>
 <dc:creator>Guerraoui, Rachid</dc:creator>
 <dc:creator>Taziki, Mahsa</dc:creator>
 <dc:creator>Tommasi, Marc</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Consider a set of agents in a peer-to-peer communication network, where each
agent has a personal dataset and a personal learning objective. The main
question addressed in this paper is: how can agents collaborate to improve upon
their locally learned model without leaking sensitive information about their
data? Our first contribution is to reformulate this problem so that it can be
solved by a block coordinate descent algorithm. We obtain an efficient and
fully decentralized protocol working in an asynchronous fashion. Our second
contribution is to make our algorithm differentially private to protect against
the disclosure of any information about personal datasets. We prove convergence
rates and exhibit the trade-off between utility and privacy. Our experiments
show that our approach dramatically outperforms previous work in the
non-private case, and that under privacy constraints we significantly improve
over purely local models.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08437</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserving Privacy while Broadcasting: $k$-Limited-Access Schemes</dc:title>
 <dc:creator>Karmoose, Mohammed</dc:creator>
 <dc:creator>Song, Linqi</dc:creator>
 <dc:creator>Cardone, Martina</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Index coding employs coding across clients within the same broadcast domain.
This typically assumes that all clients learn the coding matrix so that they
can decode and retrieve their requested data. However, learning the coding
matrix can pose privacy concerns: it may enable clients to infer information
about the requests and side information of other clients [1]. In this paper, we
formalize the intuition that the achieved privacy can increase by decreasing
the number of rows of the coding matrix that a client learns. Based on this, we
propose the use of $k$-limited-access schemes: given an index coding scheme
that employs $T$ transmissions, we create a $k$-limited-access scheme with
$T_k\geq T$ transmissions, and with the property that each client learns at
most $k$ rows of the coding matrix to decode its message. We derive upper and
lower bounds on $T_k$ for all values of $k$, and develop deterministic designs
for these schemes for which $T_k$ has an order-optimal exponent for some
regimes.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08438</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Multiparty Communication Complexity of Testing Triangle-Freeness</dc:title>
 <dc:creator>Fischer, Orr</dc:creator>
 <dc:creator>Gershtein, Shay</dc:creator>
 <dc:creator>Oshman, Rotem</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper we initiate the study of property testing in simultaneous and
non-simultaneous multi-party communication complexity, focusing on testing
triangle-freeness in graphs. We consider the $\textit{coordinator}$ model,
where we have $k$ players receiving private inputs, and a coordinator who
receives no input; the coordinator can communicate with all the players, but
the players cannot communicate with each other. In this model, we ask: if an
input graph is divided between the players, with each player receiving some of
the edges, how many bits do the players and the coordinator need to exchange to
determine if the graph is triangle-free, or $\textit{far}$ from triangle-free?
  For general communication protocols, we show that
$\tilde{O}(k(nd)^{1/4}+k^2)$ bits are sufficient to test triangle-freeness in
graphs of size $n$ with average degree $d$ (the degree need not be known in
advance). For $\textit{simultaneous}$ protocols, where there is only one
communication round, we give a protocol that uses $\tilde{O}(k \sqrt{n})$ bits
when $d = O(\sqrt{n})$ and $\tilde{O}(k (nd)^{1/3})$ when $d =
\Omega(\sqrt{n})$; here, again, the average degree $d$ does not need to be
known in advance. We show that for average degree $d = O(1)$, our simultaneous
protocol is asymptotically optimal up to logarithmic factors. For higher
degrees, we are not able to give lower bounds on testing triangle-freeness, but
we give evidence that the problem is hard by showing that finding an edge that
participates in a triangle is hard, even when promised that at least a constant
fraction of the edges must be removed in order to make the graph triangle-free.
</dc:description>
 <dc:description>Comment: To Appear in PODC 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08439</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thinking Fast and Slow with Deep Learning and Tree Search</dc:title>
 <dc:creator>Anthony, Thomas</dc:creator>
 <dc:creator>Tian, Zheng</dc:creator>
 <dc:creator>Barber, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Sequential decision making problems, such as structured prediction, robotic
control, and game playing, require a combination of planning policies and
generalisation of those plans. In this paper, we present Expert Iteration
(ExIt), a novel reinforcement learning algorithm which decomposes the problem
into separate planning and generalisation tasks. Planning new policies is
performed by tree search, while a deep neural network generalises those plans.
Subsequently, tree search is improved by using the neural network policy to
guide search, increasing the strength of new plans. In contrast, standard deep
Reinforcement Learning algorithms rely on a neural network not only to
generalise plans, but to discover them too. We show that ExIt outperforms
REINFORCE for training a neural network to play the board game Hex, and our
final tree search agent, trained tabula rasa, defeats MoHex 1.0, the most
recent Olympiad Champion player to be publicly released.
</dc:description>
 <dc:description>Comment: v1 to v2: - Add a value function in MCTS - Some MCTS hyper-parameters
  changed - Repetition of experiments: improved accuracy and errors shown.
  (note the reduction in effect size for the tpt/cat experiment) - Results from
  a longer training run, including changes in expert strength in training -
  Comparison to MoHex. v3: clarify independence of ExIt and AG0. v4: see
  appendix E</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-12-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08440</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Acquisition, Representation \&amp; Manipulation in Decision
  Support Systems</dc:title>
 <dc:creator>Michalewicz, M.</dc:creator>
 <dc:creator>Wierzcho&#x144;, S. T.</dc:creator>
 <dc:creator>K&#x142;opotek, M. A.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we present a methodology and discuss some implementation issues
for a project on statistical/expert approach to data analysis and knowledge
acquisition. We discuss some general assumptions underlying the project.
Further, the requirements for a user-friendly computer assistant are specified
along with the nature of tools aiding the researcher. Next we show some aspects
of belief network approach and Dempster-Shafer (DST) methodology introduced in
practice to system SEAD. Specifically we present the application of DS
methodology to belief revision problem. Further a concept of an interface to
probabilistic and DS belief networks enabling a user to understand the
communication with a belief network based reasoning system is presented
</dc:description>
 <dc:description>Comment: Intelligent Information Systems Proceedings of a Workshop held in
  August\'ow, Poland, 7-11 June, 1993, pages 210- 238</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08449</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Developing an edge computing platform for real-time descriptive
  analytics</dc:title>
 <dc:creator>Cao, Hung</dc:creator>
 <dc:creator>Wachowicz, Monica</dc:creator>
 <dc:creator>Cha, Sangwhan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of Mobile Things encompasses stream data being generated by
sensors, network communications that pull and push these data streams, as well
as running processing and analytics that can effectively leverage actionable
information for transportation planning, management, and business advantage.
Edge computing emerges as a new paradigm that decentralizes the communication,
computation, control and storage resources from the cloud to the edge of the
network. This paper proposes an edge computing platform where mobile edge nodes
are physical devices deployed on a transit bus where descriptive analytics is
used to uncover meaningful patterns from real-time transit data streams. An
application experiment is used to evaluate the advantages and disadvantages of
our proposed platform to support descriptive analytics at a mobile edge node
and generate actionable information to transit managers.
</dc:description>
 <dc:description>Comment: Edge-based analytics, real-time transit data streams, fog computing,
  descriptive analytics, Internet of Mobile Things, edge computing, mobile
  cloud computing, mobile edge computing</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08449</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08459</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A complete characterisation of All-versus-Nothing arguments for
  stabiliser states</dc:title>
 <dc:creator>Abramsky, Samson</dc:creator>
 <dc:creator>Barbosa, Rui Soares</dc:creator>
 <dc:creator>Car&#xf9;, Giovanni</dc:creator>
 <dc:creator>Perdrix, Simon</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  An important class of contextuality arguments in quantum foundations are the
All-versus-Nothing (AvN) proofs, generalising a construction originally due to
Mermin. We present a general formulation of All-versus-Nothing arguments, and a
complete characterisation of all such arguments which arise from stabiliser
states. We show that every AvN argument for an n-qubit stabiliser state can be
reduced to an AvN proof for a three-qubit state which is local
Clifford-equivalent to the tripartite GHZ state. This is achieved through a
combinatorial characterisation of AvN arguments, the AvN triple Theorem, whose
proof makes use of the theory of graph states. This result enables the
development of a computational method to generate all the AvN arguments in
$\mathbb{Z}_2$ on n-qubit stabiliser states. We also present new insights into
the stabiliser formalism and its connections with logic.
</dc:description>
 <dc:description>Comment: 18 pages, 6 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08464</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Benefit of Being Flexible in Distributed Computation</dc:title>
 <dc:creator>Song, Linqi</dc:creator>
 <dc:creator>Srinivasavaradhan, Sundara Rajan</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In wireless distributed computing, networked nodes perform intermediate
computations over data placed in their memory and exchange these intermediate
values to calculate function values. In this paper we consider an asymmetric
setting where each node has access to a random subset of the data, i.e., we
cannot control the data placement. The paper makes a simple point: we can
realize significant benefits if we are allowed to be &quot;flexible&quot;, and decide
which node computes which function, in our system. We make this argument in the
case where each function depends on only two of the data messages, as is the
case in similarity searches. We establish a percolation in the behavior of the
system, where, depending on the amount of observed data, by being flexible, we
may need no communication at all.
</dc:description>
 <dc:description>Comment: Published in ITW, 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08473</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New methods to generate massive synthetic networks</dc:title>
 <dc:creator>Chakrabarti, Malay</dc:creator>
 <dc:creator>Heath, Lenwood</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  One of the biggest needs in network science research is access to large
realistic datasets. As data analytics methods permeate a range of diverse
disciplines---e.g., computational epidemiology, sustainability, social media
analytics, biology, and transportation--- network datasets that can exhibit
characteristics encountered in each of these disciplines becomes paramount. The
key technical issue is to be able to generate synthetic topologies with
pre-specified, arbitrary, degree distributions. Existing methods are limited in
their ability to faithfully reproduce macro-level characteristics of networks
while at the same time respecting particular degree distributions. We present a
suite of three algorithms that exploit the principle of residual degree
attenuation to generate synthetic topologies that adhere to macro-level
real-world characteristics. By evaluating these algorithms w.r.t. several
real-world datasets we demonstrate their ability to faithfully reproduce
network characteristics such as node degree, clustering coefficient, hop
length, and k-core structure distributions.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08475</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Guarantees on the Robustness of a Classifier against Adversarial
  Manipulation</dc:title>
 <dc:creator>Hein, Matthias</dc:creator>
 <dc:creator>Andriushchenko, Maksym</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recent work has shown that state-of-the-art classifiers are quite brittle, in
the sense that a small adversarial change of an originally with high confidence
correctly classified input leads to a wrong classification again with high
confidence. This raises concerns that such classifiers are vulnerable to
attacks and calls into question their usage in safety-critical systems. We show
in this paper for the first time formal guarantees on the robustness of a
classifier by giving instance-specific lower bounds on the norm of the input
manipulation required to change the classifier decision. Based on this analysis
we propose the Cross-Lipschitz regularization functional. We show that using
this form of regularization in kernel methods resp. neural networks improves
the robustness of the classifier without any loss in prediction performance.
</dc:description>
 <dc:description>Comment: final version accepted at NIPS 2017, fixed bug in implementation of
  Cross-Lipschitz regularization and lower bound computation, now results are
  better</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08479</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Input Fast-Forwarding for Better Deep Learning</dc:title>
 <dc:creator>Ibrahim, Ahmed</dc:creator>
 <dc:creator>Abbott, A. Lynn</dc:creator>
 <dc:creator>Hussein, Mohamed E.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a new architectural framework, known as input
fast-forwarding, that can enhance the performance of deep networks. The main
idea is to incorporate a parallel path that sends representations of input
values forward to deeper network layers. This scheme is substantially different
from &quot;deep supervision&quot; in which the loss layer is re-introduced to earlier
layers. The parallel path provided by fast-forwarding enhances the training
process in two ways. First, it enables the individual layers to combine
higher-level information (from the standard processing path) with lower-level
information (from the fast-forward path). Second, this new architecture reduces
the problem of vanishing gradients substantially because the fast-forwarding
path provides a shorter route for gradient backpropagation. In order to
evaluate the utility of the proposed technique, a Fast-Forward Network (FFNet),
with 20 convolutional layers along with parallel fast-forward paths, has been
created and tested. The paper presents empirical results that demonstrate
improved learning capacity of FFNet due to fast-forwarding, as compared to
GoogLeNet (with deep supervision) and CaffeNet, which are 4x and 18x larger in
size, respectively. All of the source code and deep learning models described
in this paper will be made available to the entire research community
</dc:description>
 <dc:description>Comment: Accepted in the 14th International Conference on Image Analysis and
  Recognition (ICIAR) 2017, Montreal, Canada</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08479</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08480</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently applying attention to sequential data with the Recurrent
  Discounted Attention unit</dc:title>
 <dc:creator>Maginnis, Brendan</dc:creator>
 <dc:creator>Richemond, Pierre H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent Neural Networks architectures excel at processing sequences by
modelling dependencies over different timescales. The recently introduced
Recurrent Weighted Average (RWA) unit captures long term dependencies far
better than an LSTM on several challenging tasks. The RWA achieves this by
applying attention to each input and computing a weighted average over the full
history of its computations. Unfortunately, the RWA cannot change the attention
it has assigned to previous timesteps, and so struggles with carrying out
consecutive tasks or tasks with changing requirements. We present the Recurrent
Discounted Attention (RDA) unit that builds on the RWA by additionally allowing
the discounting of the past.
  We empirically compare our model to RWA, LSTM and GRU units on several
challenging tasks. On tasks with a single output the RWA, RDA and GRU units
learn much quicker than the LSTM and with better performance. On the multiple
sequence copy task our RDA unit learns the task three times as quickly as the
LSTM or GRU units while the RWA fails to learn at all. On the Wikipedia
character prediction task the LSTM performs best but it followed closely by our
RDA unit. Overall our RDA unit performs well and is sample efficient on a large
variety of sequence tasks.
</dc:description>
 <dc:description>Comment: Updated results of RDA-exp-tanh unit for the wikipedia char
  prediction task</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08481</identifier>
 <datestamp>2017-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Pool-based Active Learning With Abstention Feedbacks</dc:title>
 <dc:creator>Nguyen, Cuong V.</dc:creator>
 <dc:creator>Ho, Lam Si Tung</dc:creator>
 <dc:creator>Xu, Huan</dc:creator>
 <dc:creator>Dinh, Vu</dc:creator>
 <dc:creator>Nguyen, Binh</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study pool-based active learning with abstention feedbacks, where a
labeler can abstain from labeling a queried example with some unknown
abstention rate. This is an important problem with many useful applications. We
take a Bayesian approach to the problem and develop two new greedy algorithms
that learn both the classification problem and the unknown abstention rate at
the same time. These are achieved by simply incorporating the estimated
abstention rate into the greedy criteria. We prove that both of our algorithms
have near-optimality guarantees: they respectively achieve a
${(1-\frac{1}{e})}$ constant factor approximation of the optimal expected or
worst-case value of a useful utility function. Our experiments show the
algorithms perform well in various practical scenarios.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-09-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08488</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second-Order Word Embeddings from Nearest Neighbor Topological Features</dc:title>
 <dc:creator>Newman-Griffis, Denis</dc:creator>
 <dc:creator>Fosler-Lussier, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce second-order vector representations of words, induced from
nearest neighborhood topological features in pre-trained contextual word
embeddings. We then analyze the effects of using second-order embeddings as
input features in two deep natural language processing models, for named entity
recognition and recognizing textual entailment, as well as a linear model for
paraphrase recognition. Surprisingly, we find that nearest neighbor information
alone is sufficient to capture most of the performance benefits derived from
using pre-trained word embeddings. Furthermore, second-order embeddings are
able to handle highly heterogeneous data better than first-order
representations, though at the cost of some specificity. Additionally,
augmenting contextual embeddings with second-order information further improves
model performance in some cases. Due to variance in the random initializations
of word embeddings, utilizing nearest neighbor features from multiple
first-order embedding samples can also contribute to downstream performance
gains. Finally, we identify intriguing characteristics of second-order
embedding spaces for further research, including much higher density and
different semantic interpretations of cosine similarity.
</dc:description>
 <dc:description>Comment: Submitted to NIPS 2017. (8 pages + 4 reference)</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08489</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Securing Real-Time Internet-of-Things</dc:title>
 <dc:creator>Chen, Chien-Ying</dc:creator>
 <dc:creator>Hasan, Monowar</dc:creator>
 <dc:creator>Mohan, Sibin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Today's embedded and cyber-physical systems are ubiquitous. A large number of
critical cyber-physical systems have real-time requirements (e.g., avionics,
automobiles, power grids, manufacturing systems, industrial control systems,
etc.). The current trend is to connect real-time embedded devices to the
Internet. This gives rise to the real-time Internet-of-things (RT-IoT) that
promises a better user experience through stronger connectivity and better use
of next-generation embedded devices, albeit with safety-critical properties.
However RT-IoT are also increasingly becoming targets for cyber-attacks as
evident by recent events. This paper gives an introduction to RT-IoT systems,
an outlook of current approaches and possible research challenges towards a
holistic secure RT-IoT framework.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08492</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uplift Modeling with Multiple Treatments and General Response Types</dc:title>
 <dc:creator>Zhao, Yan</dc:creator>
 <dc:creator>Fang, Xiao</dc:creator>
 <dc:creator>Simchi-Levi, David</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Randomized experiments have been used to assist decision-making in many
areas. They help people select the optimal treatment for the test population
with certain statistical guarantee. However, subjects can show significant
heterogeneity in response to treatments. The problem of customizing treatment
assignment based on subject characteristics is known as uplift modeling,
differential response analysis, or personalized treatment learning in
literature. A key feature for uplift modeling is that the data is unlabeled. It
is impossible to know whether the chosen treatment is optimal for an individual
subject because response under alternative treatments is unobserved. This
presents a challenge to both the training and the evaluation of uplift models.
In this paper we describe how to obtain an unbiased estimate of the key
performance metric of an uplift model, the expected response. We present a new
uplift algorithm which creates a forest of randomized trees. The trees are
built with a splitting criterion designed to directly optimize their uplift
performance based on the proposed evaluation method. Both the evaluation method
and the algorithm apply to arbitrary number of treatments and general response
types. Experimental results on synthetic data and industry-provided data show
that our algorithm leads to significant performance improvement over other
applicable methods.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08495</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A study on exponential-size neighborhoods for the bin packing problem
  with conflicts</dc:title>
 <dc:creator>Capua, Renatha</dc:creator>
 <dc:creator>Frota, Yuri</dc:creator>
 <dc:creator>Ochi, Luiz Satoru</dc:creator>
 <dc:creator>Vidal, Thibaut</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We propose an iterated local search based on several classes of local and
large neighborhoods for the bin packing problem with conflicts. This problem,
which combines the characteristics of both bin packing and vertex coloring,
arises in various application contexts such as logistics and transportation,
timetabling, and resource allocation for cloud computing. We introduce $O(1)$
evaluation procedures for classical local-search moves, polynomial variants of
ejection chains and assignment neighborhoods, an adaptive set covering-based
neighborhood, and finally a controlled use of 0-cost moves to further diversify
the search. The overall method produces solutions of good quality on the
classical benchmark instances and scales very well with an increase of problem
size. Extensive computational experiments are conducted to measure the
respective contribution of each proposed neighborhood. In particular, the
0-cost moves and the large neighborhood based on set covering contribute very
significantly to the search. Several research perspectives are open in relation
to possible hybridizations with other state-of-the-art mathematical programming
heuristics for this problem.
</dc:description>
 <dc:description>Comment: 26 pages, 8 figures</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08498</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clinical Intervention Prediction and Understanding using Deep Networks</dc:title>
 <dc:creator>Suresh, Harini</dc:creator>
 <dc:creator>Hunt, Nathan</dc:creator>
 <dc:creator>Johnson, Alistair</dc:creator>
 <dc:creator>Celi, Leo Anthony</dc:creator>
 <dc:creator>Szolovits, Peter</dc:creator>
 <dc:creator>Ghassemi, Marzyeh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Real-time prediction of clinical interventions remains a challenge within
intensive care units (ICUs). This task is complicated by data sources that are
noisy, sparse, heterogeneous and outcomes that are imbalanced. In this paper,
we integrate data from all available ICU sources (vitals, labs, notes,
demographics) and focus on learning rich representations of this data to
predict onset and weaning of multiple invasive interventions. In particular, we
compare both long short-term memory networks (LSTM) and convolutional neural
networks (CNN) for prediction of five intervention tasks: invasive ventilation,
non-invasive ventilation, vasopressors, colloid boluses, and crystalloid
boluses. Our predictions are done in a forward-facing manner to enable
&quot;real-time&quot; performance, and predictions are made with a six hour gap time to
support clinically actionable planning. We achieve state-of-the-art results on
our predictive tasks using deep architectures. We explore the use of feature
occlusion to interpret LSTM models, and compare this to the interpretability
gained from examining inputs that maximally activate CNN outputs. We show that
our models are able to significantly outperform baselines in intervention
prediction, and provide insight into model learning, which is crucial for the
adoption of such models in practice.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08499</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Prediction Advantage: A Universally Meaningful Performance Measure
  for Classification and Regression</dc:title>
 <dc:creator>El-Yaniv, Ran</dc:creator>
 <dc:creator>Geifman, Yonatan</dc:creator>
 <dc:creator>Wiener, Yair</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce the Prediction Advantage (PA), a novel performance measure for
prediction functions under any loss function (e.g., classification or
regression). The PA is defined as the performance advantage relative to the
Bayesian risk restricted to knowing only the distribution of the labels. We
derive the PA for well-known loss functions, including 0/1 loss, cross-entropy
loss, absolute loss, and squared loss. In the latter case, the PA is identical
to the well-known R-squared measure, widely used in statistics. The use of the
PA ensures meaningful quantification of prediction performance, which is not
guaranteed, for example, when dealing with noisy imbalanced classification
problems. We argue that among several known alternative performance measures,
PA is the best (and only) quantity ensuring meaningfulness for all noise and
imbalance levels.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08500</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selective Classification for Deep Neural Networks</dc:title>
 <dc:creator>Geifman, Yonatan</dc:creator>
 <dc:creator>El-Yaniv, Ran</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Selective classification techniques (also known as reject option) have not
yet been considered in the context of deep neural networks (DNNs). These
techniques can potentially significantly improve DNNs prediction performance by
trading-off coverage. In this paper we propose a method to construct a
selective classifier given a trained neural network. Our method allows a user
to set a desired risk level. At test time, the classifier rejects instances as
needed, to grant the desired risk (with high probability). Empirical results
over CIFAR and ImageNet convincingly demonstrate the viability of our method,
which opens up possibilities to operate DNNs in mission-critical applications.
For example, using our method an unprecedented 2% error in top-5 ImageNet
classification can be guaranteed with probability 99.9%, and almost 60% test
coverage.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08501</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characteristics of On-time and Late Reward Delivery Projects</dc:title>
 <dc:creator>Tran, Thanh</dc:creator>
 <dc:creator>Lee, Kyumin</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The crowdfunding market size has increased exponentially, reaching tens of
billions of dollars and showing the popularity of crowdfunding. However,
according to Kickstarter, 35% backers did not receive rewards on time. To
maintain the trust between creators and backers, and sustain the crowdfunding
business growth, it is crucial to understand how on-time and late reward
delivery projects are different. In this paper, we analyze characteristics of
on-time and late reward delivery projects, especially, focusing on project
descriptions, creator profiles, and activeness and linguistic patterns of
creators and backers. Our analysis reveals that the less complicated a project
is and more actively a creator responds to backers, the higher an on-time
reward delivery probability is. It shows there are significant differences
between on-time and late reward delivery projects.
</dc:description>
 <dc:description>Comment: ICWSM 2017</dc:description>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08502</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Culture, Computation, Morality</dc:title>
 <dc:creator>Baek, Jongmin Jerome</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  I point to a deep and unjustly ignored relation between culture and
computation. I first establish interpretations of Piaget's and Vygotsky's
theories of child development with the language of theoretical computer
science. Using these interpretations, I argue that the two different possible
routes to Piagetian disequilibrium -- a tendency to overaccommodate, and a
tendency to overassimilate -- are equivalent to the two distinct cultural
tendencies, collectivistism and individualism. I argue that this simple
characterization of overaccommodation versus overassimilation provides a
satisfying explanation as to why the two cultural tendencies differ in the way
they empirically do. All such notions are grounded on a firm mathematical
framework for those who prefer the computable, and grounded on my personal
history for those who prefer the uncomputable.
</dc:description>
 <dc:date>2017-05-17</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08503</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Geometry and Topology of Data and Information for Analytics of
  Processes and Behaviours: Building on Bourdieu and Addressing New Societal
  Challenges</dc:title>
 <dc:creator>Murtagh, Fionn</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>62H25, 62P25</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  We begin by summarizing the relevance and importance of inductive analytics
based on the geometry and topology of data and information. Contemporary issues
are then discussed. These include how sampling data for representativity is
increasingly to be questioned. While we can always avail of analytics from a
&quot;bag of tools and techniques&quot;, in the application of machine learning and
predictive analytics, nonetheless we present the case for Bourdieu and
Benz\'ecri-based science of data, as follows. This is to construct bridges
between data sources and position-taking, and decision-making. There is summary
presentation of a few case studies, illustrating and exemplifying application
domains.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures</dc:description>
 <dc:date>2017-05-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08504</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interpreting Blackbox Models via Model Extraction</dc:title>
 <dc:creator>Bastani, Osbert</dc:creator>
 <dc:creator>Kim, Carolyn</dc:creator>
 <dc:creator>Bastani, Hamsa</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Interpretability has become an important issue as machine learning is
increasingly used to inform consequential decisions. We propose an approach for
interpreting a blackbox model by extracting a decision tree that approximates
the model. Our model extraction algorithm avoids overfitting by leveraging
blackbox model access to actively sample new training points. We prove that as
the number of samples goes to infinity, the decision tree learned using our
algorithm converges to the exact greedy decision tree. In our evaluation, we
use our algorithm to interpret random forests and neural nets trained on
several datasets from the UCI Machine Learning Repository, as well as control
policies learned for three classical reinforcement learning problems. We show
that our algorithm improves over a baseline based on CART on every problem
instance. Furthermore, we show how an interpretation generated by our approach
can be used to understand and debug these models.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08506</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HuGaDB: Human Gait Database for Activity Recognition from Wearable
  Inertial Sensor Networks</dc:title>
 <dc:creator>Chereshnev, Roman</dc:creator>
 <dc:creator>Kertesz-Farkas, Attila</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper presents a human gait data collection for analysis and activity
recognition consisting of continues recordings of combined activities, such as
walking, running, taking stairs up and down, sitting down, and so on; and the
data recorded are segmented and annotated. Data were collected from a body
sensor network consisting of six wearable inertial sensors (accelerometer and
gyroscope) located on the right and left thighs, shins, and feet. Additionally,
two electromyography sensors were used on the quadriceps (front thigh) to
measure muscle activity. This database can be used not only for activity
recognition but also for studying how activities are performed and how the
parts of the legs move relative to each other. Therefore, the data can be used
(a) to perform health-care-related studies, such as in walking rehabilitation
or Parkinson's disease recognition, (b) in virtual reality and gaming for
simulating humanoid motion, or (c) for humanoid robotics to model humanoid
walking. This dataset is the first of its kind which provides data about human
gait in great detail. The database is available free of charge
https://github.com/romanchereshnev/HuGaDB.
</dc:description>
 <dc:description>Comment: 4 Figures, 3 tables</dc:description>
 <dc:date>2017-05-10</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08507</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Teaching computer code at school</dc:title>
 <dc:creator>Henda, Mokhtar Ben</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In today's education systems, there is a deep concern about the importance of
teaching code and computer programming in schools. Moving digital learning from
a simple use of tools to understanding the processes of the internal
functioning of these tools is an old / new debate originated with the digital
laboratories of the 1960. Today, it is emerging again under impulse of the
large - scale public sphere digitalization and the new constructivist education
theories. Teachers and educators discuss not only the viability of code
teaching in the classroom, but also the intellectual and cognitive advantages
for students. The debate thus takes several orientations and is resourced in
the entanglement of arguments and interpretations of any order, technical,
educational, cultural, cognitive and psychological. However, that phenomenon
which undoubtedly augurs for a profound transformation in the future models of
learning and teaching , is predicting a new and almost congenital digital
humanism
</dc:description>
 <dc:description>Comment: in French</dc:description>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08507</dc:identifier>
 <dc:identifier>Chaire Unesco-ITEN. Actes de la 5e rencontre annuelle d'ORBICOM,
  Les \'editions de l'immat\'eriel, 2017</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08508</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vehicle Traffic Driven Camera Placement for Better Metropolis Security
  Surveillance</dc:title>
 <dc:creator>He, Yihui</dc:creator>
 <dc:creator>Ma, Xiaobo</dc:creator>
 <dc:creator>Luo, Xiapu</dc:creator>
 <dc:creator>Li, Jianfeng</dc:creator>
 <dc:creator>Zhao, Mengchen</dc:creator>
 <dc:creator>An, Bo</dc:creator>
 <dc:creator>Guan, Xiaohong</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Security surveillance is one of the most important issues in smart cities,
especially in an era of terrorism. Deploying a number of (video) cameras is a
common surveillance approach. Given the never-ending power offered by vehicles
to metropolises, exploiting vehicle traffic to design camera placement
strategies could potentially facilitate security surveillance. This article
constitutes the first effort toward building the linkage between vehicle
traffic and security surveillance, which is a critical problem for smart
cities. We expect our study could influence the decision making of surveillance
camera placement, and foster more research of principled ways of security
surveillance beneficial to our physical-world life.
</dc:description>
 <dc:description>Comment: IEEE Intelligent Systems major revision, first two authors
  contributed equally</dc:description>
 <dc:date>2017-04-01</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08509</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predictive Analytics for Enhancing Travel Time Estimation in Navigation
  Apps of Apple, Google, and Microsoft</dc:title>
 <dc:creator>Amirian, Pouria</dc:creator>
 <dc:creator>Basiri, Anahid</dc:creator>
 <dc:creator>Morley, Jeremy</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The explosive growth of the location-enabled devices coupled with the
increasing use of Internet services has led to an increasing awareness of the
importance and usage of geospatial information in many applications. The
navigation apps (often called Maps), use a variety of available data sources to
calculate and predict the travel time as well as several options for routing in
public transportation, car or pedestrian modes. This paper evaluates the
pedestrian mode of Maps apps in three major smartphone operating systems
(Android, iOS and Windows Phone). In the paper, we will show that the Maps apps
on iOS, Android and Windows Phone in pedestrian mode, predict travel time
without learning from the individual's movement profile. In addition, we will
exemplify that those apps suffer from a specific data quality issue which
relates to the absence of information about location and type of pedestrian
crossings. Finally, we will illustrate learning from movement profile of
individuals using various predictive analytics models to improve the accuracy
of travel time estimation.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08509</dc:identifier>
 <dc:identifier>doi:10.1145/3003965.3003976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08514</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cybernetic Health</dc:title>
 <dc:creator>Nag, Nitish</dc:creator>
 <dc:creator>Pandey, Vaibhav</dc:creator>
 <dc:creator>Oh, Hyungik</dc:creator>
 <dc:creator>Jain, Ramesh</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Future health ecosystems demand the integration of emerging data technology
with an increased focus on preventive medicine. Cybernetics extracts the full
potential of data to serve the spectrum of health care, from acute to chronic
problems. Building actionable cybernetic navigation tools can greatly empower
optimal health decisions, especially by quantifying lifestyle and environmental
data. This data to decisions transformation is powered by intuitive event
analysis to offer the best semantic abstraction of dynamic living systems.
Achieving the goal of preventive health systems in the cybernetic model occurs
through the flow of several components. From personalized models we can predict
health status using perpetual sensing and data streams. Given these
predictions, we give precise recommendations to best suit the prediction for
that individual. To enact these recommendations we use persuasive technology in
order to deliver and execute targeted interventions.
</dc:description>
 <dc:date>2017-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08520</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An effective algorithm for hyperparameter optimization of neural
  networks</dc:title>
 <dc:creator>Diaz, Gonzalo</dc:creator>
 <dc:creator>Fokoue, Achille</dc:creator>
 <dc:creator>Nannicini, Giacomo</dc:creator>
 <dc:creator>Samulowitz, Horst</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  A major challenge in designing neural network (NN) systems is to determine
the best structure and parameters for the network given the data for the
machine learning problem at hand. Examples of parameters are the number of
layers and nodes, the learning rates, and the dropout rates. Typically, these
parameters are chosen based on heuristic rules and manually fine-tuned, which
may be very time-consuming, because evaluating the performance of a single
parametrization of the NN may require several hours. This paper addresses the
problem of choosing appropriate parameters for the NN by formulating it as a
box-constrained mathematical optimization problem, and applying a
derivative-free optimization tool that automatically and effectively searches
the parameter space. The optimization tool employs a radial basis function
model of the objective function (the prediction accuracy of the NN) to
accelerate the discovery of configurations yielding high accuracy. Candidate
configurations explored by the algorithm are trained to a small number of
epochs, and only the most promising candidates receive full training. The
performance of the proposed methodology is assessed on benchmark sets and in
the context of predicting drug-drug interactions, showing promising results.
The optimization tool used in this paper is open-source.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08522</identifier>
 <datestamp>2017-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Internet of Things Security Research: A Rehash of Old Ideas or New
  Intellectual Challenges?</dc:title>
 <dc:creator>Fernandes, Earlence</dc:creator>
 <dc:creator>Rahmati, Amir</dc:creator>
 <dc:creator>Eykholt, Kevin</dc:creator>
 <dc:creator>Prakash, Atul</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Internet of Things (IoT) is a new computing paradigm that spans wearable
devices, homes, hospitals, cities, transportation, and critical infrastructure.
Building security into this new computing paradigm is a major technical
challenge today. However, what are the security problems in IoT that we can
solve using existing security principles? And, what are the new problems and
challenges in this space that require new security mechanisms? This article
summarizes the intellectual similarities and differences between classic
information technology security research and IoT security research.
</dc:description>
 <dc:description>Comment: published at IEEE Security and Privacy Magazine, July 2017: Systems
  Attacks and Defenses</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08525</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-driven Random Fourier Features using Stein Effect</dc:title>
 <dc:creator>Chang, Wei-Cheng</dc:creator>
 <dc:creator>Li, Chun-Liang</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Large-scale kernel approximation is an important problem in machine learning
research. Approaches using random Fourier features have become increasingly
popular [Rahimi and Recht, 2007], where kernel approximation is treated as
empirical mean estimation via Monte Carlo (MC) or Quasi-Monte Carlo (QMC)
integration [Yang et al., 2014]. A limitation of the current approaches is that
all the features receive an equal weight summing to 1. In this paper, we
propose a novel shrinkage estimator from &quot;Stein effect&quot;, which provides a
data-driven weighting strategy for random features and enjoys theoretical
justifications in terms of lowering the empirical risk. We further present an
efficient randomized algorithm for large-scale applications of the proposed
method. Our empirical results on six benchmark data sets demonstrate the
advantageous performance of this approach over representative baselines in both
kernel approximation and supervised learning tasks.
</dc:description>
 <dc:description>Comment: To appear in International Joint Conference on Artificial
  Intelligence (IJCAI), 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08530</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence Analysis of Gradient EM for Multi-component Gaussian Mixture</dc:title>
 <dc:creator>Yan, Bowei</dc:creator>
 <dc:creator>Yin, Mingzhang</dc:creator>
 <dc:creator>Sarkar, Purnamrita</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we study convergence properties of the gradient
Expectation-Maximization algorithm \cite{lange1995gradient} for Gaussian
Mixture Models for general number of clusters and mixing coefficients. We
derive the convergence rate depending on the mixing coefficients, minimum and
maximum pairwise distances between the true centers and dimensionality and
number of components; and obtain a near-optimal local contraction radius. While
there have been some recent notable works that derive local convergence rates
for EM in the two equal mixture symmetric GMM, in the more general case, the
derivations need structurally different and non-trivial arguments. We use
recent tools from learning theory and empirical processes to achieve our
theoretical results.
</dc:description>
 <dc:description>Comment: 36 pages</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08539</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conscious and controlling elements in combinatorial group testing
  problems with more defectives</dc:title>
 <dc:creator>Gerbner, D&#xe1;niel</dc:creator>
 <dc:creator>Vizer, M&#xe1;t&#xe9;</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In combinatorial group testing problems Questioner needs to find a defective
element $x\in [n]$ by testing subsets of $[n]$. In [18] the authors introduced
a new model, where each element knows the answer for those queries that contain
it and each element should be able to identify the defective one. In this
article we continue to investigate this kind of models with more defective
elements. We also consider related models inspired by secret sharing models,
where the elements should share information among them to find out the
defectives. Finally the adaptive versions of the different models are also
investigated.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08550</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Multi-instance Networks with Sparse Label Assignment for Whole
  Mammogram Classification</dc:title>
 <dc:creator>Zhu, Wentao</dc:creator>
 <dc:creator>Lou, Qi</dc:creator>
 <dc:creator>Vang, Yeeleng Scott</dc:creator>
 <dc:creator>Xie, Xiaohui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Mammogram classification is directly related to computer-aided diagnosis of
breast cancer. Traditional methods rely on regions of interest (ROIs) which
require great efforts to annotate. Inspired by the success of using deep
convolutional features for natural image analysis and multi-instance learning
(MIL) for labeling a set of instances/patches, we propose end-to-end trained
deep multi-instance networks for mass classification based on whole mammogram
without the aforementioned ROIs. We explore three different schemes to
construct deep multi-instance networks for whole mammogram classification.
Experimental results on the INbreast dataset demonstrate the robustness of
proposed networks compared to previous work using segmentation and detection
annotations.
</dc:description>
 <dc:description>Comment: MICCAI 2017 Camera Ready</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08550</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08551</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safe Model-based Reinforcement Learning with Stability Guarantees</dc:title>
 <dc:creator>Berkenkamp, Felix</dc:creator>
 <dc:creator>Turchetta, Matteo</dc:creator>
 <dc:creator>Schoellig, Angela P.</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Reinforcement learning is a powerful paradigm for learning optimal policies
from experimental data. However, to find optimal policies, most reinforcement
learning algorithms explore all possible actions, which may be harmful for
real-world systems. As a consequence, learning algorithms are rarely applied on
safety-critical systems in the real world. In this paper, we present a learning
algorithm that explicitly considers safety, defined in terms of stability
guarantees. Specifically, we extend control-theoretic results on Lyapunov
stability verification and show how to use statistical models of the dynamics
to obtain high-performance control policies with provable stability
certificates. Moreover, under additional regularity assumptions in terms of a
Gaussian process prior, we prove that one can effectively and safely collect
data in order to learn about the dynamics and thus both improve control
performance and expand the safe region of the state space. In our experiments,
we show how the resulting algorithm can safely optimize a neural network policy
on a simulated inverted pendulum, without the pendulum ever falling down.
</dc:description>
 <dc:description>Comment: Proc. of Neural Information Processing Systems (NIPS), 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08557</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grounded Recurrent Neural Networks</dc:title>
 <dc:creator>Vani, Ankit</dc:creator>
 <dc:creator>Jernite, Yacine</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this work, we present the Grounded Recurrent Neural Network (GRNN), a
recurrent neural network architecture for multi-label prediction which
explicitly ties labels to specific dimensions of the recurrent hidden state (we
call this process &quot;grounding&quot;). The approach is particularly well-suited for
extracting large numbers of concepts from text. We apply the new model to
address an important problem in healthcare of understanding what medical
concepts are discussed in clinical text. Using a publicly available dataset
derived from Intensive Care Units, we learn to label a patient's diagnoses and
procedures from their discharge summary. Our evaluation shows a clear advantage
to using our proposed architecture over a variety of strong baselines.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08562</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hashing as Tie-Aware Learning to Rank</dc:title>
 <dc:creator>He, Kun</dc:creator>
 <dc:creator>Cakir, Fatih</dc:creator>
 <dc:creator>Bargal, Sarah Adel</dc:creator>
 <dc:creator>Sclaroff, Stan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Hashing, or learning binary embeddings of data, is frequently used in nearest
neighbor retrieval. In this paper, we develop learning to rank formulations for
hashing, aimed at directly optimizing ranking-based evaluation metrics such as
Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG). We
first observe that the integer-valued Hamming distance often leads to tied
rankings, and propose to use tie-aware versions of AP and NDCG to evaluate
hashing for retrieval. Then, to optimize tie-aware ranking metrics, we derive
their continuous relaxations, and perform gradient-based optimization with deep
neural networks. Our results establish the new state-of-the-art for image
retrieval by Hamming ranking in common benchmarks.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08562</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08563</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Pricing Schemes for the Cloud</dc:title>
 <dc:creator>Kash, Ian A.</dc:creator>
 <dc:creator>Key, Peter</dc:creator>
 <dc:creator>Suksompong, Warut</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The problem of pricing the cloud has attracted much recent attention due to
the widespread use of cloud computing and cloud services. From a theoretical
perspective, several mechanisms that provide strong efficiency or fairness
guarantees and desirable incentive properties have been designed. However,
these mechanisms often rely on a rigid model, with several parameters needing
to be precisely known in order for the guarantees to hold. In this paper, we
consider a stochastic model and show that it is possible to obtain good welfare
and revenue guarantees with simple mechanisms that do not make use of the
information on some of these parameters. In particular, we prove that a
mechanism that sets the same price per time step for jobs of any length
achieves at least 50% of the welfare and revenue obtained by a mechanism that
can set different prices for jobs of different lengths, and the ratio can be
improved if we have more specific knowledge of some parameters. Similarly, a
mechanism that sets the same price for all servers even though the servers may
receive different kinds of jobs can provide a reasonable welfare and revenue
approximation compared to a mechanism that is allowed to set different prices
for different servers.
</dc:description>
 <dc:description>Comment: To appear in the 13th Conference on Web and Internet Economics
  (WINE), 2017. A preliminary version was presented at the 12th Workshop on the
  Economics of Networks, Systems and Computation (NetEcon), 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08564</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Interrogating Discriminative Machine Learning Models</dc:title>
 <dc:creator>Guo, Wenbo</dc:creator>
 <dc:creator>Zhang, Kaixuan</dc:creator>
 <dc:creator>Lin, Lin</dc:creator>
 <dc:creator>Huang, Sui</dc:creator>
 <dc:creator>Xing, Xinyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It is oftentimes impossible to understand how machine learning models reach a
decision. While recent research has proposed various technical approaches to
provide some clues as to how a learning model makes individual decisions, they
cannot provide users with ability to inspect a learning model as a complete
entity. In this work, we propose a new technical approach that augments a
Bayesian regression mixture model with multiple elastic nets. Using the
enhanced mixture model, we extract explanations for a target model through
global approximation. To demonstrate the utility of our approach, we evaluate
it on different learning models covering the tasks of text mining and image
recognition. Our results indicate that the proposed approach not only
outperforms the state-of-the-art technique in explaining individual decisions
but also provides users with an ability to discover the vulnerabilities of a
learning model.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08566</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Near-Optimal Separation Principle for Nonlinear Stochastic Systems
  Arising in Robotic Path Planning and Control</dc:title>
 <dc:creator>Rafieisakhaei, Mohammadhussein</dc:creator>
 <dc:creator>Chakravorty, Suman</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider nonlinear stochastic systems that arise in path planning and
control of mobile robots. As is typical of almost all nonlinear stochastic
systems, the optimally solving problem is intractable. We provide a design
approach which yields a tractable design that is quantifiably near-optimal. We
exhibit a &quot;separation&quot; principle under a small noise assumption consisting of
the optimal open-loop design of nominal trajectory followed by an optimal
feedback law to track this trajectory, which is different from the usual effort
of separating estimation from control. As a corollary, we obtain a
trajectory-optimized linear quadratic regulator design for stochastic nonlinear
systems with Gaussian noise.
</dc:description>
 <dc:description>Comment: 7 pages, 4 Figures, Submitted to 56th IEEE Conference on Decision and
  Control (CDC), 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08568</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Future of Ad Blocking: An Analytical Framework and New Techniques</dc:title>
 <dc:creator>Storey, Grant</dc:creator>
 <dc:creator>Reisman, Dillon</dc:creator>
 <dc:creator>Mayer, Jonathan</dc:creator>
 <dc:creator>Narayanan, Arvind</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a systematic study of ad blocking - and the associated &quot;arms race&quot;
- as a security problem. We model ad blocking as a state space with four states
and six state transitions, which correspond to techniques that can be deployed
by either publishers or ad blockers. We argue that this is a complete model of
the system. We propose several new ad blocking techniques, including ones that
borrow ideas from rootkits to prevent detection by anti-ad blocking scripts.
Another technique uses the insight that ads must be recognizable by humans to
comply with laws and industry self-regulation. We have built prototype
implementations of three of these techniques, successfully blocking ads and
evading detection. We systematically evaluate our proposed techniques, along
with existing ones, in terms of security, practicality, and legality. We
characterize the order of growth of the development effort required to
create/maintain ad blockers as a function of the growth of the web. Based on
our state-space model, our new techniques, and this systematization, we offer
insights into the likely &quot;end game&quot; of the arms race. We challenge the
widespread assumption that the arms race will escalate indefinitely, and
instead identify a combination of evolving technical and legal factors that
will determine the outcome.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08572</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Rate Control and Power Allocation for Non-Orthogonal Multiple
  Access Systems</dc:title>
 <dc:creator>Bao, Wei</dc:creator>
 <dc:creator>Chen, He</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Vucetic, Branka</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates the optimal resource allocation of a downlink
non-orthogonal multiple access (NOMA) system consisting of one base station and
multiple users. Unlike existing short-term NOMA designs that focused on the
resource allocation for only the current transmission timeslot, we aim to
maximize a long-term network utility by jointly optimizing the data rate
control at the network layer and the power allocation among multiple users at
the physical layer, subject to practical constraints on both the short-term and
long-term power consumptions. To solve this problem, we leverage the
recently-developed Lyapunov optimization framework to convert the original
long-term optimization problem into a series of online rate control and power
allocation problems in each timeslot. The power allocation problem, however, is
shown to be non-convex in nature and thus cannot be solved with a standard
method. However, we explore two structures of the optimal solution and develop
a dynamic programming based power allocation algorithm, which can derive a
globally optimal solution, with a polynomial computational complexity.
Extensive simulation results are provided to evaluate the performance of the
proposed joint rate control and power allocation framework for NOMA systems,
which demonstrate that the proposed NOMA design can significantly outperform
multiple benchmark schemes, including orthogonal multiple access (OMA) schemes
with optimal power allocation and NOMA schemes with non-optimal power
allocation, in terms of average throughput and data delay.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Journal on Selected Areas in
  Communications (JSAC)</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08576</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flexible Cache-Aided Networks with Backhauling</dc:title>
 <dc:creator>Atzeni, Italo</dc:creator>
 <dc:creator>Maso, Marco</dc:creator>
 <dc:creator>Ghamnia, Im&#xe8;ne</dc:creator>
 <dc:creator>Ba&#x15f;tu&#x11f;, Ejder</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Caching at the edge is a promising technique to cope with the increasing data
demand in wireless networks. This paper analyzes the performance of cellular
networks consisting of a tier macro-cell wireless backhaul nodes overlaid with
a tier of cache-aided small cells. We consider both static and dynamic
association policies for content delivery to the user terminals and analyze
their performance. In particular, we derive closed-form expressions for the
area spectral efficiency and the energy efficiency, which are used to optimize
relevant design parameters such as the density of cache-aided small cells and
the storage size. By means of this approach, we are able to draw useful design
insights for the deployment of highly performing cache-aided tiered networks.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures, to be presented at 18th IEEE International
  Workshop on Signal Processing Advances in Wireless Communications
  (SPAWC'2017), Sapporo, Japan, 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08583</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Summarization Using Order-constrained Kernelized Feature
  Subspaces</dc:title>
 <dc:creator>Cherian, Anoop</dc:creator>
 <dc:creator>Sra, Suvrit</dc:creator>
 <dc:creator>Hartley, Richard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Representations that can compactly and effectively capture temporal evolution
of semantic content are important to machine learning algorithms that operate
on multi-variate time-series data. We investigate such representations
motivated by the task of human action recognition. Here each data instance is
encoded by a multivariate feature (such as via a deep CNN) where action
dynamics are characterized by their variations in time. As these features are
often non-linear, we propose a novel pooling method, kernelized rank pooling,
that represents a given sequence compactly as the pre-image of the parameters
of a hyperplane in an RKHS, projections of data onto which captures their
temporal order. We develop this idea further and show that such a pooling
scheme can be cast as an order-constrained kernelized PCA objective; we then
propose to use the parameters of a kernelized low-rank feature subspace as the
representation of the sequences. We cast our formulation as an optimization
problem on generalized Grassmann manifolds and then solve it efficiently using
Riemannian optimization techniques. We present experiments on several action
recognition datasets using diverse feature modalities and demonstrate
state-of-the-art results.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08584</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MMD GAN: Towards Deeper Understanding of Moment Matching Network</dc:title>
 <dc:creator>Li, Chun-Liang</dc:creator>
 <dc:creator>Chang, Wei-Cheng</dc:creator>
 <dc:creator>Cheng, Yu</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:creator>P&#xf3;czos, Barnab&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative moment matching network (GMMN) is a deep generative model that
differs from Generative Adversarial Network (GAN) by replacing the
discriminator in GAN with a two-sample test based on kernel maximum mean
discrepancy (MMD). Although some theoretical guarantees of MMD have been
studied, the empirical performance of GMMN is still not as competitive as that
of GAN on challenging and large benchmark datasets. The computational
efficiency of GMMN is also less desirable in comparison with GAN, partially due
to its requirement for a rather large batch size during the training. In this
paper, we propose to improve both the model expressiveness of GMMN and its
computational efficiency by introducing adversarial kernel learning techniques,
as the replacement of a fixed Gaussian kernel in the original GMMN. The new
approach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN.
The new distance measure in MMD GAN is a meaningful loss that enjoys the
advantage of weak topology and can be optimized via gradient descent with
relatively small batch sizes. In our evaluation on multiple benchmark datasets,
including MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN
significantly outperforms GMMN, and is competitive with other representative
GAN works.
</dc:description>
 <dc:description>Comment: In the Proceedings of Thirty-first Annual Conference on Neural
  Information Processing Systems (NIPS 2017)</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08584</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08586</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-organized Segregation on the Grid</dc:title>
 <dc:creator>Omidvar, Hamed</dc:creator>
 <dc:creator>Franceschetti, Massimo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider an agent-based model in which two types of agents interact
locally over a graph and have a common intolerance threshold $\tau$ for
changing their types with exponentially distributed waiting times. The model is
equivalent to an unperturbed Schelling model of self-organized segregation, an
Asynchronous Cellular Automata (ACA) with extended Moore neighborhoods, or a
zero-temperature Ising model with Glauber dynamics, and has applications in the
analysis of social and biological networks, and spin glasses systems. Some
rigorous results were recently obtained in the theoretical computer science
literature, and this work provides several extensions. We enlarge the
intolerance interval leading to the formation of large segregated regions of
agents of a single type from the known size $\epsilon&gt;0$ to size $\approx
0.134$. Namely, we show that for $0.433 &lt; \tau &lt; 1/2$ (and by symmetry
$1/2&lt;\tau&lt;0.567$), the expected size of the largest segregated region
containing an arbitrary agent is exponential in the size of the neighborhood.
We further extend the interval leading to large segregated regions to size
$\approx 0.312$ considering &quot;almost segregated&quot; regions, namely regions where
the ratio of the number of agents of one type and the number of agents of the
other type vanishes quickly as the size of the neighborhood grows. In this
case, we show that for $0.344 &lt; \tau \leq 0.433$ (and by symmetry for $0.567
\leq \tau&lt;0.656$) the expected size of the largest almost segregated region
containing an arbitrary agent is exponential in the size of the neighborhood.
The exponential bounds that we provide also imply that complete segregation,
where agents of a single type cover the whole grid, does not occur with high
probability for $p=1/2$ and the range of tolerance considered.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08586</dc:identifier>
 <dc:identifier>Omidvar, H. &amp; Franceschetti, M. J Stat Phys (2017).
  https://doi.org/10.1007/s10955-017-1942-4</dc:identifier>
 <dc:identifier>doi:10.1007/s10955-017-1942-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08590</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Model with Coordinate Metric Learning for Object Recognition
  Based on 3D Models</dc:title>
 <dc:creator>Wang, Yida</dc:creator>
 <dc:creator>Deng, Weihong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Given large amount of real photos for training, Convolutional neural network
shows excellent performance on object recognition tasks. However, the process
of collecting data is so tedious and the background are also limited which
makes it hard to establish a perfect database. In this paper, our generative
model trained with synthetic images rendered from 3D models reduces the
workload of data collection and limitation of conditions. Our structure is
composed of two sub-networks: semantic foreground object reconstruction network
based on Bayesian inference and classification network based on multi-triplet
cost function for avoiding over-fitting problem on monotone surface and fully
utilizing pose information by establishing sphere-like distribution of
descriptors in each category which is helpful for recognition on regular photos
according to poses, lighting condition, background and category information of
rendered images. Firstly, our conjugate structure called generative model with
metric learning utilizing additional foreground object channels generated from
Bayesian rendering as the joint of two sub-networks. Multi-triplet cost
function based on poses for object recognition are used for metric learning
which makes it possible training a category classifier purely based on
synthetic data. Secondly, we design a coordinate training strategy with the
help of adaptive noises acting as corruption on input images to help both
sub-networks benefit from each other and avoid inharmonious parameter tuning
due to different convergence speed of two sub-networks. Our structure achieves
the state of the art accuracy of over 50\% on ShapeNet database with data
migration obstacle from synthetic images to real photos. This pipeline makes it
applicable to do recognition on real images only based on 3D models.
</dc:description>
 <dc:description>Comment: 15 pages, 12 figures, 3 tables</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08590</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08593</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Improves Template Matching by Normalized Cross Correlation</dc:title>
 <dc:creator>Buniatyan, Davit</dc:creator>
 <dc:creator>Macrina, Thomas</dc:creator>
 <dc:creator>Ih, Dodam</dc:creator>
 <dc:creator>Zung, Jonathan</dc:creator>
 <dc:creator>Seung, H. Sebastian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Template matching by normalized cross correlation (NCC) is widely used for
finding image correspondences. We improve the robustness of this algorithm by
preprocessing images with &quot;siamese&quot; convolutional networks trained to maximize
the contrast between NCC values of true and false matches. The improvement is
quantified using patches of brain images from serial section electron
microscopy. Relative to a parameter-tuned bandpass filter, siamese
convolutional networks significantly reduce false matches. Furthermore, all
false matches can be eliminated by removing a tiny fraction of all matches
based on NCC values. The improved accuracy of our method could be essential for
connectomics, because emerging petascale datasets may require billions of
template matches to assemble 2D images of serial sections into a 3D image
stack. Our method is also expected to generalize to many other computer vision
applications that use NCC template matching to find image correspondences.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08598</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Journalists' information needs, seeking behavior, and its determinants
  on social media</dc:title>
 <dc:creator>Aghili, Omid</dc:creator>
 <dc:creator>Sanderson, Mark</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We describe the results of a qualitative study on journalists' information
seeking behavior on social media. Based on interviews with eleven journalists
along with a study of a set of university level journalism modules, we
determined the categories of information need types that lead journalists to
social media. We also determined the ways that social media is exploited as a
tool to satisfy information needs and to define influential factors, which
impacted on journalists' information seeking behavior. We find that not only is
social media used as an information source, but it can also be a supplier of
stories found serendipitously. We find seven information need types that expand
the types found in previous work. We also find five categories of influential
factors that affect the way journalists seek information.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08604</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Game in Remote Estimation under DoS Attacks</dc:title>
 <dc:creator>Ding, Kemi</dc:creator>
 <dc:creator>Dey, Subhrakanti</dc:creator>
 <dc:creator>Quevedo, Daniel E.</dc:creator>
 <dc:creator>Shi, Ling</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper studies remote state estimation under denial-of-service (DoS)
attacks. A sensor transmits its local estimate of an underlying physical
process to a remote estimator via a wireless communication channel. A DoS
attacker is capable to interfere the channel and degrades the remote estimation
accuracy. Considering the tactical jamming strategies played by the attacker,
the sensor adjusts its transmission power. This interactive process between the
sensor and the attacker is studied in the framework of a zero-sum stochastic
game. To derive their optimal power schemes, we first discuss the existence of
stationary Nash equilibrium (SNE) for this game. We then present the monotone
structure of the optimal strategies, which helps reduce the computational
complexity of the stochastic game algorithm. Numerical examples are provided to
illustrate the obtained results.
</dc:description>
 <dc:description>Comment: It has some minor errors</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08614</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fully reliable error control for evolutionary problems</dc:title>
 <dc:creator>Holm, B&#xe4;rbel</dc:creator>
 <dc:creator>Matculevich, Svetlana</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  This work is focused on the application of functional-type a posteriori error
estimates and corresponding indicators to a class of time-dependent problems.
We consider the algorithmic part of their derivation and implementation and
also discuss the numerical properties of these bounds that comply with obtained
numerical results. This paper examines two different methods of approximate
solution reconstruction for evolutionary models, i.e., a time-marching
technique and a space-time approach. The first part of the study presents an
algorithm for global minimization of the majorant on each of discretization
time-cylinders (time-slabs), the effectiveness of this algorithm is confirmed
by extensive numerical tests. In the second part of the publication, the
application of functional error estimates is discussed with respect to a
space-time approach. It is followed by a set of extensive numerical tests that
demonstrate the efficiency of proposed error control method.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08614</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08616</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Parallel Message-distribution Technique for Cost-based
  Steganography</dc:title>
 <dc:creator>Sharifzadeh, Mehdi</dc:creator>
 <dc:creator>Agarwal, Chirag</dc:creator>
 <dc:creator>Salarian, Mahdi</dc:creator>
 <dc:creator>Schonfeld, Dan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper presents two novel approaches to increase performance bounds of
image steganography under the criteria of minimizing distortion. First, in
order to efficiently use the images' capacities, we propose using parallel
images in the embedding stage. The result is then used to prove sub-optimality
of the message distribution technique used by all cost based algorithms
including HUGO, S-UNIWARD, and HILL. Second, a new distribution approach is
presented to further improve the security of these algorithms. Experiments show
that this distribution method avoids embedding in smooth regions and thus
achieves a better performance, measured by state-of-the-art steganalysis, when
compared with the current used distribution.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08617</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Which bridge estimator is optimal for variable selection?</dc:title>
 <dc:creator>Wang, Shuaiwen</dc:creator>
 <dc:creator>Weng, Haolei</dc:creator>
 <dc:creator>Maleki, Arian</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of variable selection for linear models under the high
dimensional asymptotic setting, where the number of observations n grows at the
same rate as the number of predictors p. We consider two stage variable
selection techniques (TVS) in which the first stage uses bridge estimators to
obtain an estimate of the regression coefficients, and the second stage simply
thresholds the regression coefficients estimate to select the &quot;important&quot;
predictors. The asymptotic false discovery proportion (AFDP) and true positive
proportion (ATPP) of these TVS are evaluated. We prove that for a fixed ATTP,
in order to obtain the smallest AFDP one should pick an estimator that
minimizes the asymptotic mean square error in the first stage of TVS. This
simple observation enables us to evaluate and compare the performances of
different TVS with each other and with some standard variable selection
techniques, such as LASSO and Sure Independence Screening. For instance, we
prove that a TVS with LASSO in its first stage can outperform LASSO (only one
stage) in a large range of ATTP. Furthermore, we will show that for large
values of noise, a TVS with ridge in its first stage outperforms TVS with other
bridge estimators including the one that has LASSO in its first stage.
</dc:description>
 <dc:description>Comment: 63 pages, 10 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08618</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Task Learning for Contextual Bandits</dc:title>
 <dc:creator>Deshmukh, Aniket Anand</dc:creator>
 <dc:creator>Dogan, Urun</dc:creator>
 <dc:creator>Scott, Clayton</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Contextual bandits are a form of multi-armed bandit in which the agent has
access to predictive side information (known as the context) for each arm at
each time step, and have been used to model personalized news recommendation,
ad placement, and other applications. In this work, we propose a multi-task
learning framework for contextual bandit problems. Like multi-task learning in
the batch setting, the goal is to leverage similarities in contexts for
different arms so as to improve the agent's ability to predict rewards from
contexts. We propose an upper confidence bound-based multi-task learning
algorithm for contextual bandits, establish a corresponding regret bound, and
interpret this bound to quantify the advantages of learning in the presence of
high task (arm) similarity. We also describe an effective scheme for estimating
task similarity from data, and demonstrate our algorithm's performance on
several data sets.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08619</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dictionary-based Monitoring of Premature Ventricular Contractions: An
  Ultra-Low-Cost Point-of-Care Service</dc:title>
 <dc:creator>Chandra, Bollepalli S.</dc:creator>
 <dc:creator>Sastry, Challa S.</dc:creator>
 <dc:creator>Anumandla, Laxminarayana</dc:creator>
 <dc:creator>Jana, Soumya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  While cardiovascular diseases (CVDs) are prevalent across economic strata,
the economically disadvantaged population is disproportionately affected due to
the high cost of traditional CVD management. Accordingly, developing an
ultra-low-cost alternative, affordable even to groups at the bottom of the
economic pyramid, has emerged as a societal imperative. Against this backdrop,
we propose an inexpensive yet accurate home-based electrocardiogram(ECG)
monitoring service. Specifically, we seek to provide point-of-care monitoring
of premature ventricular contractions (PVCs), high frequency of which could
indicate the onset of potentially fatal arrhythmia. Note that a traditional
telecardiology system acquires the ECG, transmits it to a professional
diagnostic centre without processing, and nearly achieves the diagnostic
accuracy of a bedside setup, albeit at high bandwidth cost. In this context, we
aim at reducing cost without significantly sacrificing reliability. To this
end, we develop a dictionary-based algorithm that detects with high sensitivity
the anomalous beats only which are then transmitted. We further compress those
transmitted beats using class-specific dictionaries subject to suitable
reconstruction/diagnostic fidelity. Such a scheme would not only reduce the
overall bandwidth requirement, but also localising anomalous beats, thereby
reducing physicians' burden. Finally, using Monte Carlo cross validation on
MIT/BIH arrhythmia database, we evaluate the performance of the proposed
system. In particular, with a sensitivity target of at most one undetected PVC
in one hundred beats, and a percentage root mean squared difference less than
9% (a clinically acceptable level of fidelity), we achieved about 99.15%
reduction in bandwidth cost, equivalent to 118-fold savings over traditional
telecardiology.
</dc:description>
 <dc:description>Comment: 19 pages, 9 figures and 5 tables</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08620</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Data Geometric Structure Aligned Close yet Discriminative Domain
  Adaptation</dc:title>
 <dc:creator>Luo, Lingkun</dc:creator>
 <dc:creator>Wang, Xiaofang</dc:creator>
 <dc:creator>Hu, Shiqiang</dc:creator>
 <dc:creator>Chen, Liming</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Domain adaptation (DA) is transfer learning which aims to leverage labeled
data in a related source domain to achieve informed knowledge transfer and help
the classification of unlabeled data in a target domain. In this paper, we
propose a novel DA method, namely Robust Data Geometric Structure Aligned,
Close yet Discriminative Domain Adaptation (RSA-CDDA), which brings closer, in
a latent joint subspace, both source and target data distributions, and aligns
inherent hidden source and target data geometric structures while performing
discriminative DA in repulsing both interclass source and target data. The
proposed method performs domain adaptation between source and target in solving
a unified model, which incorporates data distribution constraints, in
particular via a nonparametric distance, i.e., Maximum Mean Discrepancy (MMD),
as well as constraints on inherent hidden data geometric structure segmentation
and alignment between source and target, through low rank and sparse
representation. RSA-CDDA achieves the search of a joint subspace in solving the
proposed unified model through iterative optimization, alternating Rayleigh
quotient algorithm and inexact augmented Lagrange multiplier algorithm.
Extensive experiments carried out on standard DA benchmarks, i.e., 16
cross-domain image classification tasks, verify the effectiveness of the
proposed method, which consistently outperforms the state-of-the-art methods.
</dc:description>
 <dc:description>Comment: 12 pages, 1 figure</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08621</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparametric Preference Completion</dc:title>
 <dc:creator>Katz-Samuels, Julian</dc:creator>
 <dc:creator>Scott, Clayton</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the task of collaborative preference completion: given a pool of
items, a pool of users and a partially observed item-user rating matrix, the
goal is to recover the personalized ranking of each user over all of the items.
Our approach is nonparametric: we assume that each item $i$ and each user $u$
have unobserved features $x_i$ and $y_u$, and that the associated rating is
given by $g_u(f(x_i,y_u))$ where $f$ is Lipschitz and $g_u$ is a monotonic
transformation that depends on the user. We propose a $k$-nearest
neighbors-like algorithm and prove that it is consistent. To the best of our
knowledge, this is the first consistency result for the collaborative
preference completion problem in a nonparametric setting. Finally, we conduct
experiments on the Netflix and Movielens datasets that suggest that our
algorithm has some advantages over existing neighborhood-based methods and that
its performance is comparable to some state-of-the art matrix factorization
methods.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08621</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08623</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Rotation Equivariant Network</dc:title>
 <dc:creator>Li, Junying</dc:creator>
 <dc:creator>Yang, Zichen</dc:creator>
 <dc:creator>Liu, Haifeng</dc:creator>
 <dc:creator>Cai, Deng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recently, learning equivariant representations has attracted considerable
research attention. Dieleman et al. introduce four operations which can be
inserted to CNN to learn deep representations equivariant to rotation. However,
feature maps should be copied and rotated four times in each layer in their
approach, which causes much running time and memory overhead. In order to
address this problem, we propose Deep Rotation Equivariant Network(DREN)
consisting of cycle layers, isotonic layers and decycle layers.Our proposed
layers apply rotation transformation on filters rather than feature maps,
achieving a speed up of more than 2 times with even less memory overhead. We
evaluate DRENs on Rotated MNIST and CIFAR-10 datasets and demonstrate that it
can improve the performance of state-of-the-art architectures. Our codes are
released on GitHub.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08624</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>VANETs Meet Autonomous Vehicles: A Multimodal 3D Environment Learning
  Approach</dc:title>
 <dc:creator>Maalej, Yassine</dc:creator>
 <dc:creator>Sorour, Sameh</dc:creator>
 <dc:creator>Abdel-Rahim, Ahmed</dc:creator>
 <dc:creator>Guizani, Mohsen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we design a multimodal framework for object detection,
recognition and mapping based on the fusion of stereo camera frames, point
cloud Velodyne Lidar scans, and Vehicle-to-Vehicle (V2V) Basic Safety Messages
(BSMs) exchanged using Dedicated Short Range Communication (DSRC). We merge the
key features of rich texture descriptions of objects from 2D images, depth and
distance between objects provided by 3D point cloud and awareness of hidden
vehicles from BSMs' 3D information. We present a joint pixel to point cloud and
pixel to V2V correspondences of objects in frames from the Kitti Vision
Benchmark Suite by using a semi-supervised manifold alignment approach to
achieve camera-Lidar and camera-V2V mapping of their recognized objects that
have the same underlying manifold.
</dc:description>
 <dc:description>Comment: 7 pages, 12 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08627</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Using Time Without Clocks via Zigzag Causality</dc:title>
 <dc:creator>Dan, Asa</dc:creator>
 <dc:creator>Manohar, Rajit</dc:creator>
 <dc:creator>Moses, Yoram</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Even in the absence of clocks, time bounds on the duration of actions enable
the use of time for distributed coordination. This paper initiates an
investigation of coordination in such a setting. A new communication structure
called a zigzag pattern is introduced, and shown to guarantee bounds on the
relative timing of events in this clockless model. Indeed, zigzag patterns are
shown to be necessary and sufficient for establishing that events occur in a
manner that satisfies prescribed bounds. We capture when a process can know
that an appropriate zigzag pattern exists, and use this to provide necessary
and sufficient conditions for timed coordination of events using a
full-information protocol in the clockless model.
</dc:description>
 <dc:description>Comment: This is an extended version of a paper to appear in PODC 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08631</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-supervised learning of visual features through embedding images
  into text topic spaces</dc:title>
 <dc:creator>Gomez, Lluis</dc:creator>
 <dc:creator>Patel, Yash</dc:creator>
 <dc:creator>Rusi&#xf1;ol, Mar&#xe7;al</dc:creator>
 <dc:creator>Karatzas, Dimosthenis</dc:creator>
 <dc:creator>Jawahar, C. V.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  End-to-end training from scratch of current deep architectures for new
computer vision problems would require Imagenet-scale datasets, and this is not
always possible. In this paper we present a method that is able to take
advantage of freely available multi-modal content to train computer vision
algorithms without human supervision. We put forward the idea of performing
self-supervised learning of visual features by mining a large scale corpus of
multi-modal (text and image) documents. We show that discriminative visual
features can be learnt efficiently by training a CNN to predict the semantic
context in which a particular image is more probable to appear as an
illustration. For this we leverage the hidden semantic structures discovered in
the text corpus with a well-known topic modeling technique. Our experiments
demonstrate state of the art performance in image classification, object
detection, and multi-modal retrieval compared to recent self-supervised or
natural-supervised approaches.
</dc:description>
 <dc:description>Comment: Accepted CVPR 2017 paper</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08631</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08632</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faithful (meta-)encodings of programmable strategies into term rewriting
  systems</dc:title>
 <dc:creator>Cirstea, Horatiu</dc:creator>
 <dc:creator>Lenglet, Serguei</dc:creator>
 <dc:creator>Moreau, Pierre-Etienne</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.4</dc:subject>
 <dc:description>  Rewriting is a formalism widely used in computer science and mathematical
logic. When using rewriting as a programming or modeling paradigm, the rewrite
rules describe the transformations one wants to operate and rewriting
strategies are used to con- trol their application. The operational semantics
of these strategies are generally accepted and approaches for analyzing the
termination of specific strategies have been studied. We propose in this paper
a generic encoding of classic control and traversal strategies used in rewrite
based languages such as Maude, Stratego and Tom into a plain term rewriting
system. The encoding is proven sound and complete and, as a direct consequence,
estab- lished termination methods used for term rewriting systems can be
applied to analyze the termination of strategy controlled term rewriting
systems. We show that the encoding of strategies into term rewriting systems
can be easily adapted to handle many-sorted signa- tures and we use a
meta-level representation of terms to reduce the size of the encodings. The
corresponding implementation in Tom generates term rewriting systems compatible
with the syntax of termination tools such as AProVE and TTT2, tools which
turned out to be very effective in (dis)proving the termination of the
generated term rewriting systems. The approach can also be seen as a generic
strategy compiler which can be integrated into languages providing pattern
matching primitives; experiments in Tom show that applying our encoding leads
to performances comparable to the native Tom strategies.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08632</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 4 (November
  28, 2017) lmcs:4096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08639</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast-Slow Recurrent Neural Networks</dc:title>
 <dc:creator>Mujika, Asier</dc:creator>
 <dc:creator>Meier, Florian</dc:creator>
 <dc:creator>Steger, Angelika</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Processing sequential data of variable length is a major challenge in a wide
range of applications, such as speech recognition, language modeling,
generative image modeling and machine translation. Here, we address this
challenge by proposing a novel recurrent neural network (RNN) architecture, the
Fast-Slow RNN (FS-RNN). The FS-RNN incorporates the strengths of both
multiscale RNNs and deep transition RNNs as it processes sequential data on
different timescales and learns complex transition functions from one time step
to the next. We evaluate the FS-RNN on two character level language modeling
data sets, Penn Treebank and Hutter Prize Wikipedia, where we improve state of
the art results to $1.19$ and $1.25$ bits-per-character (BPC), respectively. In
addition, an ensemble of two FS-RNNs achieves $1.20$ BPC on Hutter Prize
Wikipedia outperforming the best known compression algorithm with respect to
the BPC measure. We also present an empirical investigation of the learning and
network dynamics of the FS-RNN, which explains the improved performance
compared to other RNN architectures. Our approach is general as any kind of RNN
cell is a possible building block for the FS-RNN architecture, and thus can be
flexibly applied to different tasks.
</dc:description>
 <dc:description>Comment: Corrected minor typos in Figure 1 and Zoneout citation</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08640</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Representing the suffix tree with the CDAWG</dc:title>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>Cunial, Fabio</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a string $T$, it is known that its suffix tree can be represented using
the compact directed acyclic word graph (CDAWG) with $e_T$ arcs, taking overall
$O(e_T+e_{{\overline{T}}})$ words of space, where ${\overline{T}}$ is the
reverse of $T$, and supporting some key operations in time between $O(1)$ and
$O(\log{\log{n}})$ in the worst case. This representation is especially
appealing for highly repetitive strings, like collections of similar genomes or
of version-controlled documents, in which $e_T$ grows sublinearly in the length
of $T$ in practice. In this paper we augment such representation, supporting a
number of additional queries in worst-case time between $O(1)$ and $O(\log{n})$
in the RAM model, without increasing space complexity asymptotically. Our
technique, based on a heavy path decomposition of the suffix tree, enables also
a representation of the suffix array, of the inverse suffix array, and of $T$
itself, that takes $O(e_T)$ words of space, and that supports random access in
$O(\log{n})$ time. Furthermore, we establish a connection between the reversed
CDAWG of $T$ and a context-free grammar that produces $T$ and only $T$, which
might have independent interest.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure. Presented at the 28th Annual Symposium on
  Combinatorial Pattern Matching (CPM 2017)</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08652</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Success Probability of Decoding (Partial) Unit Memory Codes</dc:title>
 <dc:creator>Puchinger, Sven</dc:creator>
 <dc:creator>M&#xfc;elich, Sven</dc:creator>
 <dc:creator>Bossert, Martin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we derive analytic expressions for the success probability of
decoding (Partial) Unit Memory codes in memoryless channels. An applications of
this result is that these codes outperform individual block codes in certain
channels.
</dc:description>
 <dc:description>Comment: 9 pages, extended version of a paper submitted to the International
  Workshop on Optimal Codes and Related Topics, 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08657</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial n-fold Integer Programming and Applications</dc:title>
 <dc:creator>Knop, Du&#x161;an</dc:creator>
 <dc:creator>Kouteck&#xfd;, Martin</dc:creator>
 <dc:creator>Mnich, Matthias</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Many fundamental NP-hard problems can be formulated as integer linear
programs (ILPs). A famous algorithm by Lenstra solves ILPs in time that is
exponential only in the dimension of the program, and polynomial in the size of
the ILP. That algorithm became a ubiquitous tool in the design of
fixed-parameter algorithms for NP-hard problems, where one wishes to isolate
the hardness of a problemby some parameter. However, in many cases using
Lenstra's algorithm has two drawbacks: First, the run time of the resulting
algorithms is often doubly-exponential in the parameter, and second, an ILP
formulation in small dimension cannot easily express problems involving many
different costs.
  Inspired by the work of Hemmecke, Onn and Romanchuk [Math. Prog. 2013], we
develop a single-exponential algorithm for so-called combinatorial n-fold
integer programs, which are remarkably similar to prior ILP formulations for
various problems, but unlike them, also allow variable dimension. We then apply
our algorithm to a few representative problems like Closest String, Swap
Bribery, Weighted Set Multicover, and obtain exponential speedups in the
dependence on the respective parameters, the input size, or both.
  Unlike Lenstra's algorithm, which is essentially a bounded search tree
algorithm, our result uses the technique of augmenting steps. At its heart is a
deep result stating that in combinatorial n-fold IPs, existence of an
augmenting step implies existence of a \local&quot; augmenting step, which can be
found using dynamic programming. Our results provide an important insight into
many problems by showing that they exhibit this phenomenon, and highlights the
importance of augmentation techniques.
</dc:description>
 <dc:description>Comment: 245 pages, preliminary results were presented during ESA 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08657</dc:identifier>
 <dc:identifier>doi:10.4230/LIPIcs.ESA.2017.54</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08660</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix of Polynomials Model based Polynomial Dictionary Learning Method
  for Acoustic Impulse Response Modeling</dc:title>
 <dc:creator>Guan, Jian</dc:creator>
 <dc:creator>Wang, Xuan</dc:creator>
 <dc:creator>Feng, Pengming</dc:creator>
 <dc:creator>Dong, Jing</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We study the problem of dictionary learning for signals that can be
represented as polynomials or polynomial matrices, such as convolutive signals
with time delays or acoustic impulse responses. Recently, we developed a method
for polynomial dictionary learning based on the fact that a polynomial matrix
can be expressed as a polynomial with matrix coefficients, where the
coefficient of the polynomial at each time lag is a scalar matrix. However, a
polynomial matrix can be also equally represented as a matrix with polynomial
elements. In this paper, we develop an alternative method for learning a
polynomial dictionary and a sparse representation method for polynomial signal
reconstruction based on this model. The proposed methods can be used directly
to operate on the polynomial matrix without having to access its coefficients
matrices. We demonstrate the performance of the proposed method for acoustic
impulse response modeling.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08661</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robot Introspection with Bayesian Nonparametric Vector Autoregressive
  Hidden Markov Models</dc:title>
 <dc:creator>Wu, Hongmin</dc:creator>
 <dc:creator>Lin, Hongbin</dc:creator>
 <dc:creator>Guan, Yisheng</dc:creator>
 <dc:creator>Harada, Kensuke</dc:creator>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot introspection, as opposed to anomaly detection typical in process
monitoring, helps a robot understand what it is doing at all times. A robot
should be able to identify its actions not only when failure or novelty occurs,
but also as it executes any number of sub-tasks. As robots continue their quest
of functioning in unstructured environments, it is imperative they understand
what is it that they are actually doing to render them more robust. This work
investigates the modeling ability of Bayesian nonparametric techniques on
Markov Switching Process to learn complex dynamics typical in robot contact
tasks. We study whether the Markov switching process, together with Bayesian
priors can outperform the modeling ability of its counterparts: an HMM with
Bayesian priors and without. The work was tested in a snap assembly task
characterized by high elastic forces. The task consists of an insertion subtask
with very complex dynamics. Our approach showed a stronger ability to
generalize and was able to better model the subtask with complex dynamics in a
computationally efficient way. The modeling technique is also used to learn a
growing library of robot skills, one that when integrated with low-level
control allows for robot online decision making.
</dc:description>
 <dc:description>Comment: final version submitted to humanoids 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08661</dc:identifier>
 <dc:identifier>doi:10.1109/HUMANOIDS.2017.8246976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08664</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Understanding the Invertibility of Convolutional Neural Networks</dc:title>
 <dc:creator>Gilbert, Anna C.</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:creator>Lee, Kibok</dc:creator>
 <dc:creator>Zhang, Yuting</dc:creator>
 <dc:creator>Lee, Honglak</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Several recent works have empirically observed that Convolutional Neural Nets
(CNNs) are (approximately) invertible. To understand this approximate
invertibility phenomenon and how to leverage it more effectively, we focus on a
theoretical explanation and develop a mathematical model of sparse signal
recovery that is consistent with CNNs with random weights. We give an exact
connection to a particular model of model-based compressive sensing (and its
recovery algorithms) and random-weight CNNs. We show empirically that several
learned networks are consistent with our mathematical analysis and then
demonstrate that with such a simple theoretical framework, we can obtain
reasonable re- construction results on real images. We also discuss gaps
between our model assumptions and the CNN trained for classification in
practical scenarios.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08664</dc:identifier>
 <dc:identifier>IJCAI 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08665</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Compression for Deep Learning</dc:title>
 <dc:creator>Louizos, Christos</dc:creator>
 <dc:creator>Ullrich, Karen</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Compression and computational efficiency in deep learning have become a
problem of great significance. In this work, we argue that the most principled
and effective way to attack this problem is by adopting a Bayesian point of
view, where through sparsity inducing priors we prune large parts of the
network. We introduce two novelties in this paper: 1) we use hierarchical
priors to prune nodes instead of individual weights, and 2) we use the
posterior uncertainties to determine the optimal fixed point precision to
encode the weights. Both factors significantly contribute to achieving the
state of the art in terms of compression rates, while still staying competitive
with methods designed to optimize for speed or energy efficiency.
</dc:description>
 <dc:description>Comment: Published as a conference paper at NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08666</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Near Real-Time BGP Deep Analysis: A Big-Data Approach</dc:title>
 <dc:creator>Obstfeld, Joel</dc:creator>
 <dc:creator>Chen, Xiaoyu</dc:creator>
 <dc:creator>Frebourg, Olivier</dc:creator>
 <dc:creator>Sudheendra, Pavan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  BGP (Border Gateway Protocol) serves as the primary routing protocol for the
Internet, enabling Autonomous Systems (individual network operators) to
exchange network reachability information. Alongside significant on-going
research and development efforts, there is a practical need to understand the
nature of events that occur on the Internet.
  Network operators are acutely aware of security-related incidents such as
'Prefix Hijacking' as well as the impact of network instabilities that ripple
through the Internet. Recent research focused on the study of BGP anomalies
(both network/prefix instability and security-related incidents) has been based
on the analysis of historical logs. Further analysis to understand the nature
of these anomalous events is not always sufficient to be able to differentiate
malicious activities, such as prefix- or sub-prefix- hijacking, from those
events caused by inadvertent misconfigurations. In addition, such techniques
are challenged by a lack of sufficient resources to store and process data
feeds in real-time from multiple BGP Vantage Points (VPs).
  In this paper, we present a BGP Deep-analysis application developed using the
PNDA (Platform for Network Data Analytics) 'Big-Data' platform. PNDA provides a
highly scalable environment that enables the ingestion and processing of 'live'
BGP feeds from many vantage points in a schema-agnostic manner. The Apache
Spark-based application, in conjunction with PNDA's distributed processing
capabilities, is able to perform high-level insights as well as
near-to-real-time statistical analysis
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, 2 Tables, submitted to ACM Internet Measurement
  Conference 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08666</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08668</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alliance formation with exclusion in the spatial public goods game</dc:title>
 <dc:creator>Szolnoki, Attila</dc:creator>
 <dc:creator>Chen, Xiaojie</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Cellular Automata and Lattice Gases</dc:subject>
 <dc:subject>Physics - Biological Physics</dc:subject>
 <dc:description>  Detecting defection and alarming partners about the possible danger could be
essential to avoid being exploited. This act, however, may require a huge
individual effort from those who take this job, hence such a strategy seems to
be unfavorable. But structured populations can provide an opportunity where a
largely unselfish excluder strategy can form an effective alliance with other
cooperative strategies, hence they can sweep out defection. Interestingly, this
alliance is functioning even at the extremely high cost of exclusion where the
sole application of an exclusion strategy would be harmful otherwise. These
results may explain why the emergence of extreme selfless behavior is not
necessarily against individual selection but could be the result of an
evolutionary process.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08668</dc:identifier>
 <dc:identifier>Physical Review E 95 (2017) 052316</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.052316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08676</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the M\&quot;obius Function and Topology of General Pattern Posets</dc:title>
 <dc:creator>Smith, Jason P</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:description>  We introduce a formal definition of a pattern poset which encompasses several
previously studied posets in the literature. Using this definition we present
some general results on the M\&quot;obius function and topology of such pattern
posets. We prove our results using a poset fibration based on the embeddings of
the poset, where embeddings are representations of occurrences. We show that
the M\&quot;obius function of these posets is intrinsically linked to the number of
embeddings, and in particular to so called normal embeddings. We present
results on when topological properties such as Cohen-Macaulayness and
shellability are preserved by this fibration. Furthermore, we apply these
results to some pattern posets and derive alternative proofs of existing
results, such as Bj\&quot;orner's results on subword order. Moreover, we conjecture
that shellability is preserved by poset fibrations satisfying certain
conditions, which would generalise a result of Quillen's showing
Cohen-Macaulayness is preserved under similar conditions, and we prove a
restricted form of this conjecture.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08684</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MmWave System for Future ITS: A MAC-layer Approach for V2X Beam Steering</dc:title>
 <dc:creator>Mavromatis, Ioannis</dc:creator>
 <dc:creator>Tassi, Andrea</dc:creator>
 <dc:creator>Piechocki, Robert J.</dc:creator>
 <dc:creator>Nix, Andrew</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Millimeter Waves (mmWave) systems have the potential of enabling
multi-gigabit-per-second communications in future Intelligent Transportation
Systems (ITSs). Unfortunately, because of the increased vehicular mobility,
they require frequent antenna beam realignments - thus significantly increasing
the in-band Beamforming (BF) overhead. In this paper, we propose Smart
Motion-prediction Beam Alignment (SAMBA), a MAC-layer algorithm that exploits
the information broadcast via DSRC beacons by all vehicles. Based on this
information, overhead-free BF is achieved by estimating the position of the
vehicle and predicting its motion. Moreover, adapting the beamwidth with
respect to the estimated position can further enhance the performance. Our
investigation shows that SAMBA outperforms the IEEE 802.11ad BF strategy,
increasing the data rate by more than twice for sparse vehicle density while
enhancing the network throughput proportionally to the number of vehicles.
Furthermore, SAMBA was proven to be more efficient compared to legacy BF
algorithm under highly dynamic vehicular environments and hence, a viable
solution for future ITS services.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE VTC Fall 2017 conference proceedings</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08684</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08690</identifier>
 <datestamp>2017-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continual Learning with Deep Generative Replay</dc:title>
 <dc:creator>Shin, Hanul</dc:creator>
 <dc:creator>Lee, Jung Kwon</dc:creator>
 <dc:creator>Kim, Jaehong</dc:creator>
 <dc:creator>Kim, Jiwon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Attempts to train a comprehensive artificial intelligence capable of solving
multiple tasks have been impeded by a chronic problem called catastrophic
forgetting. Although simply replaying all previous data alleviates the problem,
it requires large memory and even worse, often infeasible in real world
applications where the access to past data is limited. Inspired by the
generative nature of hippocampus as a short-term memory system in primate
brain, we propose the Deep Generative Replay, a novel framework with a
cooperative dual model architecture consisting of a deep generative model
(&quot;generator&quot;) and a task solving model (&quot;solver&quot;). With only these two models,
training data for previous tasks can easily be sampled and interleaved with
those for a new task. We test our methods in several sequential learning
settings involving image classification tasks.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08695</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Sequential Neural Networks with Structured Inference</dc:title>
 <dc:creator>Liu, Hao</dc:creator>
 <dc:creator>Bai, Haoli</dc:creator>
 <dc:creator>He, Lirong</dc:creator>
 <dc:creator>Xu, Zenglin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Unsupervised structure learning in high-dimensional time series data has
attracted a lot of research interests. For example, segmenting and labelling
high dimensional time series can be helpful in behavior understanding and
medical diagnosis. Recent advances in generative sequential modeling have
suggested to combine recurrent neural networks with state space models (e.g.,
Hidden Markov Models). This combination can model not only the long term
dependency in sequential data, but also the uncertainty included in the hidden
states. Inheriting these advantages of stochastic neural sequential models, we
propose a structured and stochastic sequential neural network, which models
both the long-term dependencies via recurrent neural networks and the
uncertainty in the segmentation and labels via discrete random variables. For
accurate and efficient inference, we present a bi-directional inference network
by reparamterizing the categorical segmentation and labels with the recent
proposed Gumbel-Softmax approximation and resort to the Stochastic Gradient
Variational Bayes. We evaluate the proposed model in a number of tasks,
including speech modeling, automatic segmentation and labeling in behavior
understanding, and sequential multi-objects recognition. Experimental results
have demonstrated that our proposed model can achieve significant improvement
over the state-of-the-art methods.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08708</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SNMP for Common Lisp</dc:title>
 <dc:creator>Tian, Chun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.2.6</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  Simple Network Management Protocol (SNMP) is widely used for management of
Internet-based network today. In Lisp community, there're large Lisp-based
applications which may need be monitored, and there're Lispers who may need to
monitor other remote systems which are either Lisp-based or not. However, the
relationship between Lisp and SNMP haven't been studied enough during past 20
years.
  The cl-net-snmp project has developed a new Common Lisp package which
implemented the SNMP protocol. On client side, it can be used to query remote
SNMP peers, and on server side, it brings SNMP capability into Common Lisp
based applications, which could be monitored from remote through any SNMP-based
management system. It's also a flexible platform for researches on network
management and SNMP itself. But the most important, this project tries to
prove: Common Lisp is the most fit language to implement SNMP.
  Different from other exist SNMP projects on Common Lisp, cl-net-snmp is
clearly targeted on full SNMP protocol support include SNMPv3 and server-side
work (agent). During the development, an general ASN.1 compiler and runtime
package and an portable UDP networking package are also implemented, which
would be useful for other related projects.
  In this paper, the author first introduces the SNMP protocol and a quick
tutorial of cl-net-snmp on both client and server sides, and then the Lisp
native design and the implementation details of the ASN.1 and SNMP package,
especially the &quot;code generation&quot;' approach on compiling SNMP MIB definitions
from ASN.1 into Common Lisp.
</dc:description>
 <dc:description>Comment: 10 pages; reprinted from ILC '09, Proceedings of the International
  Lisp Conference, March 22-25, 2009, Cambridge, Massachusetts, USA</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08708</dc:identifier>
 <dc:identifier>ILC '09, Proceedings of the International Lisp Conference, March
  22-25, 2009, Cambridge, Massachusetts, USA</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08709</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>V2X Meets NOMA: Non-Orthogonal Multiple Access for 5G Enabled Vehicular
  Networks</dc:title>
 <dc:creator>Di, Boya</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Benefited from the widely deployed infrastructure, the LTE network has
recently been considered as a promising candidate to support the
vehicle-to-everything (V2X) services. However, with a massive number of devices
accessing the V2X network in the future, the conventional OFDM-based LTE
network faces the congestion issues due to its low efficiency of orthogonal
access, resulting in significant access delay and posing a great challenge
especially to safety-critical applications. The non-orthogonal multiple access
(NOMA) technique has been well recognized as an effective solution for the
future 5G cellular networks to provide broadband communications and massive
connectivity. In this article, we investigate the applicability of NOMA in
supporting cellular V2X services to achieve low latency and high reliability.
Starting with a basic V2X unicast system, a novel NOMA-based scheme is proposed
to tackle the technical hurdles in designing high spectral efficient scheduling
and resource allocation schemes in the ultra dense topology. We then extend it
to a more general V2X broadcasting system. Other NOMA-based extended V2X
applications and some open issues are also discussed.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Wireless Communications Magazine</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08711</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-orthogonal Multiple Access for High-reliable and Low-latency V2X
  Communications</dc:title>
 <dc:creator>Di, Boya</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In this paper, we consider a dense vehicular communication network where each
vehicle broadcasts its safety information to its neighborhood in each
transmission period. Such applications require low latency and high
reliability, and thus, we propose a non-orthogonal multiple access scheme to
reduce the latency and to improve the packet reception probability. In the
proposed scheme, the BS performs the semi-persistent scheduling to optimize the
time scheduling and allocate frequency resources in a non-orthogonal manner
while the vehicles autonomously perform distributed power control. We formulate
the centralized scheduling and resource allocation problem as equivalent to a
multi-dimensional stable roommate matching problem, in which the users and
time/frequency resources are considered as disjoint sets of players to be
matched with each other. We then develop a novel rotation matching algorithm,
which converges to a q-exchange stable matching after a limited number of
iterations. Simulation results show that the proposed scheme outperforms the
traditional orthogonal multiple access scheme in terms of the latency and
reliability.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08715</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On path-based coalgebras and weak notions of bisimulation</dc:title>
 <dc:creator>Beohar, Harsh</dc:creator>
 <dc:creator>K&#xfc;pper, Sebastian</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  It is well known that the theory of coalgebras provides an abstract
definition of behavioural equivalence that coincides with strong bisimulation
across a wide variety of state-based systems. Unfortunately, the theory in the
presence of so-called silent actions is not yet fully developed. In this paper,
we give a coalgebraic characterisation of branching bisimulation in the context
of labelled transition systems and fully probabilistic systems. It is shown
that recording executions (up to a notion of stuttering), rather than the set
of successor states, from a state is sufficient to characterise branching
bisimulation in both cases.
</dc:description>
 <dc:description>Comment: A long version (with proofs) of CALCO'17 paper</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08720</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bag-of-Paths Node Criticality Measure</dc:title>
 <dc:creator>Lebichot, Bertrand</dc:creator>
 <dc:creator>Saerens, Marco</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This work compares several node (and network) criticality measures
quantifying to which extend each node is critical with respect to the
communication flow between nodes of the network, and introduces a new measure
based on the Bag-of-Paths (BoP) framework. Network disconnection simulation
experiments show that the new BoP measure outperforms all the other measures on
a sample of Erdos-Renyi and Albert-Barabasi graphs. Furthermore, a faster
(still O(n^3)), approximate, BoP criticality relying on the Sherman-Morrison
rank-one update of a matrix is introduced for tackling larger networks. This
approximate measure shows similar performances as the original, exact, one.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08722</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open-Category Classification by Adversarial Sample Generation</dc:title>
 <dc:creator>Yu, Yang</dc:creator>
 <dc:creator>Qu, Wei-Yang</dc:creator>
 <dc:creator>Li, Nan</dc:creator>
 <dc:creator>Guo, Zimin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In real-world classification tasks, it is difficult to collect training
samples from all possible categories of the environment. Therefore, when an
instance of an unseen class appears in the prediction stage, a robust
classifier should be able to tell that it is from an unseen class, instead of
classifying it to be any known category. In this paper, adopting the idea of
adversarial learning, we propose the ASG framework for open-category
classification. ASG generates positive and negative samples of seen categories
in the unsupervised manner via an adversarial learning strategy. With the
generated samples, ASG then learns to tell seen from unseen in the supervised
manner. Experiments performed on several datasets show the effectiveness of
ASG.
</dc:description>
 <dc:description>Comment: Published in IJCAI 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08730</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Patterns and Re-Use in Bioinformatics Databases</dc:title>
 <dc:creator>Bell, Michael J</dc:creator>
 <dc:creator>Lord, Phillip</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  As the quantity of data being depositing into biological databases continues
to increase, it becomes ever more vital to develop methods that enable us to
understand this data and ensure that the knowledge is correct. It is
widely-held that data percolates between different databases, which causes
particular concerns for data correctness; if this percolation occurs, incorrect
data in one database may eventually affect many others while, conversely,
corrections in one database may fail to percolate to others.
  In this paper, we test this widely-held belief by directly looking for
sentence reuse both within and between databases. Further, we investigate
patterns of how sentences are reused over time. Finally, we consider the
limitations of this form of analysis and the implications that this may have
for bioinformatics database design.
  We show that reuse of annotation is common within many different databases,
and that also there is a detectable level of reuse between databases. In
addition, we show that there are patterns of reuse that have previously been
shown to be associated with percolation errors.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08730</dc:identifier>
 <dc:identifier>Bioinformatics 2017</dc:identifier>
 <dc:identifier>doi:10.1093/bioinformatics/btx310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08733</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic Profiling for Mobile Video Streaming</dc:title>
 <dc:creator>Tsilimantos, Dimitrios</dc:creator>
 <dc:creator>Karagkioules, Theodoros</dc:creator>
 <dc:creator>Nogales-G&#xf3;mez, Amaya</dc:creator>
 <dc:creator>Valentin, Stefan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper describes a novel system that provides key parameters of HTTP
Adaptive Streaming (HAS) sessions to the lower layers of the protocol stack. A
non-intrusive traffic profiling solution is proposed that observes packet flows
at the transmit queue of base stations, edge-routers, or gateways. By analyzing
IP flows in real time, the presented scheme identifies different phases of an
HAS session and estimates important application-layer parameters, such as
play-back buffer state and video encoding rate. The introduced estimators only
use IP-layer information, do not require standardization and work even with
traffic that is encrypted via Transport Layer Security (TLS). Experimental
results for a popular video streaming service clearly verify the high accuracy
of the proposed solution. Traffic profiling, thus, provides a valuable
alternative to cross-layer signaling and Deep Packet Inspection (DPI) in order
to perform efficient network optimization for video streaming.
</dc:description>
 <dc:description>Comment: 7 pages, 11 figures. Accepted for publication in the proceedings of
  IEEE ICC'17</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08736</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-Stationary Spectral Kernels</dc:title>
 <dc:creator>Remes, Sami</dc:creator>
 <dc:creator>Heinonen, Markus</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose non-stationary spectral kernels for Gaussian process regression.
We propose to model the spectral density of a non-stationary kernel function as
a mixture of input-dependent Gaussian process frequency density surfaces. We
solve the generalised Fourier transform with such a model, and present a family
of non-stationary and non-monotonic kernels that can learn input-dependent and
potentially long-range, non-monotonic covariances between inputs. We derive
efficient inference using model whitening and marginalized posterior, and show
with case studies that these kernels are necessary when modelling even rather
simple time series, image or geospatial data with non-stationary
characteristics.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08738</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doppler Synthetic Aperture Radar Interferometry: A Novel SAR
  Interferometry for Height Mapping using Ultra-Narrowband Waveforms</dc:title>
 <dc:creator>Yazici, Birsen</dc:creator>
 <dc:creator>Son, Il-Young</dc:creator>
 <dc:creator>Yanik, H. Cagri</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This paper introduces a new and novel radar interferometry based on Doppler
synthetic aperture radar (Doppler-SAR) paradigm. Conventional SAR
interferometry relies on wideband transmitted waveforms to obtain high range
resolution. Topography of a surface is directly related to the range difference
between two antennas configured at different positions. Doppler-SAR is a novel
imaging modality that uses ultra-narrowband continuous waves (UNCW). It takes
advantage of high resolution Doppler information provided by UNCWs to form high
resolution SAR images.
  We introduced the theory of Doppler-SAR interferometry. We derived
interferometric phase model and develop the equations of height mapping. Unlike
conventional SAR interferometry, we show that the topography of a scene is
related to the difference in Doppler between two antennas configured at
different velocities. While the conventional SAR interferometry uses range,
Doppler and Doppler due to interferometric phase in height mapping, Doppler-SAR
interferometry uses Doppler, Doppler-rate and Doppler-rate due to
interferometric phase in height mapping. We demonstrate our theory in numerical
simulations.
  Doppler-SAR interferometry offers the advantages of long-range, robust,
environmentally friendly operations; low-power, low-cost, lightweight systems
suitable for low-payload platforms, such as micro-satellites; and passive
applications using sources of opportunity transmitting UNCW.
</dc:description>
 <dc:description>Comment: Submitted to Inverse Problems</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08738</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08741</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Train longer, generalize better: closing the generalization gap in large
  batch training of neural networks</dc:title>
 <dc:creator>Hoffer, Elad</dc:creator>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:creator>Soudry, Daniel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Background: Deep learning models are typically trained using stochastic
gradient descent or one of its variants. These methods update the weights using
their gradient, estimated from a small fraction of the training data. It has
been observed that when using large batch sizes there is a persistent
degradation in generalization performance - known as the &quot;generalization gap&quot;
phenomena. Identifying the origin of this gap and closing it had remained an
open problem.
  Contributions: We examine the initial high learning rate training phase. We
find that the weight distance from its initialization grows logarithmically
with the number of weight updates. We therefore propose a &quot;random walk on
random landscape&quot; statistical model which is known to exhibit similar
&quot;ultra-slow&quot; diffusion behavior. Following this hypothesis we conducted
experiments to show empirically that the &quot;generalization gap&quot; stems from the
relatively small number of updates rather than the batch size, and can be
completely eliminated by adapting the training regime used. We further
investigate different techniques to train models in the large-batch regime and
present a novel algorithm named &quot;Ghost Batch Normalization&quot; which enables
significant decrease in the generalization gap without increasing the number of
updates. To validate our findings we conduct several additional experiments on
MNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices
and beliefs concerning training of deep models and suggest they may not be
optimal to achieve good generalization.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2018-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08741</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 30 2017; pages
  1729-1739;
  http://papers.nips.cc/paper/6770-train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08743</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast algorithms for anti-distance matrices as a generalization of
  Boolean matrices</dc:title>
 <dc:creator>de Bondt, Michiel</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that Boolean matrix multiplication, computed as a sum of products of
column vectors with row vectors, is essentially the same as Warshall's
algorithm for computing the transitive closure matrix of a graph from its
adjacency matrix.
  Warshall's algorithm can be generalized to Floyd's algorithm for computing
the distance matrix of a graph with weighted edges. We will generalize Boolean
matrices in the same way, keeping matrix multiplication essentially equivalent
to the Floyd-Warshall algorithm. This way, we get matrices over a semiring,
which are similar to the so-called &quot;funny matrices&quot;.
  We discuss our implementation of operations on Boolean matrices and on their
generalization, which make use of vector instructions.
</dc:description>
 <dc:description>Comment: 10 pages + g++ template header files; minor corrections + friend
  class declarations added</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08747</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On winning shifts of marked uniform substitutions</dc:title>
 <dc:creator>Peltom&#xe4;ki, Jarkko</dc:creator>
 <dc:creator>Salo, Ville</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  The second author introduced with I. T\&quot;orm\&quot;a a two-player word-building
game [Playing with Subshifts, Fund. Inform. 132 (2014), 131--152]. The game has
a predetermined (possibly finite) choice sequence $\alpha_1$, $\alpha_2$,
$\ldots$ of integers such that on round $n$ the player $A$ chooses a subset
$S_n$ of size $\alpha_n$ of some fixed finite alphabet and the player $B$ picks
a letter from the set $S_n$. The outcome is determined by whether the word
obtained by concatenating the letters $B$ picked lies in a prescribed target
set $X$ (a win for player $A$) or not (a win for player $B$). Typically, we
consider $X$ to be a subshift. The winning shift $W(X)$ of a subshift $X$ is
defined as the set of choice sequences for which $A$ has a winning strategy
when the target set is the language of $X$. The winning shift $W(X)$ mirrors
some properties of $X$. For instance, $W(X)$ and $X$ have the same entropy.
Virtually nothing is known about the structure of the winning shifts of
subshifts common in combinatorics on words. In this paper, we study the winning
shifts of subshifts generated by marked uniform substitutions, and show that
these winning shifts, viewed as subshifts, also have a substitutive structure.
It is known that $W(X)$ and $X$ have the same factor complexity. We exploit
this connection to give a simple derivation of the first difference and factor
complexity functions of subshifts generated by marked substitutions. We
describe these functions in particular detail for the generalized Thue-Morse
substitutions.
</dc:description>
 <dc:description>Comment: Extended version of a paper presented at RuFiDiM IV</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08754</identifier>
 <datestamp>2017-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From the Minimum Path Cover Problem to Boosting Dynamic Programming on
  DAGs</dc:title>
 <dc:creator>Kuosmanen, Anna</dc:creator>
 <dc:creator>Paavilainen, Topi</dc:creator>
 <dc:creator>Gagie, Travis</dc:creator>
 <dc:creator>Chikhi, Rayan</dc:creator>
 <dc:creator>Tomescu, Alexandru I.</dc:creator>
 <dc:creator>M&#xe4;kinen, Veli</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  A minimum path cover of a directed acyclic graph (DAG) is a
minimum-cardinality set of paths covering all its nodes. It is a fundamental
concept in combinatorics and computer science, with various applications in
both theory (e.g., reachability queries) and practice (e.g., bioinformatics).
In this paper we study the case when the size $k$ of a minimum path cover is
small, which is often the case in practice, and make three main contributions:
(1) We propose an algorithm for finding a minimum path cover of a DAG $(V,E)$
in $O(k|E|\log|V|)$ time, improving all known time-bounds when $k$ is small. An
immediate consequence is an improved space/time tradeoff for reachability
queries in arbitrary directed graphs; (2) We introduce a general technique for
extending dynamic programming (DP) algorithms from sequences to DAGs. This is
enabled by our minimum path cover algorithm, and works by mimicking the DP
algorithm for sequences on each path of the minimum path cover. This technique
generally produces algorithms that are slower than their counterparts on
sequences only by a factor $k$. We illustrate this on two classical problems
extended to labeled DAGs: longest increasing subsequence and longest common
subsequence. For the former we obtain an algorithm with running time
$O(k|E|\log |V|)$. This matches the optimal solution to the classical problem
variant when, e.g., the input sequence is modeled as a path. We obtain an
analogous result for the longest common subsequence problem; (3) We also apply
this technique to the co-linear chaining problem, which has attracted interest
recently in bioinformatics. This is a generalization of both of the above two
problems. The algorithm for this problem turns out to be more involved, needing
further ingredients, such as an FM-index tailored for large alphabets, and a
two-dimensional range search tree modified to support range maximum queries.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08759</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence
  Models for Fill-in-the-Blank Image Captioning</dc:title>
 <dc:creator>Sun, Qing</dc:creator>
 <dc:creator>Lee, Stefan</dc:creator>
 <dc:creator>Batra, Dhruv</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We develop the first approximate inference algorithm for 1-Best (and M-Best)
decoding in bidirectional neural sequence models by extending Beam Search (BS)
to reason about both forward and backward time dependencies. Beam Search (BS)
is a widely used approximate inference algorithm for decoding sequences from
unidirectional neural sequence models. Interestingly, approximate inference in
bidirectional models remains an open problem, despite their significant
advantage in modeling information from both the past and future. To enable the
use of bidirectional models, we present Bidirectional Beam Search (BiBS), an
efficient algorithm for approximate bidirectional inference.To evaluate our
method and as an interesting problem in its own right, we introduce a novel
Fill-in-the-Blank Image Captioning task which requires reasoning about both
past and future sentence structure to reconstruct sensible image descriptions.
We use this task as well as the Visual Madlibs dataset to demonstrate the
effectiveness of our approach, consistently outperforming all baseline methods.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08764</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Detrending to Accelerate Convolutional Gated Recurrent Unit
  Training for Contextual Video Recognition</dc:title>
 <dc:creator>Jung, Minju</dc:creator>
 <dc:creator>Lee, Haanvid</dc:creator>
 <dc:creator>Tani, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Based on the progress of image recognition, video recognition has been
extensively studied recently. However, most of the existing methods are focused
on short-term but not long-term video recognition, called contextual video
recognition. To address contextual video recognition, we use convolutional
recurrent neural networks (ConvRNNs) having a rich spatio-temporal information
processing capability, but ConvRNNs requires extensive computation that slows
down training. In this paper, inspired by the normalization and detrending
methods, we propose adaptive detrending (AD) for temporal normalization in
order to accelerate the training of ConvRNNs, especially for convolutional
gated recurrent unit (ConvGRU). AD removes internal covariate shift within a
sequence of each neuron in recurrent neural networks (RNNs) by subtracting a
trend. In the experiments for contextual recognition on ConvGRU, the results
show that (1) ConvGRU clearly outperforms the feed-forward neural networks, (2)
AD consistently offers a significant training acceleration and generalization
improvement, and (3) AD is further improved by collaborating with the existing
normalization methods.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08773</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Two-Level Graph Partitioning Problem Arising in Mobile Wireless
  Communications</dc:title>
 <dc:creator>Fairbrother, Jamie</dc:creator>
 <dc:creator>Letchford, Adam</dc:creator>
 <dc:creator>Briggs, Keith</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In the k-partition problem (k-PP), one is given an edge-weighted undirected
graph, and one must partition the node set into at most k subsets, in order to
minimise (or maximise) the total weight of the edges that have their end-nodes
in the same cluster. Various hierarchical variants of this problem have been
studied in the context of data mining. We consider a 'two-level' variant that
arises in mobile wireless communications. We show that an exact algorithm based
on intelligent preprocessing, cutting planes and symmetry-breaking is capable
of solving small- and medium-size instances to proven optimality, and providing
strong lower bounds for larger instances.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08775</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Control Performance Index for Multicopters Under Off-nominal
  Conditions</dc:title>
 <dc:creator>Du, Guang-Xun</dc:creator>
 <dc:creator>Quan, Quan</dc:creator>
 <dc:creator>Xi, Zhiyu</dc:creator>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Cai, Kai-Yuan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In order to prevent loss of control (LOC) accidents,the real-time control
performance monitoring problem is studied for multicopters. Different from the
existing work, this paper does not try to monitor the performance of the
controllers directly. In turn, the disturbances of multicopters under
off-nominal conditions are estimated to affect a proposed index to tell the
user whether the multicopter will be LOC or not. Firstly, a new degree of
controllability (DoC) will be proposed for multicopters subject to control
constrains and off-nominal conditions. Then a control performance index (CPI)
is defined based on the new DoC to reflect the control performance for
multicopters. Besides, the proposed CPI is applied to a new switching control
framework to guide the control decision of multicopter under off-nominal
conditions. Finally, simulation and experimental results show the effectiveness
of the CPI and the proposed switching control framework.
</dc:description>
 <dc:description>Comment: 9 pages, 5 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08775</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08779</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Back to the Drawing Board: Revisiting the Design of Optimal Location
  Privacy-preserving Mechanisms</dc:title>
 <dc:creator>Oya, Simon</dc:creator>
 <dc:creator>Troncoso, Carmela</dc:creator>
 <dc:creator>P&#xe9;rez-Gonz&#xe1;lez, Fernando</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In the last years we have witnessed the appearance of a variety of strategies
to design optimal location privacy-preserving mechanisms, in terms of
maximizing the adversary's expected error with respect to the users'
whereabouts. In this work, we take a closer look at the defenses created by
these strategies and show that, even though they are indeed optimal in terms of
adversary's correctness, not all of them offer the same protection when looking
at other dimensions of privacy. To avoid &quot;bad&quot; choices, we argue that the
search for optimal mechanisms must be guided by complementary criteria. We
provide two example auxiliary metrics that help in this regard: the conditional
entropy, that captures an information-theoretic aspect of the problem; and the
worst-case quality loss, that ensures that the output of the mechanism always
provides a minimum utility to the users. We describe a new mechanism that
maximizes the conditional entropy and is optimal in terms of average adversary
error, and compare its performance with previously proposed optimal mechanisms
using two real datasets. Our empirical results confirm that no mechanism fares
well on every privacy criteria simultaneously, making apparent the need for
considering multiple privacy dimensions to have a good understanding of the
privacy protection a mechanism provides.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08781</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep
  Learning Approach with Fully Automatic Labeling</dc:title>
 <dc:creator>Hoermann, Stefan</dc:creator>
 <dc:creator>Bach, Martin</dc:creator>
 <dc:creator>Dietmayer, Klaus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Long-term situation prediction plays a crucial role in the development of
intelligent vehicles. A major challenge still to overcome is the prediction of
complex downtown scenarios with multiple road users, e.g., pedestrians, bikes,
and motor vehicles, interacting with each other. This contribution tackles this
challenge by combining a Bayesian filtering technique for environment
representation, and machine learning as long-term predictor. More specifically,
a dynamic occupancy grid map is utilized as input to a deep convolutional
neural network. This yields the advantage of using spatially distributed
velocity estimates from a single time step for prediction, rather than a raw
data sequence, alleviating common problems dealing with input time series of
multiple sensors. Furthermore, convolutional neural networks have the inherent
characteristic of using context information, enabling the implicit modeling of
road user interaction. Pixel-wise balancing is applied in the loss function
counteracting the extreme imbalance between static and dynamic cells. One of
the major advantages is the unsupervised learning character due to fully
automatic label generation. The presented algorithm is trained and evaluated on
multiple hours of recorded sensor data and compared to Monte-Carlo simulation.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08784</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ParMooN - a modernized program package based on mapped finite elements</dc:title>
 <dc:creator>Wilbrandt, Ulrich</dc:creator>
 <dc:creator>Bartsch, Clemens</dc:creator>
 <dc:creator>Ahmed, Naveed</dc:creator>
 <dc:creator>Alia, Najib</dc:creator>
 <dc:creator>Anker, Felix</dc:creator>
 <dc:creator>Blank, Laura</dc:creator>
 <dc:creator>Caiazzo, Alfonso</dc:creator>
 <dc:creator>Ganesan, Sashikumaar</dc:creator>
 <dc:creator>Giere, Swetlana</dc:creator>
 <dc:creator>Matthies, Gunar</dc:creator>
 <dc:creator>Meesala, Raviteja</dc:creator>
 <dc:creator>Shamim, Abdus</dc:creator>
 <dc:creator>Venkatesan, Jagannath</dc:creator>
 <dc:creator>John, Volker</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  {\sc ParMooN} is a program package for the numerical solution of elliptic and
parabolic partial differential equations. It inherits the distinct features of
its predecessor {\sc MooNMD} \cite{JM04}: strict decoupling of geometry and
finite element spaces, implementation of mapped finite elements as their
definition can be found in textbooks, and a geometric multigrid preconditioner
with the option to use different finite element spaces on different levels of
the multigrid hierarchy. After having presented some thoughts about in-house
research codes, this paper focuses on aspects of the parallelization for a
distributed memory environment, which is the main novelty of {\sc ParMooN}.
Numerical studies, performed on compute servers, assess the efficiency of the
parallelized geometric multigrid preconditioner in comparison with some
parallel solvers that are available in the library {\sc PETSc}. The results of
these studies give a first indication whether the cumbersome implementation of
the parallelized geometric multigrid method was worthwhile or not.
</dc:description>
 <dc:description>Comment: partly supported by European Union (EU), Horizon 2020, Marie
  Sk{\l}odowska-Curie Innovative Training Networks (ITN-EID), MIMESIS, grant
  number 675715</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08784</dc:identifier>
 <dc:identifier>Comput. Math. Appl. 74(1), 74-88, 2017</dc:identifier>
 <dc:identifier>doi:10.1016/j.camwa.2016.12.020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08790</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of the Jaccard index for image segmentation with the
  Lov\'asz hinge</dc:title>
 <dc:creator>Berman, Maxim</dc:creator>
 <dc:creator>Blaschko, Matthew B.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The Jaccard loss, commonly referred to as the intersection-over-union loss,
is commonly employed in the evaluation of segmentation quality due to its
better perceptual quality and scale invariance, which lends appropriate
relevance to small objects compared with per-pixel losses. We present a method
for direct optimization of the per-image intersection-over-union loss in neural
networks, in the context of semantic image segmentation, based on a convex
surrogate: the Lov\'asz hinge. The loss is shown to perform better with respect
to the Jaccard index measure than other losses traditionally used in the
context of semantic segmentation; such as cross-entropy. We develop a
specialized optimization method, based on an efficient computation of the
proximal operator of the Lov\'asz hinge, yielding reliably faster and more
stable optimization than alternatives. We demonstrate the effectiveness of the
method by showing substantially improved intersection-overunion segmentation
scores on the Pascal VOC dataset using a state-of-the-art deep learning
segmentation architecture.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08792</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Combination of the Bernays-Sch\&quot;onfinkel-Ramsey Fragment with
  Simple Linear Integer Arithmetic</dc:title>
 <dc:creator>Horbach, Matthias</dc:creator>
 <dc:creator>Voigt, Marco</dc:creator>
 <dc:creator>Weidenbach, Christoph</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In general, first-order predicate logic extended with linear integer
arithmetic is undecidable. We show that the Bernays-Sch\&quot;onfinkel-Ramsey
fragment ($\exists^* \forall^*$-sentences) extended with a restricted form of
linear integer arithmetic is decidable via finite ground instantiation. The
identified ground instances can be employed to restrict the search space of
existing automated reasoning procedures considerably, e.g., when reasoning
about quantified properties of array data structures formalized in Bradley,
Manna, and Sipma's array property fragment. Typically, decision procedures for
the array property fragment are based on an exhaustive instantiation of
universally quantified array indices with all the ground index terms that occur
in the formula at hand. Our results reveal that one can get along with
significantly fewer instances.
</dc:description>
 <dc:description>Comment: Extended version of the CADE 2017 paper having the same title, 29
  pages</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08795</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>STFT with Adaptive Window Width Based on the Chirp Rate</dc:title>
 <dc:creator>Pei, Soo-Chang</dc:creator>
 <dc:creator>Huang, Shih-Gu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An adaptive time-frequency representation (TFR) with higher energy
concentration usually requires higher complexity. Recently, a low-complexity
adaptive short-time Fourier transform (ASTFT) based on the chirp rate has been
proposed. To enhance the performance, this method is substantially modified in
this paper: i) because the wavelet transform used for instantaneous frequency
(IF) estimation is not signal-dependent, a low-complexity ASTFT based on a
novel concentration measure is addressed; ii) in order to increase robustness
to IF estimation error, the principal component analysis (PCA) replaces the
difference operator for calculating the chirp rate; and iii) a more robust
Gaussian kernel with time-frequency-varying window width is proposed.
Simulation results show that our method has higher energy concentration than
the other ASTFTs, especially for multicomponent signals and nonlinear FM
signals. Also, for IF estimation, our method is superior to many other adaptive
TFRs in low signal-to-noise ratio (SNR) environments.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08795</dc:identifier>
 <dc:identifier>IEEE Transactions on Signal Processing, Volume: 60, Issue: 8, Aug.
  2012</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2012.2197204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08801</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Properties of Normalization for a math based intermediate representation</dc:title>
 <dc:creator>Chiw, Charisee</dc:creator>
 <dc:creator>Reppy, John</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  The Normalization transformation plays a key role in the compilation of
Diderot programs. The transformations are complicated and it would be easy for
a bug to go undetected. To increase our confidence in normalization part of the
compiler we provide a formal analysis on the rewriting system. We proof that
the rewrite system is type preserving, value preserving (for tensor-valued
expressions), and terminating.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08804</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Parity: Fairness Objectives for Collaborative Filtering</dc:title>
 <dc:creator>Yao, Sirui</dc:creator>
 <dc:creator>Huang, Bert</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study fairness in collaborative-filtering recommender systems, which are
sensitive to discrimination that exists in historical data. Biased data can
lead collaborative-filtering methods to make unfair predictions for users from
minority groups. We identify the insufficiency of existing fairness metrics and
propose four new metrics that address different forms of unfairness. These
fairness metrics can be optimized by adding fairness terms to the learning
objective. Experiments on synthetic and real data show that our new metrics can
better measure fairness than the baseline, and that the fairness objectives
effectively help reduce unfairness.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08807</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Will AI Exceed Human Performance? Evidence from AI Experts</dc:title>
 <dc:creator>Grace, Katja</dc:creator>
 <dc:creator>Salvatier, John</dc:creator>
 <dc:creator>Dafoe, Allan</dc:creator>
 <dc:creator>Zhang, Baobao</dc:creator>
 <dc:creator>Evans, Owain</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Advances in artificial intelligence (AI) will transform modern life by
reshaping transportation, health, science, finance, and the military. To adapt
public policy, we need to better anticipate these advances. Here we report the
results from a large survey of machine learning researchers on their beliefs
about progress in AI. Researchers predict AI will outperform humans in many
activities in the next ten years, such as translating languages (by 2024),
writing high-school essays (by 2026), driving a truck (by 2027), working in
retail (by 2031), writing a bestselling book (by 2049), and working as a
surgeon (by 2053). Researchers believe there is a 50% chance of AI
outperforming humans in all tasks in 45 years and of automating all human jobs
in 120 years, with Asian respondents expecting these dates much sooner than
North Americans. These results will inform discussion amongst researchers and
policymakers about anticipating and managing trends in AI.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08807</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08808</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Friendship and Selfishness Forwarding: applying machine learning
  techniques to Opportunistic Networks data forwarding</dc:title>
 <dc:creator>Souza, Camilo</dc:creator>
 <dc:creator>Mota, Edjair</dc:creator>
 <dc:creator>Galvao, Leandro</dc:creator>
 <dc:creator>Soares, Diogo</dc:creator>
 <dc:creator>Manzoni, Pietro</dc:creator>
 <dc:creator>Cano, Juan Carlos</dc:creator>
 <dc:creator>Calafate, Carlos</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Opportunistic networks could become the solution to provide communication
support in both cities where the cellular network could be overloaded, and in
scenarios where a fixed infrastructure is not available, like in remote and
developing regions. A critical issue that still requires a satisfactory
solution is the design of an efficient data delivery solution. Social
characteristics are recently being considered as a promising alternative. Most
opportunistic network applications rely on the different mobile devices carried
by users, and whose behavior affects the use of the device itself.
  This work presents the &quot;Friendship and Selfishness Forwarding&quot; (FSF)
algorithm. FSF analyses two aspects to make message forwarding decisions when a
contact opportunity arises: First, it classifies the friendship strength among
a pair of nodes by using a machine learning algorithm to quantify the
friendship strength among pairs of nodes in the network. Next, FSF assesses the
relay node selfishness to consider those cases in which, despite a strong
friendship with the destination, the relay node may not accept to receive the
message because it is behaving selfishly, or because its device has resource
constraints in that moment.
  By using trace-driven simulations through the ONE simulator, we show that the
FSF algorithm outperforms previously proposed schemes in terms of delivery
rate, average cost, and efficiency.
</dc:description>
 <dc:description>Comment: 27 pages, 25 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08808</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08809</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HTTP adaptive streaming with indoors-outdoors detection in mobile
  networks</dc:title>
 <dc:creator>Mekki, Sami</dc:creator>
 <dc:creator>Karagkioules, Theodoros</dc:creator>
 <dc:creator>Valentin, Stefan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In mobile networks, users may lose coverage when entering a building due to
the high signal attenuation at windows and walls. Under such conditions,
services with minimum bit-rate requirements, such as video streaming, often
show poor Quality-of-Experience (QoE). We will present a Bayesian detector that
combines measurements from two Smartphone sensors to decide if a user is inside
a building or not. Based on this coverage classification, we will propose an
HTTP adaptive streaming (HAS) algorithm to increase playback stability at a
high average bitrate. Measurements in a typical office building show high
accuracy for the presented detector and superior QoE for the proposed HAS
algorithm.
</dc:description>
 <dc:description>Comment: 6 pages, 6 figures. Accepted at CNTCV: Communication and Networking
  Techniqes for Contemporary Video Workshop of INFOCOM'17</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08809</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08815</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Systems Data Fusion based on Belief Propagation</dc:title>
 <dc:creator>Fusco, Francesco</dc:creator>
 <dc:creator>Tirupathi, Seshu</dc:creator>
 <dc:creator>Gormally, Robert</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  The increasing complexity of the power grid, due to higher penetration of
distributed resources and the growing availability of interconnected,
distributed metering devices re- quires novel tools for providing a unified and
consistent view of the system. A computational framework for power systems data
fusion, based on probabilistic graphical models, capable of combining
heterogeneous data sources with classical state estimation nodes and other
customised computational nodes, is proposed. The framework allows flexible
extension of the notion of grid state beyond the view of flows and injection in
bus-branch models, and an efficient, naturally distributed inference algorithm
can be derived. An application of the data fusion model to the quantification
of distributed solar energy is proposed through numerical examples based on
semi-synthetic simulations of the standard IEEE 14-bus test case.
</dc:description>
 <dc:description>Comment: Version as accepted for publication at the 7th IEEE International
  Conference on Innovative Smart Grid Technologies (ISGT) Europe 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08816</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing Timelines of National Histories across Wikipedia Editions: A
  Comparative Computational Approach</dc:title>
 <dc:creator>Samoilenko, Anna</dc:creator>
 <dc:creator>Lemmerich, Florian</dc:creator>
 <dc:creator>Weller, Katrin</dc:creator>
 <dc:creator>Zens, Maria</dc:creator>
 <dc:creator>Strohmaier, Markus</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Portrayals of history are never complete, and each description inherently
exhibits a specific viewpoint and emphasis. In this paper, we aim to
automatically identify such differences by computing timelines and detecting
temporal focal points of written history across languages on Wikipedia. In
particular, we study articles related to the history of all UN member states
and compare them in 30 language editions. We develop a computational approach
that allows to identify focal points quantitatively, and find that Wikipedia
narratives about national histories (i) are skewed towards more recent events
(recency bias) and (ii) are distributed unevenly across the continents with
significant focus on the history of European countries (Eurocentric bias). We
also establish that national historical timelines vary across language
editions, although average interlingual consensus is rather high. We hope that
this paper provides a starting point for a broader computational analysis of
written history on Wikipedia and elsewhere.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08816</dc:identifier>
 <dc:identifier>Proceedings of the Eleventh International AAAI Conference on Web
  an Social Media (ICWSM 2017 in Montreal, Canada)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08818</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A hierarchical multirate MPC scheme for interconnected systems -
  $\textit{extended version}$</dc:title>
 <dc:creator>Farina, Marcello</dc:creator>
 <dc:creator>Zhang, Xinglong</dc:creator>
 <dc:creator>Scattolini, Riccardo</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a hierarchical control scheme for interconnected linear
systems. At the higher layer of the control structure a robust centralized
Model Predictive Control (MPC) algorithm based on a reduced order dynamic model
of the overall system optimizes a long-term performance index penalizing the
deviation of the state and the control input from their nominal values. At the
lower layer local MPC regulators, possibly working at different rates, are
designed for the full order models of the subsystems to refine the control
action computed at the higher layer. A simulation experiment is presented to
describe the implementation aspects and the potentialities of the proposed
approach.
</dc:description>
 <dc:description>Comment: 35 pages,7 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08819</identifier>
 <datestamp>2017-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matrix-product structure of repeated-root constacyclic codes over finite
  fields</dc:title>
 <dc:creator>Cao, Yuan</dc:creator>
 <dc:creator>Cao, Yonglin</dc:creator>
 <dc:creator>Fu, Fang-Wei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For any prime number $p$, positive integers $m, k, n$ satisfying ${\rm
gcd}(p,n)=1$ and $\lambda_0\in \mathbb{F}_{p^m}^\times$, we prove that any
$\lambda_0^{p^k}$-constacyclic code of length $p^kn$ over the finite field
$\mathbb{F}_{p^m}$ is monomially equivalent to a matrix-product code of a
nested sequence of $p^k$ $\lambda_0$-constacyclic codes with length $n$ over
$\mathbb{F}_{p^m}$.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08821</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Effect Inference with Deep Latent-Variable Models</dc:title>
 <dc:creator>Louizos, Christos</dc:creator>
 <dc:creator>Shalit, Uri</dc:creator>
 <dc:creator>Mooij, Joris</dc:creator>
 <dc:creator>Sontag, David</dc:creator>
 <dc:creator>Zemel, Richard</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning individual-level causal effects from observational data, such as
inferring the most effective medication for a specific patient, is a problem of
growing importance for policy makers. The most important aspect of inferring
causal effects from observational data is the handling of confounders, factors
that affect both an intervention and its outcome. A carefully designed
observational study attempts to measure all important confounders. However,
even if one does not have direct access to all confounders, there may exist
noisy and uncertain measurement of proxies for confounders. We build on recent
advances in latent variable modeling to simultaneously estimate the unknown
latent space summarizing the confounders and the causal effect. Our method is
based on Variational Autoencoders (VAE) which follow the causal structure of
inference with proxies. We show our method is significantly more robust than
existing methods, and matches the state-of-the-art on previous benchmarks
focused on individual treatment effects.
</dc:description>
 <dc:description>Comment: Published as a conference paper at NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08824</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From source to target and back: symmetric bi-directional adaptive GAN</dc:title>
 <dc:creator>Russo, Paolo</dc:creator>
 <dc:creator>Carlucci, Fabio Maria</dc:creator>
 <dc:creator>Tommasi, Tatiana</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The effectiveness of generative adversarial approaches in producing images
according to a specific style or visual domain has recently opened new
directions to solve the unsupervised domain adaptation problem. It has been
shown that source labeled images can be modified to mimic target samples making
it possible to train directly a classifier in the target domain, despite the
original lack of annotated data. Inverse mappings from the target to the source
domain have also been evaluated but only passing through adapted feature
spaces, thus without new image generation. In this paper we propose to better
exploit the potential of generative adversarial networks for adaptation by
introducing a novel symmetric mapping among domains. We jointly optimize
bi-directional image transformations combining them with target self-labeling.
Moreover we define a new class consistency loss that aligns the generators in
the two directions imposing to conserve the class identity of an image passing
through both domain mappings. A detailed qualitative and quantitative analysis
of the reconstructed images confirm the power of our approach. By integrating
the two domain specific classifiers obtained with our bi-directional network we
exceed previous state-of-the-art unsupervised adaptation results on four
different benchmark datasets.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08824</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08826</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Average Top-k Loss</dc:title>
 <dc:creator>Fan, Yanbo</dc:creator>
 <dc:creator>Lyu, Siwei</dc:creator>
 <dc:creator>Ying, Yiming</dc:creator>
 <dc:creator>Hu, Bao-Gang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we introduce the {\em average top-$k$} (\atk) loss as a new
aggregate loss for supervised learning, which is the average over the $k$
largest individual losses over a training dataset. We show that the \atk loss
is a natural generalization of the two widely used aggregate losses, namely the
average loss and the maximum loss, but can combine their advantages and
mitigate their drawbacks to better adapt to different data distributions.
Furthermore, it remains a convex function over all individual losses, which can
lead to convex optimization problems that can be solved effectively with
conventional gradient-based methods. We provide an intuitive interpretation of
the \atk loss based on its equivalent effect on the continuous individual loss
functions, suggesting that it can reduce the penalty on correctly classified
data. We further give a learning theory analysis of \matk learning on the
classification calibration of the \atk loss and the error bounds of \atk-SVM.
We demonstrate the applicability of minimum average top-$k$ learning for binary
classification and regression using synthetic and real datasets.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08828</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Investigation of Cross-Language Plagiarism Detection Methods</dc:title>
 <dc:creator>Ferrero, Jeremy</dc:creator>
 <dc:creator>Besacier, Laurent</dc:creator>
 <dc:creator>Schwab, Didier</dc:creator>
 <dc:creator>Agnes, Frederic</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper is a deep investigation of cross-language plagiarism detection
methods on a new recently introduced open dataset, which contains parallel and
comparable collections of documents with multiple characteristics (different
genres, languages and sizes of texts). We investigate cross-language plagiarism
detection methods for 6 language pairs on 2 granularities of text units in
order to draw robust conclusions on the best methods while deeply analyzing
correlations across document styles and languages.
</dc:description>
 <dc:description>Comment: Accepted to BUCC (10th Workshop on Building and Using Comparable
  Corpora) colocated with ACL 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08841</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Level Variational Autoencoder: Learning Disentangled
  Representations from Grouped Observations</dc:title>
 <dc:creator>Bouchacourt, Diane</dc:creator>
 <dc:creator>Tomioka, Ryota</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We would like to learn a representation of the data which decomposes an
observation into factors of variation which we can independently control.
Specifically, we want to use minimal supervision to learn a latent
representation that reflects the semantics behind a specific grouping of the
data, where within a group the samples share a common factor of variation. For
example, consider a collection of face images grouped by identity. We wish to
anchor the semantics of the grouping into a relevant and disentangled
representation that we can easily exploit. However, existing deep probabilistic
models often assume that the observations are independent and identically
distributed. We present the Multi-Level Variational Autoencoder (ML-VAE), a new
deep probabilistic model for learning a disentangled representation of a set of
grouped observations. The ML-VAE separates the latent representation into
semantically meaningful parts by working both at the group level and the
observation level, while retaining efficient test-time inference. Quantitative
and qualitative evaluations show that the ML-VAE model (i) learns a
semantically meaningful disentanglement of grouped data, (ii) enables
manipulation of the latent representation, and (iii) generalises to unseen
groups.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08843</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parsing with CYK over Distributed Representations: &quot;Classical&quot; Syntactic
  Parsing in the Novel Era of Neural Networks</dc:title>
 <dc:creator>Zanzotto, Fabio Massimo</dc:creator>
 <dc:creator>Cristini, Giordano</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  Syntactic parsing is a key task in natural language processing which has been
dominated by symbolic, grammar-based syntactic parsers. Neural networks, with
their distributed representations, are challenging these methods.
  In this paper, we want to show that existing parsing algorithms can cross the
border and be defined over distributed representations. We then define D-CYK: a
version of the traditional CYK algorithm defined over distributed
representations. Our D-CYK operates as the original CYK but uses matrix
multiplications. These operations are compatible with traditional neural
networks. Experiments show that D-CYK approximates the original CYK. By showing
that CYK can be performed on distributed representations, our D-CYK opens the
possibility of defining recurrent layers of CYK-informed neural networks.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08844</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How a General-Purpose Commonsense Ontology can Improve Performance of
  Learning-Based Image Retrieval</dc:title>
 <dc:creator>Icarte, Rodrigo Toro</dc:creator>
 <dc:creator>Baier, Jorge A.</dc:creator>
 <dc:creator>Ruz, Cristian</dc:creator>
 <dc:creator>Soto, Alvaro</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The knowledge representation community has built general-purpose ontologies
which contain large amounts of commonsense knowledge over relevant aspects of
the world, including useful visual information, e.g.: &quot;a ball is used by a
football player&quot;, &quot;a tennis player is located at a tennis court&quot;. Current
state-of-the-art approaches for visual recognition do not exploit these
rule-based knowledge sources. Instead, they learn recognition models directly
from training examples. In this paper, we study how general-purpose
ontologies---specifically, MIT's ConceptNet ontology---can improve the
performance of state-of-the-art vision systems. As a testbed, we tackle the
problem of sentence-based image retrieval. Our retrieval approach incorporates
knowledge from ConceptNet on top of a large pool of object detectors derived
from a deep learning technique. In our experiments, we show that ConceptNet can
improve performance on a common benchmark dataset. Key to our performance is
the use of the ESPGAME dataset to select visually relevant relations from
ConceptNet. Consequently, a main conclusion of this work is that
general-purpose commonsense ontologies improve performance on visual reasoning
tasks when properly filtered to select meaningful visual relations.
</dc:description>
 <dc:description>Comment: Accepted in IJCAI-17</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08848</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Distribution Optimal Transportation for Domain Adaptation</dc:title>
 <dc:creator>Courty, Nicolas</dc:creator>
 <dc:creator>Flamary, R&#xe9;mi</dc:creator>
 <dc:creator>Habrard, Amaury</dc:creator>
 <dc:creator>Rakotomamonjy, Alain</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper deals with the unsupervised domain adaptation problem, where one
wants to estimate a prediction function $f$ in a given target domain without
any labeled sample by exploiting the knowledge available from a source domain
where labels are known. Our work makes the following assumption: there exists a
non-linear transformation between the joint feature/label space distributions
of the two domain $\mathcal{P}_s$ and $\mathcal{P}_t$. We propose a solution of
this problem with optimal transport, that allows to recover an estimated target
$\mathcal{P}^f_t=(X,f(X))$ by optimizing simultaneously the optimal coupling
and $f$. We show that our method corresponds to the minimization of a bound on
the target error, and provide an efficient algorithmic solution, for which
convergence is proved. The versatility of our approach, both in terms of class
of hypothesis or loss functions is demonstrated with real world classification
and regression problems, for which we reach or surpass state-of-the-art
results.
</dc:description>
 <dc:description>Comment: Accepted for publication at NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08849</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Matrix-Free Implementation of Frequency-Domain Finite
  Difference Methods for Cluster Computing</dc:title>
 <dc:creator>Geranmayeh, Amir</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Full-wave 3D electromagnetic simulations of complex planar devices,
multilayer interconnects, and chip packages are presented for wide-band
frequency-domain analysis using the finite difference integration technique
developed in the PETSc software package. Initial reordering of the index
assignment to the unknowns makes the resulting system matrix diagonally
dominant. The rearrangement also facilitates the decomposition of large domain
into slices for passing the mesh information to different machines. Matrix-free
methods are then exploited to minimize the number of element-wise
multiplications and memory requirements in the construction of the system of
linear equations. Besides, the recipes provide extreme ease of modifications in
the kernel of the code. The applicability of different Krylov subspace solvers
is investigated. The accuracy is checked through comparisons with CST MICROWAVE
STUDIO transient solver results. The parallel execution of the compiled code on
specific number of processors in multi-core distributed-memory architectures
demonstrate high scalability of the computational algorithm.
</dc:description>
 <dc:description>Comment: 7 pages, 10 figures including: Matrix-free 3D finite-difference
  frequency-domain (FDFD) methods, Simultaneous reduction in memory usage and
  computational costs of FDFD, Broadband impedance calculation of electrically
  large interconnects, Ease of solver modification for mutual field coupling
  simulation between many ports, Domain decomposition for passing the mesh
  information to parallel machines</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08850</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Learning with GANs: Manifold Invariance with Improved
  Inference</dc:title>
 <dc:creator>Kumar, Abhishek</dc:creator>
 <dc:creator>Sattigeri, Prasanna</dc:creator>
 <dc:creator>Fletcher, P. Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Semi-supervised learning methods using Generative Adversarial Networks (GANs)
have shown promising empirical success recently. Most of these methods use a
shared discriminator/classifier which discriminates real examples from fake
while also predicting the class label. Motivated by the ability of the GANs
generator to capture the data manifold well, we propose to estimate the tangent
space to the data manifold using GANs and employ it to inject invariances into
the classifier. In the process, we propose enhancements over existing methods
for learning the inverse mapping (i.e., the encoder) which greatly improves in
terms of semantic similarity of the reconstructed sample with the input sample.
We observe considerable empirical gains in semi-supervised learning over
baselines, particularly in the cases when the number of labeled examples is
low. We also provide insights into how fake examples influence the
semi-supervised learning procedure.
</dc:description>
 <dc:description>Comment: NIPS 2017 accepted version, including appendix</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08855</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the expected moments between two identical random processes with
  application to sensor network</dc:title>
 <dc:creator>Kapelko, Rafal</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We give a closed analytical formula for expected distance to the power $a$
between two identical general random processes, when $a$ is an even positive
number.
  As an application to sensor network we prove that the optimal transportation
cost to the power $b&gt;0$ of the maximal random bicolored matching with edges
$\{X_k,Y_k\}$ is in $\frac{\Theta\left(n^{\frac{b}{2}+1}\right)}{{\lambda}^b}$
when $b \ge 2,$ and in $\frac{O\left(n^{\frac{b}{2}+1}\right)}{{\lambda}^b}$
when $0&lt; b &lt; 2.$
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08855</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08858</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Audio-replay attack detection countermeasures</dc:title>
 <dc:creator>Lavrentyeva, Galina</dc:creator>
 <dc:creator>Novoselov, Sergey</dc:creator>
 <dc:creator>Malykh, Egor</dc:creator>
 <dc:creator>Kozlov, Alexander</dc:creator>
 <dc:creator>Kudashev, Oleg</dc:creator>
 <dc:creator>Shchemelinin, Vadim</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents the Speech Technology Center (STC) replay attack
detection systems proposed for Automatic Speaker Verification Spoofing and
Countermeasures Challenge 2017. In this study we focused on comparison of
different spoofing detection approaches. These were GMM based methods, high
level features extraction with simple classifier and deep learning frameworks.
Experiments performed on the development and evaluation parts of the challenge
dataset demonstrated stable efficiency of deep learning approaches in case of
changing acoustic conditions. At the same time SVM classifier with high level
features provided a substantial input in the efficiency of the resulting STC
systems according to the fusion systems results.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, accepted for Specom 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08861</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Handover analysis of the Improved Phantom Cells</dc:title>
 <dc:creator>Sharifi, Pouya</dc:creator>
 <dc:creator>Shahraki, Hamid Shahrokh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Improved Phantom cell is a new scenario which has been introduced recently to
enhance the capacity of Heterogeneous Networks (HetNets). The main trait of
this scenario is that, besides maximizing the total network capacity in both
indoor and outdoor environments, it claims to reduce the handover number
compared to the conventional scenarios. In this paper, by a comprehensive
review of the Improved Phantom cells structure, an appropriate algorithm will
be introduced for the handover procedure of this scenario. To reduce the number
of handover in the proposed algorithm, various parameters such as the received
Signal to Interference plus Noise Ratio (SINR) at the user equipment (UE),
users access conditions to the phantom cells, and users staying time in the
target cell based on its velocity, has been considered. Theoretical analyses
and simulation results show that applying the suggested algorithm the improved
phantom cell structure has a much better performance than conventional HetNets
in terms of the number of handover.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08865</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anti-spoofing Methods for Automatic SpeakerVerification System</dc:title>
 <dc:creator>Lavrentyeva, Galina</dc:creator>
 <dc:creator>Novoselov, Sergey</dc:creator>
 <dc:creator>Simonchik, Konstantin</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Growing interest in automatic speaker verification (ASV)systems has lead to
significant quality improvement of spoofing attackson them. Many research works
confirm that despite the low equal er-ror rate (EER) ASV systems are still
vulnerable to spoofing attacks. Inthis work we overview different acoustic
feature spaces and classifiersto determine reliable and robust countermeasures
against spoofing at-tacks. We compared several spoofing detection systems,
presented so far,on the development and evaluation datasets of the Automatic
SpeakerVerification Spoofing and Countermeasures (ASVspoof) Challenge
2015.Experimental results presented in this paper demonstrate that the useof
magnitude and phase information combination provides a substantialinput into
the efficiency of the spoofing detection systems. Also wavelet-based features
show impressive results in terms of equal error rate. Inour overview we compare
spoofing performance for systems based on dif-ferent classifiers. Comparison
results demonstrate that the linear SVMclassifier outperforms the conventional
GMM approach. However, manyresearchers inspired by the great success of deep
neural networks (DNN)approaches in the automatic speech recognition, applied
DNN in thespoofing detection task and obtained quite low EER for known and
un-known type of spoofing attacks.
</dc:description>
 <dc:description>Comment: 12 pages, 0 figures, published in Springer Communications in Computer
  and Information Science (CCIS) vol. 661</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08868</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in
  Generative Models</dc:title>
 <dc:creator>Grover, Aditya</dc:creator>
 <dc:creator>Dhar, Manik</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Adversarial learning of probabilistic models has recently emerged as a
promising alternative to maximum likelihood. Implicit models such as generative
adversarial networks (GAN) often generate better samples compared to explicit
models trained by maximum likelihood. Yet, GANs sidestep the characterization
of an explicit density which makes quantitative evaluations challenging. To
bridge this gap, we propose Flow-GANs, a generative adversarial network for
which we can perform exact likelihood evaluation, thus supporting both
adversarial and maximum likelihood training. When trained adversarially,
Flow-GANs generate high-quality samples but attain extremely poor
log-likelihood scores, inferior even to a mixture model memorizing the training
data; the opposite is true when trained by maximum likelihood. Results on MNIST
and CIFAR-10 demonstrate that hybrid training can attain high held-out
likelihoods while retaining visual fidelity in the generated samples.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2018-01-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08870</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PaToPa: A Data-Driven Parameter and Topology Joint Estimation Framework
  in Distribution Grids</dc:title>
 <dc:creator>Yu, Jiafan</dc:creator>
 <dc:creator>Weng, Yang</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The increasing integration of distributed energy resources (DERs) calls for
new planning and operational tools. However, such tools depend on system
topology and line parameters, which may be missing or inaccurate in
distribution grids. With abundant data, one idea is to use linear regression to
find line parameters, based on which topology can be identified. Unfortunately,
the linear regression method is accurate only if there is no noise in both the
input measurements (e.g., voltage magnitude and phase angle) and output
measurements (e.g., active and reactive power). For topology estimation, even
with a small error in measurements, the regression-based method is incapable of
finding the topology using non-zero line parameters with a proper metric. To
model input and output measurement errors simultaneously, we propose the
error-in-variables (EIV) model in a maximum likelihood estimation (MLE)
framework for joint line parameter and topology estimation. While directly
solving the problem is NP-hard, we successfully adapt the problem into a
generalized low-rank approximation problem via variable transformation and
noise decorrelation. For accurate topology estimation, we let it interact with
parameter estimation in a fashion that is similar to expectation-maximization
fashion in machine learning. The proposed PaToPa approach does not require a
radial network setting and works for mesh networks. We demonstrate the superior
performance in accuracy for our method on IEEE test cases with actual feeder
data from South California Edison.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08878</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Channel Capacities Per Unit Cost</dc:title>
 <dc:creator>Ding, Dawei</dc:creator>
 <dc:creator>Pavlichin, Dmitri S.</dc:creator>
 <dc:creator>Wilde, Mark M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Communication over a noisy channel is often conducted in a setting in which
different input symbols to the channel incur a certain cost. For example, for
the additive white Gaussian noise channel, the cost associated with a real
number input symbol is the square of its magnitude. In such a setting, it is
often useful to know the maximum amount of information that can be reliably
transmitted per cost incurred. This is known as the capacity per unit cost. In
this paper, we generalize the capacity per unit cost to various communication
tasks involving a quantum channel; in particular, we consider classical
communication, entanglement-assisted classical communication, private
communication, and quantum communication. For each task, we define the
corresponding capacity per unit cost and derive a formula for it analogous to
that of the usual capacity. Furthermore, for the special case in which there is
a zero-cost quantum state, we obtain expressions for the various capacities per
unit cost in terms of an optimized relative entropy involving the zero-cost
state. For each communication task, we construct an explicit
pulse-position-modulation coding scheme that achieves the capacity per unit
cost. Finally, we compute capacities per unit cost for various quantum Gaussian
channels and introduce the notion of a blocklength-constrained capacity per
unit cost.
</dc:description>
 <dc:description>Comment: 35 pages, 2 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08881</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dense Transformer Networks</dc:title>
 <dc:creator>Li, Jun</dc:creator>
 <dc:creator>Chen, Yongjun</dc:creator>
 <dc:creator>Cai, Lei</dc:creator>
 <dc:creator>Davidson, Ian</dc:creator>
 <dc:creator>Ji, Shuiwang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The key idea of current deep learning methods for dense prediction is to
apply a model on a regular patch centered on each pixel to make pixel-wise
predictions. These methods are limited in the sense that the patches are
determined by network architecture instead of learned from data. In this work,
we propose the dense transformer networks, which can learn the shapes and sizes
of patches from data. The dense transformer networks employ an encoder-decoder
architecture, and a pair of dense transformer modules are inserted into each of
the encoder and decoder paths. The novelty of this work is that we provide
technical solutions for learning the shapes and sizes of patches from data and
efficiently restoring the spatial correspondence required for dense prediction.
The proposed dense transformer modules are differentiable, thus the entire
network can be trained. We apply the proposed networks on natural and
biological image segmentation tasks and show superior performance is achieved
in comparison to baseline methods.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08883</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling flow in porous media with double porosity/permeability: A
  stabilized mixed formulation, error analysis, and numerical solutions</dc:title>
 <dc:creator>Joodat, S. H. S.</dc:creator>
 <dc:creator>Nakshatrala, K. B.</dc:creator>
 <dc:creator>Ballarini, R.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The flow of incompressible fluids through porous media plays a crucial role
in many technological applications such as enhanced oil recovery and geological
carbon-dioxide sequestration. The flow within numerous natural and synthetic
porous materials that contain multiple scales of pores cannot be adequately
described by the classical Darcy equations. It is for this reason that
mathematical models for fluid flow in media with multiple scales of pores have
been proposed in the literature. However, these models are analytically
intractable for realistic problems. In this paper, a stabilized mixed
four-field finite element formulation is presented to study the flow of an
incompressible fluid in porous media exhibiting double porosity/permeability.
The stabilization terms and the stabilization parameters are derived in a
mathematically and thermodynamically consistent manner, and the computationally
convenient equal-order interpolation of all the field variables is shown to be
stable. A systematic error analysis is performed on the resulting stabilized
weak formulation. Representative problems, patch tests and numerical
convergence analyses are performed to illustrate the performance and
convergence behavior of the proposed mixed formulation in the discrete setting.
The accuracy of numerical solutions is assessed using the mathematical
properties satisfied by the solutions of this double porosity/permeability
model. Moreover, it is shown that the proposed framework can perform well under
transient conditions and that it can capture well-known instabilities such as
viscous fingering.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08884</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uncovering the Flop of the EU Cookie Law</dc:title>
 <dc:creator>Trevisan, Martino</dc:creator>
 <dc:creator>Traverso, Stefano</dc:creator>
 <dc:creator>Metwalley, Hassan</dc:creator>
 <dc:creator>Mellia, Marco</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In 2002, the European Union (EU) introduced the ePrivacy Directive to
regulate the usage of online tracking technologies. Its aim is to make tracking
mechanisms explicit while increasing privacy awareness in users. It mandates
websites to ask for explicit consent before using any kind of profiling
methodology, e.g., cookies. Starting from 2013 the Directive is mandatory, and
now most of European websites embed a &quot;Cookie Bar&quot; to explicitly ask user's
consent. To the best of our knowledge, no study focused in checking whether a
website respects the Directive. For this, we engineer CookieCheck, a simple
tool that makes this check automatic. We use it to run a measure- ment campaign
on more than 35,000 websites. Results depict a dramatic picture: 65% of
websites do not respect the Directive and install tracking cookies before the
user is even offered the accept button. In few words, we testify the failure of
the ePrivacy Directive. Among motivations, we identify the absence of rules
enabling systematic auditing procedures, the lack of tools to verify its
implementation by the deputed agencies, and the technical difficulties of
webmasters in implementing it.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08885</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linearizable Iterators for Concurrent Set Implementations</dc:title>
 <dc:creator>Agarwal, Archita</dc:creator>
 <dc:creator>Liu, Zhiyu</dc:creator>
 <dc:creator>Rosenthal, Eli</dc:creator>
 <dc:creator>Saraph, Vikram</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper proposes a general framework for adding linearizable iterators to
certain data structures that implement set operations. We introduce a condition
on set operations, called locality, which informally states that set operations
never make elements existing in the data structure unreachable to a sequential
iterator's traversal. Data structures satisfying the locality condition can be
augmented with a linearizable iterator via the proposed framework. Our
technique is broadly applicable to a variety of data structures, including hash
tables and binary search trees. We apply the technique to data structures taken
from existing literature, prove locality of their operations, and demonstrate
that the iterator framework does not significantly affect the performance of
concurrent set operations.
</dc:description>
 <dc:description>Comment: 19 pages, 13 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08889</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PrivacyScore: Analyse von Webseiten auf Sicherheits- und
  Privatheitsprobleme -- Konzept und rechtliche Zul\&quot;assigkeit</dc:title>
 <dc:creator>Maass, Max</dc:creator>
 <dc:creator>Laubach, Anne</dc:creator>
 <dc:creator>Herrmann, Dominik</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  PrivacyScore ist ein \&quot;offentliches Web-Portal, mit dem automatisiert
\&quot;uberpr\&quot;uft werden kann, ob Webseiten g\&quot;angige Mechanismen zum Schutz von
Sicherheit und Privatheit korrekt implementieren. Im Gegensatz zu existierenden
Diensten erm\&quot;oglicht PrivacyScore, mehrere Webseiten in Benchmarks miteinander
zu vergleichen, die Ergebnisse differenziert und im Zeitverlauf zu analysieren
sowie nutzerdefinierte Kriterien f\&quot;ur die Auswertung zu definieren.
PrivacyScore verbessert dadurch nicht nur die Transparenz f\&quot;ur Endanwender,
sondern erleichtert auch die Arbeit der Datenschutz-Aufsichtsbeh\&quot;orden. In
diesem Beitrag stellen wir das Konzept des Dienstes vor und wir er\&quot;ortern,
unter welchen Umst\&quot;anden das automatische Scannen und \&quot;offentliche
&quot;Anprangern&quot; von Schw\&quot;achen aus rechtlicher Sicht zul\&quot;assig ist.
  --
  This German article describes the technical and legal considerations
surrounding PrivacyScore, a public web portal that allows automatic scans of
websites for privacy and security problems. For an English article discussing
the same system in more technical detail, but lacking the legal interpretation,
see arXiv:1705.05139.
</dc:description>
 <dc:description>Comment: Extended version of a paper accepted to Recht und Technik 2017.
  Partially a translation of arXiv:1705.05139. 13 pages in German</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08889</dc:identifier>
 <dc:language>de</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08918</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning Layers for Video Analysis</dc:title>
 <dc:creator>Zhao, Liang</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:creator>Yang, Yi</dc:creator>
 <dc:creator>Xu, Wei</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents two unsupervised learning layers (UL layers) for
label-free video analysis: one for fully connected layers, and the other for
convolutional ones. The proposed UL layers can play two roles: they can be the
cost function layer for providing global training signal; meanwhile they can be
added to any regular neural network layers for providing local training signals
and combined with the training signals backpropagated from upper layers for
extracting both slow and fast changing features at layers of different depths.
Therefore, the UL layers can be used in either pure unsupervised or
semi-supervised settings. Both a closed-form solution and an online learning
algorithm for two UL layers are provided. Experiments with unlabeled synthetic
and real-world videos demonstrated that the neural networks equipped with UL
layers and trained with the proposed online learning algorithm can extract
shape and motion information from video sequences of moving objects. The
experiments demonstrated the potential applications of UL layers and online
learning algorithm to head orientation estimation and moving object
localization.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08918</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08920</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Diffusion Kalman Filtering</dc:title>
 <dc:creator>Vahidpour, Vahid</dc:creator>
 <dc:creator>Rastegarnia, Amir</dc:creator>
 <dc:creator>Khalili, Azam</dc:creator>
 <dc:creator>Bazzi, Wael</dc:creator>
 <dc:creator>Sanei, Saeid</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In conventional distributed Kalman filtering, employing diffusion strategies,
each node transmits its state estimate to all its direct neighbors in each
iteration. In this paper we propose a partial diffusion Kalman filter (PDKF)
for state estimation of linear dynamic systems. In the PDKF algorithm every
node (agent) is allowed to share only a subset of its intermediate estimate
vectors at each iteration among its neighbors, which reduces the amount of
internode communications. We study the stability of the PDKF algorithm where
our analysis reveals that the algorithm is stable and convergent in both mean
and mean-square senses. We also investigate the steady-state mean-square
deviation (MSD) of the PDKF algorithm and derive a closed-form expression that
describes how the algorithm performs at the steady-state. Experimental results
validate the effectiveness of PDKF algorithm and demonstrate that the proposed
algorithm provides a trade-off between communication cost and estimation
performance that is extremely profitable.
</dc:description>
 <dc:description>Comment: 8 pages; 7 Figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08921</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent Kernel Density Estimation with Non-Vanishing Bandwidth</dc:title>
 <dc:creator>Cort&#xe9;s, Efr&#xe9;n Cruz</dc:creator>
 <dc:creator>Scott, Clayton</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Consistency of the kernel density estimator requires that the kernel
bandwidth tends to zero as the sample size grows. In this paper we investigate
the question of whether consistency is possible when the bandwidth is fixed, if
we consider a more general class of weighted KDEs. To answer this question in
the affirmative, we introduce the fixed-bandwidth KDE (fbKDE), obtained by
solving a quadratic program, and prove that it consistently estimates any
continuous square-integrable density. We also establish rates of convergence
for the fbKDE with radial kernels and the box kernel under appropriate
smoothness assumptions. Furthermore, in an experimental study we demonstrate
that the fbKDE compares favorably to the standard KDE and the previously
proposed variable bandwidth KDE.
</dc:description>
 <dc:description>Comment: 17 pages, updated abstract</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08922</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Regularity of Sparse Structure in Convolutional Neural
  Networks</dc:title>
 <dc:creator>Mao, Huizi</dc:creator>
 <dc:creator>Han, Song</dc:creator>
 <dc:creator>Pool, Jeff</dc:creator>
 <dc:creator>Li, Wenshuo</dc:creator>
 <dc:creator>Liu, Xingyu</dc:creator>
 <dc:creator>Wang, Yu</dc:creator>
 <dc:creator>Dally, William J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sparsity helps reduce the computational complexity of deep neural networks by
skipping zeros. Taking advantage of sparsity is listed as a high priority in
next generation DNN accelerators such as TPU. The structure of sparsity, i.e.,
the granularity of pruning, affects the efficiency of hardware accelerator
design as well as the prediction accuracy. Coarse-grained pruning creates
regular sparsity patterns, making it more amenable for hardware acceleration
but more challenging to maintain the same accuracy. In this paper we
quantitatively measure the trade-off between sparsity regularity and prediction
accuracy, providing insights in how to maintain accuracy while having more a
more structured sparsity pattern. Our experimental results show that
coarse-grained pruning can achieve a sparsity ratio similar to unstructured
pruning without loss of accuracy. Moreover, due to the index saving effect,
coarse-grained pruning is able to obtain a better compression ratio than
fine-grained sparsity at the same accuracy threshold. Based on the recent
sparse convolutional neural network accelerator (SCNN), our experiments further
demonstrate that coarse-grained sparsity saves about 2x the memory references
compared to fine-grained sparsity. Since memory reference is more than two
orders of magnitude more expensive than arithmetic operations, the regularity
of sparse structure leads to more efficient hardware design.
</dc:description>
 <dc:description>Comment: submitted to NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08923</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attention-based Natural Language Person Retrieval</dc:title>
 <dc:creator>Zhou, Tao</dc:creator>
 <dc:creator>Chen, Muhao</dc:creator>
 <dc:creator>Yu, Jie</dc:creator>
 <dc:creator>Terzopoulos, Demetri</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Following the recent progress in image classification and captioning using
deep learning, we develop a novel natural language person retrieval system
based on an attention mechanism. More specifically, given the description of a
person, the goal is to localize the person in an image. To this end, we first
construct a benchmark dataset for natural language person retrieval. To do so,
we generate bounding boxes for persons in a public image dataset from the
segmentation masks, which are then annotated with descriptions and attributes
using the Amazon Mechanical Turk. We then adopt a region proposal network in
Faster R-CNN as a candidate region generator. The cropped images based on the
region proposals as well as the whole images with attention weights are fed
into Convolutional Neural Networks for visual feature extraction, while the
natural language expression and attributes are input to Bidirectional Long
Short- Term Memory (BLSTM) models for text feature extraction. The visual and
text features are integrated to score region proposals, and the one with the
highest score is retrieved as the output of our system. The experimental
results show significant improvement over the state-of-the-art method for
generic object retrieval and this line of research promises to benefit search
in surveillance video footage.
</dc:description>
 <dc:description>Comment: CVPR 2017 Workshop (vision meets cognition)</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08923</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08926</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counterfactual Multi-Agent Policy Gradients</dc:title>
 <dc:creator>Foerster, Jakob</dc:creator>
 <dc:creator>Farquhar, Gregory</dc:creator>
 <dc:creator>Afouras, Triantafyllos</dc:creator>
 <dc:creator>Nardelli, Nantas</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Cooperative multi-agent systems can be naturally used to model many real
world problems, such as network packet routing and the coordination of
autonomous vehicles. There is a great need for new reinforcement learning
methods that can efficiently learn decentralised policies for such systems. To
this end, we propose a new multi-agent actor-critic method called
counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised
critic to estimate the Q-function and decentralised actors to optimise the
agents' policies. In addition, to address the challenges of multi-agent credit
assignment, it uses a counterfactual baseline that marginalises out a single
agent's action, while keeping the other agents' actions fixed. COMA also uses a
critic representation that allows the counterfactual baseline to be computed
efficiently in a single forward pass. We evaluate COMA in the testbed of
StarCraft unit micromanagement, using a decentralised variant with significant
partial observability. COMA significantly improves average performance over
other multi-agent actor-critic methods in this setting, and the best performing
agents are competitive with state-of-the-art centralised controllers that get
access to the full state.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08927</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compiling quantum circuits to realistic hardware architectures using
  temporal planners</dc:title>
 <dc:creator>Venturelli, Davide</dc:creator>
 <dc:creator>Do, Minh</dc:creator>
 <dc:creator>Rieffel, Eleanor</dc:creator>
 <dc:creator>Frank, Jeremy</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  To run quantum algorithms on emerging gate-model quantum hardware, quantum
circuits must be compiled to take into account constraints on the hardware. For
near-term hardware, with only limited means to mitigate decoherence, it is
critical to minimize the duration of the circuit. We investigate the
application of temporal planners to the problem of compiling quantum circuits
to newly emerging quantum hardware. While our approach is general, we focus on
compiling to superconducting hardware architectures with nearest neighbor
constraints. Our initial experiments focus on compiling Quantum Alternating
Operator Ansatz (QAOA) circuits whose high number of commuting gates allow
great flexibility in the order in which the gates can be applied. That freedom
makes it more challenging to find optimal compilations but also means there is
a greater potential win from more optimized compilation than for less flexible
circuits. We map this quantum circuit compilation problem to a temporal
planning problem, and generated a test suite of compilation problems for QAOA
circuits of various sizes to a realistic hardware architecture. We report
compilation results from several state-of-the-art temporal planners on this
test set. This early empirical evaluation demonstrates that temporal planning
is a viable approach to quantum circuit compilation.
</dc:description>
 <dc:description>Comment: updated manuscript, more planners and results</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08927</dc:identifier>
 <dc:identifier>2017 Quantum Sci. Technol. - also related to proceedings of IJCAI
  2017, and ICAPS SPARK Workshop 2017</dc:identifier>
 <dc:identifier>doi:10.1088/2058-9565/aaa331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08929</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transport Protocols for Large Bandwidth-Delay Product Networks - TCP
  Extensions and Alternative Transport Protocols</dc:title>
 <dc:creator>Duarte, Rui Policarpo</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>68M12</dc:subject>
 <dc:description>  TCP's poor performance is identified as the bottleneck of high-speed
networks. Extensions to TCP have been proposed and implemented. Some authors
abandon TCP at all and suggest new transport protocols to overcome TCP
limitations, at the expense of compatibility. This paper reports a research on
the most significant TCP extensions and transport alternatives, and comparison
between them. The majority of the solutions pointed out are difficult to
compare because they are tailored to specific configurations. Still there is no
specific criteria to evaluate performance metrics and comparison is done on the
most evident issues.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, 1 table, conference</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08929</dc:identifier>
 <dc:identifier>JETC'08 IV Workshop on Electronics, Telecommunications and
  Computers Engineering; Lisbon, Portugal, 2008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08931</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proximity Variational Inference</dc:title>
 <dc:creator>Altosaar, Jaan</dc:creator>
 <dc:creator>Ranganath, Rajesh</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.5.0</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  Variational inference is a powerful approach for approximate posterior
inference. However, it is sensitive to initialization and can be subject to
poor local optima. In this paper, we develop proximity variational inference
(PVI). PVI is a new method for optimizing the variational objective that
constrains subsequent iterates of the variational parameters to robustify the
optimization path. Consequently, PVI is less sensitive to initialization and
optimization quirks and finds better local optima. We demonstrate our method on
three proximity statistics. We study PVI on a Bernoulli factor model and
sigmoid belief network with both real and synthetic data and compare to
deterministic annealing (Katahira et al., 2008). We highlight the flexibility
of PVI by designing a proximity statistic for Bayesian deep learning models
such as the variational autoencoder (Kingma and Welling, 2014; Rezende et al.,
2014). Empirically, we show that PVI consistently finds better local optima and
gives better predictive performance.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08931</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08940</identifier>
 <datestamp>2017-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Servoing from Deep Neural Networks</dc:title>
 <dc:creator>Bateux, Quentin</dc:creator>
 <dc:creator>Marchand, Eric</dc:creator>
 <dc:creator>Leitner, J&#xfc;rgen</dc:creator>
 <dc:creator>Chaumette, Francois</dc:creator>
 <dc:creator>Corke, Peter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a deep neural network-based method to perform high-precision,
robust and real-time 6 DOF visual servoing. The paper describes how to create a
dataset simulating various perturbations (occlusions and lighting conditions)
from a single real-world image of the scene. A convolutional neural network is
fine-tuned using this dataset to estimate the relative pose between two images
of the same scene. The output of the network is then employed in a visual
servoing control scheme. The method converges robustly even in difficult
real-world settings with strong lighting variations and occlusions.A
positioning error of less than one millimeter is obtained in experiments with a
6 DOF robot.
</dc:description>
 <dc:description>Comment: fixed authors list</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08942</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint PoS Tagging and Stemming for Agglutinative Languages</dc:title>
 <dc:creator>B&#xf6;l&#xfc;c&#xfc;, Necva</dc:creator>
 <dc:creator>Can, Burcu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:description>  The number of word forms in agglutinative languages is theoretically infinite
and this variety in word forms introduces sparsity in many natural language
processing tasks. Part-of-speech tagging (PoS tagging) is one of these tasks
that often suffers from sparsity. In this paper, we present an unsupervised
Bayesian model using Hidden Markov Models (HMMs) for joint PoS tagging and
stemming for agglutinative languages. We use stemming to reduce sparsity in PoS
tagging. Two tasks are jointly performed to provide a mutual benefit in both
tasks. Our results show that joint POS tagging and stemming improves PoS
tagging scores. We present results for Turkish and Finnish as agglutinative
languages and English as a morphologically poor language.
</dc:description>
 <dc:description>Comment: 12 pages with 3 figures, accepted and presented at the CICLING 2017 -
  18th International Conference on Intelligent Text Processing and
  Computational Linguistics</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08942</dc:identifier>
 <dc:identifier>CICLING 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08943</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GridNet with automatic shape prior registration for automatic MRI
  cardiac segmentation</dc:title>
 <dc:creator>Zotti, Clement</dc:creator>
 <dc:creator>Luo, Zhiming</dc:creator>
 <dc:creator>Lalande, Alain</dc:creator>
 <dc:creator>Humbert, Olivier</dc:creator>
 <dc:creator>Jodoin, Pierre-Marc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a fully automatic MRI cardiac segmentation method
based on a novel deep convolutional neural network (CNN) designed for the 2017
ACDC MICCAI challenge. The novelty of our network comes with its embedded shape
prior and its loss function tailored to the cardiac anatomy. Our model includes
a cardiac centerof-mass regression module which allows for an automatic shape
prior registration. Also, since our method processes raw MR images without any
manual preprocessing and/or image cropping, our CNN learns both high-level
features (useful to distinguish the heart from other organs with a similar
shape) and low-level features (useful to get accurate segmentation results).
Those features are learned with a multi-resolution conv-deconv &quot;grid&quot;
architecture which can be seen as an extension of the U-Net. Experimental
results reveal that our method can segment the left and right ventricles as
well as the myocardium from a 3D MRI cardiac volume in 0.4 second with an
average Dice coefficient of 0.90 and an average Hausdorff distance of 10.4 mm.
</dc:description>
 <dc:description>Comment: 8 pages, 1 tables, 2 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08947</identifier>
 <datestamp>2017-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Voice 2: Multi-Speaker Neural Text-to-Speech</dc:title>
 <dc:creator>Arik, Sercan</dc:creator>
 <dc:creator>Diamos, Gregory</dc:creator>
 <dc:creator>Gibiansky, Andrew</dc:creator>
 <dc:creator>Miller, John</dc:creator>
 <dc:creator>Peng, Kainan</dc:creator>
 <dc:creator>Ping, Wei</dc:creator>
 <dc:creator>Raiman, Jonathan</dc:creator>
 <dc:creator>Zhou, Yanqi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a technique for augmenting neural text-to-speech (TTS) with
lowdimensional trainable speaker embeddings to generate different voices from a
single model. As a starting point, we show improvements over the two
state-ofthe-art approaches for single-speaker neural TTS: Deep Voice 1 and
Tacotron. We introduce Deep Voice 2, which is based on a similar pipeline with
Deep Voice 1, but constructed with higher performance building blocks and
demonstrates a significant audio quality improvement over Deep Voice 1. We
improve Tacotron by introducing a post-processing neural vocoder, and
demonstrate a significant audio quality improvement. We then demonstrate our
technique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron
on two multi-speaker TTS datasets. We show that a single neural TTS system can
learn hundreds of unique voices from less than half an hour of data per
speaker, while achieving high audio quality synthesis and preserving the
speaker identities almost perfectly.
</dc:description>
 <dc:description>Comment: Accepted in NIPS 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08948</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provable Dynamic Robust PCA or Robust Subspace Tracking</dc:title>
 <dc:creator>Narayanamurthy, Praneeth</dc:creator>
 <dc:creator>Vaswani, Namrata</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Dynamic robust PCA refers to the dynamic (time-varying) extension of the
robust PCA (RPCA) problem. It assumes that the true (uncorrupted) data lies in
a low-dimensional subspace that can change with time, albeit slowly. The goal
is to track this changing subspace over time in the presence of sparse
outliers. This work provides the first guarantee for dynamic RPCA that holds
under weakened versions of standard RPCA assumptions and a few other simple
assumptions. We analyze a novel algorithm based on the recently introduced
Recursive Projected Compressive Sensing (ReProCS) framework. Our result is
significant because (i) it removes the strong assumptions needed by the two
previous complete guarantees for ReProCS-based algorithms; (ii) it shows that,
it is possible to achieve significantly improved outlier tolerance by
exploiting slow subspace change and a lower bound on most outlier magnitudes;
and (iii) it proves that the proposed algorithm is online (after
initialization), fast, and, has near-optimal storage complexity.
</dc:description>
 <dc:description>Comment: writing changes to algorithms; included detailed discussion</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08954</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Geometric Analysis Method for Evaluation of Coexistence between DSRC
  and Wi-Fi at 5.9 GHz</dc:title>
 <dc:creator>Kim, Seungmo</dc:creator>
 <dc:creator>Dietrich, Carl</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Co-channel coexistence between Dedicated Short-Range Communications (DSRC)
and Wi-Fi needs thorough study. The reason is that although the 5.850-5.925 GHz
(5.9 GHz) band has been reserved for DSRC so far, the U.S. government is moving
swiftly on opening the band to be shared with Wi-Fi. However, most prior work
lacks sufficient scientific rigor by relying on performance metrics such as
packet delivery rate (PDR) and packet delay that cannot accurately measure
performance of a vehicular network that primarily uses broadcast in
dissemination of packets. Precise analysis of such broadcast operation is
essential for rigorous investigation of DSRC-Wi-Fi coexistence because most
safety-critical applications of DSRC operate based on broadcast. This paper
proposes a new metric that can more accurately characterize the performance of
a broadcast-based DSRC network. The new metric is used to (i) characterize
coexistence of DSRC with IEEE 802.11ac-based Wi-Fi and (ii) suggest selection
of key medium access control (MAC) parameters for DSRC: inter-broadcast
interval (IBI) and contention window (CW).
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08961</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient, Safe, and Probably Approximately Complete Learning of Action
  Models</dc:title>
 <dc:creator>Stern, Roni</dc:creator>
 <dc:creator>Juba, Brendan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper we explore the theoretical boundaries of planning in a setting
where no model of the agent's actions is given. Instead of an action model, a
set of successfully executed plans are given and the task is to generate a plan
that is safe, i.e., guaranteed to achieve the goal without failing. To this
end, we show how to learn a conservative model of the world in which actions
are guaranteed to be applicable. This conservative model is then given to an
off-the-shelf classical planner, resulting in a plan that is guaranteed to
achieve the goal. However, this reduction from a model-free planning to a
model-based planning is not complete: in some cases a plan will not be found
even when such exists. We analyze the relation between the number of observed
plans and the likelihood that our conservative approach will indeed fail to
solve a solvable problem. Our analysis show that the number of trajectories
needed scales gracefully.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08961</dc:identifier>
 <dc:identifier>International Joint Conference on Artificial Intelligence (IJCAI)
  2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08963</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepSecure: Scalable Provably-Secure Deep Learning</dc:title>
 <dc:creator>Rouhani, Bita Darvish</dc:creator>
 <dc:creator>Riazi, M. Sadegh</dc:creator>
 <dc:creator>Koushanfar, Farinaz</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper proposes DeepSecure, a novel framework that enables scalable
execution of the state-of-the-art Deep Learning (DL) models in a
privacy-preserving setting. DeepSecure targets scenarios in which neither of
the involved parties including the cloud servers that hold the DL model
parameters or the delegating clients who own the data is willing to reveal
their information. Our framework is the first to empower accurate and scalable
DL analysis of data generated by distributed clients without sacrificing the
security to maintain efficiency. The secure DL computation in DeepSecure is
performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized
realization of various components used in DL. Our optimized implementation
achieves more than 58-fold higher throughput per sample compared with the
best-known prior solution. In addition to our optimized GC realization, we
introduce a set of novel low-overhead pre-processing techniques which further
reduce the GC overall runtime in the context of deep learning. Extensive
evaluations of various DL applications demonstrate up to two
orders-of-magnitude additional runtime improvement achieved as a result of our
pre-processing methodology. This paper also provides mechanisms to securely
delegate GC computations to a third party in constrained embedded settings.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08966</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication vs Distributed Computation: an alternative trade-off curve</dc:title>
 <dc:creator>Ezzeldin, Yahya H.</dc:creator>
 <dc:creator>Karmoose, Mohammed</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we revisit the communication vs. distributed computing
trade-off, studied within the framework of MapReduce in [1]. An implicit
assumption in the aforementioned work is that each server performs all possible
computations on all the files stored in its memory. Our starting observation is
that, if servers can compute only the intermediate values they need, then
storage constraints do not directly imply computation constraints. We examine
how this affects the communication-computation trade-off and suggest that the
trade-off be studied with a predetermined storage constraint. We then proceed
to examine the case where servers need to perform computationally intensive
tasks, and may not have sufficient time to perform all computations required by
the scheme in [1]. Given a threshold that limits the computational load, we
derive a lower bound on the associated communication load, and propose a
heuristic scheme that achieves in some cases the lower bound.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08968</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Logic Tensor Networks for Semantic Image Interpretation</dc:title>
 <dc:creator>Donadello, Ivan</dc:creator>
 <dc:creator>Serafini, Luciano</dc:creator>
 <dc:creator>Garcez, Artur d'Avila</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Semantic Image Interpretation (SII) is the task of extracting structured
semantic descriptions from images. It is widely agreed that the combined use of
visual data and background knowledge is of great importance for SII. Recently,
Statistical Relational Learning (SRL) approaches have been developed for
reasoning under uncertainty and learning in the presence of data and rich
knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates
neural networks with first-order fuzzy logic to allow (i) efficient learning
from noisy data in the presence of logical constraints, and (ii) reasoning with
logical formulas describing general properties of the data. In this paper, we
develop and apply LTNs to two of the main tasks of SII, namely, the
classification of an image's bounding boxes and the detection of the relevant
part-of relations between objects. To the best of our knowledge, this is the
first successful application of SRL to such SII tasks. The proposed approach is
evaluated on a standard image processing benchmark. Experiments show that the
use of background knowledge in the form of logical constraints can improve the
performance of purely data-driven approaches, including the state-of-the-art
Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show
that the use of logical background knowledge adds robustness to the learning
system when errors are present in the labels of the training data.
</dc:description>
 <dc:description>Comment: 14 pages, 2 figures, IJCAI 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08968</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08971</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Cooperative Inference</dc:title>
 <dc:creator>Yang, Scott Cheng-Hsin</dc:creator>
 <dc:creator>Yu, Yue</dc:creator>
 <dc:creator>Givchi, Arash</dc:creator>
 <dc:creator>Wang, Pei</dc:creator>
 <dc:creator>Vong, Wai Keen</dc:creator>
 <dc:creator>Shafto, Patrick</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cooperative transmission of data fosters rapid accumulation of knowledge by
efficiently combining experiences across learners. Although well studied in
human learning and increasingly in machine learning, we lack formal frameworks
through which we may reason about the benefits and limitations of cooperative
inference. We present such a framework. We introduce novel indices for
measuring the effectiveness of probabilistic and cooperative information
transmission. We relate our indices to the well-known Teaching Dimension in
deterministic settings. We prove conditions under which optimal cooperative
inference can be achieved, including a representation theorem that constrains
the form of inductive biases for learners optimized for cooperative inference.
We conclude by demonstrating how these principles may inform the design of
machine learning algorithms and discuss implications for human and machine
learning.
</dc:description>
 <dc:description>Comment: 16 pages (5 pages of Supplementary Material), 1 figure</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2018-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08974</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cultural Diffusion and Trends in Facebook Photographs</dc:title>
 <dc:creator>You, Quanzeng</dc:creator>
 <dc:creator>Garc&#xed;a-Garc&#xed;a, Dar&#xed;o</dc:creator>
 <dc:creator>Paluri, Mahohar</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:creator>Joo, Jungseock</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online social media is a social vehicle in which people share various moments
of their lives with their friends, such as playing sports, cooking dinner or
just taking a selfie for fun, via visual means, that is, photographs. Our study
takes a closer look at the popular visual concepts illustrating various
cultural lifestyles from aggregated, de-identified photographs. We perform
analysis both at macroscopic and microscopic levels, to gain novel insights
about global and local visual trends as well as the dynamics of interpersonal
cultural exchange and diffusion among Facebook friends. We processed images by
automatically classifying the visual content by a convolutional neural network
(CNN). Through various statistical tests, we find that socially tied
individuals more likely post images showing similar cultural lifestyles. To
further identify the main cause of the observed social correlation, we use the
Shuffle test and the Preference-based Matched Estimation (PME) test to
distinguish the effects of influence and homophily. The results indicate that
the visual content of each user's photographs are temporally, although not
necessarily causally, correlated with the photographs of their friends, which
may suggest the effect of influence. Our paper demonstrates that Facebook
photographs exhibit diverse cultural lifestyles and preferences and that the
social interaction mediated through the visual channel in social media can be
an effective mechanism for cultural diffusion.
</dc:description>
 <dc:description>Comment: 10 pages, To appear in ICWSM 2017 (Full Paper)</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08974</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08979</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic sequences and generalised polynomials</dc:title>
 <dc:creator>Byszewski, Jakub</dc:creator>
 <dc:creator>Konieczny, Jakub</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Primary: 11B85, 37A45. Secondary: 37B05, 37B10, 11J71, 11B37, 05C20</dc:subject>
 <dc:description>  We conjecture that bounded generalised polynomial functions cannot be
generated by finite automata, except for the trivial case when they are
ultimately periodic.
  Using methods from ergodic theory, we are able to partially resolve this
conjecture, proving that any hypothetical counterexample is periodic away from
a very sparse and structured set.
  In particular, we show that for a polynomial $p(n)$ with at least one
irrational coefficient (except for the constant one) and integer $m\geq 2$, the
sequence $\lfloor p(n) \rfloor \bmod{m}$ is never automatic.
  We also prove that the conjecture is equivalent to the claim that the set of
powers of an integer $k\geq 2$ is not given by a generalised polynomial.
</dc:description>
 <dc:description>Comment: 29 pages, upgraded presentation and references to existing
  literature, an extended version of the second half of arxiv:1610.03900
  [math.NT]</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08982</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling The Intensity Function Of Point Process Via Recurrent Neural
  Networks</dc:title>
 <dc:creator>Xiao, Shuai</dc:creator>
 <dc:creator>Yan, Junchi</dc:creator>
 <dc:creator>Chu, Stephen M.</dc:creator>
 <dc:creator>Yang, Xiaokang</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Event sequence, asynchronously generated with random timestamp, is ubiquitous
among applications. The precise and arbitrary timestamp can carry important
clues about the underlying dynamics, and has lent the event data fundamentally
different from the time-series whereby series is indexed with fixed and equal
time interval. One expressive mathematical tool for modeling event is point
process. The intensity functions of many point processes involve two
components: the background and the effect by the history. Due to its inherent
spontaneousness, the background can be treated as a time series while the other
need to handle the history events. In this paper, we model the background by a
Recurrent Neural Network (RNN) with its units aligned with time series indexes
while the history effect is modeled by another RNN whose units are aligned with
asynchronous events to capture the long-range dynamics. The whole model with
event type and timestamp prediction output layers can be trained end-to-end.
Our approach takes an RNN perspective to point process, and models its
background and history effect. For utility, our method allows a black-box
treatment for modeling the intensity which is often a pre-defined parametric
form in point processes. Meanwhile end-to-end training opens the venue for
reusing existing rich techniques in deep network for point process modeling. We
apply our model to the predictive maintenance problem using a log dataset by
more than 1000 ATMs from a global bank headquartered in North America.
</dc:description>
 <dc:description>Comment: Accepted at Thirty-First AAAI Conference on Artificial Intelligence
  (AAAI17)</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08983</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plug-and-Play Unplugged: Optimization Free Reconstruction using
  Consensus Equilibrium</dc:title>
 <dc:creator>Buzzard, Gregery T.</dc:creator>
 <dc:creator>Chan, Stanley H.</dc:creator>
 <dc:creator>Bouman, Charles A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>94A08, 68U10</dc:subject>
 <dc:description>  Regularized inversion methods for image reconstruction are used widely due to
their tractability and their ability to combine physical sensor models with
useful regularity criteria. Such methods were used in the recently developed
Plug-and-Play prior method, which provides a framework to use advanced
denoisers as regularizers in inversion. However, the need to formulate
regularized inversion as the solution to an optimization problem limits the
expressiveness of possible regularity conditions and the variety of provably
convergent Plug-and-Play denoising operators.
  In this paper, we introduce the idea of Consensus Equilibrium (CE), which
generalizes regularized inversion to include a wide variety of regularity
operators without the need for an optimization formulation. CE is based on the
solution of a set of equilibrium equations that balance data fit and
regularity. In CE, the problem of MAP estimation in regularized inversion is
replaced by the problem of solving these equations, which can be approached in
multiple ways.
  The key contribution of CE is to provide a novel framework for fusing a wide
variety of regularizing operators with physical sensor models, even for models
and operators that are not expressible via optimization. We describe the
derivation of the CE equations and prove that the solution of the CE equations
generalizes the standard MAP estimate.
  We also discuss algorithms for solving the CE equations, including a version
of the Douglas-Rachford (DR)/ADMM algorithm with a novel form of
preconditioning and Newton's method, both standard form and a Jacobian-free
form. We illustrate the idea of consensus equilibrium on several examples, one
using an array of convolutional neural network denoisers, none of which is
tuned to match the noise level in a noisy image but which in consensus can
achieve a better result than any of them individually.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-12-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08987</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Dual Graph Shift Operator: Identifying the Support of the Frequency
  Domain</dc:title>
 <dc:creator>Leus, Geert</dc:creator>
 <dc:creator>Segarra, Santiago</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:creator>Marques, Antonio G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Contemporary data is often supported by an irregular structure, which can be
conveniently captured by a graph. Accounting for this graph support is crucial
to analyze the data, leading to an area known as graph signal processing (GSP).
The two most important tools in GSP are the graph shift operator (GSO), which
is a sparse matrix accounting for the topology of the graph, and the graph
Fourier transform (GFT), which maps graph signals into a frequency domain
spanned by a number of graph-related Fourier-like basis vectors. This
alternative representation of a graph signal is denominated the graph frequency
signal. Several attempts have been undertaken in order to interpret the support
of this graph frequency signal, but they all resulted in a one-dimensional
interpretation. However, if the support of the original signal is captured by a
graph, why would the graph frequency signal have a simple one-dimensional
support? That is why, for the first time, we propose an irregular support for
the graph frequency signal, which we coin the dual graph. The dual GSO leads to
a better interpretation of the graph frequency signal and its domain, helps to
understand how the different graph frequencies are related and clustered,
enables the development of better graph filters and filter banks, and
facilitates the generalization of classical SP results to the graph domain.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08987</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08991</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation and Convergence Properties of Generative Adversarial
  Learning</dc:title>
 <dc:creator>Liu, Shuang</dc:creator>
 <dc:creator>Bousquet, Olivier</dc:creator>
 <dc:creator>Chaudhuri, Kamalika</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GAN) approximate a target data distribution
by jointly optimizing an objective function through a &quot;two-player game&quot; between
a generator and a discriminator. Despite their empirical success, however, two
very basic questions on how well they can approximate the target distribution
remain unanswered. First, it is not known how restricting the discriminator
family affects the approximation quality. Second, while a number of different
objective functions have been proposed, we do not understand when convergence
to the global minima of the objective function leads to convergence to the
target distribution under various notions of distributional convergence.
  In this paper, we address these questions in a broad and unified setting by
defining a notion of adversarial divergences that includes a number of recently
proposed objective functions. We show that if the objective function is an
adversarial divergence with some additional conditions, then using a restricted
discriminator family has a moment-matching effect. Additionally, we show that
for objective functions that are strict adversarial divergences, convergence in
the objective function implies weak convergence, thus generalizing previous
results.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08992</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Matroids Hitting Sets and Unsupervised Dependency Grammar Induction</dc:title>
 <dc:creator>Harvey, Nicholas</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Karger, David</dc:creator>
 <dc:creator>Savova, Virginia</dc:creator>
 <dc:creator>Peshkin, Leonid</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  This paper formulates a novel problem on graphs: find the minimal subset of
edges in a fully connected graph, such that the resulting graph contains all
spanning trees for a set of specifed sub-graphs. This formulation is motivated
by an un-supervised grammar induction problem from computational linguistics.
We present a reduction to some known problems and algorithms from graph theory,
provide computational complexity results, and describe an approximation
algorithm.
</dc:description>
 <dc:description>Comment: 11 pages 4 figures</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-07-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08994</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Privacy of the Opal Data Release: A Response</dc:title>
 <dc:creator>Asghar, Hassan Jameel</dc:creator>
 <dc:creator>Tyler, Paul</dc:creator>
 <dc:creator>Kaafar, Mohamed Ali</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This document is a response to a report from the University of Melbourne on
the privacy of the Opal dataset release. The Opal dataset was released by
Data61 (CSIRO) in conjunction with the Transport for New South Wales (TfNSW).
The data consists of two separate weeks of &quot;tap-on/tap-off&quot; data of individuals
who used any of the four different modes of public transport from TfNSW: buses,
light rail, train and ferries. These taps are recorded through the smart
ticketing system, known as Opal, available in the state of New South Wales,
Australia.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08996</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Experimental Platform for Multi-spacecraft Phase-Array Communications</dc:title>
 <dc:creator>Ravindran, Aaditya</dc:creator>
 <dc:creator>Nallapu, Ravi Teja</dc:creator>
 <dc:creator>Warren, Andrew</dc:creator>
 <dc:creator>Babuscia, Alessandra</dc:creator>
 <dc:creator>Vazco, Jose</dc:creator>
 <dc:creator>Thangavelautham, Jekan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The emergence of small satellites and CubeSats for interplanetary exploration
will mean hundreds if not thousands of spacecraft exploring every corner of the
solar-system. Current methods for communication and tracking of deep space
probes use ground based systems such as the Deep Space Network (DSN). However,
the increased communication demand will require radically new methods to ease
communication congestion. Networks of communication relay satellites located at
strategic locations such as geostationary orbit and Lagrange points are
potential solutions. Instead of one large communication relay satellite, we
could have scores of small satellites that utilize phase arrays to effectively
operate as one large satellite. Excess payload capacity on rockets can be used
to warehouse more small satellites in the communication network. The advantage
of this network is that even if one or a few of the satellites are damaged or
destroyed, the network still operates but with degraded performance. The
satellite network would operate in a distributed architecture and some
satellites maybe dynamically repurposed to split and communicate with multiple
targets at once. The potential for this alternate communication architecture is
significant, but this requires development of satellite formation flying and
networking technologies. Our research has found neural-network control
approaches such as the Artificial Neural Tissue can be effectively used to
control multirobot/multi-spacecraft systems and can produce human competitive
controllers. We have been developing a laboratory experiment platform called
Athena to develop critical spacecraft control algorithms and cognitive
communication methods. We briefly report on the development of the platform and
our plans to gain insight into communication phase arrays for space.
</dc:description>
 <dc:description>Comment: 4 pages, 10 figures, IEEE Cognitive Communications for Aerospace
  Applications Workshop</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.08997</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>State Space Decomposition and Subgoal Creation for Transfer in Deep
  Reinforcement Learning</dc:title>
 <dc:creator>Sahni, Himanshu</dc:creator>
 <dc:creator>Kumar, Saurabh</dc:creator>
 <dc:creator>Tejani, Farhan</dc:creator>
 <dc:creator>Schroecker, Yannick</dc:creator>
 <dc:creator>Isbell, Charles</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Typical reinforcement learning (RL) agents learn to complete tasks specified
by reward functions tailored to their domain. As such, the policies they learn
do not generalize even to similar domains. To address this issue, we develop a
framework through which a deep RL agent learns to generalize policies from
smaller, simpler domains to more complex ones using a recurrent attention
mechanism. The task is presented to the agent as an image and an instruction
specifying the goal. This meta-controller guides the agent towards its goal by
designing a sequence of smaller subtasks on the part of the state space within
the attention, effectively decomposing it. As a baseline, we consider a setup
without attention as well. Our experiments show that the meta-controller learns
to create subgoals within the attention.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures; 3rd Multidisciplinary Conference on Reinforcement
  Learning and Decision Making (RLDM 2017), Ann Arbor, Michigan</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.08997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09003</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extraction and Classification of Diving Clips from Continuous Video
  Footage</dc:title>
 <dc:creator>Nibali, Aiden</dc:creator>
 <dc:creator>He, Zhen</dc:creator>
 <dc:creator>Morgan, Stuart</dc:creator>
 <dc:creator>Greenwood, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to recent advances in technology, the recording and analysis of video
data has become an increasingly common component of athlete training
programmes. Today it is incredibly easy and affordable to set up a fixed camera
and record athletes in a wide range of sports, such as diving, gymnastics,
golf, tennis, etc. However, the manual analysis of the obtained footage is a
time-consuming task which involves isolating actions of interest and
categorizing them using domain-specific knowledge. In order to automate this
kind of task, three challenging sub-problems are often encountered: 1)
temporally cropping events/actions of interest from continuous video; 2)
tracking the object of interest; and 3) classifying the events/actions of
interest.
  Most previous work has focused on solving just one of the above sub-problems
in isolation. In contrast, this paper provides a complete solution to the
overall action monitoring task in the context of a challenging real-world
exemplar. Specifically, we address the problem of diving classification. This
is a challenging problem since the person (diver) of interest typically
occupies fewer than 1% of the pixels in each frame. The model is required to
learn the temporal boundaries of a dive, even though other divers and
bystanders may be in view. Finally, the model must be sensitive to subtle
changes in body pose over a large number of frames to determine the
classification code. We provide effective solutions to each of the sub-problems
which combine to provide a highly functional solution to the task as a whole.
The techniques proposed can be easily generalized to video footage recorded
from other sports.
</dc:description>
 <dc:description>Comment: To appear at CVsports 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09011</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Principled Hybrids of Generative and Discriminative Domain Adaptation</dc:title>
 <dc:creator>Zhao, Han</dc:creator>
 <dc:creator>Zhu, Zhenyao</dc:creator>
 <dc:creator>Hu, Junjie</dc:creator>
 <dc:creator>Coates, Adam</dc:creator>
 <dc:creator>Gordon, Geoff</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a probabilistic framework for domain adaptation that blends both
generative and discriminative modeling in a principled way. Under this
framework, generative and discriminative models correspond to specific choices
of the prior over parameters. This provides us a very general way to
interpolate between generative and discriminative extremes through different
choices of priors. By maximizing both the marginal and the conditional
log-likelihoods, models derived from this framework can use both labeled
instances from the source domain as well as unlabeled instances from both
source and target domains. Under this framework, we show that the popular
reconstruction loss of autoencoder corresponds to an upper bound of the
negative marginal log-likelihoods of unlabeled instances, where marginal
distributions are given by proper kernel density estimations. This provides a
way to interpret the empirical success of autoencoders in domain adaptation and
semi-supervised learning. We instantiate our framework using neural networks,
and build a concrete model, DAuto. Empirically, we demonstrate the
effectiveness of DAuto on text, image and speech datasets, showing that it
outperforms related competitors when domain adaptation is possible.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09014</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The tessellation problem of quantum walks</dc:title>
 <dc:creator>Abreu, A.</dc:creator>
 <dc:creator>Cunha, L.</dc:creator>
 <dc:creator>Fernandes, T.</dc:creator>
 <dc:creator>de Figueiredo, C.</dc:creator>
 <dc:creator>Kowada, L.</dc:creator>
 <dc:creator>Marquezino, F.</dc:creator>
 <dc:creator>Posner, D.</dc:creator>
 <dc:creator>Portugal, R.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Quantum walks have received a great deal of attention recently because they
can be used to develop new quantum algorithms and to simulate interesting
quantum systems. In this work, we focus on a model called staggered quantum
walk, which employs advanced ideas of graph theory and has the advantage of
including the most important instances of other discrete-time models. The
evolution operator of the staggered model is obtained from a tessellation
cover, which is defined in terms of a set of partitions of the graph into
cliques. It is important to establish the minimum number of tessellations
required in a tessellation cover, and what classes of graphs admit a small
number of tessellations. We describe two main results: (1) infinite classes of
graphs where we relate the chromatic number of the clique graph to the minimum
number of tessellations required in a tessellation cover, and (2) the problem
of deciding whether a graph is $k$-tessellable for $k\ge 3$ is NP-complete.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figs</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09015</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Democracy Models and Civic Technologies: Tensions, Trilemmas, and
  Trade-offs</dc:title>
 <dc:creator>Poblet, Marta</dc:creator>
 <dc:creator>Plaza, Enric</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  This paper aims at connecting democratic theory with civic technologies in
order to highlight the links between some theoretical tensions and trilemmas
and design trade-offs. First, it reviews some tensions and trilemmas raised by
political philosophers and democratic theorists. Second, it considers both the
role and the limitations of civic technologies in mitigating these tensions and
trilemmas. Third, it proposes to adopt a meso-level approach, in between the
macro-level of democratic theories and the micro-level of tools, to situate the
interplay between people, digital technologies, and data.
</dc:description>
 <dc:description>Comment: Workshop on 'Linked Democracy: AI for Democratic Innovation'
  (IJCAI2017), Melbourne, August 19, 2017</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09021</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Pour</dc:title>
 <dc:creator>Huang, Yongqiang</dc:creator>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Pouring is a simple task people perform daily. It is the second most
frequently executed motion in cooking scenarios, after pick-and-place. We
present a pouring trajectory generation approach, which uses force feedback
from the cup to determine the future velocity of pouring. The approach uses
recurrent neural networks as its building blocks. We collected the pouring
demonstrations which we used for training. To test our approach in simulation,
we also created and trained a force estimation system. The simulated
experiments show that the system is able to generalize to single unseen element
of the pouring characteristics.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09024</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>UAV-Aided Cellular Offloading: A Potential Solution to Hot-Spot Issue in
  5G</dc:title>
 <dc:creator>Lyu, Jiangbin</dc:creator>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In conventional terrestrial cellular networks, mobile terminals (MTs) at the
cell edge often pose the performance bottleneck due to their long distances
from the serving ground base station (GBS), especially in hotspot period when
the GBS is heavily loaded. This paper proposes a new hybrid network
architecture by leveraging the use of unmanned aerial vehicle (UAV) as an
aerial mobile base station, which flies cyclically along the cell edge to serve
the cell-edge MTs and help offload data traffic from the GBS. We aim to
maximize the minimum throughput of all MTs in the cell, by jointly optimizing
the UAV's trajectory, as well as the bandwidth allocation and user partitioning
between the UAV and GBS. We first consider orthogonal spectrum sharing between
the UAV and GBS, and then extend to the spectrum reuse case where the total
bandwidth is used by both the GBS and UAV with their mutual interference
effectively avoided. Numerical results show that the proposed hybrid network
with optimized spectrum sharing and cyclical multiple access design
significantly improves the spatial throughput over the conventional GBS-only
network; while the spectrum reuse scheme can provide further throughput gains
compared to orthogonal spectrum sharing, at the cost of more complexity for
interference control.
</dc:description>
 <dc:description>Comment: 25 pages, 6 figures, submitted for possible publication</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09025</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automating the Proofs of Strengthening Lemmas in the Abella Proof
  Assistant</dc:title>
 <dc:creator>Michaelson, Dawn</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In logical reasoning, it is often the case that only some of a collection of
assumptions are needed to reach a conclusion. A strengthening lemma is an
assertion that a given conclusion is independent in this sense of a particular
assumption. Strengthening lemmas underlie many useful techniques for
simplifying proofs in automated and interactive theorem-provers. For example,
they underlie a mechanism called subordination that is useful in determining
that expressions of a particular type cannot contain objects of another type
and in thereby reducing the number of cases to be considered in proving
universally quantified statements.
  This thesis concerns the automation of the proofs of strengthening lemmas in
a specification logic called the logic of hereditary Harrop formulas (HOHH).
The Abella Proof Assistant embeds this logic in a way that allows it to prove
properties of both the logic itself and of specifications written in it.
Previous research has articulated a (conservative) algorithm for checking if a
claimed strengthening lemma is, in fact, true. We provide here an
implementation of this algorithm within the setting of Abella. Moreover, we
show how to generate an actual proof of the strengthening lemma in Abella from
the information computed by the algorithm; such a proof serves as a more
trustworthy certificate of the correctness of the lemma than the algorithm
itself. The results of this work have been incorporated into the Abella system
in the form of a &quot;tactic command&quot; that can be invoked within the interactive
theorem-prover and that will result in an elaboration of a proof of the lemma
and its incorporation into the collection of proven facts about a given
specification.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09026</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Edge Grafting for Efficient MRF Structure Learning</dc:title>
 <dc:creator>Chaabene, Walid</dc:creator>
 <dc:creator>Huang, Bert</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Incremental methods for structure learning of pairwise Markov random fields
(MRFs), such as grafting, improve scalability to large systems by avoiding
inference over the entire feature space in each optimization step. Instead,
inference is performed over an incrementally grown active set of features. In
this paper, we address the computational bottlenecks that current techniques
still suffer by introducing online edge grafting, an incremental, structured
method that activates edges as groups of features in a streaming setting. The
framework is based on reservoir sampling of edges that satisfy a necessary
activation condition, approximating the search for the optimal edge to
activate. Online edge grafting performs an informed edge search set
reorganization using search history and structure heuristics. Experiments show
a significant computational speedup for structure learning and a controllable
trade-off between the speed and the quality of learning.
</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09037</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deriving Neural Architectures from Sequence and Graph Kernels</dc:title>
 <dc:creator>Lei, Tao</dc:creator>
 <dc:creator>Jin, Wengong</dc:creator>
 <dc:creator>Barzilay, Regina</dc:creator>
 <dc:creator>Jaakkola, Tommi</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The design of neural architectures for structured objects is typically guided
by experimental insights rather than a formal process. In this work, we appeal
to kernels over combinatorial structures, such as sequences and graphs, to
derive appropriate neural operations. We introduce a class of deep recurrent
neural operations and formally characterize their associated kernel spaces. Our
recurrent modules compare the input to virtual reference objects (cf. filters
in CNN) via the kernels. Similar to traditional neural operations, these
reference objects are parameterized and directly optimized in end-to-end
training. We empirically evaluate the proposed class of neural architectures on
standard applications such as language modeling and molecular graph regression,
achieving state-of-the-art results across these applications.
</dc:description>
 <dc:description>Comment: extended version of ICML 2017 camera ready</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09042</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Program Completion</dc:title>
 <dc:creator>Lu, Yanxin</dc:creator>
 <dc:creator>Chaudhuri, Swarat</dc:creator>
 <dc:creator>Jermaine, Chris</dc:creator>
 <dc:creator>Melski, David</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We introduce program splicing, a programming methodology that aims to
automate the commonly used workflow of copying, pasting, and modifying code
available online. Here, the programmer starts by writing a &quot;draft&quot; that mixes
unfinished code, natural language comments, and correctness requirements in the
form of test cases or API call sequence constraints. A program synthesizer that
interacts with a large, searchable database of program snippets is used to
automatically complete the draft into a program that meets the requirements.
The synthesis process happens in two stages. First, the synthesizer identifies
a small number of programs in the database that are relevant to the synthesis
task. Next it uses an enumerative search to systematically fill the draft with
expressions and statements from these relevant programs. The resulting program
is returned to the programmer, who can modify it and possibly invoke additional
rounds of synthesis.
  We present an implementation of program splicing for the Java programming
language. The implementation uses a corpus of over 3.5 million procedures from
an open-source software repository. Our evaluation uses the system in a suite
of everyday programming tasks, and includes a comparison with a
state-of-the-art competing approach as well as a user study. The results point
to the broad scope and scalability of program splicing and indicate that the
approach can significantly boost programmer productivity.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09043</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Massive MIMO Multi-Pair Two-Way AF Relaying: Energy
  Efficiency Optimization</dc:title>
 <dc:creator>Sharma, Ekant</dc:creator>
 <dc:creator>Budhiraja, Rohit</dc:creator>
 <dc:creator>Vasudevan, K</dc:creator>
 <dc:creator>Hanzo, Lajos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider two-way amplify and forward relaying, where multiple full-duplex
user pairs exchange information via a shared full-duplex massive multiple-input
multiple-output (MIMO) relay. Most of the previous massive MIMO relaying works
maximize the spectral efficiency (SE). By contrast, we maximize the non-convex
energy efficiency (EE) metric by approximating it as a pseudo-concave problem,
which is then solved using the classic Dinkelbach approach. We also maximize
the EE of the least energy-efficient user {relying} on the max-min approach.
For solving these optimization problems, we derive closed-form lower bounds for
the ergodic achievable rate both for maximal-ratio combining and zero-forcing
processing at the relay, by using minimum mean squared error channel
estimation. We numerically characterize the accuracy of the lower bounds
derived. We also compare the SE and EE of the proposed design to those of the
existing full-duplex systems and quantify the significant improvement achieved
by the proposed algorithm. We also compare the EE of the proposed full-duplex
system to that of its half-duplex counterparts, and characterize the self-loop
and inter-user interference regimes, for which the proposed full-duplex system
succeeds in outperforming the half-duplex ones.
</dc:description>
 <dc:description>Comment: 30 pages, Updated paper</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09044</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Malignant TLS Servers Using Machine Learning Techniques</dc:title>
 <dc:creator>Bagaria, Sankalp</dc:creator>
 <dc:creator>Balaji, R.</dc:creator>
 <dc:creator>Bindhumadhava, B. S.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  TLS uses X.509 certificates for server authentication. A X.509 certificate is
a complex document and various innocent errors may occur while creating/ using
it. Also, many certificates belong to malicious websites and should be rejected
by the client and those web servers should not be visited. Usually, when a
client finds a certificate that is doubtful using the traditional tests, it
asks for human intervention. But, looking at certificates, most people can't
differentiate between malicious and non-malicious websites. Thus, once
traditional certificate validation has failed, instead of asking for human
intervention, we use machine learning techniques to enable a web browser to
decide whether the server to which the certificate belongs to is malignant or
not ie, whether the website should be visited or not.
  Once a certificate has been accepted in the above phase, we observe that the
website may still turn out to be malicious. So, in the second phase, we
download a part of the website in a sandbox without decrypting it and observe
the TLS encrypted traffic (encrypted malicious data captured in a sandbox
cannot harm the system). As the traffic is encrypted after Handshake is
completed, traditional pattern-matching techniques cannot be employed. Thus we
use flow features of the traffic along with the features used in the above
first phase. We couple these features with the unencrypted TLS header
information obtained during TLS Handshake and use these in a machine learning
classifier to identify whether the traffic is malicious or not.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09045</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cross-Domain Perceptual Reward Functions</dc:title>
 <dc:creator>Edwards, Ashley D.</dc:creator>
 <dc:creator>Sood, Srijan</dc:creator>
 <dc:creator>Isbell Jr, Charles L.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In reinforcement learning, we often define goals by specifying rewards within
desirable states. One problem with this approach is that we typically need to
redefine the rewards each time the goal changes, which often requires some
understanding of the solution in the agents environment. When humans are
learning to complete tasks, we regularly utilize alternative sources that guide
our understanding of the problem. Such task representations allow one to
specify goals on their own terms, thus providing specifications that can be
appropriately interpreted across various environments. This motivates our own
work, in which we represent goals in environments that are different from the
agents. We introduce Cross-Domain Perceptual Reward (CDPR) functions, learned
rewards that represent the visual similarity between an agents state and a
cross-domain goal image. We report results for learning the CDPRs with a deep
neural network and using them to solve two tasks with deep reinforcement
learning.
</dc:description>
 <dc:description>Comment: A shorter version of this paper was accepted to RLDM
  (http://rldm.org/rldm2017/)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09050</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Clustering-based Consistency Adaptation Strategy for Distributed SDN
  Controllers</dc:title>
 <dc:creator>Aslan, Mohamed</dc:creator>
 <dc:creator>Matrawy, Ashraf</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Distributed controllers are oftentimes used in large-scale SDN deployments
where they run a myriad of network applications simultaneously. Such
applications could have different consistency and availability preferences.
These controllers need to communicate via east/west interfaces in order to
synchronize their state information. The consistency and the availability of
the distributed state information are governed by an underlying consistency
model. Earlier, we suggested the use of adaptively-consistent controllers that
can autonomously tune their consistency parameters in order to meet the
performance requirements of a certain application. In this paper, we examine
the feasibility of employing adaptive controllers that are built on-top of
tunable consistency models similar to that of Apache Cassandra. We present an
adaptation strategy that uses clustering techniques (sequential k-means and
incremental k-means) in order to map a given application performance indicator
into a feasible consistency level that can be used with the underlying tunable
consistency model. In the cases that we modeled and tested, our results show
that in the case of sequential k-means, with a reasonable number of clusters
(&gt;= 50), a plausible mapping (low RMSE) could be estimated between the
application performance indicators and the consistency level indicator. In the
case of incremental k-means, the results also showed that a plausible mapping
(low RMSE) could be estimated using a similar number of clusters (&gt;= 50) by
using a small threshold (~$ 0.01).
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09052</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Supervised Semantic Segmentation Based on Web Image
  Co-segmentation</dc:title>
 <dc:creator>Shen, Tong</dc:creator>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Reid, Ian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Training a Fully Convolutional Network (FCN) for semantic segmentation
requires a large number of masks with pixel level labelling, which involves a
large amount of human labour and time for annotation. In contrast, web images
and their image-level labels are much easier and cheaper to obtain. In this
work, we propose a novel method for weakly supervised semantic segmentation
with only image-level labels. The method utilizes the internet to retrieve a
large number of images and uses a large scale co-segmentation framework to
generate masks for the retrieved images. We first retrieve images from search
engines, e.g. Flickr and Google, using semantic class names as queries, e.g.
class names in the dataset PASCAL VOC 2012. We then use high quality masks
produced by co-segmentation on the retrieved images as well as the target
dataset images with image level labels to train segmentation networks. We
obtain an IoU score of 56.9 on test set of PASCAL VOC 2012, which reaches the
state-of-the-art performance.
</dc:description>
 <dc:description>Comment: BMVC</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-08-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09054</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max-Cosine Matching Based Neural Models for Recognizing Textual
  Entailment</dc:title>
 <dc:creator>Xie, Zhipeng</dc:creator>
 <dc:creator>Hu, Junfeng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recognizing textual entailment is a fundamental task in a variety of text
mining or natural language processing applications. This paper proposes a
simple neural model for RTE problem. It first matches each word in the
hypothesis with its most-similar word in the premise, producing an augmented
representation of the hypothesis conditioned on the premise as a sequence of
word pairs. The LSTM model is then used to model this augmented sequence, and
the final output from the LSTM is fed into a softmax layer to make the
prediction. Besides the base model, in order to enhance its performance, we
also proposed three techniques: the integration of multiple word-embedding
library, bi-way integration, and ensemble based on model averaging.
Experimental results on the SNLI dataset have shown that the three techniques
are effective in boosting the predicative accuracy and that our method
outperforms several state-of-the-state ones.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09054</dc:identifier>
 <dc:identifier>DASFAA (1) 2017: 295-308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09055</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The cost of fairness in classification</dc:title>
 <dc:creator>Menon, Aditya Krishna</dc:creator>
 <dc:creator>Williamson, Robert C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of learning classifiers with a fairness constraint, with
three main contributions towards the goal of quantifying the problem's inherent
tradeoffs. First, we relate two existing fairness measures to cost-sensitive
risks. Second, we show that for cost-sensitive classification and fairness
measures, the optimal classifier is an instance-dependent thresholding of the
class-probability function. Third, we show how the tradeoff between accuracy
and fairness is determined by the alignment between the class-probabilities for
the target and sensitive features. Underpinning our analysis is a general
framework that casts the problem of learning with a fairness requirement as one
of minimising the difference of two statistical risks.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09056</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Decentralized Algorithms Outperform Centralized Algorithms? A Case
  Study for Decentralized Parallel Stochastic Gradient Descent</dc:title>
 <dc:creator>Lian, Xiangru</dc:creator>
 <dc:creator>Zhang, Ce</dc:creator>
 <dc:creator>Zhang, Huan</dc:creator>
 <dc:creator>Hsieh, Cho-Jui</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Liu, Ji</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most distributed machine learning systems nowadays, including TensorFlow and
CNTK, are built in a centralized fashion. One bottleneck of centralized
algorithms lies on high communication cost on the central node. Motivated by
this, we ask, can decentralized algorithms be faster than its centralized
counterpart?
  Although decentralized PSGD (D-PSGD) algorithms have been studied by the
control community, existing analysis and theory do not show any advantage over
centralized PSGD (C-PSGD) algorithms, simply assuming the application scenario
where only the decentralized network is available. In this paper, we study a
D-PSGD algorithm and provide the first theoretical analysis that indicates a
regime in which decentralized algorithms might outperform centralized
algorithms for distributed stochastic gradient descent. This is because D-PSGD
has comparable total computational complexities to C-PSGD but requires much
less communication cost on the busiest node. We further conduct an empirical
study to validate our theoretical analysis across multiple frameworks (CNTK and
Torch), different network configurations, and computation platforms up to 112
GPUs. On network configurations with low bandwidth or high latency, D-PSGD can
be up to one order of magnitude faster than its well-optimized centralized
counterparts.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09058</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Empirical Analysis of Approximation Algorithms for the Euclidean
  Traveling Salesman Problem</dc:title>
 <dc:creator>He, Yihui</dc:creator>
 <dc:creator>Xiang, Ming</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  With applications to many disciplines, the traveling salesman problem (TSP)
is a classical computer science optimization problem with applications to
industrial engineering, theoretical computer science, bioinformatics, and
several other disciplines. In recent years, there have been a plethora of novel
approaches for approximate solutions ranging from simplistic greedy to
cooperative distributed algorithms derived from artificial intelligence. In
this paper, we perform an evaluation and analysis of cornerstone algorithms for
the Euclidean TSP. We evaluate greedy, 2-opt, and genetic algorithms. We use
several datasets as input for the algorithms including a small dataset, a
mediumsized dataset representing cities in the United States, and a synthetic
dataset consisting of 200 cities to test algorithm scalability. We discover
that the greedy and 2-opt algorithms efficiently calculate solutions for
smaller datasets. Genetic algorithm has the best performance for optimality for
medium to large datasets, but generally have longer runtime. Our
implementations is public available.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09061</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triangle Finding and Listing in CONGEST Networks</dc:title>
 <dc:creator>Izumi, Taisuke</dc:creator>
 <dc:creator>Gall, Fran&#xe7;ois Le</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Triangle-free graphs play a central role in graph theory, and triangle
detection (or triangle finding) as well as triangle enumeration (triangle
listing) play central roles in the field of graph algorithms. In distributed
computing, algorithms with sublinear round complexity for triangle finding and
listing have recently been developed in the powerful CONGEST clique model,
where communication is allowed between any two nodes of the network. In this
paper we present the first algorithms with sublinear complexity for triangle
finding and triangle listing in the standard CONGEST model, where the
communication topology is the same as the topology of the network. More
precisely, we give randomized algorithms for triangle finding and listing with
round complexity $O(n^{2/3}(\log n)^{2/3})$ and $O(n^{3/4}\log n)$,
respectively, where $n$ denotes the number of nodes of the network. We also
show a lower bound $\Omega(n^{1/3}/\log n)$ on the round complexity of triangle
listing, which also holds for the CONGEST clique model.
</dc:description>
 <dc:description>Comment: To appear in PODC 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09064</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MagNet: a Two-Pronged Defense against Adversarial Examples</dc:title>
 <dc:creator>Meng, Dongyu</dc:creator>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning has shown promising results on hard perceptual problems in
recent years. However, deep learning systems are found to be vulnerable to
small adversarial perturbations that are nearly imperceptible to human. Such
specially crafted perturbations cause deep learning systems to output incorrect
decisions, with potentially disastrous consequences. These vulnerabilities
hinder the deployment of deep learning systems where safety or security is
important. Attempts to secure deep learning systems either target specific
attacks or have been shown to be ineffective.
  In this paper, we propose MagNet, a framework for defending neural network
classifiers against adversarial examples. MagNet does not modify the protected
classifier or know the process for generating adversarial examples. MagNet
includes one or more separate detector networks and a reformer network.
Different from previous work, MagNet learns to differentiate between normal and
adversarial examples by approximating the manifold of normal examples. Since it
does not rely on any process for generating adversarial examples, it has
substantial generalization power. Moreover, MagNet reconstructs adversarial
examples by moving them towards the manifold, which is effective for helping
classify adversarial examples with small perturbation correctly. We discuss the
intrinsic difficulty in defending against whitebox attack and propose a
mechanism to defend against graybox attack. Inspired by the use of randomness
in cryptography, we propose to use diversity to strengthen MagNet. We show
empirically that MagNet is effective against most advanced state-of-the-art
attacks in blackbox and graybox scenarios while keeping false positive rate on
normal examples very low.
</dc:description>
 <dc:description>Comment: Accepted at the ACM Conference on Computer and Communications
  Security (CCS), 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-09-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09073</identifier>
 <datestamp>2017-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Load Balancing for Skewed Streams on Heterogeneous Cluster</dc:title>
 <dc:creator>Nasir, Muhammad Anis Uddin</dc:creator>
 <dc:creator>Horii, Hiroshi</dc:creator>
 <dc:creator>Serafini, Marco</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:creator>Raymond, Rudy</dc:creator>
 <dc:creator>Girdzijauskas, Sarunas</dc:creator>
 <dc:creator>Osogami, Takayuki</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Streaming applications frequently encounter skewed workloads and execute on
heterogeneous clusters. Optimal resource utilization in such adverse conditions
becomes a challenge, as it requires inferring the resource capacities and input
distribution at run time. In this paper, we tackle the aforementioned
challenges by modeling them as a load balancing problem. We propose a novel
partitioning strategy called Consistent Grouping (CG), which enables each
processing element instance (PEI) to process the workload according to its
capacity. The main idea behind CG is the notion of small, equal-sized virtual
workers at the sources, which are assigned to workers based on their
capacities. We provide a theoretical analysis of the proposed algorithm and
show via extensive empirical evaluation that our proposed scheme outperforms
the state-of-the-art approaches, like key grouping. In particular, CG achieves
3.44x better performance in terms of latency compared to key grouping.
</dc:description>
 <dc:description>Comment: 12 pages, under submission</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09076</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Powered Communications with Finite Battery and Finite
  Blocklength</dc:title>
 <dc:creator>L&#xf3;pez, Onel L. A.</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Evelio M. G.</dc:creator>
 <dc:creator>Souza, R. D.</dc:creator>
 <dc:creator>Alves, H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We analyze a wireless communication system with finite block length and
finite battery energy, under quasi-static Nakagami-m fading. Wireless energy
transfer is carried out in the downlink while information transfer occurs in
the uplink. Transmission strategies for scenarios with/without energy
accumulation between transmission rounds are characterized in terms of error
probability and energy consumption. A power control protocol for the energy
accumulation scenario is proposed and results show the enormous impact on
improving the system performance, in terms of error probability and energy
consumption. The numerical results corroborate the existence and uniqueness of
an optimum target error probability, while showing that a relatively small
battery could be a limiting factor for some setups, specially when using the
energy accumulation strategy.
</dc:description>
 <dc:description>Comment: 32 pages, 9 main figures, Accepted for publication IEEE Trans. Commun</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-12-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09087</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Fan Behavior to Study Para Social Breakups</dc:title>
 <dc:creator>Garimella, Kiran</dc:creator>
 <dc:creator>Cohen, Jonathan</dc:creator>
 <dc:creator>Weber, Ingmar</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Celebrity and fandom have been studied extensively in real life. However,
with more and more celebrities using social media, the dynamics of interaction
between celebrities and fans has changed. Using data from a set of 57,000 fans
for the top followed celebrities on Twitter, we define a wide range of features
based on their Twitter activity. Using factor analysis we find the most
important factors that underlie fan behavior. Using these factors, we conduct
analysis on (i) understanding fan behavior by gender \&amp; age, and (ii)
para-social breakup behavior. We find that (i) fandom is a social phenomenon,
(ii) female fans are often more devoted and younger fans are more active &amp;
social, and (iii) the most devoted fans are more likely to be involved in a
para-social breakup. Our findings confirm existing research on para-social
interactions. Given the scale of our study and dependence on non-reactive data,
our paper opens new avenues for research in para-social interactions.
</dc:description>
 <dc:description>Comment: Accepted as a poster at WebSci 2017. This is a longer version of the
  2-page poster published at WebSci</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09093</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher-Order Operator Precedence Languages</dc:title>
 <dc:creator>Reghizzi, Stefano Crespi</dc:creator>
 <dc:creator>Pradella, Matteo</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Floyd's Operator Precedence (OP) languages are a deterministic context-free
family having many desirable properties. They are locally and parallely
parsable, and languages having a compatible structure are closed under Boolean
operations, concatenation and star; they properly include the family of Visibly
Pushdown (or Input Driven) languages. OP languages are based on three relations
between any two consecutive terminal symbols, which assign syntax structure to
words. We extend such relations to k-tuples of consecutive terminal symbols, by
using the model of strictly locally testable regular languages of order k at
least 3. The new corresponding class of Higher-order Operator Precedence
languages (HOP) properly includes the OP languages, and it is still included in
the deterministic (also in reverse) context free family. We prove Boolean
closure for each subfamily of structurally compatible HOP languages. In each
subfamily, the top language is called max-language. We show that such languages
are defined by a simple cancellation rule and we prove several properties, in
particular that max-languages make an infinite hierarchy ordered by parameter
k. HOP languages are a candidate for replacing OP languages in the various
applications where they have have been successful though sometimes too
restrictive.
</dc:description>
 <dc:description>Comment: In Proceedings AFL 2017, arXiv:1708.06226</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-08-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09093</dc:identifier>
 <dc:identifier>EPTCS 252, 2017, pp. 86-100</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.252.11</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09098</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Optimization of Co-Existing Underlay Secondary Networks</dc:title>
 <dc:creator>Chakraborty, Pratik</dc:creator>
 <dc:creator>Prakriya, Shankar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we analyze the throughput performance of two co-existing
downlink multiuser underlay secondary networks that use fixed-rate
transmissions. We assume that the interference temperature limit (ITL) is
apportioned to accommodate two concurrent transmissions using an interference
temperature apportioning parameter so as to ensure that the overall
interference to the primary receiver does not exceed the ITL. Using the derived
analytical expressions for throughput, when there is only one secondary user in
each network, or when the secondary networks do not employ opportunistic user
selection (use round robin scheduling for example), there exists a critical
fixed-rate below which sum throughput with co-existing secondary networks is
higher than the throughput with a single secondary network. We derive an
expression for this critical fixed-rate. Below this critical rate, we show that
careful apportioning of the ITL is critical to maximizing sum throughput of the
co-existing networks. We derive an expression for this apportioning parameter.
Throughput is seen to increase with increase in number of users in each of the
secondary networks. Computer simulations demonstrate accuracy of the derived
expressions.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09101</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobility Management as a Service for 5G Networks</dc:title>
 <dc:creator>Jain, Akshay</dc:creator>
 <dc:creator>Lopez-Aguilera, Elena</dc:creator>
 <dc:creator>Demirkol, Ilker</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>C.2.5</dc:subject>
 <dc:description>  Mobility Management (MM) techniques have conventionally been centralized in
nature, wherein a single network entity has been responsible for handling the
mobility related tasks of the mobile nodes attached to the network. However, an
exponential growth in network traffic and the number of users has ushered in
the concept of providing Mobility Management as a Service (MMaaS) to the
wireless nodes attached to the 5G networks. Allowing for on-demand mobility
management solutions will not only provide the network with the flexibility
that it needs to accommodate the many different use cases that are to be served
by future networks, but it will also provide the network with the scalability
that is needed alongside the flexibility to serve future networks. And hence,
in this paper, a detailed study of MMaaS has been provided, highlighting its
benefits and challenges for 5G networks. Additionally, the very important
property of granularity of service which is deeply intertwined with the
scalability and flexibility requirements of the future wireless networks, and a
consequence of MMaaS, has also been discussed in detail.
</dc:description>
 <dc:description>Comment: Submitted to 14th International Symposium on Wireless Communication
  Systems</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09107</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLAM based Quasi Dense Reconstruction For Minimally Invasive Surgery
  Scenes</dc:title>
 <dc:creator>Mahmoud, Nader</dc:creator>
 <dc:creator>Hostettler, Alexandre</dc:creator>
 <dc:creator>Collins, Toby</dc:creator>
 <dc:creator>Soler, Luc</dc:creator>
 <dc:creator>Doignon, Christophe</dc:creator>
 <dc:creator>Montiel, J. M. M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recovering surgical scene structure in laparoscope surgery is crucial step
for surgical guidance and augmented reality applications. In this paper, a
quasi dense reconstruction algorithm of surgical scene is proposed. This is
based on a state-of-the-art SLAM system, and is exploiting the initial
exploration phase that is typically performed by the surgeon at the beginning
of the surgery. We show how to convert the sparse SLAM map to a quasi dense
scene reconstruction, using pairs of keyframe images and correlation-based
featureless patch matching. We have validated the approach with a live porcine
experiment using Computed Tomography as ground truth, yielding a Root Mean
Squared Error of 4.9mm.
</dc:description>
 <dc:description>Comment: ICRA 2017 workshop C4 Surgical Robots: Compliant, Continuum,
  Cognitive, and Collaborative</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09132</identifier>
 <datestamp>2018-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First-spike based visual categorization using reward-modulated STDP</dc:title>
 <dc:creator>Mozafari, Milad</dc:creator>
 <dc:creator>Kheradpisheh, Saeed Reza</dc:creator>
 <dc:creator>Masquelier, Timoth&#xe9;e</dc:creator>
 <dc:creator>Nowzari-Dalini, Abbas</dc:creator>
 <dc:creator>Ganjtabesh, Mohammad</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reinforcement learning (RL) has recently regained popularity, with major
achievements such as beating the European game of Go champion. Here, for the
first time, we show that RL can be used efficiently to train a spiking neural
network (SNN) to perform object recognition in natural images without using an
external classifier. We used a feedforward convolutional SNN and a temporal
coding scheme where the most strongly activated neurons fire first, while less
activated ones fire later, or not at all. In the highest layers, each neuron
was assigned to an object category, and it was assumed that the stimulus
category was the category of the first neuron to fire. If this assumption was
correct, the neuron was rewarded, i.e. spike-timing-dependent plasticity (STDP)
was applied, which reinforced the neuron's selectivity. Otherwise, anti-STDP
was applied, which encouraged the neuron to learn something else. As
demonstrated on various image datasets (Caltech, ETH-80, and NORB), this reward
modulated STDP (R-STDP) approach extracted particularly discriminative visual
features, whereas classic unsupervised STDP extracts any feature that
consistently repeats. As a result, R-STDP outperformed STDP on these datasets.
Furthermore, R-STDP is suitable for online learning, and can adapt to drastic
changes such as label permutations. Finally, it is worth mentioning that both
feature extraction and classification were done with spikes, using at most one
spike per neuron. Thus the network is hardware friendly and energy efficient.
</dc:description>
 <dc:description>Comment: supplementary materials are added, Caltech face/motorbike
  demonstration figure is updated, some parts of the main manuscript are moved
  to the supplementary materials, additional network analysis and performance
  comparison with deep nets are added</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2018-01-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09137</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Decomposition of Time-Series Data for Effective Generalization</dc:title>
 <dc:creator>Godfrey, Luke B.</dc:creator>
 <dc:creator>Gashler, Michael S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present a neural network technique for the analysis and extrapolation of
time-series data called Neural Decomposition (ND). Units with a sinusoidal
activation function are used to perform a Fourier-like decomposition of
training samples into a sum of sinusoids, augmented by units with nonperiodic
activation functions to capture linear trends and other nonperiodic components.
We show how careful weight initialization can be combined with regularization
to form a simple model that generalizes well. Our method generalizes
effectively on the Mackey-Glass series, a dataset of unemployment rates as
reported by the U.S. Department of Labor Statistics, a time-series of monthly
international airline passengers, the monthly ozone concentration in downtown
Los Angeles, and an unevenly sampled time-series of oxygen isotope measurements
from a cave in north India. We find that ND outperforms popular time-series
forecasting techniques including LSTM, echo state networks, ARIMA, SARIMA, SVR
with a radial basis function, and Gashler and Ashmore's model.
</dc:description>
 <dc:description>Comment: 13 pages, 11 figures, IEEE TNNLS Preprint</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09137</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2017.2709324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09142</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep image representations using caption generators</dc:title>
 <dc:creator>Mopuri, Konda Reddy</dc:creator>
 <dc:creator>Athreya, Vishal B.</dc:creator>
 <dc:creator>Babu, R. Venkatesh</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep learning exploits large volumes of labeled data to learn powerful
models. When the target dataset is small, it is a common practice to perform
transfer learning using pre-trained models to learn new task specific
representations. However, pre-trained CNNs for image recognition are provided
with limited information about the image during training, which is label alone.
Tasks such as scene retrieval suffer from features learned from this weak
supervision and require stronger supervision to better understand the contents
of the image. In this paper, we exploit the features learned from caption
generating models to learn novel task specific image representations. In
particular, we consider the state-of-the art captioning system Show and
Tell~\cite{SnT-pami-2016} and the dense region description model
DenseCap~\cite{densecap-cvpr-2016}. We demonstrate that, owing to richer
supervision provided during the process of training, the features learned by
the captioning system perform better than those of CNNs. Further, we train a
siamese network with a modified pair-wise loss to fuse the features learned
by~\cite{SnT-pami-2016} and~\cite{densecap-cvpr-2016} and learn image
representations suitable for retrieval. Experiments show that the proposed
fusion exploits the complementary nature of the individual features and yields
state-of-the art retrieval results on benchmark datasets.
</dc:description>
 <dc:description>Comment: ICME 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09144</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling and Simulation of the Dynamics of the Quick Return Mechanism: A
  Bond Graph Approach</dc:title>
 <dc:creator>Vaz, Anand</dc:creator>
 <dc:creator>K, Thommen G</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper applies the multibond graph approach for rigid multibody systems
to model the dynamics of general spatial mechanisms. The commonly used quick
return mechanism which comprises of revolute as well as prismatic joints has
been chosen as a representative example to demonstrate the application of this
technique and its resulting advantages. In this work, the links of the quick
return mechanism are modeled as rigid bodies. The rigid links are then coupled
at the joints based on the nature of constraint. This alternative method of
formulation of system dynamics, using Bond Graphs, offers a rich set of
features that include pictorial representation of the dynamics of translation
and rotation for each link of the mechanism in the inertial frame,
representation and handling of constraints at the joints, depiction of
causality, obtaining dynamic reaction forces and moments at various locations
in the mechanism and so on. Yet another advantage of this approach is that the
coding for simulation can be carried out directly from the Bond Graph in an
algorithmic manner, without deriving system equations. In this work, the
program code for simulation is written in MATLAB. The vector and tensor
operations are conveniently represented in MATLAB, resulting in a compact and
optimized code. The simulation results are plotted and discussed in detail.
</dc:description>
 <dc:description>Comment: Document prepared for National Conference on Industrial Problems on
  Machines and Mechanisms (2010), 8 pages, 19 Figures</dc:description>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09144</dc:identifier>
 <dc:identifier>Proceedings of 10th National Conference on Industrial Problems on
  Machines and Mechanisms (IPRoMM 2010), MNIT, Jaipur, Rajasthan, December
  17-18,2010, paper No. IPRoMM 2010-34, p. 23-30</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09165</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bunshin: Compositing Security Mechanisms through Diversification (with
  Appendix)</dc:title>
 <dc:creator>Xu, Meng</dc:creator>
 <dc:creator>Lu, Kangjie</dc:creator>
 <dc:creator>Kim, Taesoo</dc:creator>
 <dc:creator>Lee, Wenke</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  A number of security mechanisms have been proposed to harden programs written
in unsafe languages, each of which mitigates a specific type of memory error.
Intuitively, enforcing multiple security mechanisms on a target program will
improve its overall security. However, this is not yet a viable approach in
practice because the execution slowdown caused by various security mechanisms
is often non-linearly accumulated, making the combined protection prohibitively
expensive; further, most security mechanisms are designed for independent or
isolated uses and thus are often in conflict with each other, making it
impossible to fuse them in a straightforward way.
  In this paper, we present Bunshin, an N-version-based system that enables
different and even conflicting security mechanisms to be combined to secure a
program while at the same time reducing the execution slowdown. In particular,
we propose an automated mechanism to distribute runtime security checks in
multiple program variants in such a way that conflicts between security checks
are inherently eliminated and execution slowdown is minimized with parallel
execution. We also present an N-version execution engine to seamlessly
synchronize these variants so that all distributed security checks work
together to guarantee the security of a target program.
</dc:description>
 <dc:description>Comment: To be appeared in Proceedings of the 2017 USENIX Annual Technical
  Conference (ATC)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09167</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean dimension and local dimension</dc:title>
 <dc:creator>Trotter, William T.</dc:creator>
 <dc:creator>Walczak, Bartosz</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>06A07</dc:subject>
 <dc:description>  Dimension is a standard and well-studied measure of complexity of posets.
Recent research has provided many new upper bounds on the dimension for various
structurally restricted classes of posets. Bounded dimension gives a succinct
representation of the poset, admitting constant response time for queries of
the form &quot;is $x&lt;y$?&quot;. This application motivates looking for stronger notions
of dimension, possibly leading to succinct representations for more general
classes of posets. We focus on two: boolean dimension, introduced in the 1980s
and revisited in recent research, and local dimension, a very new one. We
determine precisely which values of dimension/boolean dimension/local dimension
imply that the two other parameters are bounded.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09170</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mesh Model (MeMo): A Systematic Approach to Agile System Engineering</dc:title>
 <dc:creator>Mishra, Amit Kumar</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Innovation and entrepreneurship have a very special role to play in creating
sustainable development in the world. Engineering design plays a major role in
innovation. These are not new facts. However this added to the fact that in
current time knowledge seem to increase at an exponential rate, growing twice
every few months. This creates a need to have newer methods to innovate with
very little scope to fall short of the expectations from customers. In terms of
reliable designing, system design tools and methodologies have been very
helpful and have been in use in most engineering industries for decades now.
But traditional system design is rigorous and rigid. As we can see, we need an
innovation system that should be rigorous and flexible at the same time. We
take our inspiration from biosphere, where some of the most rugged yet flexible
plants are creepers which grow to create mesh. In this thematic paper we shall
explain our approach to system engineering which we call the MeMo (Mesh Model)
that fuses the rigor of system engineering with the flexibility of agile
methods to create a scheme that can give rise to reliable innovation in the
high risk market of today.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09176</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shorter stabilizer circuits via Bruhat decomposition and quantum circuit
  transformations</dc:title>
 <dc:creator>Maslov, Dmitri</dc:creator>
 <dc:creator>Roetteler, Martin</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we improve the layered implementation of arbitrary stabilizer
circuits introduced by Aaronson and Gottesman in Phys. Rev. A 70(052328), 2004:
to implement a general stabilizer circuit, we reduce their 11-stage computation
-H-C-P-C-P-C-H-P-C-P-C- over the gate set consisting of Hadamard,
Controlled-NOT, and Phase gates, into a 7-stage computation of the form
-C-CZ-P-H-P-CZ-C-. We show arguments in support of using -CZ- stages over the
-C- stages: not only the use of -CZ- stages allows a shorter layered
expression, but -CZ- stages are simpler and appear to be easier to implement
compared to the -C- stages. Based on this decomposition, we develop a two-qubit
gate depth-$(14n{-}4)$ implementation of stabilizer circuits over the gate
library {H, P, CNOT}, executable in the LNN architecture, improving best
previously known depth-$25n$ circuit, also executable in the LNN architecture.
Our constructions rely on Bruhat decomposition of the symplectic group and on
folding arbitrarily long sequences of the form $($-P-C-$)^m$ into a 3-stage
computation -P-CZ-C-. Our results include the reduction of the $11$-stage
decomposition -H-C-P-C-P-C-H-P-C-P-C- into a $9$-stage decomposition of the
form -C-P-C-P-H-C-P-C-P-. This reduction is based on the Bruhat decomposition
of the symplectic group. This result also implies a new normal form for
stabilizer circuits. We show that a circuit in this normal form is optimal in
the number of Hadamard gates used. We also show that the normal form has an
asymptotically optimal number of parameters.
</dc:description>
 <dc:description>Comment: Supersedes arXiv:1703.00874</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09177</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the (parameterized) complexity of recognizing well-covered
  (r,l)-graphs</dc:title>
 <dc:creator>Alves, Sancrey R.</dc:creator>
 <dc:creator>Dabrowski, Konrad K.</dc:creator>
 <dc:creator>Faria, Luerbio</dc:creator>
 <dc:creator>Klein, Sulamita</dc:creator>
 <dc:creator>Sau, Ignasi</dc:creator>
 <dc:creator>Souza, U&#xe9;verton S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>05C85</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  An $(r, \ell)$-partition of a graph $G$ is a partition of its vertex set into
$r$ independent sets and $\ell$ cliques. A graph is $(r, \ell)$ if it admits an
$(r, \ell)$-partition. A graph is well-covered if every maximal independent set
is also maximum. A graph is $(r,\ell)$-well-covered if it is both $(r,\ell)$
and well-covered. In this paper we consider two different decision problems. In
the $(r,\ell)$-Well-Covered Graph problem ($(r,\ell)$WCG for short), we are
given a graph $G$, and the question is whether $G$ is an
$(r,\ell)$-well-covered graph. In the Well-Covered $(r,\ell)$-Graph problem
(WC$(r,\ell)$G for short), we are given an $(r,\ell)$-graph $G$ together with
an $(r,\ell)$-partition of $V(G)$ into $r$ independent sets and $\ell$ cliques,
and the question is whether $G$ is well-covered. We classify most of these
problems into P, coNP-complete, NP-complete, NP-hard, or coNP-hard. Only the
cases WC$(r,0)$G for $r\geq 3$ remain open. In addition, we consider the
parameterized complexity of these problems for several choices of parameters,
such as the size $\alpha$ of a maximum independent set of the input graph, its
neighborhood diversity, its clique-width, or the number $\ell$ of cliques in an
$(r, \ell)$-partition. In particular, we show that the parameterized problem of
deciding whether a general graph is well-covered parameterized by $\alpha$ can
be reduced to the WC$(0,\ell)$G problem parameterized by $\ell$, and we prove
that this latter problem is in XP but does not admit polynomial kernels unless
$coNP \subseteq NP/poly$.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09180</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Quality Tabletop Rearrangement with Overhand Grasps: Hardness
  Results and Fast Methods</dc:title>
 <dc:creator>Han, Shuai D.</dc:creator>
 <dc:creator>Stiffler, Nicholas M.</dc:creator>
 <dc:creator>Krontiris, Athansios</dc:creator>
 <dc:creator>Bekris, Kostas E.</dc:creator>
 <dc:creator>Yu, Jingjin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper studies the underlying combinatorial structure of a class of
object rearrangement problems, which appear frequently in applications. The
problems involve multiple, similar-geometry objects placed on a flat,
horizontal surface, where a robot can approach them from above and perform
pick-and-place operations to rearrange them. The paper considers both the case
where the start and goal object poses overlap, and where they do not. For
overlapping poses, the primary objective is to minimize the number of
pick-and-place actions and then to minimize the distance traveled by the
end-effector. For the non-overlapping case, the objective is solely to minimize
the end-effector distance. While such problems do not involve all the
complexities of general rearrangement, they remain computationally hard
challenges in both cases. This is shown through two-way reductions between
well-understood, hard combinatorial challenges and these rearrangement
problems. The benefit of the reduction is that there are well studied
algorithms for solving these well-established combinatorial challenges. These
algorithms can be very efficient in practice despite the hardness results. The
paper builds on these reduction results to propose an algorithmic pipeline for
dealing with the rearrangement problems. Experimental evaluation shows that the
proposed pipeline achieves high-quality paths with regards to the optimization
objectives. Furthermore, it exhibits highly desirable scalability as the number
of objects increases in both the overlapping and non-overlapping setups.
</dc:description>
 <dc:description>Comment: Updated manuscript</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09185</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigation of Using VAE for i-Vector Speaker Verification</dc:title>
 <dc:creator>Pekhovsky, Timur</dc:creator>
 <dc:creator>Korenevsky, Maxim</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  New system for i-vector speaker recognition based on variational autoencoder
(VAE) is investigated. VAE is a promising approach for developing accurate deep
nonlinear generative models of complex data. Experiments show that VAE provides
speaker embedding and can be effectively trained in an unsupervised manner. LLR
estimate for VAE is developed. Experiments on NIST SRE 2010 data demonstrate
its correctness. Additionally, we show that the performance of VAE-based system
in the i-vectors space is close to that of the diagonal PLDA. Several
interesting results are also observed in the experiments with $\beta$-VAE. In
particular, we found that for $\beta\ll 1$, VAE can be trained to capture the
features of complex input data distributions in an effective way, which is hard
to obtain in the standard VAE ($\beta=1$).
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09185</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09189</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jointly Learning Sentence Embeddings and Syntax with Unsupervised
  Tree-LSTMs</dc:title>
 <dc:creator>Maillard, Jean</dc:creator>
 <dc:creator>Clark, Stephen</dc:creator>
 <dc:creator>Yogatama, Dani</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a neural network that represents sentences by composing their
words according to induced binary parse trees. We use Tree-LSTM as our
composition function, applied along a tree structure found by a fully
differentiable natural language chart parser. Our model simultaneously
optimises both the composition function and the parser, thus eliminating the
need for externally-provided parse trees which are normally required for
Tree-LSTM. It can therefore be seen as a tree-based RNN that is unsupervised
with respect to the parse trees. As it is fully differentiable, our model is
easily trained with an off-the-shelf gradient descent method and
backpropagation. We demonstrate that it achieves better performance compared to
various supervised Tree-LSTM architectures on a textual entailment task and a
reverse dictionary task.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09193</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification of Quantitative Light-Induced Fluorescence Images Using
  Convolutional Neural Network</dc:title>
 <dc:creator>Imangaliyev, Sultan</dc:creator>
 <dc:creator>van der Veen, Monique H.</dc:creator>
 <dc:creator>Volgenant, Catherine M. C.</dc:creator>
 <dc:creator>Loos, Bruno G.</dc:creator>
 <dc:creator>Keijser, Bart J. F.</dc:creator>
 <dc:creator>Crielaard, Wim</dc:creator>
 <dc:creator>Levin, Evgeni</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Images are an important data source for diagnosis and treatment of oral
diseases. The manual classification of images may lead to misdiagnosis or
mistreatment due to subjective errors. In this paper an image classification
model based on Convolutional Neural Network is applied to Quantitative
Light-induced Fluorescence images. The deep neural network outperforms other
state of the art shallow classification models in predicting labels derived
from three different dental plaque assessment scores. The model directly
benefits from multi-channel representation of the images resulting in improved
performance when, besides the Red colour channel, additional Green and Blue
colour channels are used.
</dc:description>
 <dc:description>Comment: Full version of ICANN 2017 submission</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09198</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proper Functors and their Rational Fixed Point</dc:title>
 <dc:creator>Milius, Stefan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The rational fixed point of a set functor is well-known to capture the
behaviour of finite coalgebras. In this paper we consider functors on algebraic
categories. For them the rational fixed point may no longer be a subcoalgebra
of the final coalgebra. Inspired by \'Esik and Maletti's notion of proper
semiring, we introduce the notion of a proper functor. We show that for proper
functors the rational fixed point is determined as the colimit of all
coalgebras with a free finitely generated algebra as carrier and it is a
subcoalgebra of the final coalgebra. Moreover, we prove that a functor is
proper if and only if that colimit is a subcoalgebra of the final coalgebra.
These results serve as technical tools for soundness and completeness proofs
for coalgebraic regular expression calculi, e.g. for weighted automata.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09207</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Structured Text Representations</dc:title>
 <dc:creator>Liu, Yang</dc:creator>
 <dc:creator>Lapata, Mirella</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In this paper, we focus on learning structure-aware document representations
from data without recourse to a discourse parser or additional annotations.
Drawing inspiration from recent efforts to empower neural networks with a
structural bias, we propose a model that can encode a document while
automatically inducing rich structural dependencies. Specifically, we embed a
differentiable non-projective parsing algorithm into a neural model and use
attention mechanisms to incorporate the structural biases. Experimental
evaluation across different tasks and datasets shows that the proposed model
achieves state-of-the-art results on document modeling tasks while inducing
intermediate structures which are both interpretable and meaningful.
</dc:description>
 <dc:description>Comment: Accepted by TACL</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09218</identifier>
 <datestamp>2017-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Robust Solutions to Stable Marriage</dc:title>
 <dc:creator>Genc, Begum</dc:creator>
 <dc:creator>Siala, Mohamed</dc:creator>
 <dc:creator>O'Sullivan, Barry</dc:creator>
 <dc:creator>Simonin, Gilles</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study the notion of robustness in stable matching problems. We first
define robustness by introducing (a,b)-supermatches. An $(a,b)$-supermatch is a
stable matching in which if $a$ pairs break up it is possible to find another
stable matching by changing the partners of those $a$ pairs and at most $b$
other pairs. In this context, we define the most robust stable matching as a
$(1,b)$-supermatch where b is minimum. We show that checking whether a given
stable matching is a $(1,b)$-supermatch can be done in polynomial time. Next,
we use this procedure to design a constraint programming model, a local search
approach, and a genetic algorithm to find the most robust stable matching. Our
empirical evaluation on large instances show that local search outperforms the
other approaches.
</dc:description>
 <dc:description>Comment: IJCAI 2017 proceedings</dc:description>
 <dc:date>2017-05-24</dc:date>
 <dc:date>2017-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09218</dc:identifier>
 <dc:identifier>doi:10.24963/ijcai.2017/88</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09222</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Knowledge Graph based Speech Interface</dc:title>
 <dc:creator>Kumar, Ashwini Jaya</dc:creator>
 <dc:creator>Auer, S&#xf6;ren</dc:creator>
 <dc:creator>Schmidt, Christoph</dc:creator>
 <dc:creator>k&#xf6;hler, Joachim</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Applications which use human speech as an input require a speech interface
with high recognition accuracy. The words or phrases in the recognised text are
annotated with a machine-understandable meaning and linked to knowledge graphs
for further processing by the target application. These semantic annotations of
recognised words can be represented as a subject-predicate-object triples which
collectively form a graph often referred to as a knowledge graph. This type of
knowledge representation facilitates to use speech interfaces with any spoken
input application, since the information is represented in logical, semantic
form, retrieving and storing can be followed using any web standard query
languages. In this work, we develop a methodology for linking speech input to
knowledge graphs and study the impact of recognition errors in the overall
process. We show that for a corpus with lower WER, the annotation and linking
of entities to the DBpedia knowledge graph is considerable. DBpedia Spotlight,
a tool to interlink text documents with the linked open data is used to link
the speech recognition output to the DBpedia knowledge graph. Such a
knowledge-based speech recognition interface is useful for applications such as
question answering or spoken dialog systems.
</dc:description>
 <dc:description>Comment: Under Review in International Workshop on Grounding Language
  Understanding, Satellite of Interspeech 2017</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09231</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Attribute Machines for Program Generation</dc:title>
 <dc:creator>Amodio, Matthew</dc:creator>
 <dc:creator>Chaudhuri, Swarat</dc:creator>
 <dc:creator>Reps, Thomas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Recurrent neural networks have achieved remarkable success at generating
sequences with complex structures, thanks to advances that include richer
embeddings of input and cures for vanishing gradients. Trained only on
sequences from a known grammar, though, they can still struggle to learn rules
and constraints of the grammar.
  Neural Attribute Machines (NAMs) are equipped with a logical machine that
represents the underlying grammar, which is used to teach the constraints to
the neural machine by (i) augmenting the input sequence, and (ii) optimizing a
custom loss function. Unlike traditional RNNs, NAMs are exposed to the grammar,
as well as samples from the language of the grammar. During generation, NAMs
make significantly fewer violations of the constraints of the underlying
grammar than RNNs trained only on samples from the language of the grammar.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09236</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Parallel Bayesian Optimisation via Thompson Sampling</dc:title>
 <dc:creator>Kandasamy, Kirthevasan</dc:creator>
 <dc:creator>Krishnamurthy, Akshay</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We design and analyse variations of the classical Thompson sampling (TS)
procedure for Bayesian optimisation (BO) in settings where function evaluations
are expensive, but can be performed in parallel. Our theoretical analysis shows
that a direct application of the sequential Thompson sampling algorithm in
either synchronous or asynchronous parallel settings yields a surprisingly
powerful result: making $n$ evaluations distributed among $M$ workers is
essentially equivalent to performing $n$ evaluations in sequence. Further, by
modeling the time taken to complete a function evaluation, we show that, under
a time constraint, asynchronously parallel TS achieves asymptotically lower
regret than both the synchronous and sequential versions. These results are
complemented by an experimental analysis, showing that asynchronous TS
outperforms a suite of existing parallel BO algorithms in simulations and in a
hyper-parameter tuning application in convolutional neural networks. In
addition to these, the proposed procedure is conceptually and computationally
much simpler than existing work for parallel BO.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09258</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum-secured blockchain</dc:title>
 <dc:creator>Kiktenko, E. O.</dc:creator>
 <dc:creator>Pozhar, N. O.</dc:creator>
 <dc:creator>Anufriev, M. N.</dc:creator>
 <dc:creator>Trushechkin, A. S.</dc:creator>
 <dc:creator>Yunusov, R. R.</dc:creator>
 <dc:creator>Kurochkin, Y. V.</dc:creator>
 <dc:creator>Lvovsky, A. I.</dc:creator>
 <dc:creator>Fedorov, A. K.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Blockchain is a distributed database which is cryptographically protected
against malicious modifications. While promising for a wide range of
applications, current blockchain platforms rely on digital signatures, which
are vulnerable to attacks by means of quantum computers. The same, albeit to a
lesser extent, applies to cryptographic hash functions that are used in
preparing new blocks, so parties with access to quantum computation would have
unfair advantage in procuring mining rewards. Here we propose a possible
solution to the quantum-era blockchain challenge and report an experimental
realization of a quantum-safe blockchain platform that utilizes quantum key
distribution across an urban fiber network for information-theoretically secure
authentication. These results address important questions about realizability
and scalability of quantum-safe blockchains for commercial and governmental
applications.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09269</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric Methods for Robust Data Analysis in High Dimension</dc:title>
 <dc:creator>Anderson, Joseph</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning and data analysis now finds both scientific and industrial
application in biology, chemistry, geology, medicine, and physics. These
applications rely on large quantities of data gathered from automated sensors
and user input. Furthermore, the dimensionality of many datasets is extreme:
more details are being gathered about single user interactions or sensor
readings. All of these applications encounter problems with a common theme: use
observed data to make inferences about the world. Our work obtains the first
provably efficient algorithms for Independent Component Analysis (ICA) in the
presence of heavy-tailed data. The main tool in this result is the centroid
body (a well-known topic in convex geometry), along with optimization and
random walks for sampling from a convex body. This is the first algorithmic use
of the centroid body and it is of independent theoretical interest, since it
effectively replaces the estimation of covariance from samples, and is more
generally accessible.
  This reduction relies on a non-linear transformation of samples from such an
intersection of halfspaces (i.e. a simplex) to samples which are approximately
from a linearly transformed product distribution. Through this transformation
of samples, which can be done efficiently, one can then use an ICA algorithm to
recover the vertices of the intersection of halfspaces.
  Finally, we again use ICA as an algorithmic primitive to construct an
efficient solution to the widely-studied problem of learning the parameters of
a Gaussian mixture model. Our algorithm again transforms samples from a
Gaussian mixture model into samples which fit into the ICA model and, when
processed by an ICA algorithm, result in recovery of the mixture parameters.
Our algorithm is effective even when the number of Gaussians in the mixture
grows polynomially with the ambient dimension
</dc:description>
 <dc:description>Comment: 180 Pages, 7 Figures, PhD thesis, Ohio State (2017)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09269</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09271</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is Our Model for Contention Resolution Wrong?</dc:title>
 <dc:creator>Anderton, William C.</dc:creator>
 <dc:creator>Young, Maxwell</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Randomized binary exponential backoff (BEB) is a popular algorithm for
coordinating access to a shared channel. With an operational history exceeding
four decades, BEB is currently an important component of several wireless
standards. Despite this track record, prior theoretical results indicate that
under bursty traffic (1) BEB yields poor makespan and (2) superior algorithms
are possible. To date, the degree to which these findings manifest in practice
has not been resolved.
  To address this issue, we examine one of the strongest cases against BEB: $n$
packets that simultaneously begin contending for the wireless channel. Using
Network Simulator 3, we compare against more recent algorithms that are
inspired by BEB, but whose makespan guarantees are superior. Surprisingly, we
discover that these newer algorithms significantly underperform. Through
further investigation, we identify as the culprit a flawed but common
abstraction regarding the cost of collisions. Our experimental results are
complemented by analytical arguments that the number of collisions -- and not
solely makespan -- is an important metric to optimize. We believe that these
findings have implications for the design of contention-resolution algorithms.
</dc:description>
 <dc:description>Comment: Accepted to the 29th ACM Symposium on Parallelism in Algorithms and
  Architectures (SPAA 2017)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09271</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09275</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who Will Share My Image? Predicting the Content Diffusion Path in Online
  Social Networks</dc:title>
 <dc:creator>Hu, Wenjian</dc:creator>
 <dc:creator>Singh, Krishna Kumar</dc:creator>
 <dc:creator>Xiao, Fanyi</dc:creator>
 <dc:creator>Han, Jinyoung</dc:creator>
 <dc:creator>Chuah, Chen-Nee</dc:creator>
 <dc:creator>Lee, Yong Jae</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Content popularity prediction has been extensively studied due to its
importance and interest for both users and hosts of social media sites like
Facebook, Instagram, Twitter, and Pinterest. However, existing work mainly
focuses on modeling popularity using a single metric such as the total number
of likes or shares. In this work, we propose Diffusion-LSTM, a memory-based
deep recurrent network that learns to recursively predict the entire diffusion
path of an image through a social network. By combining user social features
and image features, and encoding the diffusion path taken thus far with an
explicit memory cell, our model predicts the diffusion path of an image more
accurately compared to alternate baselines that either encode only image or
social features, or lack memory. By mapping individual users to user
prototypes, our model can generalize to new users not seen during training.
Finally, we demonstrate our model's capability of generating diffusion trees,
and show that the generated trees closely resemble ground-truth trees.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09276</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Mapping Relationships Using Table Corpus</dc:title>
 <dc:creator>Wang, Yue</dc:creator>
 <dc:creator>He, Yeye</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Mapping relationships, such as (country, country-code) or (company,
stock-ticker), are versatile data assets for an array of applications in data
cleaning and data integration like auto-correction and auto-join. However,
today there are no good repositories of mapping tables that can enable these
intelligent applications.
  Given a corpus of tables such as web tables or spreadsheet tables, we observe
that values of these mappings often exist in pairs of columns in same tables.
Motivated by their broad applicability, we study the problem of synthesizing
mapping relationships using a large table corpus. Our synthesis process
leverages compatibility of tables based on co-occurrence statistics, as well as
constraints such as functional dependency. Experiment results using web tables
and enterprise spreadsheets suggest that the proposed approach can produce high
quality mappings.
</dc:description>
 <dc:description>Comment: The long version of a paper published at SIGMOD 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09279</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Filtering Variational Objectives</dc:title>
 <dc:creator>Maddison, Chris J.</dc:creator>
 <dc:creator>Lawson, Dieterich</dc:creator>
 <dc:creator>Tucker, George</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Mnih, Andriy</dc:creator>
 <dc:creator>Doucet, Arnaud</dc:creator>
 <dc:creator>Teh, Yee Whye</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When used as a surrogate objective for maximum likelihood estimation in
latent variable models, the evidence lower bound (ELBO) produces
state-of-the-art results. Inspired by this, we consider the extension of the
ELBO to a family of lower bounds defined by a particle filter's estimator of
the marginal likelihood, the filtering variational objectives (FIVOs). FIVOs
take the same arguments as the ELBO, but can exploit a model's sequential
structure to form tighter bounds. We present results that relate the tightness
of FIVO's bound to the variance of the particle filter's estimator by
considering the generic case of bounds defined as log-transformed likelihood
estimators. Experimentally, we show that training with FIVO results in
substantial improvements over training the same model architecture with the
ELBO on sequential data.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09280</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Implicit Regularization in Matrix Factorization</dc:title>
 <dc:creator>Gunasekar, Suriya</dc:creator>
 <dc:creator>Woodworth, Blake</dc:creator>
 <dc:creator>Bhojanapalli, Srinadh</dc:creator>
 <dc:creator>Neyshabur, Behnam</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study implicit regularization when optimizing an underdetermined quadratic
objective over a matrix $X$ with gradient descent on a factorization of $X$. We
conjecture and provide empirical and theoretical evidence that with small
enough step sizes and initialization close enough to the origin, gradient
descent on a full dimensional factorization converges to the minimum nuclear
norm solution.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09283</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gated XNOR Networks: Deep Neural Networks with Ternary Weights and
  Activations under a Unified Discretization Framework</dc:title>
 <dc:creator>Deng, Lei</dc:creator>
 <dc:creator>Jiao, Peng</dc:creator>
 <dc:creator>Pei, Jing</dc:creator>
 <dc:creator>Wu, Zhenzhi</dc:creator>
 <dc:creator>Li, Guoqi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  There is a pressing need to build an architecture that could subsume these
networks undera unified framework that achieves both higher performance and
less overhead. To this end, two fundamental issues are yet to be addressed. The
first one is how to implement the back propagation when neuronal activations
are discrete. The second one is how to remove the full-precision hidden weights
in the training phase to break the bottlenecks of memory/computation
consumption. To address the first issue, we present a multistep neuronal
activation discretization method and a derivative approximation technique that
enable the implementing the back propagation algorithm on discrete DNNs. While
for the second issue, we propose a discrete state transition (DST) methodology
to constrain the weights in a discrete space without saving the hidden weights.
In this way, we build a unified framework that subsumes the binary or ternary
networks as its special cases.More particularly, we find that when both the
weights and activations become ternary values, the DNNs can be reduced to gated
XNOR networks (or sparse binary networks) since only the event of non-zero
weight and non-zero activation enables the control gate to start the XNOR logic
operations in the original binary networks. This promises the event-driven
hardware design for efficient mobile intelligence. We achieve advanced
performance compared with state-of-the-art algorithms. Furthermore,the
computational sparsity and the number of states in the discrete space can be
flexibly modified to make it suitable for various hardware platforms.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09289</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved I-vector-based Speaker Recognition for Utterances with Speaker
  Generated Non-speech sounds</dc:title>
 <dc:creator>Dumpala, Sri Harsha</dc:creator>
 <dc:creator>Panda, Ashish</dc:creator>
 <dc:creator>Kopparapu, Sunil Kumar</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Conversational speech not only contains several variants of neutral speech
but is also prominently interlaced with several speaker generated non-speech
sounds such as laughter and breath. A robust speaker recognition system should
be capable of recognizing a speaker irrespective of these variations in his
speech. An understanding of whether the speaker-specific information
represented by these variations is similar or not helps build a good speaker
recognition system. In this paper, speaker variations captured by neutral
speech of a speaker is analyzed by considering speech-laugh (a variant of
neutral speech) and laughter (non-speech) sounds of the speaker. We study an
i-vector-based speaker recognition system trained only on neutral speech and
evaluate its performance on speech-laugh and laughter. Further, we analyze the
effect of including laughter sounds during training of an i-vector-basedspeaker
recognition system. Our experimental results show that the inclusion of
laughter sounds during training seem to provide complementary speaker-specific
information which results in an overall improved performance of the speaker
recognition system, especially on the utterances with speech-laugh segments.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09296</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Framework for Generalized Topic Models</dc:title>
 <dc:creator>Card, Dallas</dc:creator>
 <dc:creator>Tan, Chenhao</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Topic models for text corpora comprise a popular family of methods that have
inspired many extensions to encode properties such as sparsity, interactions
with covariates, and the gradual evolution of topics. In this paper, we combine
certain motivating ideas behind variations on topic models with modern
techniques for variational inference to produce a flexible framework for topic
modeling that allows for rapid exploration of different models. We first
discuss how our framework relates to existing models, and then demonstrate that
it achieves strong performance, with the introduction of sparsity controlling
the trade off between perplexity and topic coherence.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, 4 tables</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09303</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent Geometry and Memorization in Generative Models</dc:title>
 <dc:creator>Feiszli, Matt</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  It can be difficult to tell whether a trained generative model has learned to
generate novel examples or has simply memorized a specific set of outputs. In
published work, it is common to attempt to address this visually, for example
by displaying a generated example and its nearest neighbor(s) in the training
set (in, for example, the L2 metric). As any generative model induces a
probability density on its output domain, we propose studying this density
directly. We first study the geometry of the latent representation and
generator, relate this to the output density, and then develop techniques to
compute and inspect the output density. As an application, we demonstrate that
&quot;memorization&quot; tends to a density made of delta functions concentrated on the
memorized examples. We note that without first understanding the geometry, the
measurement would be essentially impossible to make.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09307</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Direct Multitype Cardiac Indices Estimation via Joint Representation and
  Regression Learning</dc:title>
 <dc:creator>Xue, Wufeng</dc:creator>
 <dc:creator>Islam, Ali</dc:creator>
 <dc:creator>Bhaduri, Mousumi</dc:creator>
 <dc:creator>Li, Shuo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cardiac indices estimation is of great importance during identification and
diagnosis of cardiac disease in clinical routine. However, estimation of
multitype cardiac indices with consistently reliable and high accuracy is still
a great challenge due to the high variability of cardiac structures and
complexity of temporal dynamics in cardiac MR sequences. While efforts have
been devoted into cardiac volumes estimation through feature engineering
followed by a independent regression model, these methods suffer from the
vulnerable feature representation and incompatible regression model. In this
paper, we propose a semi-automated method for multitype cardiac indices
estimation. After manual labelling of two landmarks for ROI cropping, an
integrated deep neural network Indices-Net is designed to jointly learn the
representation and regression models. It comprises two tightly-coupled
networks: a deep convolution autoencoder (DCAE) for cardiac image
representation, and a multiple output convolution neural network (CNN) for
indices regression. Joint learning of the two networks effectively enhances the
expressiveness of image representation with respect to cardiac indices, and the
compatibility between image representation and indices regression, thus leading
to accurate and reliable estimations for all the cardiac indices.
  When applied with five-fold cross validation on MR images of 145 subjects,
Indices-Net achieves consistently low estimation error for LV wall thicknesses
(1.44$\pm$0.71mm) and areas of cavity and myocardium (204$\pm$133mm$^2$). It
outperforms, with significant error reductions, segmentation method (55.1% and
17.4%) and two-phase direct volume-only methods (12.7% and 14.6%) for wall
thicknesses and areas, respectively. These advantages endow the proposed method
a great potential in clinical cardiac function assessment.
</dc:description>
 <dc:description>Comment: accepted by IEEE Transactions on Medical Imaging</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09307</dc:identifier>
 <dc:identifier>doi:10.1109/TMI.2017.2709251</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09314</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plan3D: Viewpoint and Trajectory Optimization for Aerial Multi-View
  Stereo Reconstruction</dc:title>
 <dc:creator>Hepp, Benjamin</dc:creator>
 <dc:creator>Nie&#xdf;ner, Matthias</dc:creator>
 <dc:creator>Hilliges, Otmar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a new method that efficiently computes a set of rich viewpoints
and trajectories for high-quality 3D reconstructions in outdoor environments.
The input images of the reconstruction are taken with a commodity RGB camera
which is mounted on an autonomously navigated quadcopter, and the obtained
recordings are fed into a multi-view stereo reconstruction pipeline that
produces high-quality results but is computationally expensive. Our goal is to
automatically explore an unknown area, and obtain a complete 3D scan of a
region of interest (e.g., a large building). In this process, the scan is
constraint by the restricted flight time of quadcopters and the heavy compute
costs of the subsequent 3D reconstruction -- i.e., only a small number of
images can be recorded and processed. To this end, we introduce a novel
optimization strategy that respects these constraints by maximizing the
information gain from sparsely-sampled view points while limiting the total
number of captured images. The core of this strategy is based on the concept of
tri-state space classification, which is common in volumetric fusion
approaches, and includes labels for unknown, free, and occupied space. Our
optimization leverages a hierarchical and sparse volumetric data structure that
takes advantage of the implicit representation, where its main objective is to
convert unknown space into known regions. In addition to the surface geometry,
we utilize the free-space information to avoid obstacles and determine feasible
flight paths. A simple tool can be used to specify the region of interest and
to plan trajectories. We demonstrate our method by obtaining a number of
compelling 3D reconstructions, and provide a thorough quantitative evaluation
for our optimization strategy.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09316</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Assume-Guarantee Contracts for Cyber-Physical System Design
  Under Probabilistic Requirements</dc:title>
 <dc:creator>Li, Jiwei</dc:creator>
 <dc:creator>Nuzzo, Pierluigi</dc:creator>
 <dc:creator>Sangiovanni-Vincentelli, Alberto</dc:creator>
 <dc:creator>Xi, Yugeng</dc:creator>
 <dc:creator>Li, Dewei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We develop an assume-guarantee contract framework for the design of
cyber-physical systems, modeled as closed-loop control systems, under
probabilistic requirements. We use a variant of signal temporal logic, namely,
Stochastic Signal Temporal Logic (StSTL) to specify system behaviors as well as
contract assumptions and guarantees, thus enabling automatic reasoning about
requirements of stochastic systems. Given a stochastic linear system
representation and a set of requirements captured by bounded StSTL contracts,
we propose algorithms that can check contract compatibility, consistency, and
refinement, and generate a controller to guarantee that a contract is
satisfied, following a stochastic model predictive control approach. Our
algorithms leverage encodings of the verification and control synthesis tasks
into mixed integer optimization problems, and conservative approximations of
probabilistic constraints that produce both sound and tractable problem
formulations. We illustrate the effectiveness of our approach on a few
examples, including the design of embedded controllers for aircraft power
distribution networks.
</dc:description>
 <dc:description>Comment: Extended version of conference paper submission</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09319</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagonal Rescaling For Neural Networks</dc:title>
 <dc:creator>Lafond, Jean</dc:creator>
 <dc:creator>Vasilache, Nicolas</dc:creator>
 <dc:creator>Bottou, L&#xe9;on</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We define a second-order neural network stochastic gradient training
algorithm whose block-diagonal structure effectively amounts to normalizing the
unit activations. Investigating why this algorithm lacks in robustness then
reveals two interesting insights. The first insight suggests a new way to scale
the stepsizes, clarifying popular algorithms such as RMSProp as well as old
neural network tricks such as fanin stepsize scaling. The second insight
stresses the practical importance of dealing with fast changes of the curvature
of the cost.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09322</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergent Tree-Backup and Retrace with Function Approximation</dc:title>
 <dc:creator>Touati, Ahmed</dc:creator>
 <dc:creator>Bacon, Pierre-Luc</dc:creator>
 <dc:creator>Precup, Doina</dc:creator>
 <dc:creator>Vincent, Pascal</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Off-policy learning is key to scaling up reinforcement learning as it allows
to learn about a target policy from the experience generated by a different
behavior policy. Unfortunately, it has been challenging to combine off-policy
learning with function approximation and multi-step bootstrapping in a way that
leads to both stable and efficient algorithms. In this paper, we show that the
Tree Backup and Retrace algorithms are unstable with linear function
approximation, both in theory and with specific examples. Based on our
analysis, we then derive stable and efficient gradient-based algorithms,
compatible with accumulating or Dutch traces, using a novel methodology based
on saddle-point methods. In addition to convergence guarantees, we provide
finite-sample analysis.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09326</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoothing Method for Approximate Extensive-Form Perfect Equilibrium</dc:title>
 <dc:creator>Kroer, Christian</dc:creator>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:creator>Sandholm, Tuomas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Nash equilibrium is a popular solution concept for solving
imperfect-information games in practice. However, it has a major drawback: it
does not preclude suboptimal play in branches of the game tree that are not
reached in equilibrium. Equilibrium refinements can mend this issue, but have
experienced little practical adoption. This is largely due to a lack of
scalable algorithms.
  Sparse iterative methods, in particular first-order methods, are known to be
among the most effective algorithms for computing Nash equilibria in
large-scale two-player zero-sum extensive-form games. In this paper, we
provide, to our knowledge, the first extension of these methods to equilibrium
refinements. We develop a smoothing approach for behavioral perturbations of
the convex polytope that encompasses the strategy spaces of players in an
extensive-form game. This enables one to compute an approximate variant of
extensive-form perfect equilibria. Experiments show that our smoothing approach
leads to solutions with dramatically stronger strategies at information sets
that are reached with low probability in approximate Nash equilibria, while
retaining the overall convergence rate associated with fast algorithms for Nash
equilibrium. This has benefits both in approximate equilibrium finding (such
approximation is necessary in practice in large games) where some probabilities
are low while possibly heading toward zero in the limit, and exact equilibrium
computation where the low probabilities are actually zero.
</dc:description>
 <dc:description>Comment: Published at IJCAI 17</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09328</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Operation Frames and Clubs in Kidney Exchange</dc:title>
 <dc:creator>Farina, Gabriele</dc:creator>
 <dc:creator>Dickerson, John P.</dc:creator>
 <dc:creator>Sandholm, Tuomas</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  A kidney exchange is a centrally-administered barter market where patients
swap their willing yet incompatible donors. Modern kidney exchanges use
2-cycles, 3-cycles, and chains initiated by non-directed donors (altruists who
are willing to give a kidney to anyone) as the means for swapping.
  We propose significant generalizations to kidney exchange. We allow more than
one donor to donate in exchange for their desired patient receiving a kidney.
We also allow for the possibility of a donor willing to donate if any of a
number of patients receive kidneys. Furthermore, we combine these notions and
generalize them. The generalization is to exchange among organ clubs, where a
club is willing to donate organs outside the club if and only if the club
receives organs from outside the club according to given specifications. We
prove that unlike in the standard model, the uncapped clearing problem is
NP-complete.
  We also present the notion of operation frames that can be used to sequence
the operations across batches, and present integer programming formulations for
the market clearing problems for these new types of organ exchanges.
  Experiments show that in the single-donation setting, operation frames
improve planning by 34%--51%. Allowing up to two donors to donate in exchange
for one kidney donated to their designated patient yields a further increase in
social welfare.
</dc:description>
 <dc:description>Comment: Published at IJCAI-17</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09335</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Overcommitment in Cloud Services -- Bin packing with Chance Constraints</dc:title>
 <dc:creator>Cohen, Maxime C.</dc:creator>
 <dc:creator>Keller, Philipp W.</dc:creator>
 <dc:creator>Mirrokni, Vahab</dc:creator>
 <dc:creator>Zadimoghaddam, Morteza</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper considers a traditional problem of resource allocation, scheduling
jobs on machines. One such recent application is cloud computing, where jobs
arrive in an online fashion with capacity requirements and need to be
immediately scheduled on physical machines in data centers. It is often
observed that the requested capacities are not fully utilized, hence offering
an opportunity to employ an overcommitment policy, i.e., selling resources
beyond capacity. Setting the right overcommitment level can induce a
significant cost reduction for the cloud provider, while only inducing a very
low risk of violating capacity constraints. We introduce and study a model that
quantifies the value of overcommitment by modeling the problem as a bin packing
with chance constraints. We then propose an alternative formulation that
transforms each chance constraint into a submodular function. We show that our
model captures the risk pooling effect and can guide scheduling and
overcommitment decisions. We also develop a family of online algorithms that
are intuitive, easy to implement and provide a constant factor guarantee from
optimal. Finally, we calibrate our model using realistic workload data, and
test our approach in a practical setting. Our analysis and experiments
illustrate the benefit of overcommitment in cloud services, and suggest a cost
reduction of 1.5% to 17% depending on the provider's risk tolerance.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09336</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the number of types in sparse graphs</dc:title>
 <dc:creator>Pilipczuk, Micha&#x142;</dc:creator>
 <dc:creator>Siebertz, Sebastian</dc:creator>
 <dc:creator>Toru&#x144;czyk, Szymon</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We prove that for every class of graphs $\mathcal{C}$ which is nowhere dense,
as defined by Nesetril and Ossona de Mendez, and for every first order formula
$\phi(\bar x,\bar y)$, whenever one draws a graph $G\in \mathcal{C}$ and a
subset of its nodes $A$, the number of subsets of $A^{|\bar y|}$ which are of
the form $\{\bar v\in A^{|\bar y|}\, \colon\, G\models\phi(\bar u,\bar v)\}$
for some valuation $\bar u$ of $\bar x$ in $G$ is bounded by
$\mathcal{O}(|A|^{|\bar x|+\epsilon})$, for every $\epsilon&gt;0$. This provides
optimal bounds on the VC-density of first-order definable set systems in
nowhere dense graph classes.
  We also give two new proofs of upper bounds on quantities in nowhere dense
classes which are relevant for their logical treatment. Firstly, we provide a
new proof of the fact that nowhere dense classes are uniformly quasi-wide,
implying explicit, polynomial upper bounds on the functions relating the two
notions. Secondly, we give a new combinatorial proof of the result of Adler and
Adler stating that every nowhere dense class of graphs is stable. In contrast
to the previous proofs of the above results, our proofs are completely
finitistic and constructive, and yield explicit and computable upper bounds on
quantities related to uniform quasi-wideness (margins) and stability (ladder
indices).
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09339</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Background Subtraction Using Adaptive Sampling and Cascade of
  Gaussians</dc:title>
 <dc:creator>Kiran, B Ravi</dc:creator>
 <dc:creator>Yogamani, Senthil</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Background-Foreground classification is a fundamental well-studied problem in
computer vision. Due to the pixel-wise nature of modeling and processing in the
algorithm, it is usually difficult to satisfy real-time constraints. There is a
trade-off between the speed (because of model complexity) and accuracy.
Inspired by the rejection cascade of Viola-Jones classifier, we decompose the
Gaussian Mixture Model (GMM) into an adaptive cascade of classifiers. This way
we achieve a good improvement in speed without compensating for accuracy. In
the training phase, we learn multiple KDEs for different durations to be used
as strong prior distribution and detect probable oscillating pixels which
usually results in misclassifications. We propose a confidence measure for the
classifier based on temporal consistency and the prior distribution. The
confidence measure thus derived is used to adapt the learning rate and the
thresholds of the model, to improve accuracy. The confidence measure is also
employed to perform temporal and spatial sampling in a principled way. We
demonstrate a speed-up factor of 5x to 10x and 17 percent average improvement
in accuracy over several standard videos.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09346</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Range Assignment of Base-Stations Maximizing Coverage Area without
  Interference</dc:title>
 <dc:creator>Acharyya, Ankush</dc:creator>
 <dc:creator>De, Minati</dc:creator>
 <dc:creator>Nandy, Subhas C.</dc:creator>
 <dc:creator>Roy, Bodhayan</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>52C15, 52C17</dc:subject>
 <dc:description>  We study the problem of assigning non-overlapping geometric objects centered
at a given set of points such that the sum of area covered by them is
maximized. If the points are placed on a straight-line and the objects are
disks, then the problem is solvable in polynomial time. However, we show that
the problem is NP-hard even for simplest objects like disks or squares in
${\mathbb{R}}^2$. Eppstein [CCCG, pages 260--265, 2016] proposed a polynomial
time algorithm for maximizing the sum of radii (or perimeter) of
non-overlapping balls or disks when the points are arbitrarily placed on a
plane. We show that Eppstein's algorithm for maximizing sum of perimeter of the
disks in ${\mathbb{R}}^2$ gives a $2$-approximation solution for the sum of
area maximization problem. We propose a PTAS for our problem. These
approximation results are extendible to higher dimensions. All these
approximation results hold for the area maximization problem by regular convex
polygons with even number of edges centered at the given points.
</dc:description>
 <dc:description>Comment: 27 pages, 15 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09349</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Together We Know How to Achieve: An Epistemic Logic of Know-How</dc:title>
 <dc:creator>Naumov, Pavel</dc:creator>
 <dc:creator>Tao, Jia</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  The existence of a coalition strategy to achieve a goal does not necessarily
mean that the coalition has enough information to know how to follow the
strategy. Neither does it mean that the coalition knows that such a strategy
exists. The article studies an interplay between the distributed knowledge,
coalition strategies, and coalition &quot;know-how&quot; strategies. The main technical
result is a sound and complete trimodal logical system that describes the
properties of this interplay.
</dc:description>
 <dc:description>Comment: An extended abstract of this paper will appear in Proceedings of 16th
  conference on Theoretical Aspects of Rationality and Knowledge (TARK-17),
  Liverpool, United Kingdom, July 24-26, 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09354</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coherence for braided and symmetric pseudomonoids</dc:title>
 <dc:creator>Verdon, Dominic</dc:creator>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Quantum Algebra</dc:subject>
 <dc:description>  Presentations for unbraided, braided and symmetric pseudomonoids are defined.
Biequivalences characterising the semistrict bicategories generated by these
presentations are proven. It is shown that these biequivalences categorify
results in the theory of monoids and commutative monoids, and are
generalisations of standard coherence theorems for braided and symmetric
monoidal categories.
</dc:description>
 <dc:description>Comment: Linked Globular workspace at http://globular.science/1705.001</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09358</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shared Memory Parallel Subgraph Enumeration</dc:title>
 <dc:creator>Kimmig, Raphael</dc:creator>
 <dc:creator>Meyerhenke, Henning</dc:creator>
 <dc:creator>Strash, Darren</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The subgraph enumeration problem asks us to find all subgraphs of a target
graph that are isomorphic to a given pattern graph. Determining whether even
one such isomorphic subgraph exists is NP-complete---and therefore finding all
such subgraphs (if they exist) is a time-consuming task. Subgraph enumeration
has applications in many fields, including biochemistry and social networks,
and interestingly the fastest algorithms for solving the problem for
biochemical inputs are sequential. Since they depend on depth-first tree
traversal, an efficient parallelization is far from trivial. Nevertheless,
since important applications produce data sets with increasing difficulty,
parallelism seems beneficial.
  We thus present here a shared-memory parallelization of the state-of-the-art
subgraph enumeration algorithms RI and RI-DS (a variant of RI for dense graphs)
by Bonnici et al. [BMC Bioinformatics, 2013]. Our strategy uses work stealing
and our implementation demonstrates a significant speedup on real-world
biochemical data---despite a highly irregular data access pattern. We also
improve RI-DS by pruning the search space better; this further improves the
empirical running times compared to the already highly tuned RI-DS.
</dc:description>
 <dc:description>Comment: 18 pages, 12 figures, To appear at the 7th IEEE Workshop on Parallel
  / Distributed Computing and Optimization (PDCO 2017)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09359</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Time-Based Label Refinements to Discover More Precise Process
  Models</dc:title>
 <dc:creator>Tax, Niek</dc:creator>
 <dc:creator>Alasgarov, Emin</dc:creator>
 <dc:creator>Sidorova, Natalia</dc:creator>
 <dc:creator>van der Aalst, Wil M. P.</dc:creator>
 <dc:creator>Haakma, Reinder</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Process mining is a research field focused on the analysis of event data with
the aim of extracting insights related to dynamic behavior. Applying process
mining techniques on data from smart home environments has the potential to
provide valuable insights in (un)healthy habits and to contribute to ambient
assisted living solutions. Finding the right event labels to enable the
application of process mining techniques is however far from trivial, as simply
using the triggering sensor as the label for sensor events results in
uninformative models that allow for too much behavior (overgeneralizing).
Refinements of sensor level event labels suggested by domain experts have been
shown to enable discovery of more precise and insightful process models.
However, there exists no automated approach to generate refinements of event
labels in the context of process mining. In this paper we propose a framework
for the automated generation of label refinements based on the time attribute
of events, allowing us to distinguish behaviourally different instances of the
same event type based on their time attribute. We show on a case study with
real life smart home event data that using automatically generated refined
labels in process discovery, we can find more specific, and therefore more
insightful, process models. We observe that one label refinement could have an
effect on the usefulness of other label refinements when used together.
Therefore, we explore four strategies to generate useful combinations of
multiple label refinements and evaluate those on three real life smart home
event logs.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09363</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canonical Selection of Colimits</dc:title>
 <dc:creator>Mossakowski, Till</dc:creator>
 <dc:creator>Rabe, Florian</dc:creator>
 <dc:creator>Codescu, Mihai</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Colimits are a powerful tool for the combination of objects in a category. In
the context of modeling and specification, they are used in the
institution-independent semantics (1) of instantiations of parameterised
specifications (e.g. in the specification language CASL), and (2) of
combinations of networks of specifications (in the OMG standardised language
DOL).
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09366</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Space-Time Kernel Density Estimation</dc:title>
 <dc:creator>Saule, Erik</dc:creator>
 <dc:creator>Panchananam, Dinesh</dc:creator>
 <dc:creator>Hohl, Alexander</dc:creator>
 <dc:creator>Tang, Wenwu</dc:creator>
 <dc:creator>Delmelle, Eric</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The exponential growth of available data has increased the need for
interactive exploratory analysis. Dataset can no longer be understood through
manual crawling and simple statistics. In Geographical Information Systems
(GIS), the dataset is often composed of events localized in space and time; and
visualizing such a dataset involves building a map of where the events
occurred.
  We focus in this paper on events that are localized among three dimensions
(latitude, longitude, and time), and on computing the first step of the
visualization pipeline, space-time kernel density estimation (STKDE), which is
most computationally expensive. Starting from a gold standard implementation,
we show how algorithm design and engineering, parallel decomposition, and
scheduling can be applied to bring near real-time computing to space-time
kernel density estimation. We validate our techniques on real world datasets
extracted from infectious disease, social media, and ornithology.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09367</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilizing Training of Generative Adversarial Networks through
  Regularization</dc:title>
 <dc:creator>Roth, Kevin</dc:creator>
 <dc:creator>Lucchi, Aurelien</dc:creator>
 <dc:creator>Nowozin, Sebastian</dc:creator>
 <dc:creator>Hofmann, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep generative models based on Generative Adversarial Networks (GANs) have
demonstrated impressive sample quality but in order to work they require a
careful choice of architecture, parameter initialization, and selection of
hyper-parameters. This fragility is in part due to a dimensional mismatch or
non-overlapping support between the model distribution and the data
distribution, causing their density ratio and the associated f-divergence to be
undefined. We overcome this fundamental limitation and propose a new
regularization approach with low computational cost that yields a stable GAN
training procedure. We demonstrate the effectiveness of this regularizer across
several architectures trained on common benchmark image generation tasks. Our
regularization turns GAN models into reliable building blocks for deep
learning.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09368</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pose Guided Person Image Generation</dc:title>
 <dc:creator>Ma, Liqian</dc:creator>
 <dc:creator>Sun, Qianru</dc:creator>
 <dc:creator>Jia, Xu</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes the novel Pose Guided Person Generation Network (PG$^2$)
that allows to synthesize person images in arbitrary poses, based on an image
of that person and a novel pose. Our generation framework PG$^2$ utilizes the
pose information explicitly and consists of two key stages: pose integration
and image refinement. In the first stage the condition image and the target
pose are fed into a U-Net-like network to generate an initial but coarse image
of the person with the target pose. The second stage then refines the initial
and blurry result by training a U-Net-like generator in an adversarial way.
Extensive experimental results on both 128$\times$64 re-identification images
and 256$\times$256 fashion photos show that our model generates high-quality
person images with convincing details.
</dc:description>
 <dc:description>Comment: Qianru Sun and Xu Jia contribute equally. Accepted in Proceedings of
  31st Conference on Neural Information Processing Systems (NIPS 2017)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09369</identifier>
 <datestamp>2017-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Feature Learning for Writer Identification and Writer
  Retrieval</dc:title>
 <dc:creator>Christlein, Vincent</dc:creator>
 <dc:creator>Gropp, Martin</dc:creator>
 <dc:creator>Fiel, Stefan</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep Convolutional Neural Networks (CNN) have shown great success in
supervised classification tasks such as character classification or dating.
Deep learning methods typically need a lot of annotated training data, which is
not available in many scenarios. In these cases, traditional methods are often
better than or equivalent to deep learning methods. In this paper, we propose a
simple, yet effective, way to learn CNN activation features in an unsupervised
manner. Therefore, we train a deep residual network using surrogate classes.
The surrogate classes are created by clustering the training dataset, where
each cluster index represents one surrogate class. The activations from the
penultimate CNN layer serve as features for subsequent classification tasks. We
evaluate the feature representations on two publicly available datasets. The
focus lies on the ICDAR17 competition dataset on historical document writer
identification (Historical-WI). We show that the activation features trained
without supervision are superior to descriptors of state-of-the-art writer
identification methods. Additionally, we achieve comparable results in the case
of handwriting classification using the ICFHR16 competition dataset on
historical Latin script types (CLaMM16).
</dc:description>
 <dc:description>Comment: ICDAR2017 camera ready (fixed p@2 values, missing table references)</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09369</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09372</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centralized vs Decentralized Multi-Agent Guesswork</dc:title>
 <dc:creator>Salamatian, Salman</dc:creator>
 <dc:creator>Beirami, Ahmad</dc:creator>
 <dc:creator>Cohen, Asaf</dc:creator>
 <dc:creator>M&#xe9;dard, Muriel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study a notion of guesswork, where multiple agents intend to launch a
coordinated brute-force attack to find a single binary secret string, and each
agent has access to side information generated through either a BEC or a BSC.
The average number of trials required to find the secret string grows
exponentially with the length of the string, and the rate of the growth is
called the guesswork exponent. We compute the guesswork exponent for several
multi-agent attacks. We show that a multi-agent attack reduces the guesswork
exponent compared to a single agent, even when the agents do not exchange
information to coordinate their attack, and try to individually guess the
secret string using a predetermined scheme in a decentralized fashion. Further,
we show that the guesswork exponent of two agents who do coordinate their
attack is strictly smaller than that of any finite number of agents
individually performing decentralized guesswork.
</dc:description>
 <dc:description>Comment: Accepted at IEEE International Symposium on Information Theory (ISIT)
  2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09373</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity Scaling of Cellular Networks: Impact of Bandwidth,
  Infrastructure Density and Number of Antennas</dc:title>
 <dc:creator>G&#xf3;mez-Cuba, Felipe</dc:creator>
 <dc:creator>Erkip, Elza</dc:creator>
 <dc:creator>Rangan, Sundeep</dc:creator>
 <dc:creator>Gonz&#xe1;lez-Casta&#xf1;o, Francisco J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The availability of very wide spectrum in millimeter wave bands combined with
large antenna arrays and ultra dense networks raises two basic questions: What
is the true value of overly abundant degrees of freedom and how can networks be
designed to fully exploit them? This paper determines the capacity scaling of
large cellular networks as a function of bandwidth, area, number of antennas
and base station density. It is found that the network capacity has a
fundamental bandwidth scaling limit, beyond which the network becomes
power-limited. An infrastructure multi-hop protocol achieves the optimal
network capacity scaling for all network parameters. In contrast, current
protocols that use only single-hop direct transmissions can not achieve the
capacity scaling in wideband regimes except in the special case when the
density of base stations is taken to impractical extremes. This finding
suggests that multi-hop communication will be important to fully realize the
potential of next-generation cellular networks. Dedicated relays, if
sufficiently dense, can also perform this task, relieving user nodes from the
battery drain of cooperation. On the other hand, more sophisticated strategies
such as hierarchical cooperation, that are essential for achieving capacity
scaling in ad hoc networks, are unnecessary in the cellular context.
</dc:description>
 <dc:description>Comment: 30 pages, 4 figures, 1 table. Accepted paper to appear in IEEE
  Transactions on Wireless Communications</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09378</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analog Beam Tracking in Linear Antenna Arrays: Convergence, Optimality,
  and Performance</dc:title>
 <dc:creator>Li, Jiahui</dc:creator>
 <dc:creator>Sun, Yin</dc:creator>
 <dc:creator>Xiao, Limin</dc:creator>
 <dc:creator>Zhou, Shidong</dc:creator>
 <dc:creator>Koksal, C. Emre</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The directionality of millimeter-wave (mmWave) communications creates a
significant challenge in serving fast-moving mobile terminals on, e.g.,
high-speed vehicles, trains, and UAVs. This challenge is exacerbated in mmWave
systems using analog antenna arrays, because of the inherent non-convexity in
the control of the phase shifters. In this paper, we develop a recursive beam
tracking algorithm which can simultaneously achieve fast tracking speed, high
tracking accuracy, low complexity, and low pilot overhead. In static scenarios,
this algorithm converges to the minimum Cram\'er-Rao lower bound (CRLB) of beam
tracking with high probability. In dynamic scenarios, even at SNRs as low as
0dB, our algorithm is capable of tracking a mobile moving randomly at an
absolute angular velocity of 10-20 degrees per second, using only 5 pilot
symbols per second. If combining with a simple TDMA pilot pattern, this
algorithm can track hundreds of high-speed mobiles in 5G configurations. Our
simulations show that the tracking performance of this algorithm is much better
than several state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, Asilomar conference 2017</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09378</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09379</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor rank is not multiplicative under the tensor product</dc:title>
 <dc:creator>Christandl, Matthias</dc:creator>
 <dc:creator>Jensen, Asger Kj&#xe6;rulff</dc:creator>
 <dc:creator>Zuiddam, Jeroen</dc:creator>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>15A69</dc:subject>
 <dc:description>  The tensor rank of a tensor t is the smallest number r such that t can be
decomposed as a sum of r simple tensors. Let s be a k-tensor and let t be an
l-tensor. The tensor product of s and t is a (k + l)-tensor. Tensor rank is
sub-multiplicative under the tensor product. We revisit the connection between
restrictions and degenerations. A result of our study is that tensor rank is
not in general multiplicative under the tensor product. This answers a question
of Draisma and Saptharishi. Specifically, if a tensor t has border rank
strictly smaller than its rank, then the tensor rank of t is not multiplicative
under taking a sufficiently hight tensor product power. The &quot;tensor Kronecker
product&quot; from algebraic complexity theory is related to our tensor product but
different, namely it multiplies two k-tensors to get a k-tensor.
Nonmultiplicativity of the tensor Kronecker product has been known since the
work of Strassen.
  It remains an open question whether border rank and asymptotic rank are
multiplicative under the tensor product. Interestingly, lower bounds on border
rank obtained from generalised flattenings (including Young flattenings)
multiply under the tensor product.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09379</dc:identifier>
 <dc:identifier>Linear Algebra Appl. 543 (2018) 125-139</dc:identifier>
 <dc:identifier>doi:10.1016/j.laa.2017.12.020</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09382</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Robust Subspace Recovery</dc:title>
 <dc:creator>Huroyan, Vahan</dc:creator>
 <dc:creator>Lerman, Gilad</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>68W15, 65K05, 62H25, 90C06</dc:subject>
 <dc:description>  We study Robust Subspace Recovery (RSR) in distributed settings. We consider
a huge data set in an ad hoc network without a central processor, where each
node has access only to one chunk of the data set. We assume that part of the
whole data set lies around a low-dimensional subspace and the other part is
composed of outliers that lie away from that subspace. The goal is to recover
the underlying subspace for the whole data set, without transferring the data
itself between the nodes. We apply the Consensus Based Gradient method for the
Geometric Median Subspace algorithm for RSR. We propose an iterative solution
for the local dual minimization problem and establish its $r$-linear
convergence. We show that this mathematical framework also extends to two
simpler problems: Principal Component Analysis and the geometric median. We
also explain how to distributedly implement the Reaper and Fast Median Subspace
algorithms for RSR. We demonstrate the competitive performance of our
algorithms for both synthetic and real data.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09382</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09390</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the &quot;persistency&quot; of scientific publications: introducing an h-index
  for journals</dc:title>
 <dc:creator>Piazza, Roberto</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  What do we really mean by a &quot;good&quot; scientific journal? Do we care more about
the short-time impact of our papers, or about the chance that they will still
be read and cited on the long run? Here I show that, by regarding a journal as
a &quot;virtual scientist&quot; that can be attributed a time-dependent Hirsch h-index,
we can introduce a parameter that, arguably, better captures the &quot;persistency&quot;
of a scientific publication. Curiously, however, this parameter seems to depend
above all on the &quot;thickness&quot; of a journal.
</dc:description>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09391</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering Reliable Approximate Functional Dependencies</dc:title>
 <dc:creator>Mandros, Panagiotis</dc:creator>
 <dc:creator>Boley, Mario</dc:creator>
 <dc:creator>Vreeken, Jilles</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Given a database and a target attribute of interest, how can we tell whether
there exists a functional, or approximately functional dependence of the target
on any set of other attributes in the data? How can we reliably, without bias
to sample size or dimensionality, measure the strength of such a dependence?
And, how can we efficiently discover the optimal or $\alpha$-approximate
top-$k$ dependencies? These are exactly the questions we answer in this paper.
  As we want to be agnostic on the form of the dependence, we adopt an
information-theoretic approach, and construct a reliable, bias correcting score
that can be efficiently computed. Moreover, we give an effective optimistic
estimator of this score, by which for the first time we can mine the
approximate functional dependencies from data with guarantees of optimality.
Empirical evaluation shows that the derived score achieves a good bias for
variance trade-off, can be used within an efficient discovery algorithm, and
indeed discovers meaningful dependencies. Most important, it remains reliable
in the face of data sparsity.
</dc:description>
 <dc:description>Comment: Accepted: In Proceedings of the ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining (KDD), August 13-17, 2017, Halifax, NS, Canada</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09391</dc:identifier>
 <dc:identifier>doi:10.1145/3097983.3098062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09400</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regrasp Planning using 10,000s of Grasps</dc:title>
 <dc:creator>Wan, Weiwei</dc:creator>
 <dc:creator>Harada, Kensuke</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper develops intelligent algorithms for robots to reorient objects.
Given the initial and goal poses of an object, the proposed algorithms plan a
sequence of robot poses and grasp configurations that reorient the object from
its initial pose to the goal. While the topic has been studied extensively in
previous work, this paper makes important improvements in grasp planning by
using over-segmented meshes, in data storage by using relational database, and
in regrasp planning by mixing real-world roadmaps. The improvements enable
robots to do robust regrasp planning using 10,000s of grasps and their
relationships in interactive time. The proposed algorithms are validated using
various objects and robots.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09402</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On dynamics of excitation in F-actin: automaton model</dc:title>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We represent a filamentous actin molecule as a graph of finite-state machines
(F-actin automaton). Each node in the graph takes three states --- resting,
excited, refractory. All nodes update their states simultaneously and by the
same rule, in discrete time steps. Two rules are considered: threshold rule ---
a resting node is excited if it has at least one excited neighbour and narrow
excitation interval rule --- a resting node is excited if it has exactly one
excited neighbour. We analyse distributions of transient periods and lengths of
limit cycles in evolution of F-actin automaton, propose mechanisms for
formation of limit cycles and evaluate density of information storage in
F-actin automata.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09404</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Confidentiality-Preserving Publish/Subscribe: A Survey</dc:title>
 <dc:creator>Onica, Emanuel</dc:creator>
 <dc:creator>Felber, Pascal</dc:creator>
 <dc:creator>Mercier, Hugues</dc:creator>
 <dc:creator>Rivi&#xe8;re, Etienne</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Publish/subscribe (pub/sub) is an attractive communication paradigm for
large-scale distributed applications running across multiple administrative
domains. Pub/sub allows event-based information dissemination based on
constraints on the nature of the data rather than on pre-established
communication channels. It is a natural fit for deployment in untrusted
environments such as public clouds linking applications across multiple sites.
However, pub/sub in untrusted environments lead to major confidentiality
concerns stemming from the content-centric nature of the communications. This
survey classifies and analyzes different approaches to confidentiality
preservation for pub/sub, from applications of trust and access control models
to novel encryption techniques. It provides an overview of the current
challenges posed by confidentiality concerns and points to future research
directions in this promising field.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09404</dc:identifier>
 <dc:identifier>ACM Computing Surveys, Volume 49, Issue 2, November 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2940296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09406</identifier>
 <datestamp>2017-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Machine Learning: A Survey and Taxonomy</dc:title>
 <dc:creator>Baltru&#x161;aitis, Tadas</dc:creator>
 <dc:creator>Ahuja, Chaitanya</dc:creator>
 <dc:creator>Morency, Louis-Philippe</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Our experience of the world is multimodal - we see objects, hear sounds, feel
texture, smell odors, and taste flavors. Modality refers to the way in which
something happens or is experienced and a research problem is characterized as
multimodal when it includes multiple such modalities. In order for Artificial
Intelligence to make progress in understanding the world around us, it needs to
be able to interpret such multimodal signals together. Multimodal machine
learning aims to build models that can process and relate information from
multiple modalities. It is a vibrant multi-disciplinary field of increasing
importance and with extraordinary potential. Instead of focusing on specific
multimodal applications, this paper surveys the recent advances in multimodal
machine learning itself and presents them in a common taxonomy. We go beyond
the typical early and late fusion categorization and identify broader
challenges that are faced by multimodal machine learning, namely:
representation, translation, alignment, fusion, and co-learning. This new
taxonomy will enable researchers to better understand the state of the field
and identify directions for future research.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09406</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09407</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Algorithm for Bayesian Nearest Neighbours</dc:title>
 <dc:creator>Nuti, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  K-Nearest Neighbours (k-NN) is a popular classification and regression
algorithm, yet one of its main limitations is the difficulty in choosing the
number of neighbours. We present a Bayesian algorithm to compute the posterior
probability distribution for k given a target point within a data-set,
efficiently and without the use of Markov Chain Monte Carlo (MCMC) methods or
simulation - alongside an exact solution for distributions within the
exponential family. The central idea is that data points around our target are
generated by the same probability distribution, extending outwards over the
appropriate, though unknown, number of neighbours. Once the data is projected
onto a distance metric of choice, we can transform the choice of k into a
change-point detection problem, for which there is an efficient solution: we
recursively compute the probability of the last change-point as we move towards
our target, and thus de facto compute the posterior probability distribution
over k. Applying this approach to both a classification and a regression UCI
data-sets, we compare favourably and, most importantly, by removing the need
for simulation, we are able to compute the posterior probability of k exactly
and rapidly. As an example, the computational time for the Ripley data-set is a
few milliseconds compared to a few hours when using a MCMC approach.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09411</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Critical Risks of Cascading Failures in Power Systems</dc:title>
 <dc:creator>Zhang, Hehong</dc:creator>
 <dc:creator>Zhai, Chao</dc:creator>
 <dc:creator>Xiao, Gaoxi</dc:creator>
 <dc:creator>Pan, Tso-Chien</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Potential critical risks of cascading failures in power systems can be
identified by exposing those critical electrical elements on which certain
initial disturbances may cause maximum disruption to power transmission
networks. In this work, we investigate cascading failures in power systems
described by the direct current (DC) power flow equations, while initial
disturbances take the form of altering admittance of elements. The disruption
is quantified with the remaining transmission power at the end of cascading
process. In particular, identifying the critical elements and the corresponding
initial disturbances causing the worst-case cascading blackout is formulated as
a dynamic optimization problem (DOP) in the framework of optimal control
theory, where the entire propagation process of cascading failures is put under
consideration. An Identifying Critical Risk Algorithm (ICRA) based on the
maximum principle is proposed to solve the DOP. Simulation results on the IEEE
9-Bus and the IEEE 14-Bus test systems are presented to demonstrate the
effectiveness of the algorithm.
</dc:description>
 <dc:description>Comment: 22 pages, 4 figures</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09411</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09412</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Optimize: Training Deep Neural Networks for Wireless
  Resource Management</dc:title>
 <dc:creator>Sun, Haoran</dc:creator>
 <dc:creator>Chen, Xiangyi</dc:creator>
 <dc:creator>Shi, Qingjiang</dc:creator>
 <dc:creator>Hong, Mingyi</dc:creator>
 <dc:creator>Fu, Xiao</dc:creator>
 <dc:creator>Sidiropoulos, Nicholas D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Electrical Engineering and Systems Science - Signal Processing</dc:subject>
 <dc:description>  For the past couple of decades, numerical optimization has played a central
role in addressing wireless resource management problems such as power control
and beamformer design. However, optimization algorithms often entail
considerable complexity, which creates a serious gap between theoretical
design/analysis and real-time processing. To address this challenge, we propose
a new learning-based approach. The key idea is to treat the input and output of
a resource allocation algorithm as an unknown non-linear mapping and use a deep
neural network (DNN) to approximate it. If the non-linear mapping can be
learned accurately by a DNN of moderate size, then resource allocation can be
done in almost real time -- since passing the input through a DNN only requires
a small number of simple operations.
  In this work, we address both the thereotical and practical aspects of
DNN-based algorithm approximation with applications to wireless resource
management. We first pin down a class of optimization algorithms that are
`learnable' in theory by a fully connected DNN. Then, we focus on DNN-based
approximation to a popular power allocation algorithm named WMMSE (Shi {\it et
al} 2011). We show that using a DNN to approximate WMMSE can be fairly accurate
-- the approximation error $\epsilon$ depends mildly [in the order of
$\log(1/\epsilon)$] on the numbers of neurons and layers of the DNN. On the
implementation side, we use extensive numerical simulations to demonstrate that
DNNs can achieve orders of magnitude speedup in computational time compared to
state-of-the-art power allocation algorithms based on optimization.
</dc:description>
 <dc:description>Comment: Submitted to TSP</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09413</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learnable Programming: Blocks and Beyond</dc:title>
 <dc:creator>Bau, David</dc:creator>
 <dc:creator>Gray, Jeff</dc:creator>
 <dc:creator>Kelleher, Caitlin</dc:creator>
 <dc:creator>Sheldon, Josh</dc:creator>
 <dc:creator>Turbak, Franklyn</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>K.3.2</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>D.1.7</dc:subject>
 <dc:subject>D.2.6</dc:subject>
 <dc:description>  Blocks-based programming has become the lingua franca for introductory
coding. Studies have found that experience with blocks-based programming can
help beginners learn more traditional text-based languages. We explore how
blocks environments improve learnability for novices by 1) favoring recognition
over recall, 2) reducing cognitive load, and 3) preventing errors. Increased
usability of blocks programming has led to widespread adoption within
introductory programming contexts across a range of ages. Ongoing work explores
further reducing barriers to programming, supporting novice programmers in
expanding their programming skills, and transitioning to textual programming.
New blocks frameworks are making it easier to access a variety of APIs through
blocks environments, opening the doors to a greater diversity of programming
domains and supporting greater experimentation for novices and professionals
alike.
</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09413</dc:identifier>
 <dc:identifier>Communications of the ACM, June 2017, pp. 72-80</dc:identifier>
 <dc:identifier>doi:10.1145/3015455</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1705.09415</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Belief Space Planning via T-LQG</dc:title>
 <dc:creator>Rafieisakhaei, Mohammadhussein</dc:creator>
 <dc:creator>Chakravorty, Suman</dc:creator>
 <dc:creator>Kumar, P. R.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the problem of planning under observation and motion uncertainty
for nonlinear robotics systems. Determining the optimal solution to this
problem, generally formulated as a Partially Observed Markov Decision Process
(POMDP), is computationally intractable. We propose a Trajectory-optimized
Linear Quadratic Gaussian (T-LQG) approach that leads to quantifiably
near-optimal solutions for the POMDP problem. We provide a novel &quot;separation
principle&quot; for the design of an optimal nominal open-loop trajectory followed
by an optimal feedback control law, which provides a near-optimal feedback
control policy for belief space planning problems involving a polynomial order
of calculations of minimum order.
</dc:description>
 <dc:description>Comment: 3 pages, 3 figures, In Robotics: Science and Systems (RSS) 2017
  Workshop of &quot;POMDPs in Robotics: State of The Art, Challenges, and
  Opportunities&quot;</dc:description>
 <dc:date>2017-05-25</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1705.09415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="124000" completeListSize="155308">2369777|125001</resumptionToken>
</ListRecords>
</OAI-PMH>
