<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:24:49Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|117001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06695</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Retrofitting-based Supplementary Controller Design for Enhancing
  Damping Performance of Wind Power Systems</dc:title>
 <dc:creator>Sadamoto, Tomonori</dc:creator>
 <dc:creator>Chakrabortty, Aranya</dc:creator>
 <dc:creator>Ishizaki, Takayuki</dc:creator>
 <dc:creator>Imura, Jun-ichi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we address the growing concerns of wind power integration from
the perspective of power system dynamics and stability. We propose a new
retrofit control technique where an additional controller is designed at the
doubly-fed induction generator site inside the wind power plant. This
controller cancels the adverse impacts of the power flow from the wind side to
the grid side on the dynamics of the overall power system. The main advantage
of this controller is that it can be implemented by feeding back only the wind
states and wind bus voltage without depending on any of the other synchronous
machines in the rest of the system. Through simulations of a 4-machine Kundur
power system model we show that the retrofit can efficiently enhance the
damping performance of the system variable despite very high values of wind
penetration.
</dc:description>
 <dc:description>Comment: in Proc. American Control Conference 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06696</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Representation per Word - Does it make Sense for Composition?</dc:title>
 <dc:creator>Kober, Thomas</dc:creator>
 <dc:creator>Weeds, Julie</dc:creator>
 <dc:creator>Wilkie, John</dc:creator>
 <dc:creator>Reffin, Jeremy</dc:creator>
 <dc:creator>Weir, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper, we investigate whether an a priori disambiguation of word
senses is strictly necessary or whether the meaning of a word in context can be
disambiguated through composition alone. We evaluate the performance of
off-the-shelf single-vector and multi-sense vector models on a benchmark phrase
similarity task and a novel task for word-sense discrimination. We find that
single-sense vector models perform as well or better than multi-sense vector
models despite arguably less clean elementary representations. Our findings
furthermore show that simple composition functions such as pointwise addition
are able to recover sense specific information from a single-sense vector model
remarkably well.
</dc:description>
 <dc:description>Comment: to appear at the EACL 2017 workshop on Sense, Concept and Entity
  Representations and their Applications</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06697</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Short-Term Voltage Stability Index and case studies</dc:title>
 <dc:creator>Zhao, Wenlu</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The short-term voltage stability (SVS) problem in large-scale receiving-end
power systems is serious due to the increasing load demand, the increasing use
of electronically controlled loads and so on. Some serious blackouts are
considered to be related to short-term voltage instability. In China, the East
China Grid (ECG) is especially vulnerable to short-term voltage instability due
the its increasing dependence on power injection from external grids through
HVDC links. However, the SVS criteria used in practice are all qualitative and
the SVS indices proposed in previous researches are mostly based on the
qualitative SVS criteria. So a Short-Term Voltage Stability Index (SVSI), which
is continuous, quantitative and multi-dimensional, is proposed in this paper.
The SVSI consists of three components, which reflects the transient voltage
restoration, the transient voltage oscillation and the steady-state recovery
ability of the voltage signal respectively after the contingency has been
cleared. The theoretical backgrounds and affected factors of these three
components of SVSI are analyzed, together with some feasible applications. The
verification of the validity of SVSI are tested through more 10,000 cases based
on ECG. Additionally, a simple case of selecting candidate locations to install
dynamic var using SVSI is presented to show its feasibility to solve the
optimization problem for dynamic var allocation.
</dc:description>
 <dc:description>Comment: 7 pages, 13 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06698</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing the longest common prefix of a context-free language in
  polynomial time</dc:title>
 <dc:creator>Luttenberger, Michael</dc:creator>
 <dc:creator>Palenta, Raphaela</dc:creator>
 <dc:creator>Seidl, Helmut</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  We present two structural results concerning longest common prefixes of
non-empty languages. First, we show that the longest common prefix of the
language generated by a context-free grammar of size $N$ equals the longest
common prefix of the same grammar where the heights of the derivation trees are
bounded by $4N$. Second, we show that each nonempty language $L$ has a
representative subset of at most three elements which behaves like $L$ w.r.t.
the longest common prefix as well as w.r.t. longest common prefixes of $L$
after unions or concatenations with arbitrary other languages. From that, we
conclude that the longest common prefix, and thus the longest common suffix, of
a context-free language can be computed in polynomial time.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2018-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06700</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Task-driven Visual Saliency and Attention-based Visual Question
  Answering</dc:title>
 <dc:creator>Lin, Yuetan</dc:creator>
 <dc:creator>Pang, Zhangyang</dc:creator>
 <dc:creator>Wang, Donghui</dc:creator>
 <dc:creator>Zhuang, Yueting</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Visual question answering (VQA) has witnessed great progress since May, 2015
as a classic problem unifying visual and textual data into a system. Many
enlightening VQA works explore deep into the image and question encodings and
fusing methods, of which attention is the most effective and infusive
mechanism. Current attention based methods focus on adequate fusion of visual
and textual features, but lack the attention to where people focus to ask
questions about the image. Traditional attention based methods attach a single
value to the feature at each spatial location, which losses many useful
information. To remedy these problems, we propose a general method to perform
saliency-like pre-selection on overlapped region features by the interrelation
of bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication
based attention method to capture more competent correlation information
between visual and textual features. We conduct experiments on the large-scale
COCO-VQA dataset and analyze the effectiveness of our model demonstrated by
strong empirical results.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06703</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data Distillation for Controlling Specificity in Dialogue Generation</dc:title>
 <dc:creator>Li, Jiwei</dc:creator>
 <dc:creator>Monroe, Will</dc:creator>
 <dc:creator>Jurafsky, Dan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  People speak at different levels of specificity in different situations.
Depending on their knowledge, interlocutors, mood, etc.} A conversational agent
should have this ability and know when to be specific and when to be general.
We propose an approach that gives a neural network--based conversational agent
this ability. Our approach involves alternating between \emph{data
distillation} and model training : removing training examples that are closest
to the responses most commonly produced by the model trained from the last
round and then retrain the model on the remaining dataset. Dialogue generation
models trained with different degrees of data distillation manifest different
levels of specificity.
  We then train a reinforcement learning system for selecting among this pool
of generation models, to choose the best level of specificity for a given
input. Compared to the original generative model trained without distillation,
the proposed system is capable of generating more interesting and
higher-quality responses, in addition to appropriately adjusting specificity
depending on the context.
  Our research constitutes a specific case of a broader approach involving
training multiple subsystems from a single dataset distinguished by differences
in a specific property one wishes to model. We show that from such a set of
subsystems, one can use reinforcement learning to build a system that tailors
its output to different input contexts at test time.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06704</identifier>
 <datestamp>2017-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Portability Analysis for Axiomatic Memory Models. PORTHOS: One Tool for
  all Models</dc:title>
 <dc:creator>Ponce-de-Le&#xf3;n, Hern&#xe1;n</dc:creator>
 <dc:creator>Furbach, Florian</dc:creator>
 <dc:creator>Heljanko, Keijo</dc:creator>
 <dc:creator>Meyer, Roland</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present Porthos, the first tool that discovers porting bugs in
performance-critical code. Porthos takes as input a program and the memory
models of the source architecture for which the program has been developed and
the target model to which it is ported. If the code is not portable, Porthos
finds a bug in the form of an unexpected execution - an execution that is
consistent with the target but inconsistent with the source memory model.
Technically, Porthos implements a bounded model checking method that reduces
the portability analysis problem to satisfiability modulo theories (SMT). There
are two main problems in the reduction that we present novel and efficient
solutions for. First, the formulation of the portability problem contains a
quantifier alternation (consistent + inconsistent). We introduce a formula that
encodes both in a single existential query. Second, the supported memory models
(e.g., Power) contain recursive definitions. We compute the required least
fixed point semantics for recursion (a problem that was left open in [47])
efficiently in SMT. Finally we present the first experimental analysis of
portability from TSO to Power.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-04-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06709</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fine-Grained Entity Type Classification by Jointly Learning
  Representations and Label Embeddings</dc:title>
 <dc:creator>Abhishek</dc:creator>
 <dc:creator>Anand, Ashish</dc:creator>
 <dc:creator>Awekar, Amit</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Fine-grained entity type classification (FETC) is the task of classifying an
entity mention to a broad set of types. Distant supervision paradigm is
extensively used to generate training data for this task. However, generated
training data assigns same set of labels to every mention of an entity without
considering its local context. Existing FETC systems have two major drawbacks:
assuming training data to be noise free and use of hand crafted features. Our
work overcomes both drawbacks. We propose a neural network model that jointly
learns entity mentions and their context representation to eliminate use of
hand crafted features. Our model treats training data as noisy and uses
non-parametric variant of hinge loss function. Experiments show that the
proposed model outperforms previous state-of-the-art methods on two publicly
available datasets, namely FIGER (GOLD) and BBN with an average relative
improvement of 2.69% in micro-F1 score. Knowledge learnt by our model on one
dataset can be transferred to other datasets while using same model or other
FETC systems. These approaches of transferring knowledge further improve the
performance of respective models.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, accepted at EACL 2017 conference</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06712</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensembles of Randomized Time Series Shapelets Provide Improved Accuracy
  while Reducing Computational Costs</dc:title>
 <dc:creator>Raza, Atif</dc:creator>
 <dc:creator>Kramer, Stefan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Shapelets are discriminative time series subsequences that allow generation
of interpretable classification models, which provide faster and generally
better classification than the nearest neighbor approach. However, the shapelet
discovery process requires the evaluation of all possible subsequences of all
time series in the training set, making it extremely computation intensive.
Consequently, shapelet discovery for large time series datasets quickly becomes
intractable. A number of improvements have been proposed to reduce the training
time. These techniques use approximation or discretization and often lead to
reduced classification accuracy compared to the exact method.
  We are proposing the use of ensembles of shapelet-based classifiers obtained
using random sampling of the shapelet candidates. Using random sampling reduces
the number of evaluated candidates and consequently the required computational
cost, while the classification accuracy of the resulting models is also not
significantly different than that of the exact algorithm. The combination of
randomized classifiers rectifies the inaccuracies of individual models because
of the diversity of the solutions. Based on the experiments performed, it is
shown that the proposed approach of using an ensemble of inexpensive
classifiers provides better classification accuracy compared to the exact
method at a significantly lesser computational cost.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06715</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LED-it-GO: Leaking (a lot of) Data from Air-Gapped Computers via the
  (small) Hard Drive LED</dc:title>
 <dc:creator>Guri, Mordechai</dc:creator>
 <dc:creator>Zadov, Boris</dc:creator>
 <dc:creator>Atias, Eran</dc:creator>
 <dc:creator>Elovici, Yuval</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this paper we present a method which allows attackers to covertly leak
data from isolated, air-gapped computers. Our method utilizes the hard disk
drive (HDD) activity LED which exists in most of today's desktop PCs, laptops
and servers. We show that a malware can indirectly control the HDD LED, turning
it on and off rapidly (up to 5800 blinks per second) - a rate that exceeds the
visual perception capabilities of humans. Sensitive information can be encoded
and leaked over the LED signals, which can then be received remotely by
different kinds of cameras and light sensors. Compared to other LED methods,
our method is unique, because it is also covert - the HDD activity LED
routinely flickers frequently, and therefore the user may not be suspicious to
changes in its activity. We discuss attack scenarios and present the necessary
technical background regarding the HDD LED and its hardware control. We also
present various data modulation methods and describe the implementation of a
user-level malware, that doesn't require a kernel component. During the
evaluation, we examine the physical characteristics of different colored HDD
LEDs (red, blue, and white) and tested different types of receivers: remote
cameras, extreme cameras, security cameras, smartphone cameras, drone cameras,
and optical sensors. Finally, we discuss hardware and software countermeasures
for such a threat. Our experiment shows that sensitive data can be successfully
leaked from air-gapped computers via the HDD LED at a maximum bit rate of 4000
bits per second, depending on the type of receiver and its distance from the
transmitter. Notably, this speed is 10 times faster than the existing optical
covert channels for air-gapped computers. These rates allow fast exfiltration
of encryption keys, keystroke logging, and text and binary files.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06722</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Reconstruction of Temples in the Special Region of Yogyakarta By
  Using Close-Range Photogrammetry</dc:title>
 <dc:creator>Utomo, Adityo Priyandito</dc:creator>
 <dc:creator>Wibowo, Canggih Puspo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object reconstruction is one of the main problems in cultural heritage
preservation. This problem is due to lack of data in documentation. Thus in
this research we presented a method of 3D reconstruction using close-range
photogrammetry. We collected 1319 photos from five temples in Yogyakarta. Using
A-KAZE algorithm, keypoints of each image were obtained. Then we employed LIOP
to create feature descriptor from it. After performing feature matching, L1RA
was utilized to create sparse point clouds. In order to generate the geometry
shape, MVS was used. Finally, FSSR and Large Scale Texturing were employed to
deal with the surface and texture of the object. The quality of the
reconstructed 3D model was measured by comparing the 3D images of the model
with the original photos utilizing SSIM. The results showed that in terms of
quality, our method was on par with other commercial method such as
PhotoModeler and PhotoScan.
</dc:description>
 <dc:description>Comment: Semnasteknomedia 2017, 5 pages</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06723</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact linear programs for 2SAT</dc:title>
 <dc:creator>Avis, David</dc:creator>
 <dc:creator>Tiwary, Hans Raj</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  For each integer $n$ we present an explicit formulation of a compact linear
program, with $O(n^3)$ variables and constraints, which determines the
satisfiability of any 2SAT formula with $n$ boolean variables by a single
linear optimization. This contrasts with the fact that the natural polytope for
this problem, formed from the convex hull of all satisfiable formulas and their
satisfying assignments, has superpolynomial extension complexity. Our
formulation is based on multicommodity flows. We also discuss connections of
these results to the stable matching problem.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06724</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A new cosine series antialiasing function and its application to
  aliasing-free glottal source models for speech and singing synthesis</dc:title>
 <dc:creator>Kawahara, Hideki</dc:creator>
 <dc:creator>Sakakibara, Ken-Ichi</dc:creator>
 <dc:creator>Banno, Hideki</dc:creator>
 <dc:creator>Morise, Masanori</dc:creator>
 <dc:creator>Toda, Tomoki</dc:creator>
 <dc:creator>Irino, Toshio</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We formulated and implemented a procedure to generate aliasing-free
excitation source signals. It uses a new antialiasing filter in the continuous
time domain followed by an IIR digital filter for response equalization. We
introduced a cosine-series-based general design procedure for the new
antialiasing function. We applied this new procedure to implement the
antialiased Fujisaki-Ljungqvist model. We also applied it to revise our
previous implementation of the antialiased Fant-Liljencrants model. A
combination of these signals and a lattice implementation of the time varying
vocal tract model provides a reliable and flexible basis to test fo extractors
and source aperiodicity analysis methods. MATLAB implementations of these
antialiased excitation source models are available as part of our open source
tools for speech science.
</dc:description>
 <dc:description>Comment: Submitted to Interspeech 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06724</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06728</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Network-Based Block Up-sampling for Intra Frame
  Coding</dc:title>
 <dc:creator>Li, Yue</dc:creator>
 <dc:creator>Liu, Dong</dc:creator>
 <dc:creator>Li, Houqiang</dc:creator>
 <dc:creator>Li, Li</dc:creator>
 <dc:creator>Wu, Feng</dc:creator>
 <dc:creator>Zhang, Hong</dc:creator>
 <dc:creator>Yang, Haitao</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Inspired by the recent advances of image super-resolution using convolutional
neural network (CNN), we propose a CNN-based block up-sampling scheme for intra
frame coding. A block can be down-sampled before being compressed by normal
intra coding, and then up-sampled to its original resolution. Different from
previous studies on down/up-sampling-based coding, the up-sampling methods in
our scheme have been designed by training CNN instead of hand-crafted. We
explore a new CNN structure for up-sampling, which features deconvolution of
feature maps, multi-scale fusion, and residue learning, making the network both
compact and efficient. We also design different networks for the up-sampling of
luma and chroma components, respectively, where the chroma up-sampling CNN
utilizes the luma information to boost its performance. In addition, we design
a two-stage up-sampling process, the first stage being within the
block-by-block coding loop, and the second stage being performed on the entire
frame, so as to refine block boundaries. We also empirically study how to set
the coding parameters of down-sampled blocks for pursuing the frame-level
rate-distortion optimization. Our proposed scheme is implemented into the High
Efficiency Video Coding (HEVC) reference software, and a comprehensive set of
experiments have been performed to evaluate our methods. Experimental results
show that our scheme achieves significant bits saving compared with HEVC anchor
especially at low bit rates, leading to on average 5.5% BD-rate reduction on
common test sequences and on average 9.0% BD-rate reduction on ultra high
definition (UHD) test sequences.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06728</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2017.2727682</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06733</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving a Strong Neural Parser with Conjunction-Specific Features</dc:title>
 <dc:creator>Ficler, Jessica</dc:creator>
 <dc:creator>Goldberg, Yoav</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  While dependency parsers reach very high overall accuracy, some dependency
relations are much harder than others. In particular, dependency parsers
perform poorly in coordination construction (i.e., correctly attaching the
&quot;conj&quot; relation). We extend a state-of-the-art dependency parser with
conjunction-specific features, focusing on the similarity between the conjuncts
head words. Training the extended parser yields an improvement in &quot;conj&quot;
attachment as well as in overall dependency parsing accuracy on the Stanford
dependency conversion of the Penn TreeBank.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06733</dc:identifier>
 <dc:identifier>EACL 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06740</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Chinese SRL with Heterogeneous Annotations</dc:title>
 <dc:creator>Xia, Qiaolin</dc:creator>
 <dc:creator>Chang, Baobao</dc:creator>
 <dc:creator>Sui, Zhifang</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Previous studies on Chinese semantic role labeling (SRL) have concentrated on
single semantically annotated corpus. But the training data of single corpus is
often limited. Meanwhile, there usually exists other semantically annotated
corpora for Chinese SRL scattered across different annotation frameworks. Data
sparsity remains a bottleneck. This situation calls for larger training
datasets, or effective approaches which can take advantage of highly
heterogeneous data. In these papers, we focus mainly on the latter, that is, to
improve Chinese SRL by using heterogeneous corpora together. We propose a novel
progressive learning model which augments the Progressive Neural Network with
Gated Recurrent Adapters. The model can accommodate heterogeneous inputs and
effectively transfer knowledge between them. We also release a new corpus,
Chinese SemBank, for Chinese SRL. Experiments on CPB 1.0 show that ours model
outperforms state-of-the-art methods.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial error in
  equation 10</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06756</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risk-based Triggering of Bio-inspired Self-Preservation to Protect
  Robots from Threats</dc:title>
 <dc:creator>Chiu, Sing-Kai</dc:creator>
 <dc:creator>Araiza-Illan, Dejanira</dc:creator>
 <dc:creator>Eder, Kerstin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Safety in autonomous systems has been mostly studied from a human-centered
perspective. Besides the loads they may carry, autonomous systems are also
valuable property, and self-preservation mechanisms are needed to protect them
in the presence of external threats, including malicious robots and
antagonistic humans. We present a biologically inspired risk-based triggering
mechanism to initiate self-preservation strategies. This mechanism considers
environmental and internal system factors to measure the overall risk at any
moment in time, to decide whether behaviours such as fleeing or hiding are
necessary, or whether the system should continue on its task. We integrated our
risk-based triggering mechanism into a delivery rover that is being attacked by
a drone and evaluated its effectiveness through systematic testing in a
simulated environment in Robot Operating System (ROS) and Gazebo, with a
variety of different randomly generated conditions. We compared the use of the
triggering mechanism and different configurations of self-preservation
behaviours to not having any of these. Our results show that triggering
self-preservation increases the distance between the drone and the rover for
many of these configurations, and, in some instances, the drone does not catch
up with the rover. Our study demonstrates the benefits of embedding risk
awareness and self-preservation into autonomous systems to increase their
robustness, and the value of using bio-inspired engineering to find solutions
in this area.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06756</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06760</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory Matching Networks for Genomic Sequence Classification</dc:title>
 <dc:creator>Lanchantin, Jack</dc:creator>
 <dc:creator>Singh, Ritambhara</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When analyzing the genome, researchers have discovered that proteins bind to
DNA based on certain patterns of the DNA sequence known as &quot;motifs&quot;. However,
it is difficult to manually construct motifs due to their complexity. Recently,
externally learned memory models have proven to be effective methods for
reasoning over inputs and supporting sets. In this work, we present memory
matching networks (MMN) for classifying DNA sequences as protein binding sites.
Our model learns a memory bank of encoded motifs, which are dynamic memory
modules, and then matches a new test sequence to each of the motifs to classify
the sequence as a binding or nonbinding site.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06762</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Style Transfer Generative Adversarial Networks: Learning to Play Chess
  Differently</dc:title>
 <dc:creator>Chidambaram, Muthuraman</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The idea of style transfer has largely only been explored in image-based
tasks, which we attribute in part to the specific nature of loss functions used
for style transfer. We propose a general formulation of style transfer as an
extension of generative adversarial networks, by using a discriminator to
regularize a generator with an otherwise separate loss function. We apply our
approach to the task of learning to play chess in the style of a specific
player, and present empirical evidence for the viability of our approach.
</dc:description>
 <dc:description>Comment: style transfer, Generative Adversarial Networks</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06762</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06763</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepCloak: Masking Deep Neural Network Models for Robustness Against
  Adversarial Samples</dc:title>
 <dc:creator>Gao, Ji</dc:creator>
 <dc:creator>Wang, Beilun</dc:creator>
 <dc:creator>Lin, Zeming</dc:creator>
 <dc:creator>Xu, Weilin</dc:creator>
 <dc:creator>Qi, Yanjun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recent studies have shown that deep neural networks (DNN) are vulnerable to
adversarial samples: maliciously-perturbed samples crafted to yield incorrect
model outputs. Such attacks can severely undermine DNN systems, particularly in
security-sensitive settings. It was observed that an adversary could easily
generate adversarial samples by making a small perturbation on irrelevant
feature dimensions that are unnecessary for the current classification task. To
overcome this problem, we introduce a defensive mechanism called DeepCloak. By
identifying and removing unnecessary features in a DNN model, DeepCloak limits
the capacity an attacker can use generating adversarial samples and therefore
increase the robustness against such inputs. Comparing with other defensive
approaches, DeepCloak is easy to implement and computationally efficient.
Experimental results show that DeepCloak can increase the performance of
state-of-the-art DNN models against adversarial samples.
</dc:description>
 <dc:description>Comment: adversarial samples, deep neural network</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-04-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06763</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06764</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loophole: Timing Attacks on Shared Event Loops in Chrome</dc:title>
 <dc:creator>Vila, Pepe</dc:creator>
 <dc:creator>K&#xf6;pf, Boris</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Event-driven programming (EDP) is the prevalent paradigm for graphical user
interfaces, web clients, and it is rapidly gaining importance for server-side
and network programming. Central components of EDP are {\em event loops}, which
act as FIFO queues that are used by processes to store and dispatch messages
received from other processes.
  In this paper we demonstrate that shared event loops are vulnerable to
side-channel attacks, where a spy process monitors the loop usage pattern of
other processes by enqueueing events and measuring the time it takes for them
to be dispatched. Specifically, we exhibit attacks against the two central
event loops in Google's Chrome web browser: that of the I/O thread of the host
process, which multiplexes all network events and user actions, and that of the
main thread of the renderer processes, which handles rendering and Javascript
tasks.
  For each of these loops, we show how the usage pattern can be monitored with
high resolution and low overhead, and how this can be abused for malicious
purposes, such as web page identification, user behavior detection, and covert
communication.
</dc:description>
 <dc:description>Comment: Original publication in the Proceedings of the 26th Annual USENIX
  Security Symposium (USENIX Security 2017).
  https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/vila</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06767</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MomentsNet: a simple learning-free method for binary image recognition</dc:title>
 <dc:creator>Wu, Jiasong</dc:creator>
 <dc:creator>Qiu, Shijie</dc:creator>
 <dc:creator>Kong, Youyong</dc:creator>
 <dc:creator>Chen, Yang</dc:creator>
 <dc:creator>Senhadji, Lotfi</dc:creator>
 <dc:creator>Shu, Huazhong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a new simple and learning-free deep learning
network named MomentsNet, whose convolution layer, nonlinear processing layer
and pooling layer are constructed by Moments kernels, binary hashing and
block-wise histogram, respectively. Twelve typical moments (including
geometrical moment, Zernike moment, Tchebichef moment, etc.) are used to
construct the MomentsNet whose recognition performance for binary image is
studied. The results reveal that MomentsNet has better recognition performance
than its corresponding moments in almost all cases and ZernikeNet achieves the
best recognition performance among MomentsNet constructed by twelve moments.
ZernikeNet also shows better recognition performance on binary image database
than that of PCANet, which is a learning-based deep learning network.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06770</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of a space varying coefficient of a linear viscoelastic
  string of Maxwell-Boltzman type</dc:title>
 <dc:creator>Pandolfi, Luciano</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>45K05, 45Q05, 93B05</dc:subject>
 <dc:description>  In this paper we solve the problem of the identification of a coefficient
which appears in the model of a distributed system with persistent memory
encountered in linear viscoelasticity (and in diffusion processes with memory).
The additional data used in the identification are subsumed in the input output
map from the deformation to the traction on the boundary. We extend a dynamical
approach to identification introduced by Belishev in the case of purely elastic
(memoryless) bodies and based on a special equation due to Blagoveshchenskii.
So, in particular, we extend Blagoveshchenskii equation to our class of systems
with persistent memory.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06772</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient CSMA using Regional Free Energy Approximations</dc:title>
 <dc:creator>Swamy, Peruru Subrahmanya</dc:creator>
 <dc:creator>Bellam, Venkata Pavan Kumar</dc:creator>
 <dc:creator>Ganti, Radha Krishna</dc:creator>
 <dc:creator>Jagannathan, Krishna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  CSMA (Carrier Sense Multiple Access) algorithms based on Gibbs sampling can
achieve throughput optimality if certain parameters called the fugacities are
appropriately chosen. However, the problem of computing these fugacities is
NP-hard. In this work, we derive estimates of the fugacities by using a
framework called the regional free energy approximations. In particular, we
derive explicit expressions for approximate fugacities corresponding to any
feasible service rate vector. We further prove that our approximate fugacities
are exact for the class of chordal graphs. A distinguishing feature of our work
is that the regional approximations that we propose are tailored to conflict
graphs with small cycles, which is a typical characteristic of wireless
networks. Numerical results indicate that the fugacities obtained by the
proposed method are quite accurate and significantly outperform the existing
Bethe approximation based techniques.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Mobile Computing</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06776</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Inference by Stochastic Complexity</dc:title>
 <dc:creator>Budhathoki, Kailash</dc:creator>
 <dc:creator>Vreeken, Jilles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The algorithmic Markov condition states that the most likely causal direction
between two random variables X and Y can be identified as that direction with
the lowest Kolmogorov complexity. Due to the halting problem, however, this
notion is not computable.
  We hence propose to do causal inference by stochastic complexity. That is, we
propose to approximate Kolmogorov complexity via the Minimum Description Length
(MDL) principle, using a score that is mini-max optimal with regard to the
model class under consideration. This means that even in an adversarial
setting, such as when the true distribution is not in this class, we still
obtain the optimal encoding for the data relative to the class.
  We instantiate this framework, which we call CISC, for pairs of univariate
discrete variables, using the class of multinomial distributions. Experiments
show that CISC is highly accurate on synthetic, benchmark, as well as
real-world data, outperforming the state of the art by a margin, and scales
extremely well with regard to sample and domain sizes.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06777</identifier>
 <datestamp>2017-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dialectometric analysis of language variation in Twitter</dc:title>
 <dc:creator>Donoso, Gonzalo</dc:creator>
 <dc:creator>Sanchez, David</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In the last few years, microblogging platforms such as Twitter have given
rise to a deluge of textual data that can be used for the analysis of informal
communication between millions of individuals. In this work, we propose an
information-theoretic approach to geographic language variation using a corpus
based on Twitter. We test our models with tens of concepts and their associated
keywords detected in Spanish tweets geolocated in Spain. We employ
dialectometric measures (cosine similarity and Jensen-Shannon divergence) to
quantify the linguistic distance on the lexical level between cells created in
a uniform grid over the map. This can be done for a single concept or in the
general case taking into account an average of the considered variants. The
latter permits an analysis of the dialects that naturally emerge from the data.
Interestingly, our results reveal the existence of two dialect macrovarieties.
The first group includes a region-specific speech spoken in small towns and
rural areas whereas the second cluster encompasses cities that tend to use a
more uniform variety. Since the results obtained with the two different metrics
qualitatively agree, our work suggests that social media corpora can be
efficiently used for dialectometric analyses.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, 1 table. Accepted to VarDial 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06777</dc:identifier>
 <dc:identifier>Proceedings of the Fourth Workshop on NLP for Similar Languages,
  Varieties and Dialects (VarDial), pp. 16-25, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06780</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Spectrum Reuse and Power Control for Multi-Sharing
  Device-to-Device Communication</dc:title>
 <dc:creator>Chen, Kuo-Yi</dc:creator>
 <dc:creator>Kao, Jung-Chun</dc:creator>
 <dc:creator>Ciou, Si-An</dc:creator>
 <dc:creator>Lin, Shih-Han</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Compared to current mobile networks, next-generation mobile networks are
expected to support higher numbers of simultaneously connected devices and to
achieve higher system spectrum efficiency and lower power consumption. To
achieve these goals, we study the multi-sharing device-to-device (D2D)
communication, which allows any cellular user equipment to share its radio
resource with multiple D2D devices. We jointly consider resource block reuse
and power control and then develop the MISS algorithm. Simulation results show
that MISS performs very well in terms of transmission power consumption, system
throughput, and the number of permitted D2D devices.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06781</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gelfand numbers related to structured sparsity and Besov space
  embeddings with small mixed smoothness</dc:title>
 <dc:creator>Dirksen, Sjoerd</dc:creator>
 <dc:creator>Ullrich, Tino</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We consider the problem of determining the asymptotic order of the Gelfand
numbers of mixed-(quasi-)norm embeddings $\ell^b_p(\ell^d_q) \hookrightarrow
\ell^b_r(\ell^d_u)$ given that $p \leq r$ and $q \leq u$, with emphasis on
cases with $p\leq 1$ and/or $q\leq 1$. These cases turn out to be related to
structured sparsity. We obtain sharp bounds in a number of interesting
parameter constellations. Our new matching bounds for the Gelfand numbers of
the embeddings of $\ell_1^b(\ell_2^d)$ and $\ell_2^b(\ell_1^d)$ into
$\ell_2^b(\ell_2^d)$ imply optimality assertions for the recovery of
block-sparse and sparse-in-levels vectors, respectively. In addition, we apply
the sharp estimates for $\ell^b_p(\ell^d_q)$-spaces to obtain new two-sided
estimates for the Gelfand numbers of multivariate Besov space embeddings in
regimes of small mixed smoothness. It turns out that in some particular cases
these estimates show the same asymptotic behaviour as in the univariate
situation. In the remaining cases they differ at most by a $\log\log$ factor
from the univariate bound.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06781</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06794</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tackling Error Propagation through Reinforcement Learning: A Case of
  Greedy Dependency Parsing</dc:title>
 <dc:creator>Le, Minh</dc:creator>
 <dc:creator>Fokkens, Antske</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Error propagation is a common problem in NLP. Reinforcement learning explores
erroneous states during training and can therefore be more robust when mistakes
are made early in a process. In this paper, we apply reinforcement learning to
greedy dependency parsing which is known to suffer from error propagation.
Reinforcement learning improves accuracy of both labeled and unlabeled
dependencies of the Stanford Neural Dependency Parser, a high performance
greedy parser, while maintaining its efficiency. We investigate the portion of
errors which are the result of error propagation and confirm that reinforcement
learning reduces the occurrence of error propagation.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06799</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosted Multiple Kernel Learning for First-Person Activity Recognition</dc:title>
 <dc:creator>Ozkan, Fatih</dc:creator>
 <dc:creator>Arabaci, Mehmet Ali</dc:creator>
 <dc:creator>Surer, Elif</dc:creator>
 <dc:creator>Temizel, Alptekin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Activity recognition from first-person (ego-centric) videos has recently
gained attention due to the increasing ubiquity of the wearable cameras. There
has been a surge of efforts adapting existing feature descriptors and designing
new descriptors for the first-person videos. An effective activity recognition
system requires selection and use of complementary features and appropriate
kernels for each feature. In this study, we propose a data-driven framework for
first-person activity recognition which effectively selects and combines
features and their respective kernels during the training. Our experimental
results show that use of Multiple Kernel Learning (MKL) and Boosted MKL in
first-person activity recognition problem exhibits improved results in
comparison to the state-of-the-art. In addition, these techniques enable the
expansion of the framework with new features in an efficient and convenient
way.
</dc:description>
 <dc:description>Comment: First published in the Proceedings of the 25th European Signal
  Processing Conference (EUSIPCO-2017) in 2017, published by EURASIP</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06803</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinventing NetFlow for OpenFlow Software-Defined Networks</dc:title>
 <dc:creator>Su&#xe1;rez-Varela, Jos&#xe9;</dc:creator>
 <dc:creator>Barlet-Ros, Pere</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Obtaining flow-level measurements, similar to those provided by
Netflow/IPFIX, with OpenFlow is challenging as it requires the installation of
an entry per flow in the flow tables. This approach does not scale well with
the number of concurrent flows in the traffic as the number of entries in the
flow tables is limited and small. Flow monitoring rules may also interfere with
forwarding or other rules already present in the switches, which are often
defined at different granularities than the flow level. In this paper, we
present a transparent and scalable flow-based monitoring solution that is fully
compatible with current off-the-shelf OpenFlow switches. As in NetFlow/IPFIX,
we aggregate packets into flows directly in the switches and asynchronously
send traffic reports to an external collector. In order to reduce the overhead,
we implement three different traffic sampling methods depending on the OpenFlow
features available in the switch. We developed our complete flow monitoring
solution within OpenDaylight and evaluated its accuracy in a testbed with Open
vSwitch. Our experimental results using real-world traffic traces show that the
proposed sampling methods are accurate and can effectively reduce the resource
requirements of flow measurements in OpenFlow.
</dc:description>
 <dc:description>Comment: 20 pages, 12 figures, 1 table</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06805</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedded real-time monitoring using SystemC in IMA network</dc:title>
 <dc:creator>Aloui, Zied</dc:creator>
 <dc:creator>Ahamada, Nawfal</dc:creator>
 <dc:creator>Denoulet, Julien</dc:creator>
 <dc:creator>Pierre, Francine</dc:creator>
 <dc:creator>Rayrole, Martin</dc:creator>
 <dc:creator>Gatti, Marc</dc:creator>
 <dc:creator>Granado, Bertrand</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Avionics is one kind of domain where prevention prevails. Nonetheless fails
occur. Sometimes due to pilot misreacting, flooded in information. Sometimes
information itself would be better verified than trusted. To avoid some kind of
failure, it has been thought to add,in midst of the ARINC664 aircraft data
network, a new kind of monitoring.
</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06805</dc:identifier>
 <dc:identifier>SAE 2016 Aerospace Systems and Technology Conference, Sep 2016,
  Hartford, United States. pp.1-4, 2016, SAE 2016 Aerospace Systems and
  Technology Conference</dc:identifier>
 <dc:identifier>doi:10.4271/2016-01-2069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06806</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introducing Context Awareness in Unmodified, Context-unaware Software</dc:title>
 <dc:creator>Raab, Markus</dc:creator>
 <dc:creator>Barany, Gerg&#xf6;</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Software tends to be highly configurable, but most applications are hardly
context aware. For example, a web browser provides many settings to configure
printers and proxies, but nevertheless it is unable to dynamically adapt to a
new workplace. In this paper we aim to empirically demonstrate that by dynamic
and automatic reconfiguration of unmodified software we can systematically
introduce context awareness. In 16 real-world applications comprising 50
million lines of code we empirically investigate which of the 2,683 run-time
configuration accesses (1) already take context into account, or (2) can be
manipulated at run-time to do so. The results show that context awareness can
be exploited far beyond the developers' initial intentions. Our tool Elektra
dynamically intercepts the run-time configuration accesses and replaces them
with a context aware implementation. Users only need to specify contexts and
add context sensors to make use of this potential.
</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06810</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pricing average price advertisement options when underlying spot market
  prices are discontinuous</dc:title>
 <dc:creator>Chen, Bowei</dc:creator>
 <dc:creator>Kankanhalli, Mohan S.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Advertisement (ad) options have been recently studied as a novel guaranteed
delivery (GD) system in online advertising. In essence, an ad option is a
contract that gives an advertiser a right but not obligation to enter into
transactions to purchase ad inventories such as page views or link clicks from
a specific slot at one or multiple pre-specified prices in a specific future
period. Compared to guaranteed contracts, the advertiser pays a lower upfront
fee but can have greater flexibility and more control in advertising. So far ad
option studies have been restricted to the situations where the option payoff
is determined by the underlying auction payment price at a specific time point
and the price evolution over time is assumed to be continuous. The former leads
to a biased option payoff calculation and the latter is invalid empirically for
many ad slots. This paper discusses a new option pricing framework which can be
applied to a general situation. The option payoff is calculated based on the
average price over a specific future period. As we use the general mean, our
framework contains different payoff functions as special cases. Further, we use
jump-diffusion stochastic models to describe the auction payment price
movement, which have Markov and price discontinuity properties, and those
properties are validated by our statistical investigation of ad auctions from
different datasets. In the paper, we propose a general option pricing solution
based on Monte Carlo simulation and also give an explicit pricing formula for a
special case. The latter is also a generalisation of the option pricing models
in some other recent developments.
</dc:description>
 <dc:description>Comment: 18 pages, under review</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06813</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RenderMap: Exploiting the Link Between Perception and Rendering for
  Dense Mapping</dc:title>
 <dc:creator>Ryde, Julian</dc:creator>
 <dc:creator>Xuchu</dc:creator>
 <dc:creator>Ding</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We introduce an approach for the real-time (2Hz) creation of a dense map and
alignment of a moving robotic agent within that map by rendering using a
Graphics Processing Unit (GPU). This is done by recasting the scan alignment
part of the dense mapping process as a rendering task. Alignment errors are
computed from rendering the scene, comparing with range data from the sensors,
and minimized by an optimizer. The proposed approach takes advantage of the
advances in rendering techniques for computer graphics and GPU hardware to
accelerate the algorithm. Moreover, it allows one to exploit information not
used in classic dense mapping algorithms such as Iterative Closest Point (ICP)
by rendering interfaces between the free space, occupied space and the unknown.
The proposed approach leverages directly the rendering capabilities of the GPU,
in contrast to other GPU-based approaches that deploy the GPU as a general
purpose parallel computation platform.
  We argue that the proposed concept is a general consequence of treating
perception problems as inverse problems of rendering. Many perception problems
can be recast into a form where much of the computation is replaced by render
operations. This is not only efficient since rendering is fast, but also
simpler to implement and will naturally benefit from future advancements in GPU
speed and rendering techniques. Furthermore, this general concept can go beyond
addressing perception problems and can be used for other problem domains such
as path planning.
</dc:description>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06818</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Approximation for Canonical Correlation Analysis</dc:title>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:creator>Marinov, Teodor V.</dc:creator>
 <dc:creator>Mianjy, Poorya</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study canonical correlation analysis (CCA) as a stochastic optimization
problem. We show that regularized CCA is efficiently PAC-learnable. We give
stochastic approximation (SA) algorithms that are instances of stochastic
mirror descent, which achieve $\epsilon$-suboptimality in the population
objective in time $\operatorname{poly}(\frac{1}{\epsilon},\frac{1}{\delta},d)$
with probability $1-\delta$, where $d$ is the input dimensionality.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06819</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIGNet: Scalable Embeddings for Signed Networks</dc:title>
 <dc:creator>Islam, Mohammad Raihanul</dc:creator>
 <dc:creator>Prakash, B. Aditya</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Recent successes in word embedding and document embedding have motivated
researchers to explore similar representations for networks and to use such
representations for tasks such as edge prediction, node label prediction, and
community detection. Existing methods are largely focused on finding
distributed representations for unsigned networks and are unable to discover
embeddings that respect polarities inherent in edges. We propose SIGNet, a fast
scalable embedding method suitable for signed networks. Our proposed objective
function aims to carefully model the social structure implicit in signed
networks by reinforcing the principles of social balance theory. Our method
builds upon the traditional word2vec family of embedding approaches but we
propose a new targeted node sampling strategy to maintain structural balance in
higher-order neighborhoods. We demonstrate the superiority of SIGNet over
state-of-the-art methods proposed for both signed and unsigned networks on
several real world datasets from different domains. In particular, SIGNet
offers an approach to generate a richer vocabulary of features of signed
networks to support representation and reasoning.
</dc:description>
 <dc:description>Comment: We are expanding this work, new version will soon be available</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06820</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EOMM: An Engagement Optimized Matchmaking Framework</dc:title>
 <dc:creator>Chen, Zhengxing</dc:creator>
 <dc:creator>Xue, Su</dc:creator>
 <dc:creator>Kolen, John</dc:creator>
 <dc:creator>Aghdaie, Navid</dc:creator>
 <dc:creator>Zaman, Kazi A.</dc:creator>
 <dc:creator>Sun, Yizhou</dc:creator>
 <dc:creator>El-Nasr, Magy Seif</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Matchmaking connects multiple players to participate in online
player-versus-player games. Current matchmaking systems depend on a single core
strategy: create fair games at all times. These systems pair similarly skilled
players on the assumption that a fair game is best player experience. We will
demonstrate, however, that this intuitive assumption sometimes fails and that
matchmaking based on fairness is not optimal for engagement.
  In this paper, we propose an Engagement Optimized Matchmaking (EOMM)
framework that maximizes overall player engagement. We prove that equal-skill
based matchmaking is a special case of EOMM on a highly simplified assumption
that rarely holds in reality. Our simulation on real data from a popular game
made by Electronic Arts, Inc. (EA) supports our theoretical results, showing
significant improvement in enhancing player engagement compared to existing
matchmaking methods.
</dc:description>
 <dc:description>Comment: WWW2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06820</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06821</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Algorithms for Designing Multiple Unimodular Waveforms With Good
  Correlation Properties</dc:title>
 <dc:creator>Li, Yongzhe</dc:creator>
 <dc:creator>Vorobyov, Sergiy A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we develop new fast and efficient algorithms for designing
single/multiple unimodular waveforms/codes with good auto- and
cross-correlation or weighted correlation properties, which are highly desired
in radar and communication systems. The waveform design is based on the
minimization of the integrated sidelobe level (ISL) and weighted ISL (WISL) of
waveforms. As the corresponding optimization problems can quickly grow to large
scale with increasing the code length and number of waveforms, the main issue
turns to be the development of fast large-scale optimization techniques. The
difficulty is also that the corresponding optimization problems are non-convex,
but the required accuracy is high. Therefore, we formulate the ISL and WISL
minimization problems as non-convex quartic optimization problems in frequency
domain, and then simplify them into quadratic problems by utilizing the
majorization-minimization technique, which is one of the basic techniques for
addressing large-scale and/or non-convex optimization problems. While designing
our fast algorithms, we find out and use inherent algebraic structures in the
objective functions to rewrite them into quartic forms, and in the case of WISL
minimization, to derive additionally an alternative quartic form which allows
to apply the quartic-quadratic transformation. Our algorithms are applicable to
large-scale unimodular waveform design problems as they are proved to have
lower or comparable computational burden (analyzed theoretically) and faster
convergence speed (confirmed by comprehensive simulations) than the
state-of-the-art algorithms. In addition, the waveforms designed by our
algorithms demonstrate better correlation properties compared to their
counterparts.
</dc:description>
 <dc:description>Comment: 30 pages, 3 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06827</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Secure and Safe Appified Automated Vehicles</dc:title>
 <dc:creator>Jia, Yunhan Jack</dc:creator>
 <dc:creator>Zhao, Ding</dc:creator>
 <dc:creator>Chen, Qi Alfred</dc:creator>
 <dc:creator>Mao, Z. Morley</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The advancement in Autonomous Vehicles (AVs) has created an enormous market
for the development of self-driving functionalities,raising the question of how
it will transform the traditional vehicle development process. One adventurous
proposal is to open the AV platform to third-party developers, so that AV
functionalities can be developed in a crowd-sourcing way, which could provide
tangible benefits to both automakers and end users. Some pioneering companies
in the automotive industry have made the move to open the platform so that
developers are allowed to test their code on the road. Such openness, however,
brings serious security and safety issues by allowing untrusted code to run on
the vehicle. In this paper, we introduce the concept of an Appified AV platform
that opens the development framework to third-party developers. To further
address the safety challenges, we propose an enhanced appified AV design schema
called AVGuard, which focuses primarily on mitigating the threats brought about
by untrusted code, leveraging theory in the vehicle evaluation field, and
conducting program analysis techniques in the cybersecurity area. Our study
provides guidelines and suggested practice for the future design of open AV
platforms.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06829</identifier>
 <datestamp>2017-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Convex Layers Algorithm</dc:title>
 <dc:creator>Rufai, Raimi A.</dc:creator>
 <dc:creator>Richards, Dana S.</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W99</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  Given a set of $n$ points $P$ in the plane, the first layer $L_1$ of $P$ is
formed by the points that appear on $P$'s convex hull. In general, a point
belongs to layer $L_i$, if it lies on the convex hull of the set $P \setminus
\bigcup_{j&lt;i}\{L_j\}$. The \emph{convex layers problem} is to compute the
convex layers $L_i$. Existing algorithms for this problem either do not achieve
the optimal $\mathcal{O}\left(n\log n\right)$ runtime and linear space, or are
overly complex and difficult to apply in practice. We propose a new algorithm
that is both optimal and simple. The simplicity is achieved by independently
computing four sets of monotone convex chains in $\mathcal{O}\left(n\log
n\right)$ time and linear space. These are then merged in
$\mathcal{O}\left(n\log n\right)$ time.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06829</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06830</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intent Recognition in Smart Living Through Deep Recurrent Neural
  Networks</dc:title>
 <dc:creator>Zhang, Xiang</dc:creator>
 <dc:creator>Yao, Lina</dc:creator>
 <dc:creator>Huang, Chaoran</dc:creator>
 <dc:creator>Sheng, Quan Z.</dc:creator>
 <dc:creator>Wang, Xianzhi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Electroencephalography (EEG) signal based intent recognition has recently
attracted much attention in both academia and industries, due to helping the
elderly or motor-disabled people controlling smart devices to communicate with
outer world. However, the utilization of EEG signals is challenged by low
accuracy, arduous and time- consuming feature extraction. This paper proposes a
7-layer deep learning model to classify raw EEG signals with the aim of
recognizing subjects' intents, to avoid the time consumed in pre-processing and
feature extraction. The hyper-parameters are selected by an Orthogonal Array
experiment method for efficiency. Our model is applied to an open EEG dataset
provided by PhysioNet and achieves the accuracy of 0.9553 on the intent
recognition. The applicability of our proposed model is further demonstrated by
two use cases of smart living (assisted living with robotics and home
automation).
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures,5 tables, 21 conferences</dc:description>
 <dc:date>2017-02-19</dc:date>
 <dc:date>2017-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06831</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Redescription Mining to Relate Clinical and Biological
  Characteristics of Cognitively Impaired and Alzheimer's Disease Patients</dc:title>
 <dc:creator>Mihel&#x10d;i&#x107;, Matej</dc:creator>
 <dc:creator>&#x160;imi&#x107;, Goran</dc:creator>
 <dc:creator>Leko, Mirjana Babi&#x107;</dc:creator>
 <dc:creator>Lavra&#x10d;, Nada</dc:creator>
 <dc:creator>D&#x17e;eroski, Sa&#x161;o</dc:creator>
 <dc:creator>&#x160;muc, Tomislav</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  We used redescription mining to find interpretable rules revealing
associations between those determinants that provide insights about the
Alzheimer's disease (AD). We extended the CLUS-RM redescription mining
algorithm to a constraint-based redescription mining (CBRM) setting, which
enables several modes of targeted exploration of specific, user-constrained
associations. Redescription mining enabled finding specific constructs of
clinical and biological attributes that describe many groups of subjects of
different size, homogeneity and levels of cognitive impairment. We confirmed
some previously known findings. However, in some instances, as with the
attributes: testosterone, the imaging attribute Spatial Pattern of
Abnormalities for Recognition of Early AD, as well as the levels of leptin and
angiopoietin-2 in plasma, we corroborated previously debatable findings or
provided additional information about these variables and their association
with AD pathogenesis. Applying redescription mining on ADNI data resulted with
the discovery of one largely unknown attribute: the Pregnancy-Associated
Protein-A (PAPP-A), which we found highly associated with cognitive impairment
in AD. Statistically significant correlations (p &lt;= 0.01) were found between
PAPP-A and various different clinical tests. The high importance of this
finding lies in the fact that PAPP-A is a metalloproteinase, known to cleave
insulin-like growth factor binding proteins. Since it also shares similar
substrates with A Disintegrin and the Metalloproteinase family of enzymes that
act as {\alpha}-secretase to physiologically cleave amyloid precursor protein
(APP) in the non-amyloidogenic pathway, it could be directly involved in the
metabolism of APP very early during the disease course. Therefore, further
studies should investigate the role of PAPP-A in the development of AD more
thoroughly.
</dc:description>
 <dc:date>2017-02-20</dc:date>
 <dc:date>2017-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06831</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0187364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06832</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial examples for generative models</dc:title>
 <dc:creator>Kos, Jernej</dc:creator>
 <dc:creator>Fischer, Ian</dc:creator>
 <dc:creator>Song, Dawn</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We explore methods of producing adversarial examples on deep generative
models such as the variational autoencoder (VAE) and the VAE-GAN. Deep learning
architectures are known to be vulnerable to adversarial examples, but previous
work has focused on the application of adversarial examples to classification
tasks. Deep generative models have recently become popular due to their ability
to model input data distributions and generate realistic examples from those
distributions. We present three classes of attacks on the VAE and VAE-GAN
architectures and demonstrate them against networks trained on MNIST, SVHN and
CelebA. Our first attack leverages classification-based adversaries by
attaching a classifier to the trained encoder of the target generative model,
which can then be used to indirectly manipulate the latent representation. Our
second attack directly uses the VAE loss function to generate a target
reconstruction image from the adversarial example. Our third attack moves
beyond relying on classification or the standard loss for the gradient and
directly optimizes against differences in source and target latent
representations. We also motivate why an attacker might be interested in
deploying such techniques against a target generative network.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06844</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Shifted Combinatorial Optimization</dc:title>
 <dc:creator>Gajarsk&#xfd;, Jakub</dc:creator>
 <dc:creator>Hlin&#x11b;n&#xfd;, Petr</dc:creator>
 <dc:creator>Kouteck&#xfd;, Martin</dc:creator>
 <dc:creator>Onn, Shmuel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Shifted combinatorial optimization is a new nonlinear optimization framework
which is a broad extension of standard combinatorial optimization, involving
the choice of several feasible solutions at a time. This framework captures
well studied and diverse problems ranging from so-called vulnerability problems
to sharing and partitioning problems. In particular, every standard
combinatorial optimization problem has its shifted counterpart, which is
typically much harder. Already with explicitly given input set the shifted
problem may be NP-hard. In this article we initiate a study of the
parameterized complexity of this framework. First we show that shifting over an
explicitly given set with its cardinality as the parameter may be in XP, FPT or
P, depending on the objective function. Second, we study the shifted problem
over sets definable in MSO logic (which includes, e.g., the well known MSO
partitioning problems). Our main results here are that shifted combinatorial
optimization over MSO definable sets is in XP with respect to the MSO formula
and the treewidth (or more generally clique-width) of the input graph, and is
W[1]-hard even under further severe restrictions.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06850</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Recognition by Combining Local and Global Image Descriptors</dc:title>
 <dc:creator>Wilson, Jobin</dc:creator>
 <dc:creator>Arif, Muhammad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Object recognition is an important problem in computer vision, having diverse
applications. In this work, we construct an end-to-end scene recognition
pipeline consisting of feature extraction, encoding, pooling and
classification. Our approach simultaneously utilize global feature descriptors
as well as local feature descriptors from images, to form a hybrid feature
descriptor corresponding to each image. We utilize DAISY features associated
with key points within images as our local feature descriptor and histogram of
oriented gradients (HOG) corresponding to an entire image as a global
descriptor. We make use of a bag-of-visual-words encoding and apply Mini- Batch
K-Means algorithm to reduce the complexity of our feature encoding scheme. A
2-level pooling procedure is used to combine DAISY and HOG features
corresponding to each image. Finally, we experiment with a multi-class SVM
classifier with several kernels, in a cross-validation setting, and tabulate
our results on the fifteen scene categories dataset. The average accuracy of
our model was 76.4% in the case of a 40%-60% random split of images into
training and testing datasets respectively. The primary objective of this work
is to clearly outline the practical implementation of a basic
screne-recognition pipeline having a reasonable accuracy, in python, using
open-source libraries. A full implementation of the proposed model is available
in our github repository.
</dc:description>
 <dc:description>Comment: A full implementation of our model is available at
  https://github.com/flytxtds/scene-recognition</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06850</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06856</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robustness to Adversarial Examples through an Ensemble of Specialists</dc:title>
 <dc:creator>Abbasi, Mahdieh</dc:creator>
 <dc:creator>Gagn&#xe9;, Christian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We are proposing to use an ensemble of diverse specialists, where speciality
is defined according to the confusion matrix. Indeed, we observed that for
adversarial instances originating from a given class, labeling tend to be done
into a small subset of (incorrect) classes. Therefore, we argue that an
ensemble of specialists should be better able to identify and reject fooling
instances, with a high entropy (i.e., disagreement) over the decisions in the
presence of adversaries. Experimental results obtained confirm that
interpretation, opening a way to make the system more robust to adversarial
examples through a rejection mechanism, rather than trying to classify them
properly at any cost.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2017 Workshop Track</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06858</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Emptiness of zero automata is decidable</dc:title>
 <dc:creator>Boja&#x144;czyk, Mikolaj</dc:creator>
 <dc:creator>Gimbert, Hugo</dc:creator>
 <dc:creator>Kelmendi, Edon</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Zero automata are a probabilistic extension of parity automata on infinite
trees. The satisfiability of a certain probabilistic variant of mso, called
tmso + zero, reduces to the emptiness problem for zero automata. We introduce a
variant of zero automata called nonzero automata. We prove that for every zero
automaton there is an equivalent nonzero automaton of quadratic size and the
emptiness problem of nonzero automata is decidable and both in NP and in coNP.
These results imply that tmso + zero has decidable satisfiability.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06861</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Power of Truncated SVD for General High-rank Matrix Estimation
  Problems</dc:title>
 <dc:creator>Du, Simon S.</dc:creator>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  We show that given an estimate $\widehat{A}$ that is close to a general
high-rank positive semi-definite (PSD) matrix $A$ in spectral norm (i.e.,
$\|\widehat{A}-A\|_2 \leq \delta$), the simple truncated SVD of $\widehat{A}$
produces a multiplicative approximation of $A$ in Frobenius norm. This
observation leads to many interesting results on general high-rank matrix
estimation problems, which we briefly summarize below ($A$ is an $n\times n$
high-rank PSD matrix and $A_k$ is the best rank-$k$ approximation of $A$):
  (1) High-rank matrix completion: By observing
$\Omega(\frac{n\max\{\epsilon^{-4},k^2\}\mu_0^2\|A\|_F^2\log
n}{\sigma_{k+1}(A)^2})$ elements of $A$ where $\sigma_{k+1}\left(A\right)$ is
the $\left(k+1\right)$-th singular value of $A$ and $\mu_0$ is the incoherence,
the truncated SVD on a zero-filled matrix satisfies $\|\widehat{A}_k-A\|_F \leq
(1+O(\epsilon))\|A-A_k\|_F$ with high probability.
  (2)High-rank matrix de-noising: Let $\widehat{A}=A+E$ where $E$ is a Gaussian
random noise matrix with zero mean and $\nu^2/n$ variance on each entry. Then
the truncated SVD of $\widehat{A}$ satisfies $\|\widehat{A}_k-A\|_F \leq
(1+O(\sqrt{\nu/\sigma_{k+1}(A)}))\|A-A_k\|_F + O(\sqrt{k}\nu)$.
  (3) Low-rank Estimation of high-dimensional covariance: Given $N$
i.i.d.~samples $X_1,\cdots,X_N\sim\mathcal N_n(0,A)$, can we estimate $A$ with
a relative-error Frobenius norm bound? We show that if $N =
\Omega\left(n\max\{\epsilon^{-4},k^2\}\gamma_k(A)^2\log N\right)$ for
$\gamma_k(A)=\sigma_1(A)/\sigma_{k+1}(A)$, then $\|\widehat{A}_k-A\|_F \leq
(1+O(\epsilon))\|A-A_k\|_F$ with high probability, where
$\widehat{A}=\frac{1}{N}\sum_{i=1}^N{X_iX_i^\top}$ is the sample covariance.
</dc:description>
 <dc:description>Comment: Accepted by NIPS 2017. Add gap-dependent bounds</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06861</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06865</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Platform independent profiling of a QCD code</dc:title>
 <dc:creator>Marinkovic, Marina Krstic</dc:creator>
 <dc:creator>Stanisic, Luka</dc:creator>
 <dc:subject>High Energy Physics - Lattice</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  The supercomputing platforms available for high performance computing based
research evolve at a great rate. However, this rapid development of novel
technologies requires constant adaptations and optimizations of the existing
codes for each new machine architecture. In such context, minimizing time of
efficiently porting the code on a new platform is of crucial importance. A
possible solution for this common challenge is to use simulations of the
application that can assist in detecting performance bottlenecks. Due to
prohibitive costs of classical cycle-accurate simulators, coarse-grain
simulations are more suitable for large parallel and distributed systems. We
present a procedure of implementing the profiling for openQCD code [1] through
simulation, which will enable the global reduction of the cost of profiling and
optimizing this code commonly used in the lattice QCD community. Our approach
is based on well-known SimGrid simulator [2], which allows for fast and
accurate performance predictions of HPC codes. Additionally, accurate
estimations of the program behavior on some future machines, not yet accessible
to us, are anticipated.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06865</dc:identifier>
 <dc:identifier>34th annual International Symposium on Lattice Field Theory, Jul
  2016, Southampton, United Kingdom. 2017, PoS</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06872</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Control in Full Duplex Networks: Area Spectrum Efficiency and
  Energy Efficency</dc:title>
 <dc:creator>Feng, Chenyuan</dc:creator>
 <dc:creator>Zhong, Yi</dc:creator>
 <dc:creator>Quek, Tony Q. S.</dc:creator>
 <dc:creator>Wu, Gang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Full-duplex (FD) allows the exchange of data between nodes on the same
temporal and spectrum resources, however, it introduces self interference (SI)
and additional network interference compared to half-duplex (HD). Power control
in the FD networks, which is seldom studied in the literature, is promising to
mitigate the interference and improve the performance of the overall network.
In this work, we investigate the random and deterministic power control
strategies in the FD networks, namely, constant power control, uniform power
control, fractional power control and ALOHA-like random on-off power control
scheme. Based on the obtained coverage probabilities and their robust
approximations, we show that power control provides remarkable gain in area
spectrum efficiency (ASE) and energy efficiency (EE), and improves the fairness
among the uplink (UL) and downlink (DL) transmissions with respect to the FD
networks. Moreover, we evaluate the minimum SI cancellation capability to
guarantee the performance of the cell-edge users in FD networks. Generally,
power control is helpful to improve the performance of the transmission for
long distance in the FD networks and reduce the requirement of SI cancellation
capability.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06872</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06875</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triaging Content Severity in Online Mental Health Forums</dc:title>
 <dc:creator>Cohan, Arman</dc:creator>
 <dc:creator>Young, Sydney</dc:creator>
 <dc:creator>Yates, Andrew</dc:creator>
 <dc:creator>Goharian, Nazli</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Mental health forums are online communities where people express their issues
and seek help from moderators and other users. In such forums, there are often
posts with severe content indicating that the user is in acute distress and
there is a risk of attempted self-harm. Moderators need to respond to these
severe posts in a timely manner to prevent potential self-harm. However, the
large volume of daily posted content makes it difficult for the moderators to
locate and respond to these critical posts. We present a framework for triaging
user content into four severity categories which are defined based on
indications of self-harm ideation. Our models are based on a feature-rich
classification framework which includes lexical, psycholinguistic, contextual
and topic modeling features. Our approaches improve the state of the art in
triaging the content severity in mental health forums by large margins (up to
17% improvement over the F-1 scores). Using the proposed model, we analyze the
mental state of users and we show that overall, long-term users of the forum
demonstrate a decreased severity of risk over time. Our analysis on the
interaction of the moderators with the users further indicates that without an
automatic way to identify critical content, it is indeed challenging for the
moderators to provide timely response to the users in need.
</dc:description>
 <dc:description>Comment: Accepted for publication in Journal of the Association for
  Information Science and Technology (2017)</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06875</dc:identifier>
 <dc:identifier>doi:10.1002/asi.23865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06877</identifier>
 <datestamp>2017-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Birds: Detecting Aggression and Bullying on Twitter</dc:title>
 <dc:creator>Chatzakou, Despoina</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:creator>Blackburn, Jeremy</dc:creator>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:creator>Vakali, Athena</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In recent years, bullying and aggression against users on social media have
grown significantly, causing serious consequences to victims of all
demographics. In particular, cyberbullying affects more than half of young
social media users worldwide, and has also led to teenage suicides, prompted by
prolonged and/or coordinated digital harassment. Nonetheless, tools and
technologies for understanding and mitigating it are scarce and mostly
ineffective. In this paper, we present a principled and scalable approach to
detect bullying and aggressive behavior on Twitter. We propose a robust
methodology for extracting text, user, and network-based attributes, studying
the properties of cyberbullies and aggressors, and what features distinguish
them from regular users. We find that bully users post less, participate in
fewer online communities, and are less popular than normal users, while
aggressors are quite popular and tend to include more negativity in their
posts. We evaluate our methodology using a corpus of 1.6M tweets posted over 3
months, and show that machine learning classification algorithms can accurately
detect users exhibiting bullying and aggressive behavior, achieving over 90%
AUC.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06878</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy-Efficient $M$-QAM Precoder Design with Spatial Peak Power
  Minimization for MIMO Directional Modulation Transceivers</dc:title>
 <dc:creator>Kalantari, Ashkan</dc:creator>
 <dc:creator>Tsinos, Christos</dc:creator>
 <dc:creator>Soltanalian, Mojtaba</dc:creator>
 <dc:creator>Chatzinotas, Symeon</dc:creator>
 <dc:creator>Ma, Wing-Kin</dc:creator>
 <dc:creator>Ottersten, Bj&#xf6;rn</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Spectrally efficient multi-antenna wireless communications is a key challenge
as service demands continue to increase. At the same time, powering up radio
access networks increases $CO_2$ footprint. Hence, for an efficient radio
access design, we design a directional modulation precoder for $M$-QAM
modulation with $M=4,8,16,32$. First, extended detection regions are defined in
these constellations using analytical geometry. Then, constellation points are
placed in the optimal positions of these regions while the minimum Euclidean
distance to neighbor constellation points and detection region boundary is kept
as in the conventional $M$-QAM modulation. For further energy-efficiency,
relaxed detection regions are modeled for inner points of $M=16,32$
constellations. The modeled extended and relaxed detection regions as well as
the modulation characteristics are utilized to formulate convex symbol-level
precoder design problems for directional modulation to minimize the
transmission power while preserving the minimum required SNR at the
destination. In addition, the extended and relaxed detection regions are used
for precoder design to minimize the output of each power amplifier. Results
show that compared to the benchmark schemes, the proposed methods perform
better in terms of power and peak power reduction as well as symbol error rate
reduction for a long range of SNRs.
</dc:description>
 <dc:description>Comment: This manuscript is submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06878</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06879</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Graph Completion via Complex Tensor Factorization</dc:title>
 <dc:creator>Trouillon, Th&#xe9;o</dc:creator>
 <dc:creator>Dance, Christopher R.</dc:creator>
 <dc:creator>Welbl, Johannes</dc:creator>
 <dc:creator>Riedel, Sebastian</dc:creator>
 <dc:creator>Gaussier, &#xc9;ric</dc:creator>
 <dc:creator>Bouchard, Guillaume</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Spectral Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In statistical relational learning, knowledge graph completion deals with
automatically understanding the structure of large knowledge graphs---labeled
directed graphs---and predicting missing relationships---labeled edges.
State-of-the-art embedding models propose different trade-offs between modeling
expressiveness, and time and space complexity. We reconcile both expressiveness
and complexity through the use of complex-valued embeddings and explore the
link between such complex-valued embeddings and unitary diagonalization. We
corroborate our approach theoretically and show that all real square
matrices---thus all possible relation/adjacency matrices---are the real part of
some unitarily diagonalizable matrix. This results opens the door to a lot of
other applications of square matrices factorization. Our approach based on
complex embeddings is arguably simple, as it only involves a Hermitian dot
product, the complex counterpart of the standard dot product between real
vectors, whereas other methods resort to more and more complicated composition
functions to increase their expressiveness. The proposed complex embeddings are
scalable to large data sets as it remains linear in both space and time, while
consistently outperforming alternative approaches on standard link prediction
benchmarks.
</dc:description>
 <dc:description>Comment: 38 pages, accepted in JMLR. This is an extended version of the
  article &quot;Complex embeddings for simple link prediction&quot; (ICML 2016)</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-11-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06879</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06887</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusive Mobile Molecular Communications Over Time-Variant Channels</dc:title>
 <dc:creator>Ahmadzadeh, Arman</dc:creator>
 <dc:creator>Jamali, Vahid</dc:creator>
 <dc:creator>Noel, Adam</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter introduces a formalism for modeling time-variant channels for
diffusive molecular communication systems. In particular, we consider a fluid
environment where one transmitter nano-machine and one receiver nano-machine
are subjected to Brownian motion in addition to the diffusive motion of the
information molecules used for communication. Due to the stochastic movements
of the transmitter and receiver nano-machines, the statistics of the channel
impulse response change over time. We show that the time-variant behaviour of
the channel can be accurately captured by appropriately modifying the diffusion
coefficient of the information molecules. Furthermore, we derive an analytical
expression for evaluation of the expected error probability of a simple
detector for the considered system. The accuracy of the proposed analytical
expression is verified via particle-based simulation of the Brownian motion.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 1 table. Accepted for publication in IEEE
  Communications Letters (Author's comment: Manuscript submitted Jan. 19, 2017;
  revised Feb. 20, 2017; accepted Feb. 22, 2017)</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06887</dc:identifier>
 <dc:identifier>doi:10.1109/LCOMM.2017.2678467</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06890</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Features via Congenerous Cosine Loss for Person
  Recognition</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Li, Hongyang</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Person recognition aims at recognizing the same identity across time and
space with complicated scenes and similar appearance. In this paper, we propose
a novel method to address this task by training a network to obtain robust and
representative features. The intuition is that we directly compare and optimize
the cosine distance between two features - enlarging inter-class distinction as
well as alleviating inner-class variance. We propose a congenerous cosine loss
by minimizing the cosine distance between samples and their cluster centroid in
a cooperative way. Such a design reduces the complexity and could be
implemented via softmax with normalized inputs. Our method also differs from
previous work in person recognition that we do not conduct a second training on
the test subset. The identity of a person is determined by measuring the
similarity from several body regions in the reference set. Experimental results
show that the proposed approach achieves better classification accuracy against
previous state-of-the-arts.
</dc:description>
 <dc:description>Comment: Post-rebuttal update. Add some comparison results; correct some
  technical part; rewrite some sections to make it more readable; code link
  available</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06891</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EVE: Explainable Vector Based Embedding Technique Using Wikipedia</dc:title>
 <dc:creator>Qureshi, M. Atif</dc:creator>
 <dc:creator>Greene, Derek</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present an unsupervised explainable word embedding technique, called EVE,
which is built upon the structure of Wikipedia. The proposed model defines the
dimensions of a semantic vector representing a word using human-readable
labels, thereby it readily interpretable. Specifically, each vector is
constructed using the Wikipedia category graph structure together with the
Wikipedia article link structure. To test the effectiveness of the proposed
word embedding model, we consider its usefulness in three fundamental tasks: 1)
intruder detection - to evaluate its ability to identify a non-coherent vector
from a list of coherent vectors, 2) ability to cluster - to evaluate its
tendency to group related vectors together while keeping unrelated vectors in
separate clusters, and 3) sorting relevant items first - to evaluate its
ability to rank vectors (items) relevant to the query in the top order of the
result. For each task, we also propose a strategy to generate a task-specific
human-interpretable explanation from the model. These demonstrate the overall
effectiveness of the explainable embeddings generated by EVE. Finally, we
compare EVE with the Word2Vec, FastText, and GloVe embedding techniques across
the three tasks, and report improvements over the state-of-the-art.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06898</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing speed and scalability of the ParFlow simulation code</dc:title>
 <dc:creator>Burstedde, Carsten</dc:creator>
 <dc:creator>Fonseca, Jose A.</dc:creator>
 <dc:creator>Kollet, Stefan</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  Regional hydrology studies are often supported by high resolution simulations
of subsurface flow that require expensive and extensive computations. Efficient
usage of the latest high performance parallel computing systems becomes a
necessity. The simulation software ParFlow has been demonstrated to meet this
requirement and shown to have excellent solver scalability for up to 16,384
processes. In the present work we show that the code requires further
enhancements in order to fully take advantage of current petascale machines. We
identify ParFlow's way of parallelization of the computational mesh as a
central bottleneck. We propose to reorganize this subsystem using fast mesh
partition algorithms provided by the parallel adaptive mesh refinement library
p4est. We realize this in a minimally invasive manner by modifying selected
parts of the code to reinterpret the existing mesh data structures. We evaluate
the scaling performance of the modified version of ParFlow, demonstrating good
weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test
an example application at large scale.
</dc:description>
 <dc:description>Comment: The final publication is available at link.springer.com</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-10-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06898</dc:identifier>
 <dc:identifier>Computational Geosciences 2017</dc:identifier>
 <dc:identifier>doi:10.1007/s10596-017-9696-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06899</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>liquidSVM: A Fast and Versatile SVM package</dc:title>
 <dc:creator>Steinwart, Ingo</dc:creator>
 <dc:creator>Thomann, Philipp</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  liquidSVM is a package written in C++ that provides SVM-type solvers for
various classification and regression tasks. Because of a fully integrated
hyper-parameter selection, very carefully implemented solvers, multi-threading
and GPU support, and several built-in data decomposition strategies it provides
unprecedented speed for small training sizes as well as for data sets of tens
of millions of samples. Besides the C++ API and a command line interface,
bindings to R, MATLAB, Java, Python, and Spark are available. We present a
brief description of the package and report experimental comparisons to other
SVM packages.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06900</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Periodic I/O scheduling for super-computers</dc:title>
 <dc:creator>Aupy, Guillaume</dc:creator>
 <dc:creator>Gainaru, Ana</dc:creator>
 <dc:creator>F&#xe8;vre, Valentin Le</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  With the ever-growing need of data in HPC applications, the congestion at the
I/O level becomes critical in super-computers. Architectural enhancement such
as burst-buffers and pre-fetching are added to machines, but are not sufficient
to prevent congestion. Recent online I/O scheduling strategies have been put in
place, but they add an additional congestion point and overheads in the
computation of applications.
  In this work, we show how to take advantage of the periodic nature of HPC
applications in order to develop efficient periodic scheduling strategies for
their I/O transfers. Our strategy computes once during the job scheduling phase
a pattern where it defines the I/O behavior for each application, after which
the applications run independently, transferring their I/O at the specified
times. Our strategy limits the amount of I/O congestion at the I/O node level
and can be easily integrated into current job schedulers. We validate this
model through extensive simulations and experiments by comparing it to
state-of-the-art online solutions, showing that not only our scheduler has the
advantage of being de-centralized and thus overcoming the overhead of online
schedulers, but also that it performs better than these solutions, improving
the application dilation up to 13% and the maximum system efficiency up to 18%.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06901</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Deep Learning-based Decoding of Polar Codes via Partitioning</dc:title>
 <dc:creator>Cammerer, Sebastian</dc:creator>
 <dc:creator>Gruber, Tobias</dc:creator>
 <dc:creator>Hoydis, Jakob</dc:creator>
 <dc:creator>Brink, Stephan ten</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The training complexity of deep learning-based channel decoders scales
exponentially with the codebook size and therefore with the number of
information bits. Thus, neural network decoding (NND) is currently only
feasible for very short block lengths. In this work, we show that the
conventional iterative decoding algorithm for polar codes can be enhanced when
sub-blocks of the decoder are replaced by neural network (NN) based components.
Thus, we partition the encoding graph into smaller sub-blocks and train them
individually, closely approaching maximum a posteriori (MAP) performance per
sub-block. These blocks are then connected via the remaining conventional
belief propagation decoding stage(s). The resulting decoding algorithm is
non-iterative and inherently enables a high-level of parallelization, while
showing a competitive bit error rate (BER) performance. We examine the
degradation through partitioning and compare the resulting decoder to
state-of-the-art polar decoders such as successive cancellation list and belief
propagation decoding.
</dc:description>
 <dc:description>Comment: Submitted to Globecom 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06901</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06902</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DRYVR:Data-driven verification and compositional reasoning for
  automotive systems</dc:title>
 <dc:creator>Fan, Chuchu</dc:creator>
 <dc:creator>Qi, Bolun</dc:creator>
 <dc:creator>Mitra, Sayan</dc:creator>
 <dc:creator>Viswanathan, Mahesh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present the DRYVR framework for verifying hybrid control systems that are
described by a combination of a black-box simulator for trajectories and a
white-box transition graph specifying mode switches. The framework includes (a)
a probabilistic algorithm for learning sensitivity of the continuous
trajectories from simulation data, (b) a bounded reachability analysis
algorithm that uses the learned sensitivity, and (c) reasoning techniques based
on simulation relations and sequential composition, that enable verification of
complex systems under long switching sequences, from the reachability analysis
of a simpler system under shorter sequences. We demonstrate the utility of the
framework by verifying a suite of automotive benchmarks that include powertrain
control, automatic transmission, and several autonomous and ADAS features like
automatic emergency braking, lane-merge, and auto-passing controllers.
</dc:description>
 <dc:description>Comment: 25 pages, 3 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06903</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding multiple core-periphery pairs in networks</dc:title>
 <dc:creator>Kojaku, Sadamori</dc:creator>
 <dc:creator>Masuda, Naoki</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With a core-periphery structure of networks, core nodes are densely
interconnected, peripheral nodes are connected to core nodes to different
extents, and peripheral nodes are sparsely interconnected. Core-periphery
structure composed of a single core and periphery has been identified for
various networks. However, analogous to the observation that many empirical
networks are composed of densely interconnected groups of nodes, i.e.,
communities, a network may be better regarded as a collection of multiple cores
and peripheries. We propose a scalable algorithm to detect multiple
non-overlapping groups of core-periphery structure in a network. We illustrate
our algorithm using synthesised and empirical networks. For example, we find
distinct core-periphery pairs with different political leanings in a network of
political blogs and separation between international and domestic subnetworks
of airports in some single countries in a world-wide airport network.
</dc:description>
 <dc:description>Comment: 11 figures and 9 tables. MATLAB codes are available at
  www.naokimasuda.net/cp_codes.zip</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06903</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 052313 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.052313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06914</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Training a Subsampling Mechanism in Expectation</dc:title>
 <dc:creator>Raffel, Colin</dc:creator>
 <dc:creator>Lawson, Dieterich</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a mechanism for subsampling sequences and show how to compute its
expected output so that it can be trained with standard backpropagation. We
test this approach on a simple toy problem and discuss its shortcomings.
</dc:description>
 <dc:description>Comment: Camera-ready version. Includes additional figures in an appendix</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06915</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving DCOPs with Distributed Large Neighborhood Search</dc:title>
 <dc:creator>Fioretto, Ferdinando</dc:creator>
 <dc:creator>Dovier, Agostino</dc:creator>
 <dc:creator>Pontelli, Enrico</dc:creator>
 <dc:creator>Yeoh, William</dc:creator>
 <dc:creator>Zivan, Roie</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The field of Distributed Constraint Optimization has gained momentum in
recent years, thanks to its ability to address various applications related to
multi-agent cooperation. Nevertheless, solving Distributed Constraint
Optimization Problems (DCOPs) optimally is NP-hard. Therefore, in large-scale,
complex applications, incomplete DCOP algorithms are necessary. Current
incomplete DCOP algorithms suffer of one or more of the following limitations:
they (a) find local minima without providing quality guarantees; (b) provide
loose quality assessment; or (c) are unable to benefit from the structure of
the problem, such as domain-dependent knowledge and hard constraints.
Therefore, capitalizing on strategies from the centralized constraint solving
community, we propose a Distributed Large Neighborhood Search (D-LNS) framework
to solve DCOPs. The proposed framework (with its novel repair phase) provides
guarantees on solution quality, refining upper and lower bounds during the
iterative process, and can exploit domain-dependent structures. Our
experimental results show that D-LNS outperforms other incomplete DCOP
algorithms on both structured and unstructured problem instances.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06917</identifier>
 <datestamp>2017-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe</dc:title>
 <dc:creator>Berthet, Quentin</dc:creator>
 <dc:creator>Perchet, Vianney</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider the problem of bandit optimization, inspired by stochastic
optimization and online learning problems with bandit feedback. In this
problem, the objective is to minimize a global loss function of all the
actions, not necessarily a cumulative loss. This framework allows us to study a
very general class of problems, with applications in statistics, machine
learning, and other fields. To solve this problem, we analyze the
Upper-Confidence Frank-Wolfe algorithm, inspired by techniques for bandits and
convex optimization. We give theoretical guarantees for the performance of this
algorithm over various classes of functions, and discuss the optimality of
these results.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-09-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06917</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06920</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bad Primes in Computational Algebraic Geometry</dc:title>
 <dc:creator>Boehm, Janko</dc:creator>
 <dc:creator>Decker, Wolfram</dc:creator>
 <dc:creator>Fieker, Claus</dc:creator>
 <dc:creator>Laplagne, Santiago</dc:creator>
 <dc:creator>Pfister, Gerhard</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>13P10 (Primary) 68W10, 52C05 (Secondary)</dc:subject>
 <dc:description>  Computations over the rational numbers often suffer from intermediate
coefficient swell. One solution to this problem is to apply the given algorithm
modulo a number of primes and then lift the modular results to the rationals.
This method is guaranteed to work if we use a sufficiently large set of good
primes. In many applications, however, there is no efficient way of excluding
bad primes. In this note, we describe a technique for rational reconstruction
which will nevertheless return the correct result, provided the number of good
primes in the selected set of primes is large enough. We give a number of
illustrating examples which are implemented using the computer algebra system
Singular and the programming language Julia. We discuss applications of our
technique in computational algebraic geometry.
</dc:description>
 <dc:description>Comment: 8 pages, 1 figure, 1 table</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06920</dc:identifier>
 <dc:identifier>LNCS 9725 (2016), 93-102</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06921</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Representation of Subgraphs</dc:title>
 <dc:creator>Adhikari, Bijaya</dc:creator>
 <dc:creator>Zhang, Yao</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:creator>Prakash, B. Aditya</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Network embeddings have become very popular in learning effective feature
representations of networks. Motivated by the recent successes of embeddings in
natural language processing, researchers have tried to find network embeddings
in order to exploit machine learning algorithms for mining tasks like node
classification and edge prediction. However, most of the work focuses on
finding distributed representations of nodes, which are inherently ill-suited
to tasks such as community detection which are intuitively dependent on
subgraphs.
  Here, we propose sub2vec, an unsupervised scalable algorithm to learn feature
representations of arbitrary subgraphs. We provide means to characterize
similarties between subgraphs and provide theoretical analysis of sub2vec and
demonstrate that it preserves the so-called local proximity. We also highlight
the usability of sub2vec by leveraging it for network mining tasks, like
community detection. We show that sub2vec gets significant gains over
state-of-the-art methods and node-embedding methods. In particular, sub2vec
offers an approach to generate a richer vocabulary of features of subgraphs to
support representation and reasoning.
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06922</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formation of coalition structures as a non-cooperative game</dc:title>
 <dc:creator>Levando, Dmitry</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Traditionally social sciences are interested in structuring people in
multiple groups based on their individual preferences. This pa- per suggests an
approach to this problem in the framework of a non- cooperative game theory.
Definition of a suggested finite game includes a family of nested simultaneous
non-cooperative finite games with intra- and inter-coalition externalities. In
this family, games differ by the size of maximum coalition, partitions and by
coalition structure formation rules. A result of every game consists of
partition of players into coalitions and a payoff? profiles for every player.
Every game in the family has an equilibrium in mixed strategies with possibly
more than one coalition. The results of the game differ from those
conventionally discussed in cooperative game theory, e.g. the Shapley value,
strong Nash, coalition-proof equilibrium, core, kernel, nucleolus. We discuss
the following applications of the new game: cooperation as an allocation in one
coalition, Bayesian games, stochastic games and construction of a
non-cooperative criterion of coalition structure stability for studying focal
points.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1612.02344,
  arXiv:1612.03742</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06925</identifier>
 <datestamp>2017-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Regularizing Face Verification Nets For Pain Intensity Regression</dc:title>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:creator>Xiang, Xiang</dc:creator>
 <dc:creator>Liu, Chang</dc:creator>
 <dc:creator>Tran, Trac D.</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:creator>Quon, Harry</dc:creator>
 <dc:creator>Cheng, Jian</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Limited labeled data are available for the research of estimating facial
expression intensities. For instance, the ability to train deep networks for
automated pain assessment is limited by small datasets with labels of
patient-reported pain intensities. Fortunately, fine-tuning from a
data-extensive pre-trained domain, such as face verification, can alleviate
this problem. In this paper, we propose a network that fine-tunes a
state-of-the-art face verification network using a regularized regression loss
and additional data with expression labels. In this way, the expression
intensity regression task can benefit from the rich feature representations
trained on a huge amount of data for face verification. The proposed
regularized deep regressor is applied to estimate the pain expression intensity
and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving
the state-of-the-art performance. A weighted evaluation metric is also proposed
to address the imbalance issue of different pain intensities.
</dc:description>
 <dc:description>Comment: 5 pages, 3 figure; Camera-ready version to appear at IEEE ICIP 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06925</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.20841.49765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06934</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Realization of Ontology Web Search Engine</dc:title>
 <dc:creator>Verhodubs, Olegs</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  This paper describes the realization of the Ontology Web Search Engine. The
Ontology Web Search Engine is realizable as independent project and as a part
of other projects. The main purpose of this paper is to present the Ontology
Web Search Engine realization details as the part of the Semantic Web Expert
System and to present the results of the Ontology Web Search Engine
functioning. It is expected that the Semantic Web Expert System will be able to
process ontologies from the Web, generate rules from these ontologies and
develop its knowledge base.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06941</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algebraic Formalization of Forward and Forward-backward Algorithms</dc:title>
 <dc:creator>Azuma, Ai</dc:creator>
 <dc:creator>Shimbo, Masashi</dc:creator>
 <dc:creator>Matsumoto, Yuji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose an algebraic formalization of the two important
classes of dynamic programming algorithms called forward and forward-backward
algorithms. They are generalized extensively in this study so that a wide range
of other existing algorithms is subsumed. Forward algorithms generalized in
this study subsume the ordinary forward algorithm on trellises for sequence
labeling, the inside algorithm on derivation forests for CYK parsing, a
unidirectional message passing on acyclic factor graphs, the forward mode of
automatic differentiation on computation graphs with addition and
multiplication, and so on. In addition, we reveal algebraic structures
underlying complicated computation with forward algorithms. By the aid of the
revealed algebraic structures, we also propose a systematic framework to design
complicated variants of forward algorithms. Forward-backward algorithms
generalized in this study subsume the ordinary forward-backward algorithm on
trellises for sequence labeling, the inside-outside algorithm on derivation
forests for CYK parsing, the sum-product algorithm on acyclic factor graphs,
the reverse mode of automatic differentiation (a.k.a. back propagation) on
computation graphs with addition and multiplication, and so on. We also propose
an algebraic characterization of what can be computed by forward-backward
algorithms and elucidate the relationship between forward and forward-backward
algorithms.
</dc:description>
 <dc:description>Comment: 55 pages, in submission to JMLR</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06943</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Lempel-Ziv-Welch Meets Machine Learning: A Case Study of
  Accelerating Machine Learning using Coding</dc:title>
 <dc:creator>Li, Fengan</dc:creator>
 <dc:creator>Chen, Lingjiao</dc:creator>
 <dc:creator>Kumar, Arun</dc:creator>
 <dc:creator>Naughton, Jeffrey F.</dc:creator>
 <dc:creator>Patel, Jignesh M.</dc:creator>
 <dc:creator>Wu, Xi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we study the use of coding techniques to accelerate machine
learning (ML). Coding techniques, such as prefix codes, have been extensively
studied and used to accelerate low-level data processing primitives such as
scans in a relational database system. However, there is little work on how to
exploit them to accelerate ML algorithms. In fact, applying coding techniques
for faster ML faces a unique challenge: one needs to consider both how the
codes fit into the optimization algorithm used to train a model, and the
interplay between the model structure and the coding scheme. Surprisingly and
intriguingly, our study demonstrates that a slight variant of the classical
Lempel-Ziv-Welch (LZW) coding scheme is a good fit for several popular ML
algorithms, resulting in substantial runtime savings. Comprehensive experiments
on several real-world datasets show that our LZW-based ML algorithms exhibit
speedups of up to 31x compared to a popular and state-of-the-art ML library,
with no changes to ML accuracy, even though the implementations of our LZW
variants are not heavily tuned. Thus, our study reveals a new avenue for
accelerating ML algorithms using coding techniques and we hope this opens up a
new direction for more research.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06943</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06968</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Heuristic Process for GUI Widget Matching Across Application Versions</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:description>  This paper introduces an automated heuristic process able to achieve high
accuracy when matching graphical user interface widgets across multiple
versions of a target application. The proposed implementation is flexible as it
allows full customization of the process and easy integration with existing
tools for long term graphical user interface test case maintenance, software
visualization and analysis.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06968</dc:identifier>
 <dc:identifier>Annales Universitatis Scientiarum Budapest, Sectio Computatorica
  Vol 36, pages 255 - 275 (2012)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06969</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating Unique Games Using Low Diameter Graph Decomposition</dc:title>
 <dc:creator>Alev, Vedat Levi</dc:creator>
 <dc:creator>Lau, Lap Chi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We design approximation algorithms for Unique Games when the constraint graph
admits good low diameter graph decomposition. For the ${\sf Max2Lin}_k$ problem
in $K_r$-minor free graphs, when there is an assignment satisfying
$1-\varepsilon$ fraction of constraints, we present an algorithm that produces
an assignment satisfying $1-O(r\varepsilon)$ fraction of constraints, with the
approximation ratio independent of the alphabet size. A corollary is an
improved approximation algorithm for the ${\sf MaxCut}$ problem for $K_r$-minor
free graphs. For general Unique Games in $K_r$-minor free graphs, we provide
another algorithm that produces an assignment satisfying $1-O(r
\sqrt{\varepsilon})$ fraction of constraints.
  Our approach is to round a linear programming relaxation to find a minimum
subset of edges that intersects all the inconsistent cycles. We show that it is
possible to apply the low diameter graph decomposition technique on the
constraint graph directly, rather than to work on the label extended graph as
in previous algorithms for Unique Games. The same approach applies when the
constraint graph is of genus $g$, and we get similar results with $r$ replaced
by $\log g$ in the ${\sf Max2Lin}_k$ problem and by $\sqrt{\log g}$ in the
general problem. The former result generalizes the result of Gupta-Talwar for
Unique Games in the ${\sf Max2Lin}_k$ case, and the latter result generalizes
the result of Trevisan for general Unique Games.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06970</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Realistic Dataset for the Smart Home Device Scheduling Problem for
  DCOPs</dc:title>
 <dc:creator>Kluegel, William</dc:creator>
 <dc:creator>Iqbal, Muhammad Aamir</dc:creator>
 <dc:creator>Fioretto, Ferdinando</dc:creator>
 <dc:creator>Yeoh, William</dc:creator>
 <dc:creator>Pontelli, Enrico</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The field of Distributed Constraint Optimization has gained momentum in
recent years thanks to its ability to address various applications related to
multi-agent cooperation. While techniques to solve Distributed Constraint
Optimization Problems (DCOPs) are abundant and have matured substantially since
the field inception, the number of DCOP realistic applications and benchmark
used to asses the performance of DCOP algorithms is lagging behind. To contrast
this background we (i) introduce the Smart Home Device Scheduling (SHDS)
problem, which describe the problem of coordinating smart devices schedules
across multiple homes as a multi-agent system, (ii) detail the physical models
adopted to simulate smart sensors, smart actuators, and homes environments, and
(iii) introduce a DCOP realistic benchmark for SHDS problems.
</dc:description>
 <dc:description>Comment: 15 pages, OPTMAS17</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06972</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximations of the Restless Bandit Problem</dc:title>
 <dc:creator>Grunewalder, Steffen</dc:creator>
 <dc:creator>Khaleghi, Azadeh</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The multi-armed restless bandit problem is studied in the case where the
pay-offs are not necessarily independent over time nor across the arms. Even
though this version of the problem provides a more realistic model for most
real-world applications, it cannot be optimally solved in practice since it is
known to be PSPACE-hard. The objective of this paper is to characterize special
sub-classes of the problem where good approximate solutions can be found using
tractable approaches. Specifically, it is shown that in the case where the
joint distribution over the arms is $\varphi$-mixing, and under some conditions
on the $\varphi$-mixing coefficients, a modified version of UCB can prove
optimal. On the other hand, it is shown that when the pay-off distributions are
strongly dependent, simple switching strategies may be devised which leverage
the strong inter-dependencies. To this end, an example is provided using
Gaussian Processes. The techniques developed in this paper apply, more
generally, to the problem of online sampling under dependence.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06973</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>jSET - The Java Software Evolution Tracker</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N01</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:description>  This paper introduces the Java Software Evolution Tracker, a visualization
and analysis tool that provides practitioners the means to examine the
evolution of a software system from a top to bottom perspective, starting with
changes in the graphical user interface all the way to source code
modifications.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06973</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Knowledge
  Engineering, Principles and Techniques (KEPT 2011), Cluj-Napoca, 2011, pages
  25-35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06976</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heavy-Tailed Analogues of the Covariance Matrix for ICA</dc:title>
 <dc:creator>Anderson, Joseph</dc:creator>
 <dc:creator>Goyal, Navin</dc:creator>
 <dc:creator>Nandi, Anupama</dc:creator>
 <dc:creator>Rademacher, Luis</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Independent Component Analysis (ICA) is the problem of learning a square
matrix $A$, given samples of $X=AS$, where $S$ is a random vector with
independent coordinates. Most existing algorithms are provably efficient only
when each $S_i$ has finite and moderately valued fourth moment. However, there
are practical applications where this assumption need not be true, such as
speech and finance. Algorithms have been proposed for heavy-tailed ICA, but
they are not practical, using random walks and the full power of the ellipsoid
algorithm multiple times. The main contributions of this paper are:
  (1) A practical algorithm for heavy-tailed ICA that we call HTICA. We provide
theoretical guarantees and show that it outperforms other algorithms in some
heavy-tailed regimes, both on real and synthetic data. Like the current
state-of-the-art, the new algorithm is based on the centroid body (a first
moment analogue of the covariance matrix). Unlike the state-of-the-art, our
algorithm is practically efficient. To achieve this, we use explicit analytic
representations of the centroid body, which bypasses the use of the ellipsoid
method and random walks.
  (2) We study how heavy tails affect different ICA algorithms, including
HTICA. Somewhat surprisingly, we show that some algorithms that use the
covariance matrix or higher moments can successfully solve a range of ICA
instances with infinite second moment. We study this theoretically and
experimentally, with both synthetic and real-world heavy-tailed data.
</dc:description>
 <dc:description>Comment: 16 Pages, 9 Figures, AAAI 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06980</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Polynomial Time Methods for Exact Low Rank Tensor Completion</dc:title>
 <dc:creator>Xia, Dong</dc:creator>
 <dc:creator>Yuan, Ming</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we investigate the sample size requirement for exact recovery
of a high order tensor of low rank from a subset of its entries. We show that a
gradient descent algorithm with initial value obtained from a spectral method
can, in particular, reconstruct a ${d\times d\times d}$ tensor of multilinear
ranks $(r,r,r)$ with high probability from as few as
$O(r^{7/2}d^{3/2}\log^{7/2}d+r^7d\log^6d)$ entries. In the case when the ranks
$r=O(1)$, our sample size requirement matches those for nuclear norm
minimization (Yuan and Zhang, 2016a), or alternating least squares assuming
orthogonal decomposability (Jain and Oh, 2014). Unlike these earlier
approaches, however, our method is efficient to compute, easy to implement, and
does not impose extra structures on the tensor. Numerical results are presented
to further demonstrate the merits of the proposed approach.
</dc:description>
 <dc:description>Comment: 56 pages, 4 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.06997</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Talagrand Functions: New Lower Bounds for Testing Monotonicity
  and Unateness</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Waingarten, Erik</dc:creator>
 <dc:creator>Xie, Jinyu</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We prove a lower bound of $\tilde{\Omega}(n^{1/3})$ for the query complexity
of any two-sided and adaptive algorithm that tests whether an unknown Boolean
function $f:\{0,1\}^n\rightarrow \{0,1\}$ is monotone or far from monotone.
This improves the recent bound of $\tilde{\Omega}(n^{1/4})$ for the same
problem by Belovs and Blais [BB15]. Our result builds on a new family of random
Boolean functions that can be viewed as a two-level extension of Talagrand's
random DNFs.
  Beyond monotonicity, we also prove a lower bound of $\tilde{\Omega}(n^{2/3})$
for any two-sided and adaptive algorithm, and a lower bound of
$\tilde{\Omega}(n)$ for any one-sided and non-adaptive algorithm for testing
unateness, a natural generalization of monotonicity. The latter matches the
recent linear upper bounds by Khot and Shinkar [KS15] and by Chakrabarty and
Seshadhri [CS16].
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.06997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07001</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical and Experimental Analysis of the Canadian Traveler Problem</dc:title>
 <dc:creator>Zarchy, Doron</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Devising an optimal strategy for navigation in a partially observable
environment is one of the key objectives in AI. One of the problem in this
context is the Canadian Traveler Problem (CTP). CTP is a navigation problem
where an agent is tasked to travel from source to target in a partially
observable weighted graph, whose edge might be blocked with a certain
probability and observing such blockage occurs only when reaching upon one of
the edges end points. The goal is to find a strategy that minimizes the
expected travel cost. The problem is known to be P$\#$ hard. In this work we
study the CTP theoretically and empirically. First, we study the Dep-CTP, a CTP
variant we introduce which assumes dependencies between the edges status. We
show that Dep-CTP is intractable, and further we analyze two of its subclasses
on disjoint paths graph. Second, we develop a general algorithm Gen-PAO that
optimally solve the CTP. Gen-PAO is capable of solving two other types of CTP
called Sensing-CTP and Expensive-Edges CTP. Since the CTP is intractable,
Gen-PAO use some pruning methods to reduce the space search for the optimal
solution. We also define some variants of Gen-PAO, compare their performance
and show some benefits of Gen-PAO over existing work.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07002</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic &amp; Adaptive Non-Submodular Maximization via the Primal
  Curvature</dc:title>
 <dc:creator>Smith, J. David</dc:creator>
 <dc:creator>Thai, My T.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2</dc:subject>
 <dc:description>  While greedy algorithms have long been observed to perform well on a wide
variety of problems, up to now approximation ratios have only been known for
their application to problems having submodular objective functions $f$. Since
many practical problems have non-submodular $f$, there is a critical need to
devise new techniques to bound the performance of greedy algorithms in the case
of non-submodularity.
  Our primary contribution is the introduction of a novel technique for
estimating the approximation ratio of the greedy algorithm for maximization of
monotone non-decreasing functions based on the curvature of $f$ without relying
on the submodularity constraint. We show that this technique reduces to the
classical $(1 - 1/e)$ ratio for submodular functions. Furthermore, we develop
an extension of this ratio to the adaptive greedy algorithm, which allows
applications to non-submodular stochastic maximization problems. This notably
extends support to applications modeling incomplete data with uncertainty.
</dc:description>
 <dc:description>Comment: revised version -- removes incorrect sampling method</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07005</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Stochastic Learning using GPUs</dc:title>
 <dc:creator>Parnell, Thomas</dc:creator>
 <dc:creator>D&#xfc;nner, Celestine</dc:creator>
 <dc:creator>Atasu, Kubilay</dc:creator>
 <dc:creator>Sifalakis, Manolis</dc:creator>
 <dc:creator>Pozidis, Haris</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this work we propose an accelerated stochastic learning system for very
large-scale applications. Acceleration is achieved by mapping the training
algorithm onto massively parallel processors: we demonstrate a parallel,
asynchronous GPU implementation of the widely used stochastic coordinate
descent/ascent algorithm that can provide up to 35x speed-up over a sequential
CPU implementation. In order to train on very large datasets that do not fit
inside the memory of a single GPU, we then consider techniques for distributed
stochastic learning. We propose a novel method for optimally aggregating model
updates from worker nodes when the training data is distributed either by
example or by feature. Using this technique, we demonstrate that one can scale
out stochastic learning across up to 8 worker nodes without any significant
loss of training time. Finally, we combine GPU acceleration with the optimized
distributed method to train on a dataset consisting of 200 million training
examples and 75 million features. We show by scaling out across 4 GPUs, one can
attain a high degree of training accuracy in around 4 seconds: a 20x speed-up
in training time compared to a multi-threaded, distributed implementation
across 4 CPUs.
</dc:description>
 <dc:description>Comment: Accepted for publication in ParLearning 2017: The 6th International
  Workshop on Parallel and Distributed Computing for Large Scale Machine
  Learning and Big Data Analytics, Orlando, Florida, May 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07006</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesising Dynamic Textures using Convolutional Neural Networks</dc:title>
 <dc:creator>Funke, Christina M.</dc:creator>
 <dc:creator>Gatys, Leon A.</dc:creator>
 <dc:creator>Ecker, Alexander S.</dc:creator>
 <dc:creator>Bethge, Matthias</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Here we present a parametric model for dynamic textures. The model is based
on spatiotemporal summary statistics computed from the feature representations
of a Convolutional Neural Network (CNN) trained on object recognition. We
demonstrate how the model can be used to synthesise new samples of dynamic
textures and to predict motion in simple movies.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07011</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Software Developers Mitigate Collaboration Friction with Chatbots</dc:title>
 <dc:creator>Lebeuf, Carlene</dc:creator>
 <dc:creator>Storey, Margaret-Anne</dc:creator>
 <dc:creator>Zagalsky, Alexey</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:description>  Modern software developers rely on an extensive set of social media tools and
communication channels. The adoption of team communication platforms has led to
the emergence of conversation-based tools and integrations, many of which are
chatbots. Understanding how software developers manage their complex
constellation of collaborators in conjunction with the practices and tools they
use can bring valuable insights into socio-technical collaborative work in
software development and other knowledge work domains.
  In this paper, we explore how chatbots can help reduce the friction points
software developers face when working collaboratively. Using a socio-technical
model for collaborative work, we identify three main areas for conflict:
friction stemming from team interactions with each other, an individual's
interactions with technology, and team interactions with technology. Finally,
we provide a set of open questions for discussion within the research
community.
</dc:description>
 <dc:description>Comment: 6 pages, accepted to the Talking with Conversational Agents in
  Collaborative Action Workshop at the 20th ACM conference on
  Computer-Supported Cooperative Work and Social Computing (CSCW '17)
  https://talkingwithagents.wordpress.com/position-papers/</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07013</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Hawkes Processes from Short Doubly-Censored Event Sequences</dc:title>
 <dc:creator>Xu, Hongteng</dc:creator>
 <dc:creator>Luo, Dixin</dc:creator>
 <dc:creator>Zha, Hongyuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many real-world applications require robust algorithms to learn point
processes based on a type of incomplete data --- the so-called short
doubly-censored (SDC) event sequences. We study this critical problem of
quantitative asynchronous event sequence analysis under the framework of Hawkes
processes by leveraging the idea of data synthesis. Given SDC event sequences
observed in a variety of time intervals, we propose a sampling-stitching data
synthesis method --- sampling predecessors and successors for each SDC event
sequence from potential candidates and stitching them together to synthesize
long training sequences. The rationality and the feasibility of our method are
discussed in terms of arguments based on likelihood. Experiments on both
synthetic and real-world data demonstrate that the proposed data synthesis
method improves learning results indeed for both time-invariant and
time-varying Hawkes processes.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07015</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning of Morphological Forests</dc:title>
 <dc:creator>Luo, Jiaming</dc:creator>
 <dc:creator>Narasimhan, Karthik</dc:creator>
 <dc:creator>Barzilay, Regina</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper focuses on unsupervised modeling of morphological families,
collectively comprising a forest over the language vocabulary. This formulation
enables us to capture edgewise properties reflecting single-step morphological
derivations, along with global distributional properties of the entire forest.
These global properties constrain the size of the affix set and encourage
formation of tight morphological families. The resulting objective is solved
using Integer Linear Programming (ILP) paired with contrastive estimation. We
train the model by alternating between optimizing the local log-linear model
and the global ILP objective. We evaluate our system on three tasks: root
detection, clustering of morphological families and segmentation. Our
experiments demonstrate that our model yields consistent gains in all three
tasks compared with the best published results.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures, accepted by TACL 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07019</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CT Image Denoising with Perceptive Deep Neural Networks</dc:title>
 <dc:creator>Yang, Qingsong</dc:creator>
 <dc:creator>Yan, Pingkun</dc:creator>
 <dc:creator>Kalra, Mannudeep K.</dc:creator>
 <dc:creator>Wang, Ge</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Increasing use of CT in modern medical practice has raised concerns over
associated radiation dose. Reduction of radiation dose associated with CT can
increase noise and artifacts, which can adversely affect diagnostic confidence.
Denoising of low-dose CT images on the other hand can help improve diagnostic
confidence, which however is a challenging problem due to its ill-posed nature,
since one noisy image patch may correspond to many different output patches. In
the past decade, machine learning based approaches have made quite impressive
progress in this direction. However, most of those methods, including the
recently popularized deep learning techniques, aim for minimizing
mean-squared-error (MSE) between a denoised CT image and the ground truth,
which results in losing important structural details due to over-smoothing,
although the PSNR based performance measure looks great. In this work, we
introduce a new perceptual similarity measure as the objective function for a
deep convolutional neural network to facilitate CT image denoising. Instead of
directly computing MSE for pixel-to-pixel intensity loss, we compare the
perceptual features of a denoised output against those of the ground truth in a
feature space. Therefore, our proposed method is capable of not only reducing
the image noise levels, but also keeping the critical structural information at
the same time. Promising results have been obtained in our experiments with a
large number of CT images.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07021</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One Size Fits Many: Column Bundle for Multi-X Learning</dc:title>
 <dc:creator>Pham, Trang</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Much recent machine learning research has been directed towards leveraging
shared statistics among labels, instances and data views, commonly referred to
as multi-label, multi-instance and multi-view learning. The underlying premises
are that there exist correlations among input parts and among output targets,
and the predictive performance would increase when the correlations are
incorporated. In this paper, we propose Column Bundle (CLB), a novel deep
neural network for capturing the shared statistics in data. CLB is generic that
the same architecture can be applied for various types of shared statistics by
changing only input and output handling. CLB is capable of scaling to thousands
of input parts and output labels by avoiding explicit modeling of pairwise
relations. We evaluate CLB on different types of data: (a) multi-label, (b)
multi-view, (c) multi-view/multi-label and (d) multi-instance. CLB demonstrates
a comparable and competitive performance in all datasets against
state-of-the-art methods designed specifically for each type.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07025</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Neural Network Committees for Melanoma Classification with
  Classical And Expert Knowledge Based Image Transforms Data Augmentation</dc:title>
 <dc:creator>Vasconcelos, Cristina Nader</dc:creator>
 <dc:creator>Vasconcelos, B&#xe1;rbara Nader</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Skin cancer is a major public health problem, as is the most common type of
cancer and represents more than half of cancer diagnoses worldwide. Early
detection influences the outcome of the disease and motivates our work. We
investigate the composition of CNN committees and data augmentation for the the
ISBI 2017 Melanoma Classification Challenge (named Skin Lesion Analysis towards
Melanoma Detection) facing the peculiarities of dealing with such a small,
unbalanced, biological database. For that, we explore committees of
Convolutional Neural Networks trained over the ISBI challenge training dataset
artificially augmented by both classical image processing transforms and image
warping guided by specialist knowledge about the lesion axis and improve the
final classifier invariance to common melanoma variations.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07028</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the ability of neural nets to express distributions</dc:title>
 <dc:creator>Lee, Holden</dc:creator>
 <dc:creator>Ge, Rong</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:creator>Arora, Sanjeev</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural nets have caused a revolution in many classification tasks. A
related ongoing revolution---also theoretically not understood---concerns their
ability to serve as generative models for complicated types of data such as
images and texts. These models are trained using ideas like variational
autoencoders and Generative Adversarial Networks.
  We take a first cut at explaining the expressivity of multilayer nets by
giving a sufficient criterion for a function to be approximable by a neural
network with $n$ hidden layers. A key ingredient is Barron's Theorem
\cite{Barron1993}, which gives a Fourier criterion for approximability of a
function by a neural network with 1 hidden layer. We show that a composition of
$n$ functions which satisfy certain Fourier conditions (&quot;Barron functions&quot;) can
be approximated by a $n+1$-layer neural network.
  For probability distributions, this translates into a criterion for a
probability distribution to be approximable in Wasserstein distance---a natural
metric on probability distributions---by a neural network applied to a fixed
base distribution (e.g., multivariate gaussian).
  Building up recent lower bound work, we also give an example function that
shows that composition of Barron functions is more expressive than Barron
functions alone.
</dc:description>
 <dc:description>Comment: Accepted to COLT 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07029</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Initial Study on Ideal GUI Test Case Replayability</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:description>  In this paper we investigate the effect of long-term GUI changes occurring
during application development on the reusability of existing GUI test cases.
We conduct an empirical evaluation on two complex, open-source GUI-driven
applications for which we generate test cases of various lengths. We then
assess the replayability of generated test cases using simulation on newer
versions of the target applications and partition them according to the type of
repairing change required for their reuse.
</dc:description>
 <dc:description>Comment: http://ieeexplore.ieee.org/document/6237736/</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07029</dc:identifier>
 <dc:identifier>doi:10.1109/AQTR.2012.6237736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07030</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Net-Zero Settlement in Distribution Markets</dc:title>
 <dc:creator>Parhizi, Sina</dc:creator>
 <dc:creator>Majzoobi, Alireza</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Introduction of market mechanisms in distribution systems is currently
subject to extensive studies. One of the challenges facing Distribution Market
Operators (DMOs) is to implement a fair and economically efficient pricing
mechanism that can incentivize consumers to positively contribute to grid
operations and to improve economic performance of the distribution system. This
paper studies a penalty-based pricing mechanism in distribution markets and
further investigates the interrelationship between the locational marginal
prices (LMPs) at transmission and distribution levels. As a result, a
closed-form relationship between these LMPs is derived. The possibility of
zeroing out the settlement profit is further investigated under the proposed
pricing mechanism.
</dc:description>
 <dc:description>Comment: Accepted to the IEEE Power and Energy General Meeting 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07031</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proactive Resource Management in LTE-U Systems: A Deep Learning
  Perspective</dc:title>
 <dc:creator>Challita, Ursula</dc:creator>
 <dc:creator>Dong, Li</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  LTE in unlicensed spectrum (LTE-U) is a promising approach to overcome the
wireless spectrum scarcity. However, to reap the benefits of LTE-U, a fair
coexistence mechanism with other incumbent WiFi deployments is required. In
this paper, a novel deep learning approach is proposed for modeling the
resource allocation problem of LTE-U small base stations (SBSs). The proposed
approach enables multiple SBSs to proactively perform dynamic channel
selection, carrier aggregation, and fractional spectrum access while
guaranteeing fairness with existing WiFi networks and other LTE-U operators.
Adopting a proactive coexistence mechanism enables future delay-intolerant
LTE-U data demands to be served within a given prediction window ahead of their
actual arrival time thus avoiding the underutilization of the unlicensed
spectrum during off-peak hours while maximizing the total served LTE-U traffic
load. To this end, a noncooperative game model is formulated in which SBSs are
modeled as Homo Egualis agents that aim at predicting a sequence of future
actions and thus achieving long-term equal weighted fairness with WLAN and
other LTE-U operators over a given time horizon. The proposed deep learning
algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when
it converges. Simulation results using real data traces show that the proposed
scheme can yield up to 28% and 11% gains over a conventional reactive approach
and a proportional fair coexistence mechanism, respectively. The results also
show that the proposed framework prevents WiFi performance degradation for a
densely deployed LTE-U network.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07032</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Complexity of Simple and Optimal Deterministic Mechanisms for an
  Additive Buyer</dc:title>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Matikas, George</dc:creator>
 <dc:creator>Paparas, Dimitris</dc:creator>
 <dc:creator>Yannakakis, Mihalis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show that the Revenue-Optimal Deterministic Mechanism Design problem for a
single additive buyer is #P-hard, even when the distributions have support size
2 for each item and, more importantly, even when the optimal solution is
guaranteed to be of a very simple kind: the seller picks a price for each
individual item and a price for the grand bundle of all the items; the buyer
can purchase either the grand bundle at its given price or any subset of items
at their total individual prices. The following problems are also #P-hard, as
immediate corollaries of the proof:
  1. determining if individual item pricing is optimal for a given instance,
  2. determining if grand bundle pricing is optimal, and
  3. computing the optimal (deterministic) revenue.
  On the positive side, we show that when the distributions are i.i.d. with
support size 2, the optimal revenue obtainable by any mechanism, even a
randomized one, can be achieved by a simple solution of the above kind
(individual item pricing with a discounted price for the grand bundle) and
furthermore, it can be computed in polynomial time. The problem can be solved
in polynomial time too when the number of items is constant.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07044</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FM Backscatter: Enabling Connected Cities and Smart Fabrics</dc:title>
 <dc:creator>Wang, Anran</dc:creator>
 <dc:creator>Iyer, Vikram</dc:creator>
 <dc:creator>Talla, Vamsi</dc:creator>
 <dc:creator>Smith, Joshua R.</dc:creator>
 <dc:creator>Gollakota, Shyamnath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper enables connectivity on everyday objects by transforming them into
FM radio stations. To do this, we show for the first time that ambient FM radio
signals can be used as a signal source for backscatter communication. Our
design creates backscatter transmissions that can be decoded on any FM receiver
including those in cars and smartphones. This enables us to achieve a
previously infeasible capability: backscattering information to cars and
smartphones in outdoor environments.
  Our key innovation is a modulation technique that transforms backscatter,
which is a multiplication operation on RF signals, into an addition operation
on the audio signals output by FM receivers. This enables us to embed both
digital data as well as arbitrary audio into ambient analog FM radio signals.
We build prototype hardware of our design and successfully embed audio
transmissions over ambient FM signals. Further, we achieve data rates of up to
3.2 kbps and ranges of 5-60 feet, while consuming as little as 11.07{\mu}W of
power. To demonstrate the potential of our design, we also fabricate our
prototype on a cotton t-shirt by machine sewing patterns of a conductive thread
to create a smart fabric that can transmit data to a smartphone. We also embed
FM antennas into posters and billboards and show that they can communicate with
FM receivers in cars and smartphones.
</dc:description>
 <dc:description>Comment: NSDI 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07046</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Generation for Robust Semantic Role Labeling</dc:title>
 <dc:creator>Wolfe, Travis</dc:creator>
 <dc:creator>Dredze, Mark</dc:creator>
 <dc:creator>Van Durme, Benjamin</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Hand-engineered feature sets are a well understood method for creating robust
NLP models, but they require a lot of expertise and effort to create. In this
work we describe how to automatically generate rich feature sets from simple
units called featlets, requiring less engineering. Using information gain to
guide the generation process, we train models which rival the state of the art
on two standard Semantic Role Labeling datasets with almost no task or
linguistic insight.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07054</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Chained Deep Features and Classifiers for Cascade in Object
  Detection</dc:title>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Wang, Ku</dc:creator>
 <dc:creator>Zhu, Xin</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Cascade is a widely used approach that rejects obvious negative samples at
early stages for learning better classifier and faster inference. This paper
presents chained cascade network (CC-Net). In this CC-Net, the cascaded
classifier at a stage is aided by the classification scores in previous stages.
Feature chaining is further proposed so that the feature learning for the
current cascade stage uses the features in previous stages as the prior
information. The chained ConvNet features and classifiers of multiple stages
are jointly learned in an end-to-end network. In this way, features and
classifiers at latter stages handle more difficult samples with the help of
features and classifiers in previous stages. It yields consistent boost in
detection performance on benchmarks like PASCAL VOC 2007 and ImageNet. Combined
with better region proposal, CC-Net leads to state-of-the-art result of 81.1%
mAP on PASCAL VOC 2007.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07054</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07056</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-shell Sampling Scheme with Accurate and Efficient Transforms for
  Diffusion MRI</dc:title>
 <dc:creator>Bates, Alice P.</dc:creator>
 <dc:creator>Khalid, Zubair</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:creator>McEwen, Jason D.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We propose a multi-shell sampling grid and develop corresponding transforms
for the accurate reconstruction of the diffusion signal in diffusion MRI by
expansion in the spherical polar Fourier (SPF) basis. The transform is exact in
the radial direction and accurate, on the order of machine precision, in the
angular direction. The sampling scheme uses an optimal number of samples equal
to the degrees of freedom of the diffusion signal in the SPF domain.
</dc:description>
 <dc:description>Comment: 1 page, 1 figure, presented as a poster at the 2017 Biomedical and
  Astronomical Image Processing (BASP) Workshop</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07059</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and fully automated segmentation of mandible from CT scans</dc:title>
 <dc:creator>Torosdagli, Neslisah</dc:creator>
 <dc:creator>Liberton, Denise K.</dc:creator>
 <dc:creator>Verma, Payal</dc:creator>
 <dc:creator>Lee, Murat Sincan Janice</dc:creator>
 <dc:creator>Pattanaik, Sumanta</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mandible bone segmentation from computed tomography (CT) scans is challenging
due to mandible's structural irregularities, complex shape patterns, and lack
of contrast in joints. Furthermore, connections of teeth to mandible and
mandible to remaining parts of the skull make it extremely difficult to
identify mandible boundary automatically. This study addresses these challenges
by proposing a novel framework where we define the segmentation as two
complementary tasks: recognition and delineation. For recognition, we use
random forest regression to localize mandible in 3D. For delineation, we
propose to use 3D gradient-based fuzzy connectedness (FC) image segmentation
algorithm, operating on the recognized mandible sub-volume. Despite heavy CT
artifacts and dental fillings, consisting half of the CT image data in our
experiments, we have achieved highly accurate detection and delineation
results. Specifically, detection accuracy more than 96% (measured by union of
intersection (UoI)), the delineation accuracy of 91% (measured by dice
similarity coefficient), and less than 1 mm in shape mismatch (Hausdorff
Distance) were found.
</dc:description>
 <dc:description>Comment: 4 pages, 5 figures, IEEE International Symposium on Biomedical
  Imaging (ISBI) 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07060</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithm for computing semi-Fourier sequences of expressions involving
  exponentiations and integrations</dc:title>
 <dc:creator>Hong, Hoon</dc:creator>
 <dc:creator>Strzebonski, Adam</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>68W30, 26-04, 26A99</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  We provide an algorithm for computing semi-Fourier sequences for expressions
constructed from arithmetic operations, exponentiations and integrations. The
semi-Fourier sequence is a relaxed version of Fourier sequence for polynomials
(expressions made of additions and multiplications).
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07064</identifier>
 <datestamp>2017-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Model Predictive Control for Iterative Tasks: A Computationally
  Efficient Approach for Linear System</dc:title>
 <dc:creator>Rosolia, Ugo</dc:creator>
 <dc:creator>Borrelli, Francesco</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A Learning Model Predictive Controller (LMPC) for linear system in presented.
The proposed controller is an extension of the LMPC [1] and it aims to decrease
the computational burden. The control scheme is reference-free and is able to
improve its performance by learning from previous iterations. A convex safe set
and a terminal cost function are used in order to guarantee recursive
feasibility and non- increasing performance at each iteration. The paper
presents the control design approach, and shows how to recursively construct
the convex terminal set and the terminal cost from state and input trajectories
of previous iterations. Simulation results show the effectiveness of the
proposed control logic.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1609.01387</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-05-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07069</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flipping a Graduate-Level Software Engineering Foundations Course</dc:title>
 <dc:creator>Erdogmus, Hakan</dc:creator>
 <dc:creator>Peraire, Cecile</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Creating a graduate-level software engineering breadth course is challenging.
The scope is wide. Students prefer hands-on work over theory. Industry
increasingly values soft skills. Changing software technology requires the
syllabus to be technology-agnostic, yet abstracting away technology compromises
realism. Instructors must balance scope with depth of learning. At Carnegie
Mellon University, we designed a flipped-classroom course that tackles these
tradeoffs. The course has been offered since Fall 2014 in the Silicon Valley
campus. In this paper, we describe the course's key features and summarize our
experiences and lessons learned while designing, teaching, and maintaining it.
We found that the pure flipped-classroom format was not optimal in ensuring
sufficient transfer of knowledge, especially in remote settings. We initially
underestimated teaching assistantship resources. We gradually complemented
video lectures and hands-on live sessions with additional live components:
easily replaceable recitations that focus on current technology and mini
lectures that address application of theory and common wisdom. We also provided
the students with more opportunities to share their successes and experiments
with their peers. We achieved scalability by increasing the number of teaching
assistants, paying attention to teaching assistant recruitment, and fostering a
culture of mentoring among the teaching team.
</dc:description>
 <dc:description>Comment: 10 pages, accepted to ICSE 2017, Software Engineering and Education
  Track</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07071</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Pronunciation recognition of English phonemes /\textipa{@}/, /{\ae}/,
  /\textipa{A}:/ and /\textipa{2}/ using Formants and Mel Frequency Cepstral
  Coefficients</dc:title>
 <dc:creator>Patarroyo, Keith Y.</dc:creator>
 <dc:creator>Vargas-Calder&#xf3;n, Vladimir</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  The Vocal Joystick Vowel Corpus, by Washington University, was used to study
monophthongs pronounced by native English speakers. The objective of this study
was to quantitatively measure the extent at which speech recognition methods
can distinguish between similar sounding vowels. In particular, the phonemes
/\textipa{@}/, /{\ae}/, /\textipa{A}:/ and /\textipa{2}/ were analysed. 748
sound files from the corpus were used and subjected to Linear Predictive Coding
(LPC) to compute their formants, and to Mel Frequency Cepstral Coefficients
(MFCC) algorithm, to compute the cepstral coefficients. A Decision Tree
Classifier was used to build a predictive model that learnt the patterns of the
two first formants measured in the data set, as well as the patterns of the 13
cepstral coefficients. An accuracy of 70\% was achieved using formants for the
mentioned phonemes. For the MFCC analysis an accuracy of 52 \% was achieved and
an accuracy of 71\% when /\textipa{@}/ was ignored. The results obtained show
that the studied algorithms are far from mimicking the ability of
distinguishing subtle differences in sounds like human hearing does.
</dc:description>
 <dc:description>Comment: 11 pages, pre-print version</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07071</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07076</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Fuzzy Modeling Using Deep Learning</dc:title>
 <dc:creator>de la Rosa, Erick</dc:creator>
 <dc:creator>Yu, Wen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Fuzzy modeling has many advantages over the non-fuzzy methods, such as
robustness against uncertainties and less sensitivity to the varying dynamics
of nonlinear systems. Data-driven fuzzy modeling needs to extract fuzzy rules
from the input/output data, and train the fuzzy parameters. This paper takes
advantages from deep learning, probability theory, fuzzy modeling, and extreme
learning machines. We use the restricted Boltzmann machine (RBM) and
probability theory to overcome some common problems in data based modeling
methods. The RBM is modified such that it can be trained with continuous
values. A probability based clustering method is proposed to partition the
hidden features from the RBM, and extract fuzzy rules with probability
measurement. An extreme learning machine and an optimization method are applied
to train the consequent part of the fuzzy rules and the probability parameters.
The proposed method is validated with two benchmark problems.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07076</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07081</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DyAdHyTM: A Low Overhead Dynamically Adaptive Hybrid Transactional
  Memory on Big Data Graphs</dc:title>
 <dc:creator>Qayum, Mohammad</dc:creator>
 <dc:creator>Badawy, Abdel-Hameed</dc:creator>
 <dc:creator>Cook, Jeanine</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data is a buzzword used to describe massive volumes of data that provides
opportunities of exploring new insights through data analytics. However, big
data is mostly structured but can be semi-structured or unstructured. It is
normally so large that it is not only difficult but also slow to process using
traditional computing systems. One of the solutions is to format the data as
graph data structures and process them on shared memory architecture to use
fast and novel policies such as transactional memory. In most graph
applications in big data type problems such as bioinformatics, social networks,
and cyber security, graphs are sparse in nature. Due to this sparsity, we have
the opportunity to use Transactional Memory (TM) as the synchronization policy
for critical sections to speedup applications. At low conflict probability TM
performs better than most synchronization policies due to its inherent
non-blocking characteristics. TM can be implemented in Software, Hardware or a
combination of both. However, hardware TM implementations are fast but limited
by scarce hardware resources while software implementations have high overheads
which can degrade performance. In this paper, we develop a low overhead, yet
simple, dynamically adaptive (i.e. at runtime) hybrid (i.e. combines hardware
and software) TM (DyAdHyTM) scheme that combines the best features of both
Hardware TM (HTM) and Software TM (STM) while adapting to application
requirements. It performs better than coarse grain lock by up to 8.12x, a low
overhead STM by up to 2.68x, a couple of implementations of HTMs (by up to
2.59x), and other HyTMs (by up to 1.55x) for SSCA2 graph benchmark running on a
multicore machine with a large shared memory.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07083</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Inference for Nested Chinese Restaurant Process Topic Models</dc:title>
 <dc:creator>Chen, Jianfei</dc:creator>
 <dc:creator>Zhu, Jun</dc:creator>
 <dc:creator>Lu, Jie</dc:creator>
 <dc:creator>Liu, Shixia</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Nested Chinese Restaurant Process (nCRP) topic models are powerful
nonparametric Bayesian methods to extract a topic hierarchy from a given text
corpus, where the hierarchical structure is automatically determined by the
data. Hierarchical Latent Dirichlet Allocation (hLDA) is a popular instance of
nCRP topic models. However, hLDA has only been evaluated at small scale,
because the existing collapsed Gibbs sampling and instantiated weight
variational inference algorithms either are not scalable or sacrifice inference
quality with mean-field assumptions. Moreover, an efficient distributed
implementation of the data structures, such as dynamically growing count
matrices and trees, is challenging.
  In this paper, we propose a novel partially collapsed Gibbs sampling (PCGS)
algorithm, which combines the advantages of collapsed and instantiated weight
algorithms to achieve good scalability as well as high model quality. An
initialization strategy is presented to further improve the model quality.
Finally, we propose an efficient distributed implementation of PCGS through
vectorization, pre-processing, and a careful design of the concurrent data
structures and communication strategy.
  Empirical studies show that our algorithm is 111 times more efficient than
the previous open-source implementation for hLDA, with comparable or even
better model quality. Our distributed implementation can extract 1,722 topics
from a 131-million-document corpus with 28 billion tokens, which is 4-5 orders
of magnitude larger than the previous largest corpus, with 50 machines in 7
hours.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07092</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Neural Attention Model for Categorizing Patient Safety Events</dc:title>
 <dc:creator>Cohan, Arman</dc:creator>
 <dc:creator>Fong, Allan</dc:creator>
 <dc:creator>Goharian, Nazli</dc:creator>
 <dc:creator>Ratwani, Raj</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Medical errors are leading causes of death in the US and as such, prevention
of these errors is paramount to promoting health care. Patient Safety Event
reports are narratives describing potential adverse events to the patients and
are important in identifying and preventing medical errors. We present a neural
network architecture for identifying the type of safety events which is the
first step in understanding these narratives. Our proposed model is based on a
soft neural attention model to improve the effectiveness of encoding long
sequences. Empirical results on two large-scale real-world datasets of patient
safety reports demonstrate the effectiveness of our method with significant
improvements over existing methods.
</dc:description>
 <dc:description>Comment: ECIR 2017</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07097</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bidirectional Backpropagation: Towards Biologically Plausible Error
  Signal Transmission in Neural Networks</dc:title>
 <dc:creator>Luo, Hongyin</dc:creator>
 <dc:creator>Fu, Jie</dc:creator>
 <dc:creator>Glass, James</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The back-propagation (BP) algorithm has been considered the de-facto method
for training deep neural networks. It back-propagates errors from the output
layer to the hidden layers in an exact manner using the transpose of the
feedforward weights. However, it has been argued that this is not biologically
plausible because back-propagating error signals with the exact incoming
weights is not considered possible in biological neural systems. In this work,
we propose a biologically plausible paradigm of neural architecture based on
related literature in neuroscience and asymmetric BP-like methods.
Specifically, we propose two bidirectional learning algorithms with trainable
feedforward and feedback weights. The feedforward weights are used to relay
activations from the inputs to target outputs. The feedback weights pass the
error signals from the output layer to the hidden layers. Different from other
asymmetric BP-like methods, the feedback weights are also plastic in our
framework and are trained to approximate the forward activations. Preliminary
results show that our models outperform other asymmetric BP-like methods on the
MNIST and the CIFAR-10 datasets.
</dc:description>
 <dc:description>Comment: [v2]Extended the paper to the length of a long paper; added
  references in introduction; corrected the experiments of BFA. [v3] Added link
  to source code</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07099</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Carina: Interactive Million-Node Graph Visualization using Web Browser
  Technologies</dc:title>
 <dc:creator>Fang, Dezhi</dc:creator>
 <dc:creator>Keezer, Matthew</dc:creator>
 <dc:creator>Williams, Jacob</dc:creator>
 <dc:creator>Kulkarni, Kshitij</dc:creator>
 <dc:creator>Pienta, Robert</dc:creator>
 <dc:creator>Chau, Duen Horng</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We are working on a scalable, interactive visualization system, called
Carina, for people to explore million-node graphs. By using latest web browser
technologies, Carina offers fast graph rendering via WebGL, and works across
desktop (via Electron) and mobile platforms. Different from most existing graph
visualization tools, Carina does not store the full graph in RAM, enabling it
to work with graphs with up to 69M edges. We are working to improve and
open-source Carina, to offer researchers and practitioners a new, scalable way
to explore and visualize large graph datasets.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07099</dc:identifier>
 <dc:identifier>doi:10.1145/3041021.3054234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07103</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminating Traces with Time</dc:title>
 <dc:creator>Tizpaz-Niari, Saeid</dc:creator>
 <dc:creator>Cerny, Pavol</dc:creator>
 <dc:creator>Chang, Bor-Yuh Evan</dc:creator>
 <dc:creator>Sankaranarayanan, Sriram</dc:creator>
 <dc:creator>Trivedi, Ashutosh</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  What properties about the internals of a program explain the possible
differences in its overall running time for different inputs? In this paper, we
propose a formal framework for considering this question we dub trace-set
discrimination. We show that even though the algorithmic problem of computing
maximum likelihood discriminants is NP-hard, approaches based on integer linear
programming (ILP) and decision tree learning can be useful in zeroing-in on the
program internals. On a set of Java benchmarks, we find that
compactly-represented decision trees scalably discriminate with high
accuracy---more scalably than maximum likelihood discriminants and with
comparable accuracy. We demonstrate on three larger case studies how
decision-tree discriminants produced by our tool are useful for debugging
timing side-channel vulnerabilities (i.e., where a malicious observer infers
secrets simply from passively watching execution times) and availability
vulnerabilities.
</dc:description>
 <dc:description>Comment: Published in TACAS 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07107</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The discrete logarithm problem over prime fields: the safe prime case.
  The Smart attack, non-canonical lifts and logarithmic derivatives</dc:title>
 <dc:creator>Gadiyar, H. Gopalakrishna</dc:creator>
 <dc:creator>Padma, R.</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>11A07, 11T71, 11Y16, 14G50, 68Q25, 94A60</dc:subject>
 <dc:description>  In this brief note we connect the discrete logarithm problem over prime
fields in the safe prime case to the logarithmic derivative.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07108</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiuser Millimeter Wave Beamforming Strategies with Quantized and
  Statistical CSIT</dc:title>
 <dc:creator>Dai, Mingbo</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To alleviate the high cost of hardware in mmWave systems, hybrid
analog/digital precoding is typically employed. In the conventional two-stage
feedback scheme, the analog beamformer is determined by beam search and
feedback to maximize the desired signal power of each user. The digital
precoder is designed based on quantization and feedback of effective channel to
mitigate multiuser interference. Alternatively, we propose a one-stage feedback
scheme which effectively reduces the complexity of the signalling and feedback
procedure. Specifically, the second-order channel statistics are leveraged to
design digital precoder for interference mitigation while all feedback overhead
is reserved for precise analog beamforming. Under a fixed total feedback
constraint, we investigate the conditions under which the one-stage feedback
scheme outperforms the conventional two-stage counterpart. Moreover, a rate
splitting (RS) transmission strategy is introduced to further tackle the
multiuser interference and enhance the rate performance. Consider (1) RS
precoded by the one-stage feedback scheme and (2) conventional transmission
strategy precoded by the two-stage scheme with the same first-stage feedback as
(1) and also certain amount of extra second-stage feedback. We show that (1)
can achieve a sum rate comparable to that of (2). Hence, RS enables remarkable
saving in the second-stage training and feedback overhead.
</dc:description>
 <dc:description>Comment: submitted to TWC</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07108</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07109</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of a Cognitive VLC Network with Illumination and Handover
  Requirements</dc:title>
 <dc:creator>Hammouda, Marwan</dc:creator>
 <dc:creator>Peissig, J&#xfc;rgen</dc:creator>
 <dc:creator>Vegni, Anna Maria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider a cognitive indoor visible light communications
(VLC) system, comprised of multiple access points serving primary and secondary
users through the orthogonal frequency division multiple access method. A
cognitive lighting cell is divided into two non-overlapping regions that
distinguish the primary and secondary users based on the region they are
located in. Under the assumption of equal-power allocation among subcarriers,
each region is defined in terms of its physical area and the number of
allocated subcarriers within that region. In this paper, we provide the
lighting cell design with cognitive constraints that guarantee fulfilling
certain illumination, user mobility, and handover requirements in each cell. We
further argue that, under some conditions, a careful assignment of the
subcarriers in each region can mitigate the co-channel interference in the
overlapping areas of adjacent cells. Numerical results depict the influence of
different system parameters, such as user density, on defining both regions.
Finally, a realistic example is implemented to assess the performance of the
proposed scheme via Monte Carlo simulations.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07117</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LTSG: Latent Topical Skip-Gram for Mutually Learning Topic Model and
  Vector Representations</dc:title>
 <dc:creator>Law, Jarvan</dc:creator>
 <dc:creator>Zhuo, Hankz Hankui</dc:creator>
 <dc:creator>He, Junhua</dc:creator>
 <dc:creator>Rong, Erhu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Topic models have been widely used in discovering latent topics which are
shared across documents in text mining. Vector representations, word embeddings
and topic embeddings, map words and topics into a low-dimensional and dense
real-value vector space, which have obtained high performance in NLP tasks.
However, most of the existing models assume the result trained by one of them
are perfect correct and used as prior knowledge for improving the other model.
Some other models use the information trained from external large corpus to
help improving smaller corpus. In this paper, we aim to build such an algorithm
framework that makes topic models and vector representations mutually improve
each other within the same corpus. An EM-style algorithm framework is employed
to iteratively optimize both topic model and vector representations.
Experimental results show that our model outperforms state-of-art methods on
various NLP tasks.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07121</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent On-Line Off-Policy Evaluation</dc:title>
 <dc:creator>Hallak, Assaf</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The problem of on-line off-policy evaluation (OPE) has been actively studied
in the last decade due to its importance both as a stand-alone problem and as a
module in a policy improvement scheme. However, most Temporal Difference (TD)
based solutions ignore the discrepancy between the stationary distribution of
the behavior and target policies and its effect on the convergence limit when
function approximation is applied. In this paper we propose the Consistent
Off-Policy Temporal Difference (COP-TD($\lambda$, $\beta$)) algorithm that
addresses this issue and reduces this bias at some computational expense. We
show that COP-TD($\lambda$, $\beta$) can be designed to converge to the same
value that would have been obtained by using on-policy TD($\lambda$) with the
target policy. Subsequently, the proposed scheme leads to a related and
promising heuristic we call log-COP-TD($\lambda$, $\beta$). Both algorithms
have favorable empirical results to the current state of the art on-line OPE
algorithms. Finally, our formulation sheds some new light on the recently
proposed Emphatic TD learning.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07124</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trojan of Things: Embedding Malicious NFC Tags into Common Objects</dc:title>
 <dc:creator>Maruyama, Seita</dc:creator>
 <dc:creator>Wakabayashi, Satohiro</dc:creator>
 <dc:creator>Mori, Tatsuya</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present a novel proof-of-concept attack named Trojan of Things (ToT),
which aims to attack NFC- enabled mobile devices such as smartphones. The key
idea of ToT attacks is to covertly embed maliciously programmed NFC tags into
common objects routinely encountered in daily life such as banknotes, clothing,
or furniture, which are not considered as NFC touchpoints. To fully explore the
threat of ToT, we develop two striking techniques named ToT device and Phantom
touch generator. These techniques enable an attacker to carry out various
severe and sophisticated attacks unbeknownst to the device owner who
unintentionally puts the device close to a ToT. We discuss the feasibility of
the attack as well as the possible countermeasures against the threats of ToT
attacks.
</dc:description>
 <dc:description>Comment: 21 pages, 19 figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07125</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Representation for Lifetime Value Recommender Systems</dc:title>
 <dc:creator>Hallak, Assaf</dc:creator>
 <dc:creator>Mansour, Yishay</dc:creator>
 <dc:creator>Yom-Tov, Elad</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many modern commercial sites employ recommender systems to propose relevant
content to users. While most systems are focused on maximizing the immediate
gain (clicks, purchases or ratings), a better notion of success would be the
lifetime value (LTV) of the user-system interaction. The LTV approach considers
the future implications of the item recommendation, and seeks to maximize the
cumulative gain over time. The Reinforcement Learning (RL) framework is the
standard formulation for optimizing cumulative successes over time. However, RL
is rarely used in practice due to its associated representation, optimization
and validation techniques which can be complex. In this paper we propose a new
architecture for combining RL with recommendation systems which obviates the
need for hand-tuned features, thus automating the state-space representation
construction process. We analyze the practical difficulties in this formulation
and test our solutions on batch off-line real-world recommendation data.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07125</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07128</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Facets of the Bases Polytope of a Matroid and Two Consequences</dc:title>
 <dc:creator>Chaourar, Brahim</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Primary 90C27, Secondary 90C57, 52B40</dc:subject>
 <dc:description>  Let $M$ to be a matroid defined on a finite set $E$ and $L\subset E$. $L$ is
locked in $M$ if $M|L$ and $M^*|(E\backslash L)$ are 2-connected, and
$min\{r(L), r^*(E\backslash L)\} \geq 2$. In this paper, we prove that the
nontrivial facets of the bases polytope of $M$ are described by the locked
subsets. We deduce that finding the maximum--weight basis of $M$ is a
polynomial time problem for matroids with a polynomial number of locked
subsets. This class of matroids is closed under 2-sums and contains the class
of uniform matroids, the V\'amos matroid and all the excluded minors of 2-sums
of uniform matroids. We deduce also a matroid oracle for testing uniformity of
matroids after one call of this oracle.
</dc:description>
 <dc:description>Comment: 8 pages. arXiv admin note: text overlap with arXiv:1606.05384</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07134</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diverse Weighted Bipartite b-Matching</dc:title>
 <dc:creator>Ahmed, Faez</dc:creator>
 <dc:creator>Dickerson, John P.</dc:creator>
 <dc:creator>Fuge, Mark</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Bipartite matching, where agents on one side of a market are matched to
agents or items on the other, is a classical problem in computer science and
economics, with widespread application in healthcare, education, advertising,
and general resource allocation. A practitioner's goal is typically to maximize
a matching market's economic efficiency, possibly subject to some fairness
requirements that promote equal access to resources. A natural balancing act
exists between fairness and efficiency in matching markets, and has been the
subject of much research.
  In this paper, we study a complementary goal---balancing diversity and
efficiency---in a generalization of bipartite matching where agents on one side
of the market can be matched to sets of agents on the other. Adapting a
classical definition of the diversity of a set, we propose a quadratic
programming-based approach to solving a supermodular minimization problem that
balances diversity and total weight of the solution. We also provide a scalable
greedy algorithm with theoretical performance bounds. We then define the price
of diversity, a measure of the efficiency loss due to enforcing diversity, and
give a worst-case theoretical bound. Finally, we demonstrate the efficacy of
our methods on three real-world datasets, and show that the price of diversity
is not bad in practice.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07134</dc:identifier>
 <dc:identifier>doi:10.24963/ijcai.2017/6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07136</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Active Attacks on Wireless Sensor Networks and their
  Countermeasures</dc:title>
 <dc:creator>Shahzad, Furrakh</dc:creator>
 <dc:creator>Pasha, Maruf</dc:creator>
 <dc:creator>Ahmad, Arslan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Lately, Wireless Sensor Networks (WSNs) have become an emerging technology
and can be utilized in some crucial circumstances like battlegrounds,
commercial applications, habitat observing, buildings, smart homes, traffic
surveillance and other different places. One of the foremost difficulties that
WSN faces nowadays is protection from serious attacks. While organizing the
sensor nodes in an abandoned environment makes network systems helpless against
an assortment of strong assaults, intrinsic memory and power restrictions of
sensor nodes make the traditional security arrangements impractical. The
sensing knowledge combined with the wireless communication and processing power
makes it lucrative for being abused. The wireless sensor network technology
also obtains a big variety of security intimidations. This paper describes four
basic security threats and many active attacks on WSN with their possible
countermeasures proposed by different research scholars.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07136</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information
  Security, Vol. 14, No. 12, December 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07138</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An architecture for non-invasive software measurement</dc:title>
 <dc:creator>Artemev, Vasilii</dc:creator>
 <dc:creator>Ivanov, Vladimir</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Rogers, Alan</dc:creator>
 <dc:creator>Sillitti, Alberto</dc:creator>
 <dc:creator>Succi, Giancarlo</dc:creator>
 <dc:creator>Zouev, Eugene</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Analysis of data related to software development helps to increase quality,
control and predictability of software development processes and
products.However, collecting such data for is a complex task. A non-invasive
collection of software metrics is one of the most promising approaches to solve
the task. In this paper we present an approach which consists of four parts:
collect the data, store all collected data, unify the stored data and analyze
the data to provide insights to the user about software product or process. We
employ the approach to the development of an architecture for non-invasive
software measurement system and explain its advantages and limitations.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07140</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Framework for Information Security in Cloud Computing Using
  Auditing Algorithm Shell (AAS)</dc:title>
 <dc:creator>Mushtaq, M. Omer</dc:creator>
 <dc:creator>Shahzad, Furrakh</dc:creator>
 <dc:creator>Tariq, M. Owais</dc:creator>
 <dc:creator>Riaz, Mahina</dc:creator>
 <dc:creator>Majeed, Bushra</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  There is a dynamic escalation and extension in the new infrastructure,
educating personnel and licensing new computer programs in the field of IT, due
to the emergence of Cloud Computing (CC) paradigm. It has become a quick
growing segment of IT business in last couple of years. However, due to the
rapid growth of data, people and IT firms, the issue of information security is
getting more complex. One of the major concerns of the user is, at what degree
the data is safe on Cloud? In spite of all promotional material encompassing
the cloud, consortium customers are not willing to shift their business on the
cloud. Data security is the major problem which has limited the scope of cloud
computing. In new cloud computing infrastructure, the techniques such as the
Strong Secure Shell and Encryption are deployed to guarantee the authenticity
of the user through logs systems. The vendors utilize these logs to analyze and
view their data. Therefore, this implementation is not enough to ensure
security, privacy and authoritative use of the data. This paper introduces quad
layered framework for data security, data privacy, data breaches and process
associated aspects. Using this layered architecture we have preserved the
secrecy of confidential information and tried to build the trust of user on
cloud computing. This layered framework prevents the confidential information
by multiple means i.e. Secure Transmission of Data, Encrypted Data and its
Processing, Database Secure Shell and Internal/external log Auditing.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07140</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 14, No. 11, November 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07146</identifier>
 <datestamp>2017-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jolie Static Type Checker: a prototype</dc:title>
 <dc:creator>de Carvalho, Daniel</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Mingela, Bogdan</dc:creator>
 <dc:creator>Safina, Larisa</dc:creator>
 <dc:creator>Tchitchigin, Alexander</dc:creator>
 <dc:creator>Troshkov, Nikolay</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Static verification of a program source code correctness is an important
element of software reliability. Formal verification of software programs
involves proving that a program satisfies a formal specification of its
behavior. Many languages use both static and dynamic type checking. With such
approach, the static type checker verifies everything possible at compile time,
and dynamic checks the remaining. The current state of the Jolie programming
language includes a dynamic type system. Consequently, it allows avoidable
run-time errors. A static type system for the language has been formally
defined on paper but lacks an implementation yet. In this paper, we describe a
prototype of Jolie Static Type Checker (JSTC), which employs a technique based
on a SMT solver. We describe the theory behind and the implementation, and the
process of static analysis.
</dc:description>
 <dc:description>Comment: Modeling and Analysis of Information Systems, 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-10-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07149</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Microservices: How To Make Your Application Scale</dc:title>
 <dc:creator>Dragoni, Nicola</dc:creator>
 <dc:creator>Lanese, Ivan</dc:creator>
 <dc:creator>Larsen, Stephan Thordal</dc:creator>
 <dc:creator>Mazzara, Manuel</dc:creator>
 <dc:creator>Mustafin, Ruslan</dc:creator>
 <dc:creator>Safina, Larisa</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The microservice architecture is a style inspired by service-oriented
computing that has recently started gaining popularity and that promises to
change the way in which software is perceived, conceived and designed. In this
paper, we describe the main features of microservices and highlight how these
features improve scalability.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07151</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Replication of Virtual Network Functions: Optimizing Link Utilization
  and Resource Costs</dc:title>
 <dc:creator>Carpio, Francisco</dc:creator>
 <dc:creator>Bziuk, Wolgang</dc:creator>
 <dc:creator>Jukan, Admela</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network Function Virtualization (NFV) is enabling the softwarization of
traditional network services, commonly deployed in dedicated hardware, into
generic hardware in form of Virtual Network Functions (VNFs), which can be
located flexibly in the network. However, network load balancing can be
critical for an ordered sequence of VNFs, also known as Service Function Chains
(SFCs), a common cloud and network service approach today. The placement of
these chained functions increases the ping-pong traffic between VNFs, directly
affecting to the efficiency of bandwidth utilization. The optimization of the
placement of these VNFs is a challenge as also other factors need to be
considered, such as the resource utilization. To address this issue, we study
the problem of VNF placement with replications, and especially the potential of
VNFs replications to help load balance the network, while the server
utilization is minimized. In this paper we present a Linear Programming (LP)
model for the optimum placement of functions finding a trade-off between the
minimization of two objectives: the link utilization and CPU resource usage.
The results show how the model load balance the utilization of all links in the
network using minimum resources.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1610.08266</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07157</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Reversible Transducers</dc:title>
 <dc:creator>Dartois, Luc</dc:creator>
 <dc:creator>Fournier, Paulin</dc:creator>
 <dc:creator>Jecker, Isma&#xeb;l</dc:creator>
 <dc:creator>Lhote, Nathan</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  Deterministic two-way transducers define the robust class of regular
functions which is, among other good properties, closed under composition.
However, the best known algorithms for composing two-way transducers cause a
double exponential blow-up in the size of the inputs. In this paper, we
introduce a class of transducers for which the composition has polynomial
complexity. It is the class of reversible transducers, for which the
computation steps can be reversed deterministically. While in the one-way
setting this class is not very expressive, we prove that any two-way transducer
can be made reversible through a single exponential blow-up. As a consequence,
we prove that the composition of two-way transducers can be done with a single
exponential blow-up in the number of states. A uniformization of a relation is
a function with the same domain and which is included in the original relation.
Our main result actually states that we can uniformize any non-deterministic
two-way transducer by a reversible transducer with a single exponential
blow-up, improving the known result by de Souza which has a quadruple
exponential complexity. As a side result, our construction also gives a
quadratic transformation from copyless streaming string transducers to two-way
transducers, improving the exponential previous bound.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07157</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07158</identifier>
 <datestamp>2017-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Next Basket Prediction using Recurring Sequential Patterns</dc:title>
 <dc:creator>Guidotti, Riccardo</dc:creator>
 <dc:creator>Rossetti, Giulio</dc:creator>
 <dc:creator>Pappalardo, Luca</dc:creator>
 <dc:creator>Giannotti, Fosca</dc:creator>
 <dc:creator>Pedreschi, Dino</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Nowadays, a hot challenge for supermarket chains is to offer personalized
services for their customers. Next basket prediction, i.e., supplying the
customer a shopping list for the next purchase according to her current needs,
is one of these services. Current approaches are not capable to capture at the
same time the different factors influencing the customer's decision process:
co-occurrency, sequentuality, periodicity and recurrency of the purchased
items. To this aim, we define a pattern Temporal Annotated Recurring Sequence
(TARS) able to capture simultaneously and adaptively all these factors. We
define the method to extract TARS and develop a predictor for next basket named
TBP (TARS Based Predictor) that, on top of TARS, is able to to understand the
level of the customer's stocks and recommend the set of most necessary items.
By adopting the TBP the supermarket chains could crop tailored suggestions for
each individual customer which in turn could effectively speed up their
shopping sessions. A deep experimentation shows that TARS are able to explain
the customer purchase behavior, and that TBP outperforms the state-of-the-art
competitors.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07158</dc:identifier>
 <dc:identifier>doi:10.1109/ICDM.2017.111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07160</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Time Channel Modulation</dc:title>
 <dc:creator>Basar, Ertugrul</dc:creator>
 <dc:creator>Altunbas, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we introduce the concept of space-time channel modulation
(STCM), which extends the classical space-time block codes into a new third
dimension: channel states (transmission media) dimension. Three novel STCM
schemes, which provide interesting trade-offs among decoding complexity, error
performance and data rate, are proposed. It is shown via computer simulations
that the proposed STCM schemes achieve considerably better error performance
than the existing media-based modulation (MBM) and classical systems.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Vehicular Technology</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07168</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A DIKW Paradigm to Cognitive Engineering</dc:title>
 <dc:creator>Mishra, Amit Kumar</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Though the word cognitive has a wide range of meanings we define cognitive
engineering as learning from brain to bolster engineering solutions. However,
giving an achievable framework to the process towards this has been a difficult
task. In this work we take the classic data information knowledge wisdom (DIKW)
framework to set some achievable goals and sub-goals towards cognitive
engineering. A layered framework like DIKW aligns nicely with the layered
structure of pre-frontal cortex. And breaking the task into sub-tasks based on
the layers also makes it easier to start developmental endeavours towards
achieving the final goal of a brain-inspired system.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07172</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Bounds for Online Coloring of Basic Graph Classes</dc:title>
 <dc:creator>Albers, Susanne</dc:creator>
 <dc:creator>Schraink, Sebastian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We resolve a number of long-standing open problems in online graph coloring.
More specifically, we develop tight lower bounds on the performance of online
algorithms for fundamental graph classes. An important contribution is that our
bounds also hold for randomized online algorithms, for which hardly any results
were known. Technically, we construct lower bounds for chordal graphs. The
constructions then allow us to derive results on the performance of randomized
online algorithms for the following further graph classes: trees, planar,
bipartite, inductive, bounded-treewidth and disk graphs. It shows that the best
competitive ratio of both deterministic and randomized online algorithms is
$\Theta(\log n)$, where $n$ is the number of vertices of a graph. Furthermore,
we prove that this guarantee cannot be improved if an online algorithm has a
lookahead of size $O(n/\log n)$ or access to a reordering buffer of size
$n^{1-\epsilon}$, for any $0&lt;\epsilon\leq 1$. A consequence of our results is
that, for all of the above mentioned graph classes except bipartite graphs, the
natural $\textit{First Fit}$ coloring algorithm achieves an optimal
performance, up to constant factors, among deterministic and randomized online
algorithms.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-07-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07178</identifier>
 <datestamp>2017-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Steganalysis of 3D Objects Using Statistics of Local Feature Sets</dc:title>
 <dc:creator>Li, Zhenyu</dc:creator>
 <dc:creator>Bors, Adrian G.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  3D steganalysis aims to identify subtle invisible changes produced in
graphical objects through digital watermarking or steganography. Sets of
statistical representations of 3D features, extracted from both cover and stego
3D mesh objects, are used as inputs into machine learning classifiers in order
to decide whether any information was hidden in the given graphical object.
According to previous studies, sets of local geometry features can be used to
define the differences between stego and cover-objects. The features proposed
in this paper include those representing the local object curvature, vertex
normals, the local geometry representation in the spherical coordinate system
and are considered in various combinations with others. We also analyze the
effectiveness of various 3D feature sets applied for steganalysis based on the
Pearson correlation coefficient. The classifiers proposed in this study for
discriminating the 3D stego and cover-objects include Support Vector Machine
and the Fisher Linear Discriminant ensemble. Three different watermarking and
steganographic methods are used for hiding information in the 3D objects used
for testing the performance of the proposed steganalysis methodology.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07178</dc:identifier>
 <dc:identifier>doi:10.1016/j.ins.2017.06.011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07180</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small hitting-sets for tiny arithmetic circuits or: How to turn bad
  designs into good</dc:title>
 <dc:creator>Agrawal, Manindra</dc:creator>
 <dc:creator>Forbes, Michael</dc:creator>
 <dc:creator>Ghosh, Sumanta</dc:creator>
 <dc:creator>Saxena, Nitin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:description>  We show that if we can design poly($s$)-time hitting-sets for
$\Sigma\wedge^a\Sigma\Pi^{O(\log s)}$ circuits of size $s$, where $a=\omega(1)$
is arbitrarily small and the number of variables, or arity $n$, is $O(\log s)$,
then we can derandomize blackbox PIT for general circuits in quasipolynomial
time. This also establishes that either E$\not\subseteq$\#P/poly or that
VP$\ne$VNP. In fact, we show that one only needs a poly($s$)-time hitting-set
against individual-degree $a'=\omega(1)$ polynomials that are computable by a
size-$s$ arity-$(\log s)$ $\Sigma\Pi\Sigma$ circuit (note: $\Pi$ fanin may be
$s$). Alternatively, we claim that, to understand VP one only needs to find
hitting-sets, for depth-$3$, that have a small parameterized complexity.
Another tiny family of interest is when we restrict the arity $n=\omega(1)$ to
be arbitrarily small. We show that if we can design poly($s,\mu(n)$)-time
hitting-sets for size-$s$ arity-$n$ $\Sigma\Pi\Sigma\wedge$ circuits
(resp.~$\Sigma\wedge^a\Sigma\Pi$), where function $\mu$ is arbitrary, then we
can solve PIT for VP in quasipoly-time, and prove the corresponding lower
bounds. Our methods are strong enough to prove a surprising {\em arity
reduction} for PIT-- to solve the general problem completely it suffices to
find a blackbox PIT with time-complexity $sd2^{O(n)}$. We give several examples
of ($\log s$)-variate circuits where a new measure (called cone-size) helps in
devising poly-time hitting-sets, but the same question for their $s$-variate
versions is open till date: For eg., diagonal depth-$3$ circuits, and in
general, models that have a {\em small} partial derivative space. We also
introduce a new concept, called cone-closed basis isolation, and provide
example models where it occurs, or can be achieved by a small shift.
</dc:description>
 <dc:description>Comment: 25 pages, No figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07186</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability of Topic Modeling via Matrix Factorization</dc:title>
 <dc:creator>Belford, Mark</dc:creator>
 <dc:creator>Mac Namee, Brian</dc:creator>
 <dc:creator>Greene, Derek</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Topic models can provide us with an insight into the underlying latent
structure of a large corpus of documents. A range of methods have been proposed
in the literature, including probabilistic topic models and techniques based on
matrix factorization. However, in both cases, standard implementations rely on
stochastic elements in their initialization phase, which can potentially lead
to different results being generated on the same corpus when using the same
parameter values. This corresponds to the concept of &quot;instability&quot; which has
previously been studied in the context of $k$-means clustering. In many
applications of topic modeling, this problem of instability is not considered
and topic models are treated as being definitive, even though the results may
change considerably if the initialization process is altered. In this paper we
demonstrate the inherent instability of popular topic modeling approaches,
using a number of new measures to assess stability. To address this issue in
the context of matrix factorization for topic modeling, we propose the use of
ensemble learning strategies. Based on experiments performed on annotated text
corpora, we show that a K-Fold ensemble strategy, combining both ensembles and
structured initialization, can significantly reduce instability, while
simultaneously yielding more accurate topic models.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07187</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO 5G Cellular Networks: mm-wave vs. \mu-wave Frequencies</dc:title>
 <dc:creator>Buzzi, Stefano</dc:creator>
 <dc:creator>D'Andrea, Carmen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Enhanced mobile broadband (eMBB) is one of the key use-cases for the
development of the new standard 5G New Radio for the next generation of mobile
wireless networks. Large-scale antenna arrays, a.k.a. Massive MIMO, the usage
of carrier frequencies in the range 10-100 GHz, the so-called millimeter wave
(mm-wave) band, and the network densification with the introduction of
small-sized cells are the three technologies that will permit implementing eMBB
services and realizing the Gbit/s mobile wireless experience. This paper is
focused on the massive MIMO technology; initially conceived for conventional
cellular frequencies in the sub-6 GHz range (\mu-wave), the massive MIMO
concept has been then progressively extended to the case in which mm-wave
frequencies are used. However, due to different propagation mechanisms in urban
scenarios, the resulting MIMO channel models at \mu-wave and mm-wave are
radically different. Six key basic differences are pinpointed in this paper,
along with the implications that they have on the architecture and algorithms
of the communication transceivers and on the attainable performance in terms of
reliability and multiplexing capabilities.
</dc:description>
 <dc:description>Comment: Invited paper; to appear on the ZTE Communications special issue on
  5G New Radio</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07187</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07189</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Learned Convnet Features with Dirichlet Process Gaussian
  Mixture Models</dc:title>
 <dc:creator>Malmgren-Hansen, David</dc:creator>
 <dc:creator>Nielsen, Allan Aasbjerg</dc:creator>
 <dc:creator>Engholm, Rasmus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (Convnets) have achieved good results in a
range of computer vision tasks the recent years. Though given a lot of
attention, visualizing the learned representations to interpret Convnets, still
remains a challenging task. The high dimensionality of internal representations
and the high abstractions of deep layers are the main challenges when
visualizing Convnet functionality. We present in this paper a technique based
on clustering internal Convnet representations with a Dirichlet Process
Gaussian Mixture Model, for visualization of learned representations in
Convnets. Our method copes with the high dimensionality of a Convnet by
clustering representations across all nodes of each layer. We will discuss how
this application is useful when considering transfer learning, i.e.\
transferring a model trained on one dataset to solve a task on a different one.
</dc:description>
 <dc:description>Comment: Presented at NIPS 2016 Workshop: Practical Bayesian Nonparametrics</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07191</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ViP-CNN: Visual Phrase Guided Convolutional Neural Network</dc:title>
 <dc:creator>Li, Yikang</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:creator>Tang, Xiao'ou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As the intermediate level task connecting image captioning and object
detection, visual relationship detection started to catch researchers'
attention because of its descriptive power and clear structure. It detects the
objects and captures their pair-wise interactions with a
subject-predicate-object triplet, e.g. person-ride-horse. In this paper, each
visual relationship is considered as a phrase with three components. We
formulate the visual relationship detection as three inter-connected
recognition problems and propose a Visual Phrase guided Convolutional Neural
Network (ViP-CNN) to address them simultaneously. In ViP-CNN, we present a
Phrase-guided Message Passing Structure (PMPS) to establish the connection
among relationship components and help the model consider the three problems
jointly. Corresponding non-maximum suppression method and model training
strategy are also proposed. Experimental results show that our ViP-CNN
outperforms the state-of-art method both in speed and accuracy. We further
pretrain ViP-CNN on our cleansed Visual Genome Relationship dataset, which is
found to perform better than the pretraining on the ImageNet for this task.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures, accepted by CVPR 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07191</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07193</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ontologies in System Engineering: a Field Report</dc:title>
 <dc:creator>Menapace, Marco</dc:creator>
 <dc:creator>Tacchella, Armando</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  In recent years ontologies enjoyed a growing popularity outside specialized
AI communities. System engineering is no exception to this trend, with
ontologies being proposed as a basis for several tasks in complex industrial
implements, including system design, monitoring and diagnosis. In this paper,
we consider four different contributions to system engineering wherein
ontologies are instrumental to provide enhancements over traditional ad-hoc
techniques. For each application, we briefly report the methodologies, the
tools and the results obtained with the goal to provide an assessment of merits
and limits of ontologies in such domains.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07195</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First Experiences Optimizing Smith-Waterman on Intel's Knights Landing
  Processor</dc:title>
 <dc:creator>Rucci, Enzo</dc:creator>
 <dc:creator>Garcia, Carlos</dc:creator>
 <dc:creator>Botella, Guillermo</dc:creator>
 <dc:creator>De Giusti, Armando</dc:creator>
 <dc:creator>Naiouf, Marcelo</dc:creator>
 <dc:creator>Prieto-Matias, Manuel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  The well-known Smith-Waterman (SW) algorithm is the most commonly used method
for local sequence alignments. However, SW is very computationally demanding
for large protein databases. There exist several implementations that take
advantage of computing parallelization on many-cores, FPGAs or GPUs, in order
to increase the alignment throughtput. In this paper, we have explored SW
acceleration on Intel KNL processor. The novelty of this architecture requires
the revision of previous programming and optimization techniques on many-core
architectures. To the best of authors knowledge, this is the first KNL
architecture assessment for SW algorithm. Our evaluation, using the renowned
Environmental NR database as benchmark, has shown that multi-threading and SIMD
exploitation reports competitive performance (351 GCUPS) in comparison with
other implementations.
</dc:description>
 <dc:description>Comment: Submitted to Euro-Par 2017 Conference</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07199</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence acceleration of alternating series</dc:title>
 <dc:creator>Nowak, Rafa&#x142;</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65B10</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.1.10</dc:subject>
 <dc:description>  A new simple convergence acceleration method is proposed for a certain wide
range class of convergent alternating series. The method has some common
features with Smith's and Ford's modification of Levin's and Weniger's sequence
transformations, but it leads to less computational and memory cost. The
similarities and differences between all three methods are analyzed and some
common theoretical results are given. Numerical examples confirm a similar
performance of all three methods.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07199</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07203</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utilizing Lexical Similarity between Related, Low-resource Languages for
  Pivot-based SMT</dc:title>
 <dc:creator>Kunchukuttan, Anoop</dc:creator>
 <dc:creator>Shah, Maulik</dc:creator>
 <dc:creator>Prakash, Pradyot</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We investigate pivot-based translation between related languages in a low
resource, phrase-based SMT setting. We show that a subword-level pivot-based
SMT model using a related pivot language is substantially better than word and
morpheme-level pivot models. It is also highly competitive with the best direct
translation model, which is encouraging as no direct source-target training
corpus is used. We also show that combining multiple related language pivot
models can rival a direct translation model. Thus, the use of subwords as
translation units coupled with multiple related pivot languages can compensate
for the lack of a direct parallel corpus.
</dc:description>
 <dc:description>Comment: Accepted at IJCNLP 2017, 7 pages, 7 tables</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07205</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On normalization of inconsistency indicators in pairwise comparisons</dc:title>
 <dc:creator>Koczkodaj, W. W.</dc:creator>
 <dc:creator>Magnot, J. -P.</dc:creator>
 <dc:creator>Mazurek, J.</dc:creator>
 <dc:creator>Peters, J. F.</dc:creator>
 <dc:creator>Rakhshani, H.</dc:creator>
 <dc:creator>Soltys, M.</dc:creator>
 <dc:creator>Strza&#x142;ka, D.</dc:creator>
 <dc:creator>Szybowski, J.</dc:creator>
 <dc:creator>Tozzi, A.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In this study, we provide mathematical and practice-driven justification for
using $[0,1]$ normalization of inconsistency indicators in pairwise
comparisons. The need for normalization, as well as problems with the lack of
normalization, are presented. A new type of paradox of infinity is described.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07207</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO Pilot Decontamination and Channel Interpolation via
  Wideband Sparse Channel Estimation</dc:title>
 <dc:creator>Haghighatshoar, Saeid</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a massive MIMO system based on Time Division Duplexing (TDD) and
channel reciprocity, where the base stations (BSs) learn the channel vectors of
their users via the pilots transmitted by the users in the uplink (UL). It is
well-known that, in the limit of very large number of BS antennas, the system
performance is limited by pilot contamination, due to the fact that the same
set of orthogonal pilots is reused in multiple cells. In this paper, we propose
a low-complexity algorithm that uses the received UL wideband pilot snapshots
in an observation window comprising several coherence blocks (CBs) to obtain an
estimate of the angle-delay Power Spread Function (PSF) of the received signal.
This is generally given by the sum of the angle-delay PSF of the desired user
and the angle-delay PSFs of the copilot users (CPUs), i.e., the users re-using
the same pilot dimensions in other cells/sectors. We propose supervised and
unsupervised clustering algorithms to decompose the estimated PSF and isolate
the part corresponding to the desired user only. We use this decomposition to
obtain an estimate of the covariance matrix of the user wideband channel
vector, which we exploit to decontaminate the desired user channel estimate by
applying Minimum Mean Squared Error (MMSE) smoothing filter, i.e., the optimal
channel interpolator in the MMSE sense. We also propose an effective
low-complexity approximation/implementation of this smoothing filter. We use
numerical simulations to assess the performance of our proposed method, and
compare it with other recently proposed schemes that use the same idea of
separability of users in the angle-delay domain.
</dc:description>
 <dc:description>Comment: 33 pages, 11 Figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07211</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A minimax and asymptotically optimal algorithm for stochastic bandits</dc:title>
 <dc:creator>M&#xe9;nard, Pierre</dc:creator>
 <dc:creator>Garivier, Aur&#xe9;lien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We propose the kl-UCB ++ algorithm for regret minimization in stochastic
bandit models with exponential families of distributions. We prove that it is
simultaneously asymptotically optimal (in the sense of Lai and Robbins' lower
bound) and minimax optimal. This is the first algorithm proved to enjoy these
two properties at the same time. This work thus merges two different lines of
research with simple and clear proofs.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07211</dc:identifier>
 <dc:identifier>Algorithmic Learning Theory, Springer, 2017, 2017 Algorithmic
  Learning Theory Conference 76</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07213</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronizability of Communicating Finite State Machines is not
  Decidable</dc:title>
 <dc:creator>Finkel, Alain</dc:creator>
 <dc:creator>Lozes, Etienne</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  A system of communicating finite state machines is synchronizableif its send
trace semantics, i.e.the set of sequences of sendings it can perform, is the
same when its communications areFIFO asynchronous and when they are just
rendez-vous synchronizations. This property was claimed to be decidable in
several conference and journalpapers for either mailboxes or peer-to-peer
communications, thanks to a form of small model property. In this paper, we
show thatthis small model property does not hold neither for mailbox
communications, nor for peer-to-peer communications, therefore the
decidabilityof synchronizability becomes an open question. We close this
question for peer-to-peer communications, and we show thatsynchronizability is
actually undecidable. We show that synchronizability isdecidable if the
topology of communications is an oriented ring. We also show that,in this
case,synchronizability implies the absence of unspecified receptions and orphan
messages, and thechannel-recognizability of the reachability set.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07213</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07214</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>$\mathsf{LLF}_{\cal P}$: a logical framework for modeling external
  evidence, side conditions, and proof irrelevance using monads</dc:title>
 <dc:creator>Honsell, Furio</dc:creator>
 <dc:creator>Liquori, Luigi</dc:creator>
 <dc:creator>Maksimovic, Petar</dc:creator>
 <dc:creator>Scagnetto, Ivan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  We extend the constructive dependent type theory of the Logical Framework
$\mathsf{LF}$ with monadic, dependent type constructors indexed with predicates
over judgements, called Locks. These monads capture various possible proof
attitudes in establishing the judgment of the object logic encoded by an
$\mathsf{LF}$ type. Standard examples are factoring-out the verification of a
constraint or delegating it to an external oracle, or supplying some
non-apodictic epistemic evidence, or simply discarding the proof witness of a
precondition deeming it irrelevant. This new framework, called Lax Logical
Framework, $\mathsf{LLF}_{\cal P}$, is a conservative extension of
$\mathsf{LF}$, and hence it is the appropriate metalanguage for dealing
formally with side-conditions in rules or external evidence in logical systems.
$\mathsf{LLF}_{\cal P}$ arises once the monadic nature of the lock
type-constructor, ${\cal L}^{\cal P}_{M,\sigma}[\cdot]$, introduced by the
authors in a series of papers, together with Marina Lenisa, is fully exploited.
The nature of the lock monads permits to utilize the very Lock destructor,
${\cal U}^{\cal P}_{M,\sigma}[\cdot]$, in place of Moggi's monadic $let_T$,
thus simplifying the equational theory. The rules for ${\cal U}^{\cal
P}_{M,\sigma}[\cdot]$ permit also the removal of the monad once the constraint
is satisfied. We derive the meta-theory of $\mathsf{LLF}_{\cal P}$ by a novel
indirect method based on the encoding of $\mathsf{LLF}_{\cal P}$ in
$\mathsf{LF}$. We discuss encodings in $\mathsf{LLF}_{\cal P}$ of call-by-value
$\lambda$-calculi, Hoare's Logic, and Fitch-Prawitz Naive Set Theory.
</dc:description>
 <dc:description>Comment: Accepted for publication in LMCS</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07214</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 3 (July 6,
  2017) lmcs:3771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07219</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Load Balancing for Network Functions Virtualization</dc:title>
 <dc:creator>Pham, Tuan-Minh</dc:creator>
 <dc:creator>Nguyen, Thi-Thuy-Lien</dc:creator>
 <dc:creator>Fdida, Serge</dc:creator>
 <dc:creator>Binh, Huynh Thi Thanh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network Functions Virtualization (NFV) aims to support service providers to
deploy various services in a more agile and cost-effective way. However, the
softwarization and cloudification of network functions can result in severe
congestion and low network performance. In this paper, we propose a solution to
address this issue. We analyze and solve the online load balancing problem
using multipath routing in NFV to optimize network performance in response to
the dynamic changes of user demands. In particular, we first formulate the
optimization problem of load balancing as a mixed integer linear program for
achieving the optimal solution. We then develop the ORBIT algorithm that solves
the online load balancing problem. The performance guarantee of ORBIT is
analytically proved in comparison with the optimal offline solution. The
experiment results on real-world datasets show that ORBIT performs very well
for distributing traffic of each service demand across multipaths without
knowledge of future demands, especially under high-load conditions.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07219</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07223</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GANDALF: A fine-grained hardware-software co-design for preventing
  memory attacks</dc:title>
 <dc:creator>Krishnakumar, Gnanambikai</dc:creator>
 <dc:creator>SLPSK, Patanjali</dc:creator>
 <dc:creator>Vairam, Prasanna Karthik</dc:creator>
 <dc:creator>Rebeiro, Chester</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>68M15</dc:subject>
 <dc:subject>B.4.5</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  Reading or writing outside the bounds of a buffer is a serious security
vulnerability that has been exploited in numerous occasions. These attacks can
be prevented by ensuring that every buffer is only accessed within its
specified bounds. In this paper we present Gandalf, a compiler-assisted
hardware extension for the OpenRISC processor that thwarts all forms of memory
based attacks including buffer overflows and over-reads.The feature associates
lightweight base and bound capabilities to all pointer variables, which are
checked at run time by the hardware. Gandalf is transparent to the user and
does not require significant OS modifications. Moreover, it achieves locality,
thus resulting in small performance penalties.
</dc:description>
 <dc:description>Comment: 5 Pages, 2 figures, Winning entry of CSAW Embedded Security Challenge
  2016, Not published elsewhere</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07235</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Properties of the Power Systems Nodal Admittance Matrix</dc:title>
 <dc:creator>Kettner, Andreas Martin</dc:creator>
 <dc:creator>Paolone, Mario</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This letter provides conditions determining the rank of the nodal admittance
matrix, and arbitrary block partitions of it, for connected AC power networks
with complex admittances. Furthermore, some implications of these properties
concerning Kron Reduction and Hybrid Network Parameters are outlined.
</dc:description>
 <dc:description>Comment: Index Terms: Nodal Admittance Matrix, Rank, Block Form, Network
  Partition, Kron Reduction, Hybrid Network Parameters</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:date>2017-12-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07235</dc:identifier>
 <dc:identifier>IEEE Transactions on Power Systems, Volume 33, Issue 1, Januaray
  2018</dc:identifier>
 <dc:identifier>doi:10.1109/TPWRS.2017.2719583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07241</identifier>
 <datestamp>2017-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kalman Filter and its Modern Extensions for the Continuous-time
  Nonlinear Filtering Problem</dc:title>
 <dc:creator>Taghvaei, Amirhossein</dc:creator>
 <dc:creator>de Wiljes, Jana</dc:creator>
 <dc:creator>Mehta, Prashant G.</dc:creator>
 <dc:creator>Reich, Sebastian</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper is concerned with the filtering problem in continuous-time. Three
algorithmic solution approaches for this problem are reviewed: (i) the
classical Kalman-Bucy filter which provides an exact solution for the linear
Gaussian problem, (ii) the ensemble Kalman-Bucy filter (EnKBF) which is an
approximate filter and represents an extension of the Kalman-Bucy filter to
nonlinear problems, and (iii) the feedback particle filter (FPF) which
represents an extension of the EnKBF and furthermore provides for an consistent
solution in the general nonlinear, non-Gaussian case. The common feature of the
three algorithms is the gain times error formula to implement the update step
(to account for conditioning due to the observations) in the filter. In
contrast to the commonly used sequential Monte Carlo methods, the EnKBF and FPF
avoid the resampling of the particles in the importance sampling update step.
Moreover, the feedback control structure provides for error correction
potentially leading to smaller simulation variance and improved stability
properties. The paper also discusses the issue of non-uniqueness of the filter
update formula and formulates a novel approximation algorithm based on ideas
from optimal transport and coupling of measures. Performance of this and other
algorithms is illustrated for a numerical example.
</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07242</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast generalized Bruhat decomposition</dc:title>
 <dc:creator>Malaschonok, Gennadi</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  The deterministic recursive pivot-free algorithms for the computation of
generalized Bruhat decomposition of the matrix in the field and for the
computation of the inverse matrix are presented. This method has the same
complexity as algorithm of matrix multiplication and it is suitable for the
parallel computer systems.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07242</dc:identifier>
 <dc:identifier>Computer Algebra in Scientific Computing, LNCS 6244, Springer,
  Berlin, 2010. P. 194-202</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-15274-0_16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07243</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triangular Decomposition of Matrices in a Domain</dc:title>
 <dc:creator>Malaschonok, Gennadi</dc:creator>
 <dc:creator>Scherbinin, Anton</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Deterministic recursive algorithms for the computation of matrix triangular
decompositions with permutations like LU and Bruhat decomposition are presented
for the case of commutative domains. This decomposition can be considered as a
generalization of LU and Bruhat decompositions, because they both may be easily
obtained from this triangular decomposition. Algorithms have the same
complexity as the algorithm of matrix multiplication.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07243</dc:identifier>
 <dc:identifier>Computer Algebra in Scientific Computing. LNCS 9301, Springer,
  Switzerland, 2015, P.290-304</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-24021-3_22</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07247</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control Theoretic Approach to Predict Shock Response in Yeast</dc:title>
 <dc:creator>Chatterjee, Meenakshi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This report formulates a minimal model based on a control theoretic framework
to best describe the dynamics of perfect adaptation shown by the hyper osmotic
shock response system in yeast. Using principles from adaptive control and
stability theory, we step by step apply system identification methods to build
a simple second order linear system with only a few parameters, that can
concisely model the High Osmolarity Glycerol (HOG) Mitogen Activated Protein
Kinase (MAPK) signaling dynamics. Validation with experimental data demonstrate
that the model is sufficient to predict response of yeast to an arbitrary
external osmotic shock stimulus.
</dc:description>
 <dc:description>Comment: Technical Report</dc:description>
 <dc:date>2017-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07248</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized Bruhat decomposition in commutative domains</dc:title>
 <dc:creator>Malaschonok, Gennadi</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Deterministic recursive algorithms for the computation of generalized Bruhat
decomposition of the matrix in commutative domain are presented. This method
has the same complexity as the algorithm of matrix multiplication.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07248</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-02297-0_20</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07252</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Validation of Contact Dynamics for In-Hand Manipulation</dc:title>
 <dc:creator>Kolbert, Roman</dc:creator>
 <dc:creator>Chavan-Dafle, Nikhil</dc:creator>
 <dc:creator>Rodriguez, Alberto</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper evaluates state-of-the-art contact models at predicting the
motions and forces involved in simple in-hand robotic manipulations. In
particular it focuses on three primitive actions --linear sliding, pivoting,
and rolling-- that involve contacts between a gripper, a rigid object, and
their environment. The evaluation is done through thousands of controlled
experiments designed to capture the motion of object and gripper, and all
contact forces and torques at 250Hz. We demonstrate that a contact modeling
approach based on Coulomb's friction law and maximum energy principle is
effective at reasoning about interaction to first order, but limited for making
accurate predictions. We attribute the major limitations to 1) the
non-uniqueness of force resolution inherent to grasps with multiple hard
contacts of complex geometries, 2) unmodeled dynamics due to contact
compliance, and 3) unmodeled geometries dueto manufacturing defects.
</dc:description>
 <dc:description>Comment: International Symposium on Experimental Robotics, ISER 2016, Tokyo,
  Japan</dc:description>
 <dc:date>2017-02-06</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07262</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing and Using Minimal Polynomials</dc:title>
 <dc:creator>Abbott, John</dc:creator>
 <dc:creator>Bigatti, Anna Maria</dc:creator>
 <dc:creator>Palezzato, Elisa</dc:creator>
 <dc:creator>Robbiano, Lorenzo</dc:creator>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Given a zero-dimensional ideal I in a polynomial ring, many computations
start by finding univariate polynomials in I. Searching for a univariate
polynomial in I is a particular case of considering the minimal polynomial of
an element in P/I. It is well known that minimal polynomials may be computed
via elimination, therefore this is considered to be a &quot;resolved problem&quot;. But
being the key of so many computations, it is worth investigating its meaning,
its optimization, its applications.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07265</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Index Coding Scheme and its Application to Coded Caching</dc:title>
 <dc:creator>Wan, Kai</dc:creator>
 <dc:creator>Tuninetti, Daniela</dc:creator>
 <dc:creator>Piantanida, Pablo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a novel achievable scheme for the index problem and
applies it to the caching problem. Index coding and caching are noiseless
broadcast channel problems where receivers have message side information.In the
index coding problem the side information sets are fixed, while in the caching
problem the side information sets correspond the cache contents, which are
under the control of the system designer. The proposed index coding scheme,
based on distributed source coding and non-unique decoding,is shown to strictly
enlarge the rate region achievable by composite coding.The novel index coding
scheme applied to the caching problem is then shown to match an outer bound
(previously proposed by the authors and also based on known results for the
index coding problem) under the assumption of uncoded cache
placement/prefetching.
</dc:description>
 <dc:description>Comment: ITA 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07266</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heuristic for Maximizing Grouping Efficiency in the Cell Formation
  Problem</dc:title>
 <dc:creator>Bychkov, Ilya</dc:creator>
 <dc:creator>Batsyn, Mikhail</dc:creator>
 <dc:creator>Pardalos, Panos M.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  In our paper we consider the Cell Formation Problem in Group Technology with
grouping efficiency as an objective function. We present a heuristic approach
for obtaining high-quality solutions of the CFP. The suggested heuristic
applies an improvement procedure to obtain solutions with high grouping
efficiency. This procedure is repeated many times for randomly generated cell
configurations. Our computational experiments are performed for popular
benchmark instances taken from the literature with sizes from 10x20 to 50x150.
Better solutions unknown before are found for 23 instances of the 24
considered.
</dc:description>
 <dc:description>Comment: 15 pages, 7 tables</dc:description>
 <dc:date>2017-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07267</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second order conservative languages with a Maltsev polymorphism also
  have a majority polymorphism</dc:title>
 <dc:creator>Vodolazskiy, Evgeniy</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The paper proves that for any second order conservative constraint language
with a Maltsev polymorphism there is a majority polymorphism. Moreover, the
majority polymorphism can be defined by the Maltsev polymorphism.
</dc:description>
 <dc:date>2017-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07274</identifier>
 <datestamp>2017-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rotting Bandits</dc:title>
 <dc:creator>Levine, Nir</dc:creator>
 <dc:creator>Crammer, Koby</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Multi-Armed Bandits (MAB) framework highlights the tension between
acquiring new knowledge (Exploration) and leveraging available knowledge
(Exploitation). In the classical MAB problem, a decision maker must choose an
arm at each time step, upon which she receives a reward. The decision maker's
objective is to maximize her cumulative expected reward over the time horizon.
The MAB problem has been studied extensively, specifically under the assumption
of the arms' rewards distributions being stationary, or quasi-stationary, over
time. We consider a variant of the MAB framework, which we termed Rotting
Bandits, where each arm's expected reward decays as a function of the number of
times it has been pulled. We are motivated by many real-world scenarios such as
online advertising, content recommendation, crowdsourcing, and more. We present
algorithms, accompanied by simulations, and derive theoretical guarantees.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07281</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Probabilistic Framework for Location Inference from Social Media</dc:title>
 <dc:creator>Qian, Yujie</dc:creator>
 <dc:creator>Tang, Jie</dc:creator>
 <dc:creator>Yang, Zhilin</dc:creator>
 <dc:creator>Huang, Binxuan</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Carley, Kathleen M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We study the extent to which we can infer users' geographical locations from
social media. Location inference from social media can benefit many
applications, such as disaster management, targeted advertising, and news
content tailoring. In recent years, a number of algorithms have been proposed
for identifying user locations on social media platforms such as Twitter and
Facebook from message contents, friend networks, and interactions between
users. In this paper, we propose a novel probabilistic model based on factor
graphs for location inference that offers several unique advantages for this
task. First, the model generalizes previous methods by incorporating content,
network, and deep features learned from social context. The model is also
flexible enough to support both supervised learning and semi-supervised
learning. Second, we explore several learning algorithms for the proposed
model, and present a Two-chain Metropolis-Hastings (MH+) algorithm, which
improves the inference accuracy. Third, we validate the proposed model on three
different genres of data - Twitter, Weibo, and Facebook - and demonstrate that
the proposed model can substantially improve the inference accuracy (+3.3-18.5%
by F1-score) over that of several state-of-the-art methods.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07284</identifier>
 <datestamp>2017-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Simulation of Temperature Evolution of Overhead Transmission
  Lines Based on Analytical Solution and NWP</dc:title>
 <dc:creator>Yao, Rui</dc:creator>
 <dc:creator>Sun, Kai</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Mei, Shengwei</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Transmission lines are vital components in power systems. Tripping of
transmission lines caused by over-temperature is a major threat to the security
of system operations, so it is necessary to efficiently simulate line
temperature under both normal operation conditions and foreseen fault
conditions. Existing methods based on thermal-steady-state analyses cannot
reflect transient temperature evolution, and thus cannot provide timing
information needed for taking remedial actions. Moreover, conventional
numerical method requires huge computational efforts and barricades system-wide
analysis. In this regard, this paper derives an approximate analytical solution
of transmission-line temperature evolution enabling efficient analysis on
multiple operation states. Considering the uncertainties in environmental
parameters, the region of over-temperature is constructed in the environmental
parameter space to realize the over-temperature risk assessment in both the
planning stage and real-time operations. A test on a typical conductor model
verifies the accuracy of the approximate analytical solution. Based on the
analytical solution and numerical weather prediction (NWP) data, an efficient
simulation method for temperature evolution of transmission systems under
multiple operation states is proposed. As demonstrated on an NPCC 140-bus
system, it achieves over 1000 times of efficiency enhancement, verifying its
potentials in online risk assessment and decision support.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Transactions on Power Delivery</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07285</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Emojis Predictable?</dc:title>
 <dc:creator>Barbieri, Francesco</dc:creator>
 <dc:creator>Ballesteros, Miguel</dc:creator>
 <dc:creator>Saggion, Horacio</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Emojis are ideograms which are naturally combined with plain text to visually
complement or condense the meaning of a message. Despite being widely used in
social media, their underlying semantics have received little attention from a
Natural Language Processing standpoint. In this paper, we investigate the
relation between words and emojis, studying the novel task of predicting which
emojis are evoked by text-based tweet messages. We train several models based
on Long Short-Term Memory networks (LSTMs) in this task. Our experimental
results show that our neural model outperforms two baselines as well as humans
solving the same task, suggesting that computational models are able to better
capture the underlying semantics of emojis.
</dc:description>
 <dc:description>Comment: To appear at EACL 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07292</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Construction with Ordered Constraints</dc:title>
 <dc:creator>Huang, Yi</dc:creator>
 <dc:creator>Janardhanan, Mano Vikash</dc:creator>
 <dc:creator>Reyzin, Lev</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we study the problem of constructing a network by observing
ordered connectivity constraints, which we define herein. These ordered
constraints are made to capture realistic properties of real-world problems
that are not reflected in previous, more general models. We give hardness of
approximation results and nearly-matching upper bounds for the offline problem,
and we study the online problem in both general graphs and restricted
sub-classes. In the online problem, for general graphs, we give exponentially
better upper bounds than exist for algorithms for general connectivity
problems. For the restricted classes of stars and paths we are able to find
algorithms with optimal competitive ratios, the latter of which involve
analysis using a potential function defined over pq-trees.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07292</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07297</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Optimally Allocate Resources for Coded Distributed Computing?</dc:title>
 <dc:creator>Yu, Qian</dc:creator>
 <dc:creator>Li, Songze</dc:creator>
 <dc:creator>Maddah-Ali, Mohammad Ali</dc:creator>
 <dc:creator>Avestimehr, A. Salman</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Today's data centers have an abundance of computing resources, hosting server
clusters consisting of as many as tens or hundreds of thousands of machines. To
execute a complex computing task over a data center, it is natural to
distribute computations across many nodes to take advantage of parallel
processing. However, as we allocate more and more computing resources to a
computation task and further distribute the computations, large amounts of
(partially) computed data must be moved between consecutive stages of
computation tasks among the nodes, hence the communication load can become the
bottleneck. In this paper, we study the optimal allocation of computing
resources in distributed computing, in order to minimize the total execution
time in distributed computing accounting for both the duration of computation
and communication phases. In particular, we consider a general MapReduce-type
distributed computing framework, in which the computation is decomposed into
three stages: \emph{Map}, \emph{Shuffle}, and \emph{Reduce}. We focus on a
recently proposed \emph{Coded Distributed Computing} approach for MapReduce and
study the optimal allocation of computing resources in this framework. For all
values of problem parameters, we characterize the optimal number of servers
that should be used for distributed processing, provide the optimal placements
of the Map and Reduce tasks, and propose an optimal coded data shuffling
scheme, in order to minimize the total execution time. To prove the optimality
of the proposed scheme, we first derive a matching information-theoretic
converse on the execution time, then we prove that among all possible resource
allocation schemes that achieve the minimum execution time, our proposed scheme
uses the exactly minimum possible number of servers.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07302</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Moment Inequalities for R\'enyi Entropy and Mutual Information</dc:title>
 <dc:creator>Reeves, Galen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper explores some applications of a two-moment inequality for the
integral of the $r$-th power of a function, where $0 &lt; r&lt; 1$. The first
contribution is an upper bound on the R\'{e}nyi entropy of a random vector in
terms of the two different moments. When one of the moments is the zeroth
moment, these bounds recover previous results based on maximum entropy
distributions under a single moment constraint. More generally, evaluation of
the bound with two carefully chosen nonzero moments can lead to significant
improvements with a modest increase in complexity. The second contribution is a
method for upper bounding mutual information in terms of certain integrals with
respect to the variance of the conditional density. The bounds have a number of
useful properties arising from the connection with variance decompositions.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07305</identifier>
 <datestamp>2017-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Multiclass Boosting</dc:title>
 <dc:creator>Jung, Young Hun</dc:creator>
 <dc:creator>Goetz, Jack</dc:creator>
 <dc:creator>Tewari, Ambuj</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work has extended the theoretical analysis of boosting algorithms to
multiclass problems and to online settings. However, the multiclass extension
is in the batch setting and the online extensions only consider binary
classification. We fill this gap in the literature by defining, and justifying,
a weak learning condition for online multiclass boosting. This condition leads
to an optimal boosting algorithm that requires the minimal number of weak
learners to achieve certain accuracy. Additionally we propose an adaptive
algorithm which is near optimal and enjoys excellent performance in real data
due to its adaptive property.
</dc:description>
 <dc:description>Comment: 28 pages, 2 figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07306</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Causal Discovery Using Proxy Variables</dc:title>
 <dc:creator>Rojas-Carulla, Mateo</dc:creator>
 <dc:creator>Baroni, Marco</dc:creator>
 <dc:creator>Lopez-Paz, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Discovering causal relations is fundamental to reasoning and intelligence. In
particular, observational causal discovery algorithms estimate the cause-effect
relation between two random entities $X$ and $Y$, given $n$ samples from
$P(X,Y)$.
  In this paper, we develop a framework to estimate the cause-effect relation
between two static entities $x$ and $y$: for instance, an art masterpiece $x$
and its fraudulent copy $y$. To this end, we introduce the notion of proxy
variables, which allow the construction of a pair of random entities $(A,B)$
from the pair of static entities $(x,y)$. Then, estimating the cause-effect
relation between $A$ and $B$ using an observational causal discovery algorithm
leads to an estimation of the cause-effect relation between $x$ and $y$. For
example, our framework detects the causal relation between unprocessed
photographs and their modifications, and orders in time a set of shuffled
frames from a video.
  As our main case study, we introduce a human-elicited dataset of 10,000 pairs
of casually-linked pairs of words from natural language. Our methods discover
75% of these causal relations. Finally, we discuss the role of proxy variables
in machine learning, as a general tool to incorporate static knowledge into
prediction tasks.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07309</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounding the inefficiency of compromise</dc:title>
 <dc:creator>Caragiannis, Ioannis</dc:creator>
 <dc:creator>Kanellopoulos, Panagiotis</dc:creator>
 <dc:creator>Voudouris, Alexandros A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Social networks on the Internet have seen an enormous growth recently and
play a crucial role in different aspects of today's life. They have facilitated
information dissemination in ways that have been beneficial for their users but
they are often used strategically in order to spread information that only
serves the objectives of particular users. These properties have inspired a
revision of classical opinion formation models from sociology using
game-theoretic notions and tools. We follow the same modeling approach,
focusing on scenarios where the opinion expressed by each user is a compromise
between her internal belief and the opinions of a small number of neighbors
among her social acquaintances. We formulate simple games that capture this
behavior and quantify the inefficiency of equilibria using the well-known
notion of the price of anarchy. Our results indicate that compromise comes at a
cost that strongly depends on the neighborhood size.
</dc:description>
 <dc:description>Comment: 23 pages, 10 figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07311</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ERA: A Framework for Economic Resource Allocation for the Cloud</dc:title>
 <dc:creator>Babaioff, Moshe</dc:creator>
 <dc:creator>Mansour, Yishay</dc:creator>
 <dc:creator>Nisan, Noam</dc:creator>
 <dc:creator>Noti, Gali</dc:creator>
 <dc:creator>Curino, Carlo</dc:creator>
 <dc:creator>Ganapathy, Nar</dc:creator>
 <dc:creator>Menache, Ishai</dc:creator>
 <dc:creator>Reingold, Omer</dc:creator>
 <dc:creator>Tennenholtz, Moshe</dc:creator>
 <dc:creator>Timnat, Erez</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud computing has reached significant maturity from a systems perspective,
but currently deployed solutions rely on rather basic economics mechanisms that
yield suboptimal allocation of the costly hardware resources. In this paper we
present Economic Resource Allocation (ERA), a complete framework for scheduling
and pricing cloud resources, aimed at increasing the efficiency of cloud
resources usage by allocating resources according to economic principles. The
ERA architecture carefully abstracts the underlying cloud infrastructure,
enabling the development of scheduling and pricing algorithms independently of
the concrete lower-level cloud infrastructure and independently of its
concerns. Specifically, ERA is designed as a flexible layer that can sit on top
of any cloud system and interfaces with both the cloud resource manager and
with the users who reserve resources to run their jobs. The jobs are scheduled
based on prices that are dynamically calculated according to the predicted
demand. Additionally, ERA provides a key internal API to pluggable algorithmic
modules that include scheduling, pricing and demand prediction. We provide a
proof-of-concept software and demonstrate the effectiveness of the architecture
by testing ERA over both public and private cloud systems -- Azure Batch of
Microsoft and Hadoop/YARN. A broader intent of our work is to foster
collaborations between economics and system communities. To that end, we have
developed a simulation platform via which economics and system experts can test
their algorithmic implementations.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07311</dc:identifier>
 <dc:identifier>doi:10.1145/3041021.3054186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07312</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-synchronization and Self-stabilization of 3D Bipedal Walking Gaits</dc:title>
 <dc:creator>Chevallereau, Christine</dc:creator>
 <dc:creator>Razavi, Hamed</dc:creator>
 <dc:creator>Six, Damien</dc:creator>
 <dc:creator>Aoustin, Yannick</dc:creator>
 <dc:creator>Grizzle, Jessy</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper seeks insight into stabilization mechanisms for periodic walking
gaits in 3D bipedal robots. Based on this insight, a control strategy based on
virtual constraints, which imposes coordination between joints rather than a
temporal evolution, will be proposed for achieving asymptotic convergence
toward a periodic motion. For planar bipeds with one degree of underactuation,
it is known that a vertical displacement of the center of mass---with downward
velocity at the step transition---induces stability of a walking gait. This
paper concerns the qualitative extension of this type of property to 3D walking
with two degrees of underactuation. It is shown that a condition on the
position of the center of mass in the horizontal plane at the transition
between steps induces synchronization between the motions in the sagittal and
frontal planes. A combination of the conditions for self-synchronization and
vertical oscillations leads to stable gaits. The algorithm for
self-stabilization of 3D walking gaits is first developed for a simplified
model of a walking robot (an inverted pendulum with variable length legs), and
then it is extended to a complex model of the humanoid robot Romeo using the
notion of Hybrid Zero Dynamics. Simulations of the model of the robot
illustrate the efficacy of the method and its robustness.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07319</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Goal-Based Movement Model for Continuous Multi-Agent Tasks</dc:title>
 <dc:creator>Iqbal, Shariq</dc:creator>
 <dc:creator>Pearson, John</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Despite increasing attention paid to the need for fast, scalable methods to
analyze next-generation neuroscience data, comparatively little attention has
been paid to the development of similar methods for behavioral analysis. Just
as the volume and complexity of brain data have grown, behavioral paradigms in
systems neuroscience have likewise become more naturalistic and less
constrained, necessitating an increase in the flexibility and scalability of
the models used to study them. In particular, key assumptions made in the
analysis of typical decision paradigms --- optimality; analytic tractability;
discrete, low-dimensional action spaces --- may be untenable in richer tasks.
Here, using the case of a two-player, real-time, continuous strategic game as
an example, we show how the use of modern machine learning methods allows us to
relax each of these assumptions. Following an inverse reinforcement learning
approach, we are able to succinctly characterize the joint distribution over
players' actions via a generative model that allows us to simulate realistic
game play. We compare simulated play from a number of generative time series
models and show that ours successfully resists mode collapse while generating
trajectories with the rich variability of real behavior. Together, these
methods offer a rich class of models for the analysis of continuous action
tasks at the single-trial level.
</dc:description>
 <dc:description>Comment: New title; substantial simplifications of model</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07320</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of detecting contact nonlinearity in carbon fibre polymer
  using ultrasonic nonlinear delayed time reversal</dc:title>
 <dc:creator>Lints, Martin</dc:creator>
 <dc:creator>Salupere, Andrus</dc:creator>
 <dc:creator>Santos, Serge Dos</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A finite element method simulation of a carbon fibre reinforced polymer block
is used to analyse the nonlinearities arising from a contacting delamination
gap inside the material. The ultrasonic signal is amplified and nonlinearities
are analysed by delayed Time Reversal -- Nonlinear Elastic Wave Spectroscopy
signal processing method. This signal processing method allows to focus the
wave energy onto the receiving transducer and to modify the focused wave shape,
allowing to use several different methods, including pulse inversion, for
detecting the nonlinear signature of the damage. It is found that the small
crack with contacting acoustic nonlinearity produces a noticeable nonlinear
signature when using pulse inversion signal processing, and even higher
signature with delayed time reversal, without requiring any baseline
information from an undamaged medium.
</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07324</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inherent Biases of Recurrent Neural Networks for Phonological
  Assimilation and Dissimilation</dc:title>
 <dc:creator>Doucette, Amanda</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  A recurrent neural network model of phonological pattern learning is
proposed. The model is a relatively simple neural network with one recurrent
layer, and displays biases in learning that mimic observed biases in human
learning. Single-feature patterns are learned faster than two-feature patterns,
and vowel or consonant-only patterns are learned faster than patterns involving
vowels and consonants, mimicking the results of laboratory learning
experiments. In non-recurrent models, capturing these biases requires the use
of alpha features or some other representation of repeated features, but with a
recurrent neural network, these elaborations are not necessary.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07326</identifier>
 <datestamp>2017-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time-Series Adaptive Estimation of Vaccination Uptake Using Web Search
  Queries</dc:title>
 <dc:creator>Hansen, Niels Dalum</dc:creator>
 <dc:creator>M&#xf8;lbak, K&#xe5;re</dc:creator>
 <dc:creator>Cox, Ingemar J.</dc:creator>
 <dc:creator>Lioma, Christina</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Estimating vaccination uptake is an integral part of ensuring public health.
It was recently shown that vaccination uptake can be estimated automatically
from web data, instead of slowly collected clinical records or population
surveys. All prior work in this area assumes that features of vaccination
uptake collected from the web are temporally regular. We present the first ever
method to remove this assumption from vaccination uptake estimation: our method
dynamically adapts to temporal fluctuations in time series web data used to
estimate vaccination uptake. We show our method to outperform the state of the
art compared to competitive baselines that use not only web data but also
curated clinical data. This performance improvement is more pronounced for
vaccines whose uptake has been irregular due to negative media attention (HPV-1
and HPV-2), problems in vaccine supply (DiTeKiPol), and targeted at children of
12 years old (whose vaccination is more irregular compared to younger
children).
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07326</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07333</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>k-Means Clustering and Ensemble of Regressions: An Algorithm for the
  ISIC 2017 Skin Lesion Segmentation Challenge</dc:title>
 <dc:creator>Alvarez, David</dc:creator>
 <dc:creator>Iglesias, Monica</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This abstract briefly describes a segmentation algorithm developed for the
ISIC 2017 Skin Lesion Detection Competition hosted at [ref]. The objective of
the competition is to perform a segmentation (in the form of a binary mask
image) of skin lesions in dermoscopic images as close as possible to a
segmentation performed by trained clinicians, which is taken as ground truth.
This project only takes part in the segmentation phase of the challenge. The
other phases of the competition (feature extraction and lesion identification)
are not considered.
  The proposed algorithm consists of 4 steps: (1) lesion image preprocessing,
(2) image segmentation using k-means clustering of pixel colors, (3)
calculation of a set of features describing the properties of each segmented
region, and (4) calculation of a final score for each region, representing the
likelihood of corresponding to a suitable lesion segmentation. The scores in
step (4) are obtained by averaging the results of 2 different regression models
using the scores of each region as input. Before using the algorithm these
regression models must be trained using the training set of images and ground
truth masks provided by the Competition. Steps 2 to 4 are repeated with an
increasing number of clusters (and therefore the image is segmented into more
regions) until there is no further improvement of the calculated scores.
</dc:description>
 <dc:description>Comment: Abstract submitted to arXiv as prerequisite to participate in the
  ISIC2017 Skin Lesion Segmentation Challenge</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07335</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximately Optimal Continuous-Time Motion Planning and Control via
  Probabilistic Inference</dc:title>
 <dc:creator>Mukadam, Mustafa</dc:creator>
 <dc:creator>Cheng, Ching-An</dc:creator>
 <dc:creator>Yan, Xinyan</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The problem of optimal motion planing and control is fundamental in robotics.
However, this problem is intractable for continuous-time stochastic systems in
general and the solution is difficult to approximate if non-instantaneous
nonlinear performance indices are present. In this work, we provide an
efficient algorithm, PIPC (Probabilistic Inference for Planning and Control),
that yields approximately optimal policies with arbitrary higher-order
nonlinear performance indices. Using probabilistic inference and a Gaussian
process representation of trajectories, PIPC exploits the underlying sparsity
of the problem such that its complexity scales linearly in the number of
nonlinear factors. We demonstrate the capabilities of our algorithm in a
receding horizon setting with multiple systems in simulation.
</dc:description>
 <dc:description>Comment: minor fixes and typos</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07335</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07339</identifier>
 <datestamp>2017-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Converse to Banach's Fixed Point Theorem and its CLS Completeness</dc:title>
 <dc:creator>Daskalakis, Constantinos</dc:creator>
 <dc:creator>Tzamos, Christos</dc:creator>
 <dc:creator>Zampetakis, Manolis</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Banach's fixed point theorem for contraction maps has been widely used to
analyze the convergence of iterative methods in non-convex problems. It is a
common experience, however, that iterative maps fail to be globally contracting
under the natural metric in their domain, making the applicability of Banach's
theorem limited. We explore how generally we can apply Banach's fixed point
theorem to establish the convergence of iterative methods when pairing it with
carefully designed metrics.
  Our first result is a strong converse of Banach's theorem, showing that it is
a universal analysis tool for establishing uniqueness of fixed points and for
bounding the convergence rate of iterative maps to a unique fixed point. In
other words, we show that, whenever an iterative map globally converges to a
unique fixed point, there exists a metric under which the iterative map is
contracting and which can be used to bound the number of iterations until
convergence. We illustrate our approach in the widely used power method,
providing a new way of bounding its convergence rate through contraction
arguments.
  We next consider the computational complexity of Banach's fixed point
theorem. Making the proof of our converse theorem constructive, we show that
computing a fixed point whose existence is guaranteed by Banach's fixed point
theorem is CLS-complete. We thus provide the first natural complete problem for
the class CLS, which was defined in [Daskalakis-Papadimitriou 2011] to capture
the complexity of problems such as P-matrix LCP, computing KKT-points, and
finding mixed Nash equilibria in congestion and network coordination games.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07343</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving high-pass fusion method using wavelets</dc:title>
 <dc:creator>Shahdoosti, Hamid Reza</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In an appropriate image fusion method, spatial information of the
panchromatic image is injected into the multispectral images such that the
spectral information is not distorted. The high-pass modulation method is a
successful method in image fusion. However, the main drawback of this method is
that this technique uses the boxcar filter to extract the high frequency
information of the panchromatic image. Using the boxcar filter introduces the
ringing effect into the fused image. To cope with this problem, we use the
wavelet transform instead of boxcar filters. Then, the results of the proposed
method and those of other methods such as, Brovey, IHS, and PCA ones are
compared. Experiments show the superiority of the proposed method in terms of
correlation coefficient and mutual information.
</dc:description>
 <dc:description>Comment: 7 pages, in Persian</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07360</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Decision Trees</dc:title>
 <dc:creator>Balestriero, Randall</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we propose a synergistic melting of neural networks and
decision trees (DT) we call neural decision trees (NDT). NDT is an architecture
a la decision tree where each splitting node is an independent multilayer
perceptron allowing oblique decision functions or arbritrary nonlinear decision
function if more than one layer is used. This way, each MLP can be seen as a
node of the tree. We then show that with the weight sharing asumption among
those units, we end up with a Hashing Neural Network (HNN) which is a
multilayer perceptron with sigmoid activation function for the last layer as
opposed to the standard softmax. The output units then jointly represent the
probability to be in a particular region. The proposed framework allows for
global optimization as opposed to greedy in DT and differentiability w.r.t. all
parameters and the input, allowing easy integration in any learnable pipeline,
for example after CNNs for computer vision tasks. We also demonstrate the
modeling power of HNN allowing to learn union of disjoint regions for final
clustering or classification making it more general and powerful than standard
softmax MLP requiring linear separability thus reducing the need on the inner
layer to perform complex data transformations. We finally show experiments for
supervised, semi-suppervised and unsupervised tasks and compare results with
standard DTs and MLPs.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07367</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Newton and Quasi-Newton Methods for Large Linear
  Least-squares Problems</dc:title>
 <dc:creator>Chung, Julianne</dc:creator>
 <dc:creator>Chung, Matthias</dc:creator>
 <dc:creator>Slagel, J. Tanner</dc:creator>
 <dc:creator>Tenorio, Luis</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We describe stochastic Newton and stochastic quasi-Newton approaches to
efficiently solve large linear least-squares problems where the very large data
sets present a significant computational burden (e.g., the size may exceed
computer memory or data are collected in real-time). In our proposed framework,
stochasticity is introduced in two different frameworks as a means to overcome
these computational limitations, and probability distributions that can exploit
structure and/or sparsity are considered. Theoretical results on consistency of
the approximations for both the stochastic Newton and the stochastic
quasi-Newton methods are provided. The results show, in particular, that
stochastic Newton iterates, in contrast to stochastic quasi-Newton iterates,
may not converge to the desired least-squares solution. Numerical examples,
including an example from extreme learning machines, demonstrate the potential
applications of these methods.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07371</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feasibility of Principal Component Analysis in hand gesture recognition
  system</dc:title>
 <dc:creator>Srivastava, Tanu</dc:creator>
 <dc:creator>Singh, Raj Shree</dc:creator>
 <dc:creator>Kumar, Sunil</dc:creator>
 <dc:creator>Chakraborty, Pavan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Nowadays actions are increasingly being handled in electronic ways, instead
of physical interaction. From earlier times biometrics is used in the
authentication of a person. It recognizes a person by using a human trait
associated with it like eyes (by calculating the distance between the eyes) and
using hand gestures, fingerprint detection, face detection etc. Advantages of
using these traits for identification are that they uniquely identify a person
and cannot be forgotten or lost. These are unique features of a human being
which are being used widely to make the human life simpler. Hand gesture
recognition system is a powerful tool that supports efficient interaction
between the user and the computer. The main moto of hand gesture recognition
research is to create a system which can recognise specific hand gestures and
use them to convey useful information for device control. This paper presents
an experimental study over the feasibility of principal component analysis in
hand gesture recognition system. PCA is a powerful tool for analyzing data. The
primary goal of PCA is dimensionality reduction. Frames are extracted from the
Sheffield KInect Gesture (SKIG) dataset. The implementation is done by creating
a training set and then training the recognizer. It uses Eigen space by
processing the eigenvalues and eigenvectors of the images in training set.
Euclidean distance with the threshold value is used as similarity metric to
recognize the gestures. The experimental results show that PCA is feasible to
be used for hand gesture recognition system.
</dc:description>
 <dc:description>Comment: conference</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07375</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delta-net: Real-time Network Verification Using Atoms</dc:title>
 <dc:creator>Horn, Alex</dc:creator>
 <dc:creator>Kheradmand, Ali</dc:creator>
 <dc:creator>Prasad, Mukul R.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Real-time network verification promises to automatically detect violations of
network-wide reachability invariants on the data plane. To be useful in
practice, these violations need to be detected in the order of milliseconds,
without raising false alarms. To date, most real-time data plane checkers
address this problem by exploiting at least one of the following two
observations: (i) only small parts of the network tend to be affected by
typical changes to the data plane, and (ii) many different packets tend to
share the same forwarding behaviour in the entire network. This paper shows how
to effectively exploit a third characteristic of the problem, namely:
similarity among forwarding behaviour of packets through parts of the network,
rather than its entirety. We propose the first provably amortized quasi-linear
algorithm to do so. We implement our algorithm in a new real-time data plane
checker, Delta-net. Our experiments with SDN-IP, a globally deployed ONOS
software-defined networking application, and several hundred million IP prefix
rules generated using topologies and BGP updates from real-world deployed
networks, show that Delta-net checks a rule insertion or removal in
approximately 40 microseconds on average, a more than 10X improvement over the
state-of-the-art. We also show that Delta-net eliminates an inherent bottleneck
in the state-of-the-art that restricts its use in answering Datalog-style &quot;what
if&quot; queries.
</dc:description>
 <dc:description>Comment: NSDI'17</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07386</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Streaming Synapse Detection with Compositional ConvNets</dc:title>
 <dc:creator>Santurkar, Shibani</dc:creator>
 <dc:creator>Budden, David</dc:creator>
 <dc:creator>Matveev, Alexander</dc:creator>
 <dc:creator>Berlin, Heather</dc:creator>
 <dc:creator>Saribekyan, Hayk</dc:creator>
 <dc:creator>Meirovitch, Yaron</dc:creator>
 <dc:creator>Shavit, Nir</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Connectomics is an emerging field in neuroscience that aims to reconstruct
the 3-dimensional morphology of neurons from electron microscopy (EM) images.
Recent studies have successfully demonstrated the use of convolutional neural
networks (ConvNets) for segmenting cell membranes to individuate neurons.
However, there has been comparatively little success in high-throughput
identification of the intercellular synaptic connections required for deriving
connectivity graphs.
  In this study, we take a compositional approach to segmenting synapses,
modeling them explicitly as an intercellular cleft co-located with an
asymmetric vesicle density along a cell membrane. Instead of requiring a deep
network to learn all natural combinations of this compositionality, we train
lighter networks to model the simpler marginal distributions of membranes,
clefts and vesicles from just 100 electron microscopy samples. These feature
maps are then combined with simple rules-based heuristics derived from prior
biological knowledge.
  Our approach to synapse detection is both more accurate than previous
state-of-the-art (7% higher recall and 5% higher F1-score) and yields a 20-fold
speed-up compared to the previous fastest implementations. We demonstrate by
reconstructing the first complete, directed connectome from the largest
available anisotropic microscopy dataset (245 GB) of mouse somatosensory cortex
(S1) in just 9.7 hours on a single shared-memory CPU system. We believe that
this work marks an important step toward the goal of a microscope-pace
streaming connectomics pipeline.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07388</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Store Languages of Language Acceptors</dc:title>
 <dc:creator>Ibarra, Oscar H.</dc:creator>
 <dc:creator>McQuillan, Ian</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  It is well known that the &quot;store language&quot; of every pushdown automaton -- the
set of store configurations (state and stack contents) that can appear as an
intermediate step in accepting computations -- is a regular language. Here many
models of language acceptors with various data structures are examined, along
with a study of their store languages. For each model, an attempt is made to
find the simplest model that accepts their store languages. Some connections
between store languages of one-way and two-way machines generally are
demonstrated, as with connections between nondeterministic and deterministic
machines. A nice application of these store language results is also presented,
showing a general technique for proving families accepted by many deterministic
models are closed under right quotient with regular languages, resolving some
open questions (and significantly simplifying proofs for others that are known)
in the literature. Lower bounds on the space complexity for recognizing store
languages for the languages to be non-regular are obtained.
</dc:description>
 <dc:description>Comment: 19 pages, preprint to be submitted to a journal</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07389</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous-Time Visual-Inertial Trajectory Estimation with Event Cameras</dc:title>
 <dc:creator>Mueggler, Elias</dc:creator>
 <dc:creator>Gallego, Guillermo</dc:creator>
 <dc:creator>Rebecq, Henri</dc:creator>
 <dc:creator>Scaramuzza, Davide</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In contrast to traditional cameras, which output images at a fixed rate,
event cameras have independent pixels that output asynchronous pixel-level
brightness changes with microsecond resolution. In this paper, we leverage a
continuous-time framework to perform trajectory estimation by fusing visual
data from a moving event camera with inertial data from an IMU. This framework
allows direct integration of the asynchronous events with micro-second accuracy
and the inertial measurements at high frequency. The pose trajectory is
approximated by a smooth curve in the space of rigid-body motions using cubic
splines. This formulation significantly reduces the number of variables in
trajectory estimation problems. We evaluate our method on real data from
several scenes and compare the results against ground truth from a
motion-capture system. We show superior performance of the proposed technique
compared to non-batch event-based algorithms. We also show that both the map
orientation and scale can be recovered accurately by fusing events and inertial
data. To the best of our knowledge, this is the first work on visual-inertial
fusion with event cameras using a continuous-time framework.
</dc:description>
 <dc:description>Comment: 14 pages, 12 figures, 4 tables</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07390</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Strong Ties Using Network Motifs</dc:title>
 <dc:creator>Rotabi, Rahmtin</dc:creator>
 <dc:creator>Kamath, Krishna</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Sharma, Aneesh</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Detecting strong ties among users in social and information networks is a
fundamental operation that can improve performance on a multitude of
personalization and ranking tasks. Strong-tie edges are often readily obtained
from the social network as users often participate in multiple overlapping
networks via features such as following and messaging. These networks may vary
greatly in size, density and the information they carry. This setting leads to
a natural strong tie detection task: given a small set of labeled strong tie
edges, how well can one detect unlabeled strong ties in the remainder of the
network?
  This task becomes particularly daunting for the Twitter network due to scant
availability of pairwise relationship attribute data, and sparsity of strong
tie networks such as phone contacts. Given these challenges, a natural approach
is to instead use structural network features for the task, produced by {\em
combining} the strong and &quot;weak&quot; edges. In this work, we demonstrate via
experiments on Twitter data that using only such structural network features is
sufficient for detecting strong ties with high precision. These structural
network features are obtained from the presence and frequency of small network
motifs on combined strong and weak ties. We observe that using motifs larger
than triads alleviate sparsity problems that arise for smaller motifs, both due
to increased combinatorial possibilities as well as benefiting strongly from
searching beyond the ego network. Empirically, we observe that not all motifs
are equally useful, and need to be carefully constructed from the combined
edges in order to be effective for strong tie detection. Finally, we reinforce
our experimental findings with providing theoretical justification that
suggests why incorporating these larger sized motifs as features could lead to
increased performance in planted graph models.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of WWW 2017 (Web-science track)</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07390</dc:identifier>
 <dc:identifier>doi:10.1145/3041021.3055139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07392</identifier>
 <datestamp>2017-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WaterGAN: Unsupervised Generative Network to Enable Real-time Color
  Correction of Monocular Underwater Images</dc:title>
 <dc:creator>Li, Jie</dc:creator>
 <dc:creator>Skinner, Katherine A.</dc:creator>
 <dc:creator>Eustice, Ryan M.</dc:creator>
 <dc:creator>Johnson-Roberson, Matthew</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper reports on WaterGAN, a generative adversarial network (GAN) for
generating realistic underwater images from in-air image and depth pairings in
an unsupervised pipeline used for color correction of monocular underwater
images. Cameras onboard autonomous and remotely operated vehicles can capture
high resolution images to map the seafloor, however, underwater image formation
is subject to the complex process of light propagation through the water
column. The raw images retrieved are characteristically different than images
taken in air due to effects such as absorption and scattering, which cause
attenuation of light at different rates for different wavelengths. While this
physical process is well described theoretically, the model depends on many
parameters intrinsic to the water column as well as the objects in the scene.
These factors make recovery of these parameters difficult without simplifying
assumptions or field calibration, hence, restoration of underwater images is a
non-trivial problem. Deep learning has demonstrated great success in modeling
complex nonlinear systems but requires a large amount of training data, which
is difficult to compile in deep sea environments. Using WaterGAN, we generate a
large training dataset of paired imagery, both raw underwater and true color
in-air, as well as depth data. This data serves as input to a novel end-to-end
network for color correction of monocular underwater images. Due to the
depth-dependent water column effects inherent to underwater environments, we
show that our end-to-end network implicitly learns a coarse depth estimate of
the underwater scene from monocular underwater images. Our proposed pipeline is
validated with testing on real data collected from both a pure water tank and
from underwater surveys in field testing. Source code is made publicly
available with sample datasets and pretrained models.
</dc:description>
 <dc:description>Comment: 8 pages, 16 figures, published by RA-letter 2018. Source code
  available at: https://github.com/kskin/WaterGAN</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07392</dc:identifier>
 <dc:identifier>IEEE Robotics and Automation Letters IEEE Robotics and Automation
  Letters IEEE Robotics and Automation Letters 387 - 394 (2018)</dc:identifier>
 <dc:identifier>doi:10.1109/LRA.2017.2730363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07393</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Controlling Parent Systems Through Swarms Using Abstraction</dc:title>
 <dc:creator>Crandall, Kyle L</dc:creator>
 <dc:creator>Wickenheiser, Adam M</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This study considers the control of parent-child systems where a parent
system is acted on by a set of child systems with their own inputs. Examples of
such systems include a swarm of robots pushing an object over a surface, a
swarm of aerial vehicles carrying a large load, or a set of end effectors
manipulating an object. In this paper, a general framework for decoupling the
swarm from the parent system through a low-dimensional abstract state space is
presented. The requirements of this framework are presented along with how
constraints on both systems propagate through the abstract state and impact the
requirements of the controllers for both systems. Several controllers with hard
state constraints are designed to track a desired angle of the tilting plane
with a swarm of robots driving on top. Both homogeneous and heterogeneous
swarms of varying sizes and properties are considered. The controllers are
shown to be locally asymptotically stable and are demonstrated in simulation.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07399</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimal Algorithm for Computing the Spherical Depth of Points in the
  Plane</dc:title>
 <dc:creator>Bremner, David</dc:creator>
 <dc:creator>Shahsavarifar, Rasoul</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  For a distribution function $F$ on $\mathbb{R}^d$ and a point $q\in
\mathbb{R}^d$, the \emph{spherical depth} $\SphD(q;F)$ is defined to be the
probability that a point $q$ is contained inside a random closed hyper-ball
obtained from a pair of points from $F$. The spherical depth $\SphD(q;S)$ is
also defined for an arbitrary data set $S\subseteq \mathbb{R}^d$ and $q\in
\mathbb{R}^d$. This definition is based on counting all of the closed
hyper-balls, obtained from pairs of points in $S$, that contain $q$. The
significant advantage of using the spherical depth in multivariate data
analysis is related to its complexity of computation. Unlike most other data
depths, the time complexity of the spherical depth grows linearly rather than
exponentially in the dimension $d$. The straightforward algorithm for computing
the spherical depth in dimension $d$ takes $O(dn^2)$. The main result of this
paper is an optimal algorithm that we present for computing the bivariate
spherical depth. The algorithm takes $O(n \log n)$ time. By reducing the
problem of \textit{Element Uniqueness}, we prove that computing the spherical
depth requires $\Omega(n \log n)$ time. Some geometric properties of spherical
depth are also investigated in this paper. These properties indicate that
\emph{simplicial depth} ($\SD$) (Liu, 1990) is linearly bounded by spherical
depth (in particular, $\SphD\geq \frac{2}{3}SD$). To illustrate this
relationship between the spherical depth and the simplicial depth, some
experimental results are provided. The obtained experimental bound ($\SphD\geq
2\SD$) indicates that, perhaps, a stronger theoretical bound can be achieved.
</dc:description>
 <dc:description>Comment: The paper consisting of 11 pages, containing 11 figures. This paper
  is submitted to WADS 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07403</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Asynchronous Distributed Computations Robust to Noise</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Gelles, Ran</dc:creator>
 <dc:creator>Haeupler, Bernhard</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We consider the problem of making distributed computations robust to noise,
in particular to worst-case (adversarial) corruptions of messages. We give a
general distributed interactive coding scheme which simulates any asynchronous
distributed protocol while tolerating an optimal corruption of a $\Theta(1/n)$
fraction of all messages while incurring a moderate blowup of $O(n\log^2 n)$ in
the communication complexity.
  Our result is the first fully distributed interactive coding scheme in which
the topology of the communication network is not known in advance. Prior work
required either a coordinating node to be connected to all other nodes in the
network or assumed a synchronous network in which all nodes already know the
complete topology of the network.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07409</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Founsure 1.0: An Erasure Code Library with Efficient Repair and Update
  Features</dc:title>
 <dc:creator>Arslan, &#x15e;uayb &#x15e;.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Founsure is an open-source software library, distributed under LGPLv3 license
and implements a multi-dimensional graph-based erasure coding entirely based on
fast exclusive OR (XOR) logic. Its implementation utilizes compiler
optimizations and the multi-threaded implementation to generate the right
assembly code for the given multi-core CPU architectures with vector processing
capabilities. Founsure (version 1.0) supports a variety of features that shall
find interesting applications in modern data storage as well as communication
and computer network systems which are becoming hungry in terms of network
bandwidth, computational resources and average consumed power. In particular,
Founsure library provides a three dimensional design space that consists of
computation complexity, coding overhead and data/node repair bandwidth to meet
different requirements of modern distributed data storage and processing
systems in which the data needs to be protected against device, hardware and
node failures. Unique features of Founsure include encoding, decoding,
repairs/rebuilds and updates while the data and computation can be distributed
across the network nodes.
</dc:description>
 <dc:description>Comment: To be submitted to Elsevier Open access journal SoftwareX, 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2018-01-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07424</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Usage Profiles Using Deep Neural Nets</dc:title>
 <dc:creator>Curro, Domenic</dc:creator>
 <dc:creator>Derpanis, Konstantinos G.</dc:creator>
 <dc:creator>Miranskyy, Andriy V.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  To improve software quality, one needs to build test scenarios resembling the
usage of a software product in the field. This task is rendered challenging
when a product's customer base is large and diverse. In this scenario, existing
profiling approaches, such as operational profiling, are difficult to apply. In
this work, we consider publicly available video tutorials of a product to
profile usage. Our goal is to construct an automatic approach to extract
information about user actions from instructional videos. To achieve this goal,
we use a Deep Convolutional Neural Network (DCNN) to recognize user actions.
Our pilot study shows that a DCNN trained to recognize user actions in video
can classify five different actions in a collection of 236 publicly available
Microsoft Word tutorial videos (published on YouTube). In our empirical
evaluation we report a mean average precision of 94.42% across all actions.
This study demonstrates the efficacy of DCNN-based methods for extracting
software usage information from videos. Moreover, this approach may aid in
other software engineering activities that require information about customer
usage of a product.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07424</dc:identifier>
 <dc:identifier>Proceedings of the 39th International Conference on Software
  Engineering: New Ideas and Emerging Results Track (ICSE-NIER '17). IEEE
  Press, Piscataway, NJ, USA, 43-46, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/ICSE-NIER.2017.12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07425</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming supercomputing needs workflow-enabled programming-in-the-large</dc:title>
 <dc:creator>Wozniak, Justin M</dc:creator>
 <dc:creator>Ozik, Jonathan</dc:creator>
 <dc:creator>Katz, Daniel S.</dc:creator>
 <dc:creator>Wilde, Michael</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This is a position paper, submitted to the Future Online Analysis Platform
Workshop (https://press3.mcs.anl.gov/futureplatform/), which argues that simple
data analysis applications are common today, but future online supercomputing
workloads will need to couple multiple advanced technologies (streams, caches,
analysis, and simulations) to rapidly deliver scientific results. Each of these
technologies are active research areas when integrated with high-performance
computing. These components will interact in complex ways, therefore coupling
them needs to be programmed. Programming in the large, on top of existing
applications, enables us to build much more capable applications and to
productively manage this complexity.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07426</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of the Correlation of Spontaneous Neuron Activity in Biological
  and Noise-activated CMOS Artificial Neural Microcircuits</dc:title>
 <dc:creator>Hasani, Ramin M.</dc:creator>
 <dc:creator>Ferrari, Giorgio</dc:creator>
 <dc:creator>Yamamoto, Hideaki</dc:creator>
 <dc:creator>Kono, Sho</dc:creator>
 <dc:creator>Ishihara, Koji</dc:creator>
 <dc:creator>Fujimori, Soya</dc:creator>
 <dc:creator>Tanii, Takashi</dc:creator>
 <dc:creator>Prati, Enrico</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  There are several indications that brain is organized not on a basis of
individual unreliable neurons, but on a micro-circuital scale providing Lego
blocks employed to create complex architectures. At such an intermediate scale,
the firing activity in the microcircuits is governed by collective effects
emerging by the background noise soliciting spontaneous firing, the degree of
mutual connections between the neurons, and the topology of the connections. We
compare spontaneous firing activity of small populations of neurons adhering to
an engineered scaffold with simulations of biologically plausible CMOS
artificial neuron populations whose spontaneous activity is ignited by tailored
background noise. We provide a full set of flexible and low-power consuming
silicon blocks including neurons, excitatory and inhibitory synapses, and both
white and pink noise generators for spontaneous firing activation. We achieve a
comparable degree of correlation of the firing activity of the biological
neurons by controlling the kind and the number of connection among the silicon
neurons. The correlation between groups of neurons, organized as a ring of four
distinct populations connected by the equivalent of interneurons, is triggered
more effectively by adding multiple synapses to the connections than increasing
the number of independent point-to-point connections. The comparison between
the biological and the artificial systems suggests that a considerable number
of synapses is active also in biological populations adhering to engineered
scaffolds.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07429</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Optimality of Secret Key Agreement via Omniscience</dc:title>
 <dc:creator>Chan, Chung</dc:creator>
 <dc:creator>Mukherjee, Manuj</dc:creator>
 <dc:creator>Kashyap, Navin</dc:creator>
 <dc:creator>Zhou, Qiaoqiao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For the multiterminal secret key agreement problem under a private source
model, it is known that the maximum key rate, i.e., the secrecy capacity, can
be achieved through communication for omniscience, but the omniscience strategy
can be strictly suboptimal in terms of minimizing the public discussion rate.
While a single-letter characterization is not known for the minimum discussion
rate needed for achieving the secrecy capacity, we derive single-letter lower
and upper bounds that yield some simple conditions for omniscience to be
discussion-rate optimal. These conditions turn out to be enough to deduce the
optimality of omniscience for a large class of sources including the
hypergraphical sources. Through conjectures and examples, we explore other
source models to which our methods do not easily extend.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07429</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07431</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Debt-Aware Learning Approach for Resource Adaptations in Cloud
  Elasticity Management</dc:title>
 <dc:creator>Mera-G&#xf3;mez, Carlos</dc:creator>
 <dc:creator>Ram&#xed;rez, Francisco</dc:creator>
 <dc:creator>Bahsoon, Rami</dc:creator>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Elasticity is a cloud property that enables applications and its execution
systems to dynamically acquire and release shared computational resources on
demand. Moreover, it unfolds the advantage of economies of scale in the cloud
through a drop in the average costs of these shared resources. However, it is
still an open challenge to achieve a perfect match between resource demand and
provision in autonomous elasticity management. Resource adaptation decisions
essentially involve a trade-off between economics and performance, which
produces a gap between the ideal and actual resource provisioning. This gap, if
not properly managed, can negatively impact the aggregate utility of a cloud
customer in the long run. To address this limitation, we propose a technical
debt-aware learning approach for autonomous elasticity management based on a
reinforcement learning of elasticity debts in resource provisioning; the
adaptation pursues strategic decisions that trades off economics against
performance. We extend CloudSim and Burlap to evaluate our approach. The
evaluation shows that a reinforcement learning of technical debts in elasticity
obtains a higher utility for a cloud customer, while conforming expected levels
of performance.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07432</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Context Attention for Human Pose Estimation</dc:title>
 <dc:creator>Chu, Xiao</dc:creator>
 <dc:creator>Yang, Wei</dc:creator>
 <dc:creator>Ouyang, Wanli</dc:creator>
 <dc:creator>Ma, Cheng</dc:creator>
 <dc:creator>Yuille, Alan L.</dc:creator>
 <dc:creator>Wang, Xiaogang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose to incorporate convolutional neural networks with a
multi-context attention mechanism into an end-to-end framework for human pose
estimation. We adopt stacked hourglass networks to generate attention maps from
features at multiple resolutions with various semantics. The Conditional Random
Field (CRF) is utilized to model the correlations among neighboring regions in
the attention map. We further combine the holistic attention model, which
focuses on the global consistency of the full human body, and the body part
attention model, which focuses on the detailed description for different body
parts. Hence our model has the ability to focus on different granularity from
local salient regions to global semantic-consistent spaces. Additionally, we
design novel Hourglass Residual Units (HRUs) to increase the receptive field of
the network. These units are extensions of residual units with a side branch
incorporating filters with larger receptive fields, hence features with various
scales are learned and combined within the HRUs. The effectiveness of the
proposed multi-context attention mechanism and the hourglass residual units is
evaluated on two widely used human pose estimation benchmarks. Our approach
outperforms all existing methods on both benchmarks over all the body parts.
</dc:description>
 <dc:description>Comment: The first two authors contribute equally to this work</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07435</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacitated Center Problems with Two-Sided Bounds and Outliers</dc:title>
 <dc:creator>Ding, Hu</dc:creator>
 <dc:creator>Hu, Lunjia</dc:creator>
 <dc:creator>Huang, Lingxiao</dc:creator>
 <dc:creator>Li, Jian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In recent years, the capacitated center problems have attracted a lot of
research interest. Given a set of vertices $V$, we want to find a subset of
vertices $S$, called centers, such that the maximum cluster radius is
minimized. Moreover, each center in $S$ should satisfy some capacity
constraint, which could be an upper or lower bound on the number of vertices it
can serve. Capacitated $k$-center problems with one-sided bounds (upper or
lower) have been well studied in previous work, and a constant factor
approximation was obtained.
  We are the first to study the capacitated center problem with both capacity
lower and upper bounds (with or without outliers). We assume each vertex has a
uniform lower bound and a non-uniform upper bound. For the case of opening
exactly $k$ centers, we note that a generalization of a recent LP approach can
achieve constant factor approximation algorithms for our problems. Our main
contribution is a simple combinatorial algorithm for the case where there is no
cardinality constraint on the number of open centers. Our combinatorial
algorithm is simpler and achieves better constant approximation factor compared
to the LP approach.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07436</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Glimmers: Resolving the Privacy/Trust Quagmire</dc:title>
 <dc:creator>Lie, David</dc:creator>
 <dc:creator>Maniatis, Petros</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Many successful services rely on trustworthy contributions from users. To
establish that trust, such services often require access to privacy-sensitive
information from users, thus creating a conflict between privacy and trust.
Although it is likely impractical to expect both absolute privacy and
trustworthiness at the same time, we argue that the current state of things,
where individual privacy is usually sacrificed at the altar of trustworthy
services, can be improved with a pragmatic $Glimmer$ $of$ $Trust$, which allows
services to validate user contributions in a trustworthy way without forfeiting
user privacy. We describe how trustworthy hardware such as Intel's SGX can be
used client-side -- in contrast to much recent work exploring SGX in cloud
services -- to realize the Glimmer architecture, and demonstrate how this
realization is able to resolve the tension between privacy and trust in a
variety of cases.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07437</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Gamification Affects Physical Activity: Large-scale Analysis of
  Walking Challenges in a Mobile Application</dc:title>
 <dc:creator>Shameli, Ali</dc:creator>
 <dc:creator>Althoff, Tim</dc:creator>
 <dc:creator>Saberi, Amin</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Gamification represents an effective way to incentivize user behavior across
a number of computing applications. However, despite the fact that physical
activity is essential for a healthy lifestyle, surprisingly little is known
about how gamification and in particular competitions shape human physical
activity. Here we study how competitions affect physical activity. We focus on
walking challenges in a mobile activity tracking application where multiple
users compete over who takes the most steps over a predefined number of days.
We synthesize our findings in a series of game and app design implications. In
particular, we analyze nearly 2,500 physical activity competitions over a
period of one year capturing more than 800,000 person days of activity
tracking. We observe that during walking competitions, the average user
increases physical activity by 23%. Furthermore, there are large increases in
activity for both men and women across all ages, and weight status, and even
for users that were previously fairly inactive. We also find that the
composition of participants greatly affects the dynamics of the game. In
particular, if highly unequal participants get matched to each other, then
competition suffers and the overall effect on the physical activity drops
significantly. Furthermore, competitions with an equal mix of both men and
women are more effective in increasing the level of activities. We leverage
these insights to develop a statistical model to predict whether or not a
competition will be particularly engaging with significant accuracy. Our models
can serve as a guideline to help design more engaging competitions that lead to
most beneficial behavioral changes.
</dc:description>
 <dc:description>Comment: WWW 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07444</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandits with Movement Costs and Adaptive Pricing</dc:title>
 <dc:creator>Koren, Tomer</dc:creator>
 <dc:creator>Livni, Roi</dc:creator>
 <dc:creator>Mansour, Yishay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We extend the model of Multi-armed Bandit with unit switching cost to
incorporate a metric between the actions. We consider the case where the metric
over the actions can be modeled by a complete binary tree, and the distance
between two leaves is the size of the subtree of their least common ancestor,
which abstracts the case that the actions are points on the continuous interval
$[0,1]$ and the switching cost is their distance. In this setting, we give a
new algorithm that establishes a regret of $\widetilde{O}(\sqrt{kT} + T/k)$,
where $k$ is the number of actions and $T$ is the time horizon. When the set of
actions corresponds to whole $[0,1]$ interval we can exploit our method for the
task of bandit learning with Lipschitz loss functions, where our algorithm
achieves an optimal regret rate of $\widetilde{\Theta}(T^{2/3})$, which is the
same rate one obtains when there is no penalty for movements. As our main
application, we use our new algorithm to solve an adaptive pricing problem.
Specifically, we consider the case of a single seller faced with a stream of
patient buyers. Each buyer has a private value and a window of time in which
they are interested in buying, and they buy at the lowest price in the window,
if it is below their value. We show that with an appropriate discretization of
the prices, the seller can achieve a regret of $\widetilde{O}(T^{2/3})$
compared to the best fixed price in hindsight, which outperform the previous
regret bound of $\widetilde{O}(T^{3/4})$ for the problem.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07445</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessment of Prediction Techniques: The Impact of Human Uncertainty</dc:title>
 <dc:creator>Jasberg, Kevin</dc:creator>
 <dc:creator>Sizov, Sergej</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Many data mining approaches aim at modelling and predicting human behaviour.
An important quantity of interest is the quality of model-based predictions,
e.g. for finding a competition winner with best prediction performance.
  In real life, human beings meet their decisions with considerable
uncertainty. Its assessment and resulting implications for statistically
evident evaluation of predictive models are in the main focus of this
contribution. We identify relevant sources of uncertainty as well as the
limited ability of its accurate measurement, propose an uncertainty-aware
methodology for more evident evaluations of data mining approaches, and discuss
its implications for existing quality assessment strategies. Specifically, our
approach switches from common point-paradigm to more appropriate
distribution-paradigm.
  This is exemplified in the context of recommender systems and their
established metrics of prediction quality. The discussion is substantiated by
comprehensive experiments with real users, large-scale simulations, and
discussion of prior evaluation campaigns (i.a. Netflix Prize) in the light of
human uncertainty aspects.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07450</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strongly-Typed Agents are Guaranteed to Interact Safely</dc:title>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  As artificial agents proliferate, it is becoming increasingly important to
ensure that their interactions with one another are well-behaved. In this
paper, we formalize a common-sense notion of when algorithms are well-behaved:
an algorithm is safe if it does no harm. Motivated by recent progress in deep
learning, we focus on the specific case where agents update their actions
according to gradient descent. The first result is that gradient descent
converges to a Nash equilibrium in safe games.
  The paper provides sufficient conditions that guarantee safe interactions.
The main contribution is to define strongly-typed agents and show they are
guaranteed to interact safely. A series of examples show that strong-typing
generalizes certain key features of convexity and is closely related to blind
source separation. The analysis introduce a new perspective on classical
multilinear games based on tensor decomposition.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07451</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Viewpoint Adaptation for Rigid Object Detection</dc:title>
 <dc:creator>Wang, Patrick</dc:creator>
 <dc:creator>Morton, Kenneth</dc:creator>
 <dc:creator>Torrione, Peter</dc:creator>
 <dc:creator>Collins, Leslie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An object detector performs suboptimally when applied to image data taken
from a viewpoint different from the one with which it was trained. In this
paper, we present a viewpoint adaptation algorithm that allows a trained
single-view object detector to be adapted to a new, distinct viewpoint. We
first illustrate how a feature space transformation can be inferred from a
known homography between the source and target viewpoints. Second, we show that
a variety of trained classifiers can be modified to behave as if that
transformation were applied to each testing instance. The proposed algorithm is
evaluated on a person detection task using images from the PETS 2007 and CAVIAR
datasets, as well as from a new synthetic multi-view person detection dataset.
It yields substantial performance improvements when adapting single-view person
detectors to new viewpoints, and simultaneously reduces computational
complexity. This work has the potential to improve detection performance for
cameras viewing objects from arbitrary viewpoints, while simplifying data
collection and feature extraction.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07451</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07452</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Defined Media: Virtualization of Audio-Visual Services</dc:title>
 <dc:creator>Tsukada, Manabu</dc:creator>
 <dc:creator>Ogawa, Keiko</dc:creator>
 <dc:creator>Ikeda, Masahiro</dc:creator>
 <dc:creator>Sone, Takuro</dc:creator>
 <dc:creator>Niwa, Kenta</dc:creator>
 <dc:creator>Saito, Shoichiro</dc:creator>
 <dc:creator>Kasuya, Takashi</dc:creator>
 <dc:creator>Sunahara, Hideki</dc:creator>
 <dc:creator>Esaki, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Internet-native audio-visual services are witnessing rapid development. Among
these services, object-based audio-visual services are gaining importance. In
2014, we established the Software Defined Media (SDM) consortium to target new
research areas and markets involving object-based digital media and
Internet-by-design audio-visual environments. In this paper, we introduce the
SDM architecture that virtualizes networked audio-visual services along with
the development of smart buildings and smart cities using Internet of Things
(IoT) devices and smart building facilities. Moreover, we design the SDM
architecture as a layered architecture to promote the development of innovative
applications on the basis of rapid advancements in software-defined networking
(SDN). Then, we implement a prototype system based on the architecture, present
the system at an exhibition, and provide it as an SDM API to application
developers at hackathons. Various types of applications are developed using the
API at these events. An evaluation of SDM API access shows that the prototype
SDM platform effectively provides 3D audio reproducibility and interactiveness
for SDM applications.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Communications (ICC2017), Paris,
  France, 21-25 May 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07456</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Hidden Vector Encryptions and Its Applications</dc:title>
 <dc:creator>Lee, Kwangsu</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Predicate encryption is a new paradigm of public key encryption that enables
searches on encrypted data. Using the predicate encryption, we can search
keywords or attributes on encrypted data without decrypting the ciphertexts. In
predicate encryption, a ciphertext is associated with attributes and a token
corresponds to a predicate. The token that corresponds to a predicate $f$ can
decrypt the ciphertext associated with attributes $x$ if and only if $f(x)=1$.
Hidden vector encryption (HVE) is a special kind of predicate encryption. In
this thesis, we consider the efficiency, the generality, and the security of
HVE schemes. The results of this thesis are described as follows.
  The first results of this thesis are efficient HVE schemes where the token
consists of just four group elements and the decryption only requires four
bilinear map computations, independent of the number of attributes in the
ciphertext. The construction uses composite order bilinear groups and is
selectively secure under the well-known assumptions. The second results are
efficient HVE schemes that are secure under any kind of pairing types. To
achieve our goals, we proposed a general framework that converts HVE schemes
from composite order bilinear groups to prime order bilinear groups. Using the
framework, we convert the previous HVE schemes from composite order bilinear
groups to prime order bilinear groups. The third results are fully secure HVE
schemes with short tokens. Previous HVE schemes were proven to be secure only
in the selective security model where the capabilities of the adversaries are
severely restricted. Using the dual system encryption techniques, we construct
fully secure HVE schemes with match revealing property in composite order
groups.
</dc:description>
 <dc:description>Comment: PhD Thesis, Korea University, February 2011</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07456</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07458</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small-space encoding LCE data structure with constant-time queries</dc:title>
 <dc:creator>Tanimura, Yuka</dc:creator>
 <dc:creator>Nishimoto, Takaaki</dc:creator>
 <dc:creator>Bannai, Hideo</dc:creator>
 <dc:creator>Inenaga, Shunsuke</dc:creator>
 <dc:creator>Takeda, Masayuki</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The \emph{longest common extension} (\emph{LCE}) problem is to preprocess a
given string $w$ of length $n$ so that the length of the longest common prefix
between suffixes of $w$ that start at any two given positions is answered
quickly. In this paper, we present a data structure of $O(z \tau^2 +
\frac{n}{\tau})$ words of space which answers LCE queries in $O(1)$ time and
can be built in $O(n \log \sigma)$ time, where $1 \leq \tau \leq \sqrt{n}$ is a
parameter, $z$ is the size of the Lempel-Ziv 77 factorization of $w$ and
$\sigma$ is the alphabet size. This is an \emph{encoding} data structure, i.e.,
it does not access the input string $w$ when answering queries and thus $w$ can
be deleted after preprocessing. On top of this main result, we obtain further
results using (variants of) our LCE data structure, which include the
following:
  - For highly repetitive strings where the $z\tau^2$ term is dominated by
$\frac{n}{\tau}$, we obtain a \emph{constant-time and sub-linear space} LCE
query data structure.
  - Even when the input string is not well compressible via Lempel-Ziv 77
factorization, we still can obtain a \emph{constant-time and sub-linear space}
LCE data structure for suitable $\tau$ and for $\sigma \leq 2^{o(\log n)}$.
  - The time-space trade-off lower bounds for the LCE problem by Bille et al.
[J. Discrete Algorithms, 25:42-50, 2014] and by Kosolobov [CoRR,
abs/1611.02891, 2016] can be &quot;surpassed&quot; in some cases with our LCE data
structure.
</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07461</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Relation between Constraint Answer Set Programming and Satisfiability
  Modulo Theories</dc:title>
 <dc:creator>Lierler, Yuliya</dc:creator>
 <dc:creator>Susman, Benjamin</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>D.1.6</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Constraint answer set programming is a promising research direction that
integrates answer set programming with constraint processing. It is often
informally related to the field of satisfiability modulo theories. Yet, the
exact formal link is obscured as the terminology and concepts used in these two
research areas differ. In this paper, we connect these two research areas by
uncovering the precise formal relation between them. We believe that this work
will booster the cross-fertilization of the theoretical foundations and the
existing solving methods in both areas. As a step in this direction we provide
a translation from constraint answer set programs with integer linear
constraints to satisfiability modulo linear integer arithmetic that paves the
way to utilizing modern satisfiability modulo theories solvers for computing
answer sets of constraint answer set programs.
</dc:description>
 <dc:description>Comment: Under consideration in Theory and Practice of Logic Programming
  (TPLP)</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07462</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hidden Community Detection in Social Networks</dc:title>
 <dc:creator>He, Kun</dc:creator>
 <dc:creator>Li, Yingru</dc:creator>
 <dc:creator>Soundarajan, Sucheta</dc:creator>
 <dc:creator>Hopcroft, John E.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce a new paradigm that is important for community detection in the
realm of network analysis. Networks contain a set of strong, dominant
communities, which interfere with the detection of weak, natural community
structure. When most of the members of the weak communities also belong to
stronger communities, they are extremely hard to be uncovered. We call the weak
communities the hidden community structure.
  We present a novel approach called HICODE (HIdden COmmunity DEtection) that
identifies the hidden community structure as well as the dominant community
structure. By weakening the strength of the dominant structure, one can uncover
the hidden structure beneath. Likewise, by reducing the strength of the hidden
structure, one can more accurately identify the dominant structure. In this
way, HICODE tackles both tasks simultaneously.
  Extensive experiments on real-world networks demonstrate that HICODE
outperforms several state-of-the-art community detection methods in uncovering
both the dominant and the hidden structure. In the Facebook university social
networks, we find multiple non-redundant sets of communities that are strongly
associated with residential hall, year of registration or career position of
the faculties or students, while the state-of-the-art algorithms mainly locate
the dominant ground truth category. In the Due to the difficulty of labeling
all ground truth communities in real-world datasets, HICODE provides a
promising approach to pinpoint the existing latent communities and uncover
communities for which there is no ground truth. Finding this unknown structure
is an extremely important community detection problem.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 4 tables, submitted to KDD 2017</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07462</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07463</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Modeling via Segmentations</dc:title>
 <dc:creator>Wang, Chong</dc:creator>
 <dc:creator>Wang, Yining</dc:creator>
 <dc:creator>Huang, Po-Sen</dc:creator>
 <dc:creator>Mohamed, Abdelrahman</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Segmental structure is a common pattern in many types of sequences such as
phrases in human languages. In this paper, we present a probabilistic model for
sequences via their segmentations. The probability of a segmented sequence is
calculated as the product of the probabilities of all its segments, where each
segment is modeled using existing tools such as recurrent neural networks.
Since the segmentation of a sequence is usually unknown in advance, we sum over
all valid segmentations to obtain the final probability for the sequence. An
efficient dynamic programming algorithm is developed for forward and backward
computations without resorting to any approximation. We demonstrate our
approach on text segmentation and speech recognition tasks. In addition to
quantitative results, we also show that our approach can discover meaningful
segments in their respective application contexts.
</dc:description>
 <dc:description>Comment: recurrent neural networks, dynamic programming, structured prediction</dc:description>
 <dc:date>2017-02-23</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07463</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07464</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Models Under the GAN: Information Leakage from Collaborative Deep
  Learning</dc:title>
 <dc:creator>Hitaj, Briland</dc:creator>
 <dc:creator>Ateniese, Giuseppe</dc:creator>
 <dc:creator>Perez-Cruz, Fernando</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Learning has recently become hugely popular in machine learning,
providing significant improvements in classification accuracy in the presence
of highly-structured and large databases.
  Researchers have also considered privacy implications of deep learning.
Models are typically trained in a centralized manner with all the data being
processed by the same training algorithm. If the data is a collection of users'
private data, including habits, personal pictures, geographical positions,
interests, and more, the centralized server will have access to sensitive
information that could potentially be mishandled. To tackle this problem,
collaborative deep learning models have recently been proposed where parties
locally train their deep learning structures and only share a subset of the
parameters in the attempt to keep their respective training sets private.
Parameters can also be obfuscated via differential privacy (DP) to make
information extraction even more challenging, as proposed by Shokri and
Shmatikov at CCS'15.
  Unfortunately, we show that any privacy-preserving collaborative deep
learning is susceptible to a powerful attack that we devise in this paper. In
particular, we show that a distributed, federated, or decentralized deep
learning approach is fundamentally broken and does not protect the training
sets of honest participants. The attack we developed exploits the real-time
nature of the learning process that allows the adversary to train a Generative
Adversarial Network (GAN) that generates prototypical samples of the targeted
training set that was meant to be private (the samples generated by the GAN are
intended to come from the same distribution as the training data).
Interestingly, we show that record-level DP applied to the shared parameters of
the model, as suggested in previous work, is ineffective (i.e., record-level DP
is not designed to address our attack).
</dc:description>
 <dc:description>Comment: ACM CCS'17, 16 pages, 18 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07470</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Synthesis of Reversible Logic Circuits using Model Checking</dc:title>
 <dc:creator>Ray, Rajarshi</dc:creator>
 <dc:creator>Deka, Arup</dc:creator>
 <dc:creator>Datta, Kamalika</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Synthesis of reversible logic circuits has gained great atten- tion during
the last decade. Various synthesis techniques have been pro- posed, some
generate optimal solutions (in gate count) and are termed as exact, while
others are scalable in the sense that they can handle larger functions but
generate sub-optimal solutions. Although scalable synthe- sis is very much
essential for circuit design, exact synthesis is also of great importance as it
helps in building design library for the synthesis of larger functions. In this
paper, we propose an exact synthesis technique for re- versible circuits using
model checking. We frame the synthesis problem as a model checking instance and
propose an iterative bounded model checking calls for an optimal synthesis.
Experiments on reversible logic benchmarks shows successful synthesis of
optimal circuits. We also illus- trate optimal synthesis of random functions
with as many as 10 variables and up to 10 gates.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07470</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07472</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Non-local Image Diffusion for Image Denoising</dc:title>
 <dc:creator>Qiao, Peng</dc:creator>
 <dc:creator>Dou, Yong</dc:creator>
 <dc:creator>Feng, Wensen</dc:creator>
 <dc:creator>Chen, Yunjin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image diffusion plays a fundamental role for the task of image denoising.
Recently proposed trainable nonlinear reaction diffusion (TNRD) model defines a
simple but very effective framework for image denoising. However, as the TNRD
model is a local model, the diffusion behavior of which is purely controlled by
information of local patches, it is prone to create artifacts in the homogenous
regions and over-smooth highly textured regions, especially in the case of
strong noise levels. Meanwhile, it is widely known that the non-local
self-similarity (NSS) prior stands as an effective image prior for image
denoising, which has been widely exploited in many non-local methods. In this
work, we are highly motivated to embed the NSS prior into the TNRD model to
tackle its weaknesses. In order to preserve the expected property that
end-to-end training is available, we exploit the NSS prior by a set of
non-local filters, and derive our proposed trainable non-local reaction
diffusion (TNLRD) model for image denoising. Together with the local filters
and influence functions, the non-local filters are learned by employing
loss-specific training. The experimental results show that the trained TNLRD
model produces visually plausible recovered images with more textures and less
artifacts, compared to its local versions. Moreover, the trained TNLRD model
can achieve strongly competitive performance to recent state-of-the-art image
denoising methods in terms of peak signal-to-noise ratio (PSNR) and structural
similarity index (SSIM).
</dc:description>
 <dc:description>Comment: under review in a journal</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07474</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simultaneous Feature and Body-Part Learning for Real-Time Robot
  Awareness of Human Behaviors</dc:title>
 <dc:creator>Han, Fei</dc:creator>
 <dc:creator>Yang, Xue</dc:creator>
 <dc:creator>Reardon, Christopher</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robot awareness of human actions is an essential research problem in robotics
with many important real-world applications, including human-robot
collaboration and teaming. Over the past few years, depth sensors have become a
standard device widely used by intelligent robots for 3D perception, which can
also offer human skeletal data in 3D space. Several methods based on skeletal
data were designed to enable robot awareness of human actions with satisfactory
accuracy. However, previous methods treated all body parts and features equally
important, without the capability to identify discriminative body parts and
features. In this paper, we propose a novel simultaneous Feature And Body-part
Learning (FABL) approach that simultaneously identifies discriminative body
parts and features, and efficiently integrates all available information
together to enable real-time robot awareness of human behaviors. We formulate
FABL as a regression-like optimization problem with structured
sparsity-inducing norms to model interrelationships of body parts and features.
We also develop an optimization algorithm to solve the formulated problem,
which possesses a theoretical guarantee to find the optimal solution. To
evaluate FABL, three experiments were performed using public benchmark
datasets, including the MSR Action3D and CAD-60 datasets, as well as a Baxter
robot in practical assistive living applications. Experimental results show
that our FABL approach obtains a high recognition accuracy with a processing
speed of the order-of-magnitude of 10e4 Hz, which makes FABL a promising method
to enable real-time robot awareness of human behaviors in practical robotics
applications.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, accepted by ICRA'17</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07475</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence-based Multimodal Apprenticeship Learning For Robot Perception
  and Decision Making</dc:title>
 <dc:creator>Han, Fei</dc:creator>
 <dc:creator>Yang, Xue</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Zhang, Hao</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Apprenticeship learning has recently attracted a wide attention due to its
capability of allowing robots to learn physical tasks directly from
demonstrations provided by human experts. Most previous techniques assumed that
the state space is known a priori or employed simple state representations that
usually suffer from perceptual aliasing. Different from previous research, we
propose a novel approach named Sequence-based Multimodal Apprenticeship
Learning (SMAL), which is capable to simultaneously fusing temporal information
and multimodal data, and to integrate robot perception with decision making. To
evaluate the SMAL approach, experiments are performed using both simulations
and real-world robots in the challenging search and rescue scenarios. The
empirical study has validated that our SMAL approach can effectively learn
plans for robots to make decisions using sequence of multimodal observations.
Experimental results have also showed that SMAL outperforms the baseline
methods using individual images.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, accepted by ICRA'17</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07476</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Renyi Differential Privacy</dc:title>
 <dc:creator>Mironov, Ilya</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose a natural relaxation of differential privacy based on the Renyi
divergence. Closely related notions have appeared in several recent papers that
analyzed composition of differentially private mechanisms. We argue that the
useful analytical tool can be used as a privacy definition, compactly and
accurately representing guarantees on the tails of the privacy loss.
  We demonstrate that the new definition shares many important properties with
the standard definition of differential privacy, while additionally allowing
tighter analysis of composite heterogeneous mechanisms.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07476</dc:identifier>
 <dc:identifier>Proceedings of IEEE 30th Computer Security Foundations Symposium
  CSF 2017, pages 263-275, IEEE, Aug 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07478</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic equivalence for performance analysis of concurrent systems in
  dtsiPBC</dc:title>
 <dc:creator>Tarasyuk, Igor V.</dc:creator>
 <dc:creator>Maci&#xe0;, Hermenegilda</dc:creator>
 <dc:creator>Valero, Valent&#xed;n</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>60J10, 60J20, 60K15, 68Q55, 68Q60, 68Q85</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  We propose an extension with immediate multiactions of discrete time
stochastic Petri Box Calculus (dtsPBC), presented by I.V. Tarasyuk. The
resulting algebra dtsiPBC is a discrete time analogue of stochastic Petri Box
Calculus (sPBC) with immediate multiactions, designed by H. Maci\`a, V. Valero
et al. within a continuous time domain. The step operational semantics is
constructed via labeled probabilistic transition systems. The denotational
semantics is based on labeled discrete time stochastic Petri nets with
immediate transitions. To evaluate performance, the corresponding semi-Markov
chains are analyzed. We define step stochastic bisimulation equivalence of
expressions that is applied to reduce their transition systems and underlying
semi-Markov chains while preserving the functionality and performance
characteristics. We explain how this equivalence can be used to simplify
performance analysis of the algebraic processes. In a case study, a method of
modeling, performance evaluation and behaviour reduction for concurrent systems
is outlined and applied to the shared memory system.
</dc:description>
 <dc:description>Comment: Prepared for submission to Discrete Mathematics and Theoretical
  Computer Science</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07480</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automation in Human-Machine Networks: How Increasing Machine Agency
  Affects Human Agency</dc:title>
 <dc:creator>F&#xf8;lstad, Asbj&#xf8;rn</dc:creator>
 <dc:creator>Engen, Vegard</dc:creator>
 <dc:creator>Haugstveit, Ida Maria</dc:creator>
 <dc:creator>Pickering, Brian</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Efficient human-machine networks require productive interaction between human
and machine actors. In this study, we address how a strengthening of machine
agency, for example through increasing levels of automation, affect the human
actors of the networks. Findings from case studies within air traffic
management, crisis management, and crowd evacuation are presented, exemplifying
how automation may strengthen the agency of human actors in the network through
responsibility sharing and task allocation, and serve as a needed prerequisite
of innovation and change.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07480</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07481</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Patent Classifications: Portfolio and Statistical Analysis, and
  the Comparison of Strengths and Weaknesses</dc:title>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:creator>Kogler, Dieter Franz</dc:creator>
 <dc:creator>Yan, Bowen</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The Cooperative Patent Classifications (CPC) jointly developed by the
European and US Patent Offices provide a new basis for mapping and portfolio
analysis. This update provides an occasion for rethinking the parameter
choices. The new maps are significantly different from previous ones, although
this may not always be obvious on visual inspection. Since these maps are
statistical constructs based on index terms, their quality--as different from
utility--can only be controlled discursively. We provide nested maps online and
a routine for portfolio overlays and further statistical analysis. We add a new
tool for &quot;difference maps&quot; which is illustrated by comparing the portfolios of
patents granted to Novartis and MSD in 2016.
</dc:description>
 <dc:description>Comment: Scientometrics 112(3) (2017) 1573-1591;
  http://link.springer.com/article/10.1007/s11192-017-2449-0</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07482</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speckle Reduction with Trained Nonlinear Diffusion Filtering</dc:title>
 <dc:creator>Feng, Wensen</dc:creator>
 <dc:creator>Chen, Yunjin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Speckle reduction is a prerequisite for many image processing tasks in
synthetic aperture radar (SAR) images, as well as all coherent images. In
recent years, predominant state-of-the-art approaches for despeckling are
usually based on nonlocal methods which mainly concentrate on achieving utmost
image restoration quality, with relatively low computational efficiency.
Therefore, in this study we aim to propose an efficient despeckling model with
both high computational efficiency and high recovery quality. To this end, we
exploit a newly-developed trainable nonlinear reaction diffusion(TNRD)
framework which has proven a simple and effective model for various image
restoration problems. {In the original TNRD applications, the diffusion network
is usually derived based on the direct gradient descent scheme. However, this
approach will encounter some problem for the task of multiplicative noise
reduction exploited in this study. To solve this problem, we employed a new
architecture derived from the proximal gradient descent method.} {Taking into
account the speckle noise statistics, the diffusion process for the despeckling
task is derived. We then retrain all the model parameters in the presence of
speckle noise. Finally, optimized nonlinear diffusion filtering models are
obtained, which are specialized for despeckling with various noise levels.
Experimental results substantiate that the trained filtering models provide
comparable or even better results than state-of-the-art nonlocal approaches.
Meanwhile, our proposed model merely contains convolution of linear filters
with an image, which offers high level parallelism on GPUs. As a consequence,
for images of size $512 \times 512$, our GPU implementation takes less than 0.1
seconds to produce state-of-the-art despeckling performance.}
</dc:description>
 <dc:description>Comment: to appear in Journal of Mathematical Imaging and Vision. Demo codes
  are available from https://1drv.ms/u/s!ApXF85Oq1kvqgcscP8GqUvPE-dF7ig</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07482</dc:identifier>
 <dc:identifier>doi:10.1007/s10851-016-0697-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07484</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Featured Weighted Automata</dc:title>
 <dc:creator>Fahrenberg, Uli</dc:creator>
 <dc:creator>Legay, Axel</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  A featured transition system is a transition system in which the transitions
are annotated with feature expressions: Boolean expressions on a finite number
of given features. Depending on its feature expression, each individual
transition can be enabled when some features are present, and disabled for
other sets of features. The behavior of a featured transition system hence
depends on a given set of features. There are algorithms for featured
transition systems which can check their properties for all sets of features at
once, for example for LTL or CTL properties.
  Here we introduce a model of featured weighted automata which combines
featured transition systems and (semiring-) weighted automata. We show that
methods and techniques from weighted automata extend to featured weighted
automata and devise algorithms to compute quantitative properties of featured
weighted automata for all sets of features at once. We show applications to
minimum reachability and to energy properties.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07486</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep representation learning for human motion prediction and
  classification</dc:title>
 <dc:creator>B&#xfc;tepage, Judith</dc:creator>
 <dc:creator>Black, Michael</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:creator>Kjellstr&#xf6;m, Hedvig</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative models of 3D human motion are often restricted to a small number
of activities and can therefore not generalize well to novel movements or
applications. In this work we propose a deep learning framework for human
motion capture data that learns a generic representation from a large corpus of
motion capture data and generalizes well to new, unseen, motions. Using an
encoding-decoding network that learns to predict future 3D poses from the most
recent past, we extract a feature representation of human motion. Most work on
deep learning for sequence prediction focuses on video and speech. Since
skeletal data has a different structure, we present and evaluate different
network architectures that make different assumptions about time dependencies
and limb correlations. To quantify the learned features, we use the output of
different layers for action classification and visualize the receptive fields
of the network units. Our method outperforms the recent state of the art in
skeletal motion prediction even though these use action specific training data.
Our results show that deep feedforward networks, trained from a generic mocap
database, can successfully be used for feature extraction from human motion
data and that this representation can be used as a foundation for
classification and prediction.
</dc:description>
 <dc:description>Comment: This paper is published at the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR), 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07486</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07489</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SIFM: A network architecture for seamless flow mobility between LTE and
  WiFi networks - Analysis and Testbed Implementation</dc:title>
 <dc:creator>Purohith, Dhathri R.</dc:creator>
 <dc:creator>Sivalingam, Krishna M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper deals with cellular (e.g. LTE) networks that selectively offload
the mobile data traffic onto WiFi (IEEE 802.11) networks to improve network
performance. We propose the Seamless Internetwork Flow Mobility (SIFM)
architecture that provides seamless flow-mobility support using concepts of
Software Defined Networking (SDN). The SDN paradigm decouples the control and
data plane, leading to a centralized network intelligence and state. The SIFM
architecture utilizes this aspect of SDN and moves the mobility decisions to a
centralized Flow Controller (FC). This provides a global network view while
making mobility decisions and also reduces the complexity at the PGW. We
implement and evaluate both basic PMIPv6 and the SIFM architectures by
incorporating salient LTE and WiFi network features in the ns-3 simulator.
Performance experiments validate that seamless mobility is achieved. Also, the
SIFM architecture shows an improved network performance when compared to the
base PMIPv6 architecture. A proof-of-concept prototype of the SIFM architecture
has been implemented on an experimental testbed. The LTE network is emulated by
integrating USRP B210x with the OpenLTE eNodeB and OpenLTE EPC. The WiFi
network is emulated using hostapd and dnsmasq daemons running on Ubuntu 12.04.
An off-the-shelf LG G2 mobile phone running Android 4.2.2 is used as the user
equipment. We demonstrate seamless mobility between the LTE network and the
WiFi network with the help of ICMP ping and a TCP chat application.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07490</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Meta-learning by Parallel Algorithm Competition</dc:title>
 <dc:creator>Elfwing, Stefan</dc:creator>
 <dc:creator>Uchibe, Eiji</dc:creator>
 <dc:creator>Doya, Kenji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The efficiency of reinforcement learning algorithms depends critically on a
few meta-parameters that modulates the learning updates and the trade-off
between exploration and exploitation. The adaptation of the meta-parameters is
an open question in reinforcement learning, which arguably has become more of
an issue recently with the success of deep reinforcement learning in
high-dimensional state spaces. The long learning times in domains such as Atari
2600 video games makes it not feasible to perform comprehensive searches of
appropriate meta-parameter values. We propose the Online Meta-learning by
Parallel Algorithm Competition (OMPAC) method. In the OMPAC method, several
instances of a reinforcement learning algorithm are run in parallel with small
differences in the initial values of the meta-parameters. After a fixed number
of episodes, the instances are selected based on their performance in the task
at hand. Before continuing the learning, Gaussian noise is added to the
meta-parameters with a predefined probability. We validate the OMPAC method by
improving the state-of-the-art results in stochastic SZ-Tetris and in standard
Tetris with a smaller, 10$\times$10, board, by 31% and 84%, respectively, and
by improving the results for deep Sarsa($\lambda$) agents in three Atari 2600
games by 62% or more. The experiments also show the ability of the OMPAC method
to adapt the meta-parameters according to the learning progress in different
tasks.
</dc:description>
 <dc:description>Comment: 15 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:1702.03118</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07491</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R$^3$PUF: A Highly Reliable Memristive Device based Reconfigurable PUF</dc:title>
 <dc:creator>Gao, Yansong</dc:creator>
 <dc:creator>Ranasinghe, Damith C.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We present a memristive device based R$ ^3 $PUF construction achieving highly
desired PUF properties, which are not offered by most current PUF designs: (1)
High reliability, almost 100\% that is crucial for PUF-based cryptographic key
generations, significantly reducing, or even eliminating the expensive overhead
of on-chip error correction logic and the associated helper on-chip data
storage or off-chip storage and transfer. (2) Reconfigurability, while current
PUF designs rarely exhibit such an attractive property. We validate our R$ ^3
$PUF via extensive Monte-Carlo simulations in Cadence based on parameters of
real devices. The R$ ^3 $PUF is simple, cost-effective and easy to manage
compared to other PUF constructions exhibiting high reliability or
reconfigurability. None of previous PUF constructions is able to provide both
desired high reliability and reconfigurability concurrently.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07491</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07492</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robot gains Social Intelligence through Multimodal Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Qureshi, Ahmed Hussain</dc:creator>
 <dc:creator>Nakamura, Yutaka</dc:creator>
 <dc:creator>Yoshikawa, Yuichiro</dc:creator>
 <dc:creator>Ishiguro, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For robots to coexist with humans in a social world like ours, it is crucial
that they possess human-like social interaction skills. Programming a robot to
possess such skills is a challenging task. In this paper, we propose a
Multimodal Deep Q-Network (MDQN) to enable a robot to learn human-like
interaction skills through a trial and error method. This paper aims to develop
a robot that gathers data during its interaction with a human and learns human
interaction behaviour from the high-dimensional sensory information using
end-to-end reinforcement learning. This paper demonstrates that the robot was
able to learn basic interaction skills successfully, after 14 days of
interacting with people.
</dc:description>
 <dc:description>Comment: The paper is published in IEEE-RAS International Conference on
  Humanoid Robots (Humanoids) 2016</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07495</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dirichlet-vMF Mixture Model</dc:title>
 <dc:creator>Li, Shaohua</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This document is about the multi-document Von-Mises-Fisher mixture model with
a Dirichlet prior, referred to as VMFMix. VMFMix is analogous to Latent
Dirichlet Allocation (LDA) in that they can capture the co-occurrence patterns
acorss multiple documents. The difference is that in VMFMix, the topic-word
distribution is defined on a continuous n-dimensional hypersphere. Hence VMFMix
is used to derive topic embeddings, i.e., representative vectors, from multiple
sets of embedding vectors. An efficient Variational Expectation-Maximization
inference algorithm is derived. The performance of VMFMix on two document
classification tasks is reported, with some preliminary analysis.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07498</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Clustered Distributed Storage Against Eavesdroppers</dc:title>
 <dc:creator>Choi, Beongjun</dc:creator>
 <dc:creator>Sohn, Jy-yong</dc:creator>
 <dc:creator>Yoon, Sung Whan</dc:creator>
 <dc:creator>Moon, Jaekyun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers the security issue of practical distributed storage
systems (DSSs) which consist of multiple clusters of storage nodes. Noticing
that actual storage nodes constituting a DSS are distributed in multiple
clusters, two novel eavesdropper models - the node-restricted model and the
cluster-restricted model - are suggested which reflect the clustered nature of
DSSs. In the node-restricted model, an eavesdropper cannot access the
individual nodes, but can eavesdrop incoming/outgoing data for $L_c$
compromised clusters. In the cluster-restricted model, an eavesdropper can
access a total of $l$ individual nodes but the number of accessible clusters is
limited to $L_c$. We provide an upper bound on the securely storable data for
each model, while a specific network coding scheme which achieves the upper
bound is obtained for the node-restricted model, given some mild condition on
the node storage size.
</dc:description>
 <dc:description>Comment: 6 pages, accepted at IEEE ICC 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07499</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cograph Editing: Merging Modules is equivalent to Editing P4's</dc:title>
 <dc:creator>Hellmuth, Marc</dc:creator>
 <dc:creator>Fritz, Adrian</dc:creator>
 <dc:creator>Wieseke, Nicolas</dc:creator>
 <dc:creator>Stadler, Peter F.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The modular decomposition of a graph $G=(V,E)$ does not contain prime modules
if and only if $G$ is a cograph, that is, if no quadruple of vertices induces a
simple connected path $P_4$. The cograph editing problem consists in inserting
into and deleting from $G$ a set $F$ of edges so that $H=(V,E\Delta F)$ is a
cograph and $|F|$ is minimum. This NP-hard combinatorial optimization problem
has recently found applications, e.g., in the context of phylogenetics.
Efficient heuristics are hence of practical importance. The simple
characterization of cographs in terms of their modular decomposition suggests
that instead of editing $G$ one could operate directly on the modular
decomposition. We show here that editing the induced $P_4$s is equivalent to
resolving prime modules by means of a suitable defined merge operation on the
submodules. Moreover, we characterize so-called module-preserving edit sets and
demonstrate that optimal pairwise sequences of module-preserving edit sets
exist for every non-cograph. This eventually leads to an exact algorithm for
the cograph editing problem. In addition, we provide two heuristics with time
complexity $O(|V|^3)$, resp., $O(|V|^2)$.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07501</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterizing Classes of Potential Outliers through Traffic Data Set
  Data Signature 2D nMDS Projection</dc:title>
 <dc:creator>Oquendo, Erlo Robert F.</dc:creator>
 <dc:creator>Clemente, Jhoirene B.</dc:creator>
 <dc:creator>Malinao, Jasmine A.</dc:creator>
 <dc:creator>Adorna, Henry N.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>97K80</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  This paper presents a formal method for characterizing the potential outliers
from the data signature projection of traffic data set using Non-Metric
Multidimensional Scaling (nMDS) visualization. Previous work had only relied on
visual inspection and the subjective nature of this technique may derive false
and invalid potential outliers. The identification of correct potential
outliers had already been an open problem proposed in literature. This is due
to the fact that they pinpoint areas and time frames where traffic
incidents/accidents occur along the North Luzon Expressway (NLEX) in Luzon. In
this paper, potential outliers are classified into (1) absolute potential
outliers; (2) valid potential outliers; and (3) ambiguous potential outliers
through the use of confidence bands and confidence ellipse. A method is also
described to validate cluster membership of identified ambiguous potential
outliers. Using the 2006 NLEX Balintawak Northbound (BLK-NB) data set, we were
able to identify two absolute potential outliers, nine valid potential
outliers, and five ambiguous potential outliers. In a literature where Vector
Fusion was used, 10 potential outliers were identified. Given the results for
the nMDS visualization using the confidence bands and confidence ellipses, all
of these 10 potential outliers were also found and 8 new potential outliers
were also found.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07502</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Yet Another Pseudorandom Number Generator</dc:title>
 <dc:creator>Stoyanov, Borislav</dc:creator>
 <dc:creator>Szczypiorski, Krzysztof</dc:creator>
 <dc:creator>Kordov, Krasimir</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We propose a novel pseudorandom number generator based on R\&quot;ossler attractor
and bent Boolean function. We estimated the output bits properties by number of
statistical tests. The results of the cryptanalysis show that the new
pseudorandom number generation scheme provides a high level of data security.
</dc:description>
 <dc:description>Comment: 5 pages, 7 figures; to be published in International Journal of
  Electronics and Telecommunications, vol.63, no.4</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07507</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Use Generalized Representations, But Do Not Forget Surface Features</dc:title>
 <dc:creator>Moosavi, Nafise Sadat</dc:creator>
 <dc:creator>Strube, Michael</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Only a year ago, all state-of-the-art coreference resolvers were using an
extensive amount of surface features. Recently, there was a paradigm shift
towards using word embeddings and deep neural networks, where the use of
surface features is very limited. In this paper, we show that a simple SVM
model with surface features outperforms more complex neural models for
detecting anaphoric mentions. Our analysis suggests that using generalized
representations and surface features have different strength that should be
both taken into account for improving coreference resolution.
</dc:description>
 <dc:description>Comment: CORBON workshop@EACL 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07507</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07508</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward high-performance online HCCR: a CNN approach with DropDistortion,
  path signature and spatial stochastic max-pooling</dc:title>
 <dc:creator>Lai, Songxuan</dc:creator>
 <dc:creator>Jin, Lianwen</dc:creator>
 <dc:creator>Yang, Weixin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an investigation of several techniques that increase the
accuracy of online handwritten Chinese character recognition (HCCR). We propose
a new training strategy named DropDistortion to train a deep convolutional
neural network (DCNN) with distorted samples. DropDistortion gradually lowers
the degree of character distortion during training, which allows the DCNN to
better generalize. Path signature is used to extract effective features for
online characters. Further improvement is achieved by employing spatial
stochastic max-pooling as a method of feature map distortion and model
averaging. Experiments were carried out on three publicly available datasets,
namely CASIA-OLHWDB 1.0, CASIA-OLHWDB 1.1, and the ICDAR2013 online HCCR
competition dataset. The proposed techniques yield state-of-the-art recognition
accuracies of 97.67%, 97.30%, and 97.99%, respectively.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07508</dc:identifier>
 <dc:identifier>doi:10.1016/j.patrec.2017.02.011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07510</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Throughput Probabilistic Shaping with Product Distribution Matching</dc:title>
 <dc:creator>B&#xf6;cherer, Georg</dc:creator>
 <dc:creator>Schulte, Patrick</dc:creator>
 <dc:creator>Steiner, Fabian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Product distribution matching (PDM) is proposed to generate target
distributions over large alphabets by combining the output of several parallel
distribution matchers (DMs) with smaller output alphabets. The parallel
architecture of PDM enables low-complexity and high-throughput implementation.
PDM is used as a shaping device for probabilistic amplitude shaping (PAS). For
64-ASK and a spectral efficiency of 4.5 bits per channel use (bpcu), PDM is as
power efficient as a single full-fledged DM. It is shown how PDM enables PAS
for parallel channels present in multi-carrier systems like digital subscriber
line (DSL) and orthogonal frequency-division multiplexing (OFDM). The key
feature is that PDM shares the DMs for lower bit-levels among different
sub-carriers, which improves the power efficiency significantly. A
representative parallel channel example shows that PAS with PDM is 0.93 dB more
power efficient than conventional uniform signaling and PDM is 0.35 dB more
power efficient than individual per channel DMs.
</dc:description>
 <dc:description>Comment: Including 7 diagrams and 5 figures with simulation results</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07514</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Image Retrieval Based On the Parallelization of the Cluster
  Sampling Algorithm</dc:title>
 <dc:creator>Ali, Hesham Arafat</dc:creator>
 <dc:creator>Attiya, Salah</dc:creator>
 <dc:creator>El-henawy, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we develop parallel cluster sampling algorithms and show that a
multi-chain version is embarrassingly parallel and can be used efficiently for
medical image retrieval among other applications.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07514</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07521</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Software Grand Exposure: SGX Cache Attacks Are Practical</dc:title>
 <dc:creator>Brasser, Ferdinand</dc:creator>
 <dc:creator>M&#xfc;ller, Urs</dc:creator>
 <dc:creator>Dmitrienko, Alexandra</dc:creator>
 <dc:creator>Kostiainen, Kari</dc:creator>
 <dc:creator>Capkun, Srdjan</dc:creator>
 <dc:creator>Sadeghi, Ahmad-Reza</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Side-channel information leakage is a known limitation of SGX. Researchers
have demonstrated that secret-dependent information can be extracted from
enclave execution through page-fault access patterns. Consequently, various
recent research efforts are actively seeking countermeasures to SGX
side-channel attacks. It is widely assumed that SGX may be vulnerable to other
side channels, such as cache access pattern monitoring, as well. However, prior
to our work, the practicality and the extent of such information leakage was
not studied.
  In this paper we demonstrate that cache-based attacks are indeed a serious
threat to the confidentiality of SGX-protected programs. Our goal was to design
an attack that is hard to mitigate using known defenses, and therefore we mount
our attack without interrupting enclave execution. This approach has major
technical challenges, since the existing cache monitoring techniques experience
significant noise if the victim process is not interrupted. We designed and
implemented novel attack techniques to reduce this noise by leveraging the
capabilities of the privileged adversary. Our attacks are able to recover
confidential information from SGX enclaves, which we illustrate in two example
cases: extraction of an entire RSA-2048 key during RSA decryption, and
detection of specific human genome sequences during genomic indexing. We show
that our attacks are more effective than previous cache attacks and harder to
mitigate than previous SGX side-channel attacks.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07536</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Event-Triggered Consensus for Linear Continuous-time Multi-agent Systems
  Based on a Predictor</dc:title>
 <dc:creator>Liu, Xiaoyu</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:creator>Dou, Lihua</dc:creator>
 <dc:creator>Chen, Jie</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, the problem of event-triggered consensus for linear
continuous-time multi-agent systems is investigated. A new event-triggered
consensus protocol based on a predictor is proposed to achieve consensus
without continuous communication among agents. In the proposed consensus
protocol, each agent only needs to monitor its states to determine its
event-triggered instants. When an event is triggered, the agent will update its
consensus protocol and sent its state information to its neighbors. In
addition, the agent will also update its consensus protocol and the predictor
when it receives the state information from its neighbors. A necessary and
sufficient condition that the consensus problem can be solved is derived.
Moreover, it is proved that Zeno behavior does not exist. Finally, a numerical
example is given to illustrate that the protocol proposed in this paper can
make the multi-agent systems achieve consensus through much fewer
event-triggered times.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, 1 table, 29 references</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07539</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tight Bounds for Bandit Combinatorial Optimization</dc:title>
 <dc:creator>Cohen, Alon</dc:creator>
 <dc:creator>Hazan, Tamir</dc:creator>
 <dc:creator>Koren, Tomer</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We revisit the study of optimal regret rates in bandit combinatorial
optimization---a fundamental framework for sequential decision making under
uncertainty that abstracts numerous combinatorial prediction problems. We prove
that the attainable regret in this setting grows as
$\widetilde{\Theta}(k^{3/2}\sqrt{dT})$ where $d$ is the dimension of the
problem and $k$ is a bound over the maximal instantaneous loss, disproving a
conjecture of Audibert, Bubeck, and Lugosi (2013) who argued that the optimal
rate should be of the form $\widetilde{\Theta}(k\sqrt{dT})$. Our bounds apply
to several important instances of the framework, and in particular, imply a
tight bound for the well-studied bandit shortest path problem. By that, we also
resolve an open problem posed by Cesa-Bianchi and Lugosi (2012).
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07543</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Knowledge Graphs Based on Transitivity and Antisymmetry of
  Rules</dc:title>
 <dc:creator>Wang, Mengya</dc:creator>
 <dc:creator>Zhuo, Hankui</dc:creator>
 <dc:creator>Zhu, Huiling</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Representation learning of knowledge graphs encodes entities and relation
types into a continuous low-dimensional vector space, learns embeddings of
entities and relation types. Most existing methods only concentrate on
knowledge triples, ignoring logic rules which contain rich background
knowledge. Although there has been some work aiming at leveraging both
knowledge triples and logic rules, they ignore the transitivity and
antisymmetry of logic rules. In this paper, we propose a novel approach to
learn knowledge representations with entities and ordered relations in
knowledges and logic rules. The key idea is to integrate knowledge triples and
logic rules, and approximately order the relation types in logic rules to
utilize the transitivity and antisymmetry of logic rules. All entries of the
embeddings of relation types are constrained to be non-negative. We translate
the general constrained optimization problem into an unconstrained optimization
problem to solve the non-negative matrix factorization. Experimental results
show that our model significantly outperforms other baselines on knowledge
graph completion task. It indicates that our model is capable of capturing the
transitivity and antisymmetry information, which is significant when learning
embeddings of knowledge graphs.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the authors due to a crucial sign
  error in equations</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07544</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Multiagent Coordination with Distributed Online Open Loop
  Planning</dc:title>
 <dc:creator>Belzner, Lenz</dc:creator>
 <dc:creator>Gabor, Thomas</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose distributed online open loop planning (DOOLP), a general framework
for online multiagent coordination and decision making under uncertainty. DOOLP
is based on online heuristic search in the space defined by a generative model
of the domain dynamics, which is exploited by agents to simulate and evaluate
the consequences of their potential choices.
  We also propose distributed online Thompson sampling (DOTS) as an effective
instantiation of the DOOLP framework. DOTS models sequences of agent choices by
concatenating a number of multiarmed bandits for each agent and uses Thompson
sampling for dealing with action value uncertainty. The Bayesian approach
underlying Thompson sampling allows to effectively model and estimate
uncertainty about (a) own action values and (b) other agents' behavior. This
approach yields a principled and statistically sound solution to the
exploration-exploitation dilemma when exploring large search spaces with
limited resources.
  We implemented DOTS in a smart factory case study with positive empirical
results. We observed effective, robust and scalable planning and coordination
capabilities even when only searching a fraction of the potential search space.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07545</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Energy Beamforming under Per-Antenna Power Constraint</dc:title>
 <dc:creator>Rezaei, Zahra</dc:creator>
 <dc:creator>Yazdian, Ehsan</dc:creator>
 <dc:creator>Tabataba, Foroogh S.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Energy beamforming (EB) is a key technique to significantly enhance the
efficiency of wireless power transfer (WPT). In this paper, we study optimal EB
under per-antenna power constraint (PAC) which is more practical than
conventional sum-power constraint (SPC) at multi antenna energy transmitter
(ET). We consider a broadcast network, where one multi antenna ET with PAC,
transfers wireless energy for energy receivers (ER)s which are randomly placed
within the cell area. First, we consider sum energy maximization problem with
PAC without fairness and provide the optimal solution structure for general
case. This optimal structure implies that similar to SPC, sending one energy
beam is optimal with PAC which means that the rank of transmit covariance
matrix is one. We also derive closed-form solutions for two special cases and
propose two sub-optimal solutions for general case, which are very close to
optimal numerical results. To consider the fairness among the ERs, we further
propose max-min fair problem with PAC, and analyze it for the special case of
two transmit antennas. Simulation results show its advantages in comparison to
the recent works in the literature.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07548</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of video quality losses in the homogenous HEVC video
  transcoding</dc:title>
 <dc:creator>Grajek, Tomasz</dc:creator>
 <dc:creator>Stankowski, Jakub</dc:creator>
 <dc:creator>Karwowski, Damian</dc:creator>
 <dc:creator>Klimaszewski, Krzysztof</dc:creator>
 <dc:creator>Stankiewicz, Olgierd</dc:creator>
 <dc:creator>Wegner, Krzysztof</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The paper presents quantitative analysis of the video quality losses in the
homogenous HEVC video transcoder. With the use of HM15.0 reference software and
a set of test video sequences, cascaded pixel domain video transcoder (CPDT)
concept has been used to gather all the necessary data needed for the analysis.
This experiment was done for wide range of source and target bitrates. The
essential result of the work is extensive evaluation of CPDT, commonly used as
a reference in works on effective video transcoding. Until now no such
extensively performed study have been made available in the literature. Quality
degradation between transcoded video and the video that would be result of
direct compression of the original video at the same bitrate as the transcoded
one have been reported. The dependency between quality degradation caused by
transcoding and the bitrate changes of the transcoded data stream are clearly
presented on graphs.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07552</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Rates for Kernel-Based Expectile Regression</dc:title>
 <dc:creator>Farooq, Muhammad</dc:creator>
 <dc:creator>Steinwart, Ingo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Conditional expectiles are becoming an increasingly important tool in finance
as well as in other areas of applications. We analyse a support vector machine
type approach for estimating conditional expectiles and establish learning
rates that are minimax optimal modulo a logarithmic factor if Gaussian RBF
kernels are used and the desired expectile is smooth in a Besov sense. As a
special case, our learning rates improve the best known rates for kernel-based
least squares regression in this scenario. Key ingredients of our statistical
analysis are a general calibration inequality for the asymmetric least squares
loss, a corresponding variance bound as well as an improved entropy number
bound for Gaussian RBF kernels.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07554</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An analysis of core- and chip-level architectural features in four
  generations of Intel server processors</dc:title>
 <dc:creator>Hofmann, Johannes</dc:creator>
 <dc:creator>Hager, Georg</dc:creator>
 <dc:creator>Wellein, Gerhard</dc:creator>
 <dc:creator>Fey, Dietmar</dc:creator>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This paper presents a survey of architectural features among four generations
of Intel server processors (Sandy Bridge, Ivy Bridge, Haswell, and Broad- well)
with a focus on performance with floating point workloads. Starting on the core
level and going down the memory hierarchy we cover instruction throughput for
floating-point instructions, L1 cache, address generation capabilities, core
clock speed and its limitations, L2 and L3 cache bandwidth and latency, the
impact of Cluster on Die (CoD) and cache snoop modes, and the Uncore clock
speed. Using microbenchmarks we study the influence of these factors on code
performance. This insight can then serve as input for analytic performance
models. We show that the energy efficiency of the LINPACK and HPCG benchmarks
can be improved considerably by tuning the Uncore clock speed without
sacrificing performance, and that the Graph500 benchmark performance may profit
from a suitable choice of cache snoop mode settings.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07554</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07555</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A generalization of crossing families</dc:title>
 <dc:creator>Schnider, Patrick</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  For a set of points in the plane, a \emph{crossing family} is a set of line
segments, each joining two of the points, such that any two line segments
cross. We investigate the following generalization of crossing families: a
\emph{spoke set} is a set of lines drawn through a point set such that each
unbounded region of the induced line arrangement contains at least one point of
the point set. We show that every point set has a spoke set of size
$\sqrt{\frac{n}{8}}$. We also characterize the matchings obtained by selecting
exactly one point in each unbounded region and connecting every such point to
the point in the antipodal unbounded region.
</dc:description>
 <dc:description>Comment: 14 pages, 10 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07560</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RNN Decoding of Linear Block Codes</dc:title>
 <dc:creator>Nachmani, Eliya</dc:creator>
 <dc:creator>Marciano, Elad</dc:creator>
 <dc:creator>Burshtein, David</dc:creator>
 <dc:creator>Be'ery, Yair</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Designing a practical, low complexity, close to optimal, channel decoder for
powerful algebraic codes with short to moderate block length is an open
research problem. Recently it has been shown that a feed-forward neural network
architecture can improve on standard belief propagation decoding, despite the
large example space. In this paper we introduce a recurrent neural network
architecture for decoding linear block codes. Our method shows comparable bit
error rate results compared to the feed-forward neural network with
significantly less parameters. We also demonstrate improved performance over
belief propagation on sparser Tanner graph representations of the codes.
Furthermore, we demonstrate that the RNN decoder can be used to improve the
performance or alternatively reduce the computational complexity of the mRRD
algorithm for low complexity, close to optimal, decoding of short BCH codes.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07577</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compression with the tudocomp Framework</dc:title>
 <dc:creator>Dinklage, Patrick</dc:creator>
 <dc:creator>Fischer, Johannes</dc:creator>
 <dc:creator>K&#xf6;ppl, Dominik</dc:creator>
 <dc:creator>L&#xf6;bel, Marvin</dc:creator>
 <dc:creator>Sadakane, Kunihiko</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a framework facilitating the implementation and comparison of text
compression algorithms. We evaluate its features by a case study on two novel
compression algorithms based on the Lempel-Ziv compression schemes that perform
well on highly repetitive texts.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07578</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple, Fast and Lightweight Parallel Wavelet Tree Construction</dc:title>
 <dc:creator>Fischer, Johannes</dc:creator>
 <dc:creator>Kurpicz, Florian</dc:creator>
 <dc:creator>L&#xf6;bel, Marvin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The wavelet tree (Grossi et al. [SODA, 2003]) and wavelet matrix (Claude et
al. [Inf. Syst., 47:15--32, 2015]) are compact indices for texts over an
alphabet $[0,\sigma)$ that support rank, select and access queries in $O(\lg
\sigma)$ time. We first present new practical sequential and parallel
algorithms for wavelet tree construction. Their unifying characteristics is
that they construct the wavelet tree bottomup}, i.e., they compute the last
level first. We also show that this bottom-up construction can easily be
adapted to wavelet matrices. In practice, our best sequential algorithm is up
to twice as fast as the currently fastest sequential wavelet tree construction
algorithm (Shun [DCC, 2015]), simultaneously saving a factor of 2 in space.
This scales up to 32 cores, where we are about equally fast as the currently
fastest parallel wavelet tree construction algorithm (Labeit et al. [DCC,
2016]), but still use only about 75 % of the space. An additional theoretical
result shows how to adapt any wavelet tree construction algorithm to the
wavelet matrix in the same (asymptotic) time, using only little extra space.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07578</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07588</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Homomorphic Encryption Over the Integers</dc:title>
 <dc:creator>Dyer, James</dc:creator>
 <dc:creator>Dyer, Martin</dc:creator>
 <dc:creator>Xu, Jie</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present novel homomorphic encryption schemes for integer arithmetic,
intended for use in secure single-party computation in the cloud. These schemes
are capable of securely computing only low degree polynomials homomorphically,
but this appears sufficient for most practical applications. In this setting,
our schemes lead to practical key and ciphertext sizes. We present a sequence
of generalisations of our basic schemes, with increasing levels of security,
but decreasing practicality. We have evaluated the first four of these
algorithms by computing a low-degree inner product. The timings of these
computations are extremely favourable. Finally, we use our ideas to derive a
fully homomorphic system, which appears impractical, but can homomorphically
evaluate arbitrary Boolean circuits.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07588</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07589</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization of Schnyder woods to orientable surfaces and applications</dc:title>
 <dc:creator>L&#xe9;v&#xea;que, Benjamin</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Schnyder woods are particularly elegant combinatorial structures with
numerous applications concerning planar triangulations and more generally
3-connected planar maps. We propose a simple generalization of Schnyder woods
from the plane to maps on orientable surfaces of any genus with a special
emphasis on the toroidal case. We provide a natural partition of the set of
Schnyder woods of a given map into distributive lattices depending on the
surface homology. In the toroidal case we show the existence of particular
Schnyder woods with some global properties that are useful for optimal encoding
or graph drawing purpose.
</dc:description>
 <dc:description>Comment: 200 pages, Habilitation manuscript</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07589</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07600</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How hard is it to cross the room? -- Training (Recurrent) Neural
  Networks to steer a UAV</dc:title>
 <dc:creator>Kelchtermans, Klaas</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This work explores the feasibility of steering a drone with a (recurrent)
neural network, based on input from a forward looking camera, in the context of
a high-level navigation task. We set up a generic framework for training a
network to perform navigation tasks based on imitation learning. It can be
applied to both aerial and land vehicles. As a proof of concept we apply it to
a UAV (Unmanned Aerial Vehicle) in a simulated environment, learning to cross a
room containing a number of obstacles. So far only feedforward neural networks
(FNNs) have been used to train UAV control. To cope with more complex tasks, we
propose the use of recurrent neural networks (RNN) instead and successfully
train an LSTM (Long-Short Term Memory) network for controlling UAVs. Vision
based control is a sequential prediction problem, known for its highly
correlated input data. The correlation makes training a network hard,
especially an RNN. To overcome this issue, we investigate an alternative
sampling method during training, namely window-wise truncated backpropagation
through time (WW-TBPTT). Further, end-to-end training requires a lot of data
which often is not available. Therefore, we compare the performance of
retraining only the Fully Connected (FC) and LSTM control layers with networks
which are trained end-to-end. Performing the relatively simple task of crossing
a room already reveals important guidelines and good practices for training
neural control networks. Different visualizations help to explain the behavior
learned.
</dc:description>
 <dc:description>Comment: 12 pages, 30 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07601</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Total Energy Efficiency of Cell-Free Massive MIMO</dc:title>
 <dc:creator>Ngo, Hien Quoc</dc:creator>
 <dc:creator>Tran, Le-Nam</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:creator>Matthaiou, Michail</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the cell-free massive multiple-input multiple-output (MIMO)
downlink, where a very large number of distributed multiple-antenna access
points (APs) serve many single-antenna users in the same time-frequency
resource. A simple (distributed) conjugate beamforming scheme is applied at
each AP via the use of local channel state information (CSI). This CSI is
acquired through time-division duplex operation and the reception of uplink
training signals transmitted by the users. We derive a closed-form expression
for the spectral efficiency taking into account the effects of channel
estimation errors and power control. This closed-form result enables us to
analyze the effects of backhaul power consumption, the number of APs, and the
number of antennas per AP on the total energy efficiency, as well as, to design
an optimal power allocation algorithm. The optimal power allocation algorithm
aims at maximizing the total energy efficiency, subject to a per-user spectral
efficiency constraint and a per-AP power constraint. Compared with the equal
power control, our proposed power allocation scheme can double the total energy
efficiency. Furthermore, we propose AP selections schemes, in which each user
chooses a subset of APs, to reduce the power consumption caused by the backhaul
links. With our proposed AP selection schemes, the total energy efficiency
increases significantly, especially for large numbers of APs. Moreover, under a
requirement of good quality-of-service for all users, cell-free massive MIMO
outperforms the colocated counterpart in terms of energy efficiency.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07605</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compact Self-Stabilizing Leader Election for Arbitrary Networks</dc:title>
 <dc:creator>Blin, L&#xe9;lia</dc:creator>
 <dc:creator>Tixeuil, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present a self-stabilizing leader election algorithm for arbitrary
networks, with space-complexity $O(\max\{\log \Delta, \log \log n\})$ bits per
node in $n$-node networks with maximum degree~$\Delta$. This space complexity
is sub-logarithmic in $n$ as long as $\Delta = n^{o(1)}$. The best
space-complexity known so far for arbitrary networks was $O(\log n)$ bits per
node, and algorithms with sub-logarithmic space-complexities were known for the
ring only. To our knowledge, our algorithm is the first algorithm for
self-stabilizing leader election to break the $\Omega(\log n)$ bound for silent
algorithms in arbitrary networks. Breaking this bound was obtained via the
design of a (non-silent) self-stabilizing algorithm using sophisticated tools
such as solving the distance-2 coloring problem in a silent self-stabilizing
manner, with space-complexity $O(\max\{\log \Delta, \log \log n\})$ bits per
node. Solving this latter coloring problem allows us to implement a
sub-logarithmic encoding of spanning trees --- storing the IDs of the neighbors
requires $\Omega(\log n)$ bits per node, while we encode spanning trees using
$O(\max\{\log \Delta, \log \log n\})$ bits per node. Moreover, we show how to
construct such compactly encoded spanning trees without relying on variables
encoding distances or number of nodes, as these two types of variables would
also require $\Omega(\log n)$ bits per node.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07605</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07611</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic segmentation of agricultural objects in dynamic outdoor
  environments</dc:title>
 <dc:creator>Tabb, Amy</dc:creator>
 <dc:creator>Medeiros, Henry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Segmentation in dynamic outdoor environments can be difficult when the
illumination levels and other aspects of the scene cannot be controlled.
Specifically in agricultural contexts, a background material is often used to
shield a camera's field of view from other rows of crops. In this paper, we
describe a method that uses superpixels to determine low texture regions of the
image that correspond to the background material, and then show how this
information can be integrated with the color distribution of the image to
compute optimal segmentation parameters to segment objects of interest.
Quantitative and qualitative experiments demonstrate the suitability of this
approach for dynamic outdoor environments, specifically for tree reconstruction
and apple flower detection applications.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-10-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07611</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07612</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Localisations of Feedback Sets</dc:title>
 <dc:creator>Hecht, Michael</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The feedback arc (vertex) set problem, shortened FASP (FVSP), is to transform
a given multi digraph $G=(V,E)$ into an acyclic graph by deleting as few arcs
(vertices) as possible. Due to the results of Richard M. Karp in 1972 it is one
of the classic NP-complete problems. An important contribution of this paper is
that the subgraphs $G_{\mathrm{el}}(e)$, $G_{\mathrm{si}}(e)$ of all elementary
cycles or simple cycles running through some arc $e \in E$, can be computed in
$\mathcal{O}\big(|E|^2\big)$ and $\mathcal{O}(|E|^4)$, respectively. We use
this fact and introduce the notion of the essential minor and isolated cycles,
which yield a priori problem size reductions and in the special case of so
called resolvable graphs an exact solution in $\mathcal{O}(|V||E|^3)$. We show
that weighted versions of the FASP and FVSP possess a Bellman decomposition,
which yields exact solutions using a dynamic programming technique in times
$\mathcal{O}\big(2^{m}|E|^4\log(|V|)\big)$ and
$\mathcal{O}\big(2^{n}\Delta(G)^4|V|^4\log(|E|)\big)$, where $m \leq |E|-|V|
+1$, $n \leq (\Delta(G)-1)|V|-|E| +1$, respectively. The parameters $m,n$ can
be computed in $\mathcal{O}(|E|^3)$, $\mathcal{O}(\Delta(G)^3|V|^3)$,
respectively and denote the maximal dimension of the cycle space of all
appearing meta graphs, decoding the intersection behavior of the cycles.
Consequently, $m,n$ equal zero if all meta graphs are trees. Moreover, we
deliver several heuristics and discuss how to control their variation from the
optimum. Summarizing, the presented results allow us to suggest a strategy for
an implementation of a fast and accurate FASP/FVSP-SOLVER.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07617</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DALiuGE: A Graph Execution Framework for Harnessing the Astronomical
  Data Deluge</dc:title>
 <dc:creator>Wu, Chen</dc:creator>
 <dc:creator>Tobar, Rodrigo</dc:creator>
 <dc:creator>Vinsen, Kevin</dc:creator>
 <dc:creator>Wicenec, Andreas</dc:creator>
 <dc:creator>Pallot, Dave</dc:creator>
 <dc:creator>Lao, Baoqiang</dc:creator>
 <dc:creator>Wang, Ruonan</dc:creator>
 <dc:creator>An, Tao</dc:creator>
 <dc:creator>Boulton, Mark</dc:creator>
 <dc:creator>Cooper, Ian</dc:creator>
 <dc:creator>Dodson, Richard</dc:creator>
 <dc:creator>Dolensky, Markus</dc:creator>
 <dc:creator>Mei, Ying</dc:creator>
 <dc:creator>Wang, Feng</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:description>  The Data Activated Liu Graph Engine - DALiuGE - is an execution framework for
processing large astronomical datasets at a scale required by the Square
Kilometre Array Phase 1 (SKA1). It includes an interface for expressing complex
data reduction pipelines consisting of both data sets and algorithmic
components and an implementation run-time to execute such pipelines on
distributed resources. By mapping the logical view of a pipeline to its
physical realisation, DALiuGE separates the concerns of multiple stakeholders,
allowing them to collectively optimise large-scale data processing solutions in
a coherent manner. The execution in DALiuGE is data-activated, where each
individual data item autonomously triggers the processing on itself. Such
decentralisation also makes the execution framework very scalable and flexible,
supporting pipeline sizes ranging from less than ten tasks running on a laptop
to tens of millions of concurrent tasks on the second fastest supercomputer in
the world. DALiuGE has been used in production for reducing interferometry data
sets from the Karl E. Jansky Very Large Array and the Mingantu Ultrawide
Spectral Radioheliograph; and is being developed as the execution framework
prototype for the Science Data Processor (SDP) consortium of the Square
Kilometre Array (SKA) telescope. This paper presents a technical overview of
DALiuGE and discusses case studies from the CHILES and MUSER projects that use
DALiuGE to execute production pipelines. In a companion paper, we provide
in-depth analysis of DALiuGE's scalability to very large numbers of tasks on
two supercomputing facilities.
</dc:description>
 <dc:description>Comment: 31 pages, 12 figures, currently under review by Astronomy and
  Computing</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07619</identifier>
 <datestamp>2018-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and robust curve skeletonization for real-world elongated objects</dc:title>
 <dc:creator>Tabb, Amy</dc:creator>
 <dc:creator>Medeiros, Henry</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We consider the problem of extracting curve skeletons of three-dimensional,
elongated objects given a noisy surface, which has applications in agricultural
contexts such as extracting the branching structure of plants. We describe an
efficient and robust method based on breadth-first search that can determine
curve skeletons in these contexts. Our approach is capable of automatically
detecting junction points as well as spurious segments and loops. All of that
is accomplished with only one user-adjustable parameter. The run time of our
method ranges from hundreds of milliseconds to less than four seconds on large,
challenging datasets, which makes it appropriate for situations where real-time
decision making is needed. Experiments on synthetic models as well as on data
from real world objects, some of which were collected in challenging field
conditions, show that our approach compares favorably to classical thinning
algorithms as well as to recent contributions to the field.
</dc:description>
 <dc:description>Comment: 47 pages; IEEE WACV 2018, main paper and supplementary material</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2018-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07624</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multipath Error Correction in Radio Interferometric Positioning Systems</dc:title>
 <dc:creator>Zhang, Cheng</dc:creator>
 <dc:creator>Qi, Wangdong</dc:creator>
 <dc:creator>Wei, Li</dc:creator>
 <dc:creator>Chang, Jiang</dc:creator>
 <dc:creator>Zhao, Yuexin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The radio interferometric positioning system (RIPS) is an accurate node
localization method featuring a novel phase-based ranging process. Multipath is
the limiting error source for RIPS in ground-deployed scenarios or indoor
applications. There are four distinct channels involved in the ranging process
for RIPS. Multipath reflections affect both the phase and amplitude of the
ranging signal for each channel. By exploiting untapped amplitude information,
we put forward a scheme to estimate each channel's multipath profile, which is
then subsequently used to correct corresponding errors in phase measurements.
Simulations show that such a scheme is very effective in reducing multipath
phase errors, which are essentially brought down to the level of receiver noise
under moderate multipath conditions. It is further demonstrated that ranging
errors in RIPS are also greatly reduced via the proposed scheme.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures</dc:description>
 <dc:date>2017-02-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07627</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Performance of Edge Content Caching for Mobile Video
  Streaming</dc:title>
 <dc:creator>Ma, Ge</dc:creator>
 <dc:creator>Wang, Zhi</dc:creator>
 <dc:creator>Zhang, Miao</dc:creator>
 <dc:creator>Ye, Jiahui</dc:creator>
 <dc:creator>Chen, Minghua</dc:creator>
 <dc:creator>Zhu, Wenwu</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Today's Internet has witnessed an increase in the popularity of mobile video
streaming, which is expected to exceed 3/4 of the global mobile data traffic by
2019. To satisfy the considerable amount of mobile video requests, video
service providers have been pushing their content delivery infrastructure to
edge networks--from regional CDN servers to peer CDN servers (e.g.,
smartrouters in users' homes)--to cache content and serve users with storage
and network resources nearby. Among the edge network content caching paradigms,
Wi-Fi access point caching and cellular base station caching have become two
mainstream solutions. Thus, understanding the effectiveness and performance of
these solutions for large-scale mobile video delivery is important. However,
the characteristics and request patterns of mobile video streaming are unclear
in practical wireless network. In this paper, we use real-world datasets
containing 50 million trace items of nearly 2 million users viewing more than
0.3 million unique videos using mobile devices in a metropolis in China over 2
weeks, not only to understand the request patterns and user behaviors in mobile
video streaming, but also to evaluate the effectiveness of Wi-Fi and
cellular-based edge content caching solutions. To understand performance of
edge content caching for mobile video streaming, we first present temporal and
spatial video request patterns, and we analyze their impacts on caching
performance using frequency-domain and entropy analysis approaches. We then
study the behaviors of mobile video users, including their mobility and
geographical migration behaviors. Using trace-driven experiments, we compare
strategies for edge content caching including LRU and LFU, in terms of
supporting mobile video requests. Moreover, we design an efficient caching
strategy based on the measurement insights and experimentally evaluate its
performance.
</dc:description>
 <dc:description>Comment: 13 pages, 19 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07630</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inertia-Constrained Pixel-by-Pixel Nonnegative Matrix Factorisation: a
  Hyperspectral Unmixing Method Dealing with Intra-class Variability</dc:title>
 <dc:creator>Revel, Charlotte</dc:creator>
 <dc:creator>Deville, Yannick</dc:creator>
 <dc:creator>Achard, V&#xe9;ronique</dc:creator>
 <dc:creator>Briottet, Xavier</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Blind source separation is a common processing tool to analyse the
constitution of pixels of hyperspectral images. Such methods usually suppose
that pure pixel spectra (endmembers) are the same in all the image for each
class of materials. In the framework of remote sensing, such an assumption is
no more valid in the presence of intra-class variabilities due to illumination
conditions, weathering, slight variations of the pure materials, etc... In this
paper, we first describe the results of investigations highlighting intra-class
variability measured in real images. Considering these results, a new
formulation of the linear mixing model is presented leading to two new methods.
Unconstrained Pixel-by-pixel NMF (UP-NMF) is a new blind source separation
method based on the assumption of a linear mixing model, which can deal with
intra-class variability. To overcome UP-NMF limitations an extended method is
proposed, named Inertia-constrained Pixel-by-pixel NMF (IP-NMF). For each
sensed spectrum, these extended versions of NMF extract a corresponding set of
source spectra. A constraint is set to limit the spreading of each source's
estimates in IP-NMF. The methods are tested on a semi-synthetic data set built
with spectra extracted from a real hyperspectral image and then numerically
mixed. We thus demonstrate the interest of our methods for realistic source
variabilities. Finally, IP-NMF is tested on a real data set and it is shown to
yield better performance than state of the art methods.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07634</identifier>
 <datestamp>2017-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Thermal Transients in District Heating Systems</dc:title>
 <dc:creator>Chertkov, Michael</dc:creator>
 <dc:creator>Novitsky, Nikolai N.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:description>  Heat fluxes in a district heating pipeline systems need to be controlled on
the scale from minutes to an hour to adjust to evolving demand. There are two
principal ways to control the heat flux - keep temperature fixed but adjust
velocity of the carrier (typically water) or keep the velocity flow steady but
then adjust temperature at the heat producing source (heat plant). We study the
latter scenario, commonly used for operations in Russia and Nordic countries,
and analyze dynamics of the heat front as it propagates through the system.
Steady velocity flows in the district heating pipelines are typically turbulent
and incompressible. Changes in the heat, on either consumption or production
sides, lead to slow transients which last from tens of minutes to hours. We
classify relevant physical phenomena in a single pipe, e.g. turbulent spread of
the turbulent front. We then explain how to describe dynamics of temperature
and heat flux evolution over a network efficiently and illustrate the network
solution on a simple example involving one producer and one consumer of heat
connected by &quot;hot&quot; and &quot;cold&quot; pipes. We conclude the manuscript motivating
future research directions.
</dc:description>
 <dc:description>Comment: 31 pages, 7 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-10-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07637</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Free Information Flow Benefits Truth Seeking</dc:title>
 <dc:creator>Su, Wei</dc:creator>
 <dc:creator>Yu, Yongguang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:description>  How can we approach the truth in a society? It may depend on various factors.
In this paper, using a well-established truth seeking model, we show that the
persistent free information flow will bring us to the truth. Here the free
information flow is modeled as the environmental random noise that could alter
one's cognition. Without the random noise, the model predicts that the truth
can only be captured by the truth seekers who own active perceptive ability of
the truth and their believers, while the other individuals may stick to
falsehood. But under the influence of the random noise, we strictly prove that
even there is only one truth seeker in the group, all individuals will finally
approach the truth.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07637</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07638</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reward-penalty Mechanism for Reverse Supply Chain Network with
  Asymmetric Information and Carbon Emission Constraints</dc:title>
 <dc:creator>Zhang, Xiao-qing</dc:creator>
 <dc:creator>Yuan, Xi-gang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We discuss the government's reward and penalty mechanism in the presence of
asymmetric information and carbon emission constraint when downstream retailers
compete in a reverse supply chain network. Considering five game models which
are different in terms of the coordination structure of the reverse supply
chain network and power structure of the reward-penalty mechanism: (1) the
reverse supply chain network centralized decision-making model; (2) the reverse
supply chain network centralized decision-making model with carbon emission
constraint; (3) the retailers' competition reverse supply chain network
decentralized decision-making model; (4) the retailers' competition reverse
supply chain network decentralized decision-making model with carbon emission
constraint; (5) the retailers' competition reverse supply chain network
decentralized decision-making model with carbon emission constraint and the
government's reward-penalty mechanism. Building the participation-incentive
contract under each model use the principal-agent theory, and solving the model
use the Lagrange multiplier method. We can get the following conclusion: 1)
when the government implements the reward-penalty mechanism for carbon emission
and recycling simultaneously, the recycling rate as well as the buy-back price
offered by the manufacturer are higher than those when the government conducts
reward-penalty mechanism exclusively for carbon emission; 2) when the
government implements carbon emission constraint, both retailers' selling
prices of the new product are higher than those when no carbon emission
constraint is forced; 3) there is no certain relationship between the two
retailers' selling prices of the new product when the government implements the
reward-penalty mechanism only for carbon emission and when it implements the
mechanism for carbon emission as well as recycling.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07643</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to specify Non-functional Requirements to support seamless modeling?
  A Study Design and Preliminary Results</dc:title>
 <dc:creator>Eckhardt, Jonas</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Daniel M&#xe9;ndez</dc:creator>
 <dc:creator>Vogelsang, Andreas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: Seamless model-based development provides integrated chains of
models, covering all software engineering phases. Non-functional requirements
(NFRs), like reusability, further play a vital role in software and systems
engineering, but are often neglected in research and practice. It is still
unclear how to integrate NFRs in a seamless model-based development. Goal: Our
long-term goal is to develop a theory on the specification of NFRs such that
they can be integrated in seamless model-based development. Method: Our overall
study design includes a multi-staged procedure to infer an empirically founded
theory on specifying NFRs to support seamless modeling. In this short paper, we
present the study design and provide a discussion of (i) preliminary results
obtained from a sample, and (ii) current issues related to the design. Results:
Our study already shows significant fields of improvement, e.g., the low
agreement during the classification. However, the results indicate to
interesting points; for example, many of commonly used NFR classes concern
system modeling concepts in a way that shows how blurry the borders between
functional and NFRs are. Conclusions: We conclude so far that our overall study
design seems suitable to obtain the envisioned theory in the long run, but we
could also show current issues that are worth discussing within the empirical
software engineering community. The main goal of this contribution is not to
present and discuss current results only, but to foster discussions on the
issues related to the integration of NFRs in seamless modeling in general and,
in particular, discussions on open methodological issues.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07643</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07647</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Path Planning for Multiple Heterogeneous Unmanned Vehicles with
  Uncertain Service Times</dc:title>
 <dc:creator>Sundar, Kaarthik</dc:creator>
 <dc:creator>Venkatachalam, Saravanan</dc:creator>
 <dc:creator>Manyam, Satyanarayana G.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This article presents a framework and develops a formulation to solve a path
planning problem for multiple heterogeneous Unmanned Vehicles (UVs) with
uncertain service times for each vehicle--target pair. The vehicles incur a
penalty proportional to the duration of their total service time in excess of a
preset constant. The vehicles differ in their motion constraints and are
located at distinct depots at the start of the mission. The vehicles may also
be equipped with disparate sensors. The objective is to find a tour for each
vehicle that starts and ends at its respective depot such that every target is
visited and serviced by some vehicle while minimizing the sum of the total
travel distance and the expected penalty incurred by all the vehicles. We
formulate the problem as a two-stage stochastic program with recourse, present
the theoretical properties of the formulation and advantages of using such a
formulation, as opposed to a deterministic expected value formulation, to solve
the problem. Extensive numerical simulations also corroborate the effectiveness
of the proposed approach.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures, submitted to International Conference on Unmanned
  Aircraft Systems (ICUAS)</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07651</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Data Analysis: A Study on Friend Rating Influence</dc:title>
 <dc:creator>Gupta, Shubhanshu</dc:creator>
 <dc:creator>Desai, Vaibhavi</dc:creator>
 <dc:creator>Thakkar, Harsh</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social Networking accounts for a significant chunk of interest among various
online activities~\cite{smith2009social}. The proclivity of being social,
online, has been ingrained in us so much that we are actively producing content
for the rest of the world to see or take interest in our whereabouts, our
meals, our opinions, photographs etc. Yelp (https://www.yelp.com/), seamlessly,
integrates this very aspect of people in its portal. It engages people to write
reviews about the businesses they have availed the services of, rate them, add
photographs, tags, follow other people and their activities, etc. In this paper
we examine and present the co-relation between a user's rating and the
influence of the people, that the user follows, on the user for a particular
business. The group of people that the user follows is commonly referred as
friends of the user. We also analyze if a user can get influenced, if a
business has a certain number of reviews already present or if the reviews have
been written by elite reviewers (a reviewer who, according to Yelp, has
contributed exceptionally in engaging the community in the form of consistency
in writing reviews, as well as the quality of the reviews). Our analysis,
through correlation and regression techniques, is able to prove that the user's
rating remains unaffected by the number of people a user was friends with nor
does the existing number of reviews and presence of elite reviewers helps in
influencing a user. What shapes a user's rating is the overall experience, that
the user had at the restaurant.
</dc:description>
 <dc:description>Comment: Lighting Talk at WWC Connect India 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07652</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Control of Gene Regulatory Networks with Noisy Measurements and
  Uncertain Inputs</dc:title>
 <dc:creator>Imani, Mahdi</dc:creator>
 <dc:creator>Braga-Neto, Ulisses</dc:creator>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper is concerned with the problem of stochastic control of gene
regulatory networks (GRNs) observed indirectly through noisy measurements and
with uncertainty in the intervention inputs. The partial observability of the
gene states and uncertainty in the intervention process are accounted for by
modeling GRNs using the partially-observed Boolean dynamical system (POBDS)
signal model with noisy gene expression measurements. Obtaining the optimal
infinite-horizon control strategy for this problem is not attainable in
general, and we apply reinforcement learning and Gaussian process techniques to
find a near-optimal solution. The POBDS is first transformed to a
directly-observed Markov Decision Process in a continuous belief space, and the
Gaussian process is used for modeling the cost function over the belief and
intervention spaces. Reinforcement learning then is used to learn the cost
function from the available gene expression data. In addition, we employ
sparsification, which enables the control of large partially-observed GRNs. The
performance of the resulting algorithm is studied through a comprehensive set
of numerical experiments using synthetic gene expression data generated from a
melanoma gene regulatory network.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07656</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Does Quality of Requirements Specifications matter? Combined Results of
  Two Empirical Studies</dc:title>
 <dc:creator>Mund, Jakob</dc:creator>
 <dc:creator>Femmer, Henning</dc:creator>
 <dc:creator>Fern&#xe1;ndez, Daniel M&#xe9;ndez</dc:creator>
 <dc:creator>Eckhardt, Jonas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Background: Requirements Engineering is crucial for project success, and to
this end, many measures for quality assurance of the software requirements
specification (SRS) have been proposed. Goal: However, we still need an
empirical understanding on the extent to which SRS are created and used in
practice, as well as the degree to which the quality of an SRS matters to
subsequent development activities. Method: We studied the relevance of SRS by
relying on survey research and explored the impact of quality defects in SRS by
relying on a controlled experiment. Results: Our results suggest that the
relevance of SRS quality depends both on particular project characteristics and
what is considered as a quality defect; for instance, the domain of safety
critical systems seems to motivate for an intense usage of SRS as a means for
communication whereas defects hampering the pragmatic quality do not seem to be
as relevant as initially thought. Conclusion: Efficient and effective quality
assurance measures must be specific for carefully characterized contexts and
carefully select defect classes.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07657</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capacity of the Aperture-Constrained AWGN Free-Space Communication
  Channel</dc:title>
 <dc:creator>Barton, Richard J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we derive upper and lower bounds as well as a simple
closed-form approximation for the capacity of the continuous-time, bandlimited,
additive white Gaussian noise channel in a three-dimensional free-space
electromagnetic propagation environment subject to constraints on the total
effective antenna aperture area of the link and a total transmitter power
constraint. We assume that the communication range is much larger than the
radius of the sphere containing the antennas at both ends of the link, and we
show that, in general, the capacity can only be achieved by transmitting
multiple spatially-multiplexed data streams simultaneously over the channel.
Furthermore, the lower bound on capacity can be approached asymptotically by
transmitting the data streams between a pair of physically-realizable
distributed antenna arrays at either end of the link. A consequence of this
result is that, in general, communication at close to the maximum achievable
data rate on a deep-space communication link can be achieved in practice if and
only if the communication system utilizes spatial multiplexing over a
distributed MIMO antenna array. Such an approach to deep-space communication
does not appear to be envisioned currently by any of the international space
agencies or any commercial space companies. A second consequence is that the
capacity of a long-range free-space communication link, if properly utilized,
grows asymptotically as a function of the square root of the received SNR
rather than only logarithmically in the received SNR.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07657</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07662</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Network Epidemic Model for Online Community Commissioning Data</dc:title>
 <dc:creator>Lee, Clement</dc:creator>
 <dc:creator>Garbett, Andrew</dc:creator>
 <dc:creator>Wilkinson, Darren J.</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  A statistical model assuming a preferential attachment network, which is
generated by adding nodes sequentially according to a few simple rules, usually
describes real-life networks better than a model assuming, for example, a
Bernoulli random graph, in which any two nodes have the same probability of
being connected, does. Therefore, to study the propogation of &quot;infection&quot;
across a social network, we propose a network epidemic model by combining a
stochastic epidemic model and a preferential attachment model. A simulation
study based on the subsequent Markov Chain Monte Carlo algorithm reveals an
identifiability issue with the model parameters. Finally, the network epidemic
model is applied to a set of online commissioning data.
</dc:description>
 <dc:description>Comment: 28 pages, 9 figures, 2 tables</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07664</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How ConvNets model Non-linear Transformations</dc:title>
 <dc:creator>Pal, Dipan K.</dc:creator>
 <dc:creator>Savvides, Marios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we theoretically address three fundamental problems involving
deep convolutional networks regarding invariance, depth and hierarchy. We
introduce the paradigm of Transformation Networks (TN) which are a direct
generalization of Convolutional Networks (ConvNets). Theoretically, we show
that TNs (and thereby ConvNets) are can be invariant to non-linear
transformations of the input despite pooling over mere local translations. Our
analysis provides clear insights into the increase in invariance with depth in
these networks. Deeper networks are able to model much richer classes of
transformations. We also find that a hierarchical architecture allows the
network to generate invariance much more efficiently than a non-hierarchical
network. Our results provide useful insight into these three fundamental
problems in deep learning using ConvNets.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07665</identifier>
 <datestamp>2017-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truthful Mechanisms for Delivery with Mobile Agents</dc:title>
 <dc:creator>B&#xe4;rtschi, Andreas</dc:creator>
 <dc:creator>Graf, Daniel</dc:creator>
 <dc:creator>Penna, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  We study the game-theoretic task of selecting mobile agents to deliver
multiple items on a network. An instance is given by $m$ messages (physical
objects) which have to be transported between specified source-target pairs in
a weighted undirected graph, and $k$ mobile heterogeneous agents, each being
able to transport one message at a time. Following a recent model by
[B\&quot;artschi et al. 2016], each agent $i$ consumes energy proportional to the
distance it travels in the graph, where the different rates of energy
consumption are given by weight factors $w_i$. We are interested in optimizing
or approximating the total energy consumption over all selected agents.
  Unlike previous research, we assume the weights to be private values known
only to the respective agents. We present three different mechanisms which
select, route and pay the agents in a truthful way that guarantees voluntary
participation of the agents, while approximating the optimum energy consumption
by a constant factor. To this end we analyze a previous structural result and
an approximation algorithm given by [B\&quot;artschi et al. 2017]. Finally, we show
that for some instances in the case of a single package, the sum of the
payments can be bounded in terms of the optimum.
</dc:description>
 <dc:description>Comment: 17 pages. An extended abstract of this paper will be published at the
  Workshop on Algorithmic Approaches for Transportation Modeling, Optimization,
  and Systems 2017, ATMOS'17</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07669</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On problems equivalent to (min,+)-convolution</dc:title>
 <dc:creator>Cygan, Marek</dc:creator>
 <dc:creator>Mucha, Marcin</dc:creator>
 <dc:creator>W&#x119;grzycki, Karol</dc:creator>
 <dc:creator>W&#x142;odarczyk, Micha&#x142;</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:description>  In the recent years, significant progress has been made in explaining
apparent hardness of improving over naive solutions for many fundamental
polynomially solvable problems. This came in the form of conditional lower
bounds - reductions to one of problems assumed to be hard. These include 3SUM,
All-Pairs Shortest Paths, SAT and Orthogonal Vectors, and others.
  In the (min,+)-convolution problem, the goal is to compute a sequence
$(c[i])^{n-1}_{i=0}$, where $c[k] = \min_{i=0,\ldots,k} \{a[i]+b[k-i]\}$, given
sequences $(a[i])^{n-1}_{i=0}$ and $(b[i])_{i=0}^{n-1}$. This can easily be
done in $O(n^2)$ time, but no $O(n^{2-\varepsilon})$ algorithm is known for
$\varepsilon &gt; 0$. In this paper we undertake a systematic study of the
(min,+)-convolution problem as a hardness assumption.
  As the first step, we establish equivalence of this problem to a group of
other problems, including variants of the classic knapsack problem and problems
related to subadditive sequences. The (min,+)-convolution has been used as a
building block in algorithms for many problems, notably problems in
stringology. It has also already appeared as an ad hoc hardness assumption. We
investigate some of these connections and provide new reductions and other
results.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07669</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07670</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Insense: Incoherent Sensor Selection for Sparse Signals</dc:title>
 <dc:creator>Aghazadeh, Amirali</dc:creator>
 <dc:creator>Golbabaee, Mohammad</dc:creator>
 <dc:creator>Lan, Andrew S.</dc:creator>
 <dc:creator>Baraniuk, Richard G.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Sensor selection refers to the problem of intelligently selecting a small
subset of a collection of available sensors to reduce the sensing cost while
preserving signal acquisition performance. The majority of sensor selection
algorithms find the subset of sensors that best recovers an arbitrary signal
from a number of linear measurements that is larger than the dimension of the
signal. In this paper, we develop a new sensor selection algorithm for sparse
(or near sparse) signals that finds a subset of sensors that best recovers such
signals from a number of measurements that is much smaller than the dimension
of the signal. Existing sensor selection algorithms cannot be applied in such
situations. Our proposed Incoherent Sensor Selection (Insense) algorithm
minimizes a coherence-based cost function that is adapted from recent results
in sparse recovery theory. Using six datasets, including two real-world
datasets on microbial diagnostics and structural health monitoring, we
demonstrate the superior performance of Insense for sparse-signal sensor
selection.
</dc:description>
 <dc:date>2017-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07673</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modulation and Multiple Access for 5G Networks</dc:title>
 <dc:creator>Cai, Yunlong</dc:creator>
 <dc:creator>Qin, Zhijin</dc:creator>
 <dc:creator>Cui, Fangyu</dc:creator>
 <dc:creator>Li, Geoffrey Ye</dc:creator>
 <dc:creator>McCann, Julie A.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Fifth generation (5G) wireless networks face various challenges in order to
support large-scale heterogeneous traffic and users, therefore new modulation
and multiple access (MA) schemes are being developed to meet the changing
demands. As this research space is ever increasing, it becomes more important
to analyze the various approaches, therefore in this article we present a
comprehensive overview of the most promising modulation and MA schemes for 5G
networks. We first introduce the different types of modulation that indicate
their potential for orthogonal multiple access (OMA) schemes and compare their
performance in terms of spectral efficiency, out-of-band leakage, and bit-error
rate. We then pay close attention to various types of non-orthogonal multiple
access (NOMA) candidates, including power-domain NOMA, code-domain NOMA, and
NOMA multiplexing in multiple domains. From this exploration we can identify
the opportunities and challenges that will have significant impact on the
design of modulation and MA for 5G networks.
</dc:description>
 <dc:date>2017-02-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07673</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07679</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A recommender system to restore images with impulse noise</dc:title>
 <dc:creator>Nava-Tudela, Alfredo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We build a collaborative filtering recommender system to restore images with
impulse noise for which the noisy pixels have been previously identified. We
define this recommender system in terms of a new color image representation
using three matrices that depend on the noise-free pixels of the image to
restore, and two parameters: $k$, the number of features; and $\lambda$, the
regularization factor. We perform experiments on a well known image database to
test our algorithm and we provide image quality statistics for the results
obtained. We discuss the roles of bias and variance in the performance of our
algorithm as determined by the values of $k$ and $\lambda$, and provide
guidance on how to choose the values of these parameters. Finally, we discuss
the possibility of using our collaborative filtering recommender system to
perform image inpainting and super-resolution.
</dc:description>
 <dc:description>Comment: 22 pages, 34 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07679</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07680</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consistent Alignment of Word Embedding Models</dc:title>
 <dc:creator>Sahin, Cem Safak</dc:creator>
 <dc:creator>Caceres, Rajmonda S.</dc:creator>
 <dc:creator>Oselio, Brandon</dc:creator>
 <dc:creator>Campbell, William M.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Word embedding models offer continuous vector representations that can
capture rich contextual semantics based on their word co-occurrence patterns.
While these word vectors can provide very effective features used in many NLP
tasks such as clustering similar words and inferring learning relationships,
many challenges and open research questions remain. In this paper, we propose a
solution that aligns variations of the same model (or different models) in a
joint low-dimensional latent space leveraging carefully generated synthetic
data points. This generative process is inspired by the observation that a
variety of linguistic relationships is captured by simple linear operations in
embedded space. We demonstrate that our approach can lead to substantial
improvements in recovering embeddings of local neighborhoods.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07681</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Aspects of Mobile Ads Do Users Care About? An Empirical Study of
  Mobile In-app Ad Reviews</dc:title>
 <dc:creator>Gui, Jiaping</dc:creator>
 <dc:creator>Nagappan, Meiyappan</dc:creator>
 <dc:creator>Halfond, William G. J.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  In the mobile app ecosystem, developers receive ad revenue by placing ads in
their apps and releasing them for free. While there is evidence that users do
not like ads, we do not know what are the aspects of ads that users dislike nor
if they dislike certain aspects of ads more than others. Therefore, in this
paper, we analyzed the different topics of ad related complaints from users. In
order to do this, we investigated app reviews that users gave for apps in the
app store that were about ads. We manually examined a random sample set of 400
ad reviews to identify ad complaint topics. We found that most ad complaints
were about user interface (UI) related topics and three topics were brought up
the most often: the frequency with which ads were displayed, the timing of when
ads were displayed, and the location of the displayed ads. Our results provide
actionable information to software developers regarding the aspects of ads that
are most likely to be complained about by users in their reviews.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07694</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayes-Optimal Entropy Pursuit for Active Choice-Based Preference
  Learning</dc:title>
 <dc:creator>Pallone, Stephen N.</dc:creator>
 <dc:creator>Frazier, Peter I.</dc:creator>
 <dc:creator>Henderson, Shane G.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We analyze the problem of learning a single user's preferences in an active
learning setting, sequentially and adaptively querying the user over a finite
time horizon. Learning is conducted via choice-based queries, where the user
selects her preferred option among a small subset of offered alternatives.
These queries have been shown to be a robust and efficient way to learn an
individual's preferences. We take a parametric approach and model the user's
preferences through a linear classifier, using a Bayesian prior to encode our
current knowledge of this classifier. The rate at which we learn depends on the
alternatives offered at every time epoch. Under certain noise assumptions, we
show that the Bayes-optimal policy for maximally reducing entropy of the
posterior distribution of this linear classifier is a greedy policy, and that
this policy achieves a linear lower bound when alternatives can be constructed
from the continuum. Further, we analyze a different metric called
misclassification error, proving that the performance of the optimal policy
that minimizes misclassification error is bounded below by a linear function of
differential entropy. Lastly, we numerically compare the greedy entropy
reduction policy with a knowledge gradient policy under a number of scenarios,
examining their performance under both differential entropy and
misclassification error.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07696</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Data Structure for Dynamic Two-Dimensional Reconfiguration</dc:title>
 <dc:creator>Fekete, S&#xe1;ndor P.</dc:creator>
 <dc:creator>Reinhardt, Jan-Marc</dc:creator>
 <dc:creator>Scheffer, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  In the presence of dynamic insertions and deletions into a partially
reconfigurable FPGA, fragmentation is unavoidable. This poses the challenge of
developing efficient approaches to dynamic defragmentation and reallocation.
One key aspect is to develop efficient algorithms and data structures that
exploit the two-dimensional geometry of a chip, instead of just one. We propose
a new method for this task, based on the fractal structure of a quadtree, which
allows dynamic segmentation of the chip area, along with dynamically adjusting
the necessary communication infrastructure. We describe a number of algorithmic
aspects, and present different solutions. We also provide a number of basic
simulations that indicate that the theoretical worst-case bound may be
pessimistic.
</dc:description>
 <dc:description>Comment: 11 pages, 12 figures; full version of extended abstract that appeared
  in ARCS 2016</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07697</identifier>
 <datestamp>2017-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crosscorrelation of Rudin-Shapiro-Like Polynomials</dc:title>
 <dc:creator>Katz, Daniel J.</dc:creator>
 <dc:creator>Lee, Sangman</dc:creator>
 <dc:creator>Trunov, Stanislav A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Complex Variables</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>42A05, 94A55, 11B83</dc:subject>
 <dc:description>  We consider the class of Rudin-Shapiro-like polynomials, whose $L^4$ norms on
the complex unit circle were studied by Borwein and Mossinghoff. The polynomial
$f(z)=f_0+f_1 z + \cdots + f_d z^d$ is identified with the sequence
$(f_0,f_1,\ldots,f_d)$ of its coefficients. From the $L^4$ norm of a
polynomial, one can easily calculate the autocorrelation merit factor of its
associated sequence, and conversely. In this paper, we study the
crosscorrelation properties of pairs of sequences associated to
Rudin-Shapiro-like polynomials. We find an explicit formula for the
crosscorrelation merit factor. A computer search is then used to find pairs of
Rudin-Shapiro-like polynomials whose autocorrelation and crosscorrelation merit
factors are simultaneously high. Pursley and Sarwate proved a bound that limits
how good this combined autocorrelation and crosscorrelation performance can be.
We find infinite families of polynomials whose performance approaches quite
close to this fundamental limit.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07703</identifier>
 <datestamp>2017-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the reliability of typewriter channels</dc:title>
 <dc:creator>Dalai, M.</dc:creator>
 <dc:creator>Polyanskiy, Y.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  New lower and upper bounds on the reliability function of typewriter channels
are given. Our lower bounds improve upon the (multiletter) expurgated bound of
Gallager, furnishing a new and simple counterexample to a conjecture made in
1967 by Shannon, Gallager and Berlekamp on its tightness. The only other known
counterexample is due to Katsman, Tsfasman and Vl\u{a}du\c{t} who used
algebraic-geometric codes on a $q$-ary symmetric channels, $q\geq 49$. Here we
prove, by introducing dependence between codewords of a random ensemble, that
the conjecture is false even for a typewriter channel with $q=4$ inputs. In the
process, we also demonstrate that Lov\'asz's proof of the capacity of the
pentagon was implicitly contained (but unnoticed!) in the works of Jelinek and
Gallager on the expurgated bound done at least ten years before Lov\'asz. In
the opposite direction, new upper bounds on the reliability function are
derived for channels with an odd number of inputs by using an adaptation of
Delsarte's linear programming bound. First we derive a bound based on the
minimum distance, which combines Lov\'asz's construction for bounding the graph
capacity with the McEliece-Rodemich-Rumsey-Welch construction for bounding the
minimum distance of codes in the Hamming space. Then, for the particular case
of cross-over probability $1/2$, we derive an improved bound by also using the
method of Kalai and Linial to study the spectrum distribution of codes.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-10-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07707</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayes, not Na\&quot;ive: Security Bounds on Website Fingerprinting Defenses</dc:title>
 <dc:creator>Cherubin, Giovanni</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Website Fingerprinting (WF) attacks raise major concerns about users'
privacy. They employ Machine Learning (ML) to allow a local passive adversary
to uncover the Web browsing behavior of a user, even if she browses through an
encrypted tunnel (e.g. Tor, VPN). Numerous defenses have been proposed in the
past; however, it is typically difficult to have formal guarantees on their
security, which is most often evaluated empirically against state-of-the-art
attacks. In this paper, we present a practical method to derive security bounds
for any WF defense, which depend on a chosen feature set. This result derives
from reducing WF attacks to an ML classification task, where we can determine
the smallest achievable error (the Bayes error); such error can be estimated in
practice, and is a lower bound for a WF adversary, for any classification
algorithm he may use. Our work has two main consequences: i) it allows
determining the security of WF defenses, in a black-box manner, with respect to
the state-of-the-art feature set and ii) it favors shifting the focus of future
WF research to the identification of optimal feature sets. The generality of
the approach further suggests that the method could be used to define security
bounds for other ML-based attacks.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07707</dc:identifier>
 <dc:identifier>doi:10.1515/popets-2017-0046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07709</identifier>
 <datestamp>2017-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computationally Efficient Robust Estimation of Sparse Functionals</dc:title>
 <dc:creator>Du, Simon S.</dc:creator>
 <dc:creator>Balakrishnan, Sivaraman</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many conventional statistical procedures are extremely sensitive to seemingly
minor deviations from modeling assumptions. This problem is exacerbated in
modern high-dimensional settings, where the problem dimension can grow with and
possibly exceed the sample size. We consider the problem of robust estimation
of sparse functionals, and provide a computationally and statistically
efficient algorithm in the high-dimensional setting. Our theory identifies a
unified set of deterministic conditions under which our algorithm guarantees
accurate recovery. By further establishing that these deterministic conditions
hold with high-probability for a wide range of statistical models, our theory
applies to many problems of considerable interest including sparse mean and
covariance estimation; sparse linear regression; and sparse generalized linear
models.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07713</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multichannel Linear Prediction for Blind Reverberant Audio Source
  Separation</dc:title>
 <dc:creator>Bayram, &#x130;lker</dc:creator>
 <dc:creator>Bulek, Sava&#x15f;kan</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  A class of methods based on multichannel linear prediction (MCLP) can achieve
effective blind dereverberation of a source, when the source is observed with a
microphone array. We propose an inventive use of MCLP as a pre-processing step
for blind source separation with a microphone array. We show theoretically
that, under certain assumptions, such pre-processing reduces the original blind
reverberant source separation problem to a non-reverberant one, which in turn
can be effectively tackled using existing methods. We demonstrate our claims
using real recordings obtained with an eight-microphone circular array in
reverberant environments.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07717</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When confidence and competence collide: Effects on online
  decision-making discussions</dc:title>
 <dc:creator>Fu, Liye</dc:creator>
 <dc:creator>Lee, Lillian</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Group discussions are a way for individuals to exchange ideas and arguments
in order to reach better decisions than they could on their own. One of the
premises of productive discussions is that better solutions will prevail, and
that the idea selection process is mediated by the (relative) competence of the
individuals involved. However, since people may not know their actual
competence on a new task, their behavior is influenced by their self-estimated
competence --- that is, their confidence --- which can be misaligned with their
actual competence.
  Our goal in this work is to understand the effects of confidence-competence
misalignment on the dynamics and outcomes of discussions. To this end, we
design a large-scale natural setting, in the form of an online team-based
geography game, that allows us to disentangle confidence from competence and
thus separate their effects.
  We find that in task-oriented discussions, the more-confident individuals
have a larger impact on the group's decisions even when these individuals are
at the same level of competence as their teammates. Furthermore, this
unjustified role of confidence in the decision-making process often leads teams
to under-perform. We explore this phenomenon by investigating the effects of
confidence on conversational dynamics.
</dc:description>
 <dc:description>Comment: To appear in Proceedings of WWW 2017. Online multiplayer game
  available at http://streetcrowd.us/start</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07733</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of Patient Flow in Multiple Healthcare Units using Process
  and Data Mining Techniques for Model Identification</dc:title>
 <dc:creator>Kovalchuk, Sergey V.</dc:creator>
 <dc:creator>Funkner, Anastasia A.</dc:creator>
 <dc:creator>Metsker, Oleg G.</dc:creator>
 <dc:creator>Yakovlev, Aleksey N.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Introduction: An approach to building a hybrid simulation of patient flow is
introduced with a combination of data-driven methods for automation of model
identification. The approach is described with a conceptual framework and basic
methods for combination of different techniques. The implementation of the
proposed approach for simulation of acute coronary syndrome (ACS) was developed
and used within an experimental study. Methods: Combination of data, text, and
process mining techniques and machine learning approaches for analysis of
electronic health records (EHRs) with discrete-event simulation (DES) and
queueing theory for simulation of patient flow was proposed. The performed
analysis of EHRs for ACS patients enable identification of several classes of
clinical pathways (CPs) which were used to implement a more realistic
simulation of the patient flow. The developed solution was implemented using
Python libraries (SimPy, SciPy, and others). Results: The proposed approach
enables more realistic and detailed simulation of the patient flow within a
group of related departments. Experimental study shows that the improved
simulation of patient length of stay for ACS patient flow obtained from EHRs in
Federal Almazov North-west Medical Research Centre in Saint Petersburg, Russia.
Conclusion: The proposed approach, methods, and solutions provide a conceptual,
methodological, and programming framework for implementation of simulation of
complex and diverse scenarios within a flow of patients for different purposes:
decision making, training, management optimization, and others.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2018-01-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07735</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better Predictors for Issue Lifetime</dc:title>
 <dc:creator>Rees-Jones, Mitch</dc:creator>
 <dc:creator>Martin, Matthew</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Predicting issue lifetime can help software developers, managers, and
stakeholders effectively prioritize work, allocate development resources, and
better understand project timelines. Progress had been made on this prediction
problem, but prior work has reported low precision and high false alarms. The
latest results also use complex models such as random forests that detract from
their readability.
  We solve both issues by using small, readable decision trees (under 20 lines
long) and correlation feature selection to predict issue lifetime, achieving
high precision and low false alarms (medians of 71% and 13% respectively). We
also address the problem of high class imbalance within issue datasets - when
local data fails to train a good model, we show that cross-project data can be
used in place of the local data. In fact, cross-project data works so well that
we argue it should be the default approach for learning predictors for issue
lifetime.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, 5 tables</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07735</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07737</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoding Generalized Reed-Solomon Codes and Its Application to RLCE
  Encryption Schemes</dc:title>
 <dc:creator>Wang, Yongge</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper compares the efficiency of various algorithms for implementing
quantum resistant public key encryption scheme RLCE on 64-bit CPUs. By
optimizing various algorithms for polynomial and matrix operations over finite
fields, we obtained several interesting (or even surprising) results. For
example, it is well known (e.g., Moenck 1976 \cite{moenck1976practical}) that
Karatsuba's algorithm outperforms classical polynomial multiplication algorithm
from the degree 15 and above (practically, Karatsuba's algorithm only
outperforms classical polynomial multiplication algorithm from the degree 35
and above ). Our experiments show that 64-bit optimized Karatsuba's algorithm
will only outperform 64-bit optimized classical polynomial multiplication
algorithm for polynomials of degree 115 and above over finite field
$GF(2^{10})$. The second interesting (surprising) result shows that 64-bit
optimized Chien's search algorithm ourperforms all other 64-bit optimized
polynomial root finding algorithms such as BTA and FFT for polynomials of all
degrees over finite field $GF(2^{10})$. The third interesting (surprising)
result shows that 64-bit optimized Strassen matrix multiplication algorithm
only outperforms 64-bit optimized classical matrix multiplication algorithm for
matrices of dimension 750 and above over finite field $GF(2^{10})$. It should
be noted that existing literatures and practices recommend Strassen matrix
multiplication algorithm for matrices of dimension 40 and above. All our
experiments are done on a 64-bit MacBook Pro with i7 CPU and single thread C
codes. It should be noted that the reported results should be appliable to 64
or larger bits CPU architectures. For 32 or smaller bits CPUs, these results
may not be applicable. The source code and library for the algorithms covered
in this paper are available at http://quantumca.org/.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-07-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07740</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Key Reconciliation with Low-Density Parity-Check Codes for Long-Distance
  Quantum Cryptography</dc:title>
 <dc:creator>Milicevic, Mario</dc:creator>
 <dc:creator>Feng, Chen</dc:creator>
 <dc:creator>Zhang, Lei M.</dc:creator>
 <dc:creator>Gulak, P. Glenn</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The speed at which two remote parties can exchange secret keys over a
fixed-length fiber-optic cable in continuous-variable quantum key distribution
(CV-QKD) is currently limited by the computational complexity of
post-processing algorithms for key reconciliation. Multi-edge low-density
parity-check (LDPC) codes with low code rates and long block lengths were
proposed for CV-QKD, in order to extend the maximum reconciliation distance
between the two remote parties. Key reconciliation over multiple dimensions has
been shown to further improve the error-correction performance of multi-edge
LDPC codes in CV-QKD, thereby increasing both the secret key rate and distance.
However, the computational complexity of LDPC decoding for long block lengths
on the order of 10^6 bits remains a challenge. This work introduces a
quasi-cyclic (QC) code construction for multi-edge LDPC codes that is highly
suitable for hardware-accelerated decoding on a modern graphics processing unit
(GPU). When combined with an 8-dimensional reconciliation scheme, the LDPC
decoder achieves a raw decoding throughput of 1.72Mbit/s and an information
throughput of 7.16Kbit/s using an NVIDIA GeForce GTX 1080 GPU at a maximum
distance of 160km with a secret key rate of 4.10x10^{-7} bits/pulse for a rate
0.02 multi-edge code with block length of 10^6 bits when finite-size effects
are considered. This work extends the previous maximum CV-QKD distance of 100km
to 160km, while delivering between 1.07x and 8.03x higher decoded information
throughput over the upper bound on the secret key rate for a lossy channel. The
GPU-based QC-LDPC decoder achieves a 1.29x improvement in throughput over the
best existing GPU decoder implementation for a rate 1/10 multi-edge LDPC code
with block length of 2^{20} bits. These results show that LDPC decoding is no
longer the computational bottleneck in long-distance CV-QKD.
</dc:description>
 <dc:description>Comment: 23 pages, 22 figures, 4 tables, 97 references</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07745</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Crowdsourcing Cybersecurity: Cyber Attack Detection using Social Media</dc:title>
 <dc:creator>Khandpur, Rupinder Paul</dc:creator>
 <dc:creator>Ji, Taoran</dc:creator>
 <dc:creator>Jan, Steve</dc:creator>
 <dc:creator>Wang, Gang</dc:creator>
 <dc:creator>Lu, Chang-Tien</dc:creator>
 <dc:creator>Ramakrishnan, Naren</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Social media is often viewed as a sensor into various societal events such as
disease outbreaks, protests, and elections. We describe the use of social media
as a crowdsourced sensor to gain insight into ongoing cyber-attacks. Our
approach detects a broad range of cyber-attacks (e.g., distributed denial of
service (DDOS) attacks, data breaches, and account hijacking) in an
unsupervised manner using just a limited fixed set of seed event triggers. A
new query expansion strategy based on convolutional kernels and dependency
parses helps model reporting structure and aids in identifying key event
characteristics. Through a large-scale analysis over Twitter, we demonstrate
that our approach consistently identifies and encodes events, outperforming
existing methods.
</dc:description>
 <dc:description>Comment: 13 single column pages, 5 figures, submitted to KDD 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07745</dc:identifier>
 <dc:identifier>doi:10.1145/3132847.3132866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07748</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Methodology for Oracle Selection of Monitors and Knobs for Configuring
  an HPC System running a Flood Management Application</dc:title>
 <dc:creator>Nikolaou, Panagiota</dc:creator>
 <dc:creator>Sazeides, Yiannakis</dc:creator>
 <dc:creator>Portero, Antoni</dc:creator>
 <dc:creator>Vavrik, Radim</dc:creator>
 <dc:creator>Vondrak, Vit</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper defines a methodology for the oracle selection of the monitors and
knobs to use to configure an HPC system running a scientific application while
satisfying the application's requirements and not violating any system
constraints. This methodology relies on a heuristic correlation analysis
between requirements, monitors and knobs to determine the minimum subset of
monitors to observe and knobs to explore, to determine the optimal system
configuration for the HPC application. At the end of this analysis, we reduce
an 11-dimensional space to a 3-dimensional space for monitors and a
6-dimensional space to a 3-dimensional space for knobs. This reduction shows
the potential and highlights the need for a realistic methodology to help
identify such minimum set of monitors and knobs.
</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07748</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07752</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A supervised approach to time scale detection in dynamic networks</dc:title>
 <dc:creator>Fish, Benjamin</dc:creator>
 <dc:creator>Caceres, Rajmonda S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For any stream of time-stamped edges that form a dynamic network, an
important choice is the aggregation granularity that an analyst uses to bin the
data. Picking such a windowing of the data is often done by hand, or left up to
the technology that is collecting the data. However, the choice can make a big
difference in the properties of the dynamic network. This is the time scale
detection problem. In previous work, this problem is often solved with a
heuristic as an unsupervised task. As an unsupervised problem, it is difficult
to measure how well a given algorithm performs. In addition, we show that the
quality of the windowing is dependent on which task an analyst wants to perform
on the network after windowing. Therefore the time scale detection problem
should not be handled independently from the rest of the analysis of the
network.
  We introduce a framework that tackles both of these issues: By measuring the
performance of the time scale detection algorithm based on how well a given
task is accomplished on the resulting network, we are for the first time able
to directly compare different time scale detection algorithms to each other.
Using this framework, we introduce time scale detection algorithms that take a
supervised approach: they leverage ground truth on training data to find a good
windowing of the test data. We compare the supervised approach to previous
approaches and several baselines on real data.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07752</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07753</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Magick with C, PDL, and PDL::PP -- a guide to compiled add-ons
  for PDL</dc:title>
 <dc:creator>DeForest, C. E.</dc:creator>
 <dc:creator>Glazebrook, K.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This guide is intended to knit together, and extend, the existing PP and C
documentation on PDL internals. It draws heavily from prior work by the authors
of the code. Special thanks go to Christian Soeller, and Tuomas Lukka, who
together with Glazebrook conceived and implemented PDL and PP; and to Chris
Marshall, who has led the PDL development team through several groundbreaking
releases and to new levels of usability.
</dc:description>
 <dc:description>Comment: 42 pages, 1 figure, overview of the PDL::PP description language for
  vectorized calculation</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07759</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unifying local and non-local signal processing with graph CNNs</dc:title>
 <dc:creator>Puy, Gilles</dc:creator>
 <dc:creator>Kitic, Srdan</dc:creator>
 <dc:creator>P&#xe9;rez, Patrick</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper deals with the unification of local and non-local signal
processing on graphs within a single convolutional neural network (CNN)
framework. Building upon recent works on graph CNNs, we propose to use
convolutional layers that take as inputs two variables, a signal and a graph,
allowing the network to adapt to changes in the graph structure. In this
article, we explain how this framework allows us to design a novel method to
perform style transfer.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07772</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video and Accelerometer-Based Motion Analysis for Automated Surgical
  Skills Assessment</dc:title>
 <dc:creator>Zia, Aneeq</dc:creator>
 <dc:creator>Sharma, Yachna</dc:creator>
 <dc:creator>Bettadapura, Vinay</dc:creator>
 <dc:creator>Sarin, Eric L.</dc:creator>
 <dc:creator>Essa, Irfan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Purpose: Basic surgical skills of suturing and knot tying are an essential
part of medical training. Having an automated system for surgical skills
assessment could help save experts time and improve training efficiency. There
have been some recent attempts at automated surgical skills assessment using
either video analysis or acceleration data. In this paper, we present a novel
approach for automated assessment of OSATS based surgical skills and provide an
analysis of different features on multi-modal data (video and accelerometer
data). Methods: We conduct the largest study, to the best of our knowledge, for
basic surgical skills assessment on a dataset that contained video and
accelerometer data for suturing and knot-tying tasks. We introduce &quot;entropy
based&quot; features - Approximate Entropy (ApEn) and Cross-Approximate Entropy
(XApEn), which quantify the amount of predictability and regularity of
fluctuations in time-series data. The proposed features are compared to
existing methods of Sequential Motion Texture (SMT), Discrete Cosine Transform
(DCT) and Discrete Fourier Transform (DFT), for surgical skills assessment.
Results: We report average performance of different features across all
applicable OSATS criteria for suturing and knot tying tasks. Our analysis shows
that the proposed entropy based features out-perform previous state-of-the-art
methods using video data. For accelerometer data, our method performs better
for suturing only. We also show that fusion of video and acceleration features
can improve overall performance with the proposed entropy features achieving
highest accuracy. Conclusions: Automated surgical skills assessment can be
achieved with high accuracy using the proposed entropy features. Such a system
can significantly improve the efficiency of surgical training in medical
schools and teaching hospitals.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07772</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07776</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Higher Structure Identity Principle</dc:title>
 <dc:creator>Tsementzis, Dimitris</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>03G99, 03B15, 03B22, 03C99</dc:subject>
 <dc:description>  We prove a Structure Identity Principle for theories defined on types of
$h$-level 3 by defining a general notion of saturation for a large class of
structures definable in the Univalent Foundations.
</dc:description>
 <dc:description>Comment: 25 pages</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07779</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Stochastic Operator Approach to Model Inadequacy with Applications to
  Contaminant Transport</dc:title>
 <dc:creator>Portone, Teresa</dc:creator>
 <dc:creator>McDougall, Damon</dc:creator>
 <dc:creator>Moser, Robert D.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The mathematical models used to represent physical phenomena are generally
known to be imperfect representations of reality. Model inadequacies arise for
numerous reasons, such as incomplete knowledge of the phenomena or
computational intractability of more accurate models. In such situations it is
impractical or impossible to improve the model, but necessity requires its use
to make predictions. With this in mind, it is important to represent the
uncertainty that a model's inadequacy causes in its predictions, as neglecting
to do so can cause overconfidence in its accuracy. A powerful approach to
addressing model inadequacy leverages the composite nature of physical models
by enriching a flawed embedded closure model with a stochastic error
representation. This work outlines steps in the development of a stochastic
operator as an inadequacy representation by establishing the framework for
inferring an infinite-dimensional operator and by introducing a novel method
for interrogating available high-fidelity models to learn about modeling error.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07780</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Changing Model Behavior at Test-Time Using Reinforcement Learning</dc:title>
 <dc:creator>Odena, Augustus</dc:creator>
 <dc:creator>Lawson, Dieterich</dc:creator>
 <dc:creator>Olah, Christopher</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning models are often used at test-time subject to constraints
and trade-offs not present at training-time. For example, a computer vision
model operating on an embedded device may need to perform real-time inference,
or a translation model operating on a cell phone may wish to bound its average
compute time in order to be power-efficient. In this work we describe a
mixture-of-experts model and show how to change its test-time resource-usage on
a per-input basis using reinforcement learning. We test our method on a small
MNIST-based example.
</dc:description>
 <dc:description>Comment: Submitted to ICLR 2017 Workshop Track</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07784</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying</dc:title>
 <dc:creator>Chatzakou, Despoina</dc:creator>
 <dc:creator>Kourtellis, Nicolas</dc:creator>
 <dc:creator>Blackburn, Jeremy</dc:creator>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:creator>Stringhini, Gianluca</dc:creator>
 <dc:creator>Vakali, Athena</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Over the past few years, online aggression and abusive behaviors have
occurred in many different forms and on a variety of platforms. In extreme
cases, these incidents have evolved into hate, discrimination, and bullying,
and even materialized into real-world threats and attacks against individuals
or groups. In this paper, we study the Gamergate controversy. Started in August
2014 in the online gaming world, it quickly spread across various social
networking platforms, ultimately leading to many incidents of cyberbullying and
cyberaggression. We focus on Twitter, presenting a measurement study of a
dataset of 340k unique users and 1.6M tweets to study the properties of these
users, the content they post, and how they differ from random Twitter users. We
find that users involved in this &quot;Twitter war&quot; tend to have more friends and
followers, are generally more engaged and post tweets with negative sentiment,
less joy, and more hate than random users. We also perform preliminary
measurements on how the Twitter suspension mechanism deals with such abusive
behaviors. While we focus on Gamergate, our methodology to collect and analyze
tweets related to aggressive and bullying activities is of independent
interest.
</dc:description>
 <dc:description>Comment: WWW Cybersafety Workshop 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07784</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07787</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Gated Recurrent Neural Network Incorporating Spatial
  Features for Audio Tagging</dc:title>
 <dc:creator>Xu, Yong</dc:creator>
 <dc:creator>Kong, Qiuqiang</dc:creator>
 <dc:creator>Huang, Qiang</dc:creator>
 <dc:creator>Wang, Wenwu</dc:creator>
 <dc:creator>Plumbley, Mark D.</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Environmental audio tagging is a newly proposed task to predict the presence
or absence of a specific audio event in a chunk. Deep neural network (DNN)
based methods have been successfully adopted for predicting the audio tags in
the domestic audio scene. In this paper, we propose to use a convolutional
neural network (CNN) to extract robust features from mel-filter banks (MFBs),
spectrograms or even raw waveforms for audio tagging. Gated recurrent unit
(GRU) based recurrent neural networks (RNNs) are then cascaded to model the
long-term temporal structure of the audio signal. To complement the input
information, an auxiliary CNN is designed to learn on the spatial features of
stereo recordings. We evaluate our proposed methods on Task 4 (audio tagging)
of the Detection and Classification of Acoustic Scenes and Events 2016 (DCASE
2016) challenge. Compared with our recent DNN-based method, the proposed
structure can reduce the equal error rate (EER) from 0.13 to 0.11 on the
development set. The spatial features can further reduce the EER to 0.10. The
performance of the end-to-end learning on raw waveforms is also comparable.
Finally, on the evaluation set, we get the state-of-the-art performance with
0.12 EER while the performance of the best existing system is 0.15 EER.
</dc:description>
 <dc:description>Comment: Accepted to IJCNN2017, Anchorage, Alaska, USA</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07787</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07790</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Activation Ensembles for Deep Neural Networks</dc:title>
 <dc:creator>Harmon, Mark</dc:creator>
 <dc:creator>Klabjan, Diego</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many activation functions have been proposed in the past, but selecting an
adequate one requires trial and error. We propose a new methodology of
designing activation functions within a neural network at each layer. We call
this technique an &quot;activation ensemble&quot; because it allows the use of multiple
activation functions at each layer. This is done by introducing additional
variables, $\alpha$, at each activation layer of a network to allow for
multiple activation functions to be active at each neuron. By design,
activations with larger $\alpha$ values at a neuron is equivalent to having the
largest magnitude. Hence, those higher magnitude activations are &quot;chosen&quot; by
the network. We implement the activation ensembles on a variety of datasets
using an array of Feed Forward and Convolutional Neural Networks. By using the
activation ensemble, we achieve superior results compared to traditional
techniques. In addition, because of the flexibility of this methodology, we
more deeply explore activation functions and the features that they capture.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07790</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07793</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Residual Convolutional CTC Networks for Automatic Speech Recognition</dc:title>
 <dc:creator>Wang, Yisen</dc:creator>
 <dc:creator>Deng, Xuejiao</dc:creator>
 <dc:creator>Pu, Songbai</dc:creator>
 <dc:creator>Huang, Zhiheng</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Deep learning approaches have been widely used in Automatic Speech
Recognition (ASR) and they have achieved a significant accuracy improvement.
Especially, Convolutional Neural Networks (CNNs) have been revisited in ASR
recently. However, most CNNs used in existing work have less than 10 layers
which may not be deep enough to capture all human speech signal information. In
this paper, we propose a novel deep and wide CNN architecture denoted as
RCNN-CTC, which has residual connections and Connectionist Temporal
Classification (CTC) loss function. RCNN-CTC is an end-to-end system which can
exploit temporal and spectral structures of speech signals simultaneously.
Furthermore, we introduce a CTC-based system combination, which is different
from the conventional frame-wise senone-based one. The basic subsystems adopted
in the combination are different types and thus mutually complementary to each
other. Experimental results show that our proposed single system RCNN-CTC can
achieve the lowest word error rate (WER) on WSJ and Tencent Chat data sets,
compared to several widely used neural network systems in ASR. In addition, the
proposed system combination can offer a further error reduction on these two
data sets, resulting in relative WER reductions of $14.91\%$ and $6.52\%$ on
WSJ dev93 and Tencent Chat data sets respectively.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07798</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rank-to-engage: New Listwise Approaches to Maximize Engagement</dc:title>
 <dc:creator>Jain, Swayambhoo</dc:creator>
 <dc:creator>Soni, Akshay</dc:creator>
 <dc:creator>Laptev, Nikolay</dc:creator>
 <dc:creator>Mehdad, Yashar</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For many internet businesses, presenting a given list of items in an order
that maximizes a certain metric of interest (e.g., click-through-rate, average
engagement time etc.) is crucial. We approach the aforementioned task from a
learning-to-rank perspective which reveals a new problem setup. In traditional
learning-to-rank literature, it is implicitly assumed that during the training
data generation one has access to the \emph{best or desired} order for the
given list of items. In this work, we consider a problem setup where we do not
observe the desired ranking. We present two novel solutions: the first solution
is an extension of already existing listwise learning-to-rank
technique--Listwise maximum likelihood estimation (ListMLE)--while the second
one is a generic machine learning based framework that tackles the problem in
its entire generality. We discuss several challenges associated with this
generic framework, and propose a simple \emph{item-payoff} and
\emph{positional-gain} model that addresses these challenges. We provide
training algorithms, inference procedures, and demonstrate the effectiveness of
the two approaches over traditional ListMLE on synthetic as well as on
real-life setting of ranking news articles for increased dwell time.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07799</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Methods for Recursive Circle Packing</dc:title>
 <dc:creator>Gleixner, Ambros</dc:creator>
 <dc:creator>Maher, Stephen</dc:creator>
 <dc:creator>M&#xfc;ller, Benjamin</dc:creator>
 <dc:creator>Pedroso, Jo&#xe3;o Pedro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  Packing rings into a minimum number of rectangles is an optimization problem
which appears naturally in the logistics operations of the tube industry. It
encompasses two major difficulties, namely the positioning of rings in
rectangles and the recursive packing of rings into other rings. This problem is
known as the Recursive Circle Packing Problem (RCPP). We present the first
exact method for solving RCPP, based on a Dantzig-Wolfe decomposition of a
nonconvex mixed-integer nonlinear programming formulation. The key idea of this
reformulation is to break symmetry on each recursion level by enumerating all
so-called one-level packings, i.e., packings of circles into other circles, and
by dynamically generating packings of circles into rectangles. We propose a
branch-and-price algorithm to solve the reformulation to global optimality.
Extensive computational experiments on a large test set show that our method
not only computes exact dual bounds, but often produces primal solutions better
than computed by heuristics from the literature.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07799</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07800</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Origin of Deep Learning</dc:title>
 <dc:creator>Wang, Haohan</dc:creator>
 <dc:creator>Raj, Bhiksha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper is a review of the evolutionary history of deep learning models.
It covers from the genesis of neural networks when associationism modeling of
the brain is studied, to the models that dominate the last decade of research
in deep learning like convolutional neural networks, deep belief networks, and
recurrent neural networks. In addition to a review of these models, this paper
primarily focuses on the precedents of the models above, examining how the
initial ideas are assembled to construct the early models and how these
preliminary models are developed into their current forms. Many of these
evolutionary paths last more than half a century and have a diversity of
directions. For example, CNN is built on prior knowledge of biological vision
system; DBN is evolved from a trade-off of modeling power and computation
complexity of graphical models and many nowadays models are neural counterparts
of ancient linear models. This paper reviews these evolutionary paths and
offers a concise thought flow of how these models are developed, and aims to
provide a thorough background for deep learning. More importantly, along with
the path, this paper summarizes the gist behind these milestones and proposes
many directions to guide the future research of deep learning.
</dc:description>
 <dc:description>Comment: 70 pages, 200 references</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07802</identifier>
 <datestamp>2017-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Data Scheduling for Data Centers with Multiple Levels of Data
  Locality</dc:title>
 <dc:creator>Yekkehkhany, Ali</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Data locality is a fundamental issue for data-parallel applications.
Considering MapReduce in Hadoop, the map task scheduling part requires an
efficient algorithm which takes data locality into consideration; otherwise,
the system may become unstable under loads inside the system's capacity region
and jobs may experience longer completion times which are not of interest. The
data chunk needed for any map task can be in memory, on a local disk, in a
local rack, in the same cluster or even in another data center. Hence, unless
there has been much work on improving the speed of data center networks,
different levels of service rates still exist for a task depending on where its
data chunk is saved and from which server it receives service. Most of the
theoretical work on load balancing is for systems with two levels of data
locality including the Pandas algorithm by Xie et al. and the JSQ-MW algorithm
by Wang et al., where the former is both throughput and heavy-traffic optimal,
while the latter is only throughput optimal, but heavy-traffic optimal in only
a special traffic load. We show that an extension of the JSQ-MW algorithm for a
system with thee levels of data locality is throughput optimal, but not
heavy-traffic optimal for all loads, only for a special traffic scenario.
Furthermore, we show that the Pandas algorithm is not even throughput optimal
for a system with three levels of data locality. We then propose a novel
algorithm, Balanced-Pandas, which is both throughput and heavy-traffic optimal.
To the best of our knowledge, this is the first theoretical work on load
balancing for a system with more than two levels of data locality. This is more
challenging than two levels of data locality as a dilemma between performance
and throughput emerges.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07803</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonparanormal Information Estimation</dc:title>
 <dc:creator>Singh, Shashank</dc:creator>
 <dc:creator>P&#xf8;czos, Barnab&#xe1;s</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of using i.i.d. samples from an unknown multivariate
probability distribution $p$ to estimate the mutual information of $p$. This
problem has recently received attention in two settings: (1) where $p$ is
assumed to be Gaussian and (2) where $p$ is assumed only to lie in a large
nonparametric smoothness class. Estimators proposed for the Gaussian case
converge in high dimensions when the Gaussian assumption holds, but are
brittle, failing dramatically when $p$ is not Gaussian. Estimators proposed for
the nonparametric case fail to converge with realistic sample sizes except in
very low dimensions. As a result, there is a lack of robust mutual information
estimators for many realistic data. To address this, we propose estimators for
mutual information when $p$ is assumed to be a nonparanormal (a.k.a., Gaussian
copula) model, a semiparametric compromise between Gaussian and nonparametric
extremes. Using theoretical bounds and experiments, we show these estimators
strike a practical balance between robustness and scaling with dimensionality.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07803</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07805</identifier>
 <datestamp>2017-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term
  Dependencies</dc:title>
 <dc:creator>DiPietro, Robert</dc:creator>
 <dc:creator>Rupprecht, Christian</dc:creator>
 <dc:creator>Navab, Nassir</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent neural networks (RNNs) have achieved state-of-the-art performance
on many diverse tasks, from machine translation to surgical activity
recognition, yet training RNNs to capture long-term dependencies remains
difficult. To date, the vast majority of successful RNN architectures alleviate
this problem by facilitating long-term gradient flow using nearly-additive
connections between adjacent states, as originally introduced in long
short-term memory (LSTM). In this paper, we investigate a different approach
for encouraging gradient flow that is based on NARX RNNs, which generalize
typical RNNs by allowing direct connections from the distant past.
Analytically, we 1) generalize previous gradient decompositions for typical
RNNs to general NARX RNNs and 2) formally connect gradient flow to edges along
paths. We then introduce an example architecture that is based on these ideas,
and we demonstrate that this architecture matches or exceeds LSTM performance
on 5 diverse tasks. Finally we describe many avenues for future work, including
the exploration of other NARX RNN architectures, the possible combination of
mechanisms from LSTM and NARX RNNs, and the adoption of recent LSTM-based
advances to NARX RNN architectures.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07805</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07806</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Does Diversity of User Preferences Improve Outcomes in Selfish
  Routing?</dc:title>
 <dc:creator>Cole, Richard</dc:creator>
 <dc:creator>Lianeas, Thanasis</dc:creator>
 <dc:creator>Nikolova, Evdokia</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We seek to understand when heterogeneity in user preferences yields improved
outcomes in terms of overall cost. That this might be hoped for is based on the
common belief that diversity is advantageous in many settings. We investigate
this in the context of routing. Our main result is a sharp characterization of
the network settings in which diversity always helps, versus those in which it
is sometimes harmful. Specifically, we consider routing games, where diversity
arises in the way that users trade-off two criteria (such as time and money,
or, in the case of stochastic delays, expectation and variance of delay). Our
main contributions are the following: 1) A participant-oriented measure of cost
in the presence of user diversity, together with the identification of the
natural benchmark: the same cost measure for an appropriately defined average
of the diversity. 2) A full characterization of those network topologies for
which diversity always helps, for all latency functions and demands. For
single-commodity routings, these are series-parallel graphs, while for
multi-commodity routings, they are the newly-defined &quot;block-matching&quot; networks.
The latter comprise a suitable interweaving of multiple series-parallel graphs
each connecting a distinct source-sink pair. While the result for the
single-commodity case may seem intuitive in light of the well-known Braess
paradox, the two problems are different: there are instances where diversity
helps although the Braess paradox occurs, and vice-versa. But the main
technical challenge is to establish the &quot;only if&quot; direction of the result for
multi-commodity networks. This follows by constructing an instance where
diversity hurts, and showing how to embed it in any network which is not
block-matching, by carefully exploiting the way the simple source-sink paths of
the commodities intersect in the &quot;non-block-matching&quot; portion of the network.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07806</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07810</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decomposition of Forecast Error in Prediction Markets</dc:title>
 <dc:creator>Dud&#xed;k, Miroslav</dc:creator>
 <dc:creator>Lahaie, S&#xe9;bastien</dc:creator>
 <dc:creator>Rogers, Ryan</dc:creator>
 <dc:creator>Vaughan, Jennifer Wortman</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We introduce and analyze sources of error in prediction market forecasts in
order to characterize and bound the difference between a security's price and
its ground truth value. We consider cost-function-based prediction markets in
which an automated market maker adjusts security prices according to the
history of trade. We decompose the forecasting error into four components:
\emph{sampling error}, occurring because traders only possess noisy estimates
of ground truth; \emph{risk-aversion effect}, arising because traders reveal
beliefs only through self-interested trade; \emph{market-maker bias}, resulting
from the use of a particular market maker (i.e., cost function) to facilitate
trade; and finally, \emph{convergence error}, arising because, at any point in
time, market prices may still be in flux. Our goal is to understand the
tradeoffs between these error components, and how they are influenced by design
decisions such as the functional form of the cost function and the amount of
liquidity in the market. We specifically consider a model in which traders have
exponential utility and exponential-family beliefs drawn with an independent
noise relative to ground truth. In this setting, sampling error and
risk-aversion effect vanish as the number of traders grows, but there is a
tradeoff between the other two components: decreasing the market maker's
liquidity results in smaller market-maker bias, but may also slow down
convergence. We provide both upper and lower bounds on market-maker bias and
convergence error, and demonstrate via numerical simulations that these bounds
are tight. Our results yield new insights into the question of how to set the
market's liquidity parameter, and into the extent to which markets that enforce
coherent prices across securities produce better predictions than markets that
price securities independently.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07811</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Neural Networks for Efficient Inference</dc:title>
 <dc:creator>Bolukbasi, Tolga</dc:creator>
 <dc:creator>Wang, Joseph</dc:creator>
 <dc:creator>Dekel, Ofer</dc:creator>
 <dc:creator>Saligrama, Venkatesh</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an approach to adaptively utilize deep neural networks in order to
reduce the evaluation time on new examples without loss of accuracy. Rather
than attempting to redesign or approximate existing networks, we propose two
schemes that adaptively utilize networks. We first pose an adaptive network
evaluation scheme, where we learn a system to adaptively choose the components
of a deep network to be evaluated for each example. By allowing examples
correctly classified using early layers of the system to exit, we avoid the
computational time associated with full evaluation of the network. We extend
this to learn a network selection system that adaptively selects the network to
be evaluated for each example. We show that computational time can be
dramatically reduced by exploiting the fact that many examples can be correctly
classified using relatively efficient networks and that complex,
computationally costly networks are only necessary for a small fraction of
examples. We pose a global objective for learning an adaptive early exit or
network selection policy and solve it by reducing the policy learning problem
to a layer-by-layer weighted binary classification problem. Empirically, these
approaches yield dramatic reductions in computational cost, with up to a 2.8x
speedup on state-of-the-art networks from the ImageNet image recognition
challenge with minimal (&lt;1%) loss of top5 accuracy.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-09-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07811</dc:identifier>
 <dc:identifier>Proceedings of the 34th International Conference on Machine
  Learning, PMLR 70:527-536, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07815</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Subquadratic Algorithms for the Diameter and the Sum of Pairwise
  Distances in Planar Graphs</dc:title>
 <dc:creator>Cabello, Sergio</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We show how to compute for $n$-vertex planar graphs in $O(n^{11/6}{\rm
polylog}(n))$ expected time the diameter and the sum of the pairwise distances.
The algorithms work for directed graphs with real weights and no negative
cycles. In $O(n^{15/8}{\rm polylog}(n))$ expected time we can also compute the
number of pairs of vertices at distance smaller than a given threshold. These
are the first algorithms for these problems using time $O(n^c)$ for some
constant $c&lt;2$, even when restricted to undirected, unweighted planar graphs.
</dc:description>
 <dc:description>Comment: Preliminary version at SODA 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07817</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Sequence Classification using Sequential Output Statistics</dc:title>
 <dc:creator>Liu, Yu</dc:creator>
 <dc:creator>Chen, Jianshu</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider learning a sequence classifier without labeled data by using
sequential output statistics. The problem is highly valuable since obtaining
labels in training data is often costly, while the sequential output statistics
(e.g., language models) could be obtained independently of input data and thus
with low or no cost. To address the problem, we propose an unsupervised
learning cost function and study its properties. We show that, compared to
earlier works, it is less inclined to be stuck in trivial solutions and avoids
the need for a strong generative model. Although it is harder to optimize in
its functional form, a stochastic primal-dual gradient method is developed to
effectively solve the problem. Experiment results on real-world datasets
demonstrate that the new unsupervised learning method gives drastically lower
errors than other baseline methods. Specifically, it reaches test errors about
twice of those obtained by fully supervised learning.
</dc:description>
 <dc:description>Comment: All authors contributed equally to the paper. 17 pages, 7 figures and
  2 tables</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07823</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimizing the Coherence of Composite Networks</dc:title>
 <dc:creator>Mackin, Erika</dc:creator>
 <dc:creator>Patterson, Stacy</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider how to connect a set of disjoint networks to optimize the
performance of the resulting composite network. We quantify this performance by
the coherence of the composite network, which is defined by an $H_2$ norm of
the system. Two dynamics are considered: noisy consensus dynamics with and
without stubborn agents. For noisy consensus dynamics without stubborn agents,
we derive analytical expressions for the coherence of composite networks in
terms of the coherence of the individual networks and the structure of their
interconnections. We also identify optimal interconnection topologies and give
bounds on coherence for general composite graphs. For noisy consensus dynamics
with stubborn agents, we develop a non-combinatorial algorithm that identifies
connecting edges such that the composite network coherence closely approximates
the performance of the optimal composite graph.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, Theorem 3 from previous version removed due
  logical error in proof</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07825</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Voice: Real-time Neural Text-to-Speech</dc:title>
 <dc:creator>Arik, Sercan O.</dc:creator>
 <dc:creator>Chrzanowski, Mike</dc:creator>
 <dc:creator>Coates, Adam</dc:creator>
 <dc:creator>Diamos, Gregory</dc:creator>
 <dc:creator>Gibiansky, Andrew</dc:creator>
 <dc:creator>Kang, Yongguo</dc:creator>
 <dc:creator>Li, Xian</dc:creator>
 <dc:creator>Miller, John</dc:creator>
 <dc:creator>Ng, Andrew</dc:creator>
 <dc:creator>Raiman, Jonathan</dc:creator>
 <dc:creator>Sengupta, Shubho</dc:creator>
 <dc:creator>Shoeybi, Mohammad</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  We present Deep Voice, a production-quality text-to-speech system constructed
entirely from deep neural networks. Deep Voice lays the groundwork for truly
end-to-end neural speech synthesis. The system comprises five major building
blocks: a segmentation model for locating phoneme boundaries, a
grapheme-to-phoneme conversion model, a phoneme duration prediction model, a
fundamental frequency prediction model, and an audio synthesis model. For the
segmentation model, we propose a novel way of performing phoneme boundary
detection with deep neural networks using connectionist temporal classification
(CTC) loss. For the audio synthesis model, we implement a variant of WaveNet
that requires fewer parameters and trains faster than the original. By using a
neural network for each component, our system is simpler and more flexible than
traditional text-to-speech systems, where each component requires laborious
feature engineering and extensive domain expertise. Finally, we show that
inference with our system can be performed faster than real time and describe
optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x
speedups over existing implementations.
</dc:description>
 <dc:description>Comment: Submitted to ICML 2017</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07826</identifier>
 <datestamp>2017-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rationalization: A Neural Machine Translation Approach to Generating
  Natural Language Explanations</dc:title>
 <dc:creator>Ehsan, Upol</dc:creator>
 <dc:creator>Harrison, Brent</dc:creator>
 <dc:creator>Chan, Larry</dc:creator>
 <dc:creator>Riedl, Mark O.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce AI rationalization, an approach for generating explanations of
autonomous system behavior as if a human had performed the behavior. We
describe a rationalization technique that uses neural machine translation to
translate internal state-action representations of an autonomous agent into
natural language. We evaluate our technique in the Frogger game environment,
training an autonomous game playing agent to rationalize its action choices
using natural language. A natural language training corpus is collected from
human players thinking out loud as they play the game. We motivate the use of
rationalization as an approach to explanation generation and show the results
of two experiments evaluating the effectiveness of rationalization. Results of
these evaluations show that neural machine translation is able to accurately
generate rationalizations that describe agent behavior, and that
rationalizations are more satisfying to humans than other alternative methods
of explanation.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures; added human evaluation section; added author;
  changed author order-Upol Ehsan and Brent Harrison both contributed equally
  to this work</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:date>2017-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07831</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New constructions of MDS codes with complementary duals</dc:title>
 <dc:creator>Chen, Bocong</dc:creator>
 <dc:creator>Liu, Hongwei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear complementary-dual (LCD for short) codes are linear codes that
intersect with their duals trivially. LCD codes have been used in certain
communication systems. It is recently found that LCD codes can be applied in
cryptography. This application of LCD codes renewed the interest in the
construction of LCD codes having a large minimum distance. MDS codes are
optimal in the sense that the minimum distance cannot be improved for given
length and code size. Constructing LCD MDS codes is thus of significance in
theory and practice. Recently, Jin (\cite{Jin}, IEEE Trans. Inf. Theory, 2016)
constructed several classes of LCD MDS codes through generalized Reed-Solomon
codes. In this paper, a different approach is proposed to obtain new LCD MDS
codes from generalized Reed-Solomon codes. Consequently, new code constructions
are provided and certain previously known results in \cite{Jin} are extended.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07832</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructing Adjacency Arrays from Incidence Arrays</dc:title>
 <dc:creator>Jananthan, Hayden</dc:creator>
 <dc:creator>Dibert, Karia</dc:creator>
 <dc:creator>Kepner, Jeremy</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Graph construction, a fundamental operation in a data processing pipeline, is
typically done by multiplying the incidence array representations of a graph,
$\mathbf{E}_\mathrm{in}$ and $\mathbf{E}_\mathrm{out}$, to produce an adjacency
array of the graph, $\mathbf{A}$, that can be processed with a variety of
algorithms. This paper provides the mathematical criteria to determine if the
product $\mathbf{A} = \mathbf{E}^{\sf T}_\mathrm{out}\mathbf{E}_\mathrm{in}$
will have the required structure of the adjacency array of the graph. The
values in the resulting adjacency array are determined by the corresponding
addition $\oplus$ and multiplication $\otimes$ operations used to perform the
array multiplication. Illustrations of the various results possible from
different $\oplus$ and $\otimes$ operations are provided using a small
collection of popular music metadata.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, accepted to IEEE IPDPS 2017 Workshop on Graph
  Algorithm Building Blocks</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07832</dc:identifier>
 <dc:identifier>doi:10.1109/IPDPSW.2017.71</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07834</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient coordinate-wise leading eigenvector computation</dc:title>
 <dc:creator>Wang, Jialei</dc:creator>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Garber, Dan</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We develop and analyze efficient &quot;coordinate-wise&quot; methods for finding the
leading eigenvector, where each step involves only a vector-vector product. We
establish global convergence with overall runtime guarantees that are at least
as good as Lanczos's method and dominate it for slowly decaying spectrum. Our
methods are based on combining a shift-and-invert approach with coordinate-wise
algorithms for linear regression.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07835</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Critical Survey of the Freely Available Arabic Corpora</dc:title>
 <dc:creator>Zaghouani, Wajdi</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The availability of corpora is a major factor in building natural language
processing applications. However, the costs of acquiring corpora can prevent
some researchers from going further in their endeavours. The ease of access to
freely available corpora is urgent needed in the NLP research community
especially for language such as Arabic. Currently, there is not easy was to
access to a comprehensive and updated list of freely available Arabic corpora.
We present in this paper, the results of a recent survey conducted to identify
the list of the freely available Arabic corpora and language resources. Our
preliminary results showed an initial list of 66 sources. We presents our
findings in the various categories studied and we provided the direct links to
get the data when possible.
</dc:description>
 <dc:description>Comment: Published in the Proceedings of the International Conference on
  Language Resources and Evaluation (LREC'2014), OSACT Workshop. Reykjavik,
  Iceland, 26-31 May 2014</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07836</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing Training Data for Object Detection in Indoor Scenes</dc:title>
 <dc:creator>Georgakis, Georgios</dc:creator>
 <dc:creator>Mousavian, Arsalan</dc:creator>
 <dc:creator>Berg, Alexander C.</dc:creator>
 <dc:creator>Kosecka, Jana</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Detection of objects in cluttered indoor environments is one of the key
enabling functionalities for service robots. The best performing object
detection approaches in computer vision exploit deep Convolutional Neural
Networks (CNN) to simultaneously detect and categorize the objects of interest
in cluttered scenes. Training of such models typically requires large amounts
of annotated training data which is time consuming and costly to obtain. In
this work we explore the ability of using synthetically generated composite
images for training state-of-the-art object detectors, especially for object
instance detection. We superimpose 2D images of textured object models into
images of real environments at variety of locations and scales. Our experiments
evaluate different superimposition strategies ranging from purely image-based
blending all the way to depth and semantics informed positioning of the object
models into real scenes. We demonstrate the effectiveness of these object
detector training strategies on two publicly available datasets, the
GMU-Kitchens and the Washington RGB-D Scenes v2. As one observation, augmenting
some hand-labeled training data with synthetic examples carefully composed onto
scenes yields object detectors with comparable performance to using much more
hand-labeled data. Broadly, this work charts new opportunities for training
detectors for new objects by exploiting existing object model repositories in
either a purely automatic fashion or with only a very small number of
human-annotated examples.
</dc:description>
 <dc:description>Comment: Added more experiments and link to project webpage</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07836</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07838</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Algebraic Treatment of Recursion</dc:title>
 <dc:creator>van Glabbeek, Rob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  I review the three principal methods to assign meaning to recursion in
process algebra: the denotational, the operational and the algebraic approach,
and I extend the latter to unguarded recursion.
</dc:description>
 <dc:description>Comment: Dedicated to Jan Bergstra, at the occasion of his 65th birthday and
  retirement</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07838</dc:identifier>
 <dc:identifier>In: Liber Amicorum for Jan A. Bergstra (I. Bethke and B. Bredeweg
  and A. Ponse, eds.), Informatics Institute, University of Amsterdam, 2016,
  pp. 58-59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07841</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning for Domain Adaptation in MRI: Application in Brain
  Lesion Segmentation</dc:title>
 <dc:creator>Ghafoorian, Mohsen</dc:creator>
 <dc:creator>Mehrtash, Alireza</dc:creator>
 <dc:creator>Kapur, Tina</dc:creator>
 <dc:creator>Karssemeijer, Nico</dc:creator>
 <dc:creator>Marchiori, Elena</dc:creator>
 <dc:creator>Pesteie, Mehran</dc:creator>
 <dc:creator>Guttmann, Charles R. G.</dc:creator>
 <dc:creator>de Leeuw, Frank-Erik</dc:creator>
 <dc:creator>Tempany, Clare M.</dc:creator>
 <dc:creator>van Ginneken, Bram</dc:creator>
 <dc:creator>Fedorov, Andriy</dc:creator>
 <dc:creator>Abolmaesumi, Purang</dc:creator>
 <dc:creator>Platel, Bram</dc:creator>
 <dc:creator>Wells III, William M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis
and treatment. However, variations in MRI acquisition protocols result in
different appearances of normal and diseased tissue in the images.
Convolutional neural networks (CNNs), which have shown to be successful in many
medical image analysis tasks, are typically sensitive to the variations in
imaging protocols. Therefore, in many cases, networks trained on data acquired
with one MRI protocol, do not perform satisfactorily on data acquired with
different protocols. This limits the use of models trained with large annotated
legacy datasets on a new dataset with a different domain which is often a
recurring situation in clinical settings. In this study, we aim to answer the
following central questions regarding domain adaptation in medical image
analysis: Given a fitted legacy model, 1) How much data from the new domain is
required for a decent adaptation of the original network?; and, 2) What portion
of the pre-trained model parameters should be retrained given a certain number
of the new domain training samples? To address these questions, we conducted
extensive experiments in white matter hyperintensity segmentation task. We
trained a CNN on legacy MR images of brain and evaluated the performance of the
domain-adapted network on the same task with images from a different domain. We
then compared the performance of the model to the surrogate scenarios where
either the same trained network is used or a new network is trained from
scratch on the new dataset.The domain-adapted network tuned only by two
training examples achieved a Dice score of 0.63 substantially outperforming a
similar network trained on the same set of examples from scratch.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07841</dc:identifier>
 <dc:identifier>Medical Image Computing and Computer-Assisted Intervention 2017,
  Vol 10435, 516-524</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-66179-7_59</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07844</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Branching Time Model of CSP</dc:title>
 <dc:creator>van Glabbeek, Rob</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  I present a branching time model of CSP that is finer than all other models
of CSP proposed thus far. It is obtained by taking a semantic equivalence from
the linear time - branching time spectrum, namely divergence-preserving coupled
similarity, and showing that it is a congruence for the operators of CSP. This
equivalence belongs to the bisimulation family of semantic equivalences, in the
sense that on transition systems without internal actions it coincides with
strong bisimilarity. Nevertheless, enough of the equational laws of CSP remain
to obtain a complete axiomatisation for closed, recursion-free terms.
</dc:description>
 <dc:description>Comment: Dedicated to Bill Roscoe, on the occasion of his 60th birthday</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07844</dc:identifier>
 <dc:identifier>In: Concurrency, Security, and Puzzles; Essays Dedicated to Andrew
  William Roscoe on the Occasion of His 60th Birthday (Th. Gibson-Robinson and
  Ph.J. Hopcroft and R. Lazic, eds.), LNCS 10160, Springer, 2017, pp. 272-293</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-51046-0_14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07847</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automated Verification and Synthesis of Embedded Systems using Machine
  Learning</dc:title>
 <dc:creator>Cordeiro, Lucas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>C.3</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>I.2.2</dc:subject>
 <dc:description>  The dependency on the correct functioning of embedded systems is rapidly
growing, mainly due to their wide range of applications, such as micro-grids,
automotive device control, health care, surveillance, mobile devices, and
consumer electronics. Their structures are becoming more and more complex and
now require multi-core processors with scalable shared memory, in order to meet
increasing computational power demands. As a consequence, reliability of
embedded (distributed) software becomes a key issue during system development,
which must be carefully addressed and assured. The present research discusses
challenges, problems, and recent advances to ensure correctness and timeliness
regarding embedded systems. Reliability issues, in the development of
micro-grids and cyber-physical systems, are then considered, as a prominent
verification and synthesis application. In particular, machine learning
techniques emerge as one of the main approaches to learn reliable
implementations of embedded software for achieving a correct-by-construction
design.
</dc:description>
 <dc:description>Comment: This paper is a revised version of &quot;SMT-Based Context-Bounded Model
  Checking for Embedded Systems: Challenges and Future Trends. ACM SIGSOFT
  Software Engineering Notes 41(3): 1-6 (2016).&quot;</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07870</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Learning with Many Experts</dc:title>
 <dc:creator>Cohen, Alon</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the problem of prediction with expert advice when the number of
experts in question may be extremely large or even infinite. We devise an
algorithm that obtains a tight regret bound of $\widetilde{O}(\epsilon T + N +
\sqrt{NT})$, where $N$ is the empirical $\epsilon$-covering number of the
sequence of loss functions generated by the environment. In addition, we
present a hedging procedure that allows us to find the optimal $\epsilon$ in
hindsight.
  Finally, we discuss a few interesting applications of our algorithm. We show
how our algorithm is applicable in the approximately low rank experts model of
Hazan et al. (2016), and discuss the case of experts with bounded variation, in
which there is a surprisingly large gap between the regret bounds obtained in
the statistical and online settings.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07881</identifier>
 <datestamp>2017-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Performance of Wireless Powered Communication With Non-linear
  Energy Harvesting</dc:title>
 <dc:creator>Morsi, Rania</dc:creator>
 <dc:creator>Boshkovska, Elena</dc:creator>
 <dc:creator>Ramadan, Esmat</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we analyze the performance of a time-slotted multi-antenna
wireless powered communication (WPC) system, where a wireless device first
harvests radio frequency (RF) energy from a power station (PS) in the downlink
to facilitate information transfer to an information receiving station (IRS) in
the uplink. The main goal of this paper is to provide insights and guidelines
for the design of practical WPC systems. To this end, we adopt a recently
proposed parametric non-linear RF energy harvesting (EH) model, which has been
shown to accurately model the end-to-end non-linearity of practical RF EH
circuits. In order to enhance the RF power transfer efficiency, maximum ratio
transmission is adopted at the PS to focus the energy signals on the wireless
device. Furthermore, at the IRS, maximum ratio combining is used. We analyze
the outage probability and the average throughput of information transfer,
assuming Nakagami-$m$ fading uplink and downlink channels. Moreover, we study
the system performance as a function of the number of PS transmit antennas, the
number of IRS receive antennas, the transmit power of the PS, the fading
severity, the transmission rate of the wireless device, and the EH time
duration. In addition, we obtain a fixed point equation for the optimal
transmission rate and the optimal EH time duration that maximize the asymptotic
throughput for high PS transmit powers. All analytical results are corroborated
by simulations.
</dc:description>
 <dc:description>Comment: 5 pages, 1 Table, accepted for IEEE conference publication</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07884</identifier>
 <datestamp>2017-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An EM Based Probabilistic Two-Dimensional CCA with Application to Face
  Recognition</dc:title>
 <dc:creator>Safayani, Mehran</dc:creator>
 <dc:creator>Ahmadi, Seyed Hashem</dc:creator>
 <dc:creator>Afrabandpey, Homayun</dc:creator>
 <dc:creator>Mirzaei, Abdolreza</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently, two-dimensional canonical correlation analysis (2DCCA) has been
successfully applied for image feature extraction. The method instead of
concatenating the columns of the images to the one-dimensional vectors,
directly works with two-dimensional image matrices. Although 2DCCA works well
in different recognition tasks, it lacks a probabilistic interpretation. In
this paper, we present a probabilistic framework for 2DCCA called probabilistic
2DCCA (P2DCCA) and an iterative EM based algorithm for optimizing the
parameters. Experimental results on synthetic and real data demonstrate
superior performance in loading factor estimation for P2DCCA compared to 2DCCA.
For real data, three subsets of AR face database and also the UMIST face
database confirm the robustness of the proposed algorithm in face recognition
tasks with different illumination conditions, facial expressions, poses and
occlusions.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07884</dc:identifier>
 <dc:identifier>doi:10.1007/s10489-017-1012-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07889</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contractibility for Open Global Constraints</dc:title>
 <dc:creator>Maher, Michael J.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Open forms of global constraints allow the addition of new variables to an
argument during the execution of a constraint program. Such forms are needed
for difficult constraint programming problems where problem construction and
problem solving are interleaved, and fit naturally within constraint logic
programming. However, in general, filtering that is sound for a global
constraint can be unsound when the constraint is open. This paper provides a
simple characterization, called contractibility, of the constraints where
filtering remains sound when the constraint is open. With this characterization
we can easily determine whether a constraint has this property or not. In the
latter case, we can use it to derive a contractible approximation to the
constraint. We demonstrate this work on both hard and soft constraints. In the
process, we formulate two general classes of soft constraints.
</dc:description>
 <dc:description>Comment: Under consideration in Theory and Practice of Logic Programming
  (TPLP)</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07890</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building up user confidence for the spaceborne derived global and
  continental land cover products for the Mediterranean region: the case of
  Thessaly</dc:title>
 <dc:creator>Manakos, Ioannis</dc:creator>
 <dc:creator>Karakizi, Christina</dc:creator>
 <dc:creator>Gkinis, Giannis</dc:creator>
 <dc:creator>Karantzalos, Konstantinos</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Across globe and space agencies nations recognize the importance of
homogenized land cover information, prone to regular updates, both in the
context of thematic and spatial resolutions. Recent sensor advances and the
free distribution policy promote the utilization of spaceborne products in an
unprecedented pace into an increasingly wider range of applications. Ensuring
credibility to the users is a major enabler in this process. To this end this
study contributes with a systematic accuracy performance measurement and
continental/global land cover layers' inter-comparison moving towards
confidence built up. Confidence levels during validation and a weighted overall
accuracy assessment were applied. Google Earth imagery was employed to assess
the accuracy of three land cover products, i.e., Globeland30, HRLs and CLC
2012, for the years 2010 and 2012. Reported rates indicate a minimum weighted
overall accuracy of 84%. Specific classes' performance deviations from the
general trend were noted and discussed on the basis of an unbiased sampling
approach. By integrating confidence levels during the ground truth annotation,
stratified sampling on the several Corine Level 3 subclasses and the weighted
overall accuracy assessment, the different aspects of the considered land cover
products can be highlighted more objectively.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07890</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07893</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Persistent Homotopy Type Distance</dc:title>
 <dc:creator>Frosini, Patrizio</dc:creator>
 <dc:creator>Landi, Claudia</dc:creator>
 <dc:creator>Memoli, Facundo</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  We introduce the persistent homotopy type distance dHT to compare real valued
functions defined on possibly different homotopy equivalent topological spaces.
The underlying idea in the definition of dHT is to measure the minimal shift
that is necessary to apply to one of the two functions in order that the
sublevel sets of the two functions become homotopically equivalent. This
distance is interesting in connection with persistent homology. Indeed, our
main result states that dHT still provides an upper bound for the bottleneck
distance between the persistence diagrams of the intervening functions.
Moreover, because homotopy equivalences are weaker than homeomorphisms, this
implies a lifting of the standard stability results provided by the L-infty
distance and the natural pseudo-distance dNP. From a different standpoint, we
prove that dHT extends the L-infty distance and dNP in two ways. First, we show
that, appropriately restricting the category of objects to which dHT applies,
it can be made to coincide with the other two distances. Finally, we show that
dHT has an interpretation in terms of interleavings that naturally places it in
the family of distances used in persistence theory.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07898</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep NBNN Representations for Robust Place Categorization</dc:title>
 <dc:creator>Mancini, Massimiliano</dc:creator>
 <dc:creator>Bul&#xf2;, Samuel Rota</dc:creator>
 <dc:creator>Ricci, Elisa</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents an approach for semantic place categorization using data
obtained from RGB cameras. Previous studies on visual place recognition and
classification have shown that, by considering features derived from
pre-trained Convolutional Neural Networks (CNNs) in combination with part-based
classification models, high recognition accuracy can be achieved, even in
presence of occlusions and severe viewpoint changes. Inspired by these works,
we propose to exploit local deep representations, representing images as set of
regions applying a Na\&quot;{i}ve Bayes Nearest Neighbor (NBNN) model for image
classification. As opposed to previous methods where CNNs are merely used as
feature extractors, our approach seamlessly integrates the NBNN model into a
fully-convolutional neural network. Experimental results show that the proposed
algorithm outperforms previous methods based on pre-trained CNN models and
that, when employed in challenging robot place recognition tasks, it is robust
to occlusions, environmental and sensor changes.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07900</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing Task Driven Knowledge Worker Behaviors in Open Source Software
  Communities</dc:title>
 <dc:creator>Wu, Hongrui</dc:creator>
 <dc:creator>Shi, Xiaowan</dc:creator>
 <dc:creator>Ma, Yutao</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N30</dc:subject>
 <dc:subject>K.6.3, H.1.2, J.4</dc:subject>
 <dc:description>  Collaborative activities among knowledge workers such as software developers
underlie the development of modern society, but the in-depth understanding of
their behavioral patterns in open online communities is very challenging. The
availability of large volumes of data in open-source software (OSS)
repositories (e.g. bug tracking data, emails, and comments) enables us to
investigate this issue in a quantitative way. In this paper, we conduct an
empirical analysis of online collaborative activities closely related to assure
software quality in two well-known OSS communities, namely Eclipse and Mozilla.
Our main findings include two aspects: (1) developers exhibit two diametrically
opposite behavioral patterns in spatial and temporal scale when they work under
two different states (i.e. normal and overload), and (2) the processing times
(including bug fixing times and bug tossing times) follow a stretched
exponential distribution instead of the common power law distribution. Our work
reveals regular patterns in human dynamics beyond online collaborative
activities among skilled developers who work under different task-driven load
conditions, and it could be an important supplementary to the current work on
human dynamics.
</dc:description>
 <dc:description>Comment: 23 pages, 12 figures, 4 tables</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07902</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approval Voting with Intransitive Preferences</dc:title>
 <dc:creator>Yang, Yongjie</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We extend Approval voting to the settings where voters may have intransitive
preferences. The major obstacle to applying Approval voting in these settings
is that voters are not able to clearly determine who they should approve or
disapprove, due to the intransitivity of their preferences. An approach to
address this issue is to apply tournament solutions to help voters make the
decision. We study a class of voting systems where first each voter casts a
vote defined as a tournament, then a well-defined tournament solution is
applied to select the candidates who are assumed to be approved by the voter.
Winners are the ones receiving the most approvals. We study axiomatic
properties of this class of voting systems and complexity of control and
bribery problems for these voting systems.
</dc:description>
 <dc:description>Comment: 11 pages, 1 figure, extended abstract accepted at AAMAS 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07902</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07904</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coarse Grained Exponential Variational Autoencoders</dc:title>
 <dc:creator>Sun, Ke</dc:creator>
 <dc:creator>Zhang, Xiangliang</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Variational autoencoders (VAE) often use Gaussian or category distribution to
model the inference process. This puts a limit on variational learning because
this simplified assumption does not match the true posterior distribution,
which is usually much more sophisticated. To break this limitation and apply
arbitrary parametric distribution during inference, this paper derives a
\emph{semi-continuous} latent representation, which approximates a continuous
density up to a prescribed precision, and is much easier to analyze than its
continuous counterpart because it is fundamentally discrete. We showcase the
proposition by applying polynomial exponential family distributions as the
posterior, which are universal probability density function generators. Our
experimental results show consistent improvements over commonly used VAE
models.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07908</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CHAOS: A Parallelization Scheme for Training Convolutional Neural
  Networks on Intel Xeon Phi</dc:title>
 <dc:creator>Viebke, Andre</dc:creator>
 <dc:creator>Memeti, Suejb</dc:creator>
 <dc:creator>Pllana, Sabri</dc:creator>
 <dc:creator>Abraham, Ajith</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep learning is an important component of big-data analytic tools and
intelligent applications, such as, self-driving cars, computer vision, speech
recognition, or precision medicine. However, the training process is
computationally intensive, and often requires a large amount of time if
performed sequentially. Modern parallel computing systems provide the
capability to reduce the required training time of deep neural networks. In
this paper, we present our parallelization scheme for training convolutional
neural networks (CNN) named Controlled Hogwild with Arbitrary Order of
Synchronization (CHAOS). Major features of CHAOS include the support for thread
and vector parallelism, non-instant updates of weight parameters during
back-propagation without a significant delay, and implicit synchronization in
arbitrary order. CHAOS is tailored for parallel computing systems that are
accelerated with the Intel Xeon Phi. We evaluate our parallelization approach
empirically using measurement techniques and performance modeling for various
numbers of threads and CNN architectures. Experimental results for the MNIST
dataset of handwritten digits using the total number of threads on the Xeon Phi
show speedups of up to 103x compared to the execution on one thread of the Xeon
Phi, 14x compared to the sequential execution on Intel Xeon E5, and 58x
compared to the sequential execution on Intel Core i5.
</dc:description>
 <dc:description>Comment: The Journal of Supercomputing, 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07908</dc:identifier>
 <dc:identifier>doi:10.1007/s11227-017-1994-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07911</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The natural algorithmic approach of mixed trigonometric-polynomial
  problems</dc:title>
 <dc:creator>Lutovac, Tatjana</dc:creator>
 <dc:creator>Malesevic, Branko</dc:creator>
 <dc:creator>Mortici, Cristinel</dc:creator>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>41A10, 26D05, 12L05, 41A58</dc:subject>
 <dc:description>  The aim of this paper is to present a new algorithm for proving mixed
trigonometric-polynomial inequalities by reducing to polynomial inequalities.
Finally, we show the great applicability of this algorithm and as examples, we
use it to analyze some new rational (Pade) approximations of the function
$\cos^2(x)$, and to improve a class of inequalities by Z.-H. Yang. The results
of our analysis could be implemented by means of an automated proof assistant,
so our work is a contribution to the library of automatic support tools for
proving various analytic inequalities.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07912</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Increasing Peer Pressure on any Connected Graph Leads to Consensus</dc:title>
 <dc:creator>Semonsen, Justin</dc:creator>
 <dc:creator>Griffin, Christopher</dc:creator>
 <dc:creator>Squicciarini, Anna</dc:creator>
 <dc:creator>Rajtmajer, Sarah</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In this paper, we study a model of opinion dynamics in a social network in
the presence increasing interpersonal influence, i.e., increasing peer
pressure. Each agent in the social network has a distinct social stress
function given by a weighted sum of internal and external behavioral pressures.
We assume a weighted average update rule and prove conditions under which a
connected group of agents converge to a fixed opinion distribution, and under
which conditions the group reaches consensus. We show that the update rule is a
gradient descent and explain its transient and asymptotic convergence
properties. Through simulation, we study the rate of convergence on a
scale-free network and then validate the assumption of increasing peer pressure
in a simple empirical model.
</dc:description>
 <dc:description>Comment: Extended abstract form appearing in AAMAS 2017 (Sao Paulo, Brazil)</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07914</identifier>
 <datestamp>2017-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Chordal-$k$-Generalized Split Graphs</dc:title>
 <dc:creator>Brandst&#xe4;dt, Andreas</dc:creator>
 <dc:creator>Mosca, Raffaele</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A graph $G$ is a {\em chordal-$k$-generalized split graph} if $G$ is chordal
and there is a clique $Q$ in $G$ such that every connected component in $G[V
\setminus Q]$ has at most $k$ vertices. Thus, chordal-$1$-generalized split
graphs are exactly the split graphs.
  We characterize chordal-$k$-generalized split graphs by forbidden induced
subgraphs. Moreover, we characterize a very special case of
chordal-$2$-generalized split graphs for which the Efficient Domination problem
is \NP-complete.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1701.03414</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-04-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07915</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Rician MIMO Channel- and Jamming-Aware Decision Fusion</dc:title>
 <dc:creator>Ciuonzo, D.</dc:creator>
 <dc:creator>Aubry, A.</dc:creator>
 <dc:creator>Carotenuto, V.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this manuscript we study channel-aware decision fusion (DF) in a wireless
sensor network (WSN) where: (i) the sensors transmit their decisions
simultaneously for spectral efficiency purposes and the DF center (DFC) is
equipped with multiple antennas; (ii) each sensor-DFC channel is described via
a Rician model. As opposed to the existing literature, in order to account for
stringent energy constraints in the WSN, only statistical channel information
is assumed for the non-line-of sight (scattered) fading terms. For such a
scenario, sub-optimal fusion rules are developed in order to deal with the
exponential complexity of the likelihood ratio test (LRT) and impractical
(complete) system knowledge. Furthermore, the considered model is extended to
the case of (partially unknown) jamming-originated interference. Then the
obtained fusion rules are modified with the use of composite hypothesis testing
framework and generalized LRT. Coincidence and statistical equivalence among
them are also investigated under some relevant simplified scenarios. Numerical
results compare the proposed rules and highlight their jammingsuppression
capability.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Transactions on Signal Processing 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07915</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2686375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07920</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Invariant-EKF VINS Algorithm for Improving Consistency</dc:title>
 <dc:creator>Zhang, Teng</dc:creator>
 <dc:creator>Wu, Kanzhi</dc:creator>
 <dc:creator>Su, Daobilige</dc:creator>
 <dc:creator>Huang, Shoudong</dc:creator>
 <dc:creator>Dissanayake, Gamini</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The main contribution of this paper is an invariant extended Kalman filter
(EKF) for visual inertial navigation systems (VINS). It is demonstrated that
the conventional EKF based VINS is not invariant under the stochastic
unobservable transformation, associated with translations and a rotation about
the gravitational direction. This can lead to inconsistent state estimates as
the estimator does not obey a fundamental property of the physical system. To
address this issue, we use a novel uncertainty representation to derive a Right
Invariant error extended Kalman filter (RIEKF-VINS) that preserves this
invariance property. RIEKF-VINS is then adapted to the multistate constraint
Kalman filter framework to obtain a consistent state estimator. Both Monte
Carlo simulations and real-world experiments are used to validate the proposed
method.
</dc:description>
 <dc:description>Comment: submitted to The 2017 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS 2017)</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07922</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Hardness of Solving Simple Word Equations</dc:title>
 <dc:creator>Day, Joel D.</dc:creator>
 <dc:creator>Manea, Florin</dc:creator>
 <dc:creator>Nowotka, Dirk</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We investigate the class of regular-ordered word equations. In such
equations, each variable occurs at most once in each side and the order of the
variables occurring in both sides is the preserved (the variables can be,
however, separated by potentially distinct constant factors). Surprisingly, we
obtain that solving such simple equations, even when the sides contain exactly
the same variables, is NP-hard. By considerations regarding the combinatorial
structure of the minimal solutions of the more general quadratic equations we
obtain that the satisfiability problem for regular-ordered equations is in NP.
Finally, we also show that a related class of simple word equations, that
generalises one-variable equations, is in P.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07928</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Taxonomy for Symbiotic EM Sensors</dc:title>
 <dc:creator>Inggs, Michael</dc:creator>
 <dc:creator>Mishra, Amit</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  It is clear that the EM spectrum is now rapidly reaching saturation,
especially for frequencies below 10~GHz. Governments, who influence the
regulatory authorities around the world, have resorted to auctioning the use of
spectrum, in a sense to gauge the importance of a particular user. Billions of
USD are being paid for modest bandwidths.
  The earth observation, astronomy and similar science driven communities
cannot compete financially with such a pressure system, so this is where
governments have to step in and assess /regulate the situation.
  It has been a pleasure to see a situation where the communications and
broadcast communities have come together to formulate sharing of an important
part of the spectrum (roughly, 50 MHz to 800 MHz) in an IEEE standard,
IEEE802.22. This standard (known as the &quot;TV White Space Network&quot; (built on
lower level standards) shows a way that fixed and mobile users can collaborate
in geographically widespread regions, using cognitive radio and geographic
databases of users. This White Space (WS) standard is well described in the
literature and is not the major topic of this short paper.
  We wish to extend the idea of the WS concept to include the idea of EM
sensors (such as Radar) adopting this approach to spectrum sharing, providing a
quantum leap in access to spectrum. We postulate that networks of sensors,
using the tools developed by the WS community, can replace and enhance our
present set of EM sensors.
  We first define what Networks of Sensors entail (with some history), and then
go on to define, based on a Taxonomy of Symbiosis defined by de
Bary\cite{symb}, how these sensors and other users (especially communications)
can co-exist. This new taxonomy is important for understanding, and should
replace somewhat outdated terminologies from the radar world.
</dc:description>
 <dc:description>Comment: 4 pages, 1 Figure</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07932</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The role of quantum correlations in Cop and Robber game</dc:title>
 <dc:creator>Glos, Adam</dc:creator>
 <dc:creator>Miszczak, Jaros&#x142;aw Adam</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>05C57 (Primary), 91A46, 81P40 (Secondary)</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We introduce and study quantized versions of Cop and Robber game. We achieve
this by using graph-preserving quantum operations, which are the quantum
analogues of stochastic operations preserving the graph. We provide the tight
bound for the number of operations required to reach the given state. By
extending them to the controlled operations, we define a quantum-controlled Cop
and Robber game, which expands the classical Cop and Robber game, as well as
the classically controlled quantum Cop and Robber game. In contrast to the
typical scheme for introducing quantum games, we assume that both parties can
utilise full information about the opponent's strategy. We show that the
utilisation of the full knowledge about the opponent's state does not provide
the advantage. Moreover, the chances of catching the Robber decrease for
classical cop-win graphs. This result does not depend on the chosen model of
evolution. On the other hand, the possibility to execute controlled quantum
operations allows catching the Robber on almost all classical cop-win graphs.
By this, we demonstrate that it is necessary to enrich the structure of
correlations between the players' systems to provide a non-trivial quantized
Cop and Robber game. Thus the quantum controlled operations offer a significant
advantage over the classically controlled quantum operations.
</dc:description>
 <dc:description>Comment: 15 pages, 2 tikz figures</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07932</dc:identifier>
 <dc:identifier>Quantum Stud.: Math. Found. (2017)</dc:identifier>
 <dc:identifier>doi:10.1007/s40509-017-0148-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07933</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Learning of Mixed Membership Models</dc:title>
 <dc:creator>Tan, Zilong</dc:creator>
 <dc:creator>Mukherjee, Sayan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an efficient algorithm for learning mixed membership models when
the number of variables $p$ is much larger than the number of hidden components
$k$. This algorithm reduces the computational complexity of state-of-the-art
tensor methods, which require decomposing an $O\left(p^3\right)$ tensor, to
factorizing $O\left(p/k\right)$ sub-tensors each of size $O\left(k^3\right)$.
In addition, we address the issue of negative entries in the empirical method
of moments based estimators. We provide sufficient conditions under which our
approach has provable guarantees. Our approach obtains competitive empirical
results on both simulated and real data.
</dc:description>
 <dc:description>Comment: 23 pages, Proceedings of the 34th International Conference on Machine
  Learning (ICML), Sydney, Australia, 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-07-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07934</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A decentralized algorithm for control of autonomous agents coupled by
  feasibility constraints</dc:title>
 <dc:creator>Rosolia, Ugo</dc:creator>
 <dc:creator>Braghin, Francesco</dc:creator>
 <dc:creator>Alleyne, Andrew G.</dc:creator>
 <dc:creator>De Bruyne, Stijn</dc:creator>
 <dc:creator>Sabbioni, Edoardo</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper a decentralized control algorithm for systems composed of $N$
dynamically decoupled agents, coupled by feasibility constraints, is presented.
The control problem is divided into $N$ optimal control sub-problems and a
communication scheme is proposed to decouple computations. The derivative of
the solution of each sub-problem is used to approximate the evolution of the
system allowing the algorithm to decentralize and parallelize computations. The
effectiveness of the proposed algorithm is shown through simulations in a
cooperative driving scenario.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07935</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Stitching by Line-guided Local Warping with Global Similarity
  Constraint</dc:title>
 <dc:creator>Xiang, Tian-Zhu</dc:creator>
 <dc:creator>Xia, Gui-Song</dc:creator>
 <dc:creator>Bai, Xiang</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Low-textured image stitching remains a challenging problem. It is difficult
to achieve good alignment and it is easy to break image structures due to
insufficient and unreliable point correspondences. Moreover, because of the
viewpoint variations between multiple images, the stitched images suffer from
projective distortions. To solve these problems, this paper presents a
line-guided local warping method with a global similarity constraint for image
stitching. Line features which serve well for geometric descriptions and scene
constraints, are employed to guide image stitching accurately. On one hand, the
line features are integrated into a local warping model through a designed
weight function. On the other hand, line features are adopted to impose strong
geometric constraints, including line correspondence and line colinearity, to
improve the stitching performance through mesh optimization. To mitigate
projective distortions, we adopt a global similarity constraint, which is
integrated with the projective warps via a designed weight strategy. This
constraint causes the final warp to slowly change from a projective to a
similarity transformation across the image. Finally, the images undergo a
two-stage alignment scheme that provides accurate alignment and reduces
projective distortion. We evaluate our method on a series of images and compare
it with several other methods. The experimental results demonstrate that the
proposed method provides a convincing stitching performance and that it
outperforms other state-of-the-art methods.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07938</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity Classification of the Eight-Vertex Model</dc:title>
 <dc:creator>Cai, Jin-Yi</dc:creator>
 <dc:creator>Fu, Zhiguo</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:description>  We prove a complexity dichotomy theorem for the eight-vertex model. For every
setting of the parameters of the model, we prove that computing the partition
function is either solvable in polynomial time or \#P-hard. The dichotomy
criterion is explicit. For tractability, we find some new classes of problems
computable in polynomial time. For \#P-hardness, we employ M\&quot;{o}bius
transformations to prove the success of interpolations.
</dc:description>
 <dc:description>Comment: This submission contains two versions of the same paper, one is the
  short version and one is the full version</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07939</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Upper bounds on the smallest size of a saturating set in projective
  planes and spaces of even dimension</dc:title>
 <dc:creator>Bartoli, Daniele</dc:creator>
 <dc:creator>Davydov, Alexander</dc:creator>
 <dc:creator>Giulietti, Massimo</dc:creator>
 <dc:creator>Marcugini, Stefano</dc:creator>
 <dc:creator>Pambianco, Fernanda</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>51E21, 51E22, 94B05</dc:subject>
 <dc:description>  In a projective plane $\Pi_{q}$ (not necessarily Desarguesian) of order $q$,
a point subset $\mathcal{S}$ is saturating (or dense) if any point of
$\Pi_{q}\setminus \mathcal{S}$ is collinear with two points in $\mathcal{S}$.
Modifying an approach of [31], we proved the following upper bound on the
smallest size $s(2,q)$ of a saturating set in $\Pi_{q}$: \begin{equation*}
s(2,q)\leq \sqrt{(q+1)\left(3\ln q+\ln\ln q
+\ln\frac{3}{4}\right)}+\sqrt{\frac{q}{3\ln q}}+3. \end{equation*} The bound
holds for all q, not necessarily large.
  By using inductive constructions, upper bounds on the smallest size of a
saturating set in the projective space $\mathrm{PG}(N,q)$ with even dimension
$N$ are obtained.
  All the results are also stated in terms of linear covering codes.
</dc:description>
 <dc:description>Comment: 14 pages, 34 references, 1 figure</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07939</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07942</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BARCHAN: Blob Alignment for Robust CHromatographic ANalysis</dc:title>
 <dc:creator>Couprie, Camille</dc:creator>
 <dc:creator>Duval, Laurent</dc:creator>
 <dc:creator>Moreaud, Maxime</dc:creator>
 <dc:creator>H&#xe9;non, Sophie</dc:creator>
 <dc:creator>Tebib, M&#xe9;linda</dc:creator>
 <dc:creator>Souchon, Vincent</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Comprehensive Two dimensional gas chromatography (GCxGC) plays a central role
into the elucidation of complex samples. The automation of the identification
of peak areas is of prime interest to obtain a fast and repeatable analysis of
chromatograms. To determine the concentration of compounds or pseudo-compounds,
templates of blobs are defined and superimposed on a reference chromatogram.
The templates then need to be modified when different chromatograms are
recorded. In this study, we present a chromatogram and template alignment
method based on peak registration called BARCHAN. Peaks are identified using a
robust mathematical morphology tool. The alignment is performed by a
probabilistic estimation of a rigid transformation along the first dimension,
and a non-rigid transformation in the second dimension, taking into account
noise, outliers and missing peaks in a fully automated way. Resulting aligned
chromatograms and masks are presented on two datasets. The proposed algorithm
proves to be fast and reliable. It significantly reduces the time to results
for GCxGC analysis.
</dc:description>
 <dc:description>Comment: 15 pages, published in the Special issue for RIVA 2016, 40th
  International Symposium on Capillary Chromatography and 13th GCxGC Symposium</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07942</dc:identifier>
 <dc:identifier>Journal of Chromatography A, Volume 1484, February 2017, Pages
  65-72</dc:identifier>
 <dc:identifier>doi:10.1016/j.chroma.2017.01.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07944</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Variance Reduction Methods for Policy Evaluation</dc:title>
 <dc:creator>Du, Simon S.</dc:creator>
 <dc:creator>Chen, Jianshu</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Xiao, Lin</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Policy evaluation is a crucial step in many reinforcement-learning
procedures, which estimates a value function that predicts states' long-term
value under a given policy. In this paper, we focus on policy evaluation with
linear function approximation over a fixed dataset. We first transform the
empirical policy evaluation problem into a (quadratic) convex-concave saddle
point problem, and then present a primal-dual batch gradient method, as well as
two stochastic variance reduction methods for solving the problem. These
algorithms scale linearly in both sample size and feature dimension. Moreover,
they achieve linear convergence even when the saddle-point problem has only
strong concavity in the dual variables but no strong convexity in the primal
variables. Numerical experiments on benchmark problems demonstrate the
effectiveness of our methods.
</dc:description>
 <dc:description>Comment: Accepted by ICML 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07945</identifier>
 <datestamp>2017-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Optimality in Low-rank Matrix Optimization</dc:title>
 <dc:creator>Zhu, Zhihui</dc:creator>
 <dc:creator>Li, Qiuwei</dc:creator>
 <dc:creator>Tang, Gongguo</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers the minimization of a general objective function $f(X)$
over the set of non-square $n\times m$ matrices where the optimal solution
$X^\star$ is low-rank. To reduce the computational burden, we factorize the
variable $X$ into a product of two smaller matrices and optimize over these two
matrices instead of $X$. Despite the resulting nonconvexity, recent studies in
matrix completion and sensing have shown that the factored problem has no
spurious local minima and obeys the so-called strict saddle property (the
function has a directional negative curvature at all critical points but local
minima). We analyze the global geometry for a general and yet well-conditioned
objective function $f(X)$ whose restricted strong convexity and restricted
strong smoothness constants are comparable. In particular, we show that the
reformulated objective function has no spurious local minima and obeys the
strict saddle property. These geometric properties implies that a number of
iterative optimization algorithms (such as gradient descent) can provably solve
the factored problem with global convergence.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07946</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDN as Active Measurement Infrastructure</dc:title>
 <dc:creator>Rye, Erik</dc:creator>
 <dc:creator>Beverly, Robert</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Active measurements are integral to the operation and management of networks,
and invaluable to supporting empirical network research. Unfortunately, it is
often cost-prohibitive and logistically difficult to widely deploy measurement
nodes, especially in the core. In this work, we consider the feasibility of
tightly integrating measurement within the infrastructure by using Software
Defined Networks (SDNs). We introduce &quot;SDN as Active Measurement
Infrastructure&quot; (SAAMI) to enable measurements to originate from any location
where SDN is deployed, removing the need for dedicated measurement nodes and
increasing vantage point diversity. We implement ping and traceroute using
SAAMI, as well as a proof-of-concept custom measurement protocol to demonstrate
the power and ease of SAAMI's open framework. Via a large-scale measurement
campaign using SDN switches as vantage points, we show that SAAMI is accurate,
scalable, and extensible.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07948</identifier>
 <datestamp>2017-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Rule Estimation for Power Flow Analysis in Distribution Grids</dc:title>
 <dc:creator>Yu, Jiafan</dc:creator>
 <dc:creator>Weng, Yang</dc:creator>
 <dc:creator>Rajagopal, Ram</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The increasing integration of distributed energy resources (DERs) calls for
new monitoring and operational planning tools to ensure stability and
sustainability in distribution grids. One idea is to use existing monitoring
tools in transmission grids and some primary distribution grids. However, they
usually depend on the knowledge of the system model, e.g., the topology and
line parameters, which may be unavailable in primary and secondary distribution
grids. Furthermore, a utility usually has limited modeling ability of active
controllers for solar panels as they may belong to a third party like
residential customers. To solve the modeling problem in traditional power flow
analysis, we propose a support vector regression (SVR) approach to reveal the
mapping rules between different variables and recover useful variables based on
physical understanding and data mining. We illustrate the advantages of using
the SVR model over traditional regression method which finds line parameters in
distribution grids. Specifically, the SVR model is robust enough to recover the
mapping rules while the regression method fails when 1) there are measurement
outliers and missing data, 2) there are active controllers, or 3) measurements
are only available at some part of a distribution grid. We demonstrate the
superior performance of our method through extensive numerical validation on
different scales of distribution grids.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07948</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07951</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>McFSM: Globally Taming Complex Systems</dc:title>
 <dc:creator>Murr, Florian</dc:creator>
 <dc:creator>Mauerer, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Industrial computing devices, in particular cyber-physical, real-time and
safety-critical systems, focus on reacting to external events and the need to
cooperate with other devices to create a functional system. They are often
implemented with languages that focus on a simple, local description of how a
component reacts to external input data and stimuli. Despite the trend in
modern software architectures to structure systems into largely independent
components, the remaining interdependencies still create rich behavioural
dynamics even for small systems. Standard and industrial programming approaches
do usually not model or extensively describe the global properties of an entire
system. Although a large number of approaches to solve this dilemma have been
suggested, it remains a hard and error-prone task to implement systems with
complex interdependencies correctly.
  We introduce multiple coupled finite state machines (McFSMs), a novel
mechanism that allows us to model and manage such interdependencies. It is
based on a consistent, well-structured and simple global description. A sound
theoretical foundation is provided, and associated tools allow us to generate
efficient low-level code in various programming languages using model-driven
techniques. We also present a domain specific language to express McFSMs and
their connections to other systems, to model their dynamic behaviour, and to
investigate their efficiency and correctness at compile-time.
</dc:description>
 <dc:description>Comment: To appear in SEsCPS@ICSE2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07956</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generative Adversarial Active Learning</dc:title>
 <dc:creator>Zhu, Jia-Jie</dc:creator>
 <dc:creator>Bento, Jos&#xe9;</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new active learning by query synthesis approach using Generative
Adversarial Networks (GAN). Different from regular active learning, the
resulting algorithm adaptively synthesizes training instances for querying to
increase learning speed. We generate queries according to the uncertainty
principle, but our idea can work with other active learning principles. We
report results from various numerical experiments to demonstrate the
effectiveness the proposed approach. In some settings, the proposed algorithm
outperforms traditional pool-based approaches. To the best our knowledge, this
is the first active learning work using GAN.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07958</identifier>
 <datestamp>2018-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Online Bandit Multiclass Learning with $\tilde{O}(\sqrt{T})$
  Regret</dc:title>
 <dc:creator>Beygelzimer, Alina</dc:creator>
 <dc:creator>Orabona, Francesco</dc:creator>
 <dc:creator>Zhang, Chicheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present an efficient second-order algorithm with
$\tilde{O}(\frac{1}{\eta}\sqrt{T})$ regret for the bandit online multiclass
problem. The regret bound holds simultaneously with respect to a family of loss
functions parameterized by $\eta$, for a range of $\eta$ restricted by the norm
of the competitor. The family of loss functions ranges from hinge loss
($\eta=0$) to squared hinge loss ($\eta=1$). This provides a solution to the
open problem of (J. Abernethy and A. Rakhlin. An efficient bandit algorithm for
$\sqrt{T}$-regret in online multiclass prediction? In COLT, 2009). We test our
algorithm experimentally, showing that it also performs favorably against
earlier algorithms.
</dc:description>
 <dc:description>Comment: 22 pages, 2 figures; ICML 2017; this version includes additional
  discussions of Newtron, and a variant of SOBA that directly uses an online
  exp-concave optimization oracle</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2018-01-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07959</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised Learning of Labeled Pointcloud Differences via Cover-Tree
  Entropy Reduction</dc:title>
 <dc:creator>Smith, Abraham</dc:creator>
 <dc:creator>Bendich, Paul</dc:creator>
 <dc:creator>Harer, John</dc:creator>
 <dc:creator>Pieloch, Alex</dc:creator>
 <dc:creator>Hineman, Jay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H30, 60G55</dc:subject>
 <dc:description>  We introduce a new algorithm, called CDER, for supervised machine learning
that merges the multi-scale geometric properties of Cover Trees with the
information-theoretic properties of entropy. CDER applies to a training set of
labeled pointclouds embedded in a common Euclidean space. If typical
pointclouds corresponding to distinct labels tend to differ at any scale in any
sub-region, CDER can identify these differences in (typically) linear time,
creating a set of distributional coordinates which act as a feature extraction
mechanism for supervised learning. We describe theoretical properties and
implementation details of CDER, and illustrate its benefits on several
synthetic examples.
</dc:description>
 <dc:description>Comment: Distribution Statement A - Approved for public release, distribution
  is unlimited. Version 2: added link to code, and some minor improvements.
  Version 3: updated authors and thanks</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07960</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citation personal display: A case study of personal websites by
  physicists in 11 well-known universities</dc:title>
 <dc:creator>Li, Xingchen</dc:creator>
 <dc:creator>Wu, Qiang</dc:creator>
 <dc:creator>Zhang, Nan</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This paper aims to investigate the extent to which researchers display
citation, and wants to examine whether there are researcher differences in
citation personal display at the level of university, country, and academic
rank. Physicists in 11 well-known universities in USA, Britain, and China were
chosen as the object of study. It was manually identified if physicists had
mentioned citation counts, citation-based indices, or a link to Google Scholar
Citations (GSC) on the personal websites. A chi-square test is constructed to
test researcher differences in citation personal display. Results showed that
the overall proportion of citation personal display is not high (14.8%), with
129 of 870 physicists displaying citation. And physicists from different
well-known universities indeed had a significant difference in citation
personal display. Moreover, at the national level, it was noticed that
physicists in well-known Chinese universities had the highest level of citation
personal display, followed by Britain and the USA. Further, this study also
found that researchers who had the academic rank of professor had the highest
citation personal display. In addition, the differences in h-index personal
display by university, country or academic rank were analyzed, and the results
showed that they were not statistically significant.
</dc:description>
 <dc:description>Comment: 25 pages, 4 figures, Journal of Documentation, 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07961</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Efficient Multiway Mergesort for GPU Architectures</dc:title>
 <dc:creator>Casanova, Henri</dc:creator>
 <dc:creator>Iacono, John</dc:creator>
 <dc:creator>Karsin, Ben</dc:creator>
 <dc:creator>Sitchinava, Nodari</dc:creator>
 <dc:creator>Weichert, Volker</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Sorting is a primitive operation that is a building block for countless
algorithms. As such, it is important to design sorting algorithms that approach
peak performance on a range of hardware architectures. Graphics Processing
Units (GPUs) are particularly attractive architectures as they provides massive
parallelism and computing power. However, the intricacies of their compute and
memory hierarchies make designing GPU-efficient algorithms challenging. In this
work we present GPU Multiway Mergesort (MMS), a new GPU-efficient multiway
mergesort algorithm. MMS employs a new partitioning technique that exposes the
parallelism needed by modern GPU architectures. To the best of our knowledge,
MMS is the first sorting algorithm for the GPU that is asymptotically optimal
in terms of global memory accesses and that is completely free of shared memory
bank conflicts.
  We realize an initial implementation of MMS, evaluate its performance on
three modern GPU architectures, and compare it to competitive implementations
available in state-of-the-art GPU libraries. Despite these implementations
being highly optimized, MMS compares favorably, achieving performance
improvements for most random inputs. Furthermore, unlike MMS, state-of-the-art
algorithms are susceptible to bank conflicts. We find that for certain inputs
that cause these algorithms to incur large numbers of bank conflicts, MMS can
achieve up to a 37.6% speedup over its fastest competitor. Overall, even though
its current implementation is not fully optimized, due to its efficient use of
the memory hierarchy, MMS outperforms the fastest comparison-based sorting
implementations available to date.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07961</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07963</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatially Aware Melanoma Segmentation Using Hybrid Deep Learning
  Techniques</dc:title>
 <dc:creator>Attia, M.</dc:creator>
 <dc:creator>Hossny, M.</dc:creator>
 <dc:creator>Nahavandi, S.</dc:creator>
 <dc:creator>Yazdabadi, A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we proposed using a hybrid method that utilises deep
convolutional and recurrent neural networks for accurate delineation of skin
lesion of images supplied with ISBI 2017 lesion segmentation challenge. The
proposed method was trained using 1800 images and tested on 150 images from
ISBI 2017 challenge.
</dc:description>
 <dc:description>Comment: ISIC2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07965</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Frequency Control with Operational Constraints, Part I:
  Per-Node Power Balance</dc:title>
 <dc:creator>Wang, Zhaojian</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Low, Steven H.</dc:creator>
 <dc:creator>Zhao, Changhong</dc:creator>
 <dc:creator>Mei, Shengwei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper addresses the distributed optimal frequency control of multi-area
power system with operational constraints, including the regulation capacity of
individual control area and the power limits on tie-lines. Both generators and
controllable loads are utilized to recover nominal frequencies while minimizing
regulation cost. We study two control modes:the per-node balance mode and the
network balance mode. In Part I of the paper, we only consider the per-node
balance case, where we derive a completely decentralized strategy without the
need for communication between control areas. It can adapt to unknown load
disturbance. The tie-line powers are restored after load disturbance, while the
regulation capacity constraints are satisfied both at equilibrium and during
transient. We show that the closed-loop systems with the proposed control
strategies carry out primal-dual updates for solving the associated centralized
frequency optimization problems. We further prove the closed-loop systems are
asymptotically stable and converge to the unique optimal solution of the
centralized frequency optimization problems and their duals. Finally, we
present simulation results to demonstrate the effectiveness of our design. In
Part II of the paper, we address the network power balance case, where
transmission congestions are managed continuously.
</dc:description>
 <dc:description>Comment: 12 pages, 5 figures</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07966</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Globally Optimal Gradient Descent for a ConvNet with Gaussian Inputs</dc:title>
 <dc:creator>Brutzkus, Alon</dc:creator>
 <dc:creator>Globerson, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep learning models are often successfully trained using gradient descent,
despite the worst case hardness of the underlying non-convex optimization
problem. The key question is then under what conditions can one prove that
optimization will succeed. Here we provide a strong result of this kind. We
consider a neural net with one hidden layer and a convolutional structure with
no overlap and a ReLU activation function. For this architecture we show that
learning is NP-complete in the general case, but that when the input
distribution is Gaussian, gradient descent converges to the global optimum in
polynomial time. To the best of our knowledge, this is the first global
optimality guarantee of gradient descent on a convolutional neural network with
ReLU activations.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07969</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Related Pins at Pinterest: The Evolution of a Real-World Recommender
  System</dc:title>
 <dc:creator>Liu, David C.</dc:creator>
 <dc:creator>Rogers, Stephanie</dc:creator>
 <dc:creator>Shiau, Raymond</dc:creator>
 <dc:creator>Kislyuk, Dmitry</dc:creator>
 <dc:creator>Ma, Kevin C.</dc:creator>
 <dc:creator>Zhong, Zhigang</dc:creator>
 <dc:creator>Liu, Jenny</dc:creator>
 <dc:creator>Jing, Yushi</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Related Pins is the Web-scale recommender system that powers over 40% of user
engagement on Pinterest. This paper is a longitudinal study of three years of
its development, exploring the evolution of the system and its components from
prototypes to present state. Each component was originally built with many
constraints on engineering effort and computational resources, so we
prioritized the simplest and highest-leverage solutions. We show how organic
growth led to a complex system and how we managed this complexity. Many
challenges arose while building this system, such as avoiding feedback loops,
evaluating performance, activating content, and eliminating legacy heuristics.
Finally, we offer suggestions for tackling these challenges when engineering
Web-scale recommender systems.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07971</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Seeing What Is Not There: Learning Context to Determine Where Objects
  Are Missing</dc:title>
 <dc:creator>Sun, Jin</dc:creator>
 <dc:creator>Jacobs, David W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most of computer vision focuses on what is in an image. We propose to train a
standalone object-centric context representation to perform the opposite task:
seeing what is not there. Given an image, our context model can predict where
objects should exist, even when no object instances are present. Combined with
object detection results, we can perform a novel vision task: finding where
objects are missing in an image. Our model is based on a convolutional neural
network structure. With a specially designed training strategy, the model
learns to ignore objects and focus on context only. It is fully convolutional
thus highly efficient. Experiments show the effectiveness of the proposed
approach in one important accessibility task: finding city street regions where
curb ramps are missing, which could help millions of people with mobility
disabilities.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07973</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-scale Spectrum Sensing in Small-Cell mm-Wave Cognitive Wireless
  Networks</dc:title>
 <dc:creator>Michelusi, Nicolo</dc:creator>
 <dc:creator>Nokleby, Matthew</dc:creator>
 <dc:creator>Mitra, Urbashi</dc:creator>
 <dc:creator>Calderbank, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a multi-scale approach to spectrum sensing in cognitive
cellular networks is proposed. In order to overcome the huge cost incurred in
the acquisition of full network state information, a hierarchical scheme is
proposed, based on which local state estimates are aggregated up the hierarchy
to obtain aggregate state information at multiple scales, which are then sent
back to each cell for local decision making. Thus, each cell obtains
fine-grained estimates of the channel occupancies of nearby cells, but
coarse-grained estimates of those of distant cells. The performance of the
aggregation scheme is studied in terms of the trade-off between the throughput
achievable by secondary users and the interference generated by the activity of
these secondary users to primary users. In order to account for the irregular
structure of interference patterns arising from path loss, shadowing, and
blockages, which are especially relevant in millimeter wave networks, a greedy
algorithm is proposed to find a multi-scale aggregation tree to optimize the
performance. It is shown numerically that this tailored hierarchy outperforms a
regular tree construction by 60%.
</dc:description>
 <dc:description>Comment: To appear on ICC 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07973</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07975</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building Fast and Compact Convolutional Neural Networks for Offline
  Handwritten Chinese Character Recognition</dc:title>
 <dc:creator>Xiao, Xuefeng</dc:creator>
 <dc:creator>Jin, Lianwen</dc:creator>
 <dc:creator>Yang, Yafeng</dc:creator>
 <dc:creator>Yang, Weixin</dc:creator>
 <dc:creator>Sun, Jun</dc:creator>
 <dc:creator>Chang, Tianhai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Like other problems in computer vision, offline handwritten Chinese character
recognition (HCCR) has achieved impressive results using convolutional neural
network (CNN)-based methods. However, larger and deeper networks are needed to
deliver state-of-the-art results in this domain. Such networks intuitively
appear to incur high computational cost, and require the storage of a large
number of parameters, which renders them unfeasible for deployment in portable
devices. To solve this problem, we propose a Global Supervised Low-rank
Expansion (GSLRE) method and an Adaptive Drop-weight (ADW) technique to solve
the problems of speed and storage capacity. We design a nine-layer CNN for HCCR
consisting of 3,755 classes, and devise an algorithm that can reduce the
networks computational cost by nine times and compress the network to 1/18 of
the original size of the baseline model, with only a 0.21% drop in accuracy. In
tests, the proposed algorithm surpassed the best single-network performance
reported thus far in the literature while requiring only 2.3 MB for storage.
Furthermore, when integrated with our effective forward implementation, the
recognition of an offline character image took only 9.7 ms on a CPU. Compared
with the state-of-the-art CNN model for HCCR, our approach is approximately 30
times faster, yet 10 times more cost efficient.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07976</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ratio Utility and Cost Analysis for Privacy Preserving Subspace
  Projection</dc:title>
 <dc:creator>Al, Mert</dc:creator>
 <dc:creator>Wan, Shibiao</dc:creator>
 <dc:creator>Kung, Sun-Yuan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  With a rapidly increasing number of devices connected to the internet, big
data has been applied to various domains of human life. Nevertheless, it has
also opened new venues for breaching users' privacy. Hence it is highly
required to develop techniques that enable data owners to privatize their data
while keeping it useful for intended applications. Existing methods, however,
do not offer enough flexibility for controlling the utility-privacy trade-off
and may incur unfavorable results when privacy requirements are high. To tackle
these drawbacks, we propose a compressive-privacy based method, namely RUCA
(Ratio Utility and Cost Analysis), which can not only maximize performance for
a privacy-insensitive classification task but also minimize the ability of any
classifier to infer private information from the data. Experimental results on
Census and Human Activity Recognition data sets demonstrate that RUCA
significantly outperforms existing privacy preserving data projection
techniques for a wide range of privacy pricings.
</dc:description>
 <dc:description>Comment: Submitted to ICASSP 2017</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07979</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Customising Agent Based Analysis Towards Analysis of Disaster Management
  Knowledge</dc:title>
 <dc:creator>Inan, Dedi Iskandar</dc:creator>
 <dc:creator>Beydoun, Ghassan</dc:creator>
 <dc:creator>Opper, Simon</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In developed countries such as Australia, for recurring disasters (e.g.
floods), there are dedicated document repositories of Disaster Management Plans
(DISPLANs), and supporting doctrine and processes that are used to prepare
organisations and communities for disasters. They are maintained on an ongoing
cyclical basis and form a key information source for community education,
engagement and awareness programme in the preparation for and mitigation of
disasters. DISPLANS, generally in semi-structured text document format, are
then accessed and activated during the response and recovery to incidents to
coordinate emergency service and community safety actions. However, accessing
the appropriate plan and the specific knowledge within the text document from
across its conceptual areas in a timely manner and sharing activities between
stakeholders requires intimate domain knowledge of the plan contents and its
development. This paper describes progress on an ongoing project with NSW State
Emergency Service (NSW SES) to convert DISPLANs into a collection of knowledge
units that can be stored in a unified repository with the goal to form the
basis of a future knowledge sharing capability. All Australian emergency
services covering a wide range of hazards develop DISPLANs of various structure
and intent, in general the plans are created as instances of a template, for
example those which are developed centrally by the NSW and Victorian SESs State
planning policies. In this paper, we illustrate how by using selected templates
as part of an elaborate agent-based process, we can apply agent-oriented
analysis more efficiently to convert extant DISPLANs into a centralised
repository. The repository is structured as a layered abstraction according to
Meta Object Facility (MOF). The work is illustrated using DISPLANs along the
flood-prone Murrumbidgee River in central NSW.
</dc:description>
 <dc:description>Comment: Australasian Conference on Information Systems 2016</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07983</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maximum-Likelihood Augmented Discrete Generative Adversarial Networks</dc:title>
 <dc:creator>Che, Tong</dc:creator>
 <dc:creator>Li, Yanran</dc:creator>
 <dc:creator>Zhang, Ruixiang</dc:creator>
 <dc:creator>Hjelm, R Devon</dc:creator>
 <dc:creator>Li, Wenjie</dc:creator>
 <dc:creator>Song, Yangqiu</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite the successes in capturing continuous distributions, the application
of generative adversarial networks (GANs) to discrete settings, like natural
language tasks, is rather restricted. The fundamental reason is the difficulty
of back-propagation through discrete random variables combined with the
inherent instability of the GAN training objective. To address these problems,
we propose Maximum-Likelihood Augmented Discrete Generative Adversarial
Networks. Instead of directly optimizing the GAN objective, we derive a novel
and low-variance objective using the discriminator's output that follows
corresponds to the log-likelihood. Compared with the original, the new
objective is proved to be consistent in theory and beneficial in practice. The
experimental results on various discrete datasets demonstrate the effectiveness
of the proposed approach.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07983</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07984</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Local Voting for Collective Decision-making in Continuous
  Spaces</dc:title>
 <dc:creator>Garg, Nikhil</dc:creator>
 <dc:creator>Kamble, Vijay</dc:creator>
 <dc:creator>Goel, Ashish</dc:creator>
 <dc:creator>Marn, David</dc:creator>
 <dc:creator>Munagala, Kamesh</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Many societal decision problems lie in high-dimensional continuous spaces not
amenable to the voting techniques common for their discrete or
single-dimensional counterparts. These problems are typically discretized
before running an election or decided upon through negotiation by
representatives. We propose a meta-algorithm called Iterative Local Voting for
collective decision-making in this setting, in which voters are sequentially
sampled and asked to modify a candidate solution within some local neighborhood
of its current value, as defined by a ball in some chosen norm. In general,
such schemes do not converge, or, when they do, the resulting solution does not
have a natural description.
  We first prove the convergence of this algorithm under appropriate choices of
neighborhoods to plausible solutions in certain natural settings: when the
voters' utilities can be expressed in terms of some form of distance from their
ideal solution, and when these utilities are additively decomposable across
dimensions. In many of these cases, we obtain convergence to the societal
welfare maximizing solution.
  We then describe an experiment in which we test our algorithm for the
decision of the U.S. Federal Budget on Mechanical Turk with over 4,000 workers,
employing neighborhoods defined by $\mathcal{L}^1, \mathcal{L}^2$ and
$\mathcal{L}^\infty$ balls. We make several observations that inform future
implementations of such a procedure.
</dc:description>
 <dc:description>Comment: 34 pages, 12 figures</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07985</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-task convolutional neural network for mega-city analysis using
  very high resolution satellite imagery and geospatial data</dc:title>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Du, Bo</dc:creator>
 <dc:creator>Zhang, Liangpei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mega-city analysis with very high resolution (VHR) satellite images has been
drawing increasing interest in the fields of city planning and social
investigation. It is known that accurate land-use, urban density, and
population distribution information is the key to mega-city monitoring and
environmental studies. Therefore, how to generate land-use, urban density, and
population distribution maps at a fine scale using VHR satellite images has
become a hot topic. Previous studies have focused solely on individual tasks
with elaborate hand-crafted features and have ignored the relationship between
different tasks. In this study, we aim to propose a universal framework which
can: 1) automatically learn the internal feature representation from the raw
image data; and 2) simultaneously produce fine-scale land-use, urban density,
and population distribution maps. For the first target, a deep convolutional
neural network (CNN) is applied to learn the hierarchical feature
representation from the raw image data. For the second target, a novel
CNN-based universal framework is proposed to process the VHR satellite images
and generate the land-use, urban density, and population distribution maps. To
the best of our knowledge, this is the first CNN-based mega-city analysis
method which can process a VHR remote sensing image with such a large data
volume. A VHR satellite image (1.2 m spatial resolution) of the center of Wuhan
covering an area of 2606 km2 was used to evaluate the proposed method. The
experimental results confirm that the proposed method can achieve a promising
accuracy for land-use, urban density, and population distribution maps.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07992</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplified Biased Contribution Index (SBCI): A Mechanism to Make P2P
  Network Fair and Efficient for Resource Sharing</dc:title>
 <dc:creator>Awasthi, Sateesh Kumar</dc:creator>
 <dc:creator>Singh, Yatindra Nath</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  To balance the load and to discourage the free-riding in peer-to-peer (P2P)
networks, many incentive mechanisms and policies have been proposed in recent
years. Global peer ranking is one such mechanism. In this mechanism, peers are
ranked based on a metric called contribution index. Contribution index is
defined in such a manner that peers are motivated to share the resources in the
network. Fairness in the terms of upload to download ratio in each peer can be
achieved by this method. However, calculation of contribution index is not
trivial. It is computed distributively and iteratively in the entire network
and requires strict clock synchronization among the peers. A very small error
in clock synchronization may lead to wrong results. Furthermore, iterative
calculation requires a lot of message overhead and storage capacity, which
makes its implementation more complex. In this paper, we are proposing a simple
incentive mechanism based on the contributions of peers, which can balance the
upload and download amount of resources in each peer. It does not require
iterative calculation, therefore, can be implemented with lesser message
overhead and storage capacity without requiring strict clock synchronization.
This approach is efficient as there are very less rejections among the
cooperative peers. It can be implemented in a truly distributed fashion with
$O(N)$ time complexity per peer.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07992</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.07998</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting (Un)Important Content for Single-Document News Summarization</dc:title>
 <dc:creator>Yang, Yinfei</dc:creator>
 <dc:creator>Bao, Forrest Sheng</dc:creator>
 <dc:creator>Nenkova, Ani</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present a robust approach for detecting intrinsic sentence importance in
news, by training on two corpora of document-summary pairs. When used for
single-document summarization, our approach, combined with the &quot;beginning of
document&quot; heuristic, outperforms a state-of-the-art summarizer and the
beginning-of-article baseline in both automatic and manual evaluations. These
results represent an important advance because in the absence of cross-document
repetition, single document summarizers for news have not been able to
consistently outperform the strong beginning-of-article baseline.
</dc:description>
 <dc:description>Comment: Accepted By EACL 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.07998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08000</identifier>
 <datestamp>2017-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kiefer Wolfowitz Algorithm is Asymptotically Optimal for a Class of
  Non-Stationary Bandit Problems</dc:title>
 <dc:creator>Singh, Rahul</dc:creator>
 <dc:creator>Banerjee, Taposh</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of designing an allocation rule or an &quot;online
learning algorithm&quot; for a class of bandit problems in which the set of control
actions available at each time $s$ is a convex, compact subset of
$\mathbb{R}^d$. Upon choosing an action $x$ at time $s$, the algorithm obtains
a noisy value of the unknown and time-varying function $f_s$ evaluated at $x$.
The &quot;regret&quot; of an algorithm is the gap between its expected reward, and the
reward earned by a strategy which has the knowledge of the function $f_s$ at
each time $s$ and hence chooses the action $x_s$ that maximizes $f_s$.
  For this non-stationary bandit problem set-up, we consider two variants of
the Kiefer Wolfowitz (KW) algorithm i) KW with fixed step-size $\beta$, and ii)
KW with sliding window of length $L$. We show that if the number of times that
the function $f_s$ varies during time $T$ is $o(T)$, and if the learning rates
of the proposed algorithms are chosen &quot;optimally&quot;, then the regret of the
proposed algorithms is $o(T)$, and hence the algorithms are asymptotically
efficient.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08001</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Nonparametric Feature and Policy Learning for Decision-Making</dc:title>
 <dc:creator>Hahn, J&#xfc;rgen</dc:creator>
 <dc:creator>Zoubir, Abdelhak M.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Learning from demonstrations has gained increasing interest in the recent
past, enabling an agent to learn how to make decisions by observing an
experienced teacher. While many approaches have been proposed to solve this
problem, there is only little work that focuses on reasoning about the observed
behavior. We assume that, in many practical problems, an agent makes its
decision based on latent features, indicating a certain action. Therefore, we
propose a generative model for the states and actions. Inference reveals the
number of features, the features, and the policies, allowing us to learn and to
analyze the underlying structure of the observed behavior. Further, our
approach enables prediction of actions for new states. Simulations are used to
assess the performance of the algorithm based upon this model. Moreover, the
problem of learning a driver's behavior is investigated, demonstrating the
performance of the proposed model in a real-world scenario.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08003</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Random Coding Exponents and Universal Decoders for the Asymmetric
  Broadcast Channel</dc:title>
 <dc:creator>Averbuch, Ran</dc:creator>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work contains two main contributions concerning the asymmetric broadcast
channel. The first is an analysis of the exact random coding error exponents
for both users, and the second is the derivation of universal decoders for both
users. These universal decoders are certain variants of the maximum mutual
information (MMI) universal decoder, which achieve the corresponding random
coding exponents of optimal decoding. In addition, we introduce some lower
bounds, which involve optimization over very few parameters, unlike the
original, exact exponents, which involve minimizations over auxiliary
probability distributions. Numerical results for the binary symmetric broadcast
channel show improvements over previously derived error exponents for the same
model.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08004</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Software Repository and Toolset for Empirical Research</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>68N01</dc:subject>
 <dc:subject>D.2.0</dc:subject>
 <dc:description>  This paper proposes a software repository model together with associated
tooling and consists of several complex, open-source GUI driven applications
ready to be used in empirical software research. We start by providing the
rationale for our repository and criteria that guided us in searching for
suitable applications. We detail the model of the repository together with
associated artifacts and supportive tooling. We detail current applications in
the repository together with ways in which it can be further extended. Finally
we provide examples of how our repository facilitates research in software
visualization and testing.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08004</dc:identifier>
 <dc:identifier>Studia Informatica UBB, Vol. LVII, Nr. 1, 2012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08005</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achievement and Friends: Key Factors of Player Retention Vary Across
  Player Levels in Online Multiplayer Games</dc:title>
 <dc:creator>Park, Kunwoo</dc:creator>
 <dc:creator>Cha, Meeyoung</dc:creator>
 <dc:creator>Kwak, Haewoon</dc:creator>
 <dc:creator>Chen, Kuan-Ta</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Retaining players over an extended period of time is a long-standing
challenge in game industry. Significant effort has been paid to understanding
what motivates players enjoy games. While individuals may have varying reasons
to play or abandon a game at different stages within the game, previous studies
have looked at the retention problem from a snapshot view. This study, by
analyzing in-game logs of 51,104 distinct individuals in an online multiplayer
game, uniquely offers a multifaceted view of the retention problem over the
players' virtual life phases. We find that key indicators of longevity change
with the game level. Achievement features are important for players at the
initial to the advanced phases, yet social features become the most predictive
of longevity once players reach the highest level offered by the game. These
findings have theoretical and practical implications for designing online games
that are adaptive to meeting the players' needs.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, WWW '17 companion</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08006</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CRSTIP - An Assessment Scheme for Security Assessment Processes</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:creator>Gro&#xdf;mann, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>C.2.0</dc:subject>
 <dc:description>  Complex networked systems are an integral part of today's support
infrastructures. Due to their importance, these systems become more and more
the target for cyber-attacks, suffering a notable number of security incidents.
Also, they are subject to regulation by national and international legislation.
An operator of such an infrastructure or system is responsible for ensuring its
security and correct functioning in order to satisfy customers. In addition,
the entire process of risk and quality control needs to be efficient and
manageable. This short paper introduces the Compliance, Risk Assessment and
Security Testing Improvement Profiling (CRSTIP) scheme. CRSTIP is an evaluation
scheme that enables assessing the maturity of security assessment processes,
taking into consideration systematic use of formalisms, integration and
tool-support in the areas of compliance assessment, security risk assessment
and security testing. The paper describes the elements of the scheme and their
application to one of the case studies of the RASEN research project.
</dc:description>
 <dc:description>Comment: IEEE International Symposium on Software Reliability Engineering
  Workshops (ISSREW), 2014</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08006</dc:identifier>
 <dc:identifier>doi:10.1109/ISSREW.2014.16</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08007</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Nonparametric Unmixing of Hyperspectral Images</dc:title>
 <dc:creator>Hahn, J&#xfc;rgen</dc:creator>
 <dc:creator>Zoubir, Abdelhak M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hyperspectral imaging is an important tool in remote sensing, allowing for
accurate analysis of vast areas. Due to a low spatial resolution, a pixel of a
hyperspectral image rarely represents a single material, but rather a mixture
of different spectra. HSU aims at estimating the pure spectra present in the
scene of interest, referred to as endmembers, and their fractions in each
pixel, referred to as abundances. Today, many HSU algorithms have been
proposed, based either on a geometrical or statistical model. While most
methods assume that the number of endmembers present in the scene is known,
there is only little work about estimating this number from the observed data.
In this work, we propose a Bayesian nonparametric framework that jointly
estimates the number of endmembers, the endmembers itself, and their
abundances, by making use of the Indian Buffet Process as a prior for the
endmembers. Simulation results and experiments on real data demonstrate the
effectiveness of the proposed algorithm, yielding results comparable with
state-of-the-art methods while being able to reliably infer the number of
endmembers. In scenarios with strong noise, where other algorithms provide only
poor results, the proposed approach tends to overestimate the number of
endmembers slightly. The additional endmembers, however, often simply represent
noisy replicas of present endmembers and could easily be merged in a
post-processing step.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08008</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JETracer - A Framework for Java GUI Event Tracing</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:description>  The present paper introduces the open-source Java Event Tracer (JETracer)
framework for real-time tracing of GUI events within applications based on the
AWT, Swing or SWT graphical toolkits. Our framework provides a common event
model for supported toolkits, the possibility of receiving GUI events in
real-time, good performance in the case of complex target applications and the
possibility of deployment over a network. The present paper provides the
rationale for JETracer, presents related research and details its technical
implementation. An empirical evaluation where JETracer is used to trace GUI
events within five popular, open-source applications is also presented.
</dc:description>
 <dc:description>Comment: Proceedings of ENASE 2015, ISBN: 978-989-758-100-7</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08008</dc:identifier>
 <dc:identifier>doi:10.5220/0005372902070214</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08009</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyzing Modular CNN Architectures for Joint Depth Prediction and
  Semantic Segmentation</dc:title>
 <dc:creator>Jafari, Omid Hosseini</dc:creator>
 <dc:creator>Groth, Oliver</dc:creator>
 <dc:creator>Kirillov, Alexander</dc:creator>
 <dc:creator>Yang, Michael Ying</dc:creator>
 <dc:creator>Rother, Carsten</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper addresses the task of designing a modular neural network
architecture that jointly solves different tasks. As an example we use the
tasks of depth estimation and semantic segmentation given a single RGB image.
The main focus of this work is to analyze the cross-modality influence between
depth and semantic prediction maps on their joint refinement. While most
previous works solely focus on measuring improvements in accuracy, we propose a
way to quantify the cross-modality influence. We show that there is a
relationship between final accuracy and cross-modality influence, although not
a simple linear one. Hence a larger cross-modality influence does not
necessarily translate into an improved accuracy. We find that a beneficial
balance between the cross-modality influences can be achieved by network
architecture and conjecture that this relationship can be utilized to
understand different network design choices. Towards this end we propose a
Convolutional Neural Network (CNN) architecture that fuses the state of the
state-of-the-art results for depth estimation and semantic labeling. By
balancing the cross-modality influences between depth and semantic prediction,
we achieve improved results for both tasks using the NYU-Depth v2 benchmark.
</dc:description>
 <dc:description>Comment: Accepted to ICRA 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08010</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preventing Hospital Acquired Infections Through a Workflow-Based
  Cyber-Physical System</dc:title>
 <dc:creator>Bocicor, Maria Iuliana</dc:creator>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:creator>Taslitchi, Cristian</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>D.2.2, J.3</dc:subject>
 <dc:description>  Hospital acquired infections (HAI) are infections acquired within the
hospital from healthcare workers, patients or from the environment, but which
have no connection to the initial reason for the patient's hospital admission.
HAI are a serious world-wide problem, leading to an increase in mortality
rates, duration of hospitalisation as well as significant economic burden on
hospitals. Although clear preventive guidelines exist, studies show that
compliance to them is frequently poor. This paper details the software
perspective for an innovative, business process software based cyber-physical
system that will be implemented as part of a European Union-funded research
project. The system is composed of a network of sensors mounted in different
sites around the hospital, a series of wearables used by the healthcare workers
and a server side workflow engine. For better understanding, we describe the
system through the lens of a single, simple clinical workflow that is
responsible for a significant portion of all hospital infections. The goal is
that when completed, the system will be configurable in the sense of
facilitating the creation and automated monitoring of those clinical workflows
that when combined, account for over 90\% of hospital infections.
</dc:description>
 <dc:description>Comment: Proceedings of ENASE 2016, ISBN: 978-989-758-189-2</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08010</dc:identifier>
 <dc:identifier>doi:10.5220/0005916900630068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08013</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Live Visualization of GUI Application Code Coverage with GUITracer</dc:title>
 <dc:creator>Molnar, Arthur-Jozsef</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:description>  The present paper introduces the initial implementation of a software
exploration tool targeting graphical user interface (GUI) driven applications.
GUITracer facilitates the comprehension of GUI-driven applications by starting
from their most conspicuous artefact - the user interface itself. The current
implementation of the tool can be used with any Java-based target application
that employs one of the AWT, Swing or SWT toolkits. The tool transparently
instruments the target application and provides real time information about the
GUI events fired. For each event, call relations within the application are
displayed at method, class or package level, together with detailed coverage
information. The tool facilitates feature location, program comprehension as
well as GUI test creation by revealing the link between the application's GUI
and its underlying code. As such, GUITracer is intended for software
practitioners developing or maintaining GUI-driven applications. We believe our
tool to be especially useful for entry-level practitioners as well as students
seeking to understand complex GUI-driven software systems. The present paper
details the rationale as well as the technical implementation of the tool. As a
proof-of-concept implementation, we also discuss further development that can
lead to our tool's integration into a software development workflow.
</dc:description>
 <dc:description>Comment: http://ieeexplore.ieee.org/document/7332434/</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08013</dc:identifier>
 <dc:identifier>IEEE 3rd Working Conference on Software Visualization (VISSOFT
  2015), September 27-28, 2015, Bremen, Germany; pages 185-189</dc:identifier>
 <dc:identifier>doi:10.1109/VISSOFT.2015.7332434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08014</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Networks for the Detection of Aggressive Prostate Cancer</dc:title>
 <dc:creator>Kohl, Simon</dc:creator>
 <dc:creator>Bonekamp, David</dc:creator>
 <dc:creator>Schlemmer, Heinz-Peter</dc:creator>
 <dc:creator>Yaqubi, Kaneschka</dc:creator>
 <dc:creator>Hohenfellner, Markus</dc:creator>
 <dc:creator>Hadaschik, Boris</dc:creator>
 <dc:creator>Radtke, Jan-Philipp</dc:creator>
 <dc:creator>Maier-Hein, Klaus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic segmentation constitutes an integral part of medical image analyses
for which breakthroughs in the field of deep learning were of high relevance.
The large number of trainable parameters of deep neural networks however
renders them inherently data hungry, a characteristic that heavily challenges
the medical imaging community. Though interestingly, with the de facto standard
training of fully convolutional networks (FCNs) for semantic segmentation being
agnostic towards the `structure' of the predicted label maps, valuable
complementary information about the global quality of the segmentation lies
idle. In order to tap into this potential, we propose utilizing an adversarial
network which discriminates between expert and generated annotations in order
to train FCNs for semantic segmentation. Because the adversary constitutes a
learned parametrization of what makes a good segmentation at a global level, we
hypothesize that the method holds particular advantages for segmentation tasks
on complex structured, small datasets. This holds true in our experiments: We
learn to segment aggressive prostate cancer utilizing MRI images of 152
patients and show that the proposed scheme is superior over the de facto
standard in terms of the detection sensitivity and the dice-score for
aggressive prostate cancer. The achieved relative gains are shown to be
particularly pronounced in the small dataset limit.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures; under review as a conference paper at MICCAI 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08017</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bisimulation Metrics for Weighted Automata</dc:title>
 <dc:creator>Balle, Borja</dc:creator>
 <dc:creator>Gourdeau, Pascale</dc:creator>
 <dc:creator>Panangaden, Prakash</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  We develop a new bisimulation (pseudo)metric for weighted finite automata
(WFA) that generalizes Boreale's linear bisimulation relation. Our metrics are
induced by seminorms on the state space of WFA. Our development is based on
spectral properties of sets of linear operators. In particular, the joint
spectral radius of the transition matrices of WFA plays a central role. We also
study continuity properties of the bisimulation pseudometric, establish an
undecidability result for computing the metric, and give a preliminary account
of applications to spectral learning of weighted automata.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08019</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Support vector machine and its bias correction in high-dimension,
  low-sample-size settings</dc:title>
 <dc:creator>Nakayama, Yugo</dc:creator>
 <dc:creator>Yata, Kazuyoshi</dc:creator>
 <dc:creator>Aoshima, Makoto</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>62H30, 62G20</dc:subject>
 <dc:description>  In this paper, we consider asymptotic properties of the support vector
machine (SVM) in high-dimension, low-sample-size (HDLSS) settings. We show that
the hard-margin linear SVM holds a consistency property in which
misclassification rates tend to zero as the dimension goes to infinity under
certain severe conditions. We show that the SVM is very biased in HDLSS
settings and its performance is affected by the bias directly. In order to
overcome such difficulties, we propose a bias-corrected SVM (BC-SVM). We show
that the BC-SVM gives preferable performances in HDLSS settings. We also
discuss the SVMs in multiclass HDLSS settings. Finally, we check the
performance of the classifiers in actual data analyses.
</dc:description>
 <dc:description>Comment: 23 pages, 3 figures</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08019</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08021</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Friends and Enemies of Clinton and Trump: Using Context for Detecting
  Stance in Political Tweets</dc:title>
 <dc:creator>Lai, Mirko</dc:creator>
 <dc:creator>Far&#xed;as, Delia Iraz&#xfa; Hern&#xe1;ndez</dc:creator>
 <dc:creator>Patti, Viviana</dc:creator>
 <dc:creator>Rosso, Paolo</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Stance detection, the task of identifying the speaker's opinion towards a
particular target, has attracted the attention of researchers. This paper
describes a novel approach for detecting stance in Twitter. We define a set of
features in order to consider the context surrounding a target of interest with
the final aim of training a model for predicting the stance towards the
mentioned targets. In particular, we are interested in investigating political
debates in social media. For this reason we evaluated our approach focusing on
two targets of the SemEval-2016 Task6 on Detecting stance in tweets, which are
related to the political campaign for the 2016 U.S. presidential elections:
Hillary Clinton vs. Donald Trump. For the sake of comparison with the state of
the art, we evaluated our model against the dataset released in the
SemEval-2016 Task 6 shared task competition. Our results outperform the best
ones obtained by participating teams, and show that information about enemies
and friends of politicians help in detecting stance towards them.
</dc:description>
 <dc:description>Comment: To appear in MICAI 2016 LNAI Proceedings</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08021</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08023</identifier>
 <datestamp>2018-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A survey on difference hierarchies of regular languages</dc:title>
 <dc:creator>Carton, Olivier</dc:creator>
 <dc:creator>Perrin, Dominique</dc:creator>
 <dc:creator>Pin, Jean-&#xc9;ric</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q70, 68Q45, 20M35</dc:subject>
 <dc:description>  Difference hierarchies were originally introduced by Hausdorff and they play
an important role in descriptive set theory. In this survey paper, we study
difference hierarchies of regular languages. The first sections describe
standard techniques on difference hierarchies, mostly due to Hausdorff. We
illustrate these techniques by giving decidability results on the difference
hierarchies based on shuffle ideals, strongly cyclic regular languages and the
polynomial closure of group languages.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08033</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Euclidean and Hermitian LCD MDS codes</dc:title>
 <dc:creator>Carlet, Claude</dc:creator>
 <dc:creator>Mesnager, Sihem</dc:creator>
 <dc:creator>Tang, Chunming</dc:creator>
 <dc:creator>Qi, Yanfeng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear codes with complementary duals (abbreviated LCD) are linear codes
whose intersection with their dual is trivial. When they are binary, they play
an important role in armoring implementations against side-channel attacks and
fault injection attacks. Non-binary LCD codes in characteristic 2 can be
transformed into binary LCD codes by expansion. On the other hand, being
optimal codes, maximum distance separable codes (abbreviated MDS) have been of
much interest from many researchers due to their theoretical significant and
practical implications. However, little work has been done on LCD MDS codes. In
particular, determining the existence of $q$-ary $[n,k]$ LCD MDS codes for
various lengths $n$ and dimensions $k$ is a basic and interesting problem. In
this paper, we firstly study the problem of the existence of $q$-ary $[n,k]$
LCD MDS codes and completely solve it for the Euclidean case. More
specifically, we show that for $q&gt;3$ there exists a $q$-ary $[n,k]$ Euclidean
LCD MDS code, where $0\le k \le n\le q+1$, or, $q=2^{m}$, $n=q+2$ and $k= 3
\text{or} q-1$. Secondly, we investigate several constructions of new Euclidean
and Hermitian LCD MDS codes. Our main techniques in constructing Euclidean and
Hermitian LCD MDS codes use some linear codes with small dimension or
codimension, self-orthogonal codes and generalized Reed-Solomon codes.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08037</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Heavy Flows in the SDN Match and Action Model</dc:title>
 <dc:creator>Afek, Yehuda</dc:creator>
 <dc:creator>Bremler-Barr, Anat</dc:creator>
 <dc:creator>Feibish, Shir Landau</dc:creator>
 <dc:creator>Schiff, Liron</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Efficient algorithms and techniques to detect and identify large flows in a
high throughput traffic stream in the SDN match-and-action model are presented.
This is in contrast to previous work that either deviated from the match and
action model by requiring additional switch level capabilities or did not
exploit the SDN data plane. Our construction has two parts; (a) how to sample
in an SDN match and action model, (b) how to detect large flows efficiently and
in a scalable way, in the SDN model.
  Our large flow detection methods provide high accuracy and present a good and
practical tradeoff between switch - controller traffic, and the number of
entries required in the switch flow table. Based on different parameters, we
differentiate between heavy flows, elephant flows and bulky flows and present
efficient algorithms to detect flows of the different types.
  Additionally, as part of our heavy flow detection scheme, we present sampling
methods to sample packets with arbitrary probability $p$ per packet or per byte
that traverses an SDN switch.
  Finally, we show how our algorithms can be adapted to a distributed
monitoring SDN setting with multiple switches, and easily scale with the number
of monitoring switches.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08039</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Criticality &amp; Deep Learning I: Generally Weighted Nets</dc:title>
 <dc:creator>Oprisa, Dan</dc:creator>
 <dc:creator>Toth, Peter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Motivated by the idea that criticality and universality of phase transitions
might play a crucial role in achieving and sustaining learning and intelligent
behaviour in biological and artificial networks, we analyse a theoretical and a
pragmatic experimental set up for critical phenomena in deep learning. On the
theoretical side, we use results from statistical physics to carry out critical
point calculations in feed-forward/fully connected networks, while on the
experimental side we set out to find traces of criticality in deep neural
networks. This is our first step in a series of upcoming investigations to map
out the relationship between criticality and learning in deep networks.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08042</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Instant restore after a media failure</dc:title>
 <dc:creator>Sauer, Caetano</dc:creator>
 <dc:creator>Graefe, Goetz</dc:creator>
 <dc:creator>H&#xe4;rder, Theo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Media failures usually leave database systems unavailable for several hours
until recovery is complete, especially in applications with large devices and
high transaction volume. Previous work introduced a technique called
single-pass restore, which increases restore bandwidth and thus substantially
decreases time to repair. Instant restore goes further as it permits read/write
access to any data on a device undergoing restore--even data not yet
restored--by restoring individual data segments on demand. Thus, the restore
process is guided primarily by the needs of applications, and the observed mean
time to repair is effectively reduced from several hours to a few seconds.
  This paper presents an implementation and evaluation of instant restore. The
technique is incrementally implemented on a system starting with the
traditional ARIES design for logging and recovery. Experiments show that the
transaction latency perceived after a media failure can be cut down to less
than a second and that the overhead imposed by the technique on normal
processing is minimal. The net effect is that a few &quot;nines&quot; of availability are
added to the system using simple and low-overhead software techniques.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08044</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Benefits of Cache Assignment on Degraded Broadcast Channels</dc:title>
 <dc:creator>Bidokhti, Shirin Saeedi</dc:creator>
 <dc:creator>Wigger, Michele</dc:creator>
 <dc:creator>Yener, Aylin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Degraded K-user broadcast channels (BC) are studied when receivers are
facilitated with cache memories. Lower and upper bounds are derived on the
capacity-memory tradeoff, i.e., on the largest rate of reliable communication
over the BC as a function of the receivers' cache sizes, and the bounds are
shown to match for some special cases. The lower bounds are achieved by two new
coding schemes that benefit from non-uniform cache assignment. Lower and upper
bounds are also established on the global capacity-memory tradeoff, i.e., on
the largest capacity-memory tradeoff that can be attained by optimizing the
receivers' cache sizes subject to a total cache memory budget. The bounds
coincide when the total cache memory budget is sufficiently small or
sufficiently large, characterized in terms of the BC statistics. For small
cache memories, it is optimal to assign all the cache memory to the weakest
receiver. In this regime, the global capacity-memory tradeoff grows as the
total cache memory budget divided by the number of files in the system. In
other words, a perfect global caching gain is achievable in this regime and the
performance corresponds to a system where all cache contents in the network are
available to all receivers. For large cache memories, it is optimal to assign a
positive cache memory to every receiver such that the weaker receivers are
assigned larger cache memories compared to the stronger receivers. In this
regime, the growth rate of the global capacity-memory tradeoff is further
divided by the number of users, which corresponds to a local caching gain.
Numerical indicate suggest that a uniform cache-assignment of the total cache
memory is suboptimal in all regimes unless the BC is completely symmetric. For
erasure BCs, this claim is proved analytically in the regime of small
cache-sizes.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08044</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08045</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General Upper Bounds for Gate Complexity and Depth of Reversible
  Circuits Consisting of NOT, CNOT and 2-CNOT Gates</dc:title>
 <dc:creator>Zakablukov, Dmitry V.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The paper discusses the gate complexity and the depth of reversible circuits
consisting of NOT, CNOT and 2-CNOT gates in the case, when the number of
additional inputs is limited. We study Shannon's gate complexity function $L(n,
q)$ and depth function $D(n, q)$ for a reversible circuit implementing a
Boolean transformation $f\colon \mathbb Z_2^n \to \mathbb Z_2^n$ with $8n &lt; q
\lesssim n2^{n-o(n)}$ additional inputs. The general upper bounds $L(n,q)
\lesssim 2^n + 8n2^n \mathop / (\log_2 (q-4n) - \log_2 n - 2)$ and $D(n,q)
\lesssim 2^{n+1}(2,5 + \log_2 n - \log_2 (\log_2 (q - 4n) - \log_2 n - 2))$ are
proved for this case.
</dc:description>
 <dc:description>Comment: In Russian, 19 pages, 5 figures</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-03-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08045</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08051</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Complex Event Processing to Simple Event Processing</dc:title>
 <dc:creator>Hall&#xe9;, Sylvain</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Many problems in Computer Science can be framed as the computation of queries
over sequences, or &quot;streams&quot; of data units called events. The field of Complex
Event Processing (CEP) relates to the techniques and tools developed to
efficiently process these queries. However, most CEP systems developed so far
have concentrated on relatively narrow types of queries, which consist of
sliding windows, aggregation functions, and simple sequential patterns computed
over events that have a fixed tuple structure. Many of them boast throughput,
but in counterpart, they are difficult to setup and cumbersome to extend with
user-defined elements.
  This paper describes a variety of use cases taken from real-world scenarios
that present features seldom considered in classical CEP problems. It also
provides a broad review of current solutions, that includes tools and
techniques going beyond typical surveys on CEP. From a critical analysis of
these solutions, design principles for a new type of event stream processing
system are exposed. The paper proposes a simple, generic and extensible
framework for the processing of event streams of diverse types; it describes in
detail a stream processing engine, called BeepBeep, that implements these
principles. BeepBeep's modular architecture, which borrows concepts from many
other systems, is complemented with an extensible query language, called eSQL.
The end result is an open, versatile, and reasonably efficient query engine
that can be used in situations that go beyond the capabilities of existing
systems.
</dc:description>
 <dc:description>Comment: 40 pages</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08052</identifier>
 <datestamp>2017-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Delay-Optimal Probabilistic Scheduling with Arbitrary Arrival and
  Adaptive Transmission</dc:title>
 <dc:creator>Chen, Xiang</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Lee, Joohyun</dc:creator>
 <dc:creator>Shroff, Ness B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we aim to obtain the optimal delay-power tradeoff and the
corresponding optimal scheduling policy for an arbitrary i.i.d. arrival process
and adaptive transmissions. The number of backlogged packets at the transmitter
is known to a scheduler, who has to determine how many backlogged packets to
transmit during each time slot. The power consumption is assumed to be convex
in transmission rates. Hence, if the scheduler transmits faster, the delay will
be reduced but with higher power consumption. To obtain the optimal delay-power
tradeoff and the corresponding optimal policy, we model the problem as a
Constrained Markov Decision Process (CMDP), where we minimize the average delay
given an average power constraint. By steady-state analysis and Lagrangian
relaxation, we can show that the optimal tradeoff curve is decreasing, convex,
and piecewise linear, and the optimal policy is threshold-based. Based on the
revealed properties of the optimal policy, we develop an algorithm to
efficiently obtain the optimal tradeoff curve and the optimal policy with full
information of the system. The complexity of our proposed algorithm is much
lower than a general algorithm based on Linear Programming. However, usually
the distribution of the arrival process is unknown to the scheduler, therefore
we proposed a reinforcement learning algorithm to efficiently obtain the
optimal policy under this circumstance. We also analyse in details about how
the system parameters affect the optimal policy and the system performance. In
the final, we use simulations to validate the derived results and the proposed
algorithms.
</dc:description>
 <dc:description>Comment: An extended version of our ICC'17 paper. arXiv admin note:
  substantial text overlap with arXiv:1609.03260</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-10-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08053</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Device-to-Device Discovery Scheme for Underlay Cellular Networks</dc:title>
 <dc:creator>Naslcheraghi, Mansour</dc:creator>
 <dc:creator>Marandi, Leila</dc:creator>
 <dc:creator>Ghorashi, Seyed Ali</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Tremendous growing demand for high data rate services such as video, gaming
and social networking in wireless cellular systems, attracted researchers'
attention to focus on developing proximity services. In this regard,
device-to-device (D2D) communications as a promising technology for future
cellular systems, plays crucial rule. The key factor in D2D communication is
providing efficient peer discovery mechanisms in ultra dense networks. In this
paper, we propose a centralized D2D discovery scheme by employing a signaling
algorithm to exchange D2D discovery messages between network entities. In this
system, potential D2D pairs share uplink cellular users' resources with
collision detection, to initiate a D2D links. Stochastic geometry is used to
analyze system performance in terms of success probability of the transmitted
signal and minimum required time slots for the proposed discovery scheme.
Extensive simulations are used to evaluate the proposed system performance.
</dc:description>
 <dc:description>Comment: Accepted for publication in 25'th Iranian Conference on Electrical
  Engineering (ICEE2017)</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08053</dc:identifier>
 <dc:identifier>doi:10.1109/IranianCEE.2017.7985409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08055</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Row-Centric Lossless Compression of Markov Images</dc:title>
 <dc:creator>Reyes, Matthew G.</dc:creator>
 <dc:creator>Neuhoff, David L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by the question of whether the recently introduced Reduced Cutset
Coding (RCC) offers rate-complexity performance benefits over conventional
context-based conditional coding for sources with two-dimensional Markov
structure, this paper compares several row-centric coding strategies that vary
in the amount of conditioning as well as whether a model or an empirical table
is used in the encoding of blocks of rows. The conclusion is that, at least for
sources exhibiting low-order correlations, 1-sided model-based conditional
coding is superior to the method of RCC for a given constraint on complexity,
and conventional context-based conditional coding is nearly as good as the
1-sided model-based coding.
</dc:description>
 <dc:description>Comment: submitted to ISIT 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08061</identifier>
 <datestamp>2017-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Ensemble Kalman Filter: A Signal Processing Perspective</dc:title>
 <dc:creator>Roth, Michael</dc:creator>
 <dc:creator>Hendeby, Gustaf</dc:creator>
 <dc:creator>Fritsche, Carsten</dc:creator>
 <dc:creator>Gustafsson, Fredrik</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  The ensemble Kalman filter (EnKF) is a Monte Carlo based implementation of
the Kalman filter (KF) for extremely high-dimensional, possibly nonlinear and
non-Gaussian state estimation problems. Its ability to handle state dimensions
in the order of millions has made the EnKF a popular algorithm in different
geoscientific disciplines. Despite a similarly vital need for scalable
algorithms in signal processing, e.g., to make sense of the ever increasing
amount of sensor data, the EnKF is hardly discussed in our field.
  This self-contained review paper is aimed at signal processing researchers
and provides all the knowledge to get started with the EnKF. The algorithm is
derived in a KF framework, without the often encountered geoscientific
terminology. Algorithmic challenges and required extensions of the EnKF are
provided, as well as relations to sigma-point KF and particle filters. The
relevant EnKF literature is summarized in an extensive survey and unique
simulation examples, including popular benchmark problems, complement the
theory with practical insights. The signal processing perspective highlights
new directions of research and facilitates the exchange of potentially
beneficial ideas, both for the EnKF and high-dimensional nonlinear and
non-Gaussian filtering in general.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08061</dc:identifier>
 <dc:identifier>doi:10.1186/s13634-017-0492-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08065</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Battery Storage for Peak Shaving and Frequency Regulation: Joint
  Optimization for Superlinear Gains</dc:title>
 <dc:creator>Shi, Yuanyuan</dc:creator>
 <dc:creator>Xu, Bolun</dc:creator>
 <dc:creator>Wang, Di</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider using a battery storage system simultaneously for peak shaving
and frequency regulation through a joint optimization framework which captures
battery degradation, operational constraints and uncertainties in customer load
and regulation signals. Under this framework, using real data we show the
electricity bill of users can be reduced by up to 15\%. Furthermore, we
demonstrate that the saving from joint optimization is often larger than the
sum of the optimal savings when the battery is used for the two individual
applications. A simple threshold real-time algorithm is proposed and achieves
this super-linear gain. Compared to prior works that focused on using battery
storage systems for single applications, our results suggest that batteries can
achieve much larger economic benefits than previously thought if they jointly
provide multiple services.
</dc:description>
 <dc:description>Comment: To Appear in IEEE Transaction on Power Systems</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08070</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PubTree: A Hierarchical Search Tool for the MEDLINE Database</dc:title>
 <dc:creator>Rowe, William</dc:creator>
 <dc:creator>Dobson, Paul D.</dc:creator>
 <dc:creator>Constantinides, Bede</dc:creator>
 <dc:creator>Platt, Mark</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Keeping track of the ever-increasing body of scientific literature is an
escalating challenge. We present PubTree a hierarchical search tool that
efficiently searches the PubMed/MEDLINE dataset based upon a decision tree
constructed using &gt;26 million abstracts. The tool is implemented as a webpage,
where users are asked a series of eighteen questions to locate pertinent
articles. The implementation of this hierarchical search tool highlights issues
endemic with document retrieval. However, the construction of this tree
indicates that with future developments hierarchical search could become an
effective tool (or adjunct) in the mining of biological literature.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08072</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Reuse for Customization: Metamodels in an Open Design
  Community for 3d Printing</dc:title>
 <dc:creator>Kyriakou, Harris</dc:creator>
 <dc:creator>Nickerson, Jeffrey V</dc:creator>
 <dc:creator>Sabnis, Gaurav</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Theories of knowledge reuse posit two distinct processes: reuse for
replication and reuse for innovation. We identify another distinct process,
reuse for customization. Reuse for customization is a process in which
designers manipulate the parameters of metamodels to produce models that
fulfill their personal needs. We test hypotheses about reuse for customization
in Thingiverse, a community of designers that shares files for
three-dimensional printing. 3D metamodels are reused more often than the 3D
models they generate. The reuse of metamodels is amplified when the metamodels
are created by designers with greater community experience. Metamodels make the
community's design knowledge available for reuse for customization-or further
extension of the metamodels, a kind of reuse for innovation.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08072</dc:identifier>
 <dc:identifier>MIS Quarterly, 2017, 41(1), 315-322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08074</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Control for Air Hockey Striking using Deep Reinforcement
  Learning</dc:title>
 <dc:creator>Taitler, Ayal</dc:creator>
 <dc:creator>Shimkin, Nahum</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider the task of learning control policies for a robotic mechanism
striking a puck in an air hockey game. The control signal is a direct command
to the robot's motors. We employ a model free deep reinforcement learning
framework to learn the motoric skills of striking the puck accurately in order
to score. We propose certain improvements to the standard learning scheme which
make the deep Q-learning algorithm feasible when it might otherwise fail. Our
improvements include integrating prior knowledge into the learning scheme, and
accounting for the changing distribution of samples in the experience replay
buffer. Finally we present our simulation results for aimed striking which
demonstrate the successful learning of this task, and the improvement in
algorithm stability due to the proposed modifications.
</dc:description>
 <dc:description>Comment: Corrected typos Graphs added in results section</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08074</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08079</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topological Interference Management with Decoded Message Passing</dc:title>
 <dc:creator>Yi, Xinping</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The topological interference management (TIM) problem studies
partially-connected interference networks with no channel state information
except for the network topology (i.e., connectivity graph) at the transmitters.
In this paper, we consider a similar problem in the uplink cellular networks,
while message passing is enabled at the receivers (e.g., base stations), so
that the decoded messages can be routed to other receivers via backhaul links
to help further improve network performance. For this TIM problem with decoded
message passing (TIM-MP), we model the interference pattern by conflict
digraphs, connect orthogonal access to the acyclic set coloring on conflict
digraphs, and show that one-to-one interference alignment boils down to
orthogonal access because of message passing. With the aid of polyhedral
combinatorics, we identify the structural properties of certain classes of
network topologies where orthogonal access achieves the optimal
degrees-of-freedom (DoF) region in the information-theoretic sense. The
relation to the conventional index coding with simultaneous decoding is also
investigated by formulating a generalized index coding problem with successive
decoding as a result of decoded message passing. The properties of reducibility
and criticality are also studied, by which we are able to prove the linear
optimality of orthogonal access in terms of symmetric DoF for the networks up
to four users with all possible network topologies (218 instances). Practical
issues of the tradeoff between the overhead of message passing and the
achievable symmetric DoF are also discussed, in the hope of facilitating
efficient backhaul utilization.
</dc:description>
 <dc:description>Comment: A short version has been presented at IEEE International Symposium on
  Information Theory (ISIT 2016), Barcelona</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08083</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The linear nature of pseudowords</dc:title>
 <dc:creator>Almeida, Jorge</dc:creator>
 <dc:creator>Costa, Alfredo</dc:creator>
 <dc:creator>Costa, Jos&#xe9; Carlos</dc:creator>
 <dc:creator>Zeitoun, Marc</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:description>  Given a pseudoword over suitable pseudovarieties, we associate to it a
labeled linear order determined by the factorizations of the pseudoword. We
show that, in the case of the pseudovariety of aperiodic finite semigroups, the
pseudoword can be recovered from the labeled linear order.
</dc:description>
 <dc:description>Comment: Addresses were added. A small correction at the introduction was made</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-03-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08084</identifier>
 <datestamp>2017-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Algorithmic Statistics for space-bounded algorithms</dc:title>
 <dc:creator>Milovanov, Alexey</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Algorithmic statistics studies explanations of observed data that are good in
the algorithmic sense: an explanation should be simple i.e. should have small
Kolmogorov complexity and capture all the algorithmically discoverable
regularities in the data. However this idea can not be used in practice because
Kolmogorov complexity is not computable.
  In this paper we develop algorithmic statistics using space-bounded
Kolmogorov complexity. We prove an analogue of one of the main result of
`classic' algorithmic statistics (about the connection between optimality and
randomness deficiences). The main tool of our proof is the Nisan-Wigderson
generator.
</dc:description>
 <dc:description>Comment: accepted to CSR 2017 conference</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-07-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08088</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selection of training populations (and other subset selection problems)
  with an accelerated genetic algorithm (STPGA: An R-package for selection of
  training populations with a genetic algorithm)</dc:title>
 <dc:creator>Akdemir, Deniz</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Optimal subset selection is an important task that has numerous algorithms
designed for it and has many application areas. STPGA contains a special
genetic algorithm supplemented with a tabu memory property (that keeps track of
previously tried solutions and their fitness for a number of iterations), and
with a regression of the fitness of the solutions on their coding that is used
to form the ideal estimated solution (look ahead property) to search for
solutions of generic optimal subset selection problems. I have initially
developed the programs for the specific problem of selecting training
populations for genomic prediction or association problems, therefore I give
discussion of the theory behind optimal design of experiments to explain the
default optimization criteria in STPGA, and illustrate the use of the programs
in this endeavor. Nevertheless, I have picked a few other areas of application:
supervised and unsupervised variable selection based on kernel alignment,
supervised variable selection with design criteria, influential observation
identification for regression, solving mixed integer quadratic optimization
problems, balancing gains and inbreeding in a breeding population. Some of
these illustrations pertain new statistical approaches.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08088</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08089</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum parameter estimation via dispersive measurement in circuit QED</dc:title>
 <dc:creator>Gong, Beili</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Cui, Wei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the quantum parameter estimation in circuit quantum
electrodynamics via dispersive measurement. Based on the Metropolis Hastings
(MH) algorithm and the Markov chain Monte Carlo (MCMC) integration, a new
algorithm is proposed to calculate the Fisher information by the stochastic
master equation for unknown parameter estimation. Here, the Fisher information
is expressed in the form of log-likehood functions and further approximated by
the MCMC integration. Numerical results demonstrate that the single evolution
of the Fisher information can probably approach the quantum Fisher information.
The same phenomenon is observed in the ensemble evolution in the short time
interval. These results demonstrate the effectiveness of the proposed
algorithm.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08090</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of Guidance Modes for the AUV &quot;Slocum Glider&quot; in Time-Varying
  Ocean Flows</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Woithe, Hans Christian</dc:creator>
 <dc:creator>Kremer, Ulrich</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents possibilities for the reliable guidance of an AUV &quot;Slocum
Glider&quot; in time-varying ocean flows. The presented guidance modes consider the
restricted information during a real mission about the actual position and
ocean current conditions as well as the available control modes of a glider. A
faster-than-real-time, full software stack simulator for the Slocum glider will
be described in order to test the developed guidance modes under real mission
conditions.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures, IEEE OCEANS 2014 - TAIPEI , 7-10 April 2014</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08090</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANS-TAIPEI.2014.6964583</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08092</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallelization of Path Planning Algorithms for AUVs Concepts,
  Opportunities, and Program-Technical Implementation</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Woithe, Hans Christian</dc:creator>
 <dc:creator>Kremer, Ulrich</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Modern autonomous underwater vehicles (AUVs) have advanced sensing
capabilities including sonar, cameras, acoustic communication, and diverse
bio-sensors. Instead of just sensing its environment and storing the data for
post-Mission inspection, an AUV could use the collected information to gain an
understanding of its environment, and based on this understanding autonomously
adapt its behavior to enhance the overall effectiveness of its mission. Many
such tasks are highly computation intensive. This paper presents the results of
a case study that illustrates the effectiveness of an energy-aware, many-core
computing architecture to perform on-board path planning within a
batteryoperated AUV. A previously published path planning algorithm was ported
onto the SCC, an experimental 48 core single-chip system developed by Intel.
The performance, power, and energy consumption of the application were measured
for different numbers of cores and other system parameters. This case study
shows that computation intensive tasks can be executed within an AUV that
relies mainly on battery power. Future plans include the deployment and testing
of an SCC system within a Teledyne Webb Research Slocum glider.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures, IEEE OCEANS, 2012 - Yeosu , 21-24 May 2012</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08092</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANS-Yeosu.2012.6263557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08094</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular AUV System for Sea Water Quality Monitoring and Management</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Taubert, Ralf</dc:creator>
 <dc:creator>Ament, Christoph</dc:creator>
 <dc:creator>Jacobi, Marco</dc:creator>
 <dc:creator>Pfuetzenreuter, Torsten</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The sustained and cost-effective monitoring of the water quality within
European coastal areas is of growing importance in view of the upcoming
European marine and maritime directives, i.e. the increased industrial use of
the marine environment. Such monitoring needs mechanisms/systems to detect the
water quality in a large sea area at different depths in real time. This paper
presents a system for the automated detection and analysis of water quality
parameters using an autonomous underwater vehicle. The analysis of discharge of
nitrate into Norwegian fjords near aqua farms is one of the main application
fields of this AUV system. As carrier platform the AUV &quot;CWolf&quot; from the
Fraunhofer IOSB-AST will be used, which is perfectly suited through its modular
payload concept. The mission Task and the integration of the payload unit which
includes the sensor module, the scientific and measurement computer in the AUV
carrier platform will be described. Few practice oriented information about the
software and interface concept, the function of the several software modules
and the test platform with the several test levels to test every module will be
discussed.
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, OCEANS - Bergen, 2013 MTS/IEEE, 10-14 June 2013</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08094</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANS-Bergen.2013.6608086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08097</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Selfie is Worth a Thousand Words: Mining Personal Patterns behind User
  Selfie-posting Behaviours</dc:title>
 <dc:creator>Chen, Tianlang</dc:creator>
 <dc:creator>Chen, Yuxiao</dc:creator>
 <dc:creator>Luo, Jiebo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Selfies have become increasingly fashionable in the social media era. People
are willing to share their selfies in various social media platforms such as
Facebook, Instagram and Flicker. The popularity of selfie have caught
researchers' attention, especially psychologists. In computer vision and
machine learning areas, little attention has been paid to this phenomenon as a
valuable data source. In this paper, we focus on exploring the deeper personal
patterns behind people's different kinds of selfie-posting behaviours. We
develop this work based on a dataset of WeChat, one of the most extensively
used instant messaging platform in China. In particular, we first propose an
unsupervised approach to classify the images posted by users. Based on the
classification result, we construct three types of user-level features that
reflect user preference, activity and posting habit. Based on these features,
for a series of selfie related tasks, we build classifiers that can accurately
predict two sets of users with opposite selfie-posting behaviours. We have
found that people's interest, activity and posting habit have a great influence
on their selfie-posting behaviours. For example, the classification accuracy
between selfie-posting addict and nonaddict reaches 89.36%. We also prove that
using user's image information to predict these behaviours achieve better
performance than using text information. More importantly, for each set of
users with a specific selfie-posting behaviour, we extract and visualize
significant personal patterns about them. In addition, we cluster users and
extract their high-level attributes, revealing the correlation between these
attributes and users' selfie-posting behaviours. In the end, we demonstrate
that users' selfie-posting behaviour, as a good predictor, could predict their
different preferences toward these high-level attributes accurately.
</dc:description>
 <dc:description>Comment: WWW 2017 Companion</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08098</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunities to Parallelize Path Planning Algorithms for Autonomous
  Underwater Vehicles</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Kremer, Ulrich</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper discusses opportunities to parallelize graph based path planning
algorithms in a time varying environment. Parallel architectures have become
commonplace, requiring algorithm to be parallelized for efficient execution. An
additional focal point of this paper is the inclusion of inaccuracies in path
planning as a result of forecast error variance, accuracy of calculation in the
cost functions and a different observed vehicle speed in the real mission than
planned. In this context, robust path planning algorithms will be described.
These algorithms are equally applicable to land based, aerial, or underwater
mobile autonomous systems. The results presented here provide the basis for a
future Research project in which the parallelized algorithms will be evaluated
on multi and many core systems such as the dual core ARM Panda board and the 48
core Single-chip Cloud Computer (SCC). Modern multi and many core processors
support a wide range of performance vs. energy tradeoffs that can be exploited
in energyconstrained environments such as battery operated autonomous
underwater vehicles. For this evaluation, the boards will be deployed within
the Slocum glider, a commercially available, buoyancy driven autonomous
underwater vehicle (AUV).
</dc:description>
 <dc:description>Comment: 7 pages, 9 figures, IEEE OCEANS, 2011 - Kona , 19-22 Sept. 2011</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08099</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lattice Coding and Decoding for Multiple-Antenna Ergodic Fading Channels</dc:title>
 <dc:creator>Hindy, Ahmed</dc:creator>
 <dc:creator>Nosratinia, Aria</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For ergodic fading, a lattice coding and decoding strategy is proposed and
its performance is analyzed for the single-input single-output (SISO) and
multiple-input multiple-output (MIMO) point-to-point channel as well as the
multiple-access channel (MAC), with channel state information available only at
the receiver (CSIR). At the decoder a novel strategy is proposed consisting of
a time-varying equalization matrix followed by decision regions that depend
only on channel statistics, not individual realizations. Our encoder has a
similar structure to that of Erez and Zamir. For the SISO channel, the gap to
capacity is bounded by a constant under a wide range of fading distributions.
For the MIMO channel under Rayleigh fading, the rate achieved is within a gap
to capacity that does not depend on the signal-to-noise ratio (SNR), and
diminishes with the number of receive antennas. The analysis is extended to the
K-user MAC where similar results hold. Achieving a small gap to capacity while
limiting the use of CSIR to the equalizer highlights the scope for efficient
decoder implementations, since decision regions are fixed, i.e., independent of
channel realizations.
</dc:description>
 <dc:description>Comment: Accepted at IEEE Transactions on Communications</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08101</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solutions for Practice-oriented Requirements for Optimal Path Planning
  for the AUV &quot;SLOCUM Glider&quot;</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a few important practiceoriented requirements for optimal
path planning for the AUV &quot;SLOCUM Glider&quot; as well as solutions using fast graph
basedalgorithms. These algorithms build upon the TVE (time-varying environment)
search algorithm. The experience with this algorithm, requirements of real
missions along the Newfoundland and Labrador Shelf and the idea to find the
optimal departure time are the motivation to address the field of research,
which is described in this paper. The main focus of this paper is a discussion
of possible methods to accelerate the path planning algorithm, without
deterioration of the results.
</dc:description>
 <dc:description>Comment: 10 pages, 10 figures, IEEE OCEANS, 2010 - Seattle, 20-23 Sept. 2010</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08101</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANS.2010.5664082</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08104</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Mission Planning System for the AUV &quot;SLOCUM Glider&quot; for the
  Newfoundland and Labrador Shelf</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Williams, Christopher D.</dc:creator>
 <dc:creator>Bachmayer, Ralf</dc:creator>
 <dc:creator>de Young, Brad</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a system for mission planning for an autonomous
underwater vehicle in time-varying ocean currents. The mission planning system
is designed for the AUV &quot;SLOCUM Glider&quot; to collect oceanographic data along the
Newfoundland and Labrador Shelf. The data will be used in conjunction with a
numerical ocean model currently under development by the Department of
Fisheries and Oceans Canada. This allows for the validation and the
modification of existing ocean current and climate models as well as the design
of new models with the aim of improving the accuracy of forecasts. The use of
the ocean current forecast data in netCDF format in an ocean current model, the
algorithms which consider glider-specific behaviour, details of the program's
technical implementation in C++, and, preliminary results will be described.
</dc:description>
 <dc:description>Comment: 9 pages, 13 figures, OCEANS 2010 IEEE - Sydney, 24-27 May 2010</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08104</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANSSYD.2010.5603919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08106</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Concept for an Obstacle Avoidance System for the AUV &quot;SLOCUM
  Glider&quot; Operation under Ice</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a concept for a control System for an autonomous
underwater vehicle under ice using a &quot;SLOCUM&quot; underwater glider. The project
concept, the separate working tasks for the next one-and-a-half years and the
first results will be presented. In this context the structure of the obstacle
avoidance system and a simulator structure with a sensor and environment
simulation as well as the interfaces to the glider hardware will be discussed.
As a first result of the main research, a graph-based algorithm for the path
planning in a time-varying environment (variable ocean field, moving obstacles)
will be described.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, IEEE OCEANS 2009 - EUROPE Bremen, 11-14 May 2009</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08106</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANSE.2009.5278350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08107</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guidance of an Autonomous Underwater Vehicle in Special Situations</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This article describes a guidance system of the autonomous underwater vehicle
&quot;DeepC&quot; [1] in Special situations. A special situation occurs when one or more
objects interfere with the planned route of a mission. The possible reactions
are evasion or identification of the objects. The paper presents these two
tasks in overview. The special demands challenges of the underwater
environment, computer parameters, sensors and the maneuverability of the
vehicle are considered in the selection and development of the required
strategies. Such challenges include the sea current, maneuver in the 3-D space
and the limited perceptive faculty of the sonar.
</dc:description>
 <dc:description>Comment: 6 pages, 16 figures, IEEE Oceans 2005 - Europe Brest, 20-23 June 2005</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08107</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANSE.2005.1511680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08112</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Scanning System for Automatic High-Resolution Plant Phenotyping</dc:title>
 <dc:creator>Nguyen, Chuong V</dc:creator>
 <dc:creator>Fripp, Jurgen</dc:creator>
 <dc:creator>Lovell, David R</dc:creator>
 <dc:creator>Furbank, Robert</dc:creator>
 <dc:creator>Kuffner, Peter</dc:creator>
 <dc:creator>Daily, Helen</dc:creator>
 <dc:creator>Sirault, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Thin leaves, fine stems, self-occlusion, non-rigid and slowly changing
structures make plants difficult for three-dimensional (3D) scanning and
reconstruction -- two critical steps in automated visual phenotyping. Many
current solutions such as laser scanning, structured light, and multiview
stereo can struggle to acquire usable 3D models because of limitations in
scanning resolution and calibration accuracy. In response, we have developed a
fast, low-cost, 3D scanning platform to image plants on a rotating stage with
two tilting DSLR cameras centred on the plant. This uses new methods of camera
calibration and background removal to achieve high-accuracy 3D reconstruction.
We assessed the system's accuracy using a 3D visual hull reconstruction
algorithm applied on 2 plastic models of dicotyledonous plants, 2 sorghum
plants and 2 wheat plants across different sets of tilt angles. Scan times
ranged from 3 minutes (to capture 72 images using 2 tilt angles), to 30 minutes
(to capture 360 images using 10 tilt angles). The leaf lengths, widths, areas
and perimeters of the plastic models were measured manually and compared to
measurements from the scanning system: results were within 3-4% of each other.
The 3D reconstructions obtained with the scanning system show excellent
geometric agreement with all six plant specimens, even plants with thin leaves
and fine stems.
</dc:description>
 <dc:description>Comment: 8 papes, DICTA 2016</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08112</dc:identifier>
 <dc:identifier>In Digital Image Computing: Techniques and Applications (DICTA),
  2016 International Conference on, pp. 1-8. IEEE, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08114</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Tensor Canonicalization</dc:title>
 <dc:creator>Niehoff, Benjamin E.</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:description>  The Butler-Portugal algorithm for obtaining the canonical form of a tensor
expression with respect to slot symmetries and dummy-index renaming suffers, in
certain cases with a high degree of symmetry, from $O(n!)$ explosion in both
computation time and memory. We present a modified algorithm which alleviates
this problem in the most common cases---tensor expressions with subsets of
indices which are totally symmetric or totally antisymmetric---in polynomial
time. We also present an implementation of the label-renaming mechanism which
improves upon that of the original Butler-Portugal algorithm, thus providing a
significant speed increase for the average case as well as the highly-symmetric
special case. The worst-case behavior remains $O(n!)$, although it occurs in
more limited situations unlikely to appear in actual computations. We comment
on possible strategies to take if the nature of a computation should make these
situations more likely.
</dc:description>
 <dc:description>Comment: 45 pages + appendices and references, 9 figures, version 3 (fixed
  some references, grant acknowledgement, added link to source code)</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08115</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bioplausible multiscale filtering in retino-cortical processing as a
  mechanism in perceptual grouping</dc:title>
 <dc:creator>Nematzadeh, Nasim</dc:creator>
 <dc:creator>Powers, David M. W.</dc:creator>
 <dc:creator>Lewis, Trent W.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Why does our visual system fail to reconstruct reality, when we look at
certain patterns? Where do Geometrical illusions start to emerge in the visual
pathway? How far should we take computational models of vision with the same
visual ability to detect illusions as we do? This study addresses these
questions, by focusing on a specific underlying neural mechanism involved in
our visual experiences that affects our final perception. Among many types of
visual illusion, Geometrical and, in particular, Tilt Illusions are rather
important, being characterized by misperception of geometric patterns involving
lines and tiles in combination with contrasting orientation, size or position.
Over the last decade, many new neurophysiological experiments have led to new
insights as to how, when and where retinal processing takes place, and the
encoding nature of the retinal representation that is sent to the cortex for
further processing. Based on these neurobiological discoveries, we provide
computer simulation evidence from modelling retinal ganglion cells responses to
some complex Tilt Illusions, suggesting that the emergence of tilt in these
illusions is partially related to the interaction of multiscale visual
processing performed in the retina. The output of our low-level filtering model
is presented for several types of Tilt Illusion, predicting that the final tilt
percept arises from multiple-scale processing of the Differences of Gaussians
and the perceptual interaction of foreground and background elements. Our
results suggest that this model has a high potential in revealing the
underlying mechanism connecting low-level filtering approaches to mid- and
high-level explanations such as Anchoring theory and Perceptual grouping.
</dc:description>
 <dc:description>Comment: 23 pages, 8 figures, Brain Informatics journal: Full text access:
  https://link.springer.com/article/10.1007/s40708-017-0072-8</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08115</dc:identifier>
 <dc:identifier>doi:10.1007/s40708-017-0072-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08122</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MmWave vehicle-to-infrastructure communication: Analysis of urban
  microcellular networks</dc:title>
 <dc:creator>Wang, Yuyang</dc:creator>
 <dc:creator>Venugopal, Kiran</dc:creator>
 <dc:creator>Molisch, Andreas F.</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Vehicle-to-infrastructure (V2I) communication may provide high data rates to
vehicles via millimeter-wave (mmWave) microcellular networks. This paper uses
stochastic geometry to analyze the coverage of urban mmWave microcellular
networks. Prior work used a pathloss model with a line-of-sight probability
function based on randomly oriented buildings, to determine whether a link was
line-of-sight or non-line-of-sight. In this paper, we use a pathloss model
inspired by measurements, which uses a Manhattan distance model and accounts
for differences in pathloss exponents and losses when turning corners. In our
model, users and base stations (BSs) are randomly located on a network formed
by a two dimensional Poisson line process. Our model is well suited for urban
microcellular networks where the base stations are deployed at street level.
Based on this new approach, we derive the coverage probability under certain BS
association rules to obtain closed-form solutions without much complexity. In
addition, we draw two main conclusions from our work. First, non-line-of-sight
BSs are not a major benefit for association or source of interference. Second,
there is an ultradense regime where deploying (active) BSs does not enhance
coverage.
</dc:description>
 <dc:description>Comment: 15 pages, 16 figures</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08124</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unifying Framework for Convergence Analysis of Approximate Newton
  Methods</dc:title>
 <dc:creator>Ye, Haishan</dc:creator>
 <dc:creator>Luo, Luo</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Many machine learning models are reformulated as optimization problems. Thus,
it is important to solve a large-scale optimization problem in big data
applications. Recently, subsampled Newton methods have emerged to attract much
attention for optimization due to their efficiency at each iteration, rectified
a weakness in the ordinary Newton method of suffering a high cost in each
iteration while commanding a high convergence rate. Other efficient stochastic
second order methods are also proposed. However, the convergence properties of
these methods are still not well understood. There are also several important
gaps between the current convergence theory and the performance in real
applications. In this paper, we aim to fill these gaps. We propose a unifying
framework to analyze local convergence properties of second order methods.
Based on this framework, our theoretical analysis matches the performance in
real applications.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08130</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiuser Precoding and Channel Estimation for Hybrid Millimeter Wave
  MIMO Systems</dc:title>
 <dc:creator>Zhao, Lou</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we develop a low-complexity channel estimation for hybrid
millimeter wave (mmWave) systems, where the number of radio frequency (RF)
chains is much less than the number of antennas equipped at each transceiver.
The proposed channel estimation algorithm aims to estimate the strongest
angle-of-arrivals (AoAs) at both the base station (BS) and the users. Then all
the users transmit orthogonal pilot symbols to the BS via these estimated
strongest AoAs to facilitate the channel estimation. The algorithm does not
require any explicit channel state information (CSI) feedback from the users
and the associated signalling overhead of the algorithm is only proportional to
the number of users, which is significantly less compared to various existing
schemes. Besides, the proposed algorithm is applicable to both non-sparse and
sparse mmWave channel environments. Based on the estimated CSI, zero-forcing
(ZF) precoding is adopted for multiuser downlink transmission. In addition, we
derive a tight achievable rate upper bound of the system. Our analytical and
simulation results show that the proposed scheme offer a considerable
achievable rate gain compared to fully digital systems, where the number of RF
chains equipped at each transceiver is equal to the number of antennas.
Furthermore, the achievable rate performance gap between the considered hybrid
mmWave systems and the fully digital system is characterized, which provides
useful system design insights.
</dc:description>
 <dc:description>Comment: 6 pages, accepted for presentation, ICC 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08133</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A General Framework for Low-Resolution Receivers for MIMO Channels</dc:title>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:creator>Barletta, Luca</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Erkip, Elza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The capacity of a discrete-time multi-input multi-output (MIMO) Gaussian
channel with output quantization is investigated for different receiver
architectures. A general formulation of this problem is proposed in which the
antenna outputs are processed by analog combiners while sign quantizers are
used for analog-to-digital conversion. To exemplify this approach, four analog
receiver architectures of varying generality and complexity are considered: (a)
multiple antenna selection and sign quantization of the antenna outputs, (b)
single antenna selection and multilevel quantization, (c) multiple antenna
selection and multilevel quantization, and (d) linear combining of the antenna
outputs and multilevel quantization. Achievable rates are studied as a function
of the number of available sign quantizers and compared among different
architectures. In particular, it is shown that architecture (a) is sufficient
to attain the optimal high signal-to-noise ratio performance for a MIMO
receiver in which the number of antennas is larger than the number of sign
quantizers. Numerical evaluations of the average performance are presented for
the case in which the channel gains are i.i.d. Gaussian.
</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08134</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dropping Convexity for More Efficient and Scalable Online Multiview
  Learning</dc:title>
 <dc:creator>Chen, Zhehui</dc:creator>
 <dc:creator>Yang, Lin F.</dc:creator>
 <dc:creator>Li, Chris J.</dc:creator>
 <dc:creator>Zhao, Tuo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Multiview representation learning is very popular for latent factor analysis.
It naturally arises in many data analysis, machine learning, and information
retrieval applications to model dependent structures among multiple data
sources. For computational convenience, existing approaches usually formulate
the multiview representation learning as convex optimization problems, where
global optima can be obtained by certain algorithms in polynomial time.
However, many evidences have corroborated that heuristic nonconvex approaches
also have good empirical computational performance and convergence to the
global optima, although there is a lack of theoretical justification. Such a
gap between theory and practice motivates us to study a nonconvex formulation
for multiview representation learning, which can be efficiently solved by a
simple stochastic gradient descent (SGD) algorithm. We first illustrate the
geometry of the nonconvex formulation; Then by characterizing the dynamics of
the approximate limiting process, we establish global rates of convergence to
the global optima. Numerical experiments are provided to support our theory.
</dc:description>
 <dc:description>Comment: A preliminary version appears in ICML 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08138</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deceiving Google's Perspective API Built for Detecting Toxic Comments</dc:title>
 <dc:creator>Hosseini, Hossein</dc:creator>
 <dc:creator>Kannan, Sreeram</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:creator>Poovendran, Radha</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social media platforms provide an environment where people can freely engage
in discussions. Unfortunately, they also enable several problems, such as
online harassment. Recently, Google and Jigsaw started a project called
Perspective, which uses machine learning to automatically detect toxic
language. A demonstration website has been also launched, which allows anyone
to type a phrase in the interface and instantaneously see the toxicity score
[1]. In this paper, we propose an attack on the Perspective toxic detection
system based on the adversarial examples. We show that an adversary can subtly
modify a highly toxic phrase in a way that the system assigns significantly
lower toxicity score to it. We apply the attack on the sample phrases provided
in the Perspective website and show that we can consistently reduce the
toxicity scores to the level of the non-toxic phrases. The existence of such
adversarial examples is very harmful for toxic detection systems and seriously
undermines their usability.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08139</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Variational Autoencoders for Text Modeling using Dilated
  Convolutions</dc:title>
 <dc:creator>Yang, Zichao</dc:creator>
 <dc:creator>Hu, Zhiting</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Berg-Kirkpatrick, Taylor</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recent work on generative modeling of text has found that variational
auto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTM
language models (Bowman et al., 2015). This negative result is so far poorly
understood, but has been attributed to the propensity of LSTM decoders to
ignore conditioning information from the encoder. In this paper, we experiment
with a new type of decoder for VAE: a dilated CNN. By changing the decoder's
dilation architecture, we control the effective context from previously
generated words. In experiments, we find that there is a trade off between the
contextual capacity of the decoder and the amount of encoding information used.
We show that with the right decoder, VAE can outperform LSTM language models.
We demonstrate perplexity gains on two datasets, representing the first
positive experimental result on the use VAE for generative modeling of text.
Further, we conduct an in-depth investigation of the use of VAE (with our new
decoding architecture) for semi-supervised and unsupervised labeling tasks,
demonstrating gains over several strong baselines.
</dc:description>
 <dc:description>Comment: camera ready</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-06-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08142</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tensor Balancing on Statistical Manifold</dc:title>
 <dc:creator>Sugiyama, Mahito</dc:creator>
 <dc:creator>Nakahara, Hiroyuki</dc:creator>
 <dc:creator>Tsuda, Koji</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We solve tensor balancing, rescaling an Nth order nonnegative tensor by
multiplying N tensors of order N - 1 so that every fiber sums to one. This
generalizes a fundamental process of matrix balancing used to compare matrices
in a wide range of applications from biology to economics. We present an
efficient balancing algorithm with quadratic convergence using Newton's method
and show in numerical experiments that the proposed algorithm is several orders
of magnitude faster than existing ones. To theoretically prove the correctness
of the algorithm, we model tensors as probability distributions in a
statistical manifold and realize tensor balancing as projection onto a
submanifold. The key to our algorithm is that the gradient of the manifold,
used as a Jacobian matrix in Newton's method, can be analytically obtained
using the Moebius inversion formula, the essential of combinatorial
mathematics. Our model is not limited to tensor balancing, but has a wide
applicability as it includes various statistical and machine learning models
such as weighted DAGs and Boltzmann machines.
</dc:description>
 <dc:description>Comment: 19 pages, 5 figures, accepted to the 34th International Conference on
  Machine Learning (ICML 2017)</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08144</identifier>
 <datestamp>2017-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synchronization Problems in Automata without Non-trivial Cycles</dc:title>
 <dc:creator>Ryzhikov, Andrew</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  We study the computational complexity of various problems related to
synchronization of weakly acyclic automata, a subclass of widely studied
aperiodic automata. We provide upper and lower bounds on the length of a
shortest word synchronizing a weakly acyclic automaton or, more generally, a
subset of its states, and show that the problem of approximating this length is
hard. We investigate the complexity of finding a synchronizing set of states of
maximum size. We also show inapproximability of the problem of computing the
rank of a subset of states in a binary weakly acyclic automaton and prove that
several problems related to recognizing a synchronizing subset of states in
such automata are NP-complete.
</dc:description>
 <dc:description>Comment: Extended and corrected version, including arXiv:1608.00889.
  Conference version was published at CIAA 2017, LNCS vol. 10329, pages
  188-200, 2017</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:date>2017-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08152</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A KZ Reduction Algorithm</dc:title>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Chang, Xiao-Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The Korkine-Zolotareff (KZ) reduction is one of the often used reduction
strategies for decoding lattices. A KZ reduction algorithm involves solving
shortest vector problems (SVPs) and basis expansion. In this paper, first we
improve the commonly used Schnorr-Euchner search strategy for solving SVPs.
Then, we derive upper bounds on the magnitudes of the entries of any solution
of a SVP when its basis matrix is LLL reduced. These upper bounds only involve
the parameter of the LLL reduction and the dimension of the solution and they
are useful for analyzing the complexity of the basis expansion in a KZ
reduction algorithm. Finally, we modify the basis expansion method proposed by
Zhang et al. and combine it with the improved Schnorr-Euchner search strategy
to give a new KZ reduction algorithm. Simulation results show that the new KZ
reduction algorithm is much faster and numerically more stable than the KZ
reduction algorithm proposed by Zhang et al., especially when the basis matrix
is ill conditioned.
</dc:description>
 <dc:description>Comment: This work was presented in part at the IEEE International Symposium
  on Information Theory (ISIT 2015), Hongkong: arXiv:1504.05086</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08153</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HPDedup: A Hybrid Prioritized Data Deduplication Mechanism for Primary
  Storage in the Cloud</dc:title>
 <dc:creator>Wu, Huijun</dc:creator>
 <dc:creator>Wang, Chen</dc:creator>
 <dc:creator>Fu, Yinjin</dc:creator>
 <dc:creator>Sakr, Sherif</dc:creator>
 <dc:creator>Zhu, Liming</dc:creator>
 <dc:creator>Lu, Kai</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Eliminating duplicate data in primary storage of clouds increases the
cost-efficiency of cloud service providers as well as reduces the cost of users
for using cloud services. Existing primary deduplication techniques either use
inline caching to exploit locality in primary workloads or use post-processing
deduplication running in system idle time to avoid the negative impact on I/O
performance. However, neither of them works well in the cloud servers running
multiple services or applications for the following two reasons: Firstly, the
temporal locality of duplicate data writes may not exist in some primary
storage workloads thus inline caching often fails to achieve good deduplication
ratio. Secondly, the post-processing deduplication allows duplicate data to be
written into disks, therefore does not provide the benefit of I/O deduplication
and requires high peak storage capacity. This paper presents HPDedup, a Hybrid
Prioritized data Deduplication mechanism to deal with the storage system shared
by applications running in co-located virtual machines or containers by fusing
an inline and a post-processing process for exact deduplication. In the inline
deduplication phase, HPDedup gives a fingerprint caching mechanism that
estimates the temporal locality of duplicates in data streams from different
VMs or applications and prioritizes the cache allocation for these streams
based on the estimation. HPDedup also allows different deduplication threshold
for streams based on their spatial locality to reduce the disk fragmentation.
The post-processing phase removes duplicates whose fingerprints are not able to
be cached due to the weak temporal locality from disks. Our experimental
results show that HPDedup clearly outperforms the state-of-the-art primary
storage deduplication techniques in terms of inline cache efficiency and
primary deduplication efficiency.
</dc:description>
 <dc:description>Comment: 14 pages, 11 figures, submitted to MSST2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08153</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08154</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond-Regular Typestate</dc:title>
 <dc:creator>Mishra, Ashish</dc:creator>
 <dc:creator>Srikant, Y. N.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  We present an extension for regular typestates, called Beyond- Regular
Typestate(BR-Typestate), which is expressive enough to model non-regular
properties of programs and protocols over data. We model the BR-Typestate
system over a dependently typed, state based, impera- tive core language, and
we prove its soundness and tractability. We have implemented a prototype
typechecker for the language, and we show how several important, real world
non-regular properties of programs and protocols can be verified.
</dc:description>
 <dc:description>Comment: submitted to CAV'17</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08155</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-scale Image Fusion Between Pre-operative Clinical CT and X-ray
  Microtomography of Lung Pathology</dc:title>
 <dc:creator>Roth, Holger R.</dc:creator>
 <dc:creator>Nagara, Kai</dc:creator>
 <dc:creator>Oda, Hirohisa</dc:creator>
 <dc:creator>Oda, Masahiro</dc:creator>
 <dc:creator>Sugiyama, Tomoshi</dc:creator>
 <dc:creator>Nakamura, Shota</dc:creator>
 <dc:creator>Mori, Kensaku</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Computational anatomy allows the quantitative analysis of organs in medical
images. However, most analysis is constrained to the millimeter scale because
of the limited resolution of clinical computed tomography (CT). X-ray
microtomography ($\mu$CT) on the other hand allows imaging of ex-vivo tissues
at a resolution of tens of microns. In this work, we use clinical CT to image
lung cancer patients before partial pneumonectomy (resection of pathological
lung tissue). The resected specimen is prepared for $\mu$CT imaging at a voxel
resolution of 50 $\mu$m (0.05 mm). This high-resolution image of the lung
cancer tissue allows further insides into understanding of tumor growth and
categorization. For making full use of this additional information, image
fusion (registration) needs to be performed in order to re-align the $\mu$CT
image with clinical CT. We developed a multi-scale non-rigid registration
approach. After manual initialization using a few landmark points and rigid
alignment, several levels of non-rigid registration between down-sampled (in
the case of $\mu$CT) and up-sampled (in the case of clinical CT)
representations of the image are performed. Any non-lung tissue is ignored
during the computation of the similarity measure used to guide the registration
during optimization. We are able to recover the volume differences introduced
by the resection and preparation of the lung specimen. The average ($\pm$ std.
dev.) minimum surface distance between $\mu$CT and clinical CT at the resected
lung surface is reduced from 3.3 $\pm$ 2.9 (range: [0.1, 15.9]) to 2.3 mm $\pm$
2.8 (range: [0.0, 15.3]) mm. The alignment of clinical CT with $\mu$CT will
allow further registration with even finer resolutions of $\mu$CT (up to 10
$\mu$m resolution) and ultimately with histopathological microscopy images for
further macro to micro image fusion that can aid medical image analysis.
</dc:description>
 <dc:description>Comment: In proceedings of International Forum on Medical Imaging, IFMIA 2017,
  Okinawa, Japan</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08159</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>F2F: A Library For Fast Kernel Expansions</dc:title>
 <dc:creator>Curto, Joachim</dc:creator>
 <dc:creator>Zarza, Irene</dc:creator>
 <dc:creator>Yang, Feng</dc:creator>
 <dc:creator>Smola, Alexander J.</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  F2F is a C++ library for large-scale machine learning. It contains a CPU
optimized implementation of the Fastfood algorithm, that allows the computation
of approximated kernel expansions in loglinear time. The algorithm requires to
compute the product of Walsh-Hadamard Transform (WHT) matrices. A cache
friendly SIMD Fast Walsh-Hadamard Transform (FWHT) that achieves compelling
speed and outperforms current state-of-the-art methods has been developed. F2F
allows to obtain non-linear classification combining Fastfood and a linear
classifier.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08160</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HashBox: Hash Hierarchical Segmentation exploiting Bounding Box Object
  Detection</dc:title>
 <dc:creator>Curto, Joachim</dc:creator>
 <dc:creator>Zarza, Irene</dc:creator>
 <dc:creator>Smola, Alexander J.</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel approach to address the Simultaneous Detection and
Segmentation problem. Using hierarchical structures we use an efficient and
accurate procedure that exploits the hierarchy feature information using
Locality Sensitive Hashing. We build on recent work that utilizes convolutional
neural networks to detect bounding boxes in an image (Faster R-CNN) and then
use the top similar hierarchical region that best fits each bounding box after
hashing, we call this approach HashBox. We then refine our final segmentation
results by automatic hierarchy pruning. HashBox introduces a train-free
alternative to Hypercolumns. We conduct extensive experiments on Pascal VOC
2012 segmentation dataset, showing that HashBox gives competitive
state-of-the-art object segmentations.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08164</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDN Based QoS Provision in WSN Technologies</dc:title>
 <dc:creator>Letswamotse, Babedi. B.</dc:creator>
 <dc:creator>Modieginyane, Kgotlaetsile. M.</dc:creator>
 <dc:creator>Malekian, Reza</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless Sensor Networks (WSNs) have rapidly progressed over the years, they
are now applied in health care systems, home automation, security surveillance,
disaster management and more. With this rapid growth in the number of users and
applications leading to WSNs becoming increasingly complex, this growth makes
high demands on WSNs to provide the requirements of every user and application
that uses them. They have recently been envisioned to be integrated into
Internet of Things (IoT), their role will be to provide sensing services to the
ever increasing community of internet users. However even with so much
potential, WSNs still experience issues in node deployment, fault tolerance,
scalability and Quality of Service (QoS) provisioning amongst others. In this
paper we propose to improve QoS provisioning by introducing Software Defined
principles into WSN technologies.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08165</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning with Deep Energy-Based Policies</dc:title>
 <dc:creator>Haarnoja, Tuomas</dc:creator>
 <dc:creator>Tang, Haoran</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a method for learning expressive energy-based policies for
continuous states and actions, which has been feasible only in tabular domains
before. We apply our method to learning maximum entropy policies, resulting
into a new algorithm, called soft Q-learning, that expresses the optimal policy
via a Boltzmann distribution. We use the recently proposed amortized Stein
variational gradient descent to learn a stochastic sampling network that
approximates samples from this distribution. The benefits of the proposed
algorithm include improved exploration and compositionality that allows
transferring skills between tasks, which we confirm in simulated experiments
with swimming and walking robots. We also draw a connection to actor-critic
methods, which can be viewed performing approximate inference on the
corresponding energy-based model.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08169</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communication-efficient Algorithms for Distributed Stochastic Principal
  Component Analysis</dc:title>
 <dc:creator>Garber, Dan</dc:creator>
 <dc:creator>Shamir, Ohad</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the fundamental problem of Principal Component Analysis in a
statistical distributed setting in which each machine out of $m$ stores a
sample of $n$ points sampled i.i.d. from a single unknown distribution. We
study algorithms for estimating the leading principal component of the
population covariance matrix that are both communication-efficient and achieve
estimation error of the order of the centralized ERM solution that uses all
$mn$ samples. On the negative side, we show that in contrast to results
obtained for distributed estimation under convexity assumptions, for the PCA
objective, simply averaging the local ERM solutions cannot guarantee error that
is consistent with the centralized ERM. We show that this unfortunate phenomena
can be remedied by performing a simple correction step which correlates between
the individual solutions, and provides an estimator that is consistent with the
centralized ERM for sufficiently-large $n$. We also introduce an iterative
distributed algorithm that is applicable in any regime of $n$, which is based
on distributed matrix-vector products. The algorithm gives significant
acceleration in terms of communication rounds over previous distributed
algorithms, in a wide regime of parameters.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08171</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-point optimization of deep neural networks with adaptive step size
  retraining</dc:title>
 <dc:creator>Shin, Sungho</dc:creator>
 <dc:creator>Boo, Yoonho</dc:creator>
 <dc:creator>Sung, Wonyong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Fixed-point optimization of deep neural networks plays an important role in
hardware based design and low-power implementations. Many deep neural networks
show fairly good performance even with 2- or 3-bit precision when quantized
weights are fine-tuned by retraining. We propose an improved fixedpoint
optimization algorithm that estimates the quantization step size dynamically
during the retraining. In addition, a gradual quantization scheme is also
tested, which sequentially applies fixed-point optimizations from high- to
low-precision. The experiments are conducted for feed-forward deep neural
networks (FFDNNs), convolutional neural networks (CNNs), and recurrent neural
networks (RNNs).
</dc:description>
 <dc:description>Comment: This paper is accepted in ICASSP 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08171</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08172</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tars: Timeliness-aware Adaptive Replica Selection for Key-Value Stores</dc:title>
 <dc:creator>Jiang, Wanchun</dc:creator>
 <dc:creator>Fang, Liyuan</dc:creator>
 <dc:creator>Xie, Haiming</dc:creator>
 <dc:creator>Zhou, Xiangqian</dc:creator>
 <dc:creator>Wang, Jianxin</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In current large-scale distributed key-value stores, a single end-user
request may lead to key-value access across tens or hundreds of servers. The
tail latency of these key-value accesses is crucial to the user experience and
greatly impacts the revenue. To cut the tail latency, it is crucial for clients
to choose the fastest replica server as much as possible for the service of
each key-value access. Aware of the challenges on the time varying performance
across servers and the herd behaviors, an adaptive replica selection scheme C3
is proposed recently. In C3, feedback from individual servers is brought into
replica ranking to reflect the time-varying performance of servers, and the
distributed rate control and backpressure mechanism is invented. Despite of
C3's good performance, we reveal the timeliness issue of C3, which has large
impacts on both the replica ranking and the rate control, and propose the Tars
(timeliness-aware adaptive replica selection) scheme. Following the same
framework as C3, Tars improves the replica ranking by taking the timeliness of
the feedback information into consideration, as well as revises the rate
control of C3. Simulation results confirm that Tars outperforms C3.
</dc:description>
 <dc:description>Comment: 10pages,submitted to ICDCS 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08176</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Another Look at the Implementation of Read/write Registers in
  Crash-prone Asynchronous Message-Passing Systems (Extended Version)</dc:title>
 <dc:creator>Imbs, Damien</dc:creator>
 <dc:creator>Mostefaoui, Achour</dc:creator>
 <dc:creator>Perrin, Matthieu</dc:creator>
 <dc:creator>Raynal, Michel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  &quot; Yet another paper on &quot; the implementation of read/write registers in
crash-prone asynchronous message-passing systems! Yes..., but, differently from
its predecessors, this paper looks for a communication abstraction which
captures the essence of such an implementation in the same sense that total
order broadcast can be associated with consensus, or message causal delivery
can be associated with causal read/write registers. To this end, the paper
introduces a new communication abstraction, named SCD-broadcast (SCD standing
for &quot; Set Constrained Delivery &quot;), which, instead of a single message, delivers
to processes sets of messages (whose size can be arbitrary), such that the
sequences of message sets delivered to any two processes satisfies some
constraints. The paper then shows that: (a) SCD-broadcast allows for a very
simple implementation of a snapshot object (and consequently also of atomic
read/write registers) in crash-prone asynchronous message-passing systems, (b)
SCD-broadcast can be built from snapshot objects (hence SCD-broadcast and
snapshot objects --or read/write registers-- are &quot; computationally equivalent
&quot;), (c) SCD-broadcast can be built in message-passing systems where any
minority of processes may crash (which is the weakest assumption on the number
of possible process crashes needed to implement a read/write register).
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08178</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The metric dimension of the circulant graph $C(n,\pm\{1,2,3,4\})$</dc:title>
 <dc:creator>Grigorious, Cyriac</dc:creator>
 <dc:creator>Kalinowski, Thomas</dc:creator>
 <dc:creator>Ryan, Joe</dc:creator>
 <dc:creator>Stephen, Sudeep</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Let $G=(V,E)$ be a connected graph and let $d(u,v)$ denote the distance
between vertices $u,v \in V$. A metric basis for $G$ is a set $B\subseteq V$ of
minimum cardinality such that no two vertices of $G$ have the same distances to
all points of $B$. The cardinality of a metric basis of $G$ is called the
metric dimension of $G$, denoted by $\dim(G)$. In this paper we determine the
metric dimension of the circulant graphs $C(n,\pm\{1,2,3,4\})$ for all values
of $n$.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08178</dc:identifier>
 <dc:identifier>Australasian Journal of Combinatorics, 69(3), 417-441, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08192</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepNAT: Deep Convolutional Neural Network for Segmenting Neuroanatomy</dc:title>
 <dc:creator>Wachinger, Christian</dc:creator>
 <dc:creator>Reuter, Martin</dc:creator>
 <dc:creator>Klein, Tassilo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce DeepNAT, a 3D Deep convolutional neural network for the
automatic segmentation of NeuroAnaTomy in T1-weighted magnetic resonance
images. DeepNAT is an end-to-end learning-based approach to brain segmentation
that jointly learns an abstract feature representation and a multi-class
classification. We propose a 3D patch-based approach, where we do not only
predict the center voxel of the patch but also neighbors, which is formulated
as multi-task learning. To address a class imbalance problem, we arrange two
networks hierarchically, where the first one separates foreground from
background, and the second one identifies 25 brain structures on the
foreground. Since patches lack spatial context, we augment them with
coordinates. To this end, we introduce a novel intrinsic parameterization of
the brain volume, formed by eigenfunctions of the Laplace-Beltrami operator. As
network architecture, we use three convolutional layers with pooling, batch
normalization, and non-linearities, followed by fully connected layers with
dropout. The final segmentation is inferred from the probabilistic output of
the network with a 3D fully connected conditional random field, which ensures
label agreement between close voxels. The roughly 2.7 million parameters in the
network are learned with stochastic gradient descent. Our results show that
DeepNAT compares favorably to state-of-the-art methods. Finally, the purely
learning-based method may have a high potential for the adaptation to young,
old, or diseased brains by fine-tuning the pre-trained network with a small
training sample on the target application, where the availability of larger
datasets with manual annotations may boost the overall segmentation accuracy in
the future.
</dc:description>
 <dc:description>Comment: Accepted for publication in NeuroImage, special issue &quot;Brain
  Segmentation and Parcellation&quot;, 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08192</dc:identifier>
 <dc:identifier>doi:10.1016/j.neuroimage.2017.02.035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08193</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modularisation of Sequent Calculi for Normal and Non-normal Modalities</dc:title>
 <dc:creator>Lellmann, Bj&#xf6;rn</dc:creator>
 <dc:creator>Pimentel, Elaine</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  In this work we explore the connections between (linear) nested sequent
calculi and ordinary sequent calculi for normal and non-normal modal logics. By
proposing local versions to ordinary sequent rules we obtain linear nested
sequent calculi for a number of logics, including to our knowledge the first
nested sequent calculi for a large class of simply dependent multimodal logics,
and for many standard non-normal modal logics. The resulting systems are
modular and have separate left and right introduction rules for the modalities,
which makes them amenable to specification as bipole clauses. While this
granulation of the sequent rules introduces more choices for proof search, we
show how linear nested sequent calculi can be restricted to blocked
derivations, which directly correspond to ordinary sequent derivations.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08193</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08196</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Maximizing Energy and Data Delivery in Dense Wireless Local Area
  Networks</dc:title>
 <dc:creator>Chin, Kwan-Wu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Devices can now be powered wirelessly by Access Points (APs). However, an AP
cannot transmit frequently to charge devices as it may starve other nearby APs
operating on the same channel. Consequently, there is a need to schedule the
transmissions of APs to ensure their data queues remain short whilst charging
energy-harvesting devices. We present a finite-horizon Markov Decision Process
(MDP) to capture the queue states at APs and also channel conditions to nodes.
We then use the MDP to investigate the following transmission policies: max
weight, max queue, best channel state and random. Our results show that the max
weight policy has the best performance in terms of queue length and delivered
energy.
</dc:description>
 <dc:description>Comment: Submitted for possible publication</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08199</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mutual Information based labelling and comparing clusters</dc:title>
 <dc:creator>Koopman, Rob</dc:creator>
 <dc:creator>Wang, Shenghui</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  After a clustering solution is generated automatically, labelling these
clusters becomes important to help understanding the results. In this paper, we
propose to use a Mutual Information based method to label clusters of journal
articles. Topical terms which have the highest Normalised Mutual Information
(NMI) with a certain cluster are selected to be the labels of the cluster.
Discussion of the labelling technique with a domain expert was used as a check
that the labels are discriminating not only lexical-wise but also semantically.
Based on a common set of topical terms, we also propose to generate lexical
fingerprints as a representation of individual clusters. Eventually, we
visualise and compare these fingerprints of different clusters from either one
clustering solution or different ones.
</dc:description>
 <dc:description>Comment: Special Issue of Scientometrics: Same data - different results?
  Towards a comparative approach to the identification of thematic structures
  in science</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08199</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-017-2305-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08207</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximation Strategies for Generalized Binary Search in Weighted Trees</dc:title>
 <dc:creator>Dereniowski, Dariusz</dc:creator>
 <dc:creator>Kosowski, Adrian</dc:creator>
 <dc:creator>Uznanski, Przemyslaw</dc:creator>
 <dc:creator>Zou, Mengchuan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the following generalization of the binary search problem. A
search strategy is required to locate an unknown target node $t$ in a given
tree $T$. Upon querying a node $v$ of the tree, the strategy receives as a
reply an indication of the connected component of $T\setminus\{v\}$ containing
the target $t$. The cost of querying each node is given by a known non-negative
weight function, and the considered objective is to minimize the total query
cost for a worst-case choice of the target. Designing an optimal strategy for a
weighted tree search instance is known to be strongly NP-hard, in contrast to
the unweighted variant of the problem which can be solved optimally in linear
time. Here, we show that weighted tree search admits a quasi-polynomial time
approximation scheme: for any $0 \textless{} \varepsilon \textless{} 1$, there
exists a $(1+\varepsilon)$-approximation strategy with a computation time of
$n^{O(\log n / \varepsilon^2)}$. Thus, the problem is not APX-hard, unless $NP
\subseteq DTIME(n^{O(\log n)})$. By applying a generic reduction, we obtain as
a corollary that the studied problem admits a polynomial-time $O(\sqrt{\log
n})$-approximation. This improves previous $\hat O(\log n)$-approximation
approaches, where the $\hat O$-notation disregards $O(\mathrm{poly}\log\log
n)$-factors.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08208</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiple Fault Attack on PRESENT with a Hardware Trojan Implementation
  in FPGA</dc:title>
 <dc:creator>Breier, Jakub</dc:creator>
 <dc:creator>He, Wei</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Internet of Things connects lots of small constrained devices to the
Internet. As in any other environment, communication security is important and
cryptographic algorithms are one of many elements that we use in order to keep
messages secure. Because of the constrained nature of these environments, it is
necessary to use algorithms that do not require high computational power.
Lightweight ciphers are therefore ideal candidates for this purpose.
  In this paper, we explore a possibility of attacking an ultra-lightweight
cipher PRESENT by using a multiple fault attack. Utilizing the Differential
Fault Analysis technique, we were able to recover the secret key with two
faulty encryptions and an exhaustive search of 2^16 remaining key bits. Our
attack aims at four nibbles in the penultimate round of the cipher, causing
faulty output in all nibbles of the output. We also provide a practical attack
scenario by exploiting Hardware Trojan (HT) technique for the proposed fault
injection in a Xilinx Spartan-6 FPGA.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08208</dc:identifier>
 <dc:identifier>Proceedings of the 2015 International Workshop on Secure Internet
  of Things (SIoT), pp. 58-64</dc:identifier>
 <dc:identifier>doi:10.1109/SIOT.2015.15</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08210</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Contextualization of topics: Browsing through the universe of
  bibliographic information</dc:title>
 <dc:creator>Koopman, Rob</dc:creator>
 <dc:creator>Wang, Shenghui</dc:creator>
 <dc:creator>Scharnhorst, Andrea</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This paper describes how semantic indexing can help to generate a contextual
overview of topics and visually compare clusters of articles. The method was
originally developed for an innovative information exploration tool, called
Ariadne, which operates on bibliographic databases with tens of millions of
records. In this paper, the method behind Ariadne is further developed and
applied to the research question of the special issue &quot;Same data, different
results&quot; - the better understanding of topic (re-)construction by different
bibliometric approaches. For the case of the Astro dataset of 111,616 articles
in astronomy and astrophysics, a new instantiation of the interactive exploring
tool, LittleAriadne, has been created. This paper contributes to the overall
challenge to delineate and define topics in two different ways. First, we
produce two clustering solutions based on vector representations of articles in
a lexical space. These vectors are built on semantic indexing of entities
associated with those articles. Second, we discuss how LittleAriadne can be
used to browse through the network of topical terms, authors, journals,
citations and various cluster solutions of the Astro dataset. More
specifically, we treat the assignment of an article to the different clustering
solutions as an additional element of its bibliographic record. Keeping the
principle of semantic indexing on the level of such an extended list of
entities of the bibliographic record, LittleAriadne in turn provides a
visualization of the context of a specific clustering solution. It also conveys
the similarity of article clusters produced by different algorithms, hence
representing a complementary approach to other possible means of comparison.
</dc:description>
 <dc:description>Comment: Special Issue of Scientometrics: Same data - different results?
  Towards a comparative approach to the identification of thematic structures
  in science</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08210</dc:identifier>
 <dc:identifier>doi:10.1007/s11192-017-2303-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08211</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic Chaining and the Role of Partial Feedback in Online
  Nonparametric Learning</dc:title>
 <dc:creator>Cesa-Bianchi, Nicol&#xf2;</dc:creator>
 <dc:creator>Gaillard, Pierre</dc:creator>
 <dc:creator>Gentile, Claudio</dc:creator>
 <dc:creator>Gerchinovitz, S&#xe9;bastien</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We investigate contextual online learning with nonparametric (Lipschitz)
comparison classes under different assumptions on losses and feedback
information. For full information feedback and Lipschitz losses, we design the
first explicit algorithm achieving the minimax regret rate (up to log factors).
In a partial feedback model motivated by second-price auctions, we obtain
algorithms for Lipschitz and semi-Lipschitz losses with regret bounds improving
on the known bounds for standard bandit feedback. Our analysis combines novel
results for contextual second-price auctions with a novel algorithmic approach
based on chaining. When the context space is Euclidean, our chaining approach
is efficient and delivers an even better regret bound.
</dc:description>
 <dc:description>Comment: This document is the full version of an extended abstract accepted
  for presentation at COLT 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08212</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Anticipating many futures: Online human motion prediction and synthesis
  for human-robot collaboration</dc:title>
 <dc:creator>B&#xfc;tepage, Judith</dc:creator>
 <dc:creator>Kjellstr&#xf6;m, Hedvig</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Fluent and safe interactions of humans and robots require both partners to
anticipate the others' actions. A common approach to human intention inference
is to model specific trajectories towards known goals with supervised
classifiers. However, these approaches do not take possible future movements
into account nor do they make use of kinematic cues, such as legible and
predictable motion. The bottleneck of these methods is the lack of an accurate
model of general human motion. In this work, we present a conditional
variational autoencoder that is trained to predict a window of future human
motion given a window of past frames. Using skeletal data obtained from RGB
depth images, we show how this unsupervised approach can be used for online
motion prediction for up to 1660 ms. Additionally, we demonstrate online target
prediction within the first 300-500 ms after motion onset without the use of
target specific training data. The advantage of our probabilistic approach is
the possibility to draw samples of possible future motions. Finally, we
investigate how movements and kinematic cues are represented on the learned low
dimensional manifold.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08217</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A case study on English-Malayalam Machine Translation</dc:title>
 <dc:creator>S, Sreelekha</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this paper we present our work on a case study on Statistical Machine
Translation (SMT) and Rule based machine translation (RBMT) for translation
from English to Malayalam and Malayalam to English. One of the motivations of
our study is to make a three way performance comparison, such as, a) SMT and
RBMT b) English to Malayalam SMT and Malayalam to English SMT c) English to
Malayalam RBMT and Malayalam to English RBMT. We describe the development of
English to Malayalam and Malayalam to English baseline phrase based SMT system
and the evaluation of its performance compared against the RBMT system. Based
on our study the observations are: a) SMT systems outperform RBMT systems, b)
In the case of SMT, English - Malayalam systems perform better than that of
Malayalam - English systems, c) In the case RBMT, Malayalam to English systems
are performing better than English to Malayalam systems. Based on our
evaluations and detailed error analysis, we describe the requirements of
incorporating morphological processing into the SMT to improve the accuracy of
translation.
</dc:description>
 <dc:description>Comment: This paper contains 10 pages with 4 figures and 10 tables</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08217</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08222</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergistic Team Composition</dc:title>
 <dc:creator>Andrejczuk, Ewa</dc:creator>
 <dc:creator>Rodriguez-Aguilar, Juan A.</dc:creator>
 <dc:creator>Roig, Carme</dc:creator>
 <dc:creator>Sierra, Carles</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Effective teams are crucial for organisations, especially in environments
that require teams to be constantly created and dismantled, such as software
development, scientific experiments, crowd-sourcing, or the classroom. Key
factors influencing team performance are competences and personality of team
members. Hence, we present a computational model to compose proficient and
congenial teams based on individuals' personalities and their competences to
perform tasks of different nature. With this purpose, we extend Wilde's
post-Jungian method for team composition, which solely employs individuals'
personalities. The aim of this study is to create a model to partition agents
into teams that are balanced in competences, personality and gender. Finally,
we present some preliminary empirical results that we obtained when analysing
student performance. Results show the benefits of a more informed team
composition that exploits individuals' competences besides information about
their personalities.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08222</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08225</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the second Feng-Rao distance of Algebraic Geometry codes related to
  Arf semigroups</dc:title>
 <dc:creator>Farr&#xe1;n, J. I.</dc:creator>
 <dc:creator>Garc&#xed;a-S&#xe1;nchez, P. A.</dc:creator>
 <dc:creator>Heredia, B. A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>11T71, 20M14, 11Y55</dc:subject>
 <dc:description>  We describe the second (generalized) Feng-Rao distance for elements in an Arf
numerical semigroup that are greater than or equal to the conductor of the
semigroup. This provides a lower bound for the second Hamming weight for one
point AG codes. In particular, we can obtain the second Feng-Rao distance for
the codes defined by asymptotically good towers of function fields whose
Weierstrass semigroups are inductive. In addition, we compute the second
Feng-Rao number, and provide some examples and comparisons with previous
results on this topic. These calculations rely on Ap\'{e}ry sets, and thus
several results concerning Ap\'ery sets of Arf semigroups are presented.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08231</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Precision Batch-Normalized Activations</dc:title>
 <dc:creator>Graham, Benjamin</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Artificial neural networks can be trained with relatively low-precision
floating-point and fixed-point arithmetic, using between one and 16 bits.
Previous works have focused on relatively wide-but-shallow, feed-forward
networks. We introduce a quantization scheme that is compatible with training
very deep neural networks. Quantizing the network activations in the middle of
each batch-normalization module can greatly reduce the amount of memory and
computational power needed, with little loss in accuracy.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08234</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;If You Can't Beat them, Join them&quot;: A Usability Approach to
  Interdependent Privacy in Cloud Apps</dc:title>
 <dc:creator>Harkous, Hamza</dc:creator>
 <dc:creator>Aberer, Karl</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Cloud storage services, like Dropbox and Google Drive, have growing
ecosystems of 3rd party apps that are designed to work with users' cloud files.
Such apps often request full access to users' files, including files shared
with collaborators. Hence, whenever a user grants access to a new vendor, she
is inflicting a privacy loss on herself and on her collaborators too. Based on
analyzing a real dataset of 183 Google Drive users and 131 third party apps, we
discover that collaborators inflict a privacy loss which is at least 39% higher
than what users themselves cause. We take a step toward minimizing this loss by
introducing the concept of History-based decisions. Simply put, users are
informed at decision time about the vendors which have been previously granted
access to their data. Thus, they can reduce their privacy loss by not
installing apps from new vendors whenever possible. Next, we realize this
concept by introducing a new privacy indicator, which can be integrated within
the cloud apps' authorization interface. Via a web experiment with 141
participants recruited from CrowdFlower, we show that our privacy indicator can
significantly increase the user's likelihood of choosing the app that minimizes
her privacy loss. Finally, we explore the network effect of History-based
decisions via a simulation on top of large collaboration networks. We
demonstrate that adopting such a decision-making process is capable of reducing
the growth of users' privacy loss by 70% in a Google Drive-based network and by
40% in an author collaboration network. This is despite the fact that we
neither assume that users cooperate nor that they exhibit altruistic behavior.
To our knowledge, our work is the first to provide quantifiable evidence of the
privacy risk that collaborators pose in cloud apps. We are also the first to
mitigate this problem via a usable privacy approach.
</dc:description>
 <dc:description>Comment: Authors' extended version of the paper published at CODASPY 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08234</dc:identifier>
 <dc:identifier>doi:10.1145/3029806.3029837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08235</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Inference using Implicit Distributions</dc:title>
 <dc:creator>Husz&#xe1;r, Ferenc</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generative adversarial networks (GANs) have given us a great tool to fit
implicit generative models to data. Implicit distributions are ones we can
sample from easily, and take derivatives of samples with respect to model
parameters. These models are highly expressive and we argue they can prove just
as useful for variational inference (VI) as they are for generative modelling.
Several papers have proposed GAN-like algorithms for inference, however,
connections to the theory of VI are not always well understood. This paper
provides a unifying review of existing algorithms establishing connections
between variational autoencoders, adversarially learned inference, operator VI,
GAN-based image reconstruction, and more. Secondly, the paper provides a
framework for building new algorithms: depending on the way the variational
bound is expressed we introduce prior-contrastive and joint-contrastive
methods, and show practical inference algorithms based on either density ratio
estimation or denoising.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08236</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Critical Improvement On Open Shop Scheduling Algorithm For Routing In
  Interconnection Networks</dc:title>
 <dc:creator>Birmpilis, Stavros</dc:creator>
 <dc:creator>Aslanidis, Timotheos</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the past years, Interconnection Networks have been used quite often and
especially in applications where parallelization is critical. Message packets
transmitted through such networks can be interrupted using buffers in order to
maximize network usage and minimize the time required for all messages to reach
their destination. However, preempting a packet will result in topology
reconfiguration and consequently in time cost. The problem of scheduling
message packets through such a network is referred to as PBS and is known to be
NP-Hard. In this paper we have improved, critically, variations of polynomially
solvable instances of Open Shop to approximate PBS. We have combined these
variations and called the induced algorithm IHSA, Improved Hybridic Scheduling
Algorithm. We ran experiments to establish the efficiency of IHSA and found
that in all datasets used it produces schedules very close to the optimal. In
addition, we tested IHSA with datasets that follow non-uniform distributions
and provided statistical data which illustrates better its performance.To
further establish the efficiency of IHSA we ran tests to compare it to SGA,
another algorithm which when tested in the past has yielded excellent results.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08236</dc:identifier>
 <dc:identifier>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.9, No.1, January 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08238</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus Patterns parameterized by input string length is W[1]-hard</dc:title>
 <dc:creator>Bulteau, Laurent</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We consider the Consensus Patterns problem, where, given a set of input
strings, one is asked to extract a long-enough pattern which appears (with some
errors) in all strings. We prove that this problem is W[1]-hard when
parameterized by the maximum length of input strings.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08242</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RDCL 3D, a Model Agnostic Web Framework for the Design and Composition
  of NFV Services</dc:title>
 <dc:creator>Salsano, Stefano</dc:creator>
 <dc:creator>Lombardo, Francesco</dc:creator>
 <dc:creator>Pisa, Claudio</dc:creator>
 <dc:creator>Greto, Pierluigi</dc:creator>
 <dc:creator>Melazzi, Nicola Blefari</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We present RDCL 3D, a &quot;model agnostic&quot; web framework for the design and
composition of NFV services and components. The framework allows editing and
validating the descriptors of services and components both textually and
graphically and supports the interaction with external orchestrators or with
deployment and execution environments. RDCL 3D is open source and designed with
a modular approach, allowing developers to &quot;plug in&quot; the support for new
models. We describe several advances with respect to the NFV state of the art,
which have been implemented with RDCL 3D. We have integrated in the platform
the latest ETSI NFV ISG model specifications for which no parsers/validators
were available. We have also included in the platform the support for OASIS
TOSCA models, reusing existing parsers. Then we have considered the modelling
of components in a modular software router (Click), which goes beyond the
traditional scope of NFV. We have further developed this approach by combining
traditional NFV components (Virtual Network Functions) and Click elements in a
single model. Finally, we have considered the support of this solution using
the Unikernels virtualization technology.
</dc:description>
 <dc:description>Comment: Accepted paper</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08242</dc:identifier>
 <dc:identifier>3rd IEEE International Workshop on Orchestration for Software
  Defined Infrastructures, O4SDI at IEEE NFV-SDN conference, Berlin, 6-8
  November 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08247</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Expected Value of the Determinant of Random Sum of Rank-One
  Matrices</dc:title>
 <dc:creator>Khosoussi, Kasra</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  We present a simple, yet useful result about the expected value of the
determinant of random sum of rank-one matrices. Computing such expectations in
general may involve a sum over exponentially many terms. Nevertheless, we show
that an interesting and useful class of such expectations that arise in, e.g.,
D-optimal estimation and random graphs can be computed efficiently via
computing a single determinant.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08248</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable and Distributed Clustering via Lightweight Coresets</dc:title>
 <dc:creator>Bachem, Olivier</dc:creator>
 <dc:creator>Lucic, Mario</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Coresets are compact representations of data sets such that models trained on
a coreset are provably competitive with models trained on the full data set. As
such, they have been successfully used to scale up clustering models to massive
data sets. While existing approaches generally only allow for multiplicative
approximation errors, we propose a novel notion of coresets called lightweight
coresets that allows for both multiplicative and additive errors. We provide a
single algorithm to construct light-weight coresets for k-Means clustering,
Bregman clustering and maximum likelihood estimation of Gaussian mixture
models. The algorithm is substantially faster than existing constructions,
embarrassingly parallel and resulting coresets are smaller. In an extensive
experimental evaluation, we demonstrate that the proposed method outperforms
existing coreset constructions.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08249</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniform Deviation Bounds for Unbounded Loss Functions like k-Means</dc:title>
 <dc:creator>Bachem, Olivier</dc:creator>
 <dc:creator>Lucic, Mario</dc:creator>
 <dc:creator>Hassani, S. Hamed</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Uniform deviation bounds limit the difference between a model's expected loss
and its loss on an empirical sample uniformly for all models in a learning
problem. As such, they are a critical component to empirical risk minimization.
In this paper, we provide a novel framework to obtain uniform deviation bounds
for loss functions which are *unbounded*. In our main application, this allows
us to obtain bounds for $k$-Means clustering under weak assumptions on the
underlying distribution. If the fourth moment is bounded, we prove a rate of
$\mathcal{O}\left(m^{-\frac12}\right)$ compared to the previously known
$\mathcal{O}\left(m^{-\frac14}\right)$ rate. Furthermore, we show that the rate
also depends on the kurtosis - the normalized fourth moment which measures the
&quot;tailedness&quot; of a distribution. We further provide improved rates under
progressively stronger assumptions, namely, bounded higher moments,
subgaussianity and bounded support.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08255</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning with Errors is easy with quantum samples</dc:title>
 <dc:creator>Grilo, Alex B.</dc:creator>
 <dc:creator>Kerenidis, Iordanis</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Learning with Errors is one of the fundamental problems in computational
learning theory and has in the last years become the cornerstone of
post-quantum cryptography. In this work, we study the quantum sample complexity
of Learning with Errors and show that there exists an efficient quantum
learning algorithm (with polynomial sample and time complexity) for the
Learning with Errors problem where the error distribution is the one used in
cryptography. While our quantum learning algorithm does not break the LWE-based
encryption schemes proposed in the cryptography literature, it does have some
interesting implications for cryptography: first, when building an LWE-based
scheme, one needs to be careful about the access to the public-key generation
algorithm that is given to the adversary; second, our algorithm shows a
possible way for attacking LWE-based encryption by using classical samples to
approximate the quantum sample state, since then using our quantum learning
algorithm would solve LWE.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08256</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DepQBF 6.0: A Search-Based QBF Solver Beyond Traditional QCDCL</dc:title>
 <dc:creator>Lonsing, Florian</dc:creator>
 <dc:creator>Egly, Uwe</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We present the latest major release version 6.0 of the quantified Boolean
formula (QBF) solver DepQBF, which is based on QCDCL. QCDCL is an extension of
the conflict-driven clause learning (CDCL) paradigm implemented in state of the
art propositional satisfiability (SAT) solvers. The Q-resolution calculus
(QRES) is a QBF proof system which underlies QCDCL. QCDCL solvers can produce
QRES proofs of QBFs in prenex conjunctive normal form (PCNF) as a byproduct of
the solving process. In contrast to traditional QCDCL based on QRES, DepQBF 6.0
implements a variant of QCDCL which is based on a generalization of QRES. This
generalization is due to a set of additional axioms and leaves the original
Q-resolution rules unchanged. The generalization of QRES enables QCDCL to
potentially produce exponentially shorter proofs than the traditional variant.
We present an overview of the features implemented in DepQBF and report on
experimental results which demonstrate the effectiveness of generalized QRES in
QCDCL.
</dc:description>
 <dc:description>Comment: 12 pages + appendix; to appear in the proceedings of CADE-26, LNCS,
  Springer, 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08256</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-63046-5_23</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08258</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Upper and Lower Bounds for the Ergodic Capacity of MIMO Jacobi Fading
  Channels</dc:title>
 <dc:creator>Nafkha, Amor</dc:creator>
 <dc:creator>Bonnefoi, Remi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In multi-(core/mode) optical fiber communication, the transmission channel
can be modeled as a complex sub-matrix of the Haar-distributed unitary matrix
(complex Jacobi unitary ensemble). In this letter, we present new analytical
expressions of the upper and lower bounds for the ergodic capacity of
multiple-input multiple-output Jacobi-fading channels. Recent results on the
determinant of the Jacobi unitary ensemble are employed to derive a tight lower
bound on the ergodic capacity. We use Jensen's inequality to provide an
analytical closed-form upper bound to the ergodic capacity at any
signal-to-noise ratio (SNR). Closed-form expressions of the ergodic capacity,
at low and high SNR regimes, are also derived. Simulation results are presented
to validate the accuracy of the derived expressions.
</dc:description>
 <dc:description>Comment: 4 pages, 6 figures, submitted to the IEEE Photonics Technology
  Letters</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08258</dc:identifier>
 <dc:identifier>doi:10.1364/OE.25.012144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08259</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast and Accurate Inference with Adaptive Ensemble Prediction in Image
  Classification with Deep Neural Networks</dc:title>
 <dc:creator>Inoue, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Ensembling multiple predictions is a widely used technique to improve the
accuracy of various machine learning tasks. In image classification tasks, for
example, averaging the predictions for multiple patches extracted from the
input image significantly improves accuracy. Using multiple networks trained
independently to make predictions improves accuracy further. One obvious
drawback of the ensembling technique is its higher execution cost during
inference. If we average 100 predictions, the execution cost will be 100 times
as high as the cost without the ensemble. This higher cost limits the
real-world use of ensembling, even though using it is almost the norm to win
image classification competitions. In this paper, we describe a new technique
called adaptive ensemble prediction, which achieves the benefits of ensembling
with much smaller additional execution costs. Our observation behind this
technique is that many easy-to-predict inputs do not require ensembling. Hence
we calculate the confidence level of the prediction for each input on the basis
of the probability of the predicted label, i.e. the outputs from the softmax,
during the ensembling computation. If the prediction for an input reaches a
high enough probability on the basis of the confidence level, we stop
ensembling for this input to avoid wasting computation power. We evaluated the
adaptive ensembling by using various datasets and showed that it reduces the
computation time significantly while achieving similar accuracy to the naive
ensembling.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08259</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08272</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dataset for Developing and Benchmarking Active Vision</dc:title>
 <dc:creator>Ammirato, Phil</dc:creator>
 <dc:creator>Poirson, Patrick</dc:creator>
 <dc:creator>Park, Eunbyung</dc:creator>
 <dc:creator>Kosecka, Jana</dc:creator>
 <dc:creator>Berg, Alexander C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a new public dataset with a focus on simulating robotic vision
tasks in everyday indoor environments using real imagery. The dataset includes
20,000+ RGB-D images and 50,000+ 2D bounding boxes of object instances densely
captured in 9 unique scenes. We train a fast object category detector for
instance detection on our data. Using the dataset we show that, although
increasingly accurate and fast, the state of the art for object detection is
still severely impacted by object scale, occlusion, and viewing direction all
of which matter for robotics applications. We next validate the dataset for
simulating active vision, and use the dataset to develop and evaluate a
deep-network-based system for next best move prediction for object
classification using reinforcement learning. Our dataset is available for
download at cs.unc.edu/~ammirato/active_vision_dataset_website/.
</dc:description>
 <dc:description>Comment: To appear at ICRA 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08272</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08283</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Learning to Speed-Up Control of Prosthetic Hands: a Few Things
  Everybody Should Know</dc:title>
 <dc:creator>Gregori, Valentina</dc:creator>
 <dc:creator>Gijsberts, Arjan</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A number of studies have proposed to use domain adaptation to reduce the
training efforts needed to control an upper-limb prosthesis exploiting
pre-trained models from prior subjects. These studies generally reported
impressive reductions in the required number of training samples to achieve a
certain level of accuracy for intact subjects. We further investigate two
popular methods in this field to verify whether this result equally applies to
amputees. Our findings show instead that this improvement can largely be
attributed to a suboptimal hyperparameter configuration. When hyperparameters
are appropriately tuned, the standard approach that does not exploit prior
information performs on par with the more complicated transfer learning
algorithms. Additionally, earlier studies erroneously assumed that the number
of training samples relates proportionally to the efforts required from the
subject. However, a repetition of a movement is the atomic unit for subjects
and the total number of repetitions should therefore be used as reliable
measure for training efforts. Also when correcting for this mistake, we do not
find any performance increase due to the use of prior models.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08286</identifier>
 <datestamp>2017-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balancing Lexicographic Fairness and a Utilitarian Objective with
  Application to Kidney Exchange</dc:title>
 <dc:creator>McElfresh, Duncan C.</dc:creator>
 <dc:creator>Dickerson, John P.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  Balancing fairness and efficiency in resource allocation is a classical
economic and computational problem. The price of fairness measures the
worst-case loss of economic efficiency when using an inefficient but fair
allocation rule; for indivisible goods in many settings, this price is
unacceptably high. One such setting is kidney exchange, where needy patients
swap willing but incompatible kidney donors. In this work, we close an open
problem regarding the theoretical price of fairness in modern kidney exchanges.
We then propose a general hybrid fairness rule that balances a strict
lexicographic preference ordering over classes of agents, and a utilitarian
objective that maximizes economic efficiency. We develop a utility function for
this rule that favors disadvantaged groups lexicographically; but if cost to
overall efficiency becomes too high, it switches to a utilitarian objective.
This rule has only one parameter which is proportional to a bound on the price
of fairness, and can be adjusted by policymakers. We apply this rule to real
data from a large kidney exchange and show that our hybrid rule produces more
reliable outcomes than other fairness rules.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08289</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Almost disjoint spanning trees: relaxing the conditions for completely
  independent spanning trees</dc:title>
 <dc:creator>Darties, Benoit</dc:creator>
 <dc:creator>Gastineau, Nicolas</dc:creator>
 <dc:creator>Togni, Olivier</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The search of spanning trees with interesting disjunction properties has led
to the introduction of edge-disjoint spanning trees, independent spanning trees
and more recently completely independent spanning trees. We group together
these notions by defining (i, j)-disjoint spanning trees, where i (j,
respectively) is the number of vertices (edges, respectively) that are shared
by more than one tree. We illustrate how (i, j)-disjoint spanning trees provide
some nuances between the existence of disjoint connected dominating sets and
completely independent spanning trees. We prove that determining if there exist
two (i, j)-disjoint spanning trees in a graph G is NP-complete, for every two
positive integers i and j. Moreover we prove that for square of graphs,
k-connected interval graphs, complete graphs and several grids, there exist (i,
j)-disjoint spanning trees for interesting values of i and j.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08289</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08291</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Manifesto for Web Science @ 10</dc:title>
 <dc:creator>Hall, Wendy</dc:creator>
 <dc:creator>Hendler, Jim</dc:creator>
 <dc:creator>Staab, Steffen</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>H.0</dc:subject>
 <dc:subject>K.4.0</dc:subject>
 <dc:description>  Twenty-seven years ago, one of the biggest societal changes in human history
began slowly when the technical foundations for the World Wide Web were defined
by Tim Berners-Lee. Ever since, the Web has grown exponentially, reaching far
beyond its original technical foundations and deeply affecting the world today
- and even more so the society of the future. We have seen that the Web can
influence the realization of human rights and even the pursuit of happiness.
The Web provides an infrastructure to help us to learn, to work, to communicate
with loved ones, and to provide entertainment. However, it also creates an
environment affected by the digital divide between those who have and those who
do not have access. Additionally, the Web provides challenges we must
understand if we are to find a viable balance between data ownership and
privacy protection, between over-whelming surveillance and the prevention of
terrorism. For the Web to succeed, we need to understand its societal
challenges including increased crime, the impact of social platforms and
socio-economic discrimination, and we must work towards fairness, social
inclusion, and open governance.
  Ten Yars ago, the field of Web Science was created to explore the science
underlying the Web from a socio-technical perspective including its
mathematical properties, engineering principles, and social impacts. Ten years
later, we are learning much as the interdisciplinary endeavor to understand the
Web's global information space continues to grow.
  In this article we want to elicit the major lessons we have learned through
Web Science and make some cautious predictions of what to expect next.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08299</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independent Set Size Approximation in Graph Streams</dc:title>
 <dc:creator>Cormode, Graham</dc:creator>
 <dc:creator>Dark, Jacques</dc:creator>
 <dc:creator>Konrad, Christian</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of estimating the size of independent sets in a graph
$G$ defined by a stream of edges. Our approach relies on the Caro-Wei bound,
which expresses the desired quantity in terms of a sum over nodes of the
reciprocal of their degrees, denoted by $\beta(G)$. Our results show that
$\beta(G)$ can be approximated accurately, based on a provided lower bound on
$\beta$. Stronger results are possible when the edges are promised to arrive
grouped by an incident node. In this setting, we obtain a value that is at most
a logarithmic factor below the true value of $\beta$ and no more than the true
independent set size. To justify the form of this bound, we also show an
$\Omega(n/\beta)$ lower bound on any algorithm that approximates $\beta$ up to
a constant factor.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08299</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08300</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Functional Complexity affects the Scalability-Energy Efficiency
  Trade-Off of HCC WSN Clustering</dc:title>
 <dc:creator>Dzaferagic, Merim</dc:creator>
 <dc:creator>Kaminski, Nicholas</dc:creator>
 <dc:creator>Macaluso, Irene</dc:creator>
 <dc:creator>Marchetti, Nicola</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Even though clustering algorithms in Wireless Sensor Networks (WSN) are a
well investigate subject, the increasing interest in the Internet of Things
(IoT) and 5G technologies has precipitated the need of new ways to comprehend
and overcome a new set of challenges. While studies mainly propose new
algorithms and compare these algorithms based on a set of properties (e.g.
energy efficiency, scalability), none of them focuses on the underlying
mechanisms and organizational patterns that lead to these properties. We
address this lack of understanding by applying a complex systems science
approach to investigate the properties of WSNs arising from the communication
patterns of the network nodes. We represent different implementations of
clustering in WSNs with a functional topology graph. Moreover, we employ a
complexity metric - functional complexity (CF) - to explain how local
interactions give rise to the global behavior of the network. Our analysis
shows that higher values of CF indicate higher scalability and lower energy
efficiency.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1610.05970</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08301</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biometric Systems Private by Design: Reasoning about privacy properties
  of biometric system architectures</dc:title>
 <dc:creator>Bringer, Julien</dc:creator>
 <dc:creator>Chabanne, Herve</dc:creator>
 <dc:creator>Metayer, Daniel Le</dc:creator>
 <dc:creator>Lescuyer, Roch</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  This work aims to show the applicability, and how, of privacy by design
approach to biometric systems and the benefit of using formal methods to this
end. Starting from a general framework that has been introduced at STM in 2014,
that enables to define privacy architectures and to formally reason about their
properties, we explain how it can be adapted to biometrics. The choice of
particular techniques and the role of the components (central server, secure
module, biometric terminal, smart card, etc.) in the architecture have a strong
impact on the privacy guarantees provided by a biometric system. In the
literature, some architectures have already been analysed in some way. However,
the existing proposals were made on a case by case basis, which makes it
difficult to compare them and to provide a rationale for the choice of specific
options. In this paper, we describe, on different architectures with various
levels of protection, how a general framework for the definition of privacy
architectures can be used to specify the design options of a biometric systems
and to reason about them in a formal way.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08303</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying beneficial task relations for multi-task learning in deep
  neural networks</dc:title>
 <dc:creator>Bingel, Joachim</dc:creator>
 <dc:creator>S&#xf8;gaard, Anders</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Multi-task learning (MTL) in deep neural networks for NLP has recently
received increasing interest due to some compelling benefits, including its
potential to efficiently regularize models and to reduce the need for labeled
data. While it has brought significant improvements in a number of NLP tasks,
mixed results have been reported, and little is known about the conditions
under which MTL leads to gains in NLP. This paper sheds light on the specific
task relations that can lead to gains from MTL models over single-task setups.
</dc:description>
 <dc:description>Comment: Accepted for publication at EACL 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08306</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On-the-Fly Computation of Bisimilarity Distances</dc:title>
 <dc:creator>Bacci, Giorgio</dc:creator>
 <dc:creator>Bacci, Giovanni</dc:creator>
 <dc:creator>Larsen, Kim G.</dc:creator>
 <dc:creator>Mardare, Radu</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.1.4</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:description>  We propose a distance between continuous-time Markov chains (CTMCs) and study
the problem of computing it by comparing three different algorithmic
methodologies: iterative, linear program, and on-the-fly. In a work presented
at FoSSaCS'12, Chen et al. characterized the bisimilarity distance of
Desharnais et al. between discrete-time Markov chains as an optimal solution of
a linear program that can be solved by using the ellipsoid method. Inspired by
their result, we propose a novel linear program characterization to compute the
distance in the continuous-time setting. Differently from previous proposals,
ours has a number of constraints that is bounded by a polynomial in the size of
the CTMC. This, in particular, proves that the distance we propose can be
computed in polynomial time. Despite its theoretical importance, the proposed
linear program characterization turns out to be inefficient in practice.
Nevertheless, driven by the encouraging results of our previous work presented
at TACAS'13, we propose an efficient on-the-fly algorithm, which, unlike the
other mentioned solutions, computes the distances between two given states
avoiding an exhaustive exploration of the state space. This technique works by
successively refining over-approximations of the target distances using a
greedy strategy, which ensures that the state space is further explored only
when the current approximations are improved. Tests performed on a consistent
set of (pseudo)randomly generated CTMCs show that our algorithm improves, on
average, the efficiency of the corresponding iterative and linear program
methods with orders of magnitude.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08306</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 13, Issue 2 (June 30,
  2017) lmcs:3753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08318</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Privacy Preserving Viola-Jones Type Object Detection via
  Random Base Image Representation</dc:title>
 <dc:creator>Jin, Xin</dc:creator>
 <dc:creator>Yuan, Peng</dc:creator>
 <dc:creator>Li, Xiaodong</dc:creator>
 <dc:creator>Song, Chenggen</dc:creator>
 <dc:creator>Ge, Shiming</dc:creator>
 <dc:creator>Zhao, Geng</dc:creator>
 <dc:creator>Chen, Yingya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A cloud server spent a lot of time, energy and money to train a Viola-Jones
type object detector with high accuracy. Clients can upload their photos to the
cloud server to find objects. However, the client does not want the leakage of
the content of his/her photos. In the meanwhile, the cloud server is also
reluctant to leak any parameters of the trained object detectors. 10 years ago,
Avidan &amp; Butman introduced Blind Vision, which is a method for securely
evaluating a Viola-Jones type object detector. Blind Vision uses standard
cryptographic tools and is painfully slow to compute, taking a couple of hours
to scan a single image. The purpose of this work is to explore an efficient
method that can speed up the process. We propose the Random Base Image (RBI)
Representation. The original image is divided into random base images. Only the
base images are submitted randomly to the cloud server. Thus, the content of
the image can not be leaked. In the meanwhile, a random vector and the secure
Millionaire protocol are leveraged to protect the parameters of the trained
object detector. The RBI makes the integral-image enable again for the great
acceleration. The experimental results reveal that our method can retain the
detection accuracy of that of the plain vision algorithm and is significantly
faster than the traditional blind vision, with only a very low probability of
the information leakage theoretically.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, To appear in the proceedings of the IEEE
  International Conference on Multimedia and Expo (ICME), Jul 10, 2017 - Jul
  14, 2017, Hong Kong, Hong Kong</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08319</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Translation Embedding Network for Visual Relation Detection</dc:title>
 <dc:creator>Zhang, Hanwang</dc:creator>
 <dc:creator>Kyaw, Zawlin</dc:creator>
 <dc:creator>Chang, Shih-Fu</dc:creator>
 <dc:creator>Chua, Tat-Seng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:description>  Visual relations, such as &quot;person ride bike&quot; and &quot;bike next to car&quot;, offer a
comprehensive scene understanding of an image, and have already shown their
great utility in connecting computer vision and natural language. However, due
to the challenging combinatorial complexity of modeling
subject-predicate-object relation triplets, very little work has been done to
localize and predict visual relations. Inspired by the recent advances in
relational representation learning of knowledge bases and convolutional object
detection networks, we propose a Visual Translation Embedding network (VTransE)
for visual relation detection. VTransE places objects in a low-dimensional
relation space where a relation can be modeled as a simple vector translation,
i.e., subject + predicate $\approx$ object. We propose a novel feature
extraction layer that enables object-relation knowledge transfer in a
fully-convolutional fashion that supports training and inference in a single
forward/backward pass. To the best of our knowledge, VTransE is the first
end-to-end relation detection network. We demonstrate the effectiveness of
VTransE over other state-of-the-art methods on two large-scale datasets: Visual
Relationship and Visual Genome. Note that even though VTransE is a purely
visual model, it is still competitive to the Lu's multi-modal model with
language priors.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08324</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Impedance control approch of Ultra High Power Electric Arc Furnace</dc:title>
 <dc:creator>Guk, Yun Chol</dc:creator>
 <dc:creator>Chol, Sin Yong</dc:creator>
 <dc:creator>Il, Kwak Son</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  An approach is proposed to design the intelligent electrode position
controller for UHP by using nonlinear scaling and fuzzy self tuning PID control
algorithm. First, nonlinear scaling of controlled variable that compensate the
nonlinearity of the object is proposed. Second, a fuzzy self tuning PID
electrode position control algorithm is designed and the parameters of the
fuzzy inference are optimized by using GA (Genetic Algorithm). Finally, the
effectiveness of the proposed approach is verified by field test.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08324</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08325</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System and source identification from operational vehicle responses: A
  novel modal model accounting for the track-vehicle interaction</dc:title>
 <dc:creator>De Filippis, Giovanni</dc:creator>
 <dc:creator>Palmieri, Davide</dc:creator>
 <dc:creator>Soria, Leonardo</dc:creator>
 <dc:creator>Mangialardi, Luigi</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>74H50, 93E12</dc:subject>
 <dc:description>  Operational Modal Analysis (OMA) is a powerful tool, widely used in the
fields of structural identification and health monitoring, and certainly
eligible for identifying the real in-operation behaviour of vehicle systems.
Several attempts can be found in the literature, for which the usage of
algorithms based on the classical OMA formulation has been strained for the
identification of passenger cars and industrial trucks. The interest is mainly
focused on the assessment of suspension behaviour and, thus, on the
identification of the so-called vehicle rigid body modes. But issues arise when
the operational identification of a vehicle system is performed, basically
related to the nature of the loads induced by the roughness of rolling
profiles. The forces exerted on the wheels, in fact, depending on their
location, are affected by time and/or spatial correlation, and, more over, do
not fit the form of white noise sequences. Thus, the nature of the excitation
strongly violate the hypotheses on which the formulation of classical OMA modal
model relies, leading to pronounced modelling errors and, in turn, to poorly
estimated modal parameters. In this paper, we develop a specialised modal
model, that we refer to as the Track-Vehicle Interaction Modal Model, able to
incorporate the character of road/rail inputs acting on vehicles during
operation. Since in this novel modal model the relationship between vehicle
system outputs and modal parameters is given explicitly, the development of new
specific curve fitting techniques, in the time-lag or frequency domain, is now
possible, making available simple and cost-effective tools for vehicle
operational identification. More over, a second, but not less important outcome
of the proposed modal model is the usage of the resulting techniques for the
indirect characterisation of rolling surface roughness, that can be used to
improve comfort and safety.
</dc:description>
 <dc:date>2017-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08325</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08327</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ArrayBridge: Interweaving declarative array processing with
  high-performance computing</dc:title>
 <dc:creator>Xing, Haoyuan</dc:creator>
 <dc:creator>Floratos, Sofoklis</dc:creator>
 <dc:creator>Blanas, Spyros</dc:creator>
 <dc:creator>Byna, Suren</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:creator>Wu, Kesheng</dc:creator>
 <dc:creator>Brown, Paul</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Scientists are increasingly turning to datacenter-scale computers to produce
and analyze massive arrays. Despite decades of database research that extols
the virtues of declarative query processing, scientists still write, debug and
parallelize imperative HPC kernels even for the most mundane queries. This
impedance mismatch has been partly attributed to the cumbersome data loading
process; in response, the database community has proposed in situ mechanisms to
access data in scientific file formats. Scientists, however, desire more than a
passive access method that reads arrays from files.
  This paper describes ArrayBridge, a bi-directional array view mechanism for
scientific file formats, that aims to make declarative array manipulations
interoperable with imperative file-centric analyses. Our prototype
implementation of ArrayBridge uses HDF5 as the underlying array storage library
and seamlessly integrates into the SciDB open-source array database system. In
addition to fast querying over external array objects, ArrayBridge produces
arrays in the HDF5 file format just as easily as it can read from it.
ArrayBridge also supports time travel queries from imperative kernels through
the unmodified HDF5 API, and automatically deduplicates between array versions
for space efficiency. Our extensive performance evaluation in NERSC, a
large-scale scientific computing facility, shows that ArrayBridge exhibits
statistically indistinguishable performance and I/O scalability to the native
SciDB storage engine.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08327</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08328</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Universal Ordinary Differential Equation</dc:title>
 <dc:creator>Bournez, Olivier</dc:creator>
 <dc:creator>Pouly, Amaury</dc:creator>
 <dc:subject>Mathematics - Classical Analysis and ODEs</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  An astonishing fact was established by Lee A. Rubel in 1981: there exists a
fixed non-trivial fourth-order polynomial differential algebraic equation (DAE)
such that for any continuous function $\phi$ on the reals, and for any positive
continuous function $\epsilon(t)$, it has a $\mathcal{C}^\infty$ solution with
$|y(t)-\phi(t)|&lt;\epsilon(t)$ for all $t$. Rubel provided an explicit example of
such a polynomial DAE. More examples have later been proposed by other authors.
  However, while these results may seem very surprising, their proofs are quite
frustrating for a computability theorist. First, the constructed DAE have no
unique solutions for a given initial data. This is very different from usual
notions of universality since there is no unambiguous notion of evolution for a
given initial data. Second, the proofs usually rely on solutions that are
piecewise defined and sometimes non-constructive. Third, the proofs of these
results can be interpreted more as the fact that polynomial algebraic
differential equations is a too loose a model compared to classical ordinary
differential equations. In particular, one may challenge whether the result is
really a universality result.
  The question whether one can require the solution that approximates $\phi$ to
be the unique solution for a given initial data is a well known open problem
[Rub81] (page 2), [boshernitzan1986universal] (Conjecture 6.2). In this
article, we solve it and show that Rubel's statement holds for polynomial
ordinary differential equations (ODEs), and since polynomial ODEs have a unique
solution given an initial data, this positively answers Rubel's open problem.
More precisely, we show that there exists a \textbf{fixed} polynomial ODE such
that for any $\phi$ and $\epsilon$ there exists some initial condition that
yields a solution that is $\epsilon$-close to $\phi$ at all times.
</dc:description>
 <dc:date>2017-02-20</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08334</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Stability Analysis of Perturbed Learning Automata with
  Constant Step-Size in Strategic-Form Games</dc:title>
 <dc:creator>Chasparis, Georgios C.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This paper considers a class of reinforcement-learning that belongs to the
family of Learning Automata and provides a stochastic-stability analysis in
strategic-form games. For this class of dynamics, convergence to pure Nash
equilibria has been demonstrated only for the fine class of potential games.
Prior work primarily provides convergence properties of the dynamics through
stochastic approximations, where the asymptotic behavior can be associated with
the limit points of an ordinary-differential equation (ODE). However, analyzing
global convergence through the ODE-approximation requires the existence of a
Lyapunov or a potential function, which naturally restricts the applicabity of
these algorithms to a fine class of games. To overcome these limitations, this
paper introduces an alternative framework for analyzing stochastic-stability
that is based upon an explicit characterization of the (unique) invariant
probability measure of the induced Markov chain.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08336</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Label Segmentation via Residual-Driven Adaptive Regularization</dc:title>
 <dc:creator>Hong, Byung-Woo</dc:creator>
 <dc:creator>Koo, Ja-Keoung</dc:creator>
 <dc:creator>Soatto, Stefano</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a variational multi-label segmentation algorithm based on a robust
Huber loss for both the data and the regularizer, minimized within a convex
optimization framework. We introduce a novel constraint on the common areas, to
bias the solution towards mutually exclusive regions. We also propose a
regularization scheme that is adapted to the spatial statistics of the residual
at each iteration, resulting in a varying degree of regularization being
applied as the algorithm proceeds: the effect of the regularizer is strongest
at initialization, and wanes as the solution increasingly fits the data. This
minimizes the bias induced by the regularizer at convergence. We design an
efficient convex optimization algorithm based on the alternating direction
method of multipliers using the equivalent relation between the Huber function
and the proximal operator of the one-norm. We empirically validate our proposed
algorithm on synthetic and real images and offer an information-theoretic
derivation of the cost-function that highlights the modeling choices made.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08339</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Fienup Methods for Regularized Phase Retrieval</dc:title>
 <dc:creator>Pauwels, Edouard</dc:creator>
 <dc:creator>Beck, Amir</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Sabach, Shoham</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Alternating minimization, or Fienup methods, have a long history in phase
retrieval. We provide new insights related to the empirical and theoretical
analysis of these algorithms when used with Fourier measurements and combined
with convex priors. In particular, we show that Fienup methods can be viewed as
performing alternating minimization on a regularized nonconvex least-squares
problem with respect to amplitude measurements. We then prove that under mild
additional structural assumptions on the prior (semi-algebraicity), the
sequence of signal estimates has a smooth convergent behaviour towards a
critical point of the nonconvex regularized least-squares objective. Finally,
we propose an extension to Fienup techniques, based on a projected gradient
descent interpretation and acceleration using inertial terms. We demonstrate
experimentally that this modification combined with an $\ell_1$ prior
constitutes a competitive approach for sparse phase retrieval.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08342</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Curie: Policy-based Secure Data Exchange</dc:title>
 <dc:creator>Celik, Z. Berkay</dc:creator>
 <dc:creator>Aksu, Hidayet</dc:creator>
 <dc:creator>Acar, Abbas</dc:creator>
 <dc:creator>Sheatsley, Ryan</dc:creator>
 <dc:creator>Uluagac, A. Selcuk</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Data sharing among partners---users, organizations, companies---is crucial
for the advancement of data analytics in many domains. Sharing through secure
computation and differential privacy allows these partners to perform private
computations on their sensitive data in controlled ways. However, in reality,
there exist complex relationships among members. Politics, regulations,
interest, trust, data demands and needs are one of the many reasons. Thus,
there is a need for a mechanism to meet these conflicting relationships on data
sharing. This paper presents Curie, an approach to exchange data among members
whose membership has complex relationships. The CPL policy language that allows
members to define the specifications of data exchange requirements is
introduced. Members (partners) assert who and what to exchange through their
local policies and negotiate a global sharing agreement. The agreement is
implemented in a multi-party computation that guarantees sharing among members
will comply with the policy as negotiated. The use of Curie is validated
through an example of a health care application built on recently introduced
secure multi-party computation and differential privacy frameworks, and policy
and performance trade-offs are explored.
</dc:description>
 <dc:description>Comment: updated (minor syntax errors)</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08343</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Inference with Amortised MCMC</dc:title>
 <dc:creator>Li, Yingzhen</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:creator>Liu, Qiang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel approximate inference algorithm that approximates a target
distribution by amortising the dynamics of a user-selected MCMC sampler. The
idea is to initialise MCMC using samples from an approximation network, apply
the MCMC operator to improve these samples, and finally use the samples to
update the approximation network thereby improving its quality. This provides a
new generic framework for approximate inference, allowing us to deploy highly
complex, or implicitly defined approximation families with intractable
densities, including approximations produced by warping a source of randomness
through a deep neural network. Experiments consider image modelling with deep
generative models as a challenging test for the method. Deep models trained
using amortised MCMC are shown to generate realistic looking samples as well as
producing diverse imputations for images with regions of missing pixels.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08349</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Data for Social Sciences: Measuring patterns of human behavior
  through large-scale mobile phone data</dc:title>
 <dc:creator>Sunds&#xf8;y, P&#xe5;l</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Through seven publications this dissertation shows how anonymized mobile
phone data can contribute to the social good and provide insights into human
behaviour on a large scale. The size of the datasets analysed ranges from 500
million to 300 billion phone records, covering millions of people. The key
contributions are two-fold:
  1. Big Data for Social Good: Through prediction algorithms the results show
how mobile phone data can be useful to predict important socio-economic
indicators, such as income, illiteracy and poverty in developing countries.
Such knowledge can be used to identify where vulnerable groups in society are,
reduce economic shocks and is a critical component for monitoring poverty rates
over time. Further, the dissertation demonstrates how mobile phone data can be
used to better understand human behaviour during large shocks in society,
exemplified by an analysis of data from the terror attack in Norway and a
natural disaster on the south-coast in Bangladesh. This work leads to an
increased understanding of how information spreads, and how millions of people
move around. The intention is to identify displaced people faster, cheaper and
more accurately than existing survey-based methods.
  2. Big Data for efficient marketing: Finally, the dissertation offers an
insight into how anonymised mobile phone data can be used to map out large
social networks, covering millions of people, to understand how products spread
inside these networks. Results show that by including social patterns and
machine learning techniques in a large-scale marketing experiment in Asia, the
adoption rate is increased by 13 times compared to the approach used by
experienced marketers. A data-driven and scientific approach to marketing,
through more tailored campaigns, contributes to less irrelevant offers for the
customers, and better cost efficiency for the companies.
</dc:description>
 <dc:description>Comment: 166 pages, PHD thesis</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08357</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Message Passing Approach for Decision Fusion in Adversarial
  Multi-Sensor Networks</dc:title>
 <dc:creator>Abrardo, Andrea</dc:creator>
 <dc:creator>Barni, Mauro</dc:creator>
 <dc:creator>Kallas, Kassem</dc:creator>
 <dc:creator>Tondi, Benedetta</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider a simple, yet widely studied, set-up in which a Fusion Center
(FC) is asked to make a binary decision about a sequence of system states by
relying on the possibly corrupted decisions provided by byzantine nodes, i.e.
nodes which deliberately alter the result of the local decision to induce an
error at the fusion center. When independent states are considered, the optimum
fusion rule over a batch of observations has already been derived, however its
complexity prevents its use in conjunction with large observation windows.
  In this paper, we propose a near-optimal algorithm based on message passing
that greatly reduces the computational burden of the optimum fusion rule. In
addition, the proposed algorithm retains very good performance also in the case
of dependent system states. By first focusing on the case of small observation
windows, we use numerical simulations to show that the proposed scheme
introduces a negligible increase of the decision error probability compared to
the optimum fusion rule. We then analyse the performance of the new scheme when
the FC make its decision by relying on long observation windows. We do so by
considering both the case of independent and Markovian system states and show
that the obtained performance are superior to those obtained with prior
suboptimal schemes. As an additional result, we confirm the previous finding
that, in some cases, it is preferable for the byzantine nodes to minimise the
mutual information between the sequence system states and the reports submitted
to the FC, rather than always flipping the local decision.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08359</identifier>
 <datestamp>2017-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Word Embeddings</dc:title>
 <dc:creator>Bamler, Robert</dc:creator>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a probabilistic language model for time-stamped text data which
tracks the semantic evolution of individual words over time. The model
represents words and contexts by latent trajectories in an embedding space. At
each moment in time, the embedding vectors are inferred from a probabilistic
version of word2vec [Mikolov et al., 2013]. These embedding vectors are
connected in time through a latent diffusion process. We describe two scalable
variational inference algorithms--skip-gram smoothing and skip-gram
filtering--that allow us to train the model jointly over all times; thus
learning on all data while simultaneously allowing word and context vectors to
drift. Experimental results on three different corpora demonstrate that our
dynamic model infers word embedding trajectories that are more interpretable
and lead to higher predictive likelihoods than competing methods that are based
on static models trained separately on time slices.
</dc:description>
 <dc:description>Comment: In the proceedings of the International Conference on Machine
  Learning (ICML 2017); 8 pages + references and supplement</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-07-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08359</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08360</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Map: Structured Memory for Deep Reinforcement Learning</dc:title>
 <dc:creator>Parisotto, Emilio</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A critical component to enabling intelligent reasoning in partially
observable environments is memory. Despite this importance, Deep Reinforcement
Learning (DRL) agents have so far used relatively simple memory architectures,
with the main methods to overcome partial observability being either a temporal
convolution over the past k frames or an LSTM layer. More recent work (Oh et
al., 2016) has went beyond these architectures by using memory networks which
can allow more sophisticated addressing schemes over the past k frames. But
even these architectures are unsatisfactory due to the reason that they are
limited to only remembering information from the last k frames. In this paper,
we develop a memory system with an adaptable write operator that is customized
to the sorts of 3D environments that DRL agents typically interact with. This
architecture, called the Neural Map, uses a spatially structured 2D memory
image to learn to store arbitrary information about the environment over long
time lags. We demonstrate empirically that the Neural Map surpasses previous
DRL memories on a set of challenging 2D and 3D maze environments and show that
it is capable of generalizing to environments that were not seen during
training.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08360</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08367</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentiable Learning of Logical Rules for Knowledge Base Reasoning</dc:title>
 <dc:creator>Yang, Fan</dc:creator>
 <dc:creator>Yang, Zhilin</dc:creator>
 <dc:creator>Cohen, William W.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study the problem of learning probabilistic first-order logical rules for
knowledge base reasoning. This learning problem is difficult because it
requires learning the parameters in a continuous space as well as the structure
in a discrete space. We propose a framework, Neural Logic Programming, that
combines the parameter and structure learning of first-order logical rules in
an end-to-end differentiable model. This approach is inspired by a
recently-developed differentiable logic called TensorLog, where inference tasks
can be compiled into sequences of differentiable operations. We design a neural
controller system that learns to compose these operations. Empirically, our
method outperforms prior work on multiple knowledge base benchmark datasets,
including Freebase and WikiMovies.
</dc:description>
 <dc:description>Comment: Accepted at NIPS 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08372</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Relaxations of Chance Constrained AC Optimal Power Flow</dc:title>
 <dc:creator>Venzke, Andreas</dc:creator>
 <dc:creator>Halilbasic, Lejla</dc:creator>
 <dc:creator>Markovic, Uros</dc:creator>
 <dc:creator>Hug, Gabriela</dc:creator>
 <dc:creator>Chatzivasileiadis, Spyros</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  High penetration of renewable energy sources and the increasing share of
stochastic loads require the explicit representation of uncertainty in tools
such as the optimal power flow (OPF). Current approaches follow either a
linearized approach or an iterative approximation of non-linearities. This
paper proposes a semidefinite relaxation of a chance constrained AC-OPF which
is able to provide guarantees for global optimality. Using a piecewise affine
policy, we can ensure tractability, accurately model large power deviations,
and determine suitable corrective control policies for active power, reactive
power, and voltage. We state a tractable formulation for two types of
uncertainty sets. Using a scenario-based approach and making no prior
assumptions about the probability distribution of the forecast errors, we
obtain a robust formulation for a rectangular uncertainty set. Alternatively,
assuming a Gaussian distribution of the forecast errors, we propose an
analytical reformulation of the chance constraints suitable for semidefinite
programming. We demonstrate the performance of our approach on the IEEE 24 and
118 bus system using realistic day-ahead forecast data and obtain tight
near-global optimality guarantees.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08376</identifier>
 <datestamp>2018-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Admittance Control Parameter Adaptation for Physical Human-Robot
  Interaction</dc:title>
 <dc:creator>Landi, Chiara Talignani</dc:creator>
 <dc:creator>Ferraguti, Federica</dc:creator>
 <dc:creator>Sabattini, Lorenzo</dc:creator>
 <dc:creator>Secchi, Cristian</dc:creator>
 <dc:creator>Fantuzzi, Cesare</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In physical human-robot interaction, the coexistence of robots and humans in
the same workspace requires the guarantee of a stable interaction, trying to
minimize the effort for the operator. To this aim, the admittance control is
widely used and the appropriate selection of the its parameters is crucial,
since they affect both the stability and the ability of the robot to interact
with the user. In this paper, we present a strategy for detecting deviations
from the nominal behavior of an admittance-controlled robot and for adapting
the parameters of the controller while guaranteeing the passivity. The proposed
methodology is validated on a KUKA LWR 4+.
</dc:description>
 <dc:description>Comment: Proceedings of the IEEE International Conference on Robotics and
  Automation (ICRA), 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08376</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2017.7989338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08377</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Secure Position Sharing with Non-trusted Servers</dc:title>
 <dc:creator>Skvortsov, Pavel</dc:creator>
 <dc:creator>Schembera, Bj&#xf6;rn</dc:creator>
 <dc:creator>D&#xfc;rr, Frank</dc:creator>
 <dc:creator>Rothermel, Kurt</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68M14</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  Today, location-based applications and services such as friend finders and
geo-social networks are very popular. However, storing private position
information on third-party location servers leads to privacy problems. In our
previous work, we proposed a position sharing approach for secure management of
positions on non-trusted servers, which distributes position shares of limited
precision among servers of several providers. In this paper, we propose two
novel contributions to improve the original approach. First, we optimize the
placement of shares among servers by taking their trustworthiness into account.
Second, we optimize the location update protocols to minimize the number of
messages between mobile device and location servers.
</dc:description>
 <dc:description>Comment: 26 pages, 11 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08379</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing Hidden Potentials of the q-Space Signal in Breast Cancer</dc:title>
 <dc:creator>Jaeger, Paul</dc:creator>
 <dc:creator>Bickelhaupt, Sebastian</dc:creator>
 <dc:creator>Laun, Frederik Bernd</dc:creator>
 <dc:creator>Lederer, Wolfgang</dc:creator>
 <dc:creator>Heidi, Daniel</dc:creator>
 <dc:creator>Kuder, Tristan Anselm</dc:creator>
 <dc:creator>Paech, Daniel</dc:creator>
 <dc:creator>Bonekamp, David</dc:creator>
 <dc:creator>Radbruch, Alexander</dc:creator>
 <dc:creator>Delorme, Stefan</dc:creator>
 <dc:creator>Schlemmer, Heinz-Peter</dc:creator>
 <dc:creator>Steudle, Franziska</dc:creator>
 <dc:creator>Maier-Hein, Klaus H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Mammography screening for early detection of breast lesions currently suffers
from high amounts of false positive findings, which result in unnecessary
invasive biopsies. Diffusion-weighted MR images (DWI) can help to reduce many
of these false-positive findings prior to biopsy. Current approaches estimate
tissue properties by means of quantitative parameters taken from generative,
biophysical models fit to the q-space encoded signal under certain assumptions
regarding noise and spatial homogeneity. This process is prone to fitting
instability and partial information loss due to model simplicity. We reveal
unexplored potentials of the signal by integrating all data processing
components into a convolutional neural network (CNN) architecture that is
designed to propagate clinical target information down to the raw input images.
This approach enables simultaneous and target-specific optimization of image
normalization, signal exploitation, global representation learning and
classification. Using a multicentric data set of 222 patients, we demonstrate
that our approach significantly improves clinical decision making with respect
to the current state of the art.
</dc:description>
 <dc:description>Comment: Accepted conference paper at MICCAI 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08379</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-66182-7_76</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08380</identifier>
 <datestamp>2017-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Increasing-Chord Paths and Trees</dc:title>
 <dc:creator>Bahoo, Yeganeh</dc:creator>
 <dc:creator>Durocher, Stephane</dc:creator>
 <dc:creator>Mehrpour, Sahar</dc:creator>
 <dc:creator>Mondal, Debajyoti</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>68Q25, 65D18</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:description>  A straight-line drawing $\Gamma$ of a graph $G=(V,E)$ is a drawing of $G$ in
the Euclidean plane, where every vertex in $G$ is mapped to a distinct point,
and every edge in $G$ is mapped to a straight line segment between their
endpoints. A path $P$ in $\Gamma$ is called increasing-chord if for every four
points (not necessarily vertices) $a,b,c,d$ on $P$ in this order, the Euclidean
distance between $b,c$ is at most the Euclidean distance between $a,d$. A
spanning tree $T$ rooted at some vertex $r$ in $\Gamma$ is called
increasing-chord if $T$ contains an increasing-chord path from $r$ to every
vertex in $T$. In this paper we prove that given a vertex $r$ in a
straight-line drawing $\Gamma$, it is NP-complete to determine whether $\Gamma$
contains an increasing-chord spanning tree rooted at $r$. We conjecture that
finding an increasing-chord path between a pair of vertices in $\Gamma$, which
is an intriguing open problem posed by Alamdari et al., is also NP-complete,
and show a (non-polynomial) reduction from the 3-SAT problem.
</dc:description>
 <dc:description>Comment: A preliminary version appeared at the 29th Canadian Conference on
  Computational Geometry (CCCG 2017)</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08388</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stance Classification of Social Media Users in Independence Movements</dc:title>
 <dc:creator>Zubiaga, Arkaitz</dc:creator>
 <dc:creator>Wang, Bo</dc:creator>
 <dc:creator>Liakata, Maria</dc:creator>
 <dc:creator>Procter, Rob</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Social media and data mining are increasingly being used to analyse political
and societal issues. Here we undertake the classification of social media users
as supporting or opposing ongoing independence movements in their territories.
Independence movements occur in territories whose citizens have conflicting
national identities; users with opposing national identities will then support
or oppose the sense of being part of an independent nation that differs from
the officially recognised country. We describe a methodology that relies on
users' self-reported location to build datasets for three territories --
Catalonia, the Basque Country and Scotland -- and we test language-independent
classifiers using four types of features. We show the effectiveness of the
approach to build large annotated datasets, and the ability to achieve
accurate, language-independent classification performances ranging from 85% to
97% for the three territories under study. A data analysis shows the existence
of echo chambers that isolate opposing national identities from each other.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08389</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equivariance Through Parameter-Sharing</dc:title>
 <dc:creator>Ravanbakhsh, Siamak</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We propose to study equivariance in deep neural networks through parameter
symmetries. In particular, given a group $\mathcal{G}$ that acts discretely on
the input and output of a standard neural network layer $\phi_{W}: \Re^{M} \to
\Re^{N}$, we show that $\phi_{W}$ is equivariant with respect to
$\mathcal{G}$-action iff $\mathcal{G}$ explains the symmetries of the network
parameters $W$. Inspired by this observation, we then propose two
parameter-sharing schemes to induce the desirable symmetry on $W$. Our
procedures for tying the parameters achieve $\mathcal{G}$-equivariance and,
under some conditions on the action of $\mathcal{G}$, they guarantee
sensitivity to all other permutation groups outside $\mathcal{G}$.
</dc:description>
 <dc:description>Comment: icml'17</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08392</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining the $k$-CNF and XOR Phase-Transitions</dc:title>
 <dc:creator>Dudek, Jeffrey M.</dc:creator>
 <dc:creator>Meel, Kuldeep S.</dc:creator>
 <dc:creator>Vardi, Moshe Y.</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The runtime performance of modern SAT solvers on random $k$-CNF formulas is
deeply connected with the 'phase-transition' phenomenon seen empirically in the
satisfiability of random $k$-CNF formulas. Recent universal hashing-based
approaches to sampling and counting crucially depend on the runtime performance
of SAT solvers on formulas expressed as the conjunction of both $k$-CNF and XOR
constraints (known as $k$-CNF-XOR formulas), but the behavior of random
$k$-CNF-XOR formulas is unexplored in prior work. In this paper, we present the
first study of the satisfiability of random $k$-CNF-XOR formulas. We show
empirical evidence of a surprising phase-transition that follows a linear
trade-off between $k$-CNF and XOR constraints. Furthermore, we prove that a
phase-transition for $k$-CNF-XOR formulas exists for $k = 2$ and (when the
number of $k$-CNF constraints is small) for $k &gt; 2$.
</dc:description>
 <dc:description>Comment: Presented at The 25th International Joint Conference on Artificial
  Intelligence (IJCAI-16)</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08392</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08395</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Backhaul-aware Robust 3D Drone Placement in 5G+ Wireless Networks</dc:title>
 <dc:creator>Kalantari, Elham</dc:creator>
 <dc:creator>Shakir, Muhammad Zeeshan</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:creator>Yongacoglu, Abbas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Using drones as flying base stations is a promising approach to enhance the
network coverage and area capacity by moving supply towards demand when
required. However deployment of such base stations can face some restrictions
that need to be considered. One of the limitations in drone base stations
(drone-BSs) deployment is the availability of reliable wireless backhaul link.
This paper investigates how different types of wireless backhaul offering
various data rates would affect the number of served users. Two approaches,
namely, network-centric and user-centric, are introduced and the optimal 3D
backhaul-aware placement of a drone-BS is found for each approach. To this end,
the total number of served users and sum-rates are maximized in the
network-centric and user-centric frameworks, respectively. Moreover, as it is
preferred to decrease drone-BS movements to save more on battery and increase
flight time and to reduce the channel variations, the robustness of the network
is examined as how sensitive it is with respect to the users displacements.
</dc:description>
 <dc:description>Comment: in Proc. IEEE ICC2017 Workshops, FlexNets2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08396</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Hierarchical Features from Generative Models</dc:title>
 <dc:creator>Zhao, Shengjia</dc:creator>
 <dc:creator>Song, Jiaming</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks have been shown to be very successful at learning
feature hierarchies in supervised learning tasks. Generative models, on the
other hand, have benefited less from hierarchical models with multiple layers
of latent variables. In this paper, we prove that hierarchical latent variable
models do not take advantage of the hierarchical structure when trained with
existing variational methods, and provide some limitations on the kind of
features existing models can learn. Finally we propose an alternative
architecture that do not suffer from these limitations. Our model is able to
learn highly interpretable and disentangled hierarchical features on several
natural image datasets with no task specific regularization or prior knowledge.
</dc:description>
 <dc:description>Comment: ICML'2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08398</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>McGan: Mean and Covariance Feature Matching GAN</dc:title>
 <dc:creator>Mroueh, Youssef</dc:creator>
 <dc:creator>Sercu, Tom</dc:creator>
 <dc:creator>Goel, Vaibhava</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce new families of Integral Probability Metrics (IPM) for training
Generative Adversarial Networks (GAN). Our IPMs are based on matching
statistics of distributions embedded in a finite dimensional feature space.
Mean and covariance feature matching IPMs allow for stable training of GANs,
which we will call McGan. McGan minimizes a meaningful loss between
distributions.
</dc:description>
 <dc:description>Comment: 15 pages; published at ICML 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08400</identifier>
 <datestamp>2017-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymmetric Tri-training for Unsupervised Domain Adaptation</dc:title>
 <dc:creator>Saito, Kuniaki</dc:creator>
 <dc:creator>Ushiku, Yoshitaka</dc:creator>
 <dc:creator>Harada, Tatsuya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Deep-layered models trained on a large number of labeled samples boost the
accuracy of many tasks. It is important to apply such models to different
domains because collecting many labeled samples in various domains is
expensive. In unsupervised domain adaptation, one needs to train a classifier
that works well on a target domain when provided with labeled source samples
and unlabeled target samples. Although many methods aim to match the
distributions of source and target samples, simply matching the distribution
cannot ensure accuracy on the target domain. To learn discriminative
representations for the target domain, we assume that artificially labeling
target samples can result in a good representation. Tri-training leverages
three classifiers equally to give pseudo-labels to unlabeled samples, but the
method does not assume labeling samples generated from a different domain.In
this paper, we propose an asymmetric tri-training method for unsupervised
domain adaptation, where we assign pseudo-labels to unlabeled samples and train
neural networks as if they are true labels. In our work, we use three networks
asymmetrically. By asymmetric, we mean that two networks are used to label
unlabeled target samples and one network is trained by the samples to obtain
target-discriminative representations. We evaluate our method on digit
recognition and sentiment analysis datasets. Our proposed method achieves
state-of-the-art performance on the benchmark digit recognition datasets of
domain adaptation.
</dc:description>
 <dc:description>Comment: TBA on ICML2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08405</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game-Theoretic Semantics for ATL+ with Applications to Model Checking</dc:title>
 <dc:creator>Goranko, Valentin</dc:creator>
 <dc:creator>Kuusisto, Antti</dc:creator>
 <dc:creator>R&#xf6;nnholm, Raine</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  We develop game-theoretic semantics (GTS) for the fragment ATL+ of the full
Alternating-time Temporal Logic ATL*, essentially extending a recently
introduced GTS for ATL. We first show that the new game-theoretic semantics is
equivalent to the standard semantics of ATL+ (based on perfect recall
strategies). We then provide an analysis, based on the new semantics, of the
memory and time resources needed for model checking ATL+. Based on that, we
establish that strategies that use only a very limited amount of memory suffice
for ATL+. Furthermore, using the GTS we provide a new algorithm for model
checking of ATL+ and identify a natural hierarchy of tractable fragments of
ATL+ that extend ATL.
</dc:description>
 <dc:description>Comment: The long version of a paper in AAMAS2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08409</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Combinators</dc:title>
 <dc:creator>Evans, Clark C.</dc:creator>
 <dc:creator>Simonov, Kyrylo</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We introduce Rabbit, a combinator-based query language. Rabbit is designed to
let data analysts and other accidental programmers query complex structured
data.
  We combine the functional data model and the categorical semantics of
computations to develop denotational semantics of database queries. In Rabbit,
a query is modeled as a Kleisli arrow for a monadic container determined by the
query cardinality. In this model, monadic composition can be used to navigate
the database, while other query combinators can aggregate, filter, sort and
paginate data; construct compound data; connect self-referential data; and
reorganize data with grouping and data cube operations. A context-aware query
model, with the input context represented as a comonadic container, can express
query parameters and window functions. Rabbit semantics enables pipeline
notation, encouraging its users to construct database queries as a series of
distinct steps, each individually crafted and tested. We believe that Rabbit
can serve as a practical tool for data analytics.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08410</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Clustering in Discrete Path Planning for Approximating Minimum Length
  Paths</dc:title>
 <dc:creator>Imeson, Frank</dc:creator>
 <dc:creator>Smith, Stephen L.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper we consider discrete robot path planning problems on metric
graphs. We propose a clustering method, Gamma-Clustering for the planning graph
that significantly reduces the number of feasible solutions, yet retains a
solution within a constant factor of the optimal. By increasing the input
parameter Gamma, the constant factor can be decreased, but with less reduction
in the search space. We provide a simple polynomial- time algorithm for finding
optimal Gamma-Clusters, and show that for a given Gamma, this optimal is
unique. We demonstrate the effectiveness of the clustering method on traveling
salesman instances, showing that for many instances we obtain significant
reductions in computation time with little to no reduction in solution quality.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, 1 table, ACC 2016</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08415</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An SDP-Based Algorithm for Linear-Sized Spectral Sparsification</dc:title>
 <dc:creator>Lee, Yin Tat</dc:creator>
 <dc:creator>Sun, He</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For any undirected and weighted graph $G=(V,E,w)$ with $n$ vertices and $m$
edges, we call a sparse subgraph $H$ of $G$, with proper reweighting of the
edges, a $(1+\varepsilon)$-spectral sparsifier if \[
(1-\varepsilon)x^{\intercal}L_Gx\leq x^{\intercal} L_{H} x\leq (1+\varepsilon)
x^{\intercal} L_Gx \] holds for any $x\in\mathbb{R}^n$, where $L_G$ and $L_{H}$
are the respective Laplacian matrices of $G$ and $H$. Noticing that $\Omega(m)$
time is needed for any algorithm to construct a spectral sparsifier and a
spectral sparsifier of $G$ requires $\Omega(n)$ edges, a natural question is to
investigate, for any constant $\varepsilon$, if a $(1+\varepsilon)$-spectral
sparsifier of $G$ with $O(n)$ edges can be constructed in $\tilde{O}(m)$ time,
where the $\tilde{O}$ notation suppresses polylogarithmic factors. All previous
constructions on spectral sparsification require either super-linear number of
edges or $m^{1+\Omega(1)}$ time.
  In this work we answer this question affirmatively by presenting an algorithm
that, for any undirected graph $G$ and $\varepsilon&gt;0$, outputs a
$(1+\varepsilon)$-spectral sparsifier of $G$ with $O(n/\varepsilon^2)$ edges in
$\tilde{O}(m/\varepsilon^{O(1)})$ time. Our algorithm is based on three novel
techniques: (1) a new potential function which is much easier to compute yet
has similar guarantees as the potential functions used in previous references;
(2) an efficient reduction from a two-sided spectral sparsifier to a one-sided
spectral sparsifier; (3) constructing a one-sided spectral sparsifier by a
semi-definite program.
</dc:description>
 <dc:description>Comment: To appear at STOC'17</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08423</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Age Progression/Regression by Conditional Adversarial Autoencoder</dc:title>
 <dc:creator>Zhang, Zhifei</dc:creator>
 <dc:creator>Song, Yang</dc:creator>
 <dc:creator>Qi, Hairong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  &quot;If I provide you a face image of mine (without telling you the actual age
when I took the picture) and a large amount of face images that I crawled
(containing labeled faces of different ages but not necessarily paired), can
you show me what I would look like when I am 80 or what I was like when I was
5?&quot; The answer is probably a &quot;No.&quot; Most existing face aging works attempt to
learn the transformation between age groups and thus would require the paired
samples as well as the labeled query image. In this paper, we look at the
problem from a generative modeling perspective such that no paired samples is
required. In addition, given an unlabeled image, the generative model can
directly produce the image with desired age attribute. We propose a conditional
adversarial autoencoder (CAAE) that learns a face manifold, traversing on which
smooth age progression and regression can be realized simultaneously. In CAAE,
the face is first mapped to a latent vector through a convolutional encoder,
and then the vector is projected to the face manifold conditional on age
through a deconvolutional generator. The latent vector preserves personalized
face features (i.e., personality) and the age condition controls progression
vs. regression. Two adversarial networks are imposed on the encoder and
generator, respectively, forcing to generate more photo-realistic faces.
Experimental results demonstrate the appealing performance and flexibility of
the proposed framework by comparing with the state-of-the-art and ground truth.
</dc:description>
 <dc:description>Comment: Accepted by The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2017)</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08423</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08425</identifier>
 <datestamp>2017-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>xSDK Foundations: Toward an Extreme-scale Scientific Software
  Development Kit</dc:title>
 <dc:creator>Bartlett, Roscoe</dc:creator>
 <dc:creator>Demeshko, Irina</dc:creator>
 <dc:creator>Gamblin, Todd</dc:creator>
 <dc:creator>Hammond, Glenn</dc:creator>
 <dc:creator>Heroux, Michael</dc:creator>
 <dc:creator>Johnson, Jeffrey</dc:creator>
 <dc:creator>Klinvex, Alicia</dc:creator>
 <dc:creator>Li, Xiaoye</dc:creator>
 <dc:creator>McInnes, Lois Curfman</dc:creator>
 <dc:creator>Moulton, J. David</dc:creator>
 <dc:creator>Osei-Kuffuor, Daniel</dc:creator>
 <dc:creator>Sarich, Jason</dc:creator>
 <dc:creator>Smith, Barry</dc:creator>
 <dc:creator>Willenbring, Jim</dc:creator>
 <dc:creator>Yang, Ulrike Meier</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>D.2.0</dc:subject>
 <dc:subject>D.2.2</dc:subject>
 <dc:subject>D.2.11</dc:subject>
 <dc:description>  Extreme-scale computational science increasingly demands multiscale and
multiphysics formulations. Combining software developed by independent groups
is imperative: no single team has resources for all predictive science and
decision support capabilities. Scientific libraries provide high-quality,
reusable software components for constructing applications with improved
robustness and portability. However, without coordination, many libraries
cannot be easily composed. Namespace collisions, inconsistent arguments, lack
of third-party software versioning, and additional difficulties make
composition costly.
  The Extreme-scale Scientific Software Development Kit (xSDK) defines
community policies to improve code quality and compatibility across
independently developed packages (hypre, PETSc, SuperLU, Trilinos, and
Alquimia) and provides a foundation for addressing broader issues in software
interoperability, performance portability, and sustainability. The xSDK
provides turnkey installation of member software and seamless combination of
aggregate capabilities, and it marks first steps toward extreme-scale
scientific software ecosystems from which future applications can be composed
rapidly with assured quality and scalability.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08425</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08431</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary-Seeking Generative Adversarial Networks</dc:title>
 <dc:creator>Hjelm, R Devon</dc:creator>
 <dc:creator>Jacob, Athul Paul</dc:creator>
 <dc:creator>Che, Tong</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a novel approach to training generative adversarial networks,
where we train a generator to match a target distribution that converges to the
data distribution at the limit of a perfect discriminator. This objective can
be interpreted as training a generator to produce samples that lie on the
decision boundary of the current discriminator in training at each update, and
we call a GAN trained using this algorithm a boundary-seeking GAN (BGAN). This
approach can be used to train a generator with discrete output when the
generator outputs a parametric conditional distribution. We demonstrate the
effectiveness of the proposed algorithm with discrete image and character-based
natural language generation. Finally, we notice that the proposed
boundary-seeking algorithm works even with continuous variables, and
demonstrate its effectiveness with various natural image benchmarks.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08434</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skin Lesion Classification Using Hybrid Deep Neural Networks</dc:title>
 <dc:creator>Mahbod, Amirreza</dc:creator>
 <dc:creator>Ecker, Rupert</dc:creator>
 <dc:creator>Ellinger, Isabella</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Skin cancer is one of the major types of cancers and its incidence has been
increasing over the past decades. Skin lesions can arise from various
dermatologic disorders and can be classified to various types according to
their texture, structure, color and other morphological features. The accuracy
of diagnosis of skin lesions, specifically the discrimination of benign and
malignant lesions, is paramount to ensure appropriate patient treatment.
Machine learning-based classification approaches are among popular automatic
methods for skin lesion classification. While there are many existing methods,
convolutional neural networks (CNN) have shown to be superior over other
classical machine learning methods for object detection and classification
tasks. In this work, a fully automatic computerized method is proposed, which
employs well established pre-trained convolutional neural networks and
ensembles learning to classify skin lesions. We trained the networks using 2000
skin lesion images available from the ISIC 2017 challenge, which has three main
categories and includes 374 melanoma, 254 seborrheic keratosis and 1372 benign
nevi images. The trained classifier was then tested on 150 unlabeled images.
The results, evaluated by the challenge organizer and based on the area under
the receiver operating characteristic curve (AUC), were 84.8% and 93.6% for
Melanoma and seborrheic keratosis binary classification problem, respectively.
  The proposed method achieved competitive results to experienced
dermatologist. Further improvement and optimization of the proposed method with
a larger training dataset could lead to a more precise, reliable and robust
method for skin lesion classification.
</dc:description>
 <dc:description>Comment: 5 pages, ISIC2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08435</identifier>
 <datestamp>2017-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Anomaly Detection via Composite Hypothesis Testing for
  Markov Models</dc:title>
 <dc:creator>Zhang, Jing</dc:creator>
 <dc:creator>Paschalidis, Ioannis Ch.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Under Markovian assumptions, we leverage a Central Limit Theorem (CLT) for
the empirical measure in the test statistic of the composite hypothesis
Hoeffding test so as to establish weak convergence results for the test
statistic, and, thereby, derive a new estimator for the threshold needed by the
test. We first show the advantages of our estimator over an existing estimator
by conducting extensive numerical experiments. We find that our estimator
controls better for false alarms while maintaining satisfactory detection
probabilities. We then apply the Hoeffding test with our threshold estimator to
detecting anomalies in two distinct applications domains: one in communication
networks and the other in transportation networks. The former application seeks
to enhance cyber security and the latter aims at building smarter
transportation systems in cities.
</dc:description>
 <dc:description>Comment: Preprint submitted to the IEEE Transactions on Signal Processing</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08441</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monte Carlo Action Programming</dc:title>
 <dc:creator>Belzner, Lenz</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This paper proposes Monte Carlo Action Programming, a programming language
framework for autonomous systems that act in large probabilistic state spaces
with high branching factors. It comprises formal syntax and semantics of a
nondeterministic action programming language. The language is interpreted
stochastically via Monte Carlo Tree Search. Effectiveness of the approach is
shown empirically.
</dc:description>
 <dc:date>2017-02-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08443</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Elementary Yet Precise Worst-case Analysis of MergeSort, A short version
  (SV)</dc:title>
 <dc:creator>Suchenek, Marek A.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>68W40 Analysis of algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.0</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  This paper offers two elementary yet precise derivations of an exact formula
  \[ W(n) = \sum_{i=1} ^{n} \lceil \lg i \rceil = n \lceil \lg n \rceil -
2^{\lceil \lg n \rceil} + 1 \] for the maximum number $ W(n) $ of comparisons
of keys performed by $ {\tt MergeSort} $ on an $ n $-element array. The first
of the two, due to its structural regularity, is well worth carefully studying
in its own right.
  Close smooth bounds on $ W(n) $ are derived. It seems interesting that $ W(n)
$ is linear between the points $ n = 2^{\lfloor \lg n \rfloor} $ and it
linearly interpolates its own lower bound $ n \lg n - n + 1 $ between these
points.
</dc:description>
 <dc:description>Comment: 25 pages, 12 figures, three of which contain working Java methods</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08450</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Knowledge-Based Approach to Word Sense Disambiguation by
  distributional selection and semantic features</dc:title>
 <dc:creator>Billami, Mokhtar</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word sense disambiguation improves many Natural Language Processing (NLP)
applications such as Information Retrieval, Information Extraction, Machine
Translation, or Lexical Simplification. Roughly speaking, the aim is to choose
for each word in a text its best sense. One of the most popular method
estimates local semantic similarity relatedness between two word senses and
then extends it to all words from text. The most direct method computes a rough
score for every pair of word senses and chooses the lexical chain that has the
best score (we can imagine the exponential complexity that returns this
comprehensive approach). In this paper, we propose to use a combinatorial
optimization metaheuristic for choosing the nearest neighbors obtained by
distributional selection around the word to disambiguate. The test and the
evaluation of our method concern a corpus written in French by means of the
semantic network BabelNet. The obtained accuracy rate is 78 % on all names and
verbs chosen for the evaluation.
</dc:description>
 <dc:description>Comment: in French</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08450</dc:identifier>
 <dc:identifier>22\`eme Conf\'erence sur le Traitement Automatique des Langues
  Naturelles et 17\`eme Rencontre des \'Etudiants Chercheurs en Informatique
  pour le Traitement Automatique des Langues, Jun 2015, CAEN, France. 22\`eme
  Conf\'erence sur le Traitement Automatique des Langues Naturelles et 17\`eme
  Rencontre des \'Etudiants Chercheurs en Informatique pour le Traitement
  Automatique des Langues, pp.13--24, 2015</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08451</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approches d'analyse distributionnelle pour am\'eliorer la
  d\'esambigu\&quot;isation s\'emantique</dc:title>
 <dc:creator>Billami, Mokhtar</dc:creator>
 <dc:creator>Gala, N&#xfa;ria</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Word sense disambiguation (WSD) improves many Natural Language Processing
(NLP) applications such as Information Retrieval, Machine Translation or
Lexical Simplification. WSD is the ability of determining a word sense among
different ones within a polysemic lexical unit taking into account the context.
The most straightforward approach uses a semantic proximity measure between the
word sense candidates of the target word and those of its context. Such a
method very easily entails a combinatorial explosion. In this paper, we propose
two methods based on distributional analysis which enable to reduce the
exponential complexity without losing the coherence. We present a comparison
between the selection of distributional neighbors and the linearly nearest
neighbors. The figures obtained show that selecting distributional neighbors
leads to better results.
</dc:description>
 <dc:description>Comment: in French, Journ\'ees internationales d'Analyse statistique des
  Donn\'ees Textuelles (JADT), Jun 2016, Nice, France</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08451</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08459</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Networks: from Classical to Quantum</dc:title>
 <dc:creator>Biamonte, Jacob</dc:creator>
 <dc:creator>Faccin, Mauro</dc:creator>
 <dc:creator>De Domenico, Manlio</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Recent progress in applying complex network theory to problems faced in
quantum information and computation has resulted in a beneficial crossover
between two fields. Complex network methods have successfully been used to
characterize quantum walk and transport models, entangled communication
networks, graph theoretic models of emergent space-time and in detecting
community structure in quantum systems. Information physics is setting the
stage for a theory of complex and networked systems with quantum
information-inspired methods appearing in complex network science, including
information-theoretic distance and correlation measures for network
characterization. Novel quantum induced effects have been predicted in random
graphs---where edges represent entangled links---and quantum computer
algorithms have recently been proposed to offer super-polynomial enhancement
for several network and graph theoretic problems. Here we review the results at
the cutting edge, pinpointing the similarities and reconciling the differences
found in the series of results at the intersection of these two fields.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures, REVTeX 4-1</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08459</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08474</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Infinite Server Problem</dc:title>
 <dc:creator>Coester, Christian</dc:creator>
 <dc:creator>Koutsoupias, Elias</dc:creator>
 <dc:creator>Lazos, Philip</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:description>  We study a variant of the $k$-server problem, the infinite server problem, in
which infinitely many servers reside initially at a particular point of the
metric space and serve a sequence of requests. In the framework of competitive
analysis, we show a surprisingly tight connection between this problem and the
$(h,k)$-server problem, in which an online algorithm with $k$ servers competes
against an offline algorithm with $h$ servers. Specifically, we show that the
infinite server problem has bounded competitive ratio if and only if the
$(h,k)$-server problem has bounded competitive ratio for some $k=O(h)$. We give
a lower bound of $3.146$ for the competitive ratio of the infinite server
problem, which implies the same lower bound for the $(h,k)$-server problem even
when $k/h \to \infty$ and holds also for the line metric; the previous known
bounds were 2.4 for general metric spaces and 2 for the line. For weighted
trees and layered graphs we obtain upper bounds, although they depend on the
depth. Of particular interest is the infinite server problem on the line, which
we show to be equivalent to the seemingly easier case in which all requests are
in a fixed bounded interval away from the original position of the servers.
This is a special case of a more general reduction from arbitrary metric spaces
to bounded subspaces. Unfortunately, classical approaches (double coverage and
generalizations, work function algorithm, balancing algorithms) fail even for
this special case.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08474</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08476</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strong Chain Rules for Min-Entropy under Few Bits Spoiled</dc:title>
 <dc:creator>Skorski, Maciej</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  It is well established that the notion of min-entropy fails to satisfy the
\emph{chain rule} of the form $H(X,Y) = H(X|Y)+H(Y)$, known for Shannon
Entropy. Such a property would help to analyze how min-entropy is split among
smaller blocks. Problems of this kind arise for example when constructing
extractors and dispersers.
  We show that any sequence of variables exhibits a very strong strong
block-source structure (conditional distributions of blocks are nearly flat)
when we \emph{spoil few correlated bits}. This implies, conditioned on the
spoiled bits, that \emph{splitting-recombination properties} hold. In
particular, we have many nice properties that min-entropy doesn't obey in
general, for example strong chain rules, &quot;information can't hurt&quot; inequalities,
equivalences of average and worst-case conditional entropy definitions and
others. Quantitatively, for any sequence $X_1,\ldots,X_t$ of random variables
over an alphabet $\mathcal{X}$ we prove that, when conditioned on $m = t\cdot
O( \log\log|\mathcal{X}| + \log\log(1/\epsilon) + \log t)$ bits of auxiliary
information, all conditional distributions of the form $X_i|X_{&lt;i}$ are
$\epsilon$-close to be nearly flat (only a constant factor away). The argument
is combinatorial (based on simplex coverings).
  This result may be used as a generic tool for \emph{exhibiting block-source
structures}. We demonstrate this by reproving the fundamental converter due to
Nisan and Zuckermann (\emph{J. Computer and System Sciences, 1996}), which
shows that sampling blocks from a min-entropy source roughly preserves the
entropy rate. Our bound implies, only by straightforward chain rules, an
additive loss of $o(1)$ (for sufficiently many samples), which qualitatively
meets the first tighter analysis of this problem due to Vadhan
(\emph{CRYPTO'03}), obtained by large deviation techniques.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08478</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Risks and Transaction Costs of Distributed-Ledger Fintech: Boundary
  Effects and Consequences</dc:title>
 <dc:creator>Kaivanto, Kim</dc:creator>
 <dc:creator>Prince, Daniel</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Fintech business models based on distributed ledgers -- and their
smart-contract variants in particular -- offer the prospect of democratizing
access to faster, anywhere-accessible, lower cost, reliable-and-secure
high-quality financial services. In addition to holding great, economically
transformative promise, these business models pose new, little-studied risks
and transaction costs. However, these risks and transaction costs are not
evident during the demonstration and testing phases of development, when
adopters and users are drawn from the community of developers themselves, as
well as from among non-programmer fintech evangelists. Hence, when the new
risks and transaction costs become manifest -- as the fintech business models
are rolled out across the wider economy -- the consequences may also appear to
be new and surprising. The present study represents an effort to get ahead of
these developments by delineating risks and transaction costs inherent in
distributed-ledger- and smart-contracts-based fintech business models. The
analysis focuses on code risk and moral-hazard risk, as well as on
mixed-economy risks and the unintended consequences of replicating
bricks-and-mortar-generation contract forms within the ultra-low
transaction-cost environment of fintech.
</dc:description>
 <dc:description>Comment: 12 pages, 1 figure</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08478</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08481</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-Efficient Global Refinement of Decision-Tree Ensembles and its
  Application to Face Alignment</dc:title>
 <dc:creator>Marku&#x161;, Nenad</dc:creator>
 <dc:creator>Gogi&#x107;, Ivan</dc:creator>
 <dc:creator>Pand&#x17e;i&#x107;, Igor S.</dc:creator>
 <dc:creator>Ahlberg, J&#xf6;rgen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Ren et al. recently introduced a method for aggregating multiple decision
trees into a strong predictor by interpreting a path taken by a sample down
each tree as a binary vector and performing linear regression on top of these
vectors stacked together. They provided experimental evidence that the method
offers advantages over the usual approaches for combining decision trees
(random forests and boosting). The method truly shines when the regression
target is a large vector with correlated dimensions, such as a 2D face shape
represented with the positions of several facial landmarks. However, we argue
that their basic method is not applicable in many practical scenarios due to
large memory requirements. This paper shows how this issue can be solved
through the use of quantization and architectural changes of the predictor that
maps decision tree-derived encodings to the desired output.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08483</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The computational landscape of general physical theories</dc:title>
 <dc:creator>Barrett, Jonathan</dc:creator>
 <dc:creator>de Beaudrap, Niel</dc:creator>
 <dc:creator>Hoban, Matty J.</dc:creator>
 <dc:creator>Lee, Ciar&#xe1;n M.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The emergence of quantum computers has challenged long-held beliefs about
what is efficiently computable given our current physical theories. However,
going back to the work of Abrams and Lloyd, changing one aspect of quantum
theory can result in yet more dramatic increases in computational power, as
well as violations of fundamental physical principles. Here we focus on
efficient computation within a framework of general physical theories that make
good operational sense. In prior work, Lee and Barrett showed that in any
theory satisfying the principle of tomographic locality (roughly, local
measurements suffice for tomography of multipartite states) the complexity
bound on efficient computation is AWPP. This bound holds independently of
whether the principle of causality (roughly, no signalling from the future) is
satisfied. In this work we show that this bound is tight: there exists a theory
satisfying both the principles of tomographic locality and causality which can
efficiently decide everything in AWPP, and in particular can simulate any
efficient quantum computation. Thus the class AWPP has a natural physical
interpretation: it is precisely the class of problems that can be solved
efficiently in tomographically-local theories. This theory is built upon a
model of computing involving Turing machines with quasi-probabilities, to wit,
machines with transition weights that can be negative but sum to unity over all
branches. In analogy with the study of non-local quantum correlations, this
leads us to question what physical principles recover the power of quantum
computing. Along this line, we give some computational complexity evidence that
quantum computation does not achieve the bound of AWPP.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures. Comments welcome</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08484</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosted Generative Models</dc:title>
 <dc:creator>Grover, Aditya</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel approach for using unsupervised boosting to create an
ensemble of generative models, where models are trained in sequence to correct
earlier mistakes. Our meta-algorithmic framework can leverage any existing base
learner that permits likelihood evaluation, including recent deep expressive
models. Further, our approach allows the ensemble to include discriminative
models trained to distinguish real data from model-generated data. We show
theoretical conditions under which incorporating a new model in the ensemble
will improve the fit and empirically demonstrate the effectiveness of our
black-box boosting algorithms on density estimation, classification, and sample
generation on benchmark datasets for a wide range of generative models.
</dc:description>
 <dc:description>Comment: AAAI 2018</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-12-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08489</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth Separation for Neural Networks</dc:title>
 <dc:creator>Daniely, Amit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Let $f:\mathbb{S}^{d-1}\times \mathbb{S}^{d-1}\to\mathbb{S}$ be a function of
the form $f(\mathbf{x},\mathbf{x}') = g(\langle\mathbf{x},\mathbf{x}'\rangle)$
for $g:[-1,1]\to \mathbb{R}$. We give a simple proof that shows that poly-size
depth two neural networks with (exponentially) bounded weights cannot
approximate $f$ whenever $g$ cannot be approximated by a low degree polynomial.
Moreover, for many $g$'s, such as $g(x)=\sin(\pi d^3x)$, the number of neurons
must be $2^{\Omega\left(d\log(d)\right)}$. Furthermore, the result holds
w.r.t.\ the uniform distribution on $\mathbb{S}^{d-1}\times \mathbb{S}^{d-1}$.
As many functions of the above form can be well approximated by poly-size depth
three networks with poly-bounded weights, this establishes a separation between
depth two and depth three networks w.r.t.\ the uniform distribution on
$\mathbb{S}^{d-1}\times \mathbb{S}^{d-1}$.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08495</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument</dc:title>
 <dc:creator>Benthall, Sebastian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent years prominent intellectuals have raised ethical concerns about
the consequences of artificial intelligence. One concern is that an autonomous
agent might modify itself to become &quot;superintelligent&quot; and, in supremely
effective pursuit of poorly specified goals, destroy all of humanity. This
paper considers and rejects the possibility of this outcome. We argue that this
scenario depends on an agent's ability to rapidly improve its ability to
predict its environment through self-modification. Using a Bayesian model of a
reasoning agent, we show that there are important limitations to how an agent
may improve its predictive ability through self-modification alone. We conclude
that concern about this artificial intelligence outcome is misplaced and better
directed at policy questions around data access and storage.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08501</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Synthesis of Control Strategies for Positive Monotone Systems</dc:title>
 <dc:creator>Sadraddini, Sadra</dc:creator>
 <dc:creator>Belta, Calin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We design controllers from formal specifications for positive discrete-time
monotone systems that are subject to bounded disturbances. Such systems are
widely used to model the dynamics of transportation and biological networks.
The specifications are described using signal temporal logic (STL), which can
express a broad range of temporal properties. We formulate the problem as a
mixed-integer linear program (MILP) and show that under the assumptions made in
this paper, which are not restrictive for traffic applications, the existence
of open-loop control policies is sufficient and almost necessary to ensure the
satisfaction of STL formulas. We establish a relation between satisfaction of
STL formulas in infinite time and set-invariance theories and provide an
efficient method to compute robust control invariant sets in high dimensions.
We also develop a robust model predictive framework to plan controls optimally
while guaranteeing the satisfaction of the specification. Illustrative examples
and a traffic management case study are included.
</dc:description>
 <dc:description>Comment: 39 Pages, Single Column, submitted to IEEE Transactions on Automatic
  Control</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08502</identifier>
 <datestamp>2017-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Convolution for Semantic Segmentation</dc:title>
 <dc:creator>Wang, Panqu</dc:creator>
 <dc:creator>Chen, Pengfei</dc:creator>
 <dc:creator>Yuan, Ye</dc:creator>
 <dc:creator>Liu, Ding</dc:creator>
 <dc:creator>Huang, Zehua</dc:creator>
 <dc:creator>Hou, Xiaodi</dc:creator>
 <dc:creator>Cottrell, Garrison</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances in deep learning, especially deep convolutional neural
networks (CNNs), have led to significant improvement over previous semantic
segmentation systems. Here we show how to improve pixel-wise semantic
segmentation by manipulating convolution-related operations that are of both
theoretical and practical value. First, we design dense upsampling convolution
(DUC) to generate pixel-level prediction, which is able to capture and decode
more detailed information that is generally missing in bilinear upsampling.
Second, we propose a hybrid dilated convolution (HDC) framework in the encoding
phase. This framework 1) effectively enlarges the receptive fields (RF) of the
network to aggregate global information; 2) alleviates what we call the
&quot;gridding issue&quot; caused by the standard dilated convolution operation. We
evaluate our approaches thoroughly on the Cityscapes dataset, and achieve a
state-of-art result of 80.1% mIOU in the test set at the time of submission. We
also have achieved state-of-the-art overall on the KITTI road estimation
benchmark and the PASCAL VOC2012 segmentation task. Our source code can be
found at https://github.com/TuSimple/TuSimple-DUC.
</dc:description>
 <dc:description>Comment: Source code: https://github.com/TuSimple/TuSimple-DUC</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08502</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08503</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SGD Learns the Conjugate Kernel Class of the Network</dc:title>
 <dc:creator>Daniely, Amit</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We show that the standard stochastic gradient decent (SGD) algorithm is
guaranteed to learn, in polynomial time, a function that is competitive with
the best function in the conjugate kernel space of the network, as defined in
Daniely, Frostig and Singer. The result holds for log-depth networks from a
rich family of architectures. To the best of our knowledge, it is the first
polynomial-time guarantee for the standard neural network learning algorithm
for networks of depth more that two.
  As corollaries, it follows that for neural networks of any depth between $2$
and $\log(n)$, SGD is guaranteed to learn, in polynomial time, constant degree
polynomials with polynomially bounded coefficients. Likewise, it follows that
SGD on large enough networks can learn any continuous function (not in
polynomial time), complementing classical expressivity results.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08513</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Visual Object Models From Noisy Web Data: How to Make it
  Work</dc:title>
 <dc:creator>Massouh, Nizar</dc:creator>
 <dc:creator>Babiloni, Francesca</dc:creator>
 <dc:creator>Tommasi, Tatiana</dc:creator>
 <dc:creator>Young, Jay</dc:creator>
 <dc:creator>Hawes, Nick</dc:creator>
 <dc:creator>Caputo, Barbara</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Deep networks thrive when trained on large scale data collections. This has
given ImageNet a central role in the development of deep architectures for
visual object classification. However, ImageNet was created during a specific
period in time, and as such it is prone to aging, as well as dataset bias
issues. Moving beyond fixed training datasets will lead to more robust visual
systems, especially when deployed on robots in new environments which must
train on the objects they encounter there. To make this possible, it is
important to break free from the need for manual annotators. Recent work has
begun to investigate how to use the massive amount of images available on the
Web in place of manual image annotations. We contribute to this research thread
with two findings: (1) a study correlating a given level of noisily labels to
the expected drop in accuracy, for two deep architectures, on two different
types of noise, that clearly identifies GoogLeNet as a suitable architecture
for learning from Web data; (2) a recipe for the creation of Web datasets with
minimal noise and maximum visual variability, based on a visual and natural
language processing concept expansion strategy. By combining these two results,
we obtain a method for learning powerful deep object models automatically from
the Web. We confirm the effectiveness of our approach through object
categorization experiments using our Web-derived version of ImageNet on a
popular robot vision benchmark database, and on a lifelong object discovery
task on a mobile robot.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures, 3 tables</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08516</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lensless computational imaging through deep learning</dc:title>
 <dc:creator>Sinha, Ayan</dc:creator>
 <dc:creator>Lee, Justin</dc:creator>
 <dc:creator>Li, Shuai</dc:creator>
 <dc:creator>Barbastathis, George</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Optics</dc:subject>
 <dc:description>  Deep learning has been proven to yield reliably generalizable answers to
numerous classification and decision tasks. Here, we demonstrate for the first
time, to our knowledge, that deep neural networks (DNNs) can be trained to
solve inverse problems in computational imaging. We experimentally demonstrate
a lens-less imaging system where a DNN was trained to recover a phase object
given a raw intensity image recorded some distance away.
</dc:description>
 <dc:description>Comment: 8 pages, 13 figures</dc:description>
 <dc:date>2017-02-22</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08523</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study on modeling 40t ultra high power (UHP) electric furnace</dc:title>
 <dc:creator>Guk, Yun Chol</dc:creator>
 <dc:creator>Il, Ryang Gyong</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we proposed a modeling method of the electrode lift controlling
plant of an ultra high power electric furnace and verified the accuracy of the
proposed model by simulation and field test.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08524</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Synchronization of Sampled-Data Systems on Lie Groups</dc:title>
 <dc:creator>McCarthy, Philip James</dc:creator>
 <dc:creator>Nielsen, Christopher</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a smooth distributed nonlinear control law for local
synchronization of identical driftless kinematic agents on a Cartesian product
of matrix Lie groups with a connected communication graph. If the agents are
initialized sufficiently close to one another, then synchronization is achieved
exponentially fast. We first analyze the special case of commutative Lie groups
and show that in exponential coordinates, the closed-loop dynamics are linear.
We characterize all equilibria of the network and, in the case of an
unweighted, complete graph, characterize the settling time and conditions for
deadbeat performance. Using the Baker-Campbell-Hausdorff theorem, we show that,
in a neighbourhood of the identity element, all results generalize to arbitrary
matrix Lie groups.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08524</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08529</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-agent systems and decentralized artificial superintelligence</dc:title>
 <dc:creator>Ponomarev, S.</dc:creator>
 <dc:creator>Voronkov, A. E.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Multi-agents systems communication is a technology, which provides a way for
multiple interacting intelligent agents to communicate with each other and with
environment. Multiple-agent systems are used to solve problems that are
difficult for solving by individual agent. Multiple-agent communication
technologies can be used for management and organization of computing fog and
act as a global, distributed operating system. In present publication we
suggest technology, which combines decentralized P2P BOINC general-purpose
computing tasks distribution, multiple-agents communication protocol and
smart-contract based rewards, powered by Ethereum blockchain. Such system can
be used as distributed P2P computing power market, protected from any central
authority. Such decentralized market can further be updated to system, which
learns the most efficient way for software-hardware combinations usage and
optimization. Once system learns to optimize software-hardware efficiency it
can be updated to general-purpose distributed intelligence, which acts as
combination of single-purpose AI.
</dc:description>
 <dc:description>Comment: 18 pages, 8 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08529</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08530</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-parametric Network Structure Discovery Models</dc:title>
 <dc:creator>Dezfouli, Amir</dc:creator>
 <dc:creator>Bonilla, Edwin V.</dc:creator>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:description>  We propose a network structure discovery model for continuous observations
that generalizes linear causal models by incorporating a Gaussian process (GP)
prior on a network-independent component, and random sparsity and weight
matrices as the network-dependent parameters. This approach provides flexible
modeling of network-independent trends in the observations as well as
uncertainty quantification around the discovered network structure. We
establish a connection between our model and multi-task GPs and develop an
efficient stochastic variational inference algorithm for it. Furthermore, we
formally show that our approach is numerically stable and in fact numerically
easy to carry out almost everywhere on the support of the random variables
involved. Finally, we evaluate our model on three applications, showing that it
outperforms previous approaches. We provide a qualitative and quantitative
analysis of the structures discovered for domains such as the study of the full
genome regulation of the yeast Saccharomyces cerevisiae.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08531</identifier>
 <datestamp>2017-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical issues in decoy-state quantum key distribution based on the
  central limit theorem</dc:title>
 <dc:creator>Trushechkin, A. S.</dc:creator>
 <dc:creator>Kiktenko, E. O.</dc:creator>
 <dc:creator>Fedorov, A. K.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Decoy-state quantum key distribution is a standard tool for long-distance
quantum communications. An important issue in this field is processing the
decoy-state statistics taking into account statistical fluctuations (or
&quot;finite-key effects&quot;). In this work, we propose and analyze an option for decoy
statistics processing, which is based on the central limit theorem. We discuss
such practical issues as an inclusion of the failure probability of the
decoy-states statistical estimates in the total failure probability of a QKD
protocol and also taking into account the deviations of the binomially
distributed random variables used in the estimations from the Gaussian
distribution. The results of numerical simulations show that the obtained
estimations are quite tight. The proposed technique can be used as a part of
post-processing procedures for industrial quantum key distribution systems.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures; published version</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08531</dc:identifier>
 <dc:identifier>Phys. Rev. A 96, 022316 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.022316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08533</identifier>
 <datestamp>2017-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Competing Bandits: Learning under Competition</dc:title>
 <dc:creator>Mansour, Yishay</dc:creator>
 <dc:creator>Slivkins, Aleksandrs</dc:creator>
 <dc:creator>Wu, Zhiwei Steven</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Most modern systems strive to learn from interactions with users, and many
engage in exploration: making potentially suboptimal choices for the sake of
acquiring new information. We initiate a study of the interplay between
exploration and competition--how such systems balance the exploration for
learning and the competition for users. Here the users play three distinct
roles: they are customers that generate revenue, they are sources of data for
learning, and they are self-interested agents which choose among the competing
systems. In our model, we consider competition between two multi-armed bandit
algorithms faced with the same bandit instance. Users arrive one by one and
choose among the two algorithms, so that each algorithm makes progress if and
only if it is chosen. We ask whether and to what extent competition
incentivizes the adoption of better bandit algorithms. We investigate this
issue for several models of user response, as we vary the degree of rationality
and competitiveness in the model. Our findings are closely related to the
&quot;competition vs. innovation&quot; relationship, a well-studied theme in economics.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08533</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08534</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Analysis Using a Dual-Tree $M$-Band Wavelet Transform</dc:title>
 <dc:creator>Chaux, Caroline</dc:creator>
 <dc:creator>Duval, Laurent</dc:creator>
 <dc:creator>Pesquet, Jean-Christophe</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:description>  We propose a 2D generalization to the $M$-band case of the dual-tree
decomposition structure (initially proposed by N. Kingsbury and further
investigated by I. Selesnick) based on a Hilbert pair of wavelets. We
particularly address (\textit{i}) the construction of the dual basis and
(\textit{ii}) the resulting directional analysis. We also revisit the necessary
pre-processing stage in the $M$-band case. While several reconstructions are
possible because of the redundancy of the representation, we propose a new
optimal signal reconstruction technique, which minimizes potential estimation
errors. The effectiveness of the proposed $M$-band decomposition is
demonstrated via denoising comparisons on several image types (natural,
texture, seismics), with various $M$-band wavelets and thresholding strategies.
Significant improvements in terms of both overall noise reduction and direction
preservation are observed.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08534</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, August 2006, Volume 15,
  Issue 8, p. 2397-2412</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2006.875178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08536</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Threshold Tests for Detecting Discrimination</dc:title>
 <dc:creator>Pierson, Emma</dc:creator>
 <dc:creator>Corbett-Davies, Sam</dc:creator>
 <dc:creator>Goel, Sharad</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Threshold tests have recently been proposed as a robust method for detecting
bias in lending, hiring, and policing decisions. For example, in the case of
credit extensions, these tests aim to estimate the bar for granting loans to
white and minority applicants, with a higher inferred threshold for minorities
indicative of discrimination. This technique, however, requires fitting a
Bayesian latent variable model for which inference is often computationally
challenging. Here we develop a method for fitting threshold tests that is more
than 75 times faster than the existing approach, reducing computation from
hours to minutes. We demonstrate this technique by analyzing 2.7 million police
stops of pedestrians in New York City between 2008 and 2012. To achieve these
performance gains, we introduce and analyze a flexible family of probability
distributions on the interval [0, 1] -- which we call discriminant
distributions -- that is computationally efficient to work with. These
discriminant distributions may aid inference in a variety of applications
beyond threshold tests.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08540</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning Using Uncertainty Information</dc:title>
 <dc:creator>Yang, Yazhou</dc:creator>
 <dc:creator>Loog, Marco</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many active learning methods belong to the retraining-based approaches, which
select one unlabeled instance, add it to the training set with its possible
labels, retrain the classification model, and evaluate the criteria that we
base our selection on. However, since the true label of the selected instance
is unknown, these methods resort to calculating the average-case or worse-case
performance with respect to the unknown label. In this paper, we propose a
different method to solve this problem. In particular, our method aims to make
use of the uncertainty information to enhance the performance of
retraining-based models. We apply our method to two state-of-the-art algorithms
and carry out extensive experiments on a wide variety of real-world datasets.
The results clearly demonstrate the effectiveness of the proposed method and
indicate it can reduce human labeling efforts in many real-life applications.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure, International Conference on Pattern Recognition
  (ICPR) 2016, Cancun, Mexico</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08545</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synergistic Computation of Planar Maxima and Convex Hull</dc:title>
 <dc:creator>Barbay, J&#xe9;r&#xe9;my</dc:creator>
 <dc:creator>Ochoa, Carlos</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Refinements of the worst case complexity over instances of fixed input size
consider the input order or the input structure, but rarely both at the same
time. Barbay et al. [2016] described ``synergistic'' solutions on multisets,
which take advantage of the input order and the input structure, such as to
asymptotically outperform any comparable solution which takes advantage only of
one of those features. We consider the extension of their results to the
computation of the \textsc{Maxima Set} and the \textsc{Convex Hull} of a set of
planar points. After revisiting and improving previous approaches taking
advantage only of the input order or of the input structure, we describe
synergistic solutions taking optimally advantage of various notions of the
input order and input structure in the plane. As intermediate results, we
describe and analyze the first adaptive algorithms for \textsc{Merging Maxima}
and \textsc{Merging Convex Hulls}.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08553</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diameter-Based Active Learning</dc:title>
 <dc:creator>Tosh, Christopher</dc:creator>
 <dc:creator>Dasgupta, Sanjoy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  To date, the tightest upper and lower-bounds for the active learning of
general concept classes have been in terms of a parameter of the learning
problem called the splitting index. We provide, for the first time, an
efficient algorithm that is able to realize this upper bound, and we
empirically demonstrate its good performance.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08553</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08557</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Clustering for Community Detection</dc:title>
 <dc:creator>Ignatov, Dmitry I.</dc:creator>
 <dc:creator>Semenov, Alexander</dc:creator>
 <dc:creator>Komissarova, Daria</dc:creator>
 <dc:creator>Gnatyshak, Dmitry V.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H30, 91C20, 62H30</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Multimodal clustering is an unsupervised technique for mining interesting
patterns in $n$-adic binary relations or $n$-mode networks. Among different
types of such generalized patterns one can find biclusters and formal concepts
(maximal bicliques) for 2-mode case, triclusters and triconcepts for 3-mode
case, closed $n$-sets for $n$-mode case, etc. Object-attribute biclustering
(OA-biclustering) for mining large binary datatables (formal contexts or 2-mode
networks) arose by the end of the last decade due to intractability of
computation problems related to formal concepts; this type of patterns was
proposed as a meaningful and scalable approximation of formal concepts. In this
paper, our aim is to present recent advance in OA-biclustering and its
extensions to mining multi-mode communities in SNA setting. We also discuss
connection between clustering coefficients known in SNA community for 1-mode
and 2-mode networks and OA-bicluster density, the main quality measure of an
OA-bicluster. Our experiments with 2-, 3-, and 4-mode large real-world networks
show that this type of patterns is suitable for community detection in
multi-mode cases within reasonable time even though the number of corresponding
$n$-cliques is still unknown due to computation difficulties. An interpretation
of OA-biclusters for 1-mode networks is provided as well.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08557</dc:identifier>
 <dc:identifier>Lecture Notes in Social Networks. Formal Concept Analysis of
  Social Networks. Eds.: Kuznetsov, Missaoui, Obiedkov, Springer, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08558</identifier>
 <datestamp>2017-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DepthSynth: Real-Time Realistic Synthetic Data Generation from CAD
  Models for 2.5D Recognition</dc:title>
 <dc:creator>Planche, Benjamin</dc:creator>
 <dc:creator>Wu, Ziyan</dc:creator>
 <dc:creator>Ma, Kai</dc:creator>
 <dc:creator>Sun, Shanhui</dc:creator>
 <dc:creator>Kluckner, Stefan</dc:creator>
 <dc:creator>Chen, Terrence</dc:creator>
 <dc:creator>Hutter, Andreas</dc:creator>
 <dc:creator>Zakharov, Sergey</dc:creator>
 <dc:creator>Kosch, Harald</dc:creator>
 <dc:creator>Ernst, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent progress in computer vision has been dominated by deep neural networks
trained over large amounts of labeled data. Collecting such datasets is however
a tedious, often impossible task; hence a surge in approaches relying solely on
synthetic data for their training. For depth images however, discrepancies with
real scans still noticeably affect the end performance. We thus propose an
end-to-end framework which simulates the whole mechanism of these devices,
generating realistic depth data from 3D models by comprehensively modeling
vital factors e.g. sensor noise, material reflectance, surface geometry. Not
only does our solution cover a wider range of sensors and achieve more
realistic results than previous methods, assessed through extended evaluation,
but we go further by measuring the impact on the training of neural networks
for various recognition tasks; demonstrating how our pipeline seamlessly
integrates such architectures and consistently enhances their performance.
</dc:description>
 <dc:description>Comment: International Conference on 3D Vision 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08563</identifier>
 <datestamp>2017-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CIFT: Crowd-Informed Fine-Tuning to Improve Machine Learning Ability</dc:title>
 <dc:creator>Lalor, John P.</dc:creator>
 <dc:creator>Wu, Hao</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Item Response Theory (IRT) allows for measuring ability of Machine Learning
models as compared to a human population. However, it is difficult to create a
large dataset to train the ability of deep neural network models (DNNs). We
propose Crowd-Informed Fine-Tuning (CIFT) as a new training process, where a
pre-trained model is fine-tuned with a specialized supplemental training set
obtained via IRT model-fitting on a large set of crowdsourced response
patterns. With CIFT we can leverage the specialized set of data obtained
through IRT to inform parameter tuning in DNNs. We experiment with two loss
functions in CIFT to represent (i) memorization of fine-tuning items and (ii)
learning a probability distribution over potential labels that is similar to
the crowdsourced distribution over labels to simulate crowd knowledge. Our
results show that CIFT improves ability for a state-of-the art DNN model for
Recognizing Textual Entailment (RTE) tasks and is generalizable to a
large-scale RTE test set.
</dc:description>
 <dc:description>Comment: 8 pages plus references, 3 tables, 2 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08565</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nearly Maximally Predictive Features and Their Dimensions</dc:title>
 <dc:creator>Marzen, Sarah E.</dc:creator>
 <dc:creator>Crutchfield, James P.</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Scientific explanation often requires inferring maximally predictive features
from a given data set. Unfortunately, the collection of minimal maximally
predictive features for most stochastic processes is uncountably infinite. In
such cases, one compromises and instead seeks nearly maximally predictive
features. Here, we derive upper-bounds on the rates at which the number and the
coding cost of nearly maximally predictive features scales with desired
predictive power. The rates are determined by the fractal dimensions of a
process' mixed-state distribution. These results, in turn, show how widely-used
finite-order Markov models can fail as predictors and that mixed-state
predictive features offer a substantial improvement.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures; Supplementary materials, 5 pages, 1 figure;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/nmpf.htm</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08565</dc:identifier>
 <dc:identifier>Phys. Rev. E 95, 051301 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.95.051301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08567</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Experiment Design for Causal Discovery from Fixed Number of
  Experiments</dc:title>
 <dc:creator>Ghassami, AmirEmad</dc:creator>
 <dc:creator>Salehkaleybar, Saber</dc:creator>
 <dc:creator>Kiyavash, Negar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of causal structure learning over a set of random
variables when the experimenter is allowed to perform at most $M$ experiments
in a non-adaptive manner. We consider the optimal learning strategy in terms of
minimizing the portions of the structure that remains unknown given the limited
number of experiments in both Bayesian and minimax setting. We characterize the
theoretical optimal solution and propose an algorithm, which designs the
experiments efficiently in terms of time complexity. We show that for bounded
degree graphs, in the minimax case and in the Bayesian case with uniform
priors, our proposed algorithm is a $\rho$-approximation algorithm, where
$\rho$ is independent of the order of the underlying graph. Simulations on both
synthetic and real data show that the performance of our algorithm is very
close to the optimal solution.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08568</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>eXpose: A Character-Level Convolutional Neural Network with Embeddings
  For Detecting Malicious URLs, File Paths and Registry Keys</dc:title>
 <dc:creator>Saxe, Joshua</dc:creator>
 <dc:creator>Berlin, Konstantin</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For years security machine learning research has promised to obviate the need
for signature based detection by automatically learning to detect indicators of
attack. Unfortunately, this vision hasn't come to fruition: in fact, developing
and maintaining today's security machine learning systems can require
engineering resources that are comparable to that of signature-based detection
systems, due in part to the need to develop and continuously tune the
&quot;features&quot; these machine learning systems look at as attacks evolve. Deep
learning, a subfield of machine learning, promises to change this by operating
on raw input signals and automating the process of feature design and
extraction. In this paper we propose the eXpose neural network, which uses a
deep learning approach we have developed to take generic, raw short character
strings as input (a common case for security inputs, which include artifacts
like potentially malicious URLs, file paths, named pipes, named mutexes, and
registry keys), and learns to simultaneously extract features and classify
using character-level embeddings and convolutional neural network. In addition
to completely automating the feature design and extraction process, eXpose
outperforms manual feature extraction based baselines on all of the intrusion
detection problems we tested it on, yielding a 5%-10% detection rate gain at
0.1% false positive rate compared to these baselines.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08568</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08571</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Replicating and Scaling up Qualitative Analysis using Crowdsourcing: A
  Github-based Case Study</dc:title>
 <dc:creator>Chen, Di</dc:creator>
 <dc:creator>Stolee, Kathryn T.</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Due to the difficulties in replicating and scaling up qualitative studies,
such studies are rarely verified. Accordingly, in this paper, we leverage the
advantages of crowdsourcing (low costs, fast speed, scalable workforce) to
replicate and scale-up one state-of-the-art qualitative study. That qualitative
study explored 20 GitHub pull requests to learn factors that influence the fate
of pull requests with respect to approval and merging.
  As a secondary study, using crowdsourcing at a cost of $200, we studied 250
pull requests from 142 GitHub projects. The prior qualitative findings are
mapped into questions for crowds workers. Their answers were converted into
binary features to build a predictor which predicts whether code would be
merged with median F1 scores of 68%. For the same large group of pull requests,
the median F1 scores could achieve 90% by a predictor built with additional
features defined by prior quantitative results.
  Based on this case study, we conclude that there is much benefit in combining
different kinds of research methods. While qualitative insights are very useful
for finding novel insights, they can be hard to scale or replicate. That said,
they can guide and define the goals of scalable secondary studies that use
(e.g.) crowdsourcing+data mining. On the other hand, while data mining methods
are reproducible and scalable to large data sets, their results may be
spectacularly wrong since they lack contextual information. That said, they can
be used to test the stability and external validity, of the insights gained
from a qualitative analysis.
</dc:description>
 <dc:description>Comment: Submitted to FSE'17, 12 pages</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08574</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Millimeter Wave Beam-Selection Using Out-of-Band Spatial Information</dc:title>
 <dc:creator>Ali, Anum</dc:creator>
 <dc:creator>Gonz&#xe1;lez-Prelcic, Nuria</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communication is one feasible solution for high
data-rate applications like vehicular-to-everything communication and next
generation cellular communication. Configuring mmWave links, which can be done
through channel estimation or beam-selection, however, is a source of
significant overhead. In this paper, we propose to use spatial information
extracted at sub-6 GHz to help establish the mmWave link. First, we review the
prior work on frequency dependent channel behavior and outline a simulation
strategy to generate multi-band frequency dependent channels. Second, assuming:
(i) narrowband channels and a fully digital architecture at sub-6 GHz; and (ii)
wideband frequency selective channels, OFDM signaling, and an analog
architecture at mmWave, we outline strategies to incorporate sub-6 GHz spatial
information in mmWave compressed beam selection. We formulate compressed
beam-selection as a weighted sparse signal recovery problem, and obtain the
weighting information from sub-6 GHz channels. In addition, we outline a
structured precoder/combiner design to tailor the training to out-of-band
information. We also extend the proposed out-of-band aided compressed
beam-selection approach to leverage information from all active OFDM
subcarriers. The simulation results for achievable rate show that out-of-band
aided beam-selection can reduce the training overhead of in-band only
beam-selection by 4x.
</dc:description>
 <dc:description>Comment: 30 pages, 11 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08575</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Vector Autoregressive Models with Latent Processes</dc:title>
 <dc:creator>Salehkaleybar, Saber</dc:creator>
 <dc:creator>Etesami, Jalal</dc:creator>
 <dc:creator>Kiyavash, Negar</dc:creator>
 <dc:creator>Zhang, Kun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of learning the support of transition matrix between
random processes in a Vector Autoregressive (VAR) model from samples when a
subset of the processes are latent. It is well known that ignoring the effect
of the latent processes may lead to very different estimates of the influences
among observed processes, and we are concerned with identifying the influences
among the observed processes, those between the latent ones, and those from the
latent to the observed ones. We show that the support of transition matrix
among the observed processes and lengths of all latent paths between any two
observed processes can be identified successfully under some conditions on the
VAR model. From the lengths of latent paths, we reconstruct the latent subgraph
(representing the influences among the latent processes) with a minimum number
of variables uniquely if its topology is a directed tree. Furthermore, we
propose an algorithm that finds all possible minimal latent graphs under some
conditions on the lengths of latent paths. Our results apply to both
non-Gaussian and Gaussian cases, and experimental results on various synthetic
and real-world datasets validate our theoretical results.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08580</identifier>
 <datestamp>2017-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth Creates No Bad Local Minima</dc:title>
 <dc:creator>Lu, Haihao</dc:creator>
 <dc:creator>Kawaguchi, Kenji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In deep learning, \textit{depth}, as well as \textit{nonlinearity}, create
non-convex loss surfaces. Then, does depth alone create bad local minima? In
this paper, we prove that without nonlinearity, depth alone does not create bad
local minima, although it induces non-convex loss surface. Using this insight,
we greatly simplify a recently proposed proof to show that all of the local
minima of feedforward deep linear neural networks are global minima. Our
theoretical results generalize previous results with fewer assumptions, and
this analysis provides a method to show similar results beyond square loss in
deep linear models.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08581</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linear Time Algorithm for Solving #2SAT on Cactus Formulas</dc:title>
 <dc:creator>L&#xf3;pez, M. A.</dc:creator>
 <dc:creator>Marcial, J. R.</dc:creator>
 <dc:creator>De Ita, G.</dc:creator>
 <dc:creator>Montes-Venegas, H. A.</dc:creator>
 <dc:creator>Alejo, R.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  An O(n+m)-time algorithm is presented for counting the number of models of a
two Conjunctive Normal Form Formula F that represents a Cactus graph, where n
is the number of variables and m is the number of clauses of F. Although, it
was already known that this class of formulas could be computed in polynomial
time, we compare our proposal algorithm with two state of the art
implementations for the same problem, sharpSAT and countAntom. The results of
the comparison show that our algorithm outperforms both implementations, and it
can be considered as a base case for general counting of two Conjunctive Normal
Form Formulas.
</dc:description>
 <dc:description>Comment: 5 pages, in Spanish, submitted to IEEE Transactions on Latin America</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08581</dc:identifier>
 <dc:language>es</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08582</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private and Secure Coordination of Match-Making for Heavy-Duty Vehicle
  Platooning</dc:title>
 <dc:creator>Farokhi, Farhad</dc:creator>
 <dc:creator>Shames, Iman</dc:creator>
 <dc:creator>Johansson, Karl H.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  A secure and private framework for inter-agent communication and coordination
is developed. This allows an agent, in our case a fleet owner, to ask questions
or submit queries in an encrypted fashion using semi-homomorphic encryption.
The submitted query can be about the interest of the other fleet owners for
using a road at a specific time of the day, for instance, for the purpose of
collaborative vehicle platooning. The other agents can then provide appropriate
responses without knowing the content of the questions or the queries. Strong
privacy and security guarantees are provided for the agent who is submitting
the queries. It is also shown that the amount of the information that this
agent can extract from the other agent is bounded. In fact, with submitting one
query, a sophisticated agent can at most extract the answer to two queries.
This secure communication platform is used subsequently to develop a
distributed coordination mechanisms among fleet owners.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08584</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model-based reinforcement learning in differential graphical games</dc:title>
 <dc:creator>Kamalapurkar, Rushikesh</dc:creator>
 <dc:creator>Klotz, Justin R.</dc:creator>
 <dc:creator>Walters, Patrick</dc:creator>
 <dc:creator>Dixon, Warren E.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper seeks to combine differential game theory with the
actor-critic-identifier architecture to determine forward-in-time, approximate
optimal controllers for formation tracking in multi-agent systems, where the
agents have uncertain heterogeneous nonlinear dynamics. A continuous control
strategy is proposed, using communication feedback from extended neighbors on a
communication topology that has a spanning tree. A model-based reinforcement
learning technique is developed to cooperatively control a group of agents to
track a trajectory in a desired formation. Simulation results are presented to
demonstrate the performance of the developed technique.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08584</dc:identifier>
 <dc:identifier>doi:10.1109/TCNS.2016.2617622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08586</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Can Boltzmann Machines Discover Cluster Updates ?</dc:title>
 <dc:creator>Wang, Lei</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Boltzmann machines are physics informed generative models with wide
applications in machine learning. They can learn the probability distribution
from an input dataset and generate new samples accordingly. Applying them back
to physics, the Boltzmann machines are ideal recommender systems to accelerate
Monte Carlo simulation of physical systems due to their flexibility and
effectiveness. More intriguingly, we show that the generative sampling of the
Boltzmann Machines can even discover unknown cluster Monte Carlo algorithms.
The creative power comes from the latent representation of the Boltzmann
machines, which learn to mediate complex interactions and identify clusters of
the physical system. We demonstrate these findings with concrete examples of
the classical Ising model with and without four spin plaquette interactions.
Our results endorse a fresh research paradigm where intelligent machines are
designed to create or inspire human discovery of innovative algorithms.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, and half page appendix</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08586</dc:identifier>
 <dc:identifier>Phys. Rev. E 96, 051301 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.96.051301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08591</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Shattered Gradients Problem: If resnets are the answer, then what is
  the question?</dc:title>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:creator>Frean, Marcus</dc:creator>
 <dc:creator>Leary, Lennox</dc:creator>
 <dc:creator>Lewis, JP</dc:creator>
 <dc:creator>Ma, Kurt Wan-Duo</dc:creator>
 <dc:creator>McWilliams, Brian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A long-standing obstacle to progress in deep learning is the problem of
vanishing and exploding gradients. The problem has largely been overcome
through the introduction of carefully constructed initializations and batch
normalization. Nevertheless, architectures incorporating skip-connections such
as resnets perform much better than standard feedforward architectures despite
well-chosen initialization and batch normalization. In this paper, we identify
the shattered gradients problem. Specifically, we show that the correlation
between gradients in standard feedforward networks decays exponentially with
depth resulting in gradients that resemble white noise. In contrast, the
gradients in architectures with skip-connections are far more resistant to
shattering decaying sublinearly. Detailed empirical evidence is presented in
support of the analysis, on both fully-connected networks and convnets.
Finally, we present a new &quot;looks linear&quot; (LL) initialization that prevents
shattering. Preliminary experiments show the new initialization allows to train
very deep networks without the addition of skip-connections.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08593</identifier>
 <datestamp>2018-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mind the Gap: A Study in Global Development through Persistent Homology</dc:title>
 <dc:creator>Banman, Andrew</dc:creator>
 <dc:creator>Ziegelmeier, Lori</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  The Gapminder project set out to use statistics to dispel simplistic notions
about global development. In the same spirit, we use persistent homology, a
technique from computational algebraic topology, to explore the relationship
between country development and geography. For each country, four indicators,
gross domestic product per capita; average life expectancy; infant mortality;
and gross national income per capita, were used to quantify the development.
Two analyses were performed. The first considers clusters of the countries
based on these indicators, and the second uncovers cycles in the data when
combined with geographic border structure. Our analysis is a multi-scale
approach that reveals similarities and connections among countries at a variety
of levels. We discover localized development patterns that are invisible in
standard statistical methods.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2018-01-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08597</identifier>
 <datestamp>2017-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Sparse Winograd Convolution by Native Pruning</dc:title>
 <dc:creator>Li, Sheng</dc:creator>
 <dc:creator>Park, Jongsoo</dc:creator>
 <dc:creator>Tang, Ping Tak Peter</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse methods and the use of Winograd convolutions are two orthogonal
approaches, each of which significantly accelerates convolution computations in
modern CNNs. Sparse Winograd merges these two and thus has the potential to
offer a combined performance benefit. Nevertheless, training convolution layers
so that the resulting Winograd kernels are sparse has not hitherto been very
successful. By introducing a Winograd layer in place of a standard convolution
layer, we can learn and prune Winograd coefficients &quot;natively&quot; and obtain
sparsity level beyond 90% with only 0.1% accuracy loss with AlexNet on ImageNet
dataset. Furthermore, we present a sparse Winograd convolution algorithm and
implementation that exploits the sparsity, achieving up to 31.7 effective
TFLOP/s in 32-bit precision on a latest Intel Xeon CPU, which corresponds to a
5.4x speedup over a state-of-the-art dense convolution implementation.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08601</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Structure from Motion from Local Increment to Global Averaging</dc:title>
 <dc:creator>Zhu, Siyu</dc:creator>
 <dc:creator>Shen, Tianwei</dc:creator>
 <dc:creator>Zhou, Lei</dc:creator>
 <dc:creator>Zhang, Runze</dc:creator>
 <dc:creator>Wang, Jinglu</dc:creator>
 <dc:creator>Fang, Tian</dc:creator>
 <dc:creator>Quan, Long</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we tackle the accurate and consistent Structure from Motion
(SfM) problem, in particular camera registration, far exceeding the memory of a
single computer in parallel. Different from the previous methods which
drastically simplify the parameters of SfM and sacrifice the accuracy of the
final reconstruction, we try to preserve the connectivities among cameras by
proposing a camera clustering algorithm to divide a large SfM problem into
smaller sub-problems in terms of camera clusters with overlapping. We then
exploit a hybrid formulation that applies the relative poses from local
incremental SfM into a global motion averaging framework and produce accurate
and consistent global camera poses. Our scalable formulation in terms of camera
clusters is highly applicable to the whole SfM pipeline including track
generation, local SfM, 3D point triangulation and bundle adjustment. We are
even able to reconstruct the camera poses of a city-scale data-set containing
more than one million high-resolution images with superior accuracy and
robustness evaluated on benchmark, Internet, and sequential data-sets.
</dc:description>
 <dc:description>Comment: Under review at the International Conference on Computer Vision
  (ICCV) 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08606</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Active Atlas: Combining 3D Anatomical Models with Texture Detectors</dc:title>
 <dc:creator>Chen, Yuncong</dc:creator>
 <dc:creator>McElvain, Lauren</dc:creator>
 <dc:creator>Tolpygo, Alex</dc:creator>
 <dc:creator>Ferrante, Daniel</dc:creator>
 <dc:creator>Karten, Harvey</dc:creator>
 <dc:creator>Mitra, Partha</dc:creator>
 <dc:creator>Kleinfeld, David</dc:creator>
 <dc:creator>Freund, Yoav</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  While modern imaging technologies such as fMRI have opened exciting new
possibilities for studying the brain in vivo, histological sections remain the
best way to study the anatomy of the brain at the level of single neurons. The
histological atlas changed little since 1909 and localizing brain regions is a
still a labor intensive process performed only by experienced neuro-anatomists.
Existing digital atlases such as the Allen Brain atlas are limited to low
resolution images which cannot identify the detailed structure of the neurons.
We have developed a digital atlas methodology that combines information about
the 3D organization of the brain and the detailed texture of neurons in
different structures. Using the methodology we developed an atlas for the mouse
brainstem and mid-brain, two regions for which there are currently no good
atlases. Our atlas is &quot;active&quot; in that it can be used to automatically align a
histological stack to the atlas, thus reducing the work of the neuroanatomist.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, appeared in proceeding of MICCAI 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08607</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster DB-scan and HDB-scan in Low-Dimensional Euclidean Spaces</dc:title>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Gunawan, Ade</dc:creator>
 <dc:creator>Roeloffzen, Marcel</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We present a new algorithm for the widely used density-based clustering
method DBscan. Our algorithm computes the DBscan-clustering in $O(n\log n)$
time in $\mathbb{R}^2$, irrespective of the scale parameter $\varepsilon$ (and
assuming the second parameter MinPts is set to a fixed constant, as is the case
in practice). Experiments show that the new algorithm is not only fast in
theory, but that a slightly simplified version is competitive in practice and
much less sensitive to the choice of $\varepsilon$ than the original DBscan
algorithm. We also present an $O(n\log n)$ randomized algorithm for HDBscan in
the plane---HDBscan is a hierarchical version of DBscan introduced
recently---and we show how to compute an approximate version of HDBscan in
near-linear time in any fixed dimension.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08608</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards A Rigorous Science of Interpretable Machine Learning</dc:title>
 <dc:creator>Doshi-Velez, Finale</dc:creator>
 <dc:creator>Kim, Been</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As machine learning systems become ubiquitous, there has been a surge of
interest in interpretable machine learning: systems that provide explanation
for their outputs. These explanations are often used to qualitatively assess
other criteria such as safety or non-discrimination. However, despite the
interest in interpretability, there is very little consensus on what
interpretable machine learning is and how it should be measured. In this
position paper, we first define interpretability and describe when
interpretability is needed (and when it is not). Next, we suggest a taxonomy
for rigorous evaluation and expose open questions towards a more rigorous
science of interpretable machine learning.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08623</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progress Estimation and Phase Detection for Sequential Processes</dc:title>
 <dc:creator>Li, Xinyu</dc:creator>
 <dc:creator>Zhang, Yanyi</dc:creator>
 <dc:creator>Zhang, Jianyu</dc:creator>
 <dc:creator>Chen, Yueyang</dc:creator>
 <dc:creator>Chen, Shuhong</dc:creator>
 <dc:creator>Gu, Yue</dc:creator>
 <dc:creator>Zhou, Moliang</dc:creator>
 <dc:creator>Farneth, Richard A.</dc:creator>
 <dc:creator>Marsic, Ivan</dc:creator>
 <dc:creator>Burd, Randall S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Process modeling and understanding are fundamental for advanced
human-computer interfaces and automation systems. Most recent research has
focused on activity recognition, but little has been done on sensor-based
detection of process progress. We introduce a real-time, sensor-based system
for modeling, recognizing and estimating the progress of a work process. We
implemented a multimodal deep learning structure to extract the relevant
spatio-temporal features from multiple sensory inputs and used a novel deep
regression structure for overall completeness estimation. Using process
completeness estimation with a Gaussian mixture model, our system can predict
the phase for sequential processes. The performance speed, calculated using
completeness estimation, allows online estimation of the remaining time. To
train our system, we introduced a novel rectified hyperbolic tangent (rtanh)
activation function and conditional loss. Our system was tested on data
obtained from the medical process (trauma resuscitation) and sports events
(Olympic swimming competition). Our system outperformed the existing
trauma-resuscitation phase detectors with a phase detection accuracy of over
86%, an F1-score of 0.67, a completeness estimation error of under 12.6%, and a
remaining-time estimation error of less than 7.5 minutes. For the Olympic
swimming dataset, our system achieved an accuracy of 88%, an F1-score of 0.58,
a completeness estimation error of 6.3% and a remaining-time estimation error
of 2.9 minutes.
</dc:description>
 <dc:description>Comment: Accepted by IMWUT/Ubicomp 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08626</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Show, Attend and Interact: Perceivable Human-Robot Social Interaction
  through Neural Attention Q-Network</dc:title>
 <dc:creator>Qureshi, Ahmed Hussain</dc:creator>
 <dc:creator>Nakamura, Yutaka</dc:creator>
 <dc:creator>Yoshikawa, Yuichiro</dc:creator>
 <dc:creator>Ishiguro, Hiroshi</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  For a safe, natural and effective human-robot social interaction, it is
essential to develop a system that allows a robot to demonstrate the
perceivable responsive behaviors to complex human behaviors. We introduce the
Multimodal Deep Attention Recurrent Q-Network using which the robot exhibits
human-like social interaction skills after 14 days of interacting with people
in an uncontrolled real world. Each and every day during the 14 days, the
system gathered robot interaction experiences with people through a
hit-and-trial method and then trained the MDARQN on these experiences using
end-to-end reinforcement learning approach. The results of interaction based
learning indicate that the robot has learned to respond to complex human
behaviors in a perceivable and socially acceptable manner.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, accepted by IEEE-RAS ICRA'17</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08627</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Optimization Framework with Flexible Inexact Inner Iterations for
  Nonconvex and Nonsmooth Programming</dc:title>
 <dc:creator>Wang, Yiyang</dc:creator>
 <dc:creator>Liu, Risheng</dc:creator>
 <dc:creator>Song, Xiaoliang</dc:creator>
 <dc:creator>Su, Zhixun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In recent years, numerous vision and learning tasks have been (re)formulated
as nonconvex and nonsmooth programmings(NNPs). Although some algorithms have
been proposed for particular problems, designing fast and flexible optimization
schemes with theoretical guarantee is a challenging task for general NNPs. It
has been investigated that performing inexact inner iterations often benefit to
special applications case by case, but their convergence behaviors are still
unclear. Motivated by these practical experiences, this paper designs a novel
algorithmic framework, named inexact proximal alternating direction method
(IPAD) for solving general NNPs. We demonstrate that any numerical algorithms
can be incorporated into IPAD for solving subproblems and the convergence of
the resulting hybrid schemes can be consistently guaranteed by a series of
simple error conditions. Beyond the guarantee in theory, numerical experiments
on both synthesized and real-world data further demonstrate the superiority and
flexibility of our IPAD framework for practical use.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08627</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08628</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Agent Expertise in Ms. Pac-Man using
  Value-of-Information-based Policies</dc:title>
 <dc:creator>Sledge, Isaac J.</dc:creator>
 <dc:creator>Principe, Jose C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Conventional reinforcement learning methods for Markov decision processes
rely on weakly-guided, stochastic searches to drive the learning process. It
can therefore be difficult to predict what agent behaviors might emerge. In
this paper, we consider an information-theoretic cost function for performing
constrained stochastic searches that promote the formation of risk-averse to
risk-favoring behaviors. This cost function is the value of information, which
provides the optimal trade-off between the expected return of a policy and the
policy's complexity; policy complexity is measured by number of bits and
controlled by a single hyperparameter on the cost function. As the policy
complexity is reduced, the agents will increasingly eschew risky actions. This
reduces the potential for high accrued rewards. As the policy complexity
increases, the agents will take actions, regardless of the risk, that can raise
the long-term rewards. The obtainable reward depends on a single, tunable
hyperparameter that regulates the degree of policy complexity.
  We evaluate the performance of value-of-information-based policies on a
stochastic version of Ms. Pac-Man. A major component of this paper is the
demonstration that ranges of policy complexity values yield different game-play
styles and explaining why this occurs. We also show that our
reinforcement-learning search mechanism is more efficient than the others we
utilize. This result implies that the value of information theory is
appropriate for framing the exploitation-exploration trade-off in reinforcement
learning.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Computational Intelligence and Artificial
  Intelligence in Games</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08628</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08634</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Trajectory for Video Segmentation</dc:title>
 <dc:creator>Wang, Wenguan</dc:creator>
 <dc:creator>Shen, Jianbing</dc:creator>
 <dc:creator>Xie, Jianwen</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We introduce a novel semi-supervised video segmentation approach based on an
efficient video representation, called as &quot;super-trajectory&quot;. Each
super-trajectory corresponds to a group of compact trajectories that exhibit
consistent motion patterns, similar appearance and close spatiotemporal
relationships. We generate trajectories using a probabilistic model, which
handles occlusions and drifts in a robust and natural way. To reliably group
trajectories, we adopt a modified version of the density peaks based clustering
algorithm that allows capturing rich spatiotemporal relations among
trajectories in the clustering process. The presented video representation is
discriminative enough to accurately propagate the initial annotations in the
first frame onto the remaining video frames. Extensive experimental analysis on
challenging benchmarks demonstrate our method is capable of distinguishing the
target objects from complex backgrounds and even reidentifying them after
long-term occlusions.
</dc:description>
 <dc:description>Comment: This paper has been published in ICCV 2017</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08634</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08635</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning What Data to Learn</dc:title>
 <dc:creator>Fan, Yang</dc:creator>
 <dc:creator>Tian, Fei</dc:creator>
 <dc:creator>Qin, Tao</dc:creator>
 <dc:creator>Bian, Jiang</dc:creator>
 <dc:creator>Liu, Tie-Yan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Machine learning is essentially the sciences of playing with data. An
adaptive data selection strategy, enabling to dynamically choose different data
at various training stages, can reach a more effective model in a more
efficient way. In this paper, we propose a deep reinforcement learning
framework, which we call \emph{\textbf{N}eural \textbf{D}ata \textbf{F}ilter}
(\textbf{NDF}), to explore automatic and adaptive data selection in the
training process. In particular, NDF takes advantage of a deep neural network
to adaptively select and filter important data instances from a sequential
stream of training data, such that the future accumulative reward (e.g., the
convergence speed) is maximized. In contrast to previous studies in data
selection that is mainly based on heuristic strategies, NDF is quite generic
and thus can be widely suitable for many machine learning tasks. Taking neural
network training with stochastic gradient descent (SGD) as an example,
comprehensive experiments with respect to various neural network modeling
(e.g., multi-layer perceptron networks, convolutional neural networks and
recurrent neural networks) and several applications (e.g., image classification
and text understanding) demonstrate that NDF powered SGD can achieve comparable
accuracy with standard SGD process by using less data and fewer iterations.
</dc:description>
 <dc:description>Comment: A preliminary version will appear in ICLR 2017, workshop track.
  https://openreview.net/forum?id=SyJNmVqgg&amp;noteId=SyJNmVqgg</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08640</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selective Video Object Cutout</dc:title>
 <dc:creator>Wang, Wenguan</dc:creator>
 <dc:creator>Shen, Jianbing</dc:creator>
 <dc:creator>Porikli, Fatih</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Conventional video segmentation approaches rely heavily on appearance models.
Such methods often use appearance descriptors that have limited discriminative
power under complex scenarios. To improve the segmentation performance, this
paper presents a pyramid histogram based confidence map that incorporates
structure information into appearance statistics. It also combines geodesic
distance based dynamic models. Then, it employs an efficient measure of
uncertainty propagation using local classifiers to determine the image regions
where the object labels might be ambiguous. The final foreground cutout is
obtained by refining on the uncertain regions. Additionally, to reduce manual
labeling, our method determines the frames to be labeled by the human operator
in a principled manner, which further boosts the segmentation performance and
minimizes the labeling effort. Our extensive experimental analyses on two big
benchmarks demonstrate that our solution achieves superior performance,
favorable computational efficiency, and reduced manual labeling in comparison
to the state-of-the-art.
</dc:description>
 <dc:description>Comment: Wang, Wenguan, Jianbing Shen, and Fatih Porikli. &quot;Selective video
  object cutout.&quot; IEEE Transactions on Image Processing 26.12 (2017): 5645-5655</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08640</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, Vol. 26, No. 12, pp
  5645-5655, 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2745098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08641</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Information Fusion for Multiple-View Sensor Data in
  Multi-Object Tracking</dc:title>
 <dc:creator>Wang, Xiaoying</dc:creator>
 <dc:creator>Hoseinnezhad, Reza</dc:creator>
 <dc:creator>Gostar, Amirali K.</dc:creator>
 <dc:creator>Rathnayake, Tharindu</dc:creator>
 <dc:creator>Xu, Benlian</dc:creator>
 <dc:creator>Bab-Hadiashar, Alireza</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents a novel statistical information fusion method to
integrate multiple-view sensor data in multi-object tracking applications. The
proposed method overcomes the drawbacks of the commonly used Generalized
Covariance Intersection method, which considers constant weights allocated for
sensors. Our method is based on enhancing the Generalized Covariance
Intersection with adaptive weights that are automatically tuned based on the
amount of information carried by the measurements from each sensor. To quantify
information content, Cauchy-Schwarz divergence is used. Another distinguished
characteristic of our method lies in the usage of the Labeled Multi-Bernoulli
filter for multi-object tracking, in which the weight of each sensor can be
separately adapted for each Bernoulli component of the filter. The results of
numerical experiments show that our proposed method can successfully integrate
information provided by multiple sensors with different fields of view. In such
scenarios, our method significantly outperforms the state of art in terms of
inclusion of all existing objects and tracking accuracy.
</dc:description>
 <dc:description>Comment: 28 pages,7 figures</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08646</identifier>
 <datestamp>2017-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boundary Flow: A Siamese Network that Predicts Boundary Motion without
  Training on Motion</dc:title>
 <dc:creator>Lei, Peng</dc:creator>
 <dc:creator>Li, Fuxin</dc:creator>
 <dc:creator>Todorovic, Sinisa</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses a new problem of joint object boundary detection and
boundary motion estimation in videos, which we named boundary flow estimation.
Boundary flow is an important mid-level visual cue as boundaries characterize
objects spatial extents, and the flow indicates objects motions and
interactions. Yet, most prior work on motion estimation has focused on dense
object motion or feature points that may not necessarily reside on boundaries.
For boundary flow estimation, we specify a new fully convolutional Siamese
network (FCSN) that jointly estimates object-level boundaries in two
consecutive frames. Boundary correspondences in the two frames are predicted by
the same FCSN with a new, unconventional deconvolution approach. Finally, the
boundary flow estimate is improved with an edgelet-based filtering. Evaluation
is conducted on three tasks: boundary detection in videos, boundary flow
estimation, and optical flow estimation. On boundary detection, we achieve the
state-of-the-art performance on the benchmark VSB100 dataset. On boundary flow
estimation, we present the first results on the Sintel training dataset. For
optical flow estimation, we run the recent approach CPM-Flow but on the
augmented input with our boundary-flow matches, and achieve significant
performance improvement on the Sintel benchmark.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-09-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08648</identifier>
 <datestamp>2017-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Auto-clustering Output Layer: Automatic Learning of Latent Annotations
  in Neural Networks</dc:title>
 <dc:creator>Kilinc, Ozsel</dc:creator>
 <dc:creator>Uysal, Ismail</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we discuss a different type of semi-supervised setting: a
coarse level of labeling is available for all observations but the model has to
learn a fine level of latent annotation for each one of them. Problems in this
setting are likely to be encountered in many domains such as text
categorization, protein function prediction, image classification as well as in
exploratory scientific studies such as medical and genomics research. We
consider this setting as simultaneously performed supervised classification
(per the available coarse labels) and unsupervised clustering (within each one
of the coarse labels) and propose a novel output layer modification called
auto-clustering output layer (ACOL) that allows concurrent classification and
clustering based on Graph-based Activity Regularization (GAR) technique. As the
proposed output layer modification duplicates the softmax nodes at the output
layer for each class, GAR allows for competitive learning between these
duplicates on a traditional error-correction learning framework to ultimately
enable a neural network to learn the latent annotations in this partially
supervised setup. We demonstrate how the coarse label supervision impacts
performance and helps propagate useful clustering information between
sub-classes. Comparative tests on three of the most popular image datasets
MNIST, SVHN and CIFAR-100 rigorously demonstrate the effectiveness and
competitiveness of the proposed approach.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Neural Networks and Learning
  Systems, 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08651</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Speeding Up Latent Variable Gaussian Graphical Model Estimation via
  Nonconvex Optimizations</dc:title>
 <dc:creator>Xu, Pan</dc:creator>
 <dc:creator>Ma, Jian</dc:creator>
 <dc:creator>Gu, Quanquan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study the estimation of the latent variable Gaussian graphical model
(LVGGM), where the precision matrix is the superposition of a sparse matrix and
a low-rank matrix. In order to speed up the estimation of the sparse plus
low-rank components, we propose a sparsity constrained maximum likelihood
estimator based on matrix factorization, and an efficient alternating gradient
descent algorithm with hard thresholding to solve it. Our algorithm is orders
of magnitude faster than the convex relaxation based methods for LVGGM. In
addition, we prove that our algorithm is guaranteed to linearly converge to the
unknown sparse and low-rank components up to the optimal statistical precision.
Experiments on both synthetic and genomic data demonstrate the superiority of
our algorithm over the state-of-the-art algorithms and corroborate our theory.
</dc:description>
 <dc:description>Comment: 29 pages, 5 figures, 3 tables</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08651</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08652</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Flow to Action Map: A New Representation for RGB-D based Action
  Recognition with Convolutional Neural Networks</dc:title>
 <dc:creator>Wang, Pichao</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:creator>Gao, Zhimin</dc:creator>
 <dc:creator>Zhang, Yuyao</dc:creator>
 <dc:creator>Tang, Chang</dc:creator>
 <dc:creator>Ogunbona, Philip</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Scene flow describes the motion of 3D objects in real world and potentially
could be the basis of a good feature for 3D action recognition. However, its
use for action recognition, especially in the context of convolutional neural
networks (ConvNets), has not been previously studied. In this paper, we propose
the extraction and use of scene flow for action recognition from RGB-D data.
Previous works have considered the depth and RGB modalities as separate
channels and extract features for later fusion. We take a different approach
and consider the modalities as one entity, thus allowing feature extraction for
action recognition at the beginning. Two key questions about the use of scene
flow for action recognition are addressed: how to organize the scene flow
vectors and how to represent the long term dynamics of videos based on scene
flow. In order to calculate the scene flow correctly on the available datasets,
we propose an effective self-calibration method to align the RGB and depth data
spatially without knowledge of the camera parameters. Based on the scene flow
vectors, we propose a new representation, namely, Scene Flow to Action Map
(SFAM), that describes several long term spatio-temporal dynamics for action
recognition. We adopt a channel transform kernel to transform the scene flow
vectors to an optimal color space analogous to RGB. This transformation takes
better advantage of the trained ConvNets models over ImageNet. Experimental
results indicate that this new representation can surpass the performance of
state-of-the-art methods on two large public datasets.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08652</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08653</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaffolding Networks: Incremental Learning and Teaching Through
  Questioning</dc:title>
 <dc:creator>Celikyilmaz, Asli</dc:creator>
 <dc:creator>Deng, Li</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Wang, Chong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce a new paradigm of learning for reasoning, understanding, and
prediction, as well as the scaffolding network to implement this paradigm. The
scaffolding network embodies an incremental learning approach that is
formulated as a teacher-student network architecture to teach machines how to
understand text and do reasoning. The key to our computational scaffolding
approach is the interactions between the teacher and the student through
sequential questioning. The student observes each sentence in the text
incrementally, and it uses an attention-based neural net to discover and
register the key information in relation to its current memory. Meanwhile, the
teacher asks questions about the observed text, and the student network gets
rewarded by correctly answering these questions. The entire network is updated
continually using reinforcement learning. Our experimental results on synthetic
and real datasets show that the scaffolding network not only outperforms
state-of-the-art methods but also learns to do reasoning in a scalable way even
with little human generated input.
</dc:description>
 <dc:description>Comment: 11 pages + Abstract + 3 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08653</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08654</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Improved Lower Bound for General Position Subset Selection</dc:title>
 <dc:creator>Rudi, Ali Gholami</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>65D18, 05C69</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:subject>I.3.5</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In the General Position Subset Selection (GPSS) problem, the goal is to find
the largest possible subset of a set of points, such that no three of its
members are collinear. If $s_{\textrm{GPSS}}$ is the size the optimal solution,
$\sqrt{s_{\textrm{GPSS}}}$ is the current best guarantee for the size of the
solution obtained using a polynomial time algorithm. In this paper we present
an algorithm for GPSS to improve this bound based on the number of collinear
pairs of points. We experimentally evaluate this and few other GPSS algorithms;
the result of these experiments suggests further opportunities for obtaining
tighter lower bounds for GPSS.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08654</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08656</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stepping Forward with Exoskeletons: Team IHMC's Design and Approach in
  the 2016 Cybathlon</dc:title>
 <dc:creator>Griffin, Robert</dc:creator>
 <dc:creator>Cobb, Tyson</dc:creator>
 <dc:creator>Craig, Travis</dc:creator>
 <dc:creator>Daniel, Mark</dc:creator>
 <dc:creator>van Dijk, Nick</dc:creator>
 <dc:creator>Gines, Jeremy</dc:creator>
 <dc:creator>Kramer, Koen</dc:creator>
 <dc:creator>Shah, Shriya</dc:creator>
 <dc:creator>Siebinga, Olger</dc:creator>
 <dc:creator>Smith, Jesper</dc:creator>
 <dc:creator>Neuhaus, Peter</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Exoskeletons are a promising technology that enables individuals with
mobility limitations to walk again. As the 2016 Cybathlon illustrated, however,
the community has a considerable way to go before exoskeletons have the
necessary capabilities to be incorporated into daily life. While most
exoskeletons power only hip and knee flexion, Team Institute for Human and
Machine Cognition (IHMC) presents a new exoskeleton, Mina v2, which includes a
powered ankle dorsi/plantar flexion. As our entry to the 2016 Cybathlon Powered
Exoskeleton Competition, Mina v2's performance allowed us to explore the
effectiveness of its powered ankle compared to other powered exoskeletons for
pilots with paraplegia. We designed our gaits to incorporate powered ankle
plantar flexion to help improve mobility, which allowed our pilot to navigate
the given Cybathlon tasks quickly, including those that required ascending
movements, and reliably achieve average, conservative walking speeds of 1.04
km/h (0.29 m/s). This enabled our team to place second overall in the Powered
Exoskeleton Competition in the 2016 Cybathlon.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08656</dc:identifier>
 <dc:identifier>IEEE Robotics &amp; Automation Magazine, Volume: 24, Issue 4, Dec.
  2017</dc:identifier>
 <dc:identifier>doi:10.1109/MRA.2017.2754284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08658</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Deeper Understanding of Variational Autoencoding Models</dc:title>
 <dc:creator>Zhao, Shengjia</dc:creator>
 <dc:creator>Song, Jiaming</dc:creator>
 <dc:creator>Ermon, Stefano</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new family of optimization criteria for variational
auto-encoding models, generalizing the standard evidence lower bound. We
provide conditions under which they recover the data distribution and learn
latent features, and formally show that common issues such as blurry samples
and uninformative latent features arise when these conditions are not met.
Based on these new insights, we propose a new sequential VAE model that can
generate sharp samples on the LSUN image dataset based on pixel-wise
reconstruction loss, and propose an optimization criterion that encourages
unsupervised learning of informative latent features.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08660</identifier>
 <datestamp>2017-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity of short generating functions</dc:title>
 <dc:creator>Nguyen, Danny</dc:creator>
 <dc:creator>Pak, Igor</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:description>  We give complexity analysis of the class of short generating functions (GF).
Assuming $\#P \not\subseteq FP/poly$, we show that this class is not closed
under taking many intersections, unions or projections of GFs, in the sense
that these operations can increase the bitlength of coefficients of GFs by a
super-polynomial factor. We also prove that truncated theta functions are hard
in this class.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08661</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampled-Data Boundary Feedback Control of 1-D Hyperbolic PDEs with
  Non-Local Terms</dc:title>
 <dc:creator>Karafyllis, Iasson</dc:creator>
 <dc:creator>Krstic, Miroslav</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  The paper provides results for the application of boundary feedback control
with Zero-Order-Hold (ZOH) to 1-D linear, first-order, hyperbolic systems with
non-local terms on bounded domains. It is shown that the emulation design based
on the recently proposed continuous-time, boundary feedback, designed by means
of backstepping, guarantees closed-loop exponential stability, provided that
the sampling period is sufficiently small. It is also shown that, contrary to
the parabolic case, a smaller sampling period implies a faster convergence rate
with no upper bound for the achieved convergence rate. The obtained results
provide stability estimates for the sup-norm of the state and robustness with
respect to perturbations of the sampling schedule is guaranteed.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures, submitted to Systems and Control Letters for
  possible publication. arXiv admin note: text overlap with arXiv:1701.01955</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08662</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The computational complexity of integer programming with alternations</dc:title>
 <dc:creator>Nguyen, Danny</dc:creator>
 <dc:creator>Pak, Igor</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We prove that integer programming with three quantifier alternations is
$NP$-complete, even for a fixed number of variables. This complements earlier
results by Lenstra and Kannan, which together say that integer programming with
at most two quantifier alternations can be done in polynomial time for a fixed
number of variables. As a byproduct of the proof, we show that for two
polytopes $P,Q \subset \mathbb{R}^4$ , counting the projection of integer
points in $Q \backslash P$ is $\#P$-complete. This contrasts the 2003 result by
Barvinok and Woods, which allows counting in polynomial time the projection of
integer points in $P$ and $Q$ separately.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08664</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decomposition of polynomial sets into characteristic pairs</dc:title>
 <dc:creator>Wang, Dongming</dc:creator>
 <dc:creator>Dong, Rina</dc:creator>
 <dc:creator>Mou, Chenqi</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  A characteristic pair is a pair (G,C) of polynomial sets in which G is a
reduced lexicographic Groebner basis, C is the minimal triangular set contained
in G, and C is normal. In this paper, we show that any finite polynomial set P
can be decomposed algorithmically into finitely many characteristic pairs with
associated zero relations, which provide representations for the zero set of P
in terms of those of Groebner bases and those of triangular sets. The algorithm
we propose for the decomposition makes use of the inherent connection between
Ritt characteristic sets and lexicographic Groebner bases and is based
essentially on the structural properties and the computation of lexicographic
Groebner bases. Several nice properties about the decomposition and the
resulting characteristic pairs, in particular relationships between the
Groebner basis and the triangular set in each pair, are established. Examples
are given to illustrate the algorithm and some of the properties.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08670</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On architectural choices in deep learning: From network structure to
  gradient convergence and parameter estimation</dc:title>
 <dc:creator>Ithapu, Vamsi K</dc:creator>
 <dc:creator>Ravi, Sathya N</dc:creator>
 <dc:creator>Singh, Vikas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study mechanisms to characterize how the asymptotic convergence of
backpropagation in deep architectures, in general, is related to the network
structure, and how it may be influenced by other design choices including
activation type, denoising and dropout rate. We seek to analyze whether network
architecture and input data statistics may guide the choices of learning
parameters and vice versa. Given the broad applicability of deep architectures,
this issue is interesting both from theoretical and a practical standpoint.
Using properties of general nonconvex objectives (with first-order
information), we first build the association between structural, distributional
and learnability aspects of the network vis-\`a-vis their interaction with
parameter convergence rates. We identify a nice relationship between feature
denoising and dropout, and construct families of networks that achieve the same
level of convergence. We then derive a workflow that provides systematic
guidance regarding the choice of network sizes and learning parameters often
mediated4 by input statistics. Our technical results are corroborated by an
extensive set of evaluations, presented in this paper as well as independent
empirical observations reported by other groups. We also perform experiments
showing the practical implications of our framework for choosing the best
fully-connected design for a given problem.
</dc:description>
 <dc:description>Comment: 87 Pages; 14 figures; Under review</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08675</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>3D Shape Segmentation via Shape Fully Convolutional Networks</dc:title>
 <dc:creator>Wang, Pengyu</dc:creator>
 <dc:creator>Gan, Yuan</dc:creator>
 <dc:creator>Shui, Panpan</dc:creator>
 <dc:creator>Yu, Fenggen</dc:creator>
 <dc:creator>Zhang, Yan</dc:creator>
 <dc:creator>Chen, Songle</dc:creator>
 <dc:creator>Sun, Zhengxing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a novel fully convolutional network architecture for shapes,
denoted by Shape Fully Convolutional Networks (SFCN). 3D shapes are represented
as graph structures in the SFCN architecture, based on novel graph convolution
and pooling operations, which are similar to convolution and pooling operations
used on images. Meanwhile, to build our SFCN architecture in the original image
segmentation fully convolutional network (FCN) architecture, we also design and
implement a generating operation} with bridging function. This ensures that the
convolution and pooling operation we have designed can be successfully applied
in the original FCN architecture. In this paper, we also present a new shape
segmentation approach based on SFCN. Furthermore, we allow more general and
challenging input, such as mixed datasets of different categories of shapes}
which can prove the ability of our generalisation. In our approach, SFCNs are
trained triangles-to-triangles by using three low-level geometric features as
input. Finally, the feature voting-based multi-label graph cuts is adopted to
optimise the segmentation results obtained by SFCN prediction. The experiment
results show that our method can effectively learn and predict mixed shape
datasets of either similar or different characteristics, and achieve excellent
segmentation results.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08680</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Data-driven Approach for Furniture and Indoor Scene Colorization</dc:title>
 <dc:creator>Zhu, Jie</dc:creator>
 <dc:creator>Guo, Yanwen</dc:creator>
 <dc:creator>Ma, Han</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>65D18</dc:subject>
 <dc:subject>I.3.7</dc:subject>
 <dc:subject>I.3.8</dc:subject>
 <dc:description>  We present a data-driven approach that colorizes 3D furniture models and
indoor scenes by leveraging indoor images on the internet. Our approach is able
to colorize the furniture automatically according to an example image. The core
is to learn image-guided mesh segmentation to segment the model into different
parts according to the image object. Given an indoor scene, the system supports
colorization-by-example, and has the ability to recommend the colorization
scheme that is consistent with a user-desired color theme. The latter is
realized by formulating the problem as a Markov random field model that imposes
user input as an additional constraint. We contribute to the community a
hierarchically organized image-model database with correspondences between each
image and the corresponding model at the part-level. Our experiments and a user
study show that our system produces perceptually convincing results comparable
to those generated by interior designers.
</dc:description>
 <dc:description>Comment: 13 pages, 16 figures, submission to IEEE TVCG</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08681</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MIML-FCN+: Multi-instance Multi-label Learning via Fully Convolutional
  Networks with Privileged Information</dc:title>
 <dc:creator>Yang, Hao</dc:creator>
 <dc:creator>Zhou, Joey Tianyi</dc:creator>
 <dc:creator>Cai, Jianfei</dc:creator>
 <dc:creator>Ong, Yew Soon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Multi-instance multi-label (MIML) learning has many interesting applications
in computer visions, including multi-object recognition and automatic image
tagging. In these applications, additional information such as bounding-boxes,
image captions and descriptions is often available during training phrase,
which is referred as privileged information (PI). However, as existing works on
learning using PI only consider instance-level PI (privileged instances), they
fail to make use of bag-level PI (privileged bags) available in MIML learning.
Therefore, in this paper, we propose a two-stream fully convolutional network,
named MIML-FCN+, unified by a novel PI loss to solve the problem of MIML
learning with privileged bags. Compared to the previous works on PI, the
proposed MIML-FCN+ utilizes the readily available privileged bags, instead of
hard-to-obtain privileged instances, making the system more general and
practical in real world applications. As the proposed PI loss is convex and SGD
compatible and the framework itself is a fully convolutional network, MIML-FCN+
can be easily integrated with state of-the-art deep learning networks.
Moreover, the flexibility of convolutional layers allows us to exploit
structured correlations among instances to facilitate more effective training
and testing. Experimental results on three benchmark datasets demonstrate the
effectiveness of the proposed MIML-FCN+, outperforming state-of-the-art methods
in the application of multi-object recognition.
</dc:description>
 <dc:description>Comment: Accepted in CVPR 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08690</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Borrowing Treasures from the Wealthy: Deep Transfer Learning through
  Selective Joint Fine-tuning</dc:title>
 <dc:creator>Ge, Weifeng</dc:creator>
 <dc:creator>Yu, Yizhou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep neural networks require a large amount of labeled training data during
supervised learning. However, collecting and labeling so much data might be
infeasible in many cases. In this paper, we introduce a source-target selective
joint fine-tuning scheme for improving the performance of deep learning tasks
with insufficient training data. In this scheme, a target learning task with
insufficient training data is carried out simultaneously with another source
learning task with abundant training data. However, the source learning task
does not use all existing training data. Our core idea is to identify and use a
subset of training images from the original source learning task whose
low-level characteristics are similar to those from the target learning task,
and jointly fine-tune shared convolutional layers for both tasks. Specifically,
we compute descriptors from linear or nonlinear filter bank responses on
training images from both tasks, and use such descriptors to search for a
desired subset of training samples for the source learning task.
  Experiments demonstrate that our selective joint fine-tuning scheme achieves
state-of-the-art performance on multiple visual classification tasks with
insufficient training data for deep learning. Such tasks include Caltech 256,
MIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to
fine-tuning without a source domain, the proposed method can improve the
classification accuracy by 2% - 10% using a single model.
</dc:description>
 <dc:description>Comment: To appear in 2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2017)</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08692</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cascade one-vs-rest detection network for fine-grained recognition
  without part annotations</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Dong, Junyu</dc:creator>
 <dc:creator>Wang, ShengKe</dc:creator>
 <dc:creator>Lam, Kin-Man</dc:creator>
 <dc:creator>Jian, Muwei</dc:creator>
 <dc:creator>Zhang, Hua</dc:creator>
 <dc:creator>Cao, XiaoChun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fine-grained recognition is a challenging task due to the small
intra-category variances. Most of top-performing fine-grained recognition
methods leverage parts of objects for better performance. Therefore, part
annotations which are extremely computationally expensive are required. In this
paper, we propose a novel cascaded deep CNN detection framework for
fine-grained recognition which is trained to detect the whole object without
considering parts. Nevertheless, most of current top-performing detection
networks use the N+1 class (N object categories plus background) softmax loss,
and the background category with much more training samples dominates the
feature learning progress so that the features are not good for object
categories with fewer samples. To bridge this gap, we introduce a cascaded
structure to eliminate background and exploit a one-vs-rest loss to capture
more minute variances among different subordinate categories. Experiments show
that our proposed recognition framework achieves comparable performance with
state-of-the-art, part-free, fine-grained recognition methods on the
CUB-200-2011 Bird dataset. Moreover, our method even outperforms most of
part-based methods while does not need part annotations at the training stage
and is free from any annotations at test stage.
</dc:description>
 <dc:description>Comment: Part of authors has changed</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08694</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding Significant Combinations of Continuous Features</dc:title>
 <dc:creator>Sugiyama, Mahito</dc:creator>
 <dc:creator>Borgwardt, Karsten M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We present an efficient feature selection method that can find all
multiplicative combinations of continuous features that are statistically
significantly associated with the class variable, while rigorously correcting
for multiple testing. The key to overcome the combinatorial explosion in the
number of candidates is to derive a lower bound on the $p$-value for each
feature combination, which enables us to massively prune combinations that can
never be significant and gain more statistical power. While this problem has
been addressed for binary features in the past, we here present the first
solution for continuous features. In our experiments, our novel approach
detects true feature combinations with higher precision and recall than
competing methods that require a prior binarization of the data.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, 2 tables</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08694</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08695</identifier>
 <datestamp>2017-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Robot Introspection via Wrench-based Action Grammars</dc:title>
 <dc:creator>Rojas, Juan</dc:creator>
 <dc:creator>Luo, Shuangqi</dc:creator>
 <dc:creator>Zhu, Dingqiao</dc:creator>
 <dc:creator>Du, Yunlong</dc:creator>
 <dc:creator>Lin, Hongbin</dc:creator>
 <dc:creator>Huang, Zhengjie</dc:creator>
 <dc:creator>Kuang, Wenwei</dc:creator>
 <dc:creator>Harada, Kensuke</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Robotic failure is all too common in unstructured robot tasks. Despite
well-designed controllers, robots often fail due to unexpected events. How do
robots measure unexpected events? Many do not. Most robots are driven by the
sense-plan act paradigm, however more recently robots are undergoing a
sense-plan-act-verify paradigm. In this work, we present a principled
methodology to bootstrap online robot introspection for contact tasks. In
effect, we are trying to enable the robot to answer the question: what did I
do? Is my behavior as expected or not? To this end, we analyze noisy wrench
data and postulate that the latter inherently contains patterns that can be
effectively represented by a vocabulary. The vocabulary is generated by
segmenting and encoding the data. When the wrench information represents a
sequence of sub-tasks, we can think of the vocabulary forming a sentence (set
of words with grammar rules) for a given sub-task; allowing the latter to be
uniquely represented. The grammar, which can also include unexpected events,
was classified in offline and online scenarios as well as for simulated and
real robot experiments. Multiclass Support Vector Machines (SVMs) were used
offline, while online probabilistic SVMs were are used to give temporal
confidence to the introspection result. The contribution of our work is the
presentation of a generalizable online semantic scheme that enables a robot to
understand its high-level state whether nominal or abnormal. It is shown to
work in offline and online scenarios for a particularly challenging contact
task: snap assemblies. We perform the snap assembly in one-arm simulated and
real one-arm experiments and a simulated two-arm experiment. This verification
mechanism can be used by high-level planners or reasoning systems to enable
intelligent failure recovery or determine the next most optima manipulation
skill to be used.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1609.04947</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-07-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08695</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2017.8206438</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08699</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>II-FCN for skin lesion analysis towards melanoma detection</dc:title>
 <dc:creator>Wen, Hongdiao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Dermoscopy image detection stays a tough task due to the weak distinguishable
property of the object.Although the deep convolution neural network
signifigantly boosted the performance on prevelance computer vision tasks in
recent years,there remains a room to explore more robust and precise models to
the problem of low contrast image segmentation.Towards the challenge of Lesion
Segmentation in ISBI 2017,we built a symmetrical identity inception fully
convolution network which is based on only 10 reversible inception blocks,every
block composed of four convolution branches with combination of different layer
depth and kernel size to extract sundry semantic features.Then we proposed an
approximate loss function for jaccard index metrics to train our model.To
overcome the drawbacks of traditional convolution,we adopted the dilation
convolution and conditional random field method to rectify our segmentation.We
also introduced multiple ways to prevent the problem of overfitting.The
experimental results shows that our model achived jaccard index of 0.82 and
kept learning from epoch to epoch.
</dc:description>
 <dc:description>Comment: 4 page abstract about our solution to the challenge of Lesion
  Segmentation in ISIC2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08701</identifier>
 <datestamp>2017-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning rates for classification with Gaussian kernels</dc:title>
 <dc:creator>Lin, Shao-Bo</dc:creator>
 <dc:creator>Zeng, Jinshan</dc:creator>
 <dc:creator>Chang, Xiangyu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper aims at refined error analysis for binary classification using
support vector machine (SVM) with Gaussian kernel and convex loss. Our first
result shows that for some loss functions such as the truncated quadratic loss
and quadratic loss, SVM with Gaussian kernel can reach the almost optimal
learning rate, provided the regression function is smooth. Our second result
shows that, for a large number of loss functions, under some Tsybakov noise
assumption, if the regression function is infinitely smooth, then SVM with
Gaussian kernel can achieve the learning rate of order $m^{-1}$, where $m$ is
the number of samples.
</dc:description>
 <dc:description>Comment: This paper has been accepted by Neural Computation</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-10-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08701</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08703</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Widely-Linear Precoding for Large-Scale MIMO with IQI: Algorithms and
  Performance Analysis</dc:title>
 <dc:creator>Zhang, Wence</dc:creator>
 <dc:creator>de Lamare, Rodrigo C.</dc:creator>
 <dc:creator>Pan, Cunhua</dc:creator>
 <dc:creator>Chen, Ming</dc:creator>
 <dc:creator>Dai, Jianxin</dc:creator>
 <dc:creator>Wu, Bingyang</dc:creator>
 <dc:creator>Bao, Xu</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we study widely-linear precoding techniques to mitigate
in-phase/quadrature-phase (IQ) imbalance (IQI) in the downlink of large-scale
multiple-input multiple-output (MIMO) systems. We adopt a real-valued signal
model which takes into account the IQI at the transmitter and then develop
widely-linear zero-forcing (WL-ZF), widely-linear matched filter (WL-MF),
widely-linear minimum mean-squared error (WL-MMSE) and widely-linear
block-diagonalization (WL-BD) type precoding algorithms for both {\color{red}
single- and multiple-antenna users.} We also present a performance analysis of
WL-ZF and WL-BD. It is proved that without IQI, WL-ZF has exactly the same
multiplexing gain and power offset as ZF, while when IQI exists, WL-ZF achieves
the same multiplexing gain as ZF with ideal IQ branches, but with a minor power
loss which is related to the system scale and the IQ parameters. We also
compare the performance of WL-BD with BD. The analysis shows that with ideal IQ
branches, WL-BD has the same data rate as BD, while when IQI exists, WL-BD
achieves the same multiplexing gain as BD without IQ imbalance. Numerical
results verify the analysis and show that the proposed widely-linear type
precoding methods significantly outperform their conventional counterparts with
IQI and approach those with ideal IQ branches.
</dc:description>
 <dc:description>Comment: Accepted in IEEE TWC</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08712</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithmic stability and hypothesis complexity</dc:title>
 <dc:creator>Liu, Tongliang</dc:creator>
 <dc:creator>Lugosi, G&#xe1;bor</dc:creator>
 <dc:creator>Neu, Gergely</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a notion of algorithmic stability of learning algorithms---that
we term \emph{argument stability}---that captures stability of the hypothesis
output by the learning algorithm in the normed space of functions from which
hypotheses are selected. The main result of the paper bounds the generalization
error of any learning algorithm in terms of its argument stability. The bounds
are based on martingale inequalities in the Banach space to which the
hypotheses belong. We apply the general bounds to bound the performance of some
learning algorithms based on empirical risk minimization and stochastic
gradient descent.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08712</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08715</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Building a Completely Reversible Computer</dc:title>
 <dc:creator>Lukac, Martin</dc:creator>
 <dc:creator>Dueck, Gerhard W.</dc:creator>
 <dc:creator>Kameyama, Michitaka</dc:creator>
 <dc:creator>Pathak, Anirban</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A critical analysis of the feasibility of reversible computing is performed.
The key question is: Is it possible to build a completely reversible computer?
A closer look into the internal aspects of the reversible computing as well as
the external constraints such as the second law of thermodynamics has
demonstrated that several difficulties would have to be solved before
reversible computer is being built. It is shown that a conventional reversible
computer would require energy for setting up the reversible inputs from
irreversible signals, for the reading out of the reversible outputs, for the
transport of the information between logic elements and finally for the control
signals that will require more energy dissipating into the environment. A loose
bound on the minimum amount of energy required to be dissipated during the
physical implementation of a reversible computer is obtained and a
generalization of the principles for reversible computing is provided.
</dc:description>
 <dc:description>Comment: 15 pages, 8 figures, 2 tables</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08716</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Relationship between $k$-Planar and $k$-Quasi Planar Graphs</dc:title>
 <dc:creator>Angelini, Patrizio</dc:creator>
 <dc:creator>Bekos, Michael A.</dc:creator>
 <dc:creator>Brandenburg, Franz J.</dc:creator>
 <dc:creator>Da Lozzo, Giordano</dc:creator>
 <dc:creator>Di Battista, Giuseppe</dc:creator>
 <dc:creator>Didimo, Walter</dc:creator>
 <dc:creator>Liotta, Giuseppe</dc:creator>
 <dc:creator>Montecchiani, Fabrizio</dc:creator>
 <dc:creator>Rutter, Ignaz</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  A graph is $k$-planar $(k \geq 1)$ if it can be drawn in the plane such that
no edge is crossed more than $k$ times. A graph is $k$-quasi planar $(k \geq
2)$ if it can be drawn in the plane with no $k$ pairwise crossing edges. The
families of $k$-planar and $k$-quasi planar graphs have been widely studied in
the literature, and several bounds have been proven on their edge density.
Nonetheless, only trivial results are known about the relationship between
these two graph families. In this paper we prove that, for $k \geq 3$, every
$k$-planar graph is $(k+1)$-quasi planar.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08717</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Extensive Technique to Detect and Analyze Melanoma: A Challenge at
  the International Symposium on Biomedical Imaging (ISBI) 2017</dc:title>
 <dc:creator>Jiji, G Wiselin</dc:creator>
 <dc:creator>Raj, P Johnson Durai</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  An automated method to detect and analyze the melanoma is presented to
improve diagnosis which will leads to the exact treatment. Image processing
techniques such as segmentation, feature descriptors and classification models
are involved in this method. In the First phase the lesion region is segmented
using CIELAB Color space Based Segmentation. Then feature descriptors such as
shape, color and texture are extracted. Finally, in the third phase lesion
region is classified as melanoma, seborrheic keratosis or nevus using multi
class O-A SVM model. Experiment with ISIC 2017 Archive skin image database has
been done and analyzed the results.
</dc:description>
 <dc:description>Comment: 4 Page Abstract for ISIC2017 Challenge</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08717</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08719</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Malware Guard Extension: Using SGX to Conceal Cache Attacks</dc:title>
 <dc:creator>Schwarz, Michael</dc:creator>
 <dc:creator>Weiser, Samuel</dc:creator>
 <dc:creator>Gruss, Daniel</dc:creator>
 <dc:creator>Maurice, Cl&#xe9;mentine</dc:creator>
 <dc:creator>Mangard, Stefan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In modern computer systems, user processes are isolated from each other by
the operating system and the hardware. Additionally, in a cloud scenario it is
crucial that the hypervisor isolates tenants from other tenants that are
co-located on the same physical machine. However, the hypervisor does not
protect tenants against the cloud provider and thus the supplied operating
system and hardware. Intel SGX provides a mechanism that addresses this
scenario. It aims at protecting user-level software from attacks from other
processes, the operating system, and even physical attackers.
  In this paper, we demonstrate fine-grained software-based side-channel
attacks from a malicious SGX enclave targeting co-located enclaves. Our attack
is the first malware running on real SGX hardware, abusing SGX protection
features to conceal itself. Furthermore, we demonstrate our attack both in a
native environment and across multiple Docker containers. We perform a
Prime+Probe cache side-channel attack on a co-located SGX enclave running an
up-to-date RSA implementation that uses a constant-time multiplication
primitive. The attack works although in SGX enclaves there are no timers, no
large pages, no physical addresses, and no shared memory. In a semi-synchronous
attack, we extract 96% of an RSA private key from a single trace. We extract
the full RSA private key in an automated attack from 11 traces within 5
minutes.
</dc:description>
 <dc:description>Comment: Extended version of DIMVA 2017 submission</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08720</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Discrete Representations via Information Maximizing
  Self-Augmented Training</dc:title>
 <dc:creator>Hu, Weihua</dc:creator>
 <dc:creator>Miyato, Takeru</dc:creator>
 <dc:creator>Tokui, Seiya</dc:creator>
 <dc:creator>Matsumoto, Eiichi</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning discrete representations of data is a central machine learning task
because of the compactness of the representations and ease of interpretation.
The task includes clustering and hash learning as special cases. Deep neural
networks are promising to be used because they can model the non-linearity of
data and scale to large datasets. However, their model complexity is huge, and
therefore, we need to carefully regularize the networks in order to learn
useful representations that exhibit intended invariance for applications of
interest. To this end, we propose a method called Information Maximizing
Self-Augmented Training (IMSAT). In IMSAT, we use data augmentation to impose
the invariance on discrete representations. More specifically, we encourage the
predicted representations of augmented data points to be close to those of the
original data points in an end-to-end fashion. At the same time, we maximize
the information-theoretic dependency between data and their predicted discrete
representations. Extensive experiments on benchmark datasets show that IMSAT
produces state-of-the-art results for both clustering and unsupervised hash
learning.
</dc:description>
 <dc:description>Comment: To appear at ICML 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08720</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08725</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Verification under Model Uncertainty</dc:title>
 <dc:creator>Belzner, Lenz</dc:creator>
 <dc:creator>Gabor, Thomas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Machine learning enables systems to build and update domain models based on
runtime observations. In this paper, we study statistical model checking and
runtime verification for systems with this ability. Two challenges arise: (1)
Models built from limited runtime data yield uncertainty to be dealt with. (2)
There is no definition of satisfaction w.r.t. uncertain hypotheses. We propose
such a definition of subjective satisfaction based on recently introduced
satisfaction functions. We also propose the BV algorithm as a Bayesian solution
to runtime verification of subjective satisfaction under model uncertainty. BV
provides user-definable stochastic bounds for type I and II errors. We discuss
empirical results from an example application to illustrate our ideas.
</dc:description>
 <dc:description>Comment: Accepted at SEsCPS @ ICSE 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08726</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stacked Thompson Bandits</dc:title>
 <dc:creator>Belzner, Lenz</dc:creator>
 <dc:creator>Gabor, Thomas</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We introduce Stacked Thompson Bandits (STB) for efficiently generating plans
that are likely to satisfy a given bounded temporal logic requirement. STB uses
a simulation for evaluation of plans, and takes a Bayesian approach to using
the resulting information to guide its search. In particular, we show that
stacking multiarmed bandits and using Thompson sampling to guide the action
selection process for each bandit enables STB to generate plans that satisfy
requirements with a high probability while only searching a fraction of the
search space.
</dc:description>
 <dc:description>Comment: Accepted at SEsCPS @ ICSE 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08727</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving the Neural GPU Architecture for Algorithm Learning</dc:title>
 <dc:creator>Freivalds, Karlis</dc:creator>
 <dc:creator>Liepins, Renars</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Algorithm learning is a core problem in artificial intelligence with
significant implications on automation level that can be achieved by machines.
Recently deep learning methods are emerging for synthesizing an algorithm from
its input-output examples, the most successful being the Neural GPU, capable of
learning multiplication. We present several improvements to the Neural GPU that
substantially reduces training time and improves generalization. We introduce a
technique of general applicability to use hard nonlinearities with saturation
cost. We also introduce a technique of diagonal gates that can be applied to
active-memory models. The proposed architecture is the first capable of
learning decimal multiplication end-to-end.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08734</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Billion-scale similarity search with GPUs</dc:title>
 <dc:creator>Johnson, Jeff</dc:creator>
 <dc:creator>Douze, Matthijs</dc:creator>
 <dc:creator>J&#xe9;gou, Herv&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Similarity search finds application in specialized database systems handling
complex data such as images or videos, which are typically represented by
high-dimensional features and require specific indexing structures. This paper
tackles the problem of better utilizing GPUs for this task. While GPUs excel at
data-parallel tasks, prior approaches are bottlenecked by algorithms that
expose less parallelism, such as k-min selection, or make poor use of the
memory hierarchy.
  We propose a design for k-selection that operates at up to 55% of theoretical
peak performance, enabling a nearest neighbor implementation that is 8.5x
faster than prior GPU state of the art. We apply it in different similarity
search scenarios, by proposing optimized design for brute-force, approximate
and compressed-domain search based on product quantization. In all these
setups, we outperform the state of the art by large margins. Our implementation
enables the construction of a high accuracy k-NN graph on 95 million images
from the Yfcc100M dataset in 35 minutes, and of a graph connecting 1 billion
vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced
our approach for the sake of comparison and reproducibility.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08736</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysing Congestion Problems in Multi-agent Reinforcement Learning</dc:title>
 <dc:creator>R&#x103;dulescu, Roxana</dc:creator>
 <dc:creator>Vrancx, Peter</dc:creator>
 <dc:creator>Now&#xe9;, Ann</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T05</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  Congestion problems are omnipresent in today's complex networks and represent
a challenge in many research domains. In the context of Multi-agent
Reinforcement Learning (MARL), approaches like difference rewards and resource
abstraction have shown promising results in tackling such problems. Resource
abstraction was shown to be an ideal candidate for solving large-scale resource
allocation problems in a fully decentralized manner. However, its performance
and applicability strongly depends on some, until now, undocumented
assumptions. Two of the main congestion benchmark problems considered in the
literature are: the Beach Problem Domain and the Traffic Lane Domain. In both
settings the highest system utility is achieved when overcrowding one resource
and keeping the rest at optimum capacity. We analyse how abstract grouping can
promote this behaviour and how feasible it is to apply this approach in a
real-world domain (i.e., what assumptions need to be satisfied and what
knowledge is necessary). We introduce a new test problem, the Road Network
Domain (RND), where the resources are no longer independent, but rather part of
a network (e.g., road network), thus choosing one path will also impact the
load on other paths having common road segments. We demonstrate the application
of state-of-the-art MARL methods for this new congestion model and analyse
their performance. RND allows us to highlight an important limitation of
resource abstraction and show that the difference rewards approach manages to
better capture and inform the agents about the dynamics of the environment.
</dc:description>
 <dc:description>Comment: Adaptive Learning Agents (ALA) Workshop at AAMAS 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08736</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08740</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly- and Semi-Supervised Object Detection with
  Expectation-Maximization Algorithm</dc:title>
 <dc:creator>Yan, Ziang</dc:creator>
 <dc:creator>Liang, Jian</dc:creator>
 <dc:creator>Pan, Weishen</dc:creator>
 <dc:creator>Li, Jin</dc:creator>
 <dc:creator>Zhang, Changshui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection when provided image-level labels instead of instance-level
labels (i.e., bounding boxes) during training is an important problem in
computer vision, since large scale image datasets with instance-level labels
are extremely costly to obtain. In this paper, we address this challenging
problem by developing an Expectation-Maximization (EM) based object detection
method using deep convolutional neural networks (CNNs). Our method is
applicable to both the weakly-supervised and semi-supervised settings.
Extensive experiments on PASCAL VOC 2007 benchmark show that (1) in the weakly
supervised setting, our method provides significant detection performance
improvement over current state-of-the-art methods, (2) having access to a small
number of strongly (instance-level) annotated images, our method can almost
match the performace of the fully supervised Fast RCNN. We share our source
code at https://github.com/ZiangYan/EM-WSD.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08741</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extension complexity of stable set polytopes of bipartite graphs</dc:title>
 <dc:creator>Aprile, Manuel</dc:creator>
 <dc:creator>Faenza, Yuri</dc:creator>
 <dc:creator>Fiorini, Samuel</dc:creator>
 <dc:creator>Huynh, Tony</dc:creator>
 <dc:creator>Macchia, Marco</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05Cxx</dc:subject>
 <dc:description>  The extension complexity $\mathsf{xc}(P)$ of a polytope $P$ is the minimum
number of facets of a polytope that affinely projects to $P$. Let $G$ be a
bipartite graph with $n$ vertices, $m$ edges, and no isolated vertices. Let
$\mathsf{STAB}(G)$ be the convex hull of the stable sets of $G$. It is easy to
see that $n \leqslant \mathsf{xc} (\mathsf{STAB}(G)) \leqslant n+m$. We improve
both of these bounds. For the upper bound, we show that $\mathsf{xc}
(\mathsf{STAB}(G))$ is $O(\frac{n^2}{\log n})$, which is an improvement when
$G$ has quadratically many edges. For the lower bound, we prove that
$\mathsf{xc} (\mathsf{STAB}(G))$ is $\Omega(n \log n)$ when $G$ is the
incidence graph of a finite projective plane. We also provide examples of
$3$-regular bipartite graphs $G$ such that the edge vs stable set matrix of $G$
has a fooling set of size $|E(G)|$.
</dc:description>
 <dc:description>Comment: 13 pages, 2 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08741</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08742</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Bipedal Locomotion Control Based on Model Predictive Control and
  Divergent Component of Motion</dc:title>
 <dc:creator>Shafiee-Ashtiani, Milad</dc:creator>
 <dc:creator>Yousefi-Koma, Aghil</dc:creator>
 <dc:creator>Shariat-Panahi, Masoud</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, previous works on the Model Predictive Control (MPC) and the
Divergent Component of Motion (DCM) for bipedal walking control are extended.
To this end, we employ a single MPC which uses a combination of Center of
Pressure (CoP) manipulation, step adjustment, and Centroidal Moment Pivot (CMP)
modulation to design a robust walking controller. Furthermore, we exploit the
concept of time-varying DCM to generalize our walking controller for walking in
uneven surfaces. Using our scheme, a general and robust walking controller is
designed which can be implemented on robots with different control authorities,
for walking on various environments, e.g. uneven terrains or surfaces with a
very limited feasible area for stepping. The effectiveness of the proposed
approach is verified through simulations on different scenarios and comparison
to the state of the art.
</dc:description>
 <dc:description>Comment: This work has been accepted for publication at the IEEE ICRA 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08745</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Categorical Attribute Transformation for Granularity Change in
  Relational Databases for Binary Decision Problems in Educational Data Mining</dc:title>
 <dc:creator>Adeodato, Paulo J. L.</dc:creator>
 <dc:creator>Pereira, F&#xe1;bio C.</dc:creator>
 <dc:creator>Neto, Rosalvo F. Oliveira</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>J.1</dc:subject>
 <dc:description>  This paper presents an approach for transforming data granularity in
hierarchical databases for binary decision problems by applying regression to
categorical attributes at the lower grain levels. Attributes from a lower
hierarchy entity in the relational database have their information content
optimized through regression on the categories histogram trained on a small
exclusive labelled sample, instead of the usual mode category of the
distribution. The paper validates the approach on a binary decision task for
assessing the quality of secondary schools focusing on how logistic regression
transforms the students and teachers attributes into school attributes.
Experiments were carried out on Brazilian schools public datasets via 10-fold
cross-validation comparison of the ranking score produced also by logistic
regression. The proposed approach achieved higher performance than the usual
distribution mode transformation and equal to the expert weighing approach
measured by the maximum Kolmogorov-Smirnov distance and the area under the ROC
curve at 0.01 significance level.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08764</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Answering FO+MOD queries under updates on bounded degree databases</dc:title>
 <dc:creator>Berkholz, Christoph</dc:creator>
 <dc:creator>Keppeler, Jens</dc:creator>
 <dc:creator>Schweikardt, Nicole</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We investigate the query evaluation problem for fixed queries over fully
dynamic databases, where tuples can be inserted or deleted. The task is to
design a dynamic algorithm that immediately reports the new result of a fixed
query after every database update. We consider queries in first-order logic
(FO) and its extension with modulo-counting quantifiers (FO+MOD), and show that
they can be efficiently evaluated under updates, provided that the dynamic
database does not exceed a certain degree bound.
  In particular, we construct a data structure that allows to answer a Boolean
FO+MOD query and to compute the size of the result of a non-Boolean query
within constant time after every database update. Furthermore, after every
update we are able to immediately enumerate the new query result with constant
delay between the output tuples. The time needed to build the data structure is
linear in the size of the database. Our results extend earlier work on the
evaluation of first-order queries on static databases of bounded degree and
rely on an effective Hanf normal form for FO+MOD recently obtained by Heimberg,
Kuske, and Schweikardt (LICS 2016).
</dc:description>
 <dc:description>Comment: This is the full version of a paper with the same title that will be
  published in the Proceedings of the 20th International Conference on Database
  Theory (ICDT 2017)</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08780</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MILD: Multi-Index hashing for Loop closure Detection</dc:title>
 <dc:creator>Han, Lei</dc:creator>
 <dc:creator>Fang, Lu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Loop Closure Detection (LCD) has been proved to be extremely useful in global
consistent visual Simultaneously Localization and Mapping (SLAM) and
appearance-based robot relocalization. Methods exploiting binary features in
bag of words representation have recently gained a lot of popularity for their
efficiency, but suffer from low recall due to the inherent drawback that high
dimensional binary feature descriptors lack well-defined centroids. In this
paper, we propose a realtime LCD approach called MILD (Multi-Index Hashing for
Loop closure Detection), in which image similarity is measured by feature
matching directly to achieve high recall without introducing extra
computational complexity with the aid of Multi-Index Hashing (MIH). A
theoretical analysis of the approximate image similarity measurement using MIH
is presented, which reveals the trade-off between efficiency and accuracy from
a probabilistic perspective. Extensive comparisons with state-of-the-art LCD
methods demonstrate the superiority of MILD in both efficiency and accuracy.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures; accepted by IEEE ICME 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08782</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ShaResNet: reducing residual network parameter number by sharing weights</dc:title>
 <dc:creator>Boulch, Alexandre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>68T05, 68T45</dc:subject>
 <dc:subject>C.1.3</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  Deep Residual Networks have reached the state of the art in many image
processing tasks such image classification. However, the cost for a gain in
accuracy in terms of depth and memory is prohibitive as it requires a higher
number of residual blocks, up to double the initial value. To tackle this
problem, we propose in this paper a way to reduce the redundant information of
the networks. We share the weights of convolutional layers between residual
blocks operating at the same spatial scale. The signal flows multiple times in
the same convolutional layer. The resulting architecture, called ShaResNet,
contains block specific layers and shared layers. These ShaResNet are trained
exactly in the same fashion as the commonly used residual networks. We show, on
the one hand, that they are almost as efficient as their sequential
counterparts while involving less parameters, and on the other hand that they
are more efficient than a residual network with the same number of parameters.
For example, a 152-layer-deep residual network can be reduced to 106
convolutional layers, i.e. a parameter gain of 39\%, while loosing less than
0.2\% accuracy on ImageNet.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08783</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NOMA Meets Finite Resolution Analog Beamforming in Massive MIMO and
  Millimeter-Wave Networks</dc:title>
 <dc:creator>Ding, Zhiguo</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Finite resolution analog beamforming (FRAB) has been recognized as an
effective approach to reduce hardware costs in massive multiple-input
multiple-output (MIMO) and millimeter-wave networks. However, the use of FRAB
means that the beamformers are not perfectly aligned with the users' channels
and multiple users may be assigned similar or even identifical beamformers.
This letter shows how non-orthogonal multiple access (NOMA) can be used to
exploit this feature of FRAB, where a single FRAB based beamformer is shared by
multiple users. Both analytical and simulation results are provided to
demonstrate the excellent performance achieved by this new NOMA transmission
scheme.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08783</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08789</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nash and Wardrop equilibria in aggregative games with coupling
  constraints</dc:title>
 <dc:creator>Gentile, Basilio</dc:creator>
 <dc:creator>Parise, Francesca</dc:creator>
 <dc:creator>Paccagnan, Dario</dc:creator>
 <dc:creator>Kamgarpour, Maryam</dc:creator>
 <dc:creator>Lygeros, John</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider the framework of aggregative games, in which the cost function of
each agent depends on his own strategy and on the average population strategy.
As first contribution, we investigate the relations between the concepts of
Nash and Wardrop equilibrium. By exploiting a characterization of the two
equilibria as solutions of variational inequalities, we bound their distance
with a decreasing function of the population size. As second contribution, we
propose two decentralized algorithms that converge to such equilibria and are
capable of coping with constraints coupling the strategies of different agents.
Finally, we study the applications of charging of electric vehicles and of
route choice on a road network.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08789</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08791</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Budget Allocation via Continuous Submodular Functions</dc:title>
 <dc:creator>Staib, Matthew</dc:creator>
 <dc:creator>Jegelka, Stefanie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The optimal allocation of resources for maximizing influence, spread of
information or coverage, has gained attention in the past years, in particular
in machine learning and data mining. But in applications, the parameters of the
problem are rarely known exactly, and using wrong parameters can lead to
undesirable outcomes. We hence revisit a continuous version of the Budget
Allocation or Bipartite Influence Maximization problem introduced by Alon et
al. (2012) from a robust optimization perspective, where an adversary may
choose the least favorable parameters within a confidence set. The resulting
problem is a nonconvex-concave saddle point problem (or game). We show that
this nonconvex problem can be solved exactly by leveraging connections to
continuous submodular functions, and by solving a constrained submodular
minimization problem. Although constrained submodular minimization is hard in
general, here, we establish conditions under which such a problem can be solved
to arbitrary precision $\epsilon$.
</dc:description>
 <dc:description>Comment: ICML 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08794</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lowest Unique Bid Auctions with Resubmission Opportunities</dc:title>
 <dc:creator>Xu, Yida</dc:creator>
 <dc:creator>Tembine, Hamidou</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The recent online platforms propose multiple items for bidding. The state of
the art, however, is limited to the analysis of one item auction without
resubmission. In this paper we study multi-item lowest unique bid auctions
(LUBA) with resubmission in discrete bid spaces under budget constraints. We
show that the game does not have pure Bayes-Nash equilibria (except in very
special cases). However, at least one mixed Bayes-Nash equilibria exists for
arbitrary number of bidders and items. The equilibrium is explicitly computed
for two-bidder setup with resubmission possibilities. In the general setting we
propose a distributed strategic learning algorithm to approximate equilibria.
Computer simulations indicate that the error quickly decays in few number of
steps. When the number of bidders per item follows a Poisson distribution, it
is shown that the seller can get a non-negligible revenue on several items, and
hence making a partial revelation of the true value of the items. Finally, the
attitude of the bidders towards the risk is considered. In contrast to
risk-neutral agents who bids very small values, the cumulative distribution and
the bidding support of risk-sensitive agents are more distributed.
</dc:description>
 <dc:description>Comment: 47 pages, 13 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08798</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Triplet Hashing for Fast Image Retrieval</dc:title>
 <dc:creator>Huang, Shanshan</dc:creator>
 <dc:creator>Xiong, Yichao</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Wang, Jia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Hashing has played a pivotal role in large-scale image retrieval. With the
development of Convolutional Neural Network (CNN), hashing learning has shown
great promise. But existing methods are mostly tuned for classification, which
are not optimized for retrieval tasks, especially for instance-level retrieval.
In this study, we propose a novel hashing method for large-scale image
retrieval. Considering the difficulty in obtaining labeled datasets for image
retrieval task in large scale, we propose a novel CNN-based unsupervised
hashing method, namely Unsupervised Triplet Hashing (UTH). The unsupervised
hashing network is designed under the following three principles: 1) more
discriminative representations for image retrieval; 2) minimum quantization
loss between the original real-valued feature descriptors and the learned hash
codes; 3) maximum information entropy for the learned hash codes. Extensive
experiments on CIFAR-10, MNIST and In-shop datasets have shown that UTH
outperforms several state-of-the-art unsupervised hashing methods in terms of
retrieval accuracy.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08800</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Jamming-Resistant Receivers for the Massive MIMO Uplink</dc:title>
 <dc:creator>Do, Tan Tai</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Razavizadeh, S. Mohammad</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We design a jamming-resistant receiver scheme to enhance the robustness of a
massive MIMO uplink system against jamming. We assume that a jammer attacks the
system both in the pilot and data transmission phases. The key feature of the
proposed scheme is that, in the pilot phase, we estimate not only the
legitimate channel, but also the jamming channel by exploiting a purposely
unused pilot sequence. The jamming channel estimate is used to constructed
linear receive filters that reject the impact of the jamming signal. The
performance of the proposed scheme is analytically evaluated using asymptotic
properties of massive MIMO. The optimal regularized zero-forcing receiver and
the optimal power allocation are also studied. Numerical results are provided
to verify our analysis and show that the proposed scheme greatly improves the
achievable rates, as compared to conventional receivers. Interestingly, the
proposed scheme works particularly well under strong jamming attacks, since the
improved estimate of the jamming channel outweighs the extra jamming power.
</dc:description>
 <dc:description>Comment: submitted to IEEE Trans. Inf. Forensics and Security</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08811</identifier>
 <datestamp>2017-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Central Moment Discrepancy (CMD) for Domain-Invariant Representation
  Learning</dc:title>
 <dc:creator>Zellinger, Werner</dc:creator>
 <dc:creator>Grubinger, Thomas</dc:creator>
 <dc:creator>Lughofer, Edwin</dc:creator>
 <dc:creator>Natschl&#xe4;ger, Thomas</dc:creator>
 <dc:creator>Saminger-Platz, Susanne</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The learning of domain-invariant representations in the context of domain
adaptation with neural networks is considered. We propose a new regularization
method that minimizes the discrepancy between domain-specific latent feature
representations directly in the hidden activation space. Although some standard
distribution matching approaches exist that can be interpreted as the matching
of weighted sums of moments, e.g. Maximum Mean Discrepancy (MMD), an explicit
order-wise matching of higher order moments has not been considered before. We
propose to match the higher order central moments of probability distributions
by means of order-wise moment differences. Our model does not require
computationally expensive distance and kernel matrix computations. We utilize
the equivalent representation of probability distributions by moment sequences
to define a new distance function, called Central Moment Discrepancy (CMD). We
prove that CMD is a metric on the set of probability distributions on a compact
interval. We further prove that convergence of probability distributions on
compact intervals w.r.t. the new metric implies convergence in distribution of
the respective random variables. We test our approach on two different
benchmark data sets for object recognition (Office) and sentiment analysis of
product reviews (Amazon reviews). CMD achieves a new state-of-the-art
performance on most domain adaptation tasks of Office and outperforms networks
trained with MMD, Variational Fair Autoencoders and Domain Adversarial Neural
Networks on Amazon reviews. In addition, a post-hoc parameter sensitivity
analysis shows that the new approach is stable w.r.t. parameter changes in a
certain interval. The source code of the experiments is publicly available.
</dc:description>
 <dc:description>Comment: Published in ICLR 2017 (conference track)</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-07-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08813</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fixed-point Based Hierarchical MPC Control Design For a Cryogenic
  Refrigerator</dc:title>
 <dc:creator>Alamir, M.</dc:creator>
 <dc:creator>Bonnay, P.</dc:creator>
 <dc:creator>Bonne, F.</dc:creator>
 <dc:creator>Trinh, V. V.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper, a simple and general hierarchical control framework is
proposed and validated through the interconnection of the Joule-Thompson and
the Brayton cycle stages of a cryogenic refrigerator. The proposed framework
enables to handle the case of destabilizing interconnections through state
and/or control signals (which is the case of the cryogenic refrigerator
example). Moreover, it offers the possibility to simply change the behavior of
the overall system (depending on the context) by only changing the coordinator
problem's parameters without changing the set of local controllers used by
subsystems which is a common industrial requirement regarding industrial
control architectures. Finally, the proposed scheme enables a smooth operator
handover on a specific subsystem and/or actuator.
</dc:description>
 <dc:description>Comment: 28 pages, 10 figures, to be submitted to Journal of Process Control</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08817</identifier>
 <datestamp>2017-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-enhancing Aggregation of Internet of Things Data via Sensors
  Grouping</dc:title>
 <dc:creator>Bennati, Stefano</dc:creator>
 <dc:creator>Pournaras, Evangelos</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Big data collection practices using Internet of Things (IoT) pervasive
technologies are often privacy-intrusive and result in surveillance, profiling,
and discriminatory actions over citizens that in turn undermine the
participation of citizens to the development of sustainable smart cities.
Nevertheless, real-time data analytics and aggregate information from IoT
devices open up tremendous opportunities for managing smart city
infrastructures. The privacy-enhancing aggregation of distributed sensor data,
such as residential energy consumption or traffic information, is the research
focus of this paper. Citizens have the option to choose their privacy level by
reducing the quality of the shared data at a cost of a lower accuracy in data
analytics services. A baseline scenario is considered in which IoT sensor data
are shared directly with an untrustworthy central aggregator. A grouping
mechanism is introduced that improves privacy by sharing data aggregated first
at a group level compared as opposed to sharing data directly to the central
aggregator. Group-level aggregation obfuscates sensor data of individuals, in a
similar fashion as differential privacy and homomorphic encryption schemes,
thus inference of privacy-sensitive information from single sensors becomes
computationally harder compared to the baseline scenario. The proposed system
is evaluated using real-world data from two smart city pilot projects. Privacy
under grouping increases, while preserving the accuracy of the baseline
scenario. Intra-group influences of privacy by one group member on the other
ones are measured and fairness on privacy is found to be maximized between
group members with similar privacy choices. Several grouping strategies are
compared. Grouping by proximity of privacy choices provides the highest privacy
gains. The implications of the strategy on the design of incentives mechanisms
are discussed.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-12-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08817</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08819</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Temperature Control via Geothermal Heat Pump Systems in
  Energy Efficient Buildings</dc:title>
 <dc:creator>Zhang, Xuan</dc:creator>
 <dc:creator>Shi, Wenbo</dc:creator>
 <dc:creator>Hu, Qinran</dc:creator>
 <dc:creator>Yan, Bin</dc:creator>
 <dc:creator>Malkawi, Ali</dc:creator>
 <dc:creator>Li, Na</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Geothermal Heat Pump (GHP) systems are heating and cooling systems that use
the ground as the temperature exchange medium. GHP systems are becoming more
and more popular in recent years due to their high efficiency. Conventional
control schemes of GHP systems are mainly designed for buildings with a single
thermal zone. For large buildings with multiple thermal zones, those control
schemes either lose efficiency or become costly to implement requiring a lot of
real-time measurement, communication and computation. In this paper, we focus
on developing energy efficient control schemes for GHP systems in buildings
with multiple zones. We present a thermal dynamic model of a building equipped
with a GHP system for floor heating/cooling and formulate the GHP system
control problem as a resource allocation problem with the objective to maximize
user comfort in different zones and to minimize the building energy
consumption. We then propose real-time distributed algorithms to solve the
control problem. Our distributed multi-zone control algorithms are scalable and
do not need to measure or predict any exogenous disturbances such as the
outdoor temperature and indoor heat gains. Thus, it is easy to implement them
in practice. Simulation results demonstrate the effectiveness of the proposed
control schemes.
</dc:description>
 <dc:description>Comment: 8 pages, 10 figures, in Proc. of 2017 American Control Conference,
  the long version. arXiv admin note: text overlap with arXiv:1702.03308</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08826</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Perspectives on Collecting Human Uncertainty in Predictive
  Data Mining</dc:title>
 <dc:creator>Jasberg, Kevin</dc:creator>
 <dc:creator>Sizov, Sergej</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In many areas of data mining, data is collected from humans beings. In this
contribution, we ask the question of how people actually respond to ordinal
scales. The main problem observed is that users tend to be volatile in their
choices, i.e. complex cognitions do not always lead to the same decisions, but
to distributions of possible decision outputs. This human uncertainty may
sometimes have quite an impact on common data mining approaches and thus, the
question of effective modelling this so called human uncertainty emerges
naturally.
  Our contribution introduces two different approaches for modelling the human
uncertainty of user responses. In doing so, we develop techniques in order to
measure this uncertainty at the level of user inputs as well as the level of
user cognition. With support of comprehensive user experiments and large-scale
simulations, we systematically compare both methodologies along with their
implications for personalisation approaches. Our findings demonstrate that
significant amounts of users do submit something completely different (action)
than they really have in mind (cognition). Moreover, we demonstrate that
statistically sound evidence with respect to algorithm assessment becomes quite
hard to realise, especially when explicit rankings shall be built.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08826</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08827</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Little Less Interaction, A Little More Action: A Modular Framework for
  Network Troubleshooting</dc:title>
 <dc:creator>Pelle, Istv&#xe1;n</dc:creator>
 <dc:creator>N&#xe9;meth, Felici&#xe1;n</dc:creator>
 <dc:creator>Guly&#xe1;s, Andr&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An ideal network troubleshooting system would be an almost fully automated
system, monitoring the whole network at once, feeding the results to a
knowledge-based decision making system that suggests actions to the operator or
corrects the failure automatically. Reality is quite the contrary: operators
separated in their offices try to track down complex networking failures in
their own way, which is generally a long sequence of manually edited parallel
shell commands (mostly ping, traceroute, route, iperf, ofctl etc.). This
process requires operators to be &quot;masters of complexity&quot; (which they often are)
and continuous interaction. In this paper we aim at narrowing this huge gap
between vision and reality by introducing a modular framework capable of (i)
formalizing troubleshooting processes as the concatenation of executable
functions [called Troubleshooting Graphs (TSGs)], (ii) executing these graphs
via an interpreter, (iii) evaluating and navigating between the outputs of the
functions and (iv) sharing troubleshooting know-hows in a formalized manner.
</dc:description>
 <dc:description>Comment: 18 pages, 9 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08830</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Complexity of Translationally-Invariant Low-Dimensional Spin
  Lattices in 3D</dc:title>
 <dc:creator>Bausch, Johannes</dc:creator>
 <dc:creator>Piddock, Stephen</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17, 81V70, 68Q10, 82D25</dc:subject>
 <dc:description>  In this paper, we consider spin systems in three spatial dimensions, and
prove that the local Hamiltonian problem for 3D lattices with face-centered
cubic unit cells, 4-local translationally-invariant interactions between
spin-3/2 particles and open boundary conditions is QMAEXP-complete. We go
beyond a mere embedding of past hard 1D history state constructions, and
utilize a classical Wang tiling problem as binary counter in order to translate
one cube side length into a binary description for the verifier input. We
further make use of a recently-developed computational model especially
well-suited for history state constructions, and combine it with a specific
circuit encoding shown to be universal for quantum computation. These novel
techniques allow us to significantly lower the local spin dimension, surpassing
the best translationally-invariant result to date by two orders of magnitude
(in the number of degrees of freedom per coupling). This brings our models en
par with the best non-translationally-invariant construction.
</dc:description>
 <dc:description>Comment: 20 pages. 3 figures in main text; with technical appendix</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08830</dc:identifier>
 <dc:identifier>Journal of Mathematical Physics 58, 111901 (2017)</dc:identifier>
 <dc:identifier>doi:10.1063/1.5011338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08833</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Deep Nearest Neighbor Representations Using Differentiable
  Boundary Trees</dc:title>
 <dc:creator>Zoran, Daniel</dc:creator>
 <dc:creator>Lakshminarayanan, Balaji</dc:creator>
 <dc:creator>Blundell, Charles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Nearest neighbor (kNN) methods have been gaining popularity in recent years
in light of advances in hardware and efficiency of algorithms. There is a
plethora of methods to choose from today, each with their own advantages and
disadvantages. One requirement shared between all kNN based methods is the need
for a good representation and distance measure between samples.
  We introduce a new method called differentiable boundary tree which allows
for learning deep kNN representations. We build on the recently proposed
boundary tree algorithm which allows for efficient nearest neighbor
classification, regression and retrieval. By modelling traversals in the tree
as stochastic events, we are able to form a differentiable cost function which
is associated with the tree's predictions. Using a deep neural network to
transform the data and back-propagating through the tree allows us to learn
good representations for kNN methods.
  We demonstrate that our method is able to learn suitable representations
allowing for very efficient trees with a clearly interpretable structure.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08835</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Forest: Towards An Alternative to Deep Neural Networks</dc:title>
 <dc:creator>Zhou, Zhi-Hua</dc:creator>
 <dc:creator>Feng, Ji</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we propose gcForest, a decision tree ensemble approach with
performance highly competitive to deep neural networks. In contrast to deep
neural networks which require great effort in hyper-parameter tuning, gcForest
is much easier to train. Actually, even when gcForest is applied to different
data from different domains, excellent performance can be achieved by almost
same settings of hyper-parameters. The training process of gcForest is
efficient and scalable. In our experiments its training time running on a PC is
comparable to that of deep neural networks running with GPU facilities, and the
efficiency advantage may be more apparent because gcForest is naturally apt to
parallel implementation. Furthermore, in contrast to deep neural networks which
require large-scale training data, gcForest can work well even when there are
only small-scale training data. Moreover, as a tree-based approach, gcForest
should be easier for theoretical analysis than deep neural networks.
</dc:description>
 <dc:description>Comment: IJCAI 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08840</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Bayesian Learning for Crowdsourced Regression</dc:title>
 <dc:creator>Ok, Jungseul</dc:creator>
 <dc:creator>Oh, Sewoong</dc:creator>
 <dc:creator>Jang, Yunhun</dc:creator>
 <dc:creator>Shin, Jinwoo</dc:creator>
 <dc:creator>Yi, Yung</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Crowdsourcing platforms emerged as popular venues for purchasing human
intelligence at low cost for large volumes of tasks. As many low-paid workers
are prone to give noisy answers, one of the fundamental questions is how to
identify more reliable workers and exploit this heterogeneity to infer the true
answers accurately. Despite significant research efforts for classification
tasks with discrete answers, little attention has been paid to regression tasks
with continuous answers. The popular Dawid-Skene model for discrete answers has
the algorithmic and mathematical simplicity in relation to low-rank structures.
But it does not generalize for continuous valued answers. To this end, we
introduce a new probabilistic model for crowdsourced regression capturing the
heterogeneity of the workers, generalizing the Dawid-Skene model to the
continuous domain. We design a message-passing algorithm for Bayesian inference
inspired by the popular belief propagation algorithm. We showcase its
performance first by proving that it achieves a near optimal mean squared error
by comparing it to an oracle estimator. Asymptotically, we can provide a
tighter analysis showing that the proposed algorithm achieves the exact optimal
performance. We next show synthetic experiments confirming our theoretical
predictions. As a practical application, we further emulate a crowdsourcing
system reproducing PASCAL visual object classes datasets and show that
de-noising the crowdsourced data from the proposed scheme can significantly
improve the performance for the vision task.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08840</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08841</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifiers on languages and codensity monads</dc:title>
 <dc:creator>Gehrke, Mai</dc:creator>
 <dc:creator>Petrisan, Daniela</dc:creator>
 <dc:creator>Reggio, Luca</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Mathematics - General Topology</dc:subject>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.4.3</dc:subject>
 <dc:description>  This paper contributes to the techniques of topo-algebraic recognition for
languages beyond the regular setting as they relate to logic on words. In
particular, we provide a general construction on recognisers corresponding to
adding one layer of various kinds of quantifiers and prove a related
Reutenauer-type theorem. Our main tools are codensity monads and duality
theory. Our construction yields, in particular, a new characterisation of the
profinite monad of the free S-semimodule monad for finite commutative semirings
S, which generalises our earlier insight that the Vietoris monad on Boolean
spaces is the codensity monad of the finite powerset functor.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08862</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proportional Representation in Vote Streams</dc:title>
 <dc:creator>Dey, Palash</dc:creator>
 <dc:creator>Talmon, Nimrod</dc:creator>
 <dc:creator>van Handel, Otniel</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We consider elections where the voters come one at a time, in a streaming
fashion, and devise space-efficient algorithms which identify an approximate
winning committee with respect to common multiwinner proportional
representation voting rules; specifically, we consider the Approval-based and
the Borda-based variants of both the Chamberlin-- ourant rule and the Monroe
rule. We complement our algorithms with lower bounds. Somewhat surprisingly,
our results imply that, using space which does not depend on the number of
voters it is possible to efficiently identify an approximate representative
committee of fixed size over vote streams with huge number of voters.
</dc:description>
 <dc:description>Comment: Accepted as a full paper in AAMAS 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08866</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Studying Positive Speech on Twitter</dc:title>
 <dc:creator>Sokolova, Marina</dc:creator>
 <dc:creator>Sazonova, Vera</dc:creator>
 <dc:creator>Huang, Kanyi</dc:creator>
 <dc:creator>Chakraboty, Rudraneel</dc:creator>
 <dc:creator>Matwin, Stan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  We present results of empirical studies on positive speech on Twitter. By
positive speech we understand speech that works for the betterment of a given
situation, in this case relations between different communities in a
conflict-prone country. We worked with four Twitter data sets. Through
semi-manual opinion mining, we found that positive speech accounted for &lt; 1% of
the data . In fully automated studies, we tested two approaches: unsupervised
statistical analysis, and supervised text classification based on distributed
word representation. We discuss benefits and challenges of those approaches and
report empirical evidence obtained in the study.
</dc:description>
 <dc:description>Comment: 13 pages, 6 tables</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08866</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08875</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Debris Backwards Flow Simulation System for Malaysia Airlines Flight
  370</dc:title>
 <dc:creator>Eichhorn, Mike</dc:creator>
 <dc:creator>Haertel, Alexander</dc:creator>
 <dc:subject>Physics - Atmospheric and Oceanic Physics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  This paper presents a system based on a Two-Way Particle-Tracking Model to
analyze possible crash positions of flight MH370. The particle simulator
includes a simple flow simulation of the debris based on a Lagrangian approach
and a module to extract appropriated ocean current data from netCDF files. The
influence of wind, waves, immersion depth and hydrodynamic behavior are not
considered in the simulation.
</dc:description>
 <dc:description>Comment: 7 pages, 14 figures, IEEE OCEANS 2016 - Shanghai, 10-13 April 2016</dc:description>
 <dc:date>2017-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08875</dc:identifier>
 <dc:identifier>doi:10.1109/OCEANSAP.2016.7485732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08880</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Landau Collision Integral Solver with Adaptive Mesh Refinement on
  Emerging Architectures</dc:title>
 <dc:creator>Adams, M. F.</dc:creator>
 <dc:creator>Hirvijoki, E.</dc:creator>
 <dc:creator>Knepley, M. G.</dc:creator>
 <dc:creator>Brown, J.</dc:creator>
 <dc:creator>Isaac, T.</dc:creator>
 <dc:creator>Mills, R.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  The Landau collision integral is an accurate model for the small-angle
dominated Coulomb collisions in fusion plasmas. We investigate a high order
accurate, fully conservative, finite element discretization of the nonlinear
multi-species Landau integral with adaptive mesh refinement using the PETSc
library (www.mcs.anl.gov/petsc). We develop algorithms and techniques to
efficiently utilize emerging architectures with an approach that minimizes
memory usage and movement and is suitable for vector processing. The Landau
collision integral is vectorized with Intel AVX-512 intrinsics and the solver
sustains as much as 22% of the theoretical peak flop rate of the Second
Generation Intel Xeon Phi, Knights Landing, processor.
</dc:description>
 <dc:date>2017-02-27</dc:date>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08882</identifier>
 <datestamp>2017-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Semi-Random Features for Nonlinear Function Approximation</dc:title>
 <dc:creator>Kawaguchi, Kenji</dc:creator>
 <dc:creator>Xie, Bo</dc:creator>
 <dc:creator>Verma, Vikas</dc:creator>
 <dc:creator>Song, Le</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose semi-random features for nonlinear function approximation. The
flexibility of semi-random feature lies between the fully adjustable units in
deep learning and the random features used in kernel methods. For one hidden
layer models with semi-random features, we prove with no unrealistic
assumptions that the model classes contain an arbitrarily good function as the
width increases (universality), and despite non-convexity, we can find such a
good function (optimization theory) that generalizes to unseen new data
(generalization bound). For deep models, with no unrealistic assumptions, we
prove universal approximation ability, a lower bound on approximation error, a
partial optimization guarantee, and a generalization bound. Depending on the
problems, the generalization bound of deep semi-random features can be
exponentially better than the known bounds of deep ReLU nets; our
generalization error bound can be independent of the depth, the number of
trainable weights as well as the input dimensionality. In experiments, we show
that semi-random features can match the performance of neural networks by using
slightly more units, and it outperforms random features by using significantly
fewer units. Moreover, we introduce a new implicit ensemble method by using
semi-random features.
</dc:description>
 <dc:description>Comment: AAAI 2018 - Extended version</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08882</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08884</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-rank Label Propagation for Semi-supervised Learning with 100
  Millions Samples</dc:title>
 <dc:creator>Petegrosso, Raphael</dc:creator>
 <dc:creator>Zhang, Wei</dc:creator>
 <dc:creator>Li, Zhuliu</dc:creator>
 <dc:creator>Saad, Yousef</dc:creator>
 <dc:creator>Kuang, Rui</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The success of semi-supervised learning crucially relies on the scalability
to a huge amount of unlabelled data that are needed to capture the underlying
manifold structure for better classification. Since computing the pairwise
similarity between the training data is prohibitively expensive in most kinds
of input data, currently, there is no general ready-to-use semi-supervised
learning method/tool available for learning with tens of millions or more data
points. In this paper, we adopted the idea of two low-rank label propagation
algorithms, GLNP (Global Linear Neighborhood Propagation) and Kernel Nystr\&quot;om
Approximation, and implemented the parallelized version of the two algorithms
accelerated with Nesterov's accelerated projected gradient descent for Big-data
Label Propagation (BigLP).
  The parallel algorithms are tested on five real datasets ranging from 7000 to
10,000,000 in size and a simulation dataset of 100,000,000 samples. In the
experiments, the implementation can scale up to datasets with 100,000,000
samples and hundreds of features and the algorithms also significantly improved
the prediction accuracy when only a very small percentage of the data is
labeled. The results demonstrate that the BigLP implementation is highly
scalable to big data and effective in utilizing the unlabeled data for
semi-supervised learning.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08887</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilising Experience Replay for Deep Multi-Agent Reinforcement
  Learning</dc:title>
 <dc:creator>Foerster, Jakob</dc:creator>
 <dc:creator>Nardelli, Nantas</dc:creator>
 <dc:creator>Farquhar, Gregory</dc:creator>
 <dc:creator>Afouras, Triantafyllos</dc:creator>
 <dc:creator>Torr, Philip H. S.</dc:creator>
 <dc:creator>Kohli, Pushmeet</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Many real-world problems, such as network packet routing and urban traffic
control, are naturally modeled as multi-agent reinforcement learning (RL)
problems. However, existing multi-agent RL methods typically scale poorly in
the problem size. Therefore, a key challenge is to translate the success of
deep learning on single-agent RL to the multi-agent setting. A major stumbling
block is that independent Q-learning, the most popular multi-agent RL method,
introduces nonstationarity that makes it incompatible with the experience
replay memory on which deep Q-learning relies. This paper proposes two methods
that address this problem: 1) using a multi-agent variant of importance
sampling to naturally decay obsolete data and 2) conditioning each agent's
value function on a fingerprint that disambiguates the age of the data sampled
from the replay memory. Results on a challenging decentralised variant of
StarCraft unit micromanagement confirm that these methods enable the successful
combination of experience replay with multi-agent RL.
</dc:description>
 <dc:description>Comment: Camera-ready version, International Conference of Machine Learning
  2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08889</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computers from plants we never made. Speculations</dc:title>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:creator>Harding, Simon</dc:creator>
 <dc:creator>Erokhin, Victor</dc:creator>
 <dc:creator>Mayne, Richard</dc:creator>
 <dc:creator>Gizzie, Nina</dc:creator>
 <dc:creator>Baluska, Frantisek</dc:creator>
 <dc:creator>Mancuso, Stefano</dc:creator>
 <dc:creator>Sirakoulis, Georgios</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We discuss possible designs and prototypes of computing systems that could be
based on morphological development of roots, interaction of roots, and analog
electrical computation with plants, and plant-derived electronic components. In
morphological plant processors data are represented by initial configuration of
roots and configurations of sources of attractants and repellents; results of
computation are represented by topology of the roots' network. Computation is
implemented by the roots following gradients of attractants and repellents, as
well as interacting with each other. Problems solvable by plant roots, in
principle, include shortest-path, minimum spanning tree, Voronoi diagram,
$\alpha$-shapes, convex subdivision of concave polygons. Electrical properties
of plants can be modified by loading the plants with functional nanoparticles
or coating parts of plants of conductive polymers. Thus, we are in position to
make living variable resistors, capacitors, operational amplifiers,
multipliers, potentiometers and fixed-function generators. The electrically
modified plants can implement summation, integration with respect to time,
inversion, multiplication, exponentiation, logarithm, division. Mathematical
and engineering problems to be solved can be represented in plant root networks
of resistive or reaction elements. Developments in plant-based computing
architectures will trigger emergence of a unique community of biologists,
electronic engineering and computer scientists working together to produce
living electronic devices which future green computers will be made of.
</dc:description>
 <dc:description>Comment: The chapter will be published in &quot;Inspired by Nature. Computing
  inspired by physics, chemistry and biology. Essays presented to Julian Miller
  on the occasion of his 60th birthday&quot;, Editors: Susan Stepney and Andrew
  Adamatzky (Springer, 2017)</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08889</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08891</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Slice-to-Volume Transformation in Presence of Arbitrary
  Subject Motion</dc:title>
 <dc:creator>Hou, Benjamin</dc:creator>
 <dc:creator>Alansary, Amir</dc:creator>
 <dc:creator>McDonagh, Steven</dc:creator>
 <dc:creator>Davidson, Alice</dc:creator>
 <dc:creator>Rutherford, Mary</dc:creator>
 <dc:creator>Hajnal, Jo V.</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:creator>Glocker, Ben</dc:creator>
 <dc:creator>Kainz, Bernhard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper aims to solve a fundamental problem in intensity-based 2D/3D
registration, which concerns the limited capture range and need for very good
initialization of state-of-the-art image registration methods. We propose a
regression approach that learns to predict rotation and translations of
arbitrary 2D image slices from 3D volumes, with respect to a learned canonical
atlas co-ordinate system. To this end, we utilize Convolutional Neural Networks
(CNNs) to learn the highly complex regression function that maps 2D image
slices into their correct position and orientation in 3D space. Our approach is
attractive in challenging imaging scenarios, where significant subject motion
complicates reconstruction performance of 3D volumes from 2D slice data. We
extensively evaluate the effectiveness of our approach quantitatively on
simulated MRI brain data with extreme random motion. We further demonstrate
qualitative results on fetal MRI where our method is integrated into a full
reconstruction and motion compensation pipeline. With our CNN regression
approach we obtain an average prediction error of 7mm on simulated data, and
convincing reconstruction quality of images of very young fetuses where
previous methods fail. We further discuss applications to Computed Tomography
and X-ray projections. Our approach is a general solution to the 2D/3D
initialization problem. It is computationally efficient, with prediction times
per slice of a few milliseconds, making it suitable for real-time scenarios.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures, 6 pages supplemental material, currently under
  review for MICCAI 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08892</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridging the Gap Between Value and Policy Based Reinforcement Learning</dc:title>
 <dc:creator>Nachum, Ofir</dc:creator>
 <dc:creator>Norouzi, Mohammad</dc:creator>
 <dc:creator>Xu, Kelvin</dc:creator>
 <dc:creator>Schuurmans, Dale</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We establish a new connection between value and policy based reinforcement
learning (RL) based on a relationship between softmax temporal value
consistency and policy optimality under entropy regularization. Specifically,
we show that softmax consistent action values correspond to optimal entropy
regularized policy probabilities along any action sequence, regardless of
provenance. From this observation, we develop a new RL algorithm, Path
Consistency Learning (PCL), that minimizes a notion of soft consistency error
along multi-step action sequences extracted from both on- and off-policy
traces. We examine the behavior of PCL in different scenarios and show that PCL
can be interpreted as generalizing both actor-critic and Q-learning algorithms.
We subsequently deepen the relationship by showing how a single model can be
used to represent both a policy and the corresponding softmax state values,
eliminating the need for a separate critic. The experimental evaluation
demonstrates that PCL significantly outperforms strong actor-critic and
Q-learning baselines across several benchmarks.
</dc:description>
 <dc:description>Comment: NIPS 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08892</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08896</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hierarchical Implicit Models and Likelihood-Free Variational Inference</dc:title>
 <dc:creator>Tran, Dustin</dc:creator>
 <dc:creator>Ranganath, Rajesh</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Implicit probabilistic models are a flexible class of models defined by a
simulation process for data. They form the basis for theories which encompass
our understanding of the physical world. Despite this fundamental nature, the
use of implicit models remains limited due to challenges in specifying complex
latent structure in them, and in performing inferences in such models with
large data sets. In this paper, we first introduce hierarchical implicit models
(HIMs). HIMs combine the idea of implicit densities with hierarchical Bayesian
modeling, thereby defining models via simulators of data with rich hidden
structure. Next, we develop likelihood-free variational inference (LFVI), a
scalable variational inference algorithm for HIMs. Key to LFVI is specifying a
variational family that is also implicit. This matches the model's flexibility
and allows for accurate approximation of the posterior. We demonstrate diverse
applications: a large-scale physical simulator for predator-prey populations in
ecology; a Bayesian generative adversarial network for discrete data; and a
deep implicit model for text generation.
</dc:description>
 <dc:description>Comment: Appears in Neural Information Processing Systems, 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08898</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lipschitz Optimisation for Lipschitz Interpolation</dc:title>
 <dc:creator>Calliess, Jan-Peter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Techniques known as Nonlinear Set Membership prediction, Kinky Inference or
Lipschitz Interpolation are fast and numerically robust approaches to
nonparametric machine learning that have been proposed to be utilised in the
context of system identification and learning-based control. They utilise
presupposed Lipschitz properties in order to compute inferences over unobserved
function values. Unfortunately, most of these approaches rely on exact
knowledge about the input space metric as well as about the Lipschitz constant.
Furthermore, existing techniques to estimate the Lipschitz constants from the
data are not robust to noise or seem to be ad-hoc and typically are decoupled
from the ultimate learning and prediction task. To overcome these limitations,
we propose an approach for optimising parameters of the presupposed metrics by
minimising validation set prediction errors. To avoid poor performance due to
local minima, we propose to utilise Lipschitz properties of the optimisation
objective to ensure global optimisation success. The resulting approach is a
new flexible method for nonparametric black-box learning. We provide
experimental evidence of the competitiveness of our approach on artificial as
well as on real data.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08898</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08899</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary Search in Graphs Revisited</dc:title>
 <dc:creator>Deligkas, Argyrios</dc:creator>
 <dc:creator>Mertzios, George B.</dc:creator>
 <dc:creator>Spirakis, Paul G.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the classical binary search in a path the aim is to detect an unknown
target by asking as few queries as possible, where each query reveals the
direction to the target. This binary search algorithm has been recently
extended by [Emamjomeh-Zadeh et al., STOC, 2016] to the problem of detecting a
target in an arbitrary graph. Similarly to the classical case in the path, the
algorithm of Emamjomeh-Zadeh et al. maintains a candidates' set for the target,
while each query asks an appropriately chosen vertex-- the &quot;median&quot;--which
minimizes a potential $\Phi$ among the vertices of the candidates' set. In this
paper we address three open questions posed by Emamjomeh-Zadeh et al., namely
(a) detecting a target when the query response is a direction to an
approximately shortest path to the target, (b) detecting a target when querying
a vertex that is an approximate median of the current candidates' set (instead
of an exact one), and (c) detecting multiple targets, for which to the best of
our knowledge no progress has been made so far. We resolve questions (a) and
(b) by providing appropriate upper and lower bounds, as well as a new potential
$\Gamma$ that guarantees efficient target detection even by querying an
approximate median each time. With respect to (c), we initiate a systematic
study for detecting two targets in graphs and we identify sufficient conditions
on the queries that allow for strong (linear) lower bounds and strong
(polylogarithmic) upper bounds for the number of queries. All of our positive
results can be derived using our new potential $\Gamma$ that allows querying
approximate medians.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1702.08903</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defective Coloring on Classes of Perfect Graphs</dc:title>
 <dc:creator>Belmonte, R&#xe9;my</dc:creator>
 <dc:creator>Lampis, Michael</dc:creator>
 <dc:creator>Mitsou, Valia</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  In Defective Coloring we are given a graph $G$ and two integers $\chi_d$,
$\Delta^*$ and are asked if we can $\chi_d$-color $G$ so that the maximum
degree induced by any color class is at most $\Delta^*$. We show that this
natural generalization of Coloring is much harder on several basic graph
classes. In particular, we show that it is NP-hard on split graphs, even when
one of the two parameters $\chi_d$, $\Delta^*$ is set to the smallest possible
fixed value that does not trivialize the problem ($\chi_d = 2$ or $\Delta^* =
1$). Together with a simple treewidth-based DP algorithm this completely
determines the complexity of the problem also on chordal graphs. We then
consider the case of cographs and show that, somewhat surprisingly, Defective
Coloring turns out to be one of the few natural problems which are NP-hard on
this class. We complement this negative result by showing that Defective
Coloring is in P for cographs if either $\chi_d$ or $\Delta^*$ is fixed; that
it is in P for trivially perfect graphs; and that it admits a sub-exponential
time algorithm for cographs when both $\chi_d$ and $\Delta^*$ are unbounded.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1702.08903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00009</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Model and its Inverse of an Audio System</dc:title>
 <dc:creator>Loriga, Alessandro</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  This computer science master thesis aims at modelling the nonlinearities of a
loudspeaker. A piecewise linear approximation is initially explored and then we
present a nonlinear Volterra model to simulate the behavior of the system. The
general theory of continuous and discrete Volterra series is summarised. A
Normalized Least Mean Square algorithm is used to determine the Volterra series
to third order. We also present as inverted system which is trained with the
same algorithm. Training data for the models were collected measuring a
physical speaker using a laser interferometer. Results indicate a decrease in
Mean Squared Error compared to the linear model with a dependency on the
particular test signal, the order and the parameters of the model.
</dc:description>
 <dc:description>Comment: 113 pages, master thesis</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00031</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MPC Validation and Aggregation of Unit Vectors</dc:title>
 <dc:creator>Gray, Dylan</dc:creator>
 <dc:creator>Joy, Joshua</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  When dealing with privatized data, it is important to be able to protect
against malformed user inputs. This becomes difficult in MPC systems as each
server should not contain enough information to know what values any user has
submitted. In this paper, we implement an MPC technique to verify blinded user
inputs are unit vectors. In addition, we introduce a BGW circuit which can
securely aggregate the blinded inputs while only releasing the result when it
is above a public threshold. These distributed techniques take as input a unit
vector. While this initially seems limiting compared to real number input, it
is quite powerful for cases such as selecting from a list of options,
indicating a location from a set of possibilities, or any system which uses
one-hot encoding.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00034</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted Random Walk Sampling for Multi-Relational Recommendation</dc:title>
 <dc:creator>Vahedian, Fatemeh</dc:creator>
 <dc:creator>Burke, Robin</dc:creator>
 <dc:creator>Mobasher, Bamshad</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In the information overloaded web, personalized recommender systems are
essential tools to help users find most relevant information. The most
heavily-used recommendation frameworks assume user interactions that are
characterized by a single relation. However, for many tasks, such as
recommendation in social networks, user-item interactions must be modeled as a
complex network of multiple relations, not only a single relation. Recently
research on multi-relational factorization and hybrid recommender models has
shown that using extended meta-paths to capture additional information about
both users and items in the network can enhance the accuracy of recommendations
in such networks. Most of this work is focused on unweighted heterogeneous
networks, and to apply these techniques, weighted relations must be simplified
into binary ones. However, information associated with weighted edges, such as
user ratings, which may be crucial for recommendation, are lost in such
binarization. In this paper, we explore a random walk sampling method in which
the frequency of edge sampling is a function of edge weight, and apply this
generate extended meta-paths in weighted heterogeneous networks. With this
sampling technique, we demonstrate improved performance on multiple data sets
both in terms of recommendation accuracy and model generation efficiency.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00034</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00035</identifier>
 <datestamp>2017-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Sensitive Super-Resolution for Fast Fetal Magnetic Resonance
  Imaging</dc:title>
 <dc:creator>McDonagh, Steven</dc:creator>
 <dc:creator>Hou, Benjamin</dc:creator>
 <dc:creator>Kamnitsas, Konstantinos</dc:creator>
 <dc:creator>Oktay, Ozan</dc:creator>
 <dc:creator>Alansary, Amir</dc:creator>
 <dc:creator>Rutherford, Mary</dc:creator>
 <dc:creator>Hajnal, Jo V.</dc:creator>
 <dc:creator>Kainz, Bernhard</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  3D Magnetic Resonance Imaging (MRI) is often a trade-off between fast but
low-resolution image acquisition and highly detailed but slow image
acquisition. Fast imaging is required for targets that move to avoid motion
artefacts. This is in particular difficult for fetal MRI. Spatially independent
upsampling techniques, which are the state-of-the-art to address this problem,
are error prone and disregard contextual information. In this paper we propose
a context-sensitive upsampling method based on a residual convolutional neural
network model that learns organ specific appearance and adopts semantically to
input data allowing for the generation of high resolution images with sharp
edges and fine scale detail. By making contextual decisions about appearance
and shape, present in different parts of an image, we gain a maximum of
structural detail at a similar contrast as provided by high-resolution data. We
experiment on $145$ fetal scans and show that our approach yields an increased
PSNR of $1.25$ $dB$ when applied to under-sampled fetal data \emph{cf.}
baseline upsampling. Furthermore, our method yields an increased PSNR of $1.73$
$dB$ when utilizing under-sampled fetal data to perform brain volume
reconstruction on motion corrupted captured data.
</dc:description>
 <dc:description>Comment: 11 pages, 6 figures, published in Proc MICCAI RAMBO'17
  https://link.springer.com/chapter/10.1007/978-3-319-67564-0_12</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-09-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00035</dc:identifier>
 <dc:identifier>Springer LNCS 10555 2017</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-67564-0_12</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00037</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Managing the Public to Manage Data: Citizen Science and Astronomy</dc:title>
 <dc:creator>Darch, Peter T.</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.1.2</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>H.5.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>K.6.1</dc:subject>
 <dc:description>  Citizen science projects recruit members of the public as volunteers to
process and produce datasets. These datasets must win the trust of the
scientific community. The task of securing credibility involves, in part,
applying standard scientific procedures to clean these datasets. However,
effective management of volunteer behavior also makes a significant
contribution to enhancing data quality. Through a case study of Galaxy Zoo, a
citizen science project set up to generate datasets based on volunteer
classifications of galaxy morphologies, this paper explores how those involved
in running the project manage volunteers. The paper focuses on how methods for
crediting volunteer contributions motivate volunteers to provide higher quality
contributions and to behave in a way that better corresponds to statistical
assumptions made when combining volunteer contributions into datasets. These
methods have made a significant contribution to the success of the project in
securing trust in these datasets, which have been well used by other
scientists. Implications for practice are then presented for citizen science
projects, providing a list of considerations to guide choices regarding how to
credit volunteer contributions to improve the quality and trustworthiness of
citizen science-produced datasets.
</dc:description>
 <dc:description>Comment: 16 pages, 0 figures, published in International Journal of Digital
  Curation</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00037</dc:identifier>
 <dc:identifier>International Journal of Digital Curation, 2014, 9(1), 25-40</dc:identifier>
 <dc:identifier>doi:10.2218/ijdc.v9i1.298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00039</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A description length approach to determining the number of k-means
  clusters</dc:title>
 <dc:creator>Mizutani, Hiromitsu</dc:creator>
 <dc:creator>Kanai, Ryota</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present an asymptotic criterion to determine the optimal number of
clusters in k-means. We consider k-means as data compression, and propose to
adopt the number of clusters that minimizes the estimated description length
after compression. Here we report two types of compression ratio based on two
ways to quantify the description length of data after compression. This
approach further offers a way to evaluate whether clusters obtained with
k-means have a hierarchical structure by examining whether multi-stage
compression can further reduce the description length. We applied our criteria
to determine the number of clusters to synthetic data and empirical
neuroimaging data to observe the behavior of the criteria across different
types of data set and suitability of the two types of criteria for different
datasets. We found that our method can offer reasonable clustering results that
are useful for dimension reduction. While our numerical results revealed
dependency of our criteria on the various aspects of dataset such as the
dimensionality, the description length approach proposed here provides a useful
guidance to determine the number of clusters in a principled manner when
underlying properties of the data are unknown and only inferred from
observation of data.
</dc:description>
 <dc:description>Comment: 27 pages, 6 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00042</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reproducible experiments on dynamic resource allocation in cloud data
  centers</dc:title>
 <dc:creator>Wolke, Andreas</dc:creator>
 <dc:creator>Bichler, Martin</dc:creator>
 <dc:creator>Chirigati, Fernando</dc:creator>
 <dc:creator>Steeves, Victoria</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In Wolke et al. [1] we compare the efficiency of different resource
allocation strategies experimentally. We focused on dynamic environments where
virtual machines need to be allocated and deallocated to servers over time. In
this companion paper, we describe the simulation framework and how to run
simulations to replicate experiments or run new experiments within the
framework.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00042</dc:identifier>
 <dc:identifier>Information Systems, Volume 59, July 2016, Pages 98-101, ISSN
  0306-4379</dc:identifier>
 <dc:identifier>doi:10.1016/j.is.2015.12.004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00043</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree tribes and lower bounds for switching lemmas</dc:title>
 <dc:creator>Mehta, Jenish C.</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We show tight upper and lower bounds for switching lemmas obtained by the
action of random $p$-restrictions on boolean functions that can be expressed as
decision trees in which every vertex is at a distance of at most $t$ from some
leaf, also called $t$-clipped decision trees. More specifically, we show the
following:
  $\bullet$ If a boolean function $f$ can be expressed as a $t$-clipped
decision tree, then under the action of a random $p$-restriction $\rho$, the
probability that the smallest depth decision tree for $f|_{\rho}$ has depth
greater than $d$ is upper bounded by $(4p2^{t})^{d}$.
  $\bullet$ For every $t$, there exists a function $g_{t}$ that can be
expressed as a $t$-clipped decision tree, such that under the action of a
random $p$-restriction $\rho$, the probability that the smallest depth decision
tree for $g_{t}|_{\rho}$ has depth greater than $d$ is lower bounded by
$(c_{0}p2^{t})^{d}$, for $0\leq p\leq c_{p}2^{-t}$ and $0\leq d\leq
c_{d}\frac{\log n}{2^{t}\log t}$, where $c_{0},c_{p},c_{d}$ are universal
constants.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00043</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00045</identifier>
 <datestamp>2017-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregated knowledge from a small number of debates outperforms the
  wisdom of large crowds</dc:title>
 <dc:creator>Navajas, Joaquin</dc:creator>
 <dc:creator>Niella, Tamara</dc:creator>
 <dc:creator>Garbulsky, Gerry</dc:creator>
 <dc:creator>Bahrami, Bahador</dc:creator>
 <dc:creator>Sigman, Mariano</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The aggregation of many independent estimates can outperform the most
accurate individual judgment. This centenarian finding, popularly known as the
wisdom of crowds, has been applied to problems ranging from the diagnosis of
cancer to financial forecasting. It is widely believed that social influence
undermines collective wisdom by reducing the diversity of opinions within the
crowd. Here, we show that if a large crowd is structured in small independent
groups, deliberation and social influence within groups improve the crowd's
collective accuracy. We asked a live crowd (N=5180) to respond to
general-knowledge questions (e.g., what is the height of the Eiffel Tower?).
Participants first answered individually, then deliberated and made consensus
decisions in groups of five, and finally provided revised individual estimates.
We found that averaging consensus decisions was substantially more accurate
than aggregating the initial independent opinions. Remarkably, combining as few
as four consensus choices outperformed the wisdom of thousands of individuals.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00045</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00048</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Provably Optimal Algorithms for Generalized Linear Contextual Bandits</dc:title>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Lu, Yu</dc:creator>
 <dc:creator>Zhou, Dengyong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Contextual bandits are widely used in Internet services from news
recommendation to advertising, and to Web search. Generalized linear models
(logistical regression in particular) have demonstrated stronger performance
than linear models in many applications where rewards are binary. However, most
theoretical analyses on contextual bandits so far are on linear bandits. In
this work, we propose an upper confidence bound based algorithm for generalized
linear contextual bandits, which achieves an $\tilde{O}(\sqrt{dT})$ regret over
$T$ rounds with $d$ dimensional feature vectors. This regret matches the
minimax lower bound, up to logarithmic terms, and improves on the best previous
result by a $\sqrt{d}$ factor, assuming the number of arms is fixed. A key
component in our analysis is to establish a new, sharp finite-sample confidence
bound for maximum-likelihood estimates in generalized linear models, which may
be of independent interest. We also analyze a simpler upper confidence bound
algorithm, which is useful in practice, and prove it to have optimal regret for
certain cases.
</dc:description>
 <dc:description>Comment: Published at ICML 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00050</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SceneSeer: 3D Scene Design with Natural Language</dc:title>
 <dc:creator>Chang, Angel X.</dc:creator>
 <dc:creator>Eric, Mihail</dc:creator>
 <dc:creator>Savva, Manolis</dc:creator>
 <dc:creator>Manning, Christopher D.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Designing 3D scenes is currently a creative task that requires significant
expertise and effort in using complex 3D design interfaces. This effortful
design process starts in stark contrast to the easiness with which people can
use language to describe real and imaginary environments. We present SceneSeer:
an interactive text to 3D scene generation system that allows a user to design
3D scenes using natural language. A user provides input text from which we
extract explicit constraints on the objects that should appear in the scene.
Given these explicit constraints, the system then uses a spatial knowledge base
learned from an existing database of 3D scenes and 3D object models to infer an
arrangement of the objects forming a natural scene matching the input
description. Using textual commands the user can then iteratively refine the
created scene by adding, removing, replacing, and manipulating objects. We
evaluate the quality of 3D scenes generated by SceneSeer in a perceptual
evaluation experiment where we compare against manually designed scenes and
simpler baselines for 3D scene generation. We demonstrate how the generated
scenes can be iteratively refined through simple natural language commands.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00053</identifier>
 <datestamp>2017-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Verified Low-Level Programming Embedded in F*</dc:title>
 <dc:creator>Protzenko, Jonathan</dc:creator>
 <dc:creator>Zinzindohou&#xe9;, Jean-Karim</dc:creator>
 <dc:creator>Rastogi, Aseem</dc:creator>
 <dc:creator>Ramananandro, Tahina</dc:creator>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Zanella-B&#xe9;guelin, Santiago</dc:creator>
 <dc:creator>Delignat-Lavaud, Antoine</dc:creator>
 <dc:creator>Hritcu, Catalin</dc:creator>
 <dc:creator>Bhargavan, Karthikeyan</dc:creator>
 <dc:creator>Fournet, C&#xe9;dric</dc:creator>
 <dc:creator>Swamy, Nikhil</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present Low*, a language for low-level programming and verification, and
its application to high-assurance optimized cryptographic libraries. Low* is a
shallow embedding of a small, sequential, well-behaved subset of C in F*, a
dependently-typed variant of ML aimed at program verification. Departing from
ML, Low* does not involve any garbage collection or implicit heap allocation;
instead, it has a structured memory model \`a la CompCert, and it provides the
control required for writing efficient low-level security-critical code.
  By virtue of typing, any Low* program is memory safe. In addition, the
programmer can make full use of the verification power of F* to write
high-level specifications and verify the functional correctness of Low* code
using a combination of SMT automation and sophisticated manual proofs. At
extraction time, specifications and proofs are erased, and the remaining code
enjoys a predictable translation to C. We prove that this translation preserves
semantics and side-channel resistance.
  We provide a new compiler back-end from Low* to C and, to evaluate our
approach, we implement and verify various cryptographic algorithms,
constructions, and tools for a total of about 28,000 lines of code,
specification and proof. We show that our Low* code delivers performance
competitive with existing (unverified) C cryptographic libraries, suggesting
our approach may be applicable to larger-scale low-level software.
</dc:description>
 <dc:description>Comment: extended version of ICFP final camera ready version</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00055</identifier>
 <datestamp>2017-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Monadic Framework for Relational Verification: Applied to Information
  Security, Program Equivalence, and Optimizations</dc:title>
 <dc:creator>Grimm, Niklas</dc:creator>
 <dc:creator>Maillard, Kenji</dc:creator>
 <dc:creator>Fournet, C&#xe9;dric</dc:creator>
 <dc:creator>Hritcu, Catalin</dc:creator>
 <dc:creator>Maffei, Matteo</dc:creator>
 <dc:creator>Protzenko, Jonathan</dc:creator>
 <dc:creator>Ramananandro, Tahina</dc:creator>
 <dc:creator>Rastogi, Aseem</dc:creator>
 <dc:creator>Swamy, Nikhil</dc:creator>
 <dc:creator>Zanella-B&#xe9;guelin, Santiago</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Relational properties describe multiple runs of one or more programs. They
characterize many useful notions of security, program refinement, and
equivalence for programs with diverse computational effects, and they have
received much attention in the recent literature. Rather than developing
separate tools for special classes of effects and relational properties, we
advocate using a general purpose proof assistant as a unifying framework for
the relational verification of effectful programs. The essence of our approach
is to model effectful computations using monads and to prove relational
properties on their monadic representations, making the most of existing
support for reasoning about pure programs.
  We apply this method in F* and evaluate it by encoding a variety of
relational program analyses, including information flow control, program
equivalence and refinement at higher order, correctness of program
optimizations and game-based cryptographic security. By relying on SMT-based
automation, unary weakest preconditions, user-defined effects, and monadic
reification, we show that, compared to unary properties, verifying relational
properties requires little additional effort from the F* programmer.
</dc:description>
 <dc:description>Comment: CPP'18 extended version</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-11-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00055</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00056</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments</dc:title>
 <dc:creator>Chouldechova, Alexandra</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recidivism prediction instruments (RPI's) provide decision makers with an
assessment of the likelihood that a criminal defendant will reoffend at a
future point in time. While such instruments are gaining increasing popularity
across the country, their use is attracting tremendous controversy. Much of the
controversy concerns potential discriminatory bias in the risk assessments that
are produced. This paper discusses several fairness criteria that have recently
been applied to assess the fairness of recidivism prediction instruments. We
demonstrate that the criteria cannot all be simultaneously satisfied when
recidivism prevalence differs across groups. We then show how disparate impact
can arise when a recidivism prediction instrument fails to satisfy the
criterion of error rate balance.
</dc:description>
 <dc:description>Comment: The short conference version of the paper was previously uploaded as
  arXiv:1610.07524</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00056</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00060</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving non-discrimination in prediction</dc:title>
 <dc:creator>Zhang, Lu</dc:creator>
 <dc:creator>Wu, Yongkai</dc:creator>
 <dc:creator>Wu, Xintao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Discrimination-aware classification is receiving an increasing attention in
the data mining and machine learning fields. The data preprocessing methods for
constructing a discrimination-free classifier remove discrimination from the
training data, and learn the classifier from the cleaned data. However, there
lacks of a theoretical guarantee for the performance of these methods. In this
paper, we fill this theoretical gap by mathematically bounding the probability
that the discrimination in predictions is within a given interval in terms of
the given training data and classifier. In our analysis, we adopt the causal
model for modeling the mechanisms in data generation, and formally defining
discrimination in the population, in a dataset, and in the prediction. The
theoretical results show that the fundamental assumption made by the data
preprocessing methods is not correct. Finally, we develop a framework for
constructing a discrimination-free classifier with a theoretical guarantee.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00061</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SceneSuggest: Context-driven 3D Scene Design</dc:title>
 <dc:creator>Savva, Manolis</dc:creator>
 <dc:creator>Chang, Angel X.</dc:creator>
 <dc:creator>Agrawala, Maneesh</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We present SceneSuggest: an interactive 3D scene design system providing
context-driven suggestions for 3D model retrieval and placement. Using a
point-and-click metaphor we specify regions in a scene in which to
automatically place and orient relevant 3D models. Candidate models are ranked
using a set of static support, position, and orientation priors learned from 3D
scenes. We show that our suggestions enable rapid assembly of indoor scenes. We
perform a user study comparing suggestions to manual search and selection, as
well as to suggestions with no automatic orientation. We find that suggestions
reduce total modeling time by 32%, that orientation priors reduce time spent
re-orienting objects by 27%, and that context-driven suggestions reduce the
number of text queries by 50%.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00064</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ending the Anomaly: Achieving Low Latency and Airtime Fairness in WiFi</dc:title>
 <dc:creator>H&#xf8;iland-J&#xf8;rgensen, Toke</dc:creator>
 <dc:creator>Kazior, Micha&#x142;</dc:creator>
 <dc:creator>T&#xe4;ht, Dave</dc:creator>
 <dc:creator>Hurtig, Per</dc:creator>
 <dc:creator>Brunstrom, Anna</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With more devices connected, delays and jitter at the WiFi hop become more
prevalent, and correct functioning during network congestion becomes more
important. However, two important performance issues prevent modern WiFi from
reaching its potential: Increased latency under load caused by excessive
queueing (i.e. bufferbloat) and the 802.11 performance anomaly.
  To remedy these issues, we present a novel two-part solution: We design a new
queueing scheme that eliminates bufferbloat in the wireless setting. Leveraging
this queueing scheme, we then design an airtime fairness scheduler that
operates at the access point and doesn't require any changes to clients.
  We evaluate our solution using both a theoretical model and experiments in a
testbed environment, formulating a suitable analytical model in the process. We
show that our solution achieves an order of magnitude reduction in latency
under load, large improvements in multi-station throughput, and nearly perfect
airtime fairness for both TCP and downstream UDP traffic. Further experiments
with application traffic confirm that the solution provides significant
performance gains for real-world traffic.We develop a production quality
implementation of our solution in the Linux kernel, the platform powering most
access points outside of the managed enterprise setting. The implementation has
been accepted into the mainline kernel distribution, making it available for
deployment on billions of devices running Linux today.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00066</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Power of Learning from $k$-Wise Queries</dc:title>
 <dc:creator>Feldman, Vitaly</dc:creator>
 <dc:creator>Ghazi, Badih</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Several well-studied models of access to data samples, including statistical
queries, local differential privacy and low-communication algorithms rely on
queries that provide information about a function of a single sample. (For
example, a statistical query (SQ) gives an estimate of $Ex_{x \sim D}[q(x)]$
for any choice of the query function $q$ mapping $X$ to the reals, where $D$ is
an unknown data distribution over $X$.) Yet some data analysis algorithms rely
on properties of functions that depend on multiple samples. Such algorithms
would be naturally implemented using $k$-wise queries each of which is
specified by a function $q$ mapping $X^k$ to the reals. Hence it is natural to
ask whether algorithms using $k$-wise queries can solve learning problems more
efficiently and by how much.
  Blum, Kalai and Wasserman (2003) showed that for any weak PAC learning
problem over a fixed distribution, the complexity of learning with $k$-wise SQs
is smaller than the (unary) SQ complexity by a factor of at most $2^k$. We show
that for more general problems over distributions the picture is substantially
richer. For every $k$, the complexity of distribution-independent PAC learning
with $k$-wise queries can be exponentially larger than learning with
$(k+1)$-wise queries. We then give two approaches for simulating a $k$-wise
query using unary queries. The first approach exploits the structure of the
problem that needs to be solved. It generalizes and strengthens (exponentially)
the results of Blum et al.. It allows us to derive strong lower bounds for
learning DNF formulas and stochastic constraint satisfaction problems that hold
against algorithms using $k$-wise queries. The second approach exploits the
$k$-party communication complexity of the $k$-wise query function.
</dc:description>
 <dc:description>Comment: 32 pages, Appeared in Innovations in Theoretical Computer Science
  (ITCS) 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00069</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Image Harmonization</dc:title>
 <dc:creator>Tsai, Yi-Hsuan</dc:creator>
 <dc:creator>Shen, Xiaohui</dc:creator>
 <dc:creator>Lin, Zhe</dc:creator>
 <dc:creator>Sunkavalli, Kalyan</dc:creator>
 <dc:creator>Lu, Xin</dc:creator>
 <dc:creator>Yang, Ming-Hsuan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Compositing is one of the most common operations in photo editing. To
generate realistic composites, the appearances of foreground and background
need to be adjusted to make them compatible. Previous approaches to harmonize
composites have focused on learning statistical relationships between
hand-crafted appearance features of the foreground and background, which is
unreliable especially when the contents in the two layers are vastly different.
In this work, we propose an end-to-end deep convolutional neural network for
image harmonization, which can capture both the context and semantic
information of the composite images during harmonization. We also introduce an
efficient way to collect large-scale and high-quality training data that can
facilitate the training process. Experiments on the synthesized dataset and
real composite images show that the proposed network outperforms previous
state-of-the-art methods.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00073</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Physically unclonable function using initial waveform of ring
  oscillators on 65 nm CMOS technology</dc:title>
 <dc:creator>Tanamoto, Tetsufumi</dc:creator>
 <dc:creator>Takaya, Satoshi</dc:creator>
 <dc:creator>Sakamoto, Nobuaki</dc:creator>
 <dc:creator>Kasho, Hirotsugu</dc:creator>
 <dc:creator>Yasuda, Shinichi</dc:creator>
 <dc:creator>Marukame, Takao</dc:creator>
 <dc:creator>Fujita, Shinobu</dc:creator>
 <dc:creator>Mitani, Yuichiro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  A silicon physically unclonable function (PUF) using ring oscillators (ROs)
has the advantage of easy application in both an application specific
integrated circuit (ASIC) and a field-programmable gate array (FPGA). Here, we
provide a RO-PUF using the initial waveform of the ROs based on 65 nm CMOS
technology. Compared with the conventional RO-PUF, the number of ROs is greatly
reduced and the time needed to generate an ID is within a couple of system
clocks.
</dc:description>
 <dc:description>Comment: 5 pages, 9 figures</dc:description>
 <dc:date>2017-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00073</dc:identifier>
 <dc:identifier>Jpn. J. Appl. Phys. 56, 04CF13 (2017)</dc:identifier>
 <dc:identifier>doi:10.7567/JJAP.56.04CF13</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00075</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discrete Wavelet Transform Based Algorithm for Recognition of QRS
  Complexes</dc:title>
 <dc:creator>Haddadi, Rachid</dc:creator>
 <dc:creator>Abdelmounim, Elhassane</dc:creator>
 <dc:creator>Hanine, Mustapha El</dc:creator>
 <dc:creator>Belaguid, Abdelaziz</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes the application of Discrete Wavelet Transform (DWT) to
detect the QRS (ECG is characterized by a recurrent wave sequence of P, QRS and
T-wave) of an electrocardiogram (ECG) signal. Wavelet Transform provides
localization in both time and frequency. In preprocessing stage, DWT is used to
remove the baseline wander in the ECG signal. The performance of the algorithm
of QRS detection is evaluated against the standard MIT BIH (Massachusetts
Institute of Technology, Beth Israel Hospital) Arrhythmia database. The average
QRS complexes detection rate of 98.1 % is achieved.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00075</dc:identifier>
 <dc:identifier>World of Computer Science and Information Technology Journal
  (WCSIT) ; ISSN: 2221-0741; Vol. 4, No. 9, 127-132, 2014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00079</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fault Tolerant Thermal Control of Steam Turbine Shell Deflections</dc:title>
 <dc:creator>Geveci, Mert</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The metal-to-metal clearances of a steam turbine during full or part load
operation are among the main drivers of efficiency. The requirement to add
clearances is driven by a number of factors including the relative movements of
the steam turbine shell and rotor during transient conditions such as startup
and shutdown. This paper includes a description of a control algorithm to
manage external heating blankets for the thermal control of the shell
deflections during turbine shutdown. The proposed method is tolerant of changes
in the heat loss characteristics of the system as well as simultaneous
component failures.
</dc:description>
 <dc:description>Comment: Six pages, nine figures, and one table</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00079</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00080</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Computation of Subspace Skyline over Categorical Domains</dc:title>
 <dc:creator>Rahman, Md Farhadur</dc:creator>
 <dc:creator>Asudeh, Abolfazl</dc:creator>
 <dc:creator>Koudas, Nick</dc:creator>
 <dc:creator>Das, Gautam</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Platforms such as AirBnB, Zillow, Yelp, and related sites have transformed
the way we search for accommodation, restaurants, etc. The underlying datasets
in such applications have numerous attributes that are mostly Boolean or
Categorical. Discovering the skyline of such datasets over a subset of
attributes would identify entries that stand out while enabling numerous
applications. There are only a few algorithms designed to compute the skyline
over categorical attributes, yet are applicable only when the number of
attributes is small.
  In this paper, we place the problem of skyline discovery over categorical
attributes into perspective and design efficient algorithms for two cases. (i)
In the absence of indices, we propose two algorithms, ST-S and ST-P, that
exploits the categorical characteristics of the datasets, organizing tuples in
a tree data structure, supporting efficient dominance tests over the candidate
set. (ii) We then consider the existence of widely used precomputed sorted
lists. After discussing several approaches, and studying their limitations, we
propose TA-SKY, a novel threshold style algorithm that utilizes sorted lists.
Moreover, we further optimize TA-SKY and explore its progressive nature, making
it suitable for applications with strict interactive requirements. In addition
to the extensive theoretical analysis of the proposed algorithms, we conduct a
comprehensive experimental evaluation of the combination of real (including the
entire AirBnB data collection) and synthetic datasets to study the practicality
of the proposed algorithms. The results showcase the superior performance of
our techniques, outperforming applicable approaches by orders of magnitude.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00083</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Frequency Control with Operational Constraints, Part II:
  Network Power Balance</dc:title>
 <dc:creator>Wang, Zhaojian</dc:creator>
 <dc:creator>Liu, Feng</dc:creator>
 <dc:creator>Low, Steven H.</dc:creator>
 <dc:creator>Zhao, Changhong</dc:creator>
 <dc:creator>Mei, Shengwei</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In Part I of this paper we propose a decentralized optimal frequency control
of multi-area power system with operational constraints, where the tie-line
powers remain unchanged in the steady state and the power mismatch is balanced
within individual control areas. In Part II of the paper, we propose a
distributed controller for optimal frequency control in the network power
balance case, where the power mismatch is balanced over the whole system. With
the proposed controller, the tie-line powers remain within the acceptable range
at equilibrium, while the regulation capacity constraints are satisfied both at
equilibrium and during transient. It is revealed that the closed-loop system
with the proposed controller carries out primal-dual updates with saturation
for solving an associated optimization problem. To cope with discontinuous
dynamics of the closed-loop system, we deploy the invariance principle for
nonpathological Lyapunov function to prove its asymptotic stability. Simulation
results are provided to show the effectiveness of our controller.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00084</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Sensor Data Pattern Recognition for Multi-Target Localization: A
  Machine Learning Approach</dc:title>
 <dc:creator>Suresh, Kasthurirengan</dc:creator>
 <dc:creator>Silva, Samuel</dc:creator>
 <dc:creator>Votion, Johnathan</dc:creator>
 <dc:creator>Cao, Yongcan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Data-target pairing is an important step towards multi-target localization
for the intelligent operation of unmanned systems. Target localization plays a
crucial role in numerous applications, such as search, and rescue missions,
traffic management and surveillance. The objective of this paper is to present
an innovative target location learning approach, where numerous machine
learning approaches, including K-means clustering and supported vector machines
(SVM), are used to learn the data pattern across a list of spatially
distributed sensors. To enable the accurate data association from different
sensors for accurate target localization, appropriate data pre-processing is
essential, which is then followed by the application of different machine
learning algorithms to appropriately group data from different sensors for the
accurate localization of multiple targets. Through simulation examples, the
performance of these machine learning algorithms is quantified and compared.
</dc:description>
 <dc:description>Comment: submitted for conference publication</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00087</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised Saliency Map Driven Segmentation of the Lesions in
  Dermoscopic Images</dc:title>
 <dc:creator>Jahanifar, Mostafa</dc:creator>
 <dc:creator>Tajeddin, Neda Zamani</dc:creator>
 <dc:creator>Asl, Babak Mohammadzadeh</dc:creator>
 <dc:creator>Gooya, Ali</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lesion segmentation is the first step in the most automatic melanoma
recognition systems. There are some deficiencies and difficulties in
dermoscopic images that make the lesion segmentation an intricate task e.g.,
hair occlusion, presence of dark corners and color charts, indistinct lesion
borders, and lesions touching the image boundaries. In order to overcome these
problems, we proposed a supervised saliency detection method specially tailored
for dermoscopic images based on the discriminative regional feature integration
(DRFI) method. DRFI method incorporates multi-level segmentation, regional
contrast, property and backgroundness descriptors, and a random forest
regressor to create saliency scores for each region in the image. In our
improved saliency detection method, mDRFI, we have introduced some features as
regional property descriptors and proposed a novel pseudo-background region to
boost the performance. The overall segmentation framework uses the saliency map
to construct an initial mask of the lesion through thresholding and
post-processing operations. The initial mask is then evolving in a level set
framework to fit better on the lesion boundaries. Results of evaluation
experiments on three public datasets show that our proposed segmentation method
outperforms the other conventional state-of-the-art segmentation algorithms and
its performance is comparable with the most recent deep convolutional neural
networks based approaches.
</dc:description>
 <dc:description>Comment: ISIC2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00087</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00089</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Joint Identification Approach for Argumentative Writing Revisions</dc:title>
 <dc:creator>Zhang, Fan</dc:creator>
 <dc:creator>Litman, Diane</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Prior work on revision identification typically uses a pipeline method:
revision extraction is first conducted to identify the locations of revisions
and revision classification is then conducted on the identified revisions. Such
a setting propagates the errors of the revision extraction step to the revision
classification step. This paper proposes an approach that identifies the
revision location and the revision type jointly to solve the issue of error
propagation. It utilizes a sequence representation of revisions and conducts
sequence labeling for revision identification. A mutation-based approach is
utilized to update identification sequences. Results demonstrate that our
proposed approach yields better performance on both revision location
extraction and revision type classification compared to a pipeline baseline.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00095</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active End-Effector Pose Selection for Tactile Object Recognition
  through Monte Carlo Tree Search</dc:title>
 <dc:creator>Zhang, Mabel M.</dc:creator>
 <dc:creator>Atanasov, Nikolay</dc:creator>
 <dc:creator>Daniilidis, Kostas</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper considers the problem of active object recognition using touch
only. The focus is on adaptively selecting a sequence of wrist poses that
achieves accurate recognition by enclosure grasps. It seeks to minimize the
number of touches and maximize recognition confidence. The actions are
formulated as wrist poses relative to each other, making the algorithm
independent of absolute workspace coordinates. The optimal sequence is
approximated by Monte Carlo tree search. We demonstrate results in a physics
engine and on a real robot. In the physics engine, most object instances were
recognized in at most 16 grasps. On a real robot, our method recognized objects
in 2--9 grasps and outperformed a greedy baseline.
</dc:description>
 <dc:description>Comment: Accepted to International Conference on Intelligent Robots and
  Systems (IROS) 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00096</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence
  Labelling</dc:title>
 <dc:creator>Liu, Hairong</dc:creator>
 <dc:creator>Zhu, Zhenyao</dc:creator>
 <dc:creator>Li, Xiangang</dc:creator>
 <dc:creator>Satheesh, Sanjeev</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Most existing sequence labelling models rely on a fixed decomposition of a
target sequence into a sequence of basic units. These methods suffer from two
major drawbacks: 1) the set of basic units is fixed, such as the set of words,
characters or phonemes in speech recognition, and 2) the decomposition of
target sequences is fixed. These drawbacks usually result in sub-optimal
performance of modeling sequences. In this pa- per, we extend the popular CTC
loss criterion to alleviate these limitations, and propose a new loss function
called Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically
learns the best set of basic units (grams), as well as the most suitable
decomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to
output variable number of characters at each time step, which enables the model
to capture longer term dependency and improves the computational efficiency. We
demonstrate that the proposed Gram-CTC improves CTC in terms of both
performance and efficiency on the large vocabulary speech recognition task at
multiple scales of data, and that with Gram-CTC we can outperform the
state-of-the-art on a standard speech benchmark.
</dc:description>
 <dc:description>Comment: Published at ICML 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00096</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00099</identifier>
 <datestamp>2018-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Conversational Systems that Interleave Task and Non-Task
  Content</dc:title>
 <dc:creator>Yu, Zhou</dc:creator>
 <dc:creator>Black, Alan W</dc:creator>
 <dc:creator>Rudnicky, Alexander I.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Task-oriented dialog systems have been applied in various tasks, such as
automated personal assistants, customer service providers and tutors. These
systems work well when users have clear and explicit intentions that are
well-aligned to the systems' capabilities. However, they fail if users
intentions are not explicit. To address this shortcoming, we propose a
framework to interleave non-task content (i.e. everyday social conversation)
into task conversations. When the task content fails, the system can still keep
the user engaged with the non-task content. We trained a policy using
reinforcement learning algorithms to promote long-turn conversation coherence
and consistency, so that the system can have smooth transitions between task
and non-task content. To test the effectiveness of the proposed framework, we
developed a movie promotion dialog system. Experiments with human users
indicate that a system that interleaves social and task content achieves a
better task success rate and is also rated as more engaging compared to a pure
task-oriented system.
</dc:description>
 <dc:description>Comment: Dialog Systems, Reinforcement Learning</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00099</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00102</identifier>
 <datestamp>2017-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SARAH: A Novel Method for Machine Learning Problems Using Stochastic
  Recursive Gradient</dc:title>
 <dc:creator>Nguyen, Lam M.</dc:creator>
 <dc:creator>Liu, Jie</dc:creator>
 <dc:creator>Scheinberg, Katya</dc:creator>
 <dc:creator>Tak&#xe1;&#x10d;, Martin</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH),
as well as its practical variant SARAH+, as a novel approach to the finite-sum
minimization problems. Different from the vanilla SGD and other modern
stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple
recursive framework for updating stochastic gradient estimates; when comparing
to SAG/SAGA, SARAH does not require a storage of past gradients. The linear
convergence rate of SARAH is proven under strong convexity assumption. We also
prove a linear convergence rate (in the strongly convex case) for an inner loop
of SARAH, the property that SVRG does not possess. Numerical experiments
demonstrate the efficiency of our algorithm.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00102</dc:identifier>
 <dc:identifier>Proceedings of the 34th International Conference on Machine
  Learning, PMLR 70:2613-2621, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00104</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Beamforming and Antenna Selection for Sum Rate Maximization in
  Cognitive Radio Networks</dc:title>
 <dc:creator>Nguyen, Van-Dinh</dc:creator>
 <dc:creator>Nguyen, Chuyen T.</dc:creator>
 <dc:creator>Nguyen, Hieu V.</dc:creator>
 <dc:creator>Shin, Oh-Soon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This letter studies joint transmit beamforming and antenna selection at a
secondary base station (BS) with multiple primary users (PUs) in an underlay
cognitive radio multiple-input single-output broadcast channel. The objective
is to maximize the sum rate subject to the secondary BS transmit power, minimum
required rates for secondary users, and PUs' interference power constraints.
The utility function of interest is nonconcave and the involved constraints are
nonconvex, so this problem is hard to solve. Nevertheless, we propose a new
iterative algorithm that finds local optima at the least. We use an inner
approximation method to construct and solve a simple convex quadratic program
of moderate dimension at each iteration of the proposed algorithm. Simulation
results indicate that the proposed algorithm converges quickly and outperforms
existing approaches.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00112</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Enclosing Circle of a Set of Static Points with Dynamic Weight
  from One Free Point</dc:title>
 <dc:creator>Qiu, Lei</dc:creator>
 <dc:creator>Zhang, Yu</dc:creator>
 <dc:creator>Zhang, Li</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Given a set $S$ of $n$ static points and a free point $p$ in the Euclidean
plane, we study a new variation of the minimum enclosing circle problem, in
which a dynamic weight that equals to the reciprocal of the distance from the
free point $p$ to the undetermined circle center is included. In this work, we
prove the optimal solution of the new problem is unique and lies on the
boundary of the farthest-point Voronoi diagram of $S$, once $p$ does not
coincide with any vertex of the convex hull of $S$. We propose a tree structure
constructed from the boundary of the farthest-point Voronoi diagram and use the
hierarchical relationship between edges to locate the optimal solution. The
plane could be divide into at most $3n-4$ non-overlapping regions. When $p$
lies in one of the regions, the optimal solution locates at one node or lies on
the interior of one edge in the boundary of the farthest-point Voronoi diagram.
Moreover, we apply the new variation to calculate the maximum displacement of
one point $p$ under the condition that the displacements of points in $S$ are
restricted in 2D rigid motion.
</dc:description>
 <dc:description>Comment: 14 pages, 8 figures</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00119</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dual Iterative Hard Thresholding: From Non-convex Sparse Minimization to
  Non-smooth Concave Maximization</dc:title>
 <dc:creator>Liu, Bo</dc:creator>
 <dc:creator>Yuan, Xiao-Tong</dc:creator>
 <dc:creator>Wang, Lezi</dc:creator>
 <dc:creator>Liu, Qingshan</dc:creator>
 <dc:creator>Metaxas, Dimitris N.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Iterative Hard Thresholding (IHT) is a class of projected gradient descent
methods for optimizing sparsity-constrained minimization models, with the best
known efficiency and scalability in practice. As far as we know, the existing
IHT-style methods are designed for sparse minimization in primal form. It
remains open to explore duality theory and algorithms in such a non-convex and
NP-hard problem setting. In this paper, we bridge this gap by establishing a
duality theory for sparsity-constrained minimization with $\ell_2$-regularized
loss function and proposing an IHT-style algorithm for dual maximization. Our
sparse duality theory provides a set of sufficient and necessary conditions
under which the original NP-hard/non-convex problem can be equivalently solved
in a dual formulation. The proposed dual IHT algorithm is a super-gradient
method for maximizing the non-smooth dual objective. An interesting finding is
that the sparse recovery performance of dual IHT is invariant to the Restricted
Isometry Property (RIP), which is required by virtually all the existing primal
IHT algorithms without sparsity relaxation. Moreover, a stochastic variant of
dual IHT is proposed for large-scale stochastic optimization. Numerical results
demonstrate the superiority of dual IHT algorithms to the state-of-the-art
primal IHT-style algorithms in model estimation accuracy and computational
efficiency.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00119</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00120</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Capturing Distribution Grid-Integrated Solar Variability and Uncertainty
  Using Microgrids</dc:title>
 <dc:creator>Majzoobi, Alireza</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:creator>Bahramirad, Shay</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The variable nature of the solar generation and the inherent uncertainty in
solar generation forecasts are two challenging issues for utility grids,
especially as the distribution grid integrated solar generation proliferates.
This paper offers to utilize microgrids as local solutions for mitigating these
negative drawbacks and helping the utility grid in hosting a higher penetration
of solar generation. A microgrid optimal scheduling model based on robust
optimization is developed to capture solar generation variability and
uncertainty. Numerical simulations on a test feeder indicate the effectiveness
of the proposed model.
</dc:description>
 <dc:description>Comment: IEEE Power and Energy Society General Meeting, 2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00121</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Remote Sensing Image Scene Classification: Benchmark and State of the
  Art</dc:title>
 <dc:creator>Cheng, Gong</dc:creator>
 <dc:creator>Han, Junwei</dc:creator>
 <dc:creator>Lu, Xiaoqiang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remote sensing image scene classification plays an important role in a wide
range of applications and hence has been receiving remarkable attention. During
the past years, significant efforts have been made to develop various datasets
or present a variety of approaches for scene classification from remote sensing
images. However, a systematic review of the literature concerning datasets and
methods for scene classification is still lacking. In addition, almost all
existing datasets have a number of limitations, including the small scale of
scene classes and the image numbers, the lack of image variations and
diversity, and the saturation of accuracy. These limitations severely limit the
development of new approaches especially deep learning-based methods. This
paper first provides a comprehensive review of the recent progress. Then, we
propose a large-scale dataset, termed &quot;NWPU-RESISC45&quot;, which is a publicly
available benchmark for REmote Sensing Image Scene Classification (RESISC),
created by Northwestern Polytechnical University (NWPU). This dataset contains
31,500 images, covering 45 scene classes with 700 images in each class. The
proposed NWPU-RESISC45 (i) is large-scale on the scene classes and the total
image number, (ii) holds big variations in translation, spatial resolution,
viewpoint, object pose, illumination, background, and occlusion, and (iii) has
high within-class diversity and between-class similarity. The creation of this
dataset will enable the community to develop and evaluate various data-driven
algorithms. Finally, several representative methods are evaluated using the
proposed dataset and the results are reported as a useful baseline for future
research.
</dc:description>
 <dc:description>Comment: This manuscript is the accepted version for Proceedings of the IEEE</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00121</dc:identifier>
 <dc:identifier>doi:10.1109/JPROC.2017.2675998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00122</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RGB-D Salient Object Detection Based on Discriminative Cross-modal
  Transfer Learning</dc:title>
 <dc:creator>Chen, Hao</dc:creator>
 <dc:creator>Li, Y. F.</dc:creator>
 <dc:creator>Su, Dan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose to utilize Convolutional Neural Networks to boost
the performance of depth-induced salient object detection by capturing the
high-level representative features for depth modality. We formulate the
depth-induced saliency detection as a CNN-based cross-modal transfer problem to
bridge the gap between the &quot;data-hungry&quot; nature of CNNs and the unavailability
of sufficient labeled training data in depth modality. In the proposed
approach, we leverage the auxiliary data from the source modality effectively
by training the RGB saliency detection network to obtain the task-specific
pre-understanding layers for the target modality. Meanwhile, we exploit the
depth-specific information by pre-training a modality classification network
that encourages modal-specific representations during the optimizing course.
Thus, it could make the feature representations of the RGB and depth modalities
as discriminative as possible. These two modules are pre-trained independently
and then stitched to initialize and optimize the eventual depth-induced
saliency detection model. Experiments demonstrate the effectiveness of the
proposed novel pre-training strategy as well as the significant and consistent
improvements of the proposed approach over other state-of-the-art methods.
</dc:description>
 <dc:description>Comment: This paper has been rejected by CVPR2017, we plan to withdraw this
  manuscript for further revision</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00123</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DTNC: A New Server-side Data Cleansing Framework for Cellular Trajectory
  Services</dc:title>
 <dc:creator>Dai, Jian</dc:creator>
 <dc:creator>He, Fei</dc:creator>
 <dc:creator>Lee, Wang-Chien</dc:creator>
 <dc:creator>Chen, Gang</dc:creator>
 <dc:creator>Ooi, Beng Chin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  It is essential for the cellular network operators to provide cellular
location services to meet the needs of their users and mobile applications.
However, cellular locations, estimated by network-based methods at the
server-side, bear with {\it high spatial errors} and {\it arbitrary missing
locations}. Moreover, auxiliary sensor data at the client-side are not
available to the operators. In this paper, we study the {\em cellular
trajectory cleansing problem} and propose an innovative data cleansing
framework, namely \underline{D}ynamic \underline{T}ransportation
\underline{N}etwork based \underline{C}leansing (DTNC) to improve the quality
of cellular locations delivered in online cellular trajectory services. We
maintain a dynamic transportation network (DTN), which associates a network
edge with a probabilistic distribution of travel times updated continuously. In
addition, we devise an object motion model, namely, {\em travel-time-aware
hidden semi-Markov model} ({\em TT-HsMM}), which is used to infer the most
probable traveled edge sequences on DTN. To validate our ideas, we conduct a
comprehensive evaluation using real-world cellular data provided by a major
cellular network operator and a GPS dataset collected by smartphones as the
ground truth. In the experiments, DTNC displays significant advantages over six
state-of-the-art techniques.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00132</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting Unsupervised Learning for Defect Prediction</dc:title>
 <dc:creator>Fu, Wei</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Collecting quality data from software projects can be time-consuming and
expensive. Hence, some researchers explore &quot;unsupervised&quot; approaches to quality
prediction that does not require labelled data. An alternate technique is to
use &quot;supervised&quot; approaches that learn models from project data labelled with,
say, &quot;defective&quot; or &quot;not-defective&quot;. Most researchers use these supervised
models since, it is argued, they can exploit more knowledge of the projects.
  At FSE'16, Yang et al. reported startling results where unsupervised defect
predictors outperformed supervised predictors for effort-aware just-in-time
defect prediction. If confirmed, these results would lead to a dramatic
simplification of a seemingly complex task (data mining) that is widely
explored in the software engineering literature.
  This paper repeats and refutes those results as follows. (1) There is much
variability in the efficacy of the Yang et al. predictors so even with their
approach, some supervised data is required to prune weaker predictors away.
(2)Their findings were grouped across $N$ projects. When we repeat their
analysis on a project-by-project basis, supervised predictors are seen to work
better.
  Even though this paper rejects the specific conclusions of Yang et al., we
still endorse their general goal. In our our experiments, supervised predictors
did not perform outstandingly better than unsupervised ones for effort-aware
just-in-time defect prediction. Hence, they may indeed be some combination of
unsupervised learners to achieve comparable performance to supervised ones. We
therefore encourage others to work in this promising area.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures. Accepted at FSE2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00132</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3106257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00133</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Easy over Hard: A Case Study on Deep Learning</dc:title>
 <dc:creator>Fu, Wei</dc:creator>
 <dc:creator>Menzies, Tim</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  While deep learning is an exciting new technique, the benefits of this method
need to be assessed with respect to its computational cost. This is
particularly important for deep learning since these learners need hours (to
weeks) to train the model. Such long training time limits the ability of (a)~a
researcher to test the stability of their conclusion via repeated runs with
different random seeds; and (b)~other researchers to repeat, improve, or even
refute that original work.
  For example, recently, deep learning was used to find which questions in the
Stack Overflow programmer discussion forum can be linked together. That deep
learning system took 14 hours to execute. We show here that applying a very
simple optimizer called DE to fine tune SVM, it can achieve similar (and
sometimes better) results. The DE approach terminated in 10 minutes; i.e. 84
times faster hours than deep learning method.
  We offer these results as a cautionary tale to the software analytics
community and suggest that not every new innovation should be applied without
critical analysis. If researchers deploy some new and expensive process, that
work should be baselined against some simpler and faster alternatives.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, accepted at FSE2017</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:date>2017-06-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00133</dc:identifier>
 <dc:identifier>doi:10.1145/3106237.3106256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00134</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collision Resolution and Interference Elimination in Multiaccess
  Communication Networks</dc:title>
 <dc:creator>Akl, Naeem</dc:creator>
 <dc:creator>Tewfik, Ahmed</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We define a multiaccess communication scheme that effectively eliminates
interference and resolves collisions in many-to-one and many-to-many
communication scenarios. Each transmitter is uniquely identified by a steering
vector. All signals issued from a specific transmitter will be steered into the
same single-dimensional or double-dimensional subspace at all receivers hearing
this transmission. This subspace is orthogonal to the noise subspace at a
receiver and the signals within the subspace can be extracted using the
root-MUSIC method. At high SNR, local channel knowledge and strict
synchronization, the algorithm asymptotically achieves full network capacity on
condition that a channel remains constant within a single time slot. Without
synchronization, the worst case asymptotic performance is still greater than
the $50\%$ throughput achieved by collision resolution algorithms and
interference management techniques like interference alignment.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00143</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Codebook Design for Channel Feedback in Lens-Based Millimeter-Wave
  Massive MIMO Systems</dc:title>
 <dc:creator>Shen, Wenqian</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Li, Yue</dc:creator>
 <dc:creator>Wang, Zhaocheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The number of radio frequency (RF) chains can be reduced through beam
selection in lens-based millimeter-wave (mmWave) massive MIMO systems, where
the equivalent channel between RF chains and multiple users is required at the
BS to achieve the multi-user multiplexing gain. However, to the best of our
knowledge, there is no dedicated codebook for the equivalent channel feedback
in such systems. In this paper, we propose the dimension-reduced subspace
codebook, which achieves a significant reduction of the feedback overhead and
codebook size. Specifically, we firstly utilize the limited scattering property
of mmWave channels to generate the high-dimensional vectors in the channel
subspace. Then, according to the function of lens and beam selector, we propose
the dimension-reduced subspace codebook to quantize the equivalent channel
vector.Moreover, the performance analysis of the proposed codebook is also
provided.Finally, simulation results show the superior performance of the
proposed dimension-reduced subspace codebook compared with conventional
codebooks.
</dc:description>
 <dc:description>Comment: Submitted to SPL for publication</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00144</identifier>
 <datestamp>2017-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Theoretical Properties for Neural Networks with Weight Matrices of Low
  Displacement Rank</dc:title>
 <dc:creator>Zhao, Liang</dc:creator>
 <dc:creator>Liao, Siyu</dc:creator>
 <dc:creator>Wang, Yanzhi</dc:creator>
 <dc:creator>Li, Zhe</dc:creator>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Pan, Victor</dc:creator>
 <dc:creator>Yuan, Bo</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Recently low displacement rank (LDR) matrices, or so-called structured
matrices, have been proposed to compress large-scale neural networks. Empirical
results have shown that neural networks with weight matrices of LDR matrices,
referred as LDR neural networks, can achieve significant reduction in space and
computational complexity while retaining high accuracy. We formally study LDR
matrices in deep learning. First, we prove the universal approximation property
of LDR neural networks with a mild condition on the displacement operators. We
then show that the error bounds of LDR neural networks are as efficient as
general neural networks with both single-layer and multiple-layer structure.
Finally, we propose back-propagation based training algorithm for general LDR
neural networks.
</dc:description>
 <dc:description>Comment: 13 pages, 1 figure</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-09-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00144</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00147</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Beamforming for Secrecy Rate in Cooperative Cognitive Radio
  Multicast Communications</dc:title>
 <dc:creator>Nguyen, Van-Dinh</dc:creator>
 <dc:creator>Duong, Trung Q.</dc:creator>
 <dc:creator>Shin, Oh-Soon</dc:creator>
 <dc:creator>Nallanathan, Arumugam</dc:creator>
 <dc:creator>Karagiannidis, George K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a cooperative approach to improve the security of
both primary and secondary systems in cognitive radio multicast communications.
During their access to the frequency spectrum licensed to the primary users,
the secondary unlicensed users assist the primary system in fortifying security
by sending a jamming noise to the eavesdroppers, while simultaneously protect
themselves from eavesdropping. The main objective of this work is to maximize
the secrecy rate of the secondary system, while adhering to all individual
primary users' secrecy rate constraints. In the case of passive eavesdroppers
and imperfect channel state information knowledge at the transceivers, the
utility function of interest is nonconcave and involved constraints are
nonconvex, and thus, the optimal solutions are troublesome. To address this
problem, we propose an iterative algorithm to arrive at a local optimum of the
considered problem. The proposed iterative algorithm is guaranteed to achieve a
Karush-Kuhn-Tucker solution.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, IEEE ICC 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00147</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00152</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency Detection by Forward and Backward Cues in Deep-CNNs</dc:title>
 <dc:creator>Imamoglu, Nevrez</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Shimoda, Wataru</dc:creator>
 <dc:creator>Fang, Yuming</dc:creator>
 <dc:creator>Shi, Boxin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  As prior knowledge of objects or object features helps us make relations for
similar objects on attentional tasks, pre-trained deep convolutional neural
networks (CNNs) can be used to detect salient objects on images regardless of
the object class is in the network knowledge or not. In this paper, we propose
a top-down saliency model using CNN, a weakly supervised CNN model trained for
1000 object labelling task from RGB images. The model detects attentive regions
based on their objectness scores predicted by selected features from CNNs. To
estimate the salient objects effectively, we combine both forward and backward
features, while demonstrating that partially-guided backpropagation will
provide sufficient information for selecting the features from forward run of
CNN model. Finally, these top-down cues are enhanced with a state-of-the-art
bottom-up model as complementing the overall saliency. As the proposed model is
an effective integration of forward and backward cues through objectness
without any supervision or regression to ground truth data, it gives promising
results compared to state-of-the-art models in two different datasets.
</dc:description>
 <dc:description>Comment: 5 pages,4 figures,and 1 table. the content of this work is accepted
  for ICIP 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00152</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00154</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inertial Odometry on Handheld Smartphones</dc:title>
 <dc:creator>Solin, Arno</dc:creator>
 <dc:creator>Cortes, Santiago</dc:creator>
 <dc:creator>Rahtu, Esa</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Building a complete inertial navigation system using the limited quality data
provided by current smartphones has been regarded challenging, if not
impossible. We present a probabilistic approach for orientation and use-case
free inertial odometry, which is based on double-integrating rotated
accelerations. Our approach uses a probabilistic approach in fusing the noisy
sensor data and learning the model parameters online. It is able to track the
phone position, velocity, and pose in real-time and in a computationally
lightweight fashion. The information fusion is completed with altitude
correction from barometric pressure readings (if available), zero-velocity
updates (if the phone remains stationary), and pseudo-updates limiting the
momentary speed. We demonstrate our approach using a standard iPad and iPhone
in several indoor dead-reckoning applications and in a measurement tool setup.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00159</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Calculus for True Concurrency</dc:title>
 <dc:creator>Wang, Yong</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We design a calculus for true concurrency called CTC, including its syntax
and operational semantics. CTC has good properties modulo several kinds of
strongly truly concurrent bisimulations and weakly truly concurrent
bisimulations, such as monoid laws, static laws, new expansion law for strongly
truly concurrent bisimulations, $\tau$ laws for weakly truly concurrent
bisimulations, and full congruences for strongly and weakly truly concurrent
bisimulations, and also unique solution for recursion.
</dc:description>
 <dc:description>Comment: 31 pages, 1 figures. arXiv admin note: text overlap with
  arXiv:1611.09035</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00160</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Saliency Fusion in Eigenvector Space with Multi-Channel Pulse Coupled
  Neural Network</dc:title>
 <dc:creator>Imamoglu, Nevrez</dc:creator>
 <dc:creator>Wei, Zhixuan</dc:creator>
 <dc:creator>Shi, Huangjun</dc:creator>
 <dc:creator>Yoshida, Yuki</dc:creator>
 <dc:creator>Nergui, Myagmarbayar</dc:creator>
 <dc:creator>Gonzalez, Jose</dc:creator>
 <dc:creator>Gu, Dongyun</dc:creator>
 <dc:creator>Chen, Weidong</dc:creator>
 <dc:creator>Nonami, Kenzo</dc:creator>
 <dc:creator>Yu, Wenwei</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Saliency computation has become a popular research field for many
applications due to the useful information provided by saliency maps. For a
saliency map, local relations around the salient regions in multi-channel
perspective should be taken into consideration by aiming uniformity on the
region of interest as an internal approach. And, irrelevant salient regions
have to be avoided as much as possible. Most of the works achieve these
criteria with external processing modules; however, these can be accomplished
during the conspicuity map fusion process. Therefore, in this paper, a new
model is proposed for saliency/conspicuity map fusion with two concepts: a)
input image transformation relying on the principal component analysis (PCA),
and b) saliency conspicuity map fusion with multi-channel pulsed coupled neural
network (m-PCNN). Experimental results, which are evaluated by precision,
recall, F-measure, and area under curve (AUC), support the reliability of the
proposed method by enhancing the saliency computation.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, 1 table. This submission includes detailed
  explanation of partial section (saliency detection) of the work &quot;An Improved
  Saliency for RGB-D Visual Tracking and Control Strategies for a
  Bio-monitoring Mobile Robot&quot;, Evaluating AAL Systems Through Competitive
  Benchmarking, Communications in Computer and Information Science, vol. 386,
  pp.1-12, 2013</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00160</dc:identifier>
 <dc:identifier>Evaluating AAL Systems Through Competitive Benchmarking,
  Communications in Computer and Information Science, 2013</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-642-41043-7_1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00168</identifier>
 <datestamp>2017-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modular Representation of Layered Neural Networks</dc:title>
 <dc:creator>Watanabe, Chihiro</dc:creator>
 <dc:creator>Hiramatsu, Kaoru</dc:creator>
 <dc:creator>Kashino, Kunio</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Layered neural networks have greatly improved the performance of various
applications including image processing, speech recognition, natural language
processing, and bioinformatics. However, it is still difficult to discover or
interpret knowledge from the inference provided by a layered neural network,
since its internal representation has many nonlinear and complex parameters
embedded in hierarchical layers. Therefore, it becomes important to establish a
new methodology by which layered neural networks can be understood.
  In this paper, we propose a new method for extracting a global and simplified
structure from a layered neural network. Based on network analysis, the
proposed method detects communities or clusters of units with similar
connection patterns. We show its effectiveness by applying it to three use
cases. (1) Network decomposition: it can decompose a trained neural network
into multiple small independent networks thus dividing the problem and reducing
the computation time. (2) Training assessment: the appropriateness of a trained
result with a given hyperparameter or randomly chosen initial parameters can be
evaluated by using a modularity index. And (3) data analysis: in practical data
it reveals the community structure in the input, hidden, and output layers,
which serves as a clue for discovering knowledge from a trained neural network.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00170</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How long delays impact TCP performance for a connectivity from Reunion
  Island ?</dc:title>
 <dc:creator>Noordally, R&#xe9;han</dc:creator>
 <dc:creator>Nicolay, Xavier</dc:creator>
 <dc:creator>Gangat, Yassine</dc:creator>
 <dc:creator>Anelli, Pascal</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  TCP is the protocol of transport the most used in the Internet and have a
heavy-dependence on delay. Reunion Island have a specific Internet connection,
based on main links to France, located 10.000 km away. As a result, the minimal
delay between Reunion Island and France is around 180 ms. In this paper, we
will study TCP traces collected in Reunion Island University. The goal is to
determine the metrics to study the impacts of long delays on TCP performance.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00170</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00177</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optical Flow-based 3D Human Motion Estimation from Monocular Video</dc:title>
 <dc:creator>Alldieck, Thiemo</dc:creator>
 <dc:creator>Kassubeck, Marc</dc:creator>
 <dc:creator>Magnor, Marcus</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present a generative method to estimate 3D human motion and body shape
from monocular video. Under the assumption that starting from an initial pose
optical flow constrains subsequent human motion, we exploit flow to find
temporally coherent human poses of a motion sequence. We estimate human motion
by minimizing the difference between computed flow fields and the output of an
artificial flow renderer. A single initialization step is required to estimate
motion over multiple frames. Several regularization functions enhance
robustness over time. Our test scenarios demonstrate that optical flow
effectively regularizes the under-constrained problem of human shape and motion
estimation from monocular video.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00178</identifier>
 <datestamp>2017-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Mobile Cellular Networks: Enabling Distributed State Estimation for
  Smart Grids</dc:title>
 <dc:creator>Cosovic, Mirsad</dc:creator>
 <dc:creator>Tsitsimelis, Achilleas</dc:creator>
 <dc:creator>Vukobratovic, Dejan</dc:creator>
 <dc:creator>Matamoros, Javier</dc:creator>
 <dc:creator>Anton-Haro, Carles</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With transition towards 5G, mobile cellular networks are evolving into a
powerful platform for ubiquitous large-scale information acquisition,
communication, storage and processing. 5G will provide suitable services for
mission-critical and real-time applications such as the ones envisioned in
future Smart Grids. In this work, we show how emerging 5G mobile cellular
network, with its evolution of Machine-Type Communications and the concept of
Mobile Edge Computing, provides an adequate environment for distributed
monitoring and control tasks in Smart Grids. In particular, we present in
detail how Smart Grids could benefit from advanced distributed State Estimation
methods placed within 5G environment. We present an overview of emerging
distributed State Estimation solutions, focusing on those based on distributed
optimization and probabilistic graphical models, and investigate their
integration as part of the future 5G Smart Grid services.
</dc:description>
 <dc:description>Comment: 8 pages, 6 figures, version of the magazine paper submitted for
  publication</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00185</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively parallel lattice-Boltzmann codes on large GPU clusters</dc:title>
 <dc:creator>Calore, E.</dc:creator>
 <dc:creator>Gabbana, A.</dc:creator>
 <dc:creator>Kraus, J.</dc:creator>
 <dc:creator>Pellegrini, E.</dc:creator>
 <dc:creator>Schifano, S. F.</dc:creator>
 <dc:creator>Tripiccione, R.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper describes a massively parallel code for a state-of-the art thermal
lattice- Boltzmann method. Our code has been carefully optimized for
performance on one GPU and to have a good scaling behavior extending to a large
number of GPUs. Versions of this code have been already used for large-scale
studies of convective turbulence. GPUs are becoming increasingly popular in HPC
applications, as they are able to deliver higher performance than traditional
processors. Writing efficient programs for large clusters is not an easy task
as codes must adapt to increasingly parallel architectures, and the overheads
of node-to-node communications must be properly handled. We describe the
structure of our code, discussing several key design choices that were guided
by theoretical models of performance and experimental benchmarks. We present an
extensive set of performance measurements and identify the corresponding main
bot- tlenecks; finally we compare the results of our GPU code with those
measured on other currently available high performance processors. Our results
are a production-grade code able to deliver a sustained performance of several
tens of Tflops as well as a design and op- timization methodology that can be
used for the development of other high performance applications for
computational physics.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00185</dc:identifier>
 <dc:identifier>doi:10.1016/j.parco.2016.08.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00186</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance and Portability of Accelerated Lattice Boltzmann
  Applications with OpenACC</dc:title>
 <dc:creator>Calore, E.</dc:creator>
 <dc:creator>Gabbana, A.</dc:creator>
 <dc:creator>Kraus, J.</dc:creator>
 <dc:creator>Schifano, S. F.</dc:creator>
 <dc:creator>Tripiccione, R.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  An increasingly large number of HPC systems rely on heterogeneous
architectures combining traditional multi-core CPUs with power efficient
accelerators. Designing efficient applications for these systems has been
troublesome in the past as accelerators could usually be programmed using
specific programming languages threatening maintainability, portability and
correctness. Several new programming environments try to tackle this problem.
Among them, OpenACC offers a high-level approach based on compiler directive
clauses to mark regions of existing C, C++ or Fortran codes to run on
accelerators. This approach directly addresses code portability, leaving to
compilers the support of each different accelerator, but one has to carefully
assess the relative costs of portable approaches versus computing efficiency.
In this paper we address precisely this issue, using as a test-bench a
massively parallel Lattice Boltzmann algorithm. We first describe our
multi-node implementation and optimization of the algorithm, using OpenACC and
MPI. We then benchmark the code on a variety of processors, including
traditional CPUs and GPUs, and make accurate performance comparisons with other
GPU implementations of the same algorithm using CUDA and OpenCL. We also asses
the performance impact associated to portable programming, and the actual
portability and performance-portability of OpenACC-based applications across
several state-of-the- art architectures.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00186</dc:identifier>
 <dc:identifier>doi:10.1002/cpe.3862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00188</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds on Exponential Moments of the Quadratic Error in Parameter
  Estimation</dc:title>
 <dc:creator>Merhav, Neri</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Considering the problem of risk-sensitive parameter estimation, we propose a
fairly wide family of lower bounds on the exponential moments of the quadratic
error, both in the Bayesian and the non--Bayesian regime. This family of
bounds, which is based on a change of measures, offers considerable freedom in
the choice of the reference measure, and our efforts are devoted to explore
this freedom to a certain extent. Our focus is mostly on signal models that are
relevant to communication problems, namely, models of a parameter-dependent
signal (modulated signal) corrupted by additive white Gaussian noise, but the
methodology proposed is also applicable to other types of parametric families,
such as models of linear systems driven by random input signals (white noise,
in most cases), and others. In addition to the well known motivations of the
risk-sensitive cost function (i.e., the exponential quadratic cost function),
which is most notably, the robustness to model uncertainty, we also view this
cost function as a tool for studying fundamental limits concerning the tail
behavior of the estimation error. Another interesting aspect, that we
demonstrate in a certain parametric model, is that the risk-sensitive cost
function may be subjected to phase transitions, owing to some analogies with
statistical mechanics.
</dc:description>
 <dc:description>Comment: 28 pages; 4 figures; submitted for publication</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00190</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Video transrating in AVC and HEVC transcoding</dc:title>
 <dc:creator>Wegner, Krzysztof</dc:creator>
 <dc:creator>Grajek, Tomasz</dc:creator>
 <dc:creator>Stankowski, Jakub</dc:creator>
 <dc:creator>Domanski, Marek</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  HEVC (MPEG-H Part 2 and H.265) is a new coding technology which is expected
to be deployed on the market along with new video services in the near future.
HEVC is a successor of currently widely used AVC (MPEG-4 Part 10 and H.264). In
this paper, the quality coding gains obtained for the Cascaded Pixel Domain
Transcoder of AVC-coded material to HEVC standard are reported. Extensive
experiments showed that transcoding with bitrate reduction allows the
achievement of better rate-distortion performance than by compressing an
original video sequence with the use of AVC at the same (reduced) bitrate.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00194</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Functional Gradient for Motion Planning in Continuous
  Occupancy Maps</dc:title>
 <dc:creator>Francis, Gilad</dc:creator>
 <dc:creator>Ott, Lionel</dc:creator>
 <dc:creator>Ramos, Fabio</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Safe path planning is a crucial component in autonomous robotics. The many
approaches to find a collision free path can be categorically divided into
trajectory optimisers and sampling-based methods. When planning using occupancy
maps, the sampling-based approach is the prevalent method. The main drawback of
such techniques is that the reasoning about the expected cost of a plan is
limited to the search heuristic used by each method. We introduce a novel
planning method based on trajectory optimisation to plan safe and efficient
paths in continuous occupancy maps. We extend the expressiveness of the
state-of-the-art functional gradient optimisation methods by devising a
stochastic gradient update rule to optimise a path represented as a Gaussian
process. This approach avoids the need to commit to a specific resolution of
the path representation, whether spatial or parametric. We utilise a continuous
occupancy map representation in order to define our optimisation objective,
which enables fast computation of occupancy gradients. We show that this
approach is essential in order to ensure convergence to the optimal path, and
present results and comparisons to other planning methods in both simulation
and with real laser data. The experiments demonstrate the benefits of using
this technique when planning for safe and efficient paths in continuous
occupancy maps.
</dc:description>
 <dc:description>Comment: To appear in the 2017 IEEE International Conference on Robotics and
  Automation (ICRA)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00194</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00195</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two strings at Hamming distance 1 cannot be both quasiperiodic</dc:title>
 <dc:creator>Amir, Amihood</dc:creator>
 <dc:creator>Iliopoulos, Costas S.</dc:creator>
 <dc:creator>Radoszewski, Jakub</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We present a generalization of a known fact from combinatorics on words
related to periodicity into quasiperiodicity. A string is called periodic if it
has a period which is at most half of its length. A string $w$ is called
quasiperiodic if it has a non-trivial cover, that is, there exists a string $c$
that is shorter than $w$ and such that every position in $w$ is inside one of
the occurrences of $c$ in $w$. It is a folklore fact that two strings that
differ at exactly one position cannot be both periodic. Here we prove a more
general fact that two strings that differ at exactly one position cannot be
both quasiperiodic. Along the way we obtain new insights into combinatorics of
quasiperiodicities.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00196</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incorporating Intra-Class Variance to Fine-Grained Visual Recognition</dc:title>
 <dc:creator>Bai, Yan</dc:creator>
 <dc:creator>Gao, Feng</dc:creator>
 <dc:creator>Lou, Yihang</dc:creator>
 <dc:creator>Wang, Shiqi</dc:creator>
 <dc:creator>Huang, Tiejun</dc:creator>
 <dc:creator>Duan, Ling-Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Fine-grained visual recognition aims to capture discriminative
characteristics amongst visually similar categories. The state-of-the-art
research work has significantly improved the fine-grained recognition
performance by deep metric learning using triplet network. However, the impact
of intra-category variance on the performance of recognition and robust feature
representation has not been well studied. In this paper, we propose to leverage
intra-class variance in metric learning of triplet network to improve the
performance of fine-grained recognition. Through partitioning training images
within each category into a few groups, we form the triplet samples across
different categories as well as different groups, which is called Group
Sensitive TRiplet Sampling (GS-TRS). Accordingly, the triplet loss function is
strengthened by incorporating intra-class variance with GS-TRS, which may
contribute to the optimization objective of triplet network. Extensive
experiments over benchmark datasets CompCar and VehicleID show that the
proposed GS-TRS has significantly outperformed state-of-the-art approaches in
both classification and retrieval tasks.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00197</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal and Canonical Images</dc:title>
 <dc:creator>Jefferson, Christopher</dc:creator>
 <dc:creator>Jonauskyte, Eliza</dc:creator>
 <dc:creator>Pfeiffer, Markus</dc:creator>
 <dc:creator>Waldecker, Rebecca</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We describe a family of new algorithms for finding the canonical image of a
set of points under the action of a permutation group. This family of
algorithms makes use of the orbit structure of the group, and a chain of
subgroups of the group, to efficiently reduce the amount of search which must
be performed to find a canonical image.
  We present both a formal proof of correctness of our algorithms and
experiments on different permutation groups, which compare our algorithms with
the previous state of the art.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00198</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Test Case Generation for Program Repair: A Study of Feasibility and
  Effectiveness</dc:title>
 <dc:creator>Yu, Zhongxing</dc:creator>
 <dc:creator>Martinez, Matias</dc:creator>
 <dc:creator>Danglot, Benjamin</dc:creator>
 <dc:creator>Durieux, Thomas</dc:creator>
 <dc:creator>Monperrus, Martin</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Among the many different kinds of program repair techniques, one widely
studied family of techniques is called test suite based repair. Test-suites are
in essence input-output specifications and are therefore typically inadequate
for completely specifying the expected behavior of the program under repair.
Consequently, the patches generated by test suite based program repair
techniques pass the test suite, yet may be incorrect. Patches that are overly
specific to the used test suite and fail to generalize to other test cases are
called overfitting patches. In this paper, we investigate the feasibility and
effectiveness of test case generation in alleviating the overfitting issue. We
propose two approaches for using test case generation to improve test suite
based repair, and perform an extensive evaluation of the effectiveness of the
proposed approaches in enabling better test suite based repair on 224 bugs of
the Defects4J repository. The results indicate that test case generation can
change the resulting patch, but is not effective at turning incorrect patches
into correct ones. We identify the problems related with the ineffectiveness,
and anticipate that our results and findings will lead to future research to
build test-case generation techniques that are tailored to automatic repair
systems.
</dc:description>
 <dc:description>Comment: working paper</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00203</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Frequency patterns of semantic change: Corpus-based evidence of a
  near-critical dynamics in language change</dc:title>
 <dc:creator>Feltgen, Quentin</dc:creator>
 <dc:creator>Fagard, Benjamin</dc:creator>
 <dc:creator>Nadal, Jean-Pierre</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  It is generally believed that, when a linguistic item acquires a new meaning,
its overall frequency of use in the language rises with time with an S-shaped
growth curve. Yet, this claim has only been supported by a limited number of
case studies. In this paper, we provide the first corpus-based quantitative
confirmation of the genericity of the S-curve in language change. Moreover, we
uncover another generic pattern, a latency phase of variable duration preceding
the S-growth, during which the frequency of use of the semantically expanding
word remains low and more or less constant. We also propose a usage-based model
of language change supported by cognitive considerations, which predicts that
both phases, the latency and the fast S-growth, take place. The driving
mechanism is a stochastic dynamics, a random walk in the space of frequency of
use. The underlying deterministic dynamics highlights the role of a control
parameter, the strength of the cognitive impetus governing the onset of change,
which tunes the system at the vicinity of a saddle-node bifurcation. In the
neighborhood of the critical point, the latency phase corresponds to the
diffusion time over the critical region, and the S-growth to the fast
convergence that follows. The duration of the two phases is computed as
specific first passage times of the random walk process, leading to
distributions that fit well the ones extracted from our dataset. We argue that
our results are not specific to the studied corpus, but apply to semantic
change in general.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00203</dc:identifier>
 <dc:identifier>R. Soc. open sci. 2017 4 170830; DOI: 10.1098/rsos.170830.
  Published 8 November 2017</dc:identifier>
 <dc:identifier>doi:10.1098/rsos.170830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00206</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling Agile Development in Mechatronic Organizations - A Comparative
  Case Study</dc:title>
 <dc:creator>Eklund, Ulrik</dc:creator>
 <dc:creator>Berger, Christian</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>K.6.1</dc:subject>
 <dc:description>  Agile software development principles enable companies to successfully and
quickly deliver software by meeting their customers' expectations while
focusing on high quality. Many companies working with pure software systems
have adopted these principles, but implementing them in companies dealing with
non-pure software products is challenging. We identified a set of goals and
practices to support large-scale agile development in companies that develop
software-intense mechatronic systems. We used an inductive approach based on
empirical data collected during a longitudinal study with six companies in the
Nordic region. The data collection took place over two years through focus
group workshops, individual on-site interviews, and complementary surveys. The
primary benefit of large-scale agile development is improved quality, enabled
by practices that support regular or continuous integration between teams
delivering software, hardware, and mechanics. In this regard, the most
beneficial integration cycle for deliveries is every four weeks; while
continuous integra- tion on a daily basis would favor software teams, other
disciplines does not seem to benefit from faster integration cycles. We
identified 108 goals and development practices supporting agile principles
among the companies, most of them concerned with integration; therefrom, 26
agile practices are unique to the mechatronics domain to support adopting agile
beyond pure software development teams. 16 of these practices are considered as
key enablers, confirmed by our control cases.
</dc:description>
 <dc:description>Comment: International Conference on Software Engineering 2017 - Software
  Engineering ni Practice track</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00207</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Quantum-Classical Scheme towards Quantum Functional Encryption</dc:title>
 <dc:creator>Ahuja, Aditya</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Quantum encryption is a well studied problem for both classical and quantum
information. However, little is known about quantum encryption schemes which
enable the user, under different keys, to learn different functions of the
plaintext, given the ciphertext. In this paper, we give a novel one-bit
secret-key quantum encryption scheme, a classical extension of which allows
different key holders to learn different length subsequences of the plaintext
from the ciphertext. We prove our quantum-classical scheme secure under the
notions of quantum semantic security, quantum entropic indistinguishability,
and recent security definitions from the field of functional encryption.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00210</identifier>
 <datestamp>2017-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Erd\&quot;os- R\'enyi Random Graphs Topologically Random?</dc:title>
 <dc:creator>Smith, Keith</dc:creator>
 <dc:creator>Escudero, Javier</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  No. We prove that Erdos- Renyi Random Graphs are not topologically random.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to known results. See
  B. Bollobas, The Automorphism Group, Chapter 9 of Random Graphs, Cambridge
  University Press, 2011</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00212</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two New Contributions to the Visualization of AMR Grids: I. Interactive
  Rendering of Extreme-Scale 2-Dimensional Grids II. Novel Selection Filters in
  Arbitrary Dimension</dc:title>
 <dc:creator>Harel, Gu&#xe9;nol&#xe9;</dc:creator>
 <dc:creator>Lekien, Jacques-Bernard</dc:creator>
 <dc:creator>P&#xe9;ba&#xff;, Philippe P.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present here the result of continuation work, performed to further fulfill
the vision we outlined in [Harel,Lekien,P\'eba\&quot;y-2017] for the visualization
and analysis of tree-based adaptive mesh refinement (AMR) simulations, using
the hypertree grid paradigm which we proposed.
  The first filter presented hereafter implements an adaptive approach in order
to accelerate the rendering of 2-dimensional AMR grids, hereby solving the
problem posed by the loss of interactivity that occurs when dealing with large
and/or deeply refined meshes. Specifically, view parameters are taken into
account, in order to: on one hand, avoid creating surface elements that are
outside of the view area; on the other hand, utilize level-of-detail properties
to cull those cells that are deemed too small to be visible with respect to the
given view parameters. This adaptive approach often results in a massive
increase in rendering performance.
  In addition, two new selection filters provide data analysis capabilities, by
means of allowing for the extraction of those cells within a hypertree grid
that are deemed relevant in some sense, either geometrically or topologically.
After a description of these new algorithms, we illustrate their use within the
Visualization Toolkit (VTK) in which we implemented them. This note ends with
some suggestions for subsequent work.
</dc:description>
 <dc:description>Comment: Keywords: scientific visualization, interactive visualization,
  meshing, AMR, mesh refinement, tree-based, octree, VTK, parallel
  visualization, large scale visualization, HPC, data analysis</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00216</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Congestion-Aware Distributed Network Selection for Integrated Cellular
  and Wi-Fi Networks</dc:title>
 <dc:creator>Cheung, Man Hon</dc:creator>
 <dc:creator>Hou, Fen</dc:creator>
 <dc:creator>Huang, Jianwei</dc:creator>
 <dc:creator>Southwell, Richard</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Intelligent network selection plays an important role in achieving an
effective data offloading in the integrated cellular and Wi-Fi networks.
However, previously proposed network selection schemes mainly focused on
offloading as much data traffic to Wi-Fi as possible, without systematically
considering the Wi-Fi network congestion and the ping-pong effect, both of
which may lead to a poor overall user quality of experience. Thus, in this
paper, we study a more practical network selection problem by considering both
the impacts of the network congestion and switching penalties. More
specifically, we formulate the users' interactions as a Bayesian network
selection game (NSG) under the incomplete information of the users' mobilities.
We prove that it is a Bayesian potential game and show the existence of a pure
Bayesian Nash equilibrium that can be easily reached. We then propose a
distributed network selection (DNS) algorithm based on the network congestion
statistics obtained from the operator. Furthermore, we show that computing the
optimal centralized network allocation is an NP-hard problem, which further
justifies our distributed approach. Simulation results show that the DNS
algorithm achieves the highest user utility and a good fairness among users, as
compared with the on-the-spot offloading and cellular-only benchmark schemes.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00227</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Occupancy Map Building through Bayesian Exploration</dc:title>
 <dc:creator>Francis, Gilad</dc:creator>
 <dc:creator>Ott, Lionel</dc:creator>
 <dc:creator>Marchant, Roman</dc:creator>
 <dc:creator>Ramos, Fabio</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose a novel holistic approach for safe autonomous exploration and map
building based on constrained Bayesian optimisation. This method finds optimal
continuous paths instead of discrete sensing locations that inherently satisfy
motion and safety constraints. Evaluating both the objective and constraints
functions requires forward simulation of expected observations. As such
evaluations are costly, the Bayesian optimiser proposes only paths which are
likely to yield optimal results and satisfy the constraints with high
confidence. By balancing the reward and risk associated with each path, the
optimiser minimises the number of expensive function evaluations. We
demonstrate the effectiveness of our approach in a series of experiments both
in simulation and with a real ground robot and provide comparisons to other
exploration techniques. Evidently, each method has its specific favourable
conditions, where it outperforms all other techniques. Yet, by reasoning on the
usefulness of the entire path instead of its end point, our method provides a
robust and consistent performance through all tests and performs better than or
as good as the other leading methods.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00234</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Object Detection with Region Similarity Learning</dc:title>
 <dc:creator>Gao, Feng</dc:creator>
 <dc:creator>Lou, Yihang</dc:creator>
 <dc:creator>Bai, Yan</dc:creator>
 <dc:creator>Wang, Shiqi</dc:creator>
 <dc:creator>Huang, Tiejun</dc:creator>
 <dc:creator>Duan, Ling-Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object detection aims to identify instances of semantic objects of a certain
class in images or videos. The success of state-of-the-art approaches is
attributed to the significant progress of object proposal and convolutional
neural networks (CNNs). Most promising detectors involve multi-task learning
with an optimization objective of softmax loss and regression loss. The first
is for multi-class categorization, while the latter is for improving
localization accuracy. However, few of them attempt to further investigate the
hardness of distinguishing different sorts of distracting background regions
(i.e., negatives) from true object regions (i.e., positives). To improve the
performance of classifying positive object regions vs. a variety of negative
background regions, we propose to incorporate triplet embedding into learning
objective. The triplet units are formed by assigning each negative region to a
meaningful object class and establishing class- specific negatives, followed by
triplets construction. Over the benchmark PASCAL VOC 2007, the proposed triplet
em- bedding has improved the performance of well-known FastRCNN model with a
mAP gain of 2.1%. In particular, the state-of-the-art approach OHEM can benefit
from the triplet embedding and has achieved a mAP improvement of 1.2%.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00236</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms and Bounds for Very Strong Rainbow Coloring</dc:title>
 <dc:creator>Chandran, L. Sunil</dc:creator>
 <dc:creator>Das, Anita</dc:creator>
 <dc:creator>Issac, Davis</dc:creator>
 <dc:creator>van Leeuwen, Erik Jan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  A well-studied coloring problem is to assign colors to the edges of a graph
$G$ so that, for every pair of vertices, all edges of at least one shortest
path between them receive different colors. The minimum number of colors
necessary in such a coloring is the strong rainbow connection number
($\src(G)$) of the graph. When proving upper bounds on $\src(G)$, it is natural
to prove that a coloring exists where, for \emph{every} shortest path between
every pair of vertices in the graph, all edges of the path receive different
colors. Therefore, we introduce and formally define this more restricted edge
coloring number, which we call \emph{very strong rainbow connection number}
($\vsrc(G)$).
  In this paper, we give upper bounds on $\vsrc(G)$ for several graph classes,
some of which are tight. These immediately imply new upper bounds on $\src(G)$
for these classes, showing that the study of $\vsrc(G)$ enables meaningful
progress on bounding $\src(G)$. Then we study the complexity of the problem to
compute $\vsrc(G)$, particularly for graphs of bounded treewidth, and show this
is an interesting problem in its own right. We prove that $\vsrc(G)$ can be
computed in polynomial time on cactus graphs; in contrast, this question is
still open for $\src(G)$. We also observe that deciding whether $\vsrc(G) = k$
is fixed-parameter tractable in $k$ and the treewidth of $G$. Finally, on
general graphs, we prove that there is no polynomial-time algorithm to decide
whether $\vsrc(G) \leq 3$ nor to approximate $\vsrc(G)$ within a factor
$n^{1-\varepsilon}$, unless P$=$NP.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2018-01-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00237</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Completeness Results of Hoare Logic Relative to the Standard Model</dc:title>
 <dc:creator>Xu, Zhaowei</dc:creator>
 <dc:creator>Zhang, Wenhui</dc:creator>
 <dc:creator>Sui, Yuefei</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The general completeness problem of Hoare logic relative to the standard
model $N$ of Peano arithmetic has been studied by Cook, and it allows for the
use of arbitrary arithmetical formulas as assertions. In practice, the
assertions would be simple arithmetical formulas, e.g. of a low level in the
arithmetical hierarchy. In addition, we find that, by restricting inputs to
$N$, the complexity of the minimal assertion theory for the completeness of
Hoare logic to hold can be reduced. This paper further studies the completeness
of Hoare Logic relative to $N$ by restricting assertions to subclasses of
arithmetical formulas (and by restricting inputs to $N$). Our completeness
results refine Cook's result by reducing the complexity of the assertion
theory.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00240</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Completeness of Hoare Logic over Nonstandard Models</dc:title>
 <dc:creator>Xu, Zhaowei</dc:creator>
 <dc:creator>Sui, Yuefei</dc:creator>
 <dc:creator>Zhang, Wenhui</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The nonstandard approach to program semantics has successfully resolved the
completeness problem of Floyd-Hoare logic. The known versions of nonstandard
semantics, the Hungary semantics and axiomatic semantics, are so general that
they are absent either from mathematical elegance or from practical usefulness.
The aim of this paper is to exhibit a not only mathematically elegant but also
practically useful nonstandard semantics. A basic property of computable
functions in the standard model $N$ of Peano arithmetic $PA$ is
$\Sigma_1$-definability. However, the functions induced by the standard
interpretation of while-programs $S$ in nonstandard models $M$ of $PA$ are not
always arithmetical. The problem consists in that the standard termination of
$S$ in $M$ uses the finiteness in $N$, which is not the finiteness in $M$. To
this end, we shall give a new interpretation of $S$ in $M$ such that the
termination of $S$ uses $M$-finiteness, and the functions produced by $S$ in
all models of $PA$ have the uniform $\Sigma_1$-definability. Then we define,
based on the new semantics of while-programs, a new semantics of Hoare logic in
nonstandard models of $PA$, and show that the standard axiom system of Hoare
logic is sound and complete w.r.t. the new semantics. It will be established,
in $PA$, that the Hungary semantics and axiomatic semantics coincide with the
new semantics of while-programs. Moreover, various comparisons with the
previous results, usefulness of the nonstandard semantics, and remarks on the
completeness issues are presented.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00240</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00242</identifier>
 <datestamp>2017-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reordering Method and Hierarchies for Quantum and Classical Ordered
  Binary Decision Diagrams</dc:title>
 <dc:creator>Khadiev, Kamil</dc:creator>
 <dc:creator>Khadieva, Aliya</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We consider Quantum OBDD model. It is restricted version of read-once Quantum
Branching Programs, with respect to &quot;width&quot; complexity. It is known that
maximal complexity gap between deterministic and quantum model is exponential.
But there are few examples of such functions. We present method (called
&quot;reordering&quot;), which allows to build Boolean function $g$ from Boolean Function
$f$, such that if for $f$ we have gap between quantum and deterministic OBDD
complexity for natural order of variables, then we have almost the same gap for
function $g$, but for any order. Using it we construct the total function $REQ$
which deterministic OBDD complexity is $2^{\Omega(n/\log n)}$ and present
quantum OBDD of width $O(n^2)$. It is bigger gap for explicit function that was
known before for OBDD of width more than linear. Using this result we prove the
width hierarchy for complexity classes of Boolean functions for quantum OBDDs.
  Additionally, we prove the width hierarchy for complexity classes of Boolean
functions for bounded error probabilistic OBDDs. And using &quot;reordering&quot; method
we extend a hierarchy for $k$-OBDD of polynomial size, for $k=o(n/\log^3n)$.
Moreover, we proved a similar hierarchy for bounded error probabilistic
$k$-OBDD. And for deterministic and probabilistic $k$-OBDDs of superpolynomial
and subexponential size.
</dc:description>
 <dc:description>Comment: submitted to CSR 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00247</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning A Physical Long-term Predictor</dc:title>
 <dc:creator>Ehrhardt, Sebastien</dc:creator>
 <dc:creator>Monszpart, Aron</dc:creator>
 <dc:creator>Mitra, Niloy J.</dc:creator>
 <dc:creator>Vedaldi, Andrea</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Evolution has resulted in highly developed abilities in many natural
intelligences to quickly and accurately predict mechanical phenomena. Humans
have successfully developed laws of physics to abstract and model such
mechanical phenomena. In the context of artificial intelligence, a recent line
of work has focused on estimating physical parameters based on sensory data and
use them in physical simulators to make long-term predictions. In contrast, we
investigate the effectiveness of a single neural network for end-to-end
long-term prediction of mechanical phenomena. Based on extensive evaluation, we
demonstrate that such networks can outperform alternate approaches having even
access to ground-truth physical simulators, especially when some physical
parameters are unobserved or not known a-priori. Further, our network outputs a
distribution of outcomes to capture the inherent uncertainty in the data. Our
approach demonstrates for the first time the possibility of making actionable
long-term predictions from sensor data without requiring to explicitly model
the underlying physical laws.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00249</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Eye Visual Hyperacuity: A New Paradigm for Sensing?</dc:title>
 <dc:creator>Lagunas, Adur</dc:creator>
 <dc:creator>Dominguez, Oier</dc:creator>
 <dc:creator>Martinez-Conde, Susana</dc:creator>
 <dc:creator>Macknik, Stephen L.</dc:creator>
 <dc:creator>del-Rio, Carlos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4.3</dc:subject>
 <dc:subject>I.4.4</dc:subject>
 <dc:description>  The human eye appears to be using a low number of sensors for image
capturing. Furthermore, regarding the physical dimensions of
cones-photoreceptors responsible for the sharp central vision-, we may realize
that these sensors are of a relatively small size and area. Nonetheless, the
eye is capable to obtain high resolution images due to visual hyperacuity and
presents an impressive sensitivity and dynamic range when set against
conventional digital cameras of similar characteristics. This article is based
on the hypothesis that the human eye may be benefiting from diffraction to
improve both image resolution and acquisition process. The developed method
intends to explain and simulate using MATLAB software the visual hyperacuity:
the introduction of a controlled diffraction pattern at an initial stage,
enables the use of a reduced number of sensors for capturing the image and
makes possible a subsequent processing to improve the final image resolution.
The results have been compared with the outcome of an equivalent system but in
absence of diffraction, achieving promising results. The main conclusion of
this work is that diffraction could be helpful for capturing images or signals
when a small number of sensors available, which is far from being a
resolution-limiting factor.
</dc:description>
 <dc:description>Comment: 8 pages,9 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00263</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Information Set Decoding Algorithms</dc:title>
 <dc:creator>Kachigar, Ghazal</dc:creator>
 <dc:creator>Tillich, Jean-Pierre</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The security of code-based cryptosystems such as the McEliece cryptosystem
relies primarily on the difficulty of decoding random linear codes. The best
decoding algorithms are all improvements of an old algorithm due to Prange:
they are known under the name of information set decoding techniques. It is
also important to assess the security of such cryptosystems against a quantum
computer. This research thread started in Overbeck and Sendrier's 2009 survey
on code-based cryptography, and the best algorithm to date has been Bernstein's
quantising of the simplest information set decoding algorithm, namely Prange's
algorithm. It consists in applying Grover's quantum search to obtain a
quadratic speed-up of Prange's algorithm. In this paper, we quantise other
information set decoding algorithms by using quantum walk techniques which were
devised for the subset-sum problem by Bernstein, Jeffery, Lange and Meurer.
This results in improving the worst-case complexity of $2^{0.06035n}$ of
Bernstein's algorithm to $2^{0.05869n}$ with the best algorithm presented here
(where $n$ is the codelength).
</dc:description>
 <dc:description>Comment: 20 pages, 3 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-04-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00263</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00279</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Systematic Generation of Algorithms for Iterative Methods</dc:title>
 <dc:creator>Barthels, Henrik</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  The FLAME methodology makes it possible to derive provably correct algorithms
from a formal description of a linear algebra problem. So far, the methodology
has been successfully used to automate the derivation of direct algorithms such
as the Cholesky decomposition and the solution of Sylvester equations. In this
thesis, we present an extension of the FLAME methodology to tackle iterative
methods such as Conjugate Gradient. As a starting point, we use a formal
description of the iterative method in matrix form. The result is a family of
provably correct pseudocode algorithms. We argue that all the intermediate
steps are sufficiently systematic to be fully automated.
</dc:description>
 <dc:description>Comment: Master's Thesis</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00284</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>L$^3$-SVMs: Landmarks-based Linear Local Support Vectors Machines</dc:title>
 <dc:creator>Zantedeschi, Valentina</dc:creator>
 <dc:creator>Emonet, R&#xe9;mi</dc:creator>
 <dc:creator>Sebban, Marc</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  For their ability to capture non-linearities in the data and to scale to
large training sets, local Support Vector Machines (SVMs) have received a
special attention during the past decade. In this paper, we introduce a new
local SVM method, called L$^3$-SVMs, which clusters the input space, carries
out dimensionality reduction by projecting the data on landmarks, and jointly
learns a linear combination of local models. Simple and effective, our
algorithm is also theoretically well-founded. Using the framework of Uniform
Stability, we show that our SVM formulation comes with generalization
guarantees on the true risk. The experiments based on the simplest
configuration of our model (i.e. landmarks randomly selected, linear
projection, linear kernel) show that L$^3$-SVMs is very competitive w.r.t. the
state of the art and opens the door to new exciting lines of research.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00291</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Development Regression on Non-Linear Manifolds</dc:title>
 <dc:creator>K&#xfc;hnel, Line</dc:creator>
 <dc:creator>Sommer, Stefan</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  We introduce a regression model for data on non-linear manifolds. The model
describes the relation between a set of manifold valued observations, such as
shapes of anatomical objects, and Euclidean explanatory variables. The approach
is based on stochastic development of Euclidean diffusion processes to the
manifold. Defining the data distribution as the transition distribution of the
mapped stochastic process, parameters of the model, the non-linear analogue of
design matrix and intercept, are found via maximum likelihood. The model is
intrinsically related to the geometry encoded in the connection of the
manifold. We propose an estimation procedure which applies the Laplace
approximation of the likelihood function. A simulation study of the performance
of the model is performed and the model is applied to a real dataset of Corpus
Callosum shapes.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00297</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Group Sparsity Residual Constraint for Image Denoising</dc:title>
 <dc:creator>Zha, Zhiyuan</dc:creator>
 <dc:creator>Zhang, Xinggan</dc:creator>
 <dc:creator>Wang, Qiong</dc:creator>
 <dc:creator>Tang, Lan</dc:creator>
 <dc:creator>Liu, Xin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Group-based sparse representation has shown great potential in image
denoising. However, most existing methods only consider the nonlocal
self-similarity (NSS) prior of noisy input image. That is, the similar patches
are collected only from degraded input, which makes the quality of image
denoising largely depend on the input itself. However, such methods often
suffer from a common drawback that the denoising performance may degrade
quickly with increasing noise levels. In this paper we propose a new prior
model, called group sparsity residual constraint (GSRC). Unlike the
conventional group-based sparse representation denoising methods, two kinds of
prior, namely, the NSS priors of noisy and pre-filtered images, are used in
GSRC. In particular, we integrate these two NSS priors through the mechanism of
sparsity residual, and thus, the task of image denoising is converted to the
problem of reducing the group sparsity residual. To this end, we first obtain a
good estimation of the group sparse coefficients of the original image by
pre-filtering, and then the group sparse coefficients of the noisy image are
used to approximate this estimation. To improve the accuracy of the nonlocal
similar patch selection, an adaptive patch search scheme is designed.
Furthermore, to fuse these two NSS prior better, an effective iterative
shrinkage algorithm is developed to solve the proposed GSRC model. Experimental
results demonstrate that the proposed GSRC modeling outperforms many
state-of-the-art denoising methods in terms of the objective and the perceptual
metrics.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00297</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00298</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Library Version Identification, an Exploration of Techniques</dc:title>
 <dc:creator>Rinsma, Thomas</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This paper is the result of a two month research internship on the topic of
library version identification. In this paper, ideas and techniques from
literature in the area of binary comparison and fingerprinting are outlined and
applied to the problem of (version) identification of shared libraries and of
libraries within statically linked binary executables. Six comparison
techniques are chosen and implemented in an open-source tool which in turn
makes use of the open-source radare2 framework for signature generation. The
effectiveness of the techniques is empirically analyzed by comparing both
artificial and real sample files against a reference dataset of multiple
versions of dozens of libraries. The results show that out of these techniques,
readable string--based techniques perform the best and that one of these
techniques correctly identifies multiple libraries contained in a stripped
statically linked executable file.
</dc:description>
 <dc:description>Comment: 9 pages, short technical report</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00302</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disturbance-to-State Stabilization and Quantized Control for Linear
  Hyperbolic Systems</dc:title>
 <dc:creator>Tanwani, Aneel</dc:creator>
 <dc:creator>Prieur, Christophe</dc:creator>
 <dc:creator>Tarbouriech, Sophie</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  We consider a system of linear hyperbolic PDEs where the state at one of the
boundary points is controlled using the measurements of another boundary point.
Because of the disturbances in the measurement, the problem of designing
dynamic controllers is considered so that the closed-loop system is robust with
respect to measurement errors. Assuming that the disturbance is a locally
essentially bounded measurable function of time, we derive a
disturbance-to-state estimate which provides an upper bound on the maximum norm
of the state (with respect to the spatial variable) at each time in terms of
$\mathcal{L}^\infty$-norm of the disturbance up to that time. The analysis is
based on constructing a Lyapunov function for the closed-loop system, which
leads to controller synthesis and the conditions on system dynamics required
for stability. As an application of this stability notion, the problem of
quantized control for hyperbolic PDEs is considered where the measurements sent
to the controller are communicated using a quantizer of finite length. The
presence of quantizer yields practical stability only, and the ultimate bounds
on the norm of the state trajectory are also derived.
</dc:description>
 <dc:description>Comment: Some minor errors in the derivations have been corrected, and the
  references have been updated</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00304</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second Screen User Profiling and Multi-level Smart Recommendations in
  the context of Social TVs</dc:title>
 <dc:creator>Valsamis, Angelos</dc:creator>
 <dc:creator>Psychas, Alexandros</dc:creator>
 <dc:creator>Aisopos, Fotis</dc:creator>
 <dc:creator>Menychtas, Andreas</dc:creator>
 <dc:creator>Varvarigou, Theodora</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  In the context of Social TV, the increasing popularity of first and second
screen users, interacting and posting content online, illustrates new business
opportunities and related technical challenges, in order to enrich user
experience on such environments. SAM (Socializing Around Media) project uses
Social Media-connected infrastructure to deal with the aforementioned
challenges, providing intelligent user context management models and mechanisms
capturing social patterns, to apply collaborative filtering techniques and
personalized recommendations towards this direction. This paper presents the
Context Management mechanism of SAM, running in a Social TV environment to
provide smart recommendations for first and second screen content. Work
presented is evaluated using real movie rating dataset found online, to
validate the SAM's approach in terms of effectiveness as well as efficiency.
</dc:description>
 <dc:description>Comment: In: Wu TT., Gennari R., Huang YM., Xie H., Cao Y. (eds) Emerging
  Technologies for Education. SETE 2016</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00304</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science, vol 10108. Springer, Cham,
  2017, pp 514-525</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-52836-6_55</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00311</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-stage Neural Networks with Single-sided Classifiers for False
  Positive Reduction and its Evaluation using Lung X-ray CT Images</dc:title>
 <dc:creator>Sakamoto, Masaharu</dc:creator>
 <dc:creator>Nakano, Hiroki</dc:creator>
 <dc:creator>Zhao, Kun</dc:creator>
 <dc:creator>Sekiyama, Taro</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Lung nodule classification is a class imbalanced problem because nodules are
found with much lower frequency than non-nodules. In the class imbalanced
problem, conventional classifiers tend to be overwhelmed by the majority class
and ignore the minority class. We therefore propose cascaded convolutional
neural networks to cope with the class imbalanced problem. In the proposed
approach, multi-stage convolutional neural networks that perform as
single-sided classifiers filter out obvious non-nodules. Successively, a
convolutional neural network trained with a balanced data set calculates nodule
probabilities. The proposed method achieved the sensitivity of 92.4\% and 94.5%
at 4 and 8 false positives per scan in Free Receiver Operating Characteristics
(FROC) curve analysis, respectively.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.07136</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00312</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perturb-and-MPM: Quantifying Segmentation Uncertainty in Dense
  Multi-Label CRFs</dc:title>
 <dc:creator>Meier, Raphael</dc:creator>
 <dc:creator>Knecht, Urspeter</dc:creator>
 <dc:creator>Jungo, Alain</dc:creator>
 <dc:creator>Wiest, Roland</dc:creator>
 <dc:creator>Reyes, Mauricio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a novel approach for uncertainty quantification in dense
Conditional Random Fields (CRFs). The presented approach, called
Perturb-and-MPM, enables efficient, approximate sampling from dense multi-label
CRFs via random perturbations. An analytic error analysis was performed which
identified the main cause of approximation error as well as showed that the
error is bounded. Spatial uncertainty maps can be derived from the
Perturb-and-MPM model, which can be used to visualize uncertainty in image
segmentation results. The method is validated on synthetic and clinical
Magnetic Resonance Imaging data. The effectiveness of the approach is
demonstrated on the challenging problem of segmenting the tumor core in
glioblastoma. We found that areas of high uncertainty correspond well to
wrongly segmented image regions. Furthermore, we demonstrate the potential use
of uncertainty maps to refine imaging biomarkers in the case of extent of
resection and residual tumor volume in brain tumor patients.
</dc:description>
 <dc:description>Comment: Deactivated review mode (line spacing)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00312</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00317</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing Linguistic Relations in Winning and Losing Sides of Explicit
  Opposing Groups</dc:title>
 <dc:creator>Sanli, Ceyda</dc:creator>
 <dc:creator>Mondal, Anupam</dc:creator>
 <dc:creator>Cambria, Erik</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Linguistic relations in oral conversations present how opinions are
constructed and developed in a restricted time. The relations bond ideas,
arguments, thoughts, and feelings, re-shape them during a speech, and finally
build knowledge out of all information provided in the conversation. Speakers
share a common interest to discuss. It is expected that each speaker's reply
includes duplicated forms of words from previous speakers. However, linguistic
adaptation is observed and evolves in a more complex path than just
transferring slightly modified versions of common concepts. A conversation
aiming a benefit at the end shows an emergent cooperation inducing the
adaptation. Not only cooperation, but also competition drives the adaptation or
an opposite scenario and one can capture the dynamic process by tracking how
the concepts are linguistically linked. To uncover salient complex dynamic
events in verbal communications, we attempt to discover self-organized
linguistic relations hidden in a conversation with explicitly stated winners
and losers. We examine open access data of the United States Supreme Court. Our
understanding is crucial in big data research to guide how transition states in
opinion mining and decision-making should be modeled and how this required
knowledge to guide the model should be pinpointed, by filtering large amount of
data.
</dc:description>
 <dc:description>Comment: Full paper, Proceedings of FLAIRS-2017 (30th Florida Artificial
  Intelligence Research Society), Special Track, Artificial Intelligence for
  Big Social Data Analysis</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00317</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00319</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust and structural ergodicity analysis of stochastic biomolecular
  networks involving synthetic antithetic integral controllers</dc:title>
 <dc:creator>Briat, Corentin</dc:creator>
 <dc:creator>Khammash, Mustafa</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Ergodicity and output controllability have been shown to be fundamental
concepts for the analysis and synthetic design of closed-loop stochastic
reaction networks, as exemplified by the use of antithetic integral feedback
controllers. In [Gupta, Briat &amp; Khammash, PLoS Comput. Biol., 2014], some
ergodicity and output controllability conditions for unimolecular and certain
classes of bimolecular reaction networks were obtained and formulated through
linear programs. To account for context dependence, these conditions were later
extended in [Briat &amp; Khammash, CDC, 2016] to reaction networks with uncertain
rate parameters using simple and tractable, yet potentially conservative,
methods. Here we develop some exact theoretical methods for verifying, in a
robust setting, the original ergodicity and output controllability conditions
based on algebraic and polynomial techniques. Some examples are given for
illustration.
</dc:description>
 <dc:description>Comment: 18 pages; 1 Figure</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00319</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00320</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Characteristics of One-Sided Matching Mechanisms Under
  Various Preferences and Risk Attitudes</dc:title>
 <dc:creator>Hosseini, Hadi</dc:creator>
 <dc:creator>Larson, Kate</dc:creator>
 <dc:creator>Cohen, Robin</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  One-sided matching mechanisms are fundamental for assigning a set of
indivisible objects to a set of self-interested agents when monetary transfers
are not allowed. Two widely-studied randomized mechanisms in multiagent
settings are the Random Serial Dictatorship (RSD) and the Probabilistic Serial
Rule (PS). Both mechanisms require only that agents specify ordinal preferences
and have a number of desirable economic and computational properties. However,
the induced outcomes of the mechanisms are often incomparable and thus there
are challenges when it comes to deciding which mechanism to adopt in practice.
In this paper, we first consider the space of general ordinal preferences and
provide empirical results on the (in)comparability of RSD and PS. We analyze
their respective economic properties under general and lexicographic
preferences. We then instantiate utility functions with the goal of gaining
insights on the manipulability, efficiency, and envyfreeness of the mechanisms
under different risk-attitude models. Our results hold under various preference
distribution models, which further confirm the broad use of RSD in most
practical applications.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1503.01488</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00331</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memristor nanodevice for unconventional computing:review and
  applications</dc:title>
 <dc:creator>Shahsavari, Mahyar</dc:creator>
 <dc:creator>Boulet, Pierre</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A memristor is a two-terminal nanodevice that its properties attract a wide
community of researchers from various domains such as physics, chemistry,
electronics, computer and neuroscience.The simple structure for manufacturing,
small scalability, nonvolatility and potential of using inlow power platforms
are outstanding characteristics of this emerging nanodevice. In this report,we
review a brief literature of memristor from mathematic model to the physical
realization. Wediscuss different classes of memristors based on the material
used for its manufacturing. Thepotential applications of memristor are
presented and a wide domain of applications are explainedand classified.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00331</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00332</identifier>
 <datestamp>2017-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design and Analysis of Time-Invariant SC-LDPC Convolutional Codes With
  Small Constraint Length</dc:title>
 <dc:creator>Battaglioni, Massimo</dc:creator>
 <dc:creator>Tasdighi, Alireza</dc:creator>
 <dc:creator>Cancellieri, Giovanni</dc:creator>
 <dc:creator>Chiaraluce, Franco</dc:creator>
 <dc:creator>Baldi, Marco</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we deal with time-invariant spatially coupled low-density
parity-check convolutional codes (SC-LDPC-CCs). Classic design approaches
usually start from quasi-cyclic low-density parity-check (QC-LDPC) block codes
and exploit suitable unwrapping procedures to obtain SC-LDPC-CCs. We show that
the direct design of the SC-LDPC-CCs syndrome former matrix or, equivalently,
the symbolic parity-check matrix, leads to codes with smaller syndrome former
constraint lengths with respect to the best solutions available in the
literature. We provide theoretical lower bounds on the syndrome former
constraint length for the most relevant families of SC-LDPC-CCs, under
constraints on the minimum length of cycles in their Tanner graphs. We also
propose new code design techniques that approach or achieve such theoretical
limits.
</dc:description>
 <dc:description>Comment: 30 pages, 5 figures, accepted for publication in IEEE Transactions on
  Communications</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00332</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2017.2774821</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00340</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytical Modeling for Virtualized Network Functions</dc:title>
 <dc:creator>Prados-Garzon, Jonathan</dc:creator>
 <dc:creator>Ameigeiras, Pablo</dc:creator>
 <dc:creator>Ramos-Munoz, Juan J.</dc:creator>
 <dc:creator>Andres-Maldonado, Pilar</dc:creator>
 <dc:creator>Lopez-Soler, Juan M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Network Function Virtualization (NFV) is considered one of the key
technologies for the 5G mobile networks. In NFV, network functions are
implemented in software components denominated Virtual Network Functions (VNFs)
running on commodity hardware. In this paper, we propose an analytical model
based on an open queuing network of G/G/m queues to model VNFs with single- or
multi-tier designs, and chains of VNFs. Our model is flexible and generic
enough to capture the behavior of such systems. We validate our model by
simulation. Specifically, we validate it for an LTE virtualized Mobility
Management Entity with a three-tiered architecture use case. We also compare
our model with the estate of the art, in terms of computational complexity and
estimation error. The results show that our model has a computational
complexity similar to the method for analyzing Jackson's networks.
Additionally, our model exhibits an estimation error, measured as the relative
error for the estimation of the mean response time, approximately equal to 10%,
whereas for the considered baseline systems it ranges roughly from 60% to 90%.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, conference ICC17-WT01</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00340</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00352</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do Reichenbachian Common Cause Systems of Arbitrary Finite Size Exist?</dc:title>
 <dc:creator>Mazzola, Claudio</dc:creator>
 <dc:creator>Evans, Peter</dc:creator>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Physics - History and Philosophy of Physics</dc:subject>
 <dc:description>  The principle of common cause asserts that positive correlations between
causally unrelated events ought to be explained through the action of some
shared causal factors. Reichenbachian common cause systems are probabilistic
structures aimed at accounting for cases where correlations of the aforesaid
sort cannot be explained through the action of a single common cause. The
existence of Reichenbachian common cause systems of arbitrary finite size for
each pair of non-causally correlated events was allegedly demonstrated by
Hofer-Szab\'o and R\'edei in 2006. This paper shows that their proof is
logically deficient, and we propose an improved proof.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00352</dc:identifier>
 <dc:identifier>doi:10.1007/s10701-017-0124-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00356</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based Isometry Invariant Representation Learning</dc:title>
 <dc:creator>Khasanova, Renata</dc:creator>
 <dc:creator>Frossard, Pascal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning transformation invariant representations of visual data is an
important problem in computer vision. Deep convolutional networks have
demonstrated remarkable results for image and video classification tasks.
However, they have achieved only limited success in the classification of
images that undergo geometric transformations. In this work we present a novel
Transformation Invariant Graph-based Network (TIGraNet), which learns
graph-based features that are inherently invariant to isometric transformations
such as rotation and translation of input images. In particular, images are
represented as signals on graphs, which permits to replace classical
convolution and pooling layers in deep networks with graph spectral convolution
and dynamic graph pooling layers that together contribute to invariance to
isometric transformations. Our experiments show high performance on rotated and
translated images from the test set compared to classical architectures that
are very sensitive to transformations in the data. The inherent invariance
properties of our framework provide key advantages, such as increased
resiliency to data variability and sustained performance with limited training
sets.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00356</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00366</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Does The Crowd Say About You? Evaluating Aggregation-based Location
  Privacy</dc:title>
 <dc:creator>Pyrgelis, Apostolos</dc:creator>
 <dc:creator>Troncoso, Carmela</dc:creator>
 <dc:creator>De Cristofaro, Emiliano</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Information about people's movements and the locations they visit enables an
increasing number of mobility analytics applications, e.g., in the context of
urban and transportation planning, In this setting, rather than collecting or
sharing raw data, entities often use aggregation as a privacy protection
mechanism, aiming to hide individual users' location traces. Furthermore, to
bound information leakage from the aggregates, they can perturb the input of
the aggregation or its output to ensure that these are differentially private.
  In this paper, we set to evaluate the impact of releasing aggregate location
time-series on the privacy of individuals contributing to the aggregation. We
introduce a framework allowing us to reason about privacy against an adversary
attempting to predict users' locations or recover their mobility patterns. We
formalize these attacks as inference problems, and discuss a few strategies to
model the adversary's prior knowledge based on the information she may have
access to. We then use the framework to quantify the privacy loss stemming from
aggregate location data, with and without the protection of differential
privacy, using two real-world mobility datasets. We find that aggregates do
leak information about individuals' punctual locations and mobility profiles.
The density of the observations, as well as timing, play important roles, e.g.,
regular patterns during peak hours are better protected than sporadic
movements. Finally, our evaluation shows that both output and input
perturbation offer little additional protection, unless they introduce large
amounts of noise ultimately destroying the utility of the data.
</dc:description>
 <dc:description>Comment: To appear in PETS 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00369</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MattockFS; Page-cache and access-control concerns in asynchronous
  message-based forensic frameworks on the Linux platform</dc:title>
 <dc:creator>Meijer, Rob J</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  In this dissertation the feasibility of creating a page-cache efficient
storage- and messaging solution with integrity geared access control for a
scalable forensic framework is researched. The Open Computer Forensics
Architecture (OCFA),a lab-side scalable computer forensics framework,
introduced the concept of a message passing concurrency based forensic
framework. Since then, the amount of per-investigation data to be processed in
a lab environment has continued to grow significantly while available RAM and
CPU processing power combined with prohibitive cost and limited capacity of SSD
solutions have shifted processing from being largely CPU constrained to being
much more IO constrained. OCFA suffered from several page-cache-miss related
performance issues that have grown more significant as a result of this shift.
In the light of anti-forensics and general issues related to process integrity,
OCFA did not leverage the power of its message passing based design to address
integrity concerns.
  The main purpose of this dissertation is to analyze and evaluate a number of
page-cache friendly technologies that could contribute to the creation of a
computer forensics lab-geared scalable message-passing-concurrency based
forensic framework with a significantly reduced quantity of page-cache-miss
induced spurious IO operations, taking into account integrity related issues.
  Provenance logs from historic investigations conducted using the Open
Computer Forensics Architecture were thoroughly analyzed in this study, during
which several bottlenecks and design flaws in OCFA were identified. A number of
strategies were devised to address these bottlenecks in future computer
forensic frameworks. Finally, the most prominently page-cache related
strategies were consolidated with access-control measures into a user-space
file-system and low-level API prototype.
</dc:description>
 <dc:description>Comment: dissertation, Univ College London, June 2016</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00369</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.2.35426.53440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00371</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Steganographic Images via Adversarial Training</dc:title>
 <dc:creator>Hayes, Jamie</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Adversarial training was recently shown to be competitive against supervised
learning methods on computer vision tasks, however, studies have mainly been
confined to generative tasks such as image synthesis. In this paper, we apply
adversarial training techniques to the discriminative task of learning a
steganographic algorithm. Steganography is a collection of techniques for
concealing information by embedding it within a non-secret medium, such as
cover texts or images. We show that adversarial training can produce robust
steganographic techniques: our unsupervised training scheme produces a
steganographic algorithm that competes with state-of-the-art steganographic
techniques, and produces a robust steganalyzer, which performs the
discriminative task of deciding if an image contains secret information. We
define a game between three parties, Alice, Bob and Eve, in order to
simultaneously train both a steganographic algorithm and a steganalyzer. Alice
and Bob attempt to communicate a secret message contained within an image,
while Eve eavesdrops on their conversation and attempts to determine if secret
information is embedded within the image. We represent Alice, Bob and Eve by
neural networks, and validate our scheme on two independent image datasets,
showing our novel method of studying steganographic problems is surprisingly
competitive against established steganographic techniques.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00371</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00372</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factoring Odd Integers without Multiplication and Division</dc:title>
 <dc:creator>Sauerbier, Charles</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>11Y05, 11Y16, 65Q10, 65Y20, 68Q17, 03D17</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  A method of determining two factors of an odd integer without need of
multiplication or division operation in iterative portion of computation is
presented. It is feasible for an implementing algorithm to use only integer
addition and subtraction throughout. Presentation of material is
non-theoretical; intended to be accessible to a broader audience of non
academic and theoretical practitioners.
</dc:description>
 <dc:description>Comment: 6 pages, source code</dc:description>
 <dc:date>2017-01-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00372</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00374</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Resource Management in Cloud Computing: Classification and Taxonomy</dc:title>
 <dc:creator>Parikh, Swapnil M</dc:creator>
 <dc:creator>Patel, Narendra M</dc:creator>
 <dc:creator>Prajapati, Harshadkumar B</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud Computing is a new era of remote computing / Internet based computing
where one can access their personal resources easily from any computer through
Internet. Cloud delivers computing as a utility as it is available to the cloud
consumers on demand. It is a simple pay-per-use consumer-provider service
model. It contains large number of shared resources. So Resource Management is
always a major issue in cloud computing like any other computing paradigm. Due
to the availability of finite resources it is very challenging for cloud
providers to provide all the requested resources. From the cloud providers
perspective cloud resources must be allocated in a fair and efficient manner.
Research Survey is not available from the perspective of resource management as
a process in cloud computing. So this research paper provides a detailed
sequential view / steps on resource management in cloud computing. Firstly this
research paper classifies various resources in cloud computing. It also gives
taxonomy on resource management in cloud computing through which one can do
further research. Lastly comparisons on various resource management algorithms
has been presented.
</dc:description>
 <dc:date>2017-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00375</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Using Micro-Clouds to Deliver the Fog</dc:title>
 <dc:creator>Elkhatib, Yehia</dc:creator>
 <dc:creator>Porter, Barry</dc:creator>
 <dc:creator>Ribeiro, Heverson B.</dc:creator>
 <dc:creator>Zhani, Mohamed Faten</dc:creator>
 <dc:creator>Qadir, Junaid</dc:creator>
 <dc:creator>Riviere, Etienne</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Cloud computing has demonstrated itself to be a scalable and cost-efficient
solution for many real-world applications. However, its modus operandi is not
ideally suited to resource-constrained environments that are characterized by
limited network bandwidth and high latencies. With the increasing proliferation
and sophistication of edge devices, the idea of fog computing proposes to
offload some of the computation to the edge. To this end, micro-clouds---which
are modular and portable assemblies of small single-board computers---have
started to gain attention as infrastructures to support fog computing by
offering isolated resource provisioning at the edge in a cost-effective way. We
investigate the feasibility and readiness of micro-clouds for delivering the
vision of fog computing. Through a number of experiments, we showcase the
potential of micro-clouds formed by collections of Raspberry Pi computers to
host a range of fog-related applications, particularly for locations where
there is limited network bandwidths and long latencies.
</dc:description>
 <dc:date>2017-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00375</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00377</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gradient Boosting on Stochastic Data Streams</dc:title>
 <dc:creator>Hu, Hanzhang</dc:creator>
 <dc:creator>Sun, Wen</dc:creator>
 <dc:creator>Venkatraman, Arun</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:creator>Bagnell, J. Andrew</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Boosting is a popular ensemble algorithm that generates more powerful
learners by linearly combining base models from a simpler hypothesis class. In
this work, we investigate the problem of adapting batch gradient boosting for
minimizing convex loss functions to online setting where the loss at each
iteration is i.i.d sampled from an unknown distribution. To generalize from
batch to online, we first introduce the definition of online weak learning edge
with which for strongly convex and smooth loss functions, we present an
algorithm, Streaming Gradient Boosting (SGB) with exponential shrinkage
guarantees in the number of weak learners. We further present an adaptation of
SGB to optimize non-smooth loss functions, for which we derive a O(ln N/N)
convergence rate. We also show that our analysis can extend to adversarial
online learning setting under a stronger assumption that the online weak
learning edge will hold in adversarial setting. We finally demonstrate
experimental results showing that in practice our algorithms can achieve
competitive results as classic gradient boosting while using less computation.
</dc:description>
 <dc:description>Comment: To appear in AISTATS 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00380</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Personal Model Training under Privacy Constraints</dc:title>
 <dc:creator>Servia-Rodriguez, Sandra</dc:creator>
 <dc:creator>Wang, Liang</dc:creator>
 <dc:creator>Zhao, Jianxin R.</dc:creator>
 <dc:creator>Mortier, Richard</dc:creator>
 <dc:creator>Haddadi, Hamed</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many current Internet services rely on inferences from models trained on user
data. Commonly, both the training and inference tasks are carried out using
cloud resources fed by personal data collected at scale from users. Holding and
using such large collections of personal data in the cloud creates privacy
risks to the data subjects, but is currently required for users to benefit from
such services. We explore how to provide for model training and inference in a
system where computation is moved to the data in preference to moving data to
the cloud, obviating many current privacy risks. Specifically, we take an
initial model learnt from a small set of users and retrain it locally using
data from a single user. We evaluate on two tasks: one supervised learning
task, using a neural network to recognise users' current activity from
accelerometer traces; and one unsupervised learning task, identifying topics in
a large set of documents. In both cases the accuracy is improved. We also
demonstrate the robustness of our approach against adversarial attacks, as well
as its feasibility by presenting a performance evaluation on a representative
resource-constrained device (a Raspberry Pi).
</dc:description>
 <dc:description>Comment: Databox Project Technical Report</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00380</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00381</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Statistical Recurrent Unit</dc:title>
 <dc:creator>Oliva, Junier B.</dc:creator>
 <dc:creator>Poczos, Barnabas</dc:creator>
 <dc:creator>Schneider, Jeff</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Sophisticated gated recurrent neural network architectures like LSTMs and
GRUs have been shown to be highly effective in a myriad of applications. We
develop an un-gated unit, the statistical recurrent unit (SRU), that is able to
learn long term dependencies in data by only keeping moving averages of
statistics. The SRU's architecture is simple, un-gated, and contains a
comparable number of parameters to LSTMs; yet, SRUs perform favorably to more
sophisticated LSTM and GRU alternatives, often outperforming one or both in
various tasks. We show the efficacy of SRUs as compared to LSTMs and GRUs in an
unbiased manner by optimizing respective architectures' hyperparameters in a
Bayesian optimization scheme for both synthetic and real-world tasks.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00381</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00383</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identification of image source using serialnumber-based watermarking
  under Compressive Sensing conditions</dc:title>
 <dc:creator>Draganic, Andjela</dc:creator>
 <dc:creator>Maric, Milan</dc:creator>
 <dc:creator>Orovic, Irena</dc:creator>
 <dc:creator>Stankovic, Srdjan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Although the protection of ownership and the prevention of unauthorized
manipulation of digital images becomes an important concern, there is also a
big issue of image source origin authentication. This paper proposes a
procedure for the identification of the image source and content by using the
Public Key Cryptography Signature (PKCS). The procedure is based on the PKCS
watermarking of the images captured with numerous automatic observing cameras
in the Trap View cloud system. Watermark is created based on 32-bit PKCS serial
number and embedded into the captured image. Watermark detection on the
receiver side extracts the serial number and indicates the camera which
captured the image by comparing the original and the extracted serial numbers.
The watermarking procedure is designed to provide robustness to image
optimization based on the Compressive Sensing approach. Also, the procedure is
tested under various attacks and shows successful identification of ownership.
</dc:description>
 <dc:description>Comment: submitted to MIPRO 2017 conference, Opatija, Croatia</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00384</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Volterra model of a loudspeaker behavior based on Laser
  Doppler Vibrometry</dc:title>
 <dc:creator>Loriga, Alessandro</dc:creator>
 <dc:creator>Moyassari, Parvin</dc:creator>
 <dc:creator>Bernardini, Daniele</dc:creator>
 <dc:creator>Landi, Gregorio</dc:creator>
 <dc:creator>Venturini, Francesca</dc:creator>
 <dc:creator>Dumont, Elisabeth</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>H.5.5</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:description>  We demonstrate the capabilities of nonlinear Volterra models to simulate the
behavior of an audio system and compare them to linear filters. In this paper a
nonlinear model of an audio system based on Volterra series is presented and
Normalized Least Mean Square algorithm is used to determine the Volterra series
to third order. Training data for the models were collected measuring a
physical speaker using a laser interferometer. We explore several training
signals and filter's parameters. Results indicate a decrease in Mean Squared
Error compared to the linear model with a dependency on the particular test
signal, the order and the parameters of the model.
</dc:description>
 <dc:date>2017-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00390</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Gaze Stabilization of a Humanoid Robot based on Reafferences</dc:title>
 <dc:creator>Habra, Timothee</dc:creator>
 <dc:creator>Grotz, Markus</dc:creator>
 <dc:creator>Sippel, David</dc:creator>
 <dc:creator>Asfour, Tamim</dc:creator>
 <dc:creator>Ronsse, Renaud</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Gaze stabilization is fundamental for humanoid robots. By stabilizing vision,
it enhances perception of the environment and keeps points of interest in the
field of view. In this contribution, a multimodal gaze stabilization combining
classic inverse kinematic control with vestibulo-ocular and optokinetic
reflexes is introduced. Inspired by neuroscience, it implements a forward model
that can modulate the reflexes based on the reafference principle. This
principle filters self-generated movements out of the reflexive feedback loop.
The versatility and effectiveness of this method are experimentally validated
on the Armar-III humanoid robot. It is first demonstrated that each
stabilization mechanism (inverse kinematics and reflexes) performs better than
the others as a function of the type of perturbation to be stabilized.
Furthermore, combining these three modalities by reafference provides a
universal gaze stabilizer which can handle any kind of perturbation.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00391</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Hypercat-enabled Semantic Internet of Things Data Hub: Technical
  Report</dc:title>
 <dc:creator>Tachmazidis, Ilias</dc:creator>
 <dc:creator>Batsakis, Sotiris</dc:creator>
 <dc:creator>Davies, John</dc:creator>
 <dc:creator>Duke, Alistair</dc:creator>
 <dc:creator>Vallati, Mauro</dc:creator>
 <dc:creator>Antoniou, Grigoris</dc:creator>
 <dc:creator>Clarke, Sandra Stincic</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  An increasing amount of information is generated from the rapidly increasing
number of sensor networks and smart devices. A wide variety of sources generate
and publish information in different formats, thus highlighting
interoperability as one of the key prerequisites for the success of Internet of
Things (IoT). The BT Hypercat Data Hub provides a focal point for the sharing
and consumption of available datasets from a wide range of sources. In this
work, we propose a semantic enrichment of the BT Hypercat Data Hub, using
well-accepted Semantic Web standards and tools. We propose an ontology that
captures the semantics of the imported data and present the BT SPARQL Endpoint
by means of a mapping between SPARQL and SQL queries. Furthermore, federated
SPARQL queries allow queries over multiple hub-based and external data sources.
Finally, we provide two use cases in order to illustrate the advantages
afforded by our semantic approach.
</dc:description>
 <dc:description>Comment: Technical report of an accepted ESWC-2017 paper</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00391</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00395</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lossy Image Compression with Compressive Autoencoders</dc:title>
 <dc:creator>Theis, Lucas</dc:creator>
 <dc:creator>Shi, Wenzhe</dc:creator>
 <dc:creator>Cunningham, Andrew</dc:creator>
 <dc:creator>Husz&#xe1;r, Ferenc</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a new approach to the problem of optimizing autoencoders for lossy
image compression. New media formats, changing hardware technology, as well as
diverse requirements and content types create a need for compression algorithms
which are more flexible than existing codecs. Autoencoders have the potential
to address this need, but are difficult to optimize directly due to the
inherent non-differentiabilty of the compression loss. We here show that
minimal changes to the loss are sufficient to train deep autoencoders
competitive with JPEG 2000 and outperforming recently proposed approaches based
on RNNs. Our network is furthermore computationally efficient thanks to a
sub-pixel architecture, which makes it suitable for high-resolution images.
This is in contrast to previous work on autoencoders for compression using
coarser approximations, shallower architectures, computationally expensive
methods, or focusing on small images.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00395</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00397</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combating the Cold Start User Problem in Model Based Collaborative
  Filtering</dc:title>
 <dc:creator>Biswas, Sampoorna</dc:creator>
 <dc:creator>Lakshmanan, Laks V. S.</dc:creator>
 <dc:creator>Ray, Senjuti Basu</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  For tackling the well known cold-start user problem in model-based
recommender systems, one approach is to recommend a few items to a cold-start
user and use the feedback to learn a profile. The learned profile can then be
used to make good recommendations to the cold user. In the absence of a good
initial profile, the recommendations are like random probes, but if not chosen
judiciously, both bad recommendations and too many recommendations may turn off
a user. We formalize the cold-start user problem by asking what are the $b$
best items we should recommend to a cold-start user, in order to learn her
profile most accurately, where $b$, a given budget, is typically a small
number. We formalize the problem as an optimization problem and present
multiple non-trivial results, including NP-hardness as well as hardness of
approximation. We furthermore show that the objective function, i.e., the least
square error of the learned profile w.r.t. the true user profile, is neither
submodular nor supermodular, suggesting efficient approximations are unlikely
to exist. Finally, we discuss several scalable heuristic approaches for
identifying the $b$ best items to recommend to the user and experimentally
evaluate their performance on 4 real datasets. Our experiments show that our
proposed accelerated algorithms significantly outperform the prior art in
runnning time, while achieving similar error in the learned user profile as
well as in the rating predictions.
</dc:description>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00397</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00399</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Measurement Based Multilink Shadowing Model for V2V Network
  Simulations of Highway Scenarios</dc:title>
 <dc:creator>Nilsson, Mikael G.</dc:creator>
 <dc:creator>Gustafson, Carl</dc:creator>
 <dc:creator>Abbas, Taimoor</dc:creator>
 <dc:creator>Tufvesson, Fredrik</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Shadowing from vehicles can significantly degrade the performance of
vehicle-to-vehicle (V2V) communication in multilink systems, e.g., vehicular
ad-hoc networks (VANETs). It is thus important to characterize and model the
influence of common shadowing objects like cars properly when designing these
VANETs. Despite the fact that for multilink systems it is essential to model
the joint effects on the different links, the multilink shadowing effects of
V2V channels on VANET simulations are not yet well understood. In this paper we
present a measurement based analysis of multilink shadowing effects in a V2V
communication system with cars as blocking objects. In particular we analyze,
characterize and model the large scale fading, both regarding the
autocorrelation and the joint multilink cross-correlation process, for
communication at 5.9 GHz between four cars in a highway convoy scenario. The
results show that it is essential to separate the instantaneous propagation
condition into line-of-sight (LOS) and obstructed LOS (OLOS), by other cars,
and then apply an appropriate pathloss model for each of the two cases. The
choice of the pathloss model not only influences the autocorrelation but also
changes the cross-correlation of the large scale fading process between
different links. By this, we conclude that it is important that VANET
simulators should use geometry based models, that distinguish between LOS and
OLOS communication. Otherwise, the VANET simulators need to consider the
cross-correlation between different communication links to achieve results
close to reality.
</dc:description>
 <dc:description>Comment: 12 pages, 13 figures, Preprint; submitted to IEEE Transactions on
  Vehicular Technology</dc:description>
 <dc:date>2017-02-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00403</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserving Differential Privacy Between Features in Distributed
  Estimation</dc:title>
 <dc:creator>Heinze-Deml, Christina</dc:creator>
 <dc:creator>McWilliams, Brian</dc:creator>
 <dc:creator>Meinshausen, Nicolai</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Privacy is crucial in many applications of machine learning. Legal, ethical
and societal issues restrict the sharing of sensitive data making it difficult
to learn from datasets that are partitioned between many parties. One important
instance of such a distributed setting arises when information about each
record in the dataset is held by different data owners (the design matrix is
&quot;vertically-partitioned&quot;).
  In this setting few approaches exist for private data sharing for the
purposes of statistical estimation and the classical setup of differential
privacy with a &quot;trusted curator&quot; preparing the data does not apply. We work
with the notion of $(\epsilon,\delta)$-distributed differential privacy which
extends single-party differential privacy to the distributed,
vertically-partitioned case. We propose PriDE, a scalable framework for
distributed estimation where each party communicates perturbed random
projections of their locally held features ensuring
$(\epsilon,\delta)$-distributed differential privacy is preserved. For
$\ell_2$-penalized supervised learning problems PriDE has bounded estimation
error compared with the optimal estimates obtained without privacy constraints
in the non-distributed setting. We confirm this empirically on real world and
synthetic datasets.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00405</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and performance analysis of linear positive systems with
  delays using input-output methods</dc:title>
 <dc:creator>Briat, Corentin</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  It is known that input-output approaches based on scaled small-gain theorems
with constant $D$-scalings and integral linear constraints are non-conservative
for the analysis of some classes of linear positive systems interconnected with
uncertain linear operators. This dramatically contrasts with the case of
general linear systems with delays where input-output approaches provide, in
general, sufficient conditions only. Using these results we provide simple
alternative proofs for many of the existing results on the stability of linear
positive systems with discrete/distributed/neutral time-invariant/-varying
delays and linear difference equations. In particular, we give a simple proof
for the characterization of diagonal Riccati stability for systems with
discrete-delays and generalize this equation to other types of delay systems.
The fact that all those results can be reproved in a very simple way
demonstrates the importance and the efficiency of the input-output framework
for the analysis of linear positive systems. The approach is also used to
derive performance results evaluated in terms of the $L_1$-, $L_2$- and
$L_\infty$-gains. It is also flexible enough to be used for design purposes.
</dc:description>
 <dc:description>Comment: 34 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00405</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00409</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence of purchases in credit card data reveal life styles in urban
  populations</dc:title>
 <dc:creator>Di Clemente, Riccardo</dc:creator>
 <dc:creator>Luengo-Oroz, Miguel</dc:creator>
 <dc:creator>Travizano, Matias</dc:creator>
 <dc:creator>Xu, Sharon</dc:creator>
 <dc:creator>Vaitla, Bapu</dc:creator>
 <dc:creator>Gonzalez, Marta C.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Zipf-like distributions characterize a wide set of phenomena in physics,
biology, economics and social sciences. In human activities, Zipf-laws describe
for example the frequency of words appearance in a text or the purchases types
in shopping patterns. In the latter, the uneven distribution of transaction
types is bound with the temporal sequences of purchases of individual choices.
In this work, we define a new framework using a text compression technique on
the sequences of credit card purchases to detect ubiquitous patterns of
collective behavior. Clustering the consumers by their similarity in purchases
sequences, we detect five consumer groups. Remarkably, post checking,
individuals in each group are also similar in their age, total expenditure,
gender, and the diversity of their social and mobility networks extracted by
their mobile phone records. By properly deconstructing transaction data with
Zipf-like distributions, this method uncovers sets of significant sequences
that reveal insights on collective human behavior.
</dc:description>
 <dc:description>Comment: 33 pages, 21 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00410</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detecting Adversarial Samples from Artifacts</dc:title>
 <dc:creator>Feinman, Reuben</dc:creator>
 <dc:creator>Curtin, Ryan R.</dc:creator>
 <dc:creator>Shintre, Saurabh</dc:creator>
 <dc:creator>Gardner, Andrew B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep neural networks (DNNs) are powerful nonlinear architectures that are
known to be robust to random perturbations of the input. However, these models
are vulnerable to adversarial perturbations--small input changes crafted
explicitly to fool the model. In this paper, we ask whether a DNN can
distinguish adversarial samples from their normal and noisy counterparts. We
investigate model confidence on adversarial samples by looking at Bayesian
uncertainty estimates, available in dropout neural networks, and by performing
density estimation in the subspace of deep features learned by the model. The
result is a method for implicit adversarial detection that is oblivious to the
attack algorithm. We evaluate this method on a variety of standard datasets
including MNIST and CIFAR-10 and show that it generalizes well across different
architectures and attacks. Our findings report that 85-93% ROC-AUC can be
achieved on a number of standard classification tasks with a negative class
that consists of both normal and noisy samples.
</dc:description>
 <dc:description>Comment: Submitted to ICML 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00420</identifier>
 <datestamp>2017-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual-to-real Deep Reinforcement Learning: Continuous Control of
  Mobile Robots for Mapless Navigation</dc:title>
 <dc:creator>Tai, Lei</dc:creator>
 <dc:creator>Paolo, Giuseppe</dc:creator>
 <dc:creator>Liu, Ming</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a learning-based mapless motion planner by taking the sparse
10-dimensional range findings and the target position with respect to the
mobile robot coordinate frame as input and the continuous steering commands as
output. Traditional motion planners for mobile ground robots with a laser range
sensor mostly depend on the obstacle map of the navigation environment where
both the highly precise laser sensor and the obstacle map building work of the
environment are indispensable. We show that, through an asynchronous deep
reinforcement learning method, a mapless motion planner can be trained
end-to-end without any manually designed features and prior demonstrations. The
trained planner can be directly applied in unseen virtual and real
environments. The experiments show that the proposed mapless motion planner can
navigate the nonholonomic mobile robot to the desired targets without colliding
with any obstacles.
</dc:description>
 <dc:description>Comment: video: https://www.youtube.com/watch?v=9AOIwBYIBbs, 6 pages, 9
  figures, to appear in he 2017 IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS 2017), final submission version</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00426</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HolStep: A Machine Learning Dataset for Higher-order Logic Theorem
  Proving</dc:title>
 <dc:creator>Kaliszyk, Cezary</dc:creator>
 <dc:creator>Chollet, Fran&#xe7;ois</dc:creator>
 <dc:creator>Szegedy, Christian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Large computer-understandable proofs consist of millions of intermediate
logical steps. The vast majority of such steps originate from manually selected
and manually guided heuristics applied to intermediate goals. So far, machine
learning has generally not been used to filter or generate these steps. In this
paper, we introduce a new dataset based on Higher-Order Logic (HOL) proofs, for
the purpose of developing new machine learning-based theorem-proving
strategies. We make this dataset publicly available under the BSD license. We
propose various machine learning tasks that can be performed on this dataset,
and discuss their significance for theorem proving. We also benchmark a set of
simple baseline machine learning models suited for the tasks (including
logistic regression, convolutional neural networks and recurrent neural
networks). The results of our baseline models show the promise of applying
machine learning to HOL theorem proving.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00428</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Repair Strategies for Storage on Mobile Clouds</dc:title>
 <dc:creator>Calis, Gokhan</dc:creator>
 <dc:creator>Shivaramaiah, Swetha</dc:creator>
 <dc:creator>Koyluoglu, O. Ozan</dc:creator>
 <dc:creator>Lazos, Loukas</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the data reliability problem for a community of devices forming a
mobile cloud storage system. We consider the application of regenerating codes
for file maintenance within a geographically-limited area. Such codes require
lower bandwidth to regenerate lost data fragments compared to file replication
or reconstruction. We investigate threshold-based repair strategies where data
repair is initiated after a threshold number of data fragments have been lost
due to node mobility. We show that at a low departure-to-repair rate regime, a
lazy repair strategy in which repairs are initiated after several nodes have
left the system outperforms eager repair in which repairs are initiated after a
single departure. This optimality is reversed when nodes are highly mobile. We
further compare distributed and centralized repair strategies and derive the
optimal repair threshold for minimizing the average repair cost per unit of
time, as a function of underlying code parameters. In addition, we examine
cooperative repair strategies and show performance improvements compared to
non-cooperative codes. We investigate several models for the time needed for
node repair including a simple fixed time model that allows for the computation
of closed-form expressions and a more realistic model that takes into account
the number of repaired nodes. We derive the conditions under which the former
model approximates the latter. Finally, an extended model where additional
failures are allowed during the repair process is investigated. Overall, our
results establish the joint effect of code design and repair algorithms on the
maintenance cost of distributed storage systems.
</dc:description>
 <dc:description>Comment: 23 pages, 11 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00439</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for
  Regularized Empirical Risk Minimization</dc:title>
 <dc:creator>Murata, Tomoya</dc:creator>
 <dc:creator>Suzuki, Taiji</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we develop a new accelerated stochastic gradient method for
efficiently solving the convex regularized empirical risk minimization problem
in mini-batch settings. The use of mini-batches is becoming a golden standard
in the machine learning community, because mini-batch settings stabilize the
gradient estimate and can easily make good use of parallel computing. The core
of our proposed method is the incorporation of our new &quot;double acceleration&quot;
technique and variance reduction technique. We theoretically analyze our
proposed method and show that our method much improves the mini-batch
efficiencies of previous accelerated stochastic methods, and essentially only
needs size $\sqrt{n}$ mini-batches for achieving the optimal iteration
complexities for both non-strongly and strongly convex objectives, where $n$ is
the training set size. Further, we show that even in non-mini-batch settings,
our method achieves the best known convergence rate for both non-strongly and
strongly convex objectives.
</dc:description>
 <dc:description>Comment: 27 pages, 9 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00440</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast k-Nearest Neighbour Search via Prioritized DCI</dc:title>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Most exact methods for k-nearest neighbour search suffer from the curse of
dimensionality; that is, their query times exhibit exponential dependence on
either the ambient or the intrinsic dimensionality. Dynamic Continuous Indexing
(DCI) offers a promising way of circumventing the curse and successfully
reduces the dependence of query time on intrinsic dimensionality from
exponential to sublinear. In this paper, we propose a variant of DCI, which we
call Prioritized DCI, and show a remarkable improvement in the dependence of
query time on intrinsic dimensionality. In particular, a linear increase in
intrinsic dimensionality, or equivalently, an exponential increase in the
number of points near a query, can be mostly counteracted with just a linear
increase in space. We also demonstrate empirically that Prioritized DCI
significantly outperforms prior methods. In particular, relative to
Locality-Sensitive Hashing (LSH), Prioritized DCI reduces the number of
distance evaluations by a factor of 14 to 116 and the memory consumption by a
factor of 21.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures; International Conference on Machine Learning
  (ICML), 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00440</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00441</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Optimize Neural Nets</dc:title>
 <dc:creator>Li, Ke</dc:creator>
 <dc:creator>Malik, Jitendra</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning to Optimize is a recently proposed framework for learning
optimization algorithms using reinforcement learning. In this paper, we explore
learning an optimization algorithm for training shallow neural nets. Such
high-dimensional stochastic optimization problems present interesting
challenges for existing reinforcement learning algorithms. We develop an
extension that is suited to learning optimization algorithms in this setting
and demonstrate that the learned optimization algorithm consistently
outperforms other known optimization algorithms even on unseen tasks and is
robust to changes in stochasticity of gradients and the neural net
architecture. More specifically, we show that an optimization algorithm trained
with the proposed method on the problem of training a neural net on MNIST
generalizes to the problems of training neural nets on the Toronto Faces
Dataset, CIFAR-10 and CIFAR-100.
</dc:description>
 <dc:description>Comment: 10 pages, 15 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00441</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00443</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OptNet: Differentiable Optimization as a Layer in Neural Networks</dc:title>
 <dc:creator>Amos, Brandon</dc:creator>
 <dc:creator>Kolter, J. Zico</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents OptNet, a network architecture that integrates
optimization problems (here, specifically in the form of quadratic programs) as
individual layers in larger end-to-end trainable deep networks. These layers
encode constraints and complex dependencies between the hidden states that
traditional convolutional and fully-connected layers often cannot capture. In
this paper, we explore the foundations for such an architecture: we show how
techniques from sensitivity analysis, bilevel optimization, and implicit
differentiation can be used to exactly differentiate through these layers and
with respect to layer parameters; we develop a highly efficient solver for
these layers that exploits fast GPU-based batch solves within a primal-dual
interior point method, and which provides backpropagation gradients with
virtually no additional cost on top of the solve; and we highlight the
application of these approaches in several problems. In one notable example, we
show that the method is capable of learning to play mini-Sudoku (4x4) given
just input and output games, with no a priori information about the rules of
the game; this highlights the ability of our architecture to learn hard
constraints better than other neural architectures.
</dc:description>
 <dc:description>Comment: ICML 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2018-01-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00444</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bayesian Gates for Reliable Logical Operations under Noisy Condition</dc:title>
 <dc:creator>Kobayashi, Tetsuya J.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  The reliability of logical operations is indispensable for the reliable
operation of computational systems. Since the down-sizing of micro-fabrication
generates non-negligible noise in these systems, a new approach for designing
noise-immune gates is required. In this paper, we demonstrate that noise-immune
gates can be designed by combining Bayesian inference theory with the idea of
computation over a noisy signal. To reveal their practical advantages, the
performance of these gates is evaluated in comparison with a stochastic
resonance-based gate proposed previously. This approach for computation is also
demonstrated to be better than a conventional one that conducts information
transmission and computation separately.
</dc:description>
 <dc:description>Comment: 3figures + 3 supplementary figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00444</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00446</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A tool for ECG signal analysis using standard and optimized Hermite
  transform</dc:title>
 <dc:creator>Vulaj, Zoja</dc:creator>
 <dc:creator>Draganic, Andjela</dc:creator>
 <dc:creator>Brajovic, Milos</dc:creator>
 <dc:creator>Orovic, Irena</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The development of a system that would ease the diagnosis of heart diseases
would also fasten the work of the cardiologic department in hospitals and
facilitate the monitoring of patients with portable devices. This paper
presents a tool for ECG signal analysis which is designed in Matlab. The
Hermite transform domain is exploited for the analysis. The proposed transform
domain is very convenient for ECG signal analysis and classification. Parts of
the ECG signals, i.e. QRS complexes, show shape similarity with the Hermite
basis functions, which is one of the reasons for choosing this domain. Also,
the information about the signal can be represented using a small set of
coefficients in this domain, which makes data transmission and analysis faster.
The signal concentration in the Hermite domain and consequently, the number of
samples required for signal representation, can additionally be reduced by
performing the parametization of the Hermite transform. For the comparison
purpose, the Fourier transform domain is also implemented within the software,
in order to compare the signal concentration in two transform domains.
</dc:description>
 <dc:description>Comment: accepted for presentation at the MECO 2017 conference (6th
  Mediterranean Conference on Embedded Computing MECO 2017, Bar, Montenegro)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00461</identifier>
 <datestamp>2017-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reactive Trajectory Generation in an Unknown Environment</dc:title>
 <dc:creator>Cole, Kenan</dc:creator>
 <dc:creator>Wickenheiser, Adam</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous trajectory generation for unmanned aerial vehicles (UAVs) in
unknown environments continues to be an important research area as UAVs become
more prolific. We define a trajectory generation algorithm for a vehicle in an
unknown environment with wind disturbances, that relies only on the vehicle's
on-board distance sensors and communication with other vehicles within a finite
region to generate a smooth, collision-free trajectory up to the fourth
derivative. The proposed trajectory generation algorithm can be used in
conjunction with high-level planners and low-level motion controllers. The
algorithm provides guarantees that the trajectory does not violate the
vehicle's thrust limitation, sensor constraints, or a user-defined clearance
radius around other vehicles and obstacles. Simulation results of a quadrotor
moving through an unknown environment with a moving obstacle demonstrates the
trajectory generation performance.
</dc:description>
 <dc:description>Comment: Revised version with minor text updates and more representative
  simulation results for IROS 2017 conference</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00461</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00471</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multidimensional Sampling of Isotropically Bandlimited Signals</dc:title>
 <dc:creator>Agrell, Erik</dc:creator>
 <dc:creator>Cs&#xe9;bfalvi, Bal&#xe1;zs</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  A new lower bound on the average reconstruction error variance of
multidimensional sampling and reconstruction is presented. It applies to
sampling on arbitrary lattices in arbitrary dimensions, assuming a stochastic
process with constant, isotropically bandlimited spectrum and reconstruction by
the best linear interpolator. The lower bound is exact for any lattice at
sufficiently high and low sampling rates. The two threshold rates where the
error variance deviates from the lower bound gives two optimality criteria for
sampling lattices. It is proved that at low rates, near the first threshold,
the optimal lattice is the dual of the best sphere-covering lattice, which for
the first time establishes a rigorous relation between optimal sampling and
optimal sphere covering. A previously known result is confirmed at high rates,
near the second threshold, namely, that the optimal lattice is the dual of the
best sphere-packing lattice. Numerical results quantify the performance of
various lattices for sampling and support the theoretical optimality criteria.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00471</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00472</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reinforcement Learning for Pivoting Task</dc:title>
 <dc:creator>Antonova, Rika</dc:creator>
 <dc:creator>Cruciani, Silvia</dc:creator>
 <dc:creator>Smith, Christian</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work we propose an approach to learn a robust policy for solving the
pivoting task. Recently, several model-free continuous control algorithms were
shown to learn successful policies without prior knowledge of the dynamics of
the task. However, obtaining successful policies required thousands to millions
of training episodes, limiting the applicability of these approaches to real
hardware. We developed a training procedure that allows us to use a simple
custom simulator to learn policies robust to the mismatch of simulation vs
robot. In our experiments, we demonstrate that the policy learned in the
simulator is able to pivot the object to the desired target angle on the real
robot. We also show generalization to an object with different inertia, shape,
mass and friction properties than those used during training. This result is a
step towards making model-free reinforcement learning available for solving
robotics tasks via pre-training in simulators that offer only an imprecise
match to the real-world dynamics.
</dc:description>
 <dc:description>Comment: (Rika Antonova and Silvia Cruciani contributed equally)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00472</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00475</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design Automation for Obfuscated Circuits with Multiple Viable Functions</dc:title>
 <dc:creator>Keshavarz, Shahrzad</dc:creator>
 <dc:creator>Paar, Christof</dc:creator>
 <dc:creator>Holcomb, Daniel</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Gate camouflaging is a technique for obfuscating the function of a circuit
against reverse engineering attacks. However, if an adversary has pre-existing
knowledge about the set of functions that are viable for an application, random
camouflaging of gates will not obfuscate the function well. In this case, the
adversary can target their search, and only needs to decide whether each of the
viable functions could be implemented by the circuit.
  In this work, we propose a method for using camouflaged cells to obfuscate a
design that has a known set of viable functions. The circuit produced by this
method ensures that an adversary will not be able to rule out any viable
functions unless she is able to uncover the gate functions of the camouflaged
cells. Our method comprises iterated synthesis within an overall optimization
loop to combine the viable functions, followed by technology mapping to deploy
camouflaged cells while maintaining the plausibility of all viable functions.
We evaluate our technique on cryptographic S-box functions and show that,
relative to a baseline approach, it achieves up to 38\% area reduction in
PRESENT-style S-Boxes and 48\% in DES S-boxes.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00477</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Walking Stabilization Using Step Timing and Location Adjustment on the
  Humanoid Robot, Atlas</dc:title>
 <dc:creator>Griffin, Robert J.</dc:creator>
 <dc:creator>Wiedebach, Georg</dc:creator>
 <dc:creator>Bertrand, Sylvain</dc:creator>
 <dc:creator>Leonessa, Alexander</dc:creator>
 <dc:creator>Pratt, Jerry</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  While humans are highly capable of recovering from external disturbances and
uncertainties that result in large tracking errors, humanoid robots have yet to
reliably mimic this level of robustness. Essential to this is the ability to
combine traditional &quot;ankle strategy&quot; balancing with step timing and location
adjustment techniques. In doing so, the robot is able to step quickly to the
necessary location to continue walking. In this work, we present both a new
swing speed up algorithm to adjust the step timing, allowing the robot to set
the foot down more quickly to recover from errors in the direction of the
current capture point dynamics, and a new algorithm to adjust the desired
footstep, expanding the base of support to utilize the center of pressure
(CoP)-based ankle strategy for balance. We then utilize the desired centroidal
moment pivot (CMP) to calculate the momentum rate of change for our
inverse-dynamics based whole-body controller. We present simulation and
experimental results using this work, and discuss performance limitations and
potential improvements.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00477</dc:identifier>
 <dc:identifier>Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International
  Conference on</dc:identifier>
 <dc:identifier>doi:10.1109/IROS.2017.8202223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00482</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distortion Based Approach for Protecting Inferences</dc:title>
 <dc:creator>Tsai, Chi-Yo</dc:creator>
 <dc:creator>Agarwal, Gaurav Kumar</dc:creator>
 <dc:creator>Fragouli, Christina</dc:creator>
 <dc:creator>Diggavi, Suhas</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Eavesdropping attacks in inference systems aim to learn not the raw data, but
the system inferences to predict and manipulate system actions. We argue that
conventional information security measures can be ambiguous on the adversary's
estimation abilities, and adopt instead a distortion based framework that
enables to operate over a metric space. We show that requiring perfect
distortion-based security is more frugal than requiring perfect
information-theoretic secrecy even for block length one codes, offering in some
cases unbounded gains. Within this framework, we design algorithms that enable
to efficiently use shared randomness, and show that each bit of shared random
key is exponentially useful in security.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00484</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Truth and Regret in Online Scheduling</dc:title>
 <dc:creator>Chawla, Shuchi</dc:creator>
 <dc:creator>Devanur, Nikhil</dc:creator>
 <dc:creator>Kulkarni, Janardhan</dc:creator>
 <dc:creator>Niazadeh, Rad</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a scheduling problem where a cloud service provider has multiple
units of a resource available over time. Selfish clients submit jobs, each with
an arrival time, deadline, length, and value. The service provider's goal is to
implement a truthful online mechanism for scheduling jobs so as to maximize the
social welfare of the schedule. Recent work shows that under a stochastic
assumption on job arrivals, there is a single-parameter family of mechanisms
that achieves near-optimal social welfare. We show that given any such family
of near-optimal online mechanisms, there exists an online mechanism that in the
worst case performs nearly as well as the best of the given mechanisms. Our
mechanism is truthful whenever the mechanisms in the given family are truthful
and prompt, and achieves optimal (within constant factors) regret.
  We model the problem of competing against a family of online scheduling
mechanisms as one of learning from expert advice. A primary challenge is that
any scheduling decisions we make affect not only the payoff at the current
step, but also the resource availability and payoffs in future steps.
Furthermore, switching from one algorithm (a.k.a. expert) to another in an
online fashion is challenging both because it requires synchronization with the
state of the latter algorithm as well as because it affects the incentive
structure of the algorithms. We further show how to adapt our algorithm to a
non-clairvoyant setting where job lengths are unknown until jobs are run to
completion. Once again, in this setting, we obtain truthfulness along with
asymptotically optimal regret (within poly-logarithmic factors).
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00484</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00492</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Qualitative Action Recognition by Wireless Radio Signals in
  Human-Machine Systems</dc:title>
 <dc:creator>Lv, Shaohe</dc:creator>
 <dc:creator>Lu, Yong</dc:creator>
 <dc:creator>Dong, Mianxiong</dc:creator>
 <dc:creator>Wang, Xiaodong</dc:creator>
 <dc:creator>Dou, Yong</dc:creator>
 <dc:creator>Zhuang, Weihua</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Human-machine systems required a deep understanding of human behaviors. Most
existing research on action recognition has focused on discriminating between
different actions, however, the quality of executing an action has received
little attention thus far. In this paper, we study the quality assessment of
driving behaviors and present WiQ, a system to assess the quality of actions
based on radio signals. This system includes three key components, a deep
neural network based learning engine to extract the quality information from
the changes of signal strength, a gradient based method to detect the signal
boundary for an individual action, and an activitybased fusion policy to
improve the recognition performance in a noisy environment. By using the
quality information, WiQ can differentiate a triple body status with an
accuracy of 97%, while for identification among 15 drivers, the average
accuracy is 88%. Our results show that, via dedicated analysis of radio
signals, a fine-grained action characterization can be achieved, which can
facilitate a large variety of applications, such as smart driving assistants.
</dc:description>
 <dc:description>Comment: 12 pages, 18 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00492</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00495</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making 360$^{\circ}$ Video Watchable in 2D: Learning Videography for
  Click Free Viewing</dc:title>
 <dc:creator>Su, Yu-Chuan</dc:creator>
 <dc:creator>Grauman, Kristen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  360$^{\circ}$ video requires human viewers to actively control &quot;where&quot; to
look while watching the video. Although it provides a more immersive experience
of the visual content, it also introduces additional burden for viewers;
awkward interfaces to navigate the video lead to suboptimal viewing
experiences. Virtual cinematography is an appealing direction to remedy these
problems, but conventional methods are limited to virtual environments or rely
on hand-crafted heuristics. We propose a new algorithm for virtual
cinematography that automatically controls a virtual camera within a
360$^{\circ}$ video. Compared to the state of the art, our algorithm allows
more general camera control, avoids redundant outputs, and extracts its output
videos substantially more efficiently. Experimental results on over 7 hours of
real &quot;in the wild&quot; video show that our generalized camera control is crucial
for viewing 360$^{\circ}$ video, while the proposed efficient algorithm is
essential for making the generalized control computationally tractable.
</dc:description>
 <dc:description>Comment: CVPR 2017 Spotlight</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00495</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00500</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinity-Norm Permutation Covering Codes from Cyclic Groups</dc:title>
 <dc:creator>Karni, Ronen</dc:creator>
 <dc:creator>Schwartz, Moshe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study covering codes of permutations with the $\ell_\infty$-metric. We
provide a general code construction, which uses smaller building-block codes.
We study cyclic transitive groups as building blocks, determining their exact
covering radius, and showing linear-time algorithms for finding a covering
codeword. We also bound the covering radius of relabeled cyclic transitive
groups under conjugation.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00500</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00503</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Social Affordance Grammar from Videos: Transferring Human
  Interactions to Human-Robot Interactions</dc:title>
 <dc:creator>Shu, Tianmin</dc:creator>
 <dc:creator>Gao, Xiaofeng</dc:creator>
 <dc:creator>Ryoo, Michael S.</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we present a general framework for learning social affordance
grammar as a spatiotemporal AND-OR graph (ST-AOG) from RGB-D videos of human
interactions, and transfer the grammar to humanoids to enable a real-time
motion inference for human-robot interaction (HRI). Based on Gibbs sampling,
our weakly supervised grammar learning can automatically construct a
hierarchical representation of an interaction with long-term joint sub-tasks of
both agents and short term atomic actions of individual agents. Based on a new
RGB-D video dataset with rich instances of human interactions, our experiments
of Baxter simulation, human evaluation, and real Baxter test demonstrate that
the model learned from limited training data successfully generates human-like
behaviors in unseen scenarios and outperforms both baselines.
</dc:description>
 <dc:description>Comment: The 2017 IEEE International Conference on Robotics and Automation
  (ICRA)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00512</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PMLB: A Large Benchmark Suite for Machine Learning Evaluation and
  Comparison</dc:title>
 <dc:creator>Olson, Randal S.</dc:creator>
 <dc:creator>La Cava, William</dc:creator>
 <dc:creator>Orzechowski, Patryk</dc:creator>
 <dc:creator>Urbanowicz, Ryan J.</dc:creator>
 <dc:creator>Moore, Jason H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The selection, development, or comparison of machine learning methods in data
mining can be a difficult task based on the target problem and goals of a
particular study. Numerous publicly available real-world and simulated
benchmark datasets have emerged from different sources, but their organization
and adoption as standards have been inconsistent. As such, selecting and
curating specific benchmarks remains an unnecessary burden on machine learning
practitioners and data scientists. The present study introduces an accessible,
curated, and developing public benchmark resource to facilitate identification
of the strengths and weaknesses of different machine learning methodologies. We
compare meta-features among the current set of benchmark datasets in this
resource to characterize the diversity of available data. Finally, we apply a
number of established machine learning methods to the entire benchmark suite
and analyze how datasets and algorithms cluster in terms of performance. This
work is an important first step towards understanding the limitations of
popular benchmarking suites and developing a resource that connects existing
benchmarking standards to more diverse and efficient standards in the future.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures, submitted for review to JMLR</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00512</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00518</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying leading indicators of product recalls from online reviews
  using positive unlabeled learning and domain adaptation</dc:title>
 <dc:creator>Bhat, Shreesh Kumara</dc:creator>
 <dc:creator>Culotta, Aron</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Consumer protection agencies are charged with safeguarding the public from
hazardous products, but the thousands of products under their jurisdiction make
it challenging to identify and respond to consumer complaints quickly. From the
consumer's perspective, online reviews can provide evidence of product defects,
but manually sifting through hundreds of reviews is not always feasible. In
this paper, we propose a system to mine Amazon.com reviews to identify products
that may pose safety or health hazards. Since labeled data for this task are
scarce, our approach combines positive unlabeled learning with domain
adaptation to train a classifier from consumer complaints submitted to the U.S.
Consumer Product Safety Commission. On a validation set of manually annotated
Amazon product reviews, we find that our approach results in an absolute F1
score improvement of 8% over the best competing baseline. Furthermore, we apply
the classifier to Amazon reviews of known recalled products; the classifier
identifies reviews reporting safety hazards prior to the recall date for 45% of
the products. This suggests that the system may be able to provide an early
warning system to alert consumers to hazardous products before an official
recall is announced.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00520</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geohyperbolic Routing and Addressing Schemes</dc:title>
 <dc:creator>Voitalov, Ivan</dc:creator>
 <dc:creator>Aldecoa, Rodrigo</dc:creator>
 <dc:creator>Wang, Lan</dc:creator>
 <dc:creator>Krioukov, Dmitri</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.2</dc:subject>
 <dc:description>  The key requirement to routing in any telecommunication network, and
especially in Internet-of-Things (IoT) networks, is scalability. Routing must
route packets between any source and destination in the network without
incurring unmanageable routing overhead that grows quickly with increasing
network size and dynamics. Here we present an addressing scheme and a coupled
network topology design scheme that guarantee essentially optimal routing
scalability. The FIB sizes are as small as they can be, equal to the number of
adjacencies a node has, while the routing control overhead is minimized as
nearly zero routing control messages are exchanged even upon catastrophic
failures in the network. The key new ingredient is the addressing scheme, which
is purely local, based only on geographic coordinates of nodes and a centrality
measure, and does not require any sophisticated non-local computations or
global network topology knowledge for network embedding. The price paid for
these benefits is that network topology cannot be arbitrary but should follow a
specific design, resulting in Internet-like topologies. The proposed schemes
can be most easily deployed in overlay networks, and also in other network
deployments, where geolocation information is available, and where network
topology can grow following the design specifications.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00520</dc:identifier>
 <dc:identifier>ACM SIGCOMM Computer Communication Review (CCR), vol. 47, issue 3,
  p. 11-18, July 2017</dc:identifier>
 <dc:identifier>doi:10.1145/3138808.3138811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00521</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Signals and Systems Approach to Animation</dc:title>
 <dc:creator>Reach, Andrew McCaleb</dc:creator>
 <dc:creator>North, Chris</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Animation is ubiquitous in visualization systems, and a common technique for
creating these animations is the transition. In the transition approach,
animations are created by smoothly interpolating a visual attribute between a
start and end value, reaching the end value after a specified duration. This
approach works well when each transition for an attribute is allowed to finish
before the next is triggered, but performs poorly when a new transition is
triggered before the current transition has finished. In particular,
interruptions introduce velocity discontinuities, and frequent interruptions
can slow down the resulting animation. To solve these problems, we model the
problem of animation as a signal processing problem. In our technique,
animations are produced by transformations of signals, or functions over time.
In particular, an animation is produced by transforming an input signal, a
function from time to target attribute value, into an output signal, a function
from time to displayed attribute value. We show that well-known
signal-processing techniques can be applied to produce animations that are free
from velocity discontinuities even when interrupted.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00521</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00522</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Understanding Synthetic Gradients and Decoupled Neural Interfaces</dc:title>
 <dc:creator>Czarnecki, Wojciech Marian</dc:creator>
 <dc:creator>&#x15a;wirszcz, Grzegorz</dc:creator>
 <dc:creator>Jaderberg, Max</dc:creator>
 <dc:creator>Osindero, Simon</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  When training neural networks, the use of Synthetic Gradients (SG) allows
layers or modules to be trained without update locking - without waiting for a
true error gradient to be backpropagated - resulting in Decoupled Neural
Interfaces (DNIs). This unlocked ability of being able to update parts of a
neural network asynchronously and with only local information was demonstrated
to work empirically in Jaderberg et al (2016). However, there has been very
little demonstration of what changes DNIs and SGs impose from a functional,
representational, and learning dynamics point of view. In this paper, we study
DNIs through the use of synthetic gradients on feed-forward networks to better
understand their behaviour and elucidate their effect on optimisation. We show
that the incorporation of SGs does not affect the representational strength of
the learning system for a neural network, and prove the convergence of the
learning system for linear and deep linear models. On practical problems we
investigate the mechanism by which synthetic gradient estimators approximate
the true loss, and, surprisingly, how that leads to drastically different
layer-wise representations. Finally, we also expose the relationship of using
synthetic gradients to other error approximation techniques and find a unifying
language for discussion and comparison.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00523</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ISIC 2017 - Skin Lesion Analysis Towards Melanoma Detection</dc:title>
 <dc:creator>Berseth, Matt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Our system addresses Part 1, Lesion Segmentation and Part 3, Lesion
Classification of the ISIC 2017 challenge. Both algorithms make use of deep
convolutional networks to achieve the challenge objective.
</dc:description>
 <dc:description>Comment: ISIC2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00525</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Centralized Network Utility Maximization over Aggregate Flows</dc:title>
 <dc:creator>Gupta, Riten</dc:creator>
 <dc:creator>Vandenberghe, Lieven</dc:creator>
 <dc:creator>Gerla, Mario</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study a network utility maximization (NUM) decomposition in which the set
of flow rates is grouped by source-destination pairs. We develop theorems for
both single-path and multipath cases, which relate an arbitrary NUM problem
involving all flow rates to a simpler problem involving only the aggregate
rates for each source-destination pair. The optimal aggregate flows are then
apportioned among the constituent flows of each pair. This apportionment is
simple for the case of $\alpha$-fair utility functions. We also show how the
decomposition can be implemented with the alternating direction method of
multipliers (ADMM) algorithm.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00525</dc:identifier>
 <dc:identifier>doi:10.1109/WIOPT.2016.7492926</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00532</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stability and optimality of distributed secondary frequency control
  schemes in power networks</dc:title>
 <dc:creator>Kasis, Andreas</dc:creator>
 <dc:creator>Monshizadeh, Nima</dc:creator>
 <dc:creator>Devane, Eoin</dc:creator>
 <dc:creator>Lestas, Ioannis</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a systematic method for designing distributed generation and
demand control schemes for secondary frequency regulation in power networks
such that stability and an economically optimal power allocation can be
guaranteed. A dissipativity condition is imposed on net power supply variables
to provide stability guarantees. Furthermore, economic optimality is achieved
by explicit decentralized steady state conditions on the generation and
controllable demand. We discuss how various classes of dynamics used in recent
studies fit within our framework and give examples of higher order generation
and controllable demand dynamics that can be included within our analysis. In
case of linear dynamics, we discuss how the proposed dissipativity condition
can be efficiently verified using an appropriate linear matrix inequality.
Moreover, it is shown how the addition of a suitable observer layer can relax
the requirement for demand measurements in the employed controller. The
efficiency and practicality of the proposed results are demonstrated with a
simulation on the Northeast Power Coordinating Council (NPCC) 140-bus system.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00534</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skin cancer reorganization and classification with deep neural network</dc:title>
 <dc:creator>Chang, Hao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>68T20</dc:subject>
 <dc:description>  As one kind of skin cancer, melanoma is very dangerous. Dermoscopy based
early detection and recarbonization strategy is critical for melanoma therapy.
However, well-trained dermatologists dominant the diagnostic accuracy. In order
to solve this problem, many effort focus on developing automatic image analysis
systems. Here we report a novel strategy based on deep learning technique, and
achieve very high skin lesion segmentation and melanoma diagnosis accuracy: 1)
we build a segmentation neural network (skin_segnn), which achieved very high
lesion boundary detection accuracy; 2) We build another very deep neural
network based on Google inception v3 network (skin_recnn) and its well-trained
weight. The novel designed transfer learning based deep neural network
skin_inceptions_v3_nn helps to achieve a high prediction accuracy.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures. ISIC2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00535</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Interaction with Recommendation Systems: On Bias and Exploration</dc:title>
 <dc:creator>Schmit, Sven</dc:creator>
 <dc:creator>Riquelme, Carlos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommendation systems rely on historical user data to provide suggestions.
We propose an explicit and simple model for the interaction between users and
recommendations provided by a platform, and relate this model to the
multi-armed bandit literature. First, we show that this interaction leads to a
bias in naive estimators due to selection effects. This bias leads to
suboptimal outcomes, which we quantify in terms of linear regret. We end the
first part by discussing ways to obtain unbiased estimates. The second part of
this work considers exploration of alternatives. We show that although agents
are myopic, agents' heterogeneous preferences ensure that recommendation
systems 'learn' about all alternatives without explicitly incentivizing this
exploration. This work provides new and practical insights relevant to a wide
range of systems designed to help users make better decisions.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00535</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00536</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Loopix Anonymity System</dc:title>
 <dc:creator>Piotrowska, Ania</dc:creator>
 <dc:creator>Hayes, Jamie</dc:creator>
 <dc:creator>Elahi, Tariq</dc:creator>
 <dc:creator>Meiser, Sebastian</dc:creator>
 <dc:creator>Danezis, George</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present Loopix, a low-latency anonymous communication system that provides
bi-directional 'third-party' sender and receiver anonymity and unobservability.
Loopix leverages cover traffic and brief message delays to provide anonymity
and achieve traffic analysis resistance, including against a global network
adversary. Mixes and clients self-monitor the network via loops of traffic to
provide protection against active attacks, and inject cover traffic to provide
stronger anonymity and a measure of sender and receiver unobservability.
Service providers mediate access in and out of a stratified network of Poisson
mix nodes to facilitate accounting and off-line message reception, as well as
to keep the number of links in the system low, and to concentrate cover
traffic. We provide a theoretical analysis of the Poisson mixing strategy as
well as an empirical evaluation of the anonymity provided by the protocol and a
functional implementation that we analyze in terms of scalability by running it
on AWS EC2. We show that a Loopix relay can handle upwards of 300 messages per
second, at a small delay overhead of less than 1.5 ms on top of the delays
introduced into messages to provide security. Overall message latency is in the
order of seconds - which is low for a mix-system. Furthermore, many mix nodes
can be securely added to a stratified topology to scale throughput without
sacrificing anonymity.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00538</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Ensemble Ranking of Terms in Electronic Health Record Notes
  Based on Their Importance to Patients</dc:title>
 <dc:creator>Chen, Jinying</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Background: Electronic health record (EHR) notes contain abundant medical
jargon that can be difficult for patients to comprehend. One way to help
patients is to reduce information overload and help them focus on medical terms
that matter most to them.
  Objective: The aim of this work was to develop FIT (Finding Important Terms
for patients), an unsupervised natural language processing (NLP) system that
ranks medical terms in EHR notes based on their importance to patients.
  Methods: We built FIT on a new unsupervised ensemble ranking model derived
from the biased random walk algorithm to combine heterogeneous information
resources for ranking candidate terms from each EHR note. Specifically, FIT
integrates four single views for term importance: patient use of medical
concepts, document-level term salience, word-occurrence based term relatedness,
and topic coherence. It also incorporates partial information of term
importance as conveyed by terms' unfamiliarity levels and semantic types. We
evaluated FIT on 90 expert-annotated EHR notes and compared it with three
benchmark unsupervised ensemble ranking methods.
  Results: FIT achieved 0.885 AUC-ROC for ranking candidate terms from EHR
notes to identify important terms. When including term identification, the
performance of FIT for identifying important terms from EHR notes was 0.813
AUC-ROC. It outperformed the three ensemble rankers for most metrics. Its
performance is relatively insensitive to its parameter.
  Conclusions: FIT can automatically identify EHR terms important to patients
and may help develop personalized interventions to improve quality of care. By
using unsupervised learning as well as a robust and flexible framework for
information fusion, FIT can be readily applied to other domains and
applications.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00538</dc:identifier>
 <dc:identifier>doi:10.1016/j.jbi.2017.02.016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00541</identifier>
 <datestamp>2017-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When IoT Keeps People in the Loop: A Path Towards a New Global Utility</dc:title>
 <dc:creator>Petrov, Vitaly</dc:creator>
 <dc:creator>Mikhaylov, Konstantin</dc:creator>
 <dc:creator>Moltchanov, Dmitri</dc:creator>
 <dc:creator>Andreev, Sergey</dc:creator>
 <dc:creator>Fodor, Gabor</dc:creator>
 <dc:creator>Torsner, Johan</dc:creator>
 <dc:creator>Yanikomeroglu, Halim</dc:creator>
 <dc:creator>Juntti, Markku</dc:creator>
 <dc:creator>Koucheryavy, Yevgeni</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  While the Internet of Things (IoT) has made significant progress along the
lines of supporting individual machine-type applications, it is only recently
that the importance of people as an integral component of the overall IoT
infrastructure has started to be fully recognized. Several powerful concepts
have emerged to facilitate this vision, whether involving the human context
whenever required or directly impacting user behavior and decisions. As these
become the stepping stones to develop the IoT into a novel people-centric
utility, this paper outlines a path to materialize this decisive
transformation. We begin by reviewing the latest progress in human-aware
wireless networking, then classify the attractive human-machine applications
and summarize the enabling IoT radio technologies. We continue with a unique
system-level performance characterization of a representative urban IoT
scenario and quantify the benefits of keeping people in the loop on various
levels. Our comprehensive numerical results confirm the significant gains that
have been made available with tighter user involvement, and also corroborate
the development of efficient incentivization mechanisms, thereby opening the
door to future commoditization of the global people-centric IoT utility.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, revised for IEEE Communications Magazine</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-10-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00541</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00544</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simplified Algorithmic Metatheorems Beyond MSO: Treewidth and
  Neighborhood Diversity</dc:title>
 <dc:creator>Knop, Du&#x161;an</dc:creator>
 <dc:creator>Kouteck&#xfd;, Martin</dc:creator>
 <dc:creator>Masa&#x159;&#xed;k, Tom&#xe1;&#x161;</dc:creator>
 <dc:creator>Toufar, Tom&#xe1;&#x161;</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03D15</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  This paper settles the computational complexity of model checking of several
extensions of the monadic second order (MSO) logic on two classes of graphs:
graphs of bounded treewidth and graphs of bounded neighborhood diversity. A
classical theorem of Courcelle states that any graph property definable in MSO
is decidable in linear time on graphs of bounded treewidth. Algorithmic
metatheorems like Courcelle's serve to generalize known positive results on
various graph classes. We explore and extend three previously studied MSO
extensions: global and local cardinality constraints (CardMSO and MSO-LCC) and
optimizing a fair objective function (fairMSO). First, we show how these
fragments relate to each other in expressive power and highlight their
(non)linearity. On the side of neighborhood diversity, we show that combining
the linear variants of local and global cardinality constraints is possible
while keeping the linear runtime but removing linearity of either makes this
impossible, and we provide a polynomial time algorithm for the hard case.
Furthemore, we show that even the combination of the two most powerful
fragments is solvable in polynomial time on graphs of bounded treewidth.
</dc:description>
 <dc:description>Comment: Accepted in WG 2017, June 21-23 Eindhoven, Netherlands</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00544</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00548</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolving Deep Neural Networks</dc:title>
 <dc:creator>Miikkulainen, Risto</dc:creator>
 <dc:creator>Liang, Jason</dc:creator>
 <dc:creator>Meyerson, Elliot</dc:creator>
 <dc:creator>Rawal, Aditya</dc:creator>
 <dc:creator>Fink, Dan</dc:creator>
 <dc:creator>Francon, Olivier</dc:creator>
 <dc:creator>Raju, Bala</dc:creator>
 <dc:creator>Shahrzad, Hormoz</dc:creator>
 <dc:creator>Navruzyan, Arshak</dc:creator>
 <dc:creator>Duffy, Nigel</dc:creator>
 <dc:creator>Hodjat, Babak</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The success of deep learning depends on finding an architecture to fit the
task. As deep learning has scaled up to more challenging tasks, the
architectures have become difficult to design by hand. This paper proposes an
automated method, CoDeepNEAT, for optimizing deep learning architectures
through evolution. By extending existing neuroevolution methods to topology,
components, and hyperparameters, this method achieves results comparable to
best human designs in standard benchmarks in object recognition and language
modeling. It also supports building a real-world application of automated image
captioning on a magazine website. Given the anticipated increases in available
computing power, evolution of deep networks is promising approach to
constructing deep learning applications in the future.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00548</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00549</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Statistical Verification of Computational Rapport Model</dc:title>
 <dc:creator>Xu, Xuhai</dc:creator>
 <dc:creator>Cassell, Justine</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Rapport plays an important role during communication because it can help
people understand each other's feelings or ideas and leads to a smooth
communication. Computational rapport model has been proposed based on theory in
previous work. But there lacks solid verification. In this paper, we apply
structural equation model (SEM) to the theoretical model on both dyads of
friend and stranger. The results indicate some unfavorable paths. Based on the
results and more literature, we modify the original model to integrate more
nonverbal behaviors, including gaze and smile. Fit indices and other
examination show the goodness of our new models, which can give us more insight
into rapport management during conversation.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00549</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00551</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Label Refinement Network for Coarse-to-Fine Semantic Segmentation</dc:title>
 <dc:creator>Islam, Md Amirul</dc:creator>
 <dc:creator>Naha, Shujon</dc:creator>
 <dc:creator>Rochan, Mrigank</dc:creator>
 <dc:creator>Bruce, Neil</dc:creator>
 <dc:creator>Wang, Yang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider the problem of semantic image segmentation using deep
convolutional neural networks. We propose a novel network architecture called
the label refinement network that predicts segmentation labels in a
coarse-to-fine fashion at several resolutions. The segmentation labels at a
coarse resolution are used together with convolutional features to obtain finer
resolution segmentation labels. We define loss functions at several stages in
the network to provide supervisions at different stages. Our experimental
results on several standard datasets demonstrate that the proposed model
provides an effective way of producing pixel-wise dense image labeling.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00552</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Change Detection under Global Viewpoint Uncertainty</dc:title>
 <dc:creator>Tomoya, Murase</dc:creator>
 <dc:creator>Kanji, Tanaka</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper addresses the problem of change detection from a novel perspective
of long-term map learning. We are particularly interested in designing an
approach that can scale to large maps and that can function under global
uncertainty in the viewpoint (i.e., GPS-denied situations). Our approach, which
utilizes a compact bag-of-words (BoW) scene model, makes several contributions
to the problem:
  1) Two kinds of prior information are extracted from the view sequence map
and used for change detection. Further, we propose a novel type of prior,
called motion prior, to predict the relative motions of stationary objects and
anomaly ego-motion detection. The proposed prior is also useful for
distinguishing stationary from non-stationary objects.
  2) A small set of good reference images (e.g., 10) are efficiently retrieved
from the view sequence map by employing the recently developed
Bag-of-Local-Convolutional-Features (BoLCF) scene model.
  3) Change detection is reformulated as a scene retrieval over these reference
images to find changed objects using a novel spatial Bag-of-Words (SBoW) scene
model. Evaluations conducted of individual techniques and also their
combinations on a challenging dataset of highly dynamic scenes in the publicly
available Malaga dataset verify their efficacy.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, technical report</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00555</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Cascade of Convolutional Neural Networks for MR Image
  Reconstruction</dc:title>
 <dc:creator>Schlemper, Jo</dc:creator>
 <dc:creator>Caballero, Jose</dc:creator>
 <dc:creator>Hajnal, Joseph V.</dc:creator>
 <dc:creator>Price, Anthony</dc:creator>
 <dc:creator>Rueckert, Daniel</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The acquisition of Magnetic Resonance Imaging (MRI) is inherently slow.
Inspired by recent advances in deep learning, we propose a framework for
reconstructing MR images from undersampled data using a deep cascade of
convolutional neural networks to accelerate the data acquisition process. We
show that for Cartesian undersampling of 2D cardiac MR images, the proposed
method outperforms the state-of-the-art compressed sensing approaches, such as
dictionary learning-based MRI (DLMRI) reconstruction, in terms of
reconstruction error, perceptual quality and reconstruction speed for both
3-fold and 6-fold undersampling. Compared to DLMRI, the error produced by the
method proposed is approximately twice as small, allowing to preserve
anatomical structures more faithfully. Using our method, each image can be
reconstructed in 23 ms, which is fast enough to enable real-time applications.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00555</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00556</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conversion Rate Optimization through Evolutionary Computation</dc:title>
 <dc:creator>Miikkulainen, Risto</dc:creator>
 <dc:creator>Iscoe, Neil</dc:creator>
 <dc:creator>Shagrin, Aaron</dc:creator>
 <dc:creator>Cordell, Ron</dc:creator>
 <dc:creator>Nazari, Sam</dc:creator>
 <dc:creator>Schoolland, Cory</dc:creator>
 <dc:creator>Brundage, Myles</dc:creator>
 <dc:creator>Epstein, Jonathan</dc:creator>
 <dc:creator>Dean, Randy</dc:creator>
 <dc:creator>Lamba, Gurmeet</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Conversion optimization means designing a web interface so that as many users
as possible take a desired action on it, such as register or purchase. Such
design is usually done by hand, testing one change at a time through A/B
testing, or a limited number of combinations through multivariate testing,
making it possible to evaluate only a small fraction of designs in a vast
design space. This paper describes Sentient Ascend, an automatic conversion
optimization system that uses evolutionary optimization to create effective web
interface designs. Ascend makes it possible to discover and utilize
interactions between the design elements that are difficult to identify
otherwise. Moreover, evaluation of design candidates is done in parallel
online, i.e. with a large number of real users interacting with the system. A
case study on an existing media site shows that significant improvements (i.e.
over 43%) are possible beyond human design. Ascend can therefore be seen as an
approach to massively multivariate conversion optimization, based on a
massively parallel interactive evolution.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00556</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00557</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diffusion Independent Semi-Bandit Influence Maximization</dc:title>
 <dc:creator>Vaswani, Sharan</dc:creator>
 <dc:creator>Kveton, Branislav</dc:creator>
 <dc:creator>Wen, Zheng</dc:creator>
 <dc:creator>Ghavamzadeh, Mohammad</dc:creator>
 <dc:creator>Lakshmanan, Laks</dc:creator>
 <dc:creator>Schmidt, Mark</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider \emph{influence maximization} (IM) in social networks, which is
the problem of maximizing the number of users that become aware of a product by
selecting a set of &quot;seed&quot; users to expose the product to. While prior work
assumes a known model of information diffusion, we propose a parametrization in
terms of pairwise reachability which makes our framework agnostic to the
underlying diffusion model. We give a corresponding monotone, submodular
surrogate function, and show that it is a good approximation to the original IM
objective. We also consider the case of a new marketer looking to exploit an
existing social network, while simultaneously learning the factors governing
information propagation. For this, we propose a pairwise-influence semi-bandit
feedback model and develop a LinUCB-based bandit algorithm. Our
model-independent regret analysis shows that our bound on the cumulative regret
has a better (as compared to previous work) dependence on the size of the
network. By using the graph Laplacian eigenbasis to construct features, we
describe a practical LinUCB implementation. Experimental evaluation suggests
that our framework is robust to the underlying diffusion model and can
efficiently learn a near-optimal solution.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00558</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Topology Design for Disturbance Minimization in Power Grids</dc:title>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Nagarajan, Harsha</dc:creator>
 <dc:creator>Backhaus, Scott</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The transient response of power grids to external disturbances influences
their stable operation. This paper studies the effect of topology in linear
time-invariant dynamics of different power grids. For a variety of objective
functions, a unified framework based on $H_2$ norm is presented to analyze the
robustness to ambient fluctuations. Such objectives include loss reduction,
weighted consensus of phase angle deviations, oscillations in nodal frequency,
and other graphical metrics. The framework is then used to study the problem of
optimal topology design for robust control goals of different grids. For radial
grids, the problem is shown as equivalent to the hard &quot;optimum communication
spanning tree&quot; problem in graph theory and a combinatorial topology
construction is presented with bounded approximation gap. Extended to loopy
(meshed) grids, a greedy topology design algorithm is discussed. The
performance of the topology design algorithms under multiple control objectives
are presented on both loopy and radial test grids. Overall, this paper analyzes
topology design algorithms on a broad class of control problems in power grid
by exploring their combinatorial and graphical properties.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, a version of this work will appear in ACC 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00558</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00560</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Analytical Formula of Population Gradient for two-layered ReLU
  network and its Applications in Convergence and Critical Point Analysis</dc:title>
 <dc:creator>Tian, Yuandong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we explore theoretical properties of training a two-layered
ReLU network $g(\mathbf{x}; \mathbf{w}) = \sum_{j=1}^K
\sigma(\mathbf{w}_j^T\mathbf{x})$ with centered $d$-dimensional spherical
Gaussian input $\mathbf{x}$ ($\sigma$=ReLU). We train our network with gradient
descent on $\mathbf{w}$ to mimic the output of a teacher network with the same
architecture and fixed parameters $\mathbf{w}^*$. We show that its population
gradient has an analytical formula, leading to interesting theoretical analysis
of critical points and convergence behaviors. First, we prove that critical
points outside the hyperplane spanned by the teacher parameters
(&quot;out-of-plane&quot;) are not isolated and form manifolds, and characterize in-plane
critical-point-free regions for two ReLU case. On the other hand, convergence
to $\mathbf{w}^*$ for one ReLU node is guaranteed with at least
$(1-\epsilon)/2$ probability, if weights are initialized randomly with standard
deviation upper-bounded by $O(\epsilon/\sqrt{d})$, consistent with empirical
practice. For network with many ReLU nodes, we prove that an infinitesimal
perturbation of weight initialization results in convergence towards
$\mathbf{w}^*$ (or its permutation), a phenomenon known as spontaneous
symmetric-breaking (SSB) in physics. We assume no independence of ReLU
activations. Simulation verifies our findings.
</dc:description>
 <dc:description>Comment: International Conference on Machine Learning (ICML) 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00561</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal-based Bayesian Seismic Monitoring</dc:title>
 <dc:creator>Moore, David A.</dc:creator>
 <dc:creator>Russell, Stuart J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Geophysics</dc:subject>
 <dc:description>  Detecting weak seismic events from noisy sensors is a difficult perceptual
task. We formulate this task as Bayesian inference and propose a generative
model of seismic events and signals across a network of spatially distributed
stations. Our system, SIGVISA, is the first to directly model seismic
waveforms, allowing it to incorporate a rich representation of the physics
underlying the signal generation process. We use Gaussian processes over
wavelet parameters to predict detailed waveform fluctuations based on
historical events, while degrading smoothly to simple parametric envelopes in
regions with no historical seismicity. Evaluating on data from the western US,
we recover three times as many events as previous work, and reduce mean
location errors by a factor of four while greatly increasing sensitivity to
low-magnitude events.
</dc:description>
 <dc:description>Comment: Appearing at AISTATS 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00561</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00564</identifier>
 <datestamp>2017-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MoleculeNet: A Benchmark for Molecular Machine Learning</dc:title>
 <dc:creator>Wu, Zhenqin</dc:creator>
 <dc:creator>Ramsundar, Bharath</dc:creator>
 <dc:creator>Feinberg, Evan N.</dc:creator>
 <dc:creator>Gomes, Joseph</dc:creator>
 <dc:creator>Geniesse, Caleb</dc:creator>
 <dc:creator>Pappu, Aneesh S.</dc:creator>
 <dc:creator>Leswing, Karl</dc:creator>
 <dc:creator>Pande, Vijay</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Chemical Physics</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Molecular machine learning has been maturing rapidly over the last few years.
Improved methods and the presence of larger datasets have enabled machine
learning algorithms to make increasingly accurate predictions about molecular
properties. However, algorithmic progress has been limited due to the lack of a
standard benchmark to compare the efficacy of proposed methods; most new
algorithms are benchmarked on different datasets making it challenging to gauge
the quality of proposed methods. This work introduces MoleculeNet, a large
scale benchmark for molecular machine learning. MoleculeNet curates multiple
public datasets, establishes metrics for evaluation, and offers high quality
open-source implementations of multiple previously proposed molecular
featurization and learning algorithms (released as part of the DeepChem open
source library). MoleculeNet benchmarks demonstrate that learnable
representations are powerful tools for molecular machine learning and broadly
offer the best performance. However, this result comes with caveats. Learnable
representations still struggle to deal with complex tasks under data scarcity
and highly imbalanced classification. For quantum mechanical and biophysical
datasets, the use of physics-aware featurizations can be more important than
choice of particular learning algorithm.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-10-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00564</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00565</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ</dc:title>
 <dc:creator>Kessler, Jason S.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Scattertext is an open source tool for visualizing linguistic variation
between document categories in a language-independent way. The tool presents a
scatterplot, where each axis corresponds to the rank-frequency a term occurs in
a category of documents. Through a tie-breaking strategy, the tool is able to
display thousands of visible term-representing points and find space to legibly
label hundreds of them. Scattertext also lends itself to a query-based
visualization of how the use of terms with similar embeddings differs between
document categories, as well as a visualization for comparing the importance
scores of bag-of-words features to univariate metrics.
</dc:description>
 <dc:description>Comment: ACL 2017 Demos. 6 pages, 5 figures. See the Githup repo
  https://github.com/JasonKessler/scattertext for source code and documentation</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00565</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00572</identifier>
 <datestamp>2017-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Structural Embedding of Syntactic Trees for Machine Comprehension</dc:title>
 <dc:creator>Liu, Rui</dc:creator>
 <dc:creator>Hu, Junjie</dc:creator>
 <dc:creator>Wei, Wei</dc:creator>
 <dc:creator>Yang, Zi</dc:creator>
 <dc:creator>Nyberg, Eric</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Deep neural networks for machine comprehension typically utilizes only word
or character embeddings without explicitly taking advantage of structured
linguistic information such as constituency trees and dependency trees. In this
paper, we propose structural embedding of syntactic trees (SEST), an algorithm
framework to utilize structured information and encode them into vector
representations that can boost the performance of algorithms for the machine
comprehension. We evaluate our approach using a state-of-the-art neural
attention model on the SQuAD dataset. Experimental results demonstrate that our
model can accurately identify the syntactic boundaries of the sentences and
extract answers that are syntactically coherent over the baseline methods.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-08-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00573</identifier>
 <datestamp>2017-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalization and Equilibrium in Generative Adversarial Nets (GANs)</dc:title>
 <dc:creator>Arora, Sanjeev</dc:creator>
 <dc:creator>Ge, Rong</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Ma, Tengyu</dc:creator>
 <dc:creator>Zhang, Yi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We show that training of generative adversarial network (GAN) may not have
good generalization properties; e.g., training may appear successful but the
trained distribution may be far from target distribution in standard metrics.
However, generalization does occur for a weaker metric called neural net
distance. It is also shown that an approximate pure equilibrium exists in the
discriminator/generator game for a special class of generators with natural
training objectives when generator capacity and training set sizes are
moderate.
  This existence of equilibrium inspires MIX+GAN protocol, which can be
combined with any existing GAN training, and empirically shown to improve some
of them.
</dc:description>
 <dc:description>Comment: This is an updated version of an ICML'17 paper with the same title.
  The main difference is that in the ICML'17 version the pure equilibrium
  result was only proved for Wasserstein GAN. In the current version the result
  applies to most reasonable training objectives. In particular, Theorem 4.3
  now applies to both original GAN and Wasserstein GAN</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-08-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00575</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the NP-hardness of scheduling with time restrictions</dc:title>
 <dc:creator>Zhang, An</dc:creator>
 <dc:creator>Chen, Yong</dc:creator>
 <dc:creator>Chen, Lin</dc:creator>
 <dc:creator>Chen, Guangting</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In a recent paper, Braun, Chung and Graham [1] have addressed a
single-processor scheduling problem with time restrictions. Given a fixed
integer $B \geq 2$, there is a set of jobs to be processed by a single
processor subject to the following B-constraint. For any real $x$, no unit time
interval $[x, x+1)$ is allowed to intersect more than $B$ jobs. The problem has
been shown to be NP-hard when $B$ is part of the input and left as an open
question whether it remains NP-hard or not if $B$ is fixed [1, 5, 7]. This
paper contributes to answering this question that we prove the problem is
NP-hard even when $B=2$. A PTAS is also presented for any constant $B \geq 2$.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00577</identifier>
 <datestamp>2017-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skin Lesion Analysis Towards Melanoma Detection Using Deep Learning
  Network</dc:title>
 <dc:creator>Li, Yuexiang</dc:creator>
 <dc:creator>Shen, Linlin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Skin lesion is a severe disease in world-wide extent. Early detection of
melanoma in dermoscopy images significantly increases the survival rate.
However, the accurate recognition of melanoma is extremely challenging due to
the following reasons, e.g. low contrast between lesions and skin, visual
similarity between melanoma and non-melanoma lesions, etc. Hence, reliable
automatic detection of skin tumors is very useful to increase the accuracy and
efficiency of pathologists. International Skin Imaging Collaboration (ISIC) is
a challenge focusing on the automatic analysis of skin lesion. In this paper,
we proposed two deep learning methods to address all the three tasks announced
in ISIC 2017, i.e. lesion segmentation (task 1), lesion dermoscopic feature
extraction (task 2) and lesion classification (task 3). A deep learning
framework consisting of two fully-convolutional residual networks (FCRN) is
proposed to simultaneously produce the segmentation result and the coarse
classification result. A lesion index calculation unit (LICU) is developed to
refine the coarse classification results by calculating the distance heat-map.
A straight-forward CNN is proposed for the dermoscopic feature extraction task.
To our best knowledges, we are not aware of any previous work proposed for this
task. The proposed deep learning frameworks were evaluated on the ISIC 2017
testing set. Experimental results show the promising accuracies of our
frameworks, i.e. 0.718 for task 1, 0.833 for task 2 and 0.823 for task 3 were
achieved.
</dc:description>
 <dc:description>Comment: ISIC2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00579</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning for Accurate Estimation of Linear Models</dc:title>
 <dc:creator>Riquelme, Carlos</dc:creator>
 <dc:creator>Ghavamzadeh, Mohammad</dc:creator>
 <dc:creator>Lazaric, Alessandro</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We explore the sequential decision making problem where the goal is to
estimate uniformly well a number of linear models, given a shared budget of
random contexts independently sampled from a known distribution. The decision
maker must query one of the linear models for each incoming context, and
receives an observation corrupted by noise levels that are unknown, and depend
on the model instance. We present Trace-UCB, an adaptive allocation algorithm
that learns the noise levels while balancing contexts accordingly across the
different linear functions, and derive guarantees for simple regret in both
expectation and high-probability. Finally, we extend the algorithm and its
guarantees to high dimensional settings, where the number of linear models
times the dimension of the contextual space is higher than the total budget of
samples. Simulations with real data suggest that Trace-UCB is remarkably
robust, outperforming a number of baselines even when its assumptions are
violated.
</dc:description>
 <dc:description>Comment: 37 pages, 8 figures, International Conference on Machine Learning,
  ICML 2017</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-07-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00579</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00586</identifier>
 <datestamp>2017-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A novel image tag completion method based on convolutional neural
  network</dc:title>
 <dc:creator>Geng, Yanyan</dc:creator>
 <dc:creator>Zhang, Guohui</dc:creator>
 <dc:creator>Li, Weizhi</dc:creator>
 <dc:creator>Gu, Yi</dc:creator>
 <dc:creator>Liang, Ru-Ze</dc:creator>
 <dc:creator>Liang, Gaoyuan</dc:creator>
 <dc:creator>Wang, Jingbin</dc:creator>
 <dc:creator>Wu, Yanbin</dc:creator>
 <dc:creator>Patil, Nitin</dc:creator>
 <dc:creator>Wang, Jing-Yan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In the problems of image retrieval and annotation, complete textual tag lists
of images play critical roles. However, in real-world applications, the image
tags are usually incomplete, thus it is important to learn the complete tags
for images. In this paper, we study the problem of image tag complete and
proposed a novel method for this problem based on a popular image
representation method, convolutional neural network (CNN). The method estimates
the complete tags from the convolutional filtering outputs of images based on a
linear predictor. The CNN parameters, linear predictor, and the complete tags
are learned jointly by our method. We build a minimization problem to encourage
the consistency between the complete tags and the available incomplete tags,
reduce the estimation error, and reduce the model complexity. An iterative
algorithm is developed to solve the minimization problem. Experiments over
benchmark image data sets show its effectiveness.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00593</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Positive-Unlabeled Learning with Non-Negative Risk Estimator</dc:title>
 <dc:creator>Kiryo, Ryuichi</dc:creator>
 <dc:creator>Niu, Gang</dc:creator>
 <dc:creator>Plessis, Marthinus C. du</dc:creator>
 <dc:creator>Sugiyama, Masashi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  From only positive (P) and unlabeled (U) data, a binary classifier could be
trained with PU learning, in which the state of the art is unbiased PU
learning. However, if its model is very flexible, empirical risks on training
data will go negative, and we will suffer from serious overfitting. In this
paper, we propose a non-negative risk estimator for PU learning: when getting
minimized, it is more robust against overfitting, and thus we are able to use
very flexible models (such as deep neural networks) given limited P data.
Moreover, we analyze the bias, consistency, and mean-squared-error reduction of
the proposed risk estimator, and bound the estimation error of the resulting
empirical risk minimizer. Experiments demonstrate that our risk estimator fixes
the overfitting problem of its unbiased counterparts.
</dc:description>
 <dc:description>Comment: NIPS 2017 camera-ready version (this paper was selected for oral
  presentation)</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00606</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coloring ($P_6$, diamond, $K_4$)-free graphs</dc:title>
 <dc:creator>Karthick, T.</dc:creator>
 <dc:creator>Mishra, Suchismita</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We show that every ($P_6$, diamond, $K_4$)-free graph is $6$-colorable.
Moreover, we give an example of a ($P_6$, diamond, $K_4$)-free graph $G$ with
$\chi(G) = 6$. This generalizes some known results in the literature.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00606</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00607</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovery of Evolving Semantics through Dynamic Word Embedding Learning</dc:title>
 <dc:creator>Yao, Zijun</dc:creator>
 <dc:creator>Sun, Yifan</dc:creator>
 <dc:creator>Ding, Weicong</dc:creator>
 <dc:creator>Rao, Nikhil</dc:creator>
 <dc:creator>Xiong, Hui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  During the course of human language evolution, the semantic meanings of words
keep evolving with time. The understanding of evolving semantics enables us to
capture the true meaning of the words in different usage contexts, and thus is
critical for various applications, such as machine translation. While it is
naturally promising to study word semantics in a time-aware manner, traditional
methods to learn word vector representation do not adequately capture the
change over time. To this end, in this paper, we aim at learning time-aware
vector representation of words through dynamic word embedding modeling.
Specifically, we first propose a method that captures time-specific semantics
and across-time alignment simultaneously in a way that is robust to data
sparsity. Then, we solve the resulting optimization problem using a scalable
coordinate descent method. Finally, we perform the empirical study on New York
Times data to learn the temporal embeddings and develop multiple evaluations
that illustrate the semantic evolution of words, discovered from news media.
Moreover, our qualitative and quantitative tests indicate that the our method
not only reliably captures the semantic evolution over time, but also
onsistently outperforms state-of-the-art temporal embedding approaches on both
semantic accuracy and alignment quality.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00607</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00617</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>In Search of an Entity Resolution OASIS: Optimal Asymptotic Sequential
  Importance Sampling</dc:title>
 <dc:creator>Marchant, Neil G.</dc:creator>
 <dc:creator>Rubinstein, Benjamin I. P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Entity resolution (ER) presents unique challenges for evaluation methodology.
While crowdsourcing platforms acquire ground truth, sound approaches to
sampling must drive labelling efforts. In ER, extreme class imbalance between
matching and non-matching records can lead to enormous labelling requirements
when seeking statistically consistent estimates for rigorous evaluation. This
paper addresses this important challenge with the OASIS algorithm: a sampler
and F-measure estimator for ER evaluation. OASIS draws samples from a (biased)
instrumental distribution, chosen to ensure estimators with optimal asymptotic
variance. As new labels are collected OASIS updates this instrumental
distribution via a Bayesian latent variable model of the annotator oracle, to
quickly focus on unlabelled items providing more information. We prove that
resulting estimates of F-measure, precision, recall converge to the true
population values. Thorough comparisons of sampling methods on a variety of ER
datasets demonstrate significant labelling reductions of up to 83% without loss
to estimate accuracy.
</dc:description>
 <dc:description>Comment: 13 pages, 5 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:date>2017-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00617</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00619</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reflections on Cyberethics Education for Millennial Software Engineers</dc:title>
 <dc:creator>Melo, Claudia de O.</dc:creator>
 <dc:creator>de Sousa, Thiago C.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Software is a key component of solutions for 21st Century problems. These
problems are often &quot;wicked&quot;, complex, and unpredictable. To provide the best
possible solution, millennial software engineers must be prepared to make
ethical decisions, thinking critically, and acting systematically. This reality
demands continuous changes in educational systems and curricula delivery, as
misjudgment might have serious social impact. This study aims to investigate
and reflect on Software Engineering (SE) Programs, proposing a conceptual
framework for analyzing cyberethics education and a set of suggestions on how
to integrate it into the SE undergraduate curriculum.
</dc:description>
 <dc:description>Comment: International Workshop on Software Engineering Curricula for
  Millennials (SECM), ICSE 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00626</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The RowHammer Problem and Other Issues We May Face as Memory Becomes
  Denser</dc:title>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  As memory scales down to smaller technology nodes, new failure mechanisms
emerge that threaten its correct operation. If such failure mechanisms are not
anticipated and corrected, they can not only degrade system reliability and
availability but also, perhaps even more importantly, open up security
vulnerabilities: a malicious attacker can exploit the exposed failure mechanism
to take over the entire system. As such, new failure mechanisms in memory can
become practical and significant threats to system security.
  In this work, we discuss the RowHammer problem in DRAM, which is a prime (and
perhaps the first) example of how a circuit-level failure mechanism in DRAM can
cause a practical and widespread system security vulnerability. RowHammer, as
it is popularly referred to, is the phenomenon that repeatedly accessing a row
in a modern DRAM chip causes bit flips in physically-adjacent rows at
consistently predictable bit locations. It is caused by a hardware failure
mechanism called DRAM disturbance errors, which is a manifestation of
circuit-level cell-to-cell interference in a scaled memory technology. We
analyze the root causes of the RowHammer problem and examine various solutions.
We also discuss what other vulnerabilities may be lurking in DRAM and other
types of memories, e.g., NAND flash memory or Phase Change Memory, that can
potentially threaten the foundations of secure systems, as the memory
technologies scale to higher densities. We conclude by describing and
advocating a principled approach to memory reliability and security research
that can enable us to better anticipate and prevent such vulnerabilities.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00626</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00632</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dominant Strategy Truthful, Deterministic Multi-Armed Bandit Mechanism
  with Logarithmic Regret</dc:title>
 <dc:creator>Padmanabhan, Divya</dc:creator>
 <dc:creator>Bhat, Satyanath</dc:creator>
 <dc:creator>J., Prabuchandran K.</dc:creator>
 <dc:creator>Shevade, Shirish</dc:creator>
 <dc:creator>Narahari, Y.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Stochastic multi-armed bandit (MAB) mechanisms are widely used in sponsored
search auctions, crowdsourcing, online procurement, etc. Existing stochastic
MAB mechanisms with a deterministic payment rule, proposed in the literature,
necessarily suffer a regret of $\Omega(T^{2/3})$, where $T$ is the number of
time steps. This happens because the existing mechanisms consider the worst
case scenario where the means of the agents' stochastic rewards are separated
by a very small amount that depends on $T$. We make, and, exploit the crucial
observation that in most scenarios, the separation between the agents' rewards
is rarely a function of $T$. Moreover, in the case that the rewards of the arms
are arbitrarily close, the regret contributed by such sub-optimal arms is
minimal. Our idea is to allow the center to indicate the resolution, $\Delta$,
with which the agents must be distinguished. This immediately leads us to
introduce the notion of $\Delta$-Regret. Using sponsored search auctions as a
concrete example (the same idea applies for other applications as well), we
propose a dominant strategy incentive compatible (DSIC) and individually
rational (IR), deterministic MAB mechanism, based on ideas from the Upper
Confidence Bound (UCB) family of MAB algorithms. Remarkably, the proposed
mechanism $\Delta$-UCB achieves a $\Delta$-regret of $O(\log T)$ for the case
of sponsored search auctions. We first establish the results for single slot
sponsored search auctions and then non-trivially extend the results to the case
where multiple slots are to be allocated.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00632</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00633</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Predict Streaming Video QoE: Distortions, Rebuffering and
  Memory</dc:title>
 <dc:creator>Bampis, Christos G.</dc:creator>
 <dc:creator>Bovik, Alan C.</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Mobile streaming video data accounts for a large and increasing percentage of
wireless network traffic. The available bandwidths of modern wireless networks
are often unstable, leading to difficulties in delivering smooth, high-quality
video. Streaming service providers such as Netflix and YouTube attempt to adapt
their systems to adjust in response to these bandwidth limitations by changing
the video bitrate or, failing that, allowing playback interruptions
(rebuffering). Being able to predict end user' quality of experience (QoE)
resulting from these adjustments could lead to perceptually-driven network
resource allocation strategies that would deliver streaming content of higher
quality to clients, while being cost effective for providers. Existing
objective QoE models only consider the effects on user QoE of video quality
changes or playback interruptions. For streaming applications, adaptive network
strategies may involve a combination of dynamic bitrate allocation along with
playback interruptions when the available bandwidth reaches a very low value.
Towards effectively predicting user QoE, we propose Video Assessment of
TemporaL Artifacts and Stalls (Video ATLAS): a machine learning framework where
we combine a number of QoE-related features, including objective quality
features, rebuffering-aware features and memory-driven features to make QoE
predictions. We evaluated our learning-based QoE prediction model on the
recently designed LIVE-Netflix Video QoE Database which consists of practical
playout patterns, where the videos are afflicted by both quality changes and
rebuffering events, and found that it provides improved performance over
state-of-the-art video quality metrics while generalizing well on different
datasets. The proposed algorithm is made publicly available at
http://live.ece.utexas.edu/research/Quality/VideoATLAS release_v2.rar.
</dc:description>
 <dc:description>Comment: under review in Transactions on Image Processing</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00640</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster truncated integer multiplication</dc:title>
 <dc:creator>Harvey, David</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W30 (Primary)</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:description>  We present new algorithms for computing the low n bits or the high n bits of
the product of two n-bit integers. We show that these problems may be solved in
asymptotically 75% of the time required to compute the full 2n-bit product,
assuming that the underlying integer multiplication algorithm relies on
computing cyclic convolutions of real sequences.
</dc:description>
 <dc:description>Comment: 28 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00641</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Mixtures of Sparse Linear Regressions Using Sparse Graph Codes</dc:title>
 <dc:creator>Yin, Dong</dc:creator>
 <dc:creator>Pedarsani, Ramtin</dc:creator>
 <dc:creator>Chen, Yudong</dc:creator>
 <dc:creator>Ramchandran, Kannan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the mixture of sparse linear regressions model.
Let ${\beta}^{(1)},\ldots,{\beta}^{(L)}\in\mathbb{C}^n$ be $ L $ unknown sparse
parameter vectors with a total of $ K $ non-zero coefficients. Noisy linear
measurements are obtained in the form $y_i={x}_i^H {\beta}^{(\ell_i)} + w_i$,
each of which is generated randomly from one of the sparse vectors with the
label $ \ell_i $ unknown. The goal is to estimate the parameter vectors
efficiently with low sample and computational costs. This problem presents
significant challenges as one needs to simultaneously solve the demixing
problem of recovering the labels $ \ell_i $ as well as the estimation problem
of recovering the sparse vectors $ {\beta}^{(\ell)} $.
  Our solution to the problem leverages the connection between modern coding
theory and statistical inference. We introduce a new algorithm, Mixed-Coloring,
which samples the mixture strategically using query vectors $ {x}_i $
constructed based on ideas from sparse graph codes. Our novel code design
allows for both efficient demixing and parameter estimation. The algorithm
achieves the order-optimal sample and time complexities of $\Theta(K)$ in the
noiseless setting, and near-optimal $\Theta(K\text{polylog}(n))$ complexities
in the noisy setting. In one of our experiments, to recover a mixture of two
regressions with dimension $n=500$ and sparsity $K=50$, our algorithm is more
than $300$ times faster than EM algorithm, with about $ 1/3 $ of its sample
cost.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00645</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TumorNet: Lung Nodule Characterization Using Multi-View Convolutional
  Neural Network with Gaussian Process</dc:title>
 <dc:creator>Hussein, Sarfaraz</dc:creator>
 <dc:creator>Gillies, Robert</dc:creator>
 <dc:creator>Cao, Kunlin</dc:creator>
 <dc:creator>Song, Qi</dc:creator>
 <dc:creator>Bagci, Ulas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Characterization of lung nodules as benign or malignant is one of the most
important tasks in lung cancer diagnosis, staging and treatment planning. While
the variation in the appearance of the nodules remains large, there is a need
for a fast and robust computer aided system. In this work, we propose an
end-to-end trainable multi-view deep Convolutional Neural Network (CNN) for
nodule characterization. First, we use median intensity projection to obtain a
2D patch corresponding to each dimension. The three images are then
concatenated to form a tensor, where the images serve as different channels of
the input image. In order to increase the number of training samples, we
perform data augmentation by scaling, rotating and adding noise to the input
image. The trained network is used to extract features from the input image
followed by a Gaussian Process (GP) regression to obtain the malignancy score.
We also empirically establish the significance of different high level nodule
attributes such as calcification, sphericity and others for malignancy
determination. These attributes are found to be complementary to the deep
multi-view CNN features and a significant improvement over other methods is
obtained.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE International Symposium on
  Biomedical Imaging (ISBI) 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00659</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decidable and Undecidable Fragments of Asynchronous Subtyping for
  Session Types</dc:title>
 <dc:creator>Bravetti, Mario</dc:creator>
 <dc:creator>Carbone, Marco</dc:creator>
 <dc:creator>Zavattaro, Gianluigi</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Session types are behavioural types for guaranteeing that some programs are
free from basic communication errors. Recent work has shown that the notion of
asynchronous subtyping for session types is undecidable. However, it is not
clear what the possible alternatives for making such relation decidable are. In
this work, we propose two algorithms for deciding restricted but practically
relevant definitions of asynchronous subtyping. Additionally, we further refine
the existing undecidability results by showing how two restricted forms of
asynchronous subtyping remain undecidable.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00660</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Traffic-Aware Transmission Mode Selection in D2D-enabled Cellular
  Networks with Token System</dc:title>
 <dc:creator>Yuan, Yiling</dc:creator>
 <dc:creator>Yang, Tao</dc:creator>
 <dc:creator>Feng, Hui</dc:creator>
 <dc:creator>Hu, Bo</dc:creator>
 <dc:creator>Zhang, Jianqiu</dc:creator>
 <dc:creator>Wang, Bin</dc:creator>
 <dc:creator>Lu, Qiyong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a D2D-enabled cellular network where user equipments (UEs) owned
by rational users are incentivized to form D2D pairs using tokens. They
exchange tokens electronically to &quot;buy&quot; and &quot;sell&quot; D2D services. Meanwhile the
devices have the ability to choose the transmission mode, i.e. receiving data
via cellular links or D2D links. Thus taking the different benefits brought by
diverse traffic types as a prior, the UEs can utilize their tokens more
efficiently via transmission mode selection. In this paper, the optimal
transmission mode selection strategy as well as token collection policy are
investigated to maximize the long-term utility in the dynamic network
environment. The optimal policy is proved to be a threshold strategy, and the
thresholds have a monotonicity property. Numerical simulations verify our
observations and the gain from transmission mode selection is observed.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures. A shorter version is submitted to EUSIPCO</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00662</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a User-Centric Base Station Cooperation Scheme for Reliable
  Communications</dc:title>
 <dc:creator>Kim, Dong Min</dc:creator>
 <dc:creator>Thomsen, Henning</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, we describe CoMP2flex, a user-centric base station (BS)
cooperation scheme that provides improvements in reliability of both uplink
(UL) and downlink (DL) communications of wireless cellular networks. CoMP2flex
supports not only cooperation of two BSs with same direction of traffic but
also cooperation of two BSs serving bidirectional traffic. The reliability
performance of CoMP2flex is shown with numerical simulations and analytical
expressions. We quantify and numerically validate the performance of the greedy
BS pairing algorithm by comparing maximum weight matching methods, implemented
as the Edmonds matching algorithm for weighted graphs.
</dc:description>
 <dc:description>Comment: to be presented in IEEE VTC 2017 Spring</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00662</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00663</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Introduction to Nonnegative Matrix Factorization</dc:title>
 <dc:creator>Gillis, Nicolas</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we introduce and provide a short overview of nonnegative
matrix factorization (NMF). Several aspects of NMF are discussed, namely, the
application in hyperspectral imaging, geometry and uniqueness of NMF solutions,
complexity, algorithms, and its link with extended formulations of polyhedra.
In order to put NMF into perspective, the more general problem class of
constrained low-rank matrix approximation problems is first briefly introduced.
</dc:description>
 <dc:description>Comment: 18 pages, 4 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00663</dc:identifier>
 <dc:identifier>SIAG/OPT Views and News 25 (1), pp. 7-16 (2017)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00667</identifier>
 <datestamp>2017-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A resource-frugal probabilistic dictionary and applications in
  bioinformatics</dc:title>
 <dc:creator>Marchet, Camille</dc:creator>
 <dc:creator>Lecompte, Lolita</dc:creator>
 <dc:creator>Limasset, Antoine</dc:creator>
 <dc:creator>Bittner, Lucie</dc:creator>
 <dc:creator>Peterlongo, Pierre</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Indexing massive data sets is extremely expensive for large scale problems.
In many fields, huge amounts of data are currently generated, however
extracting meaningful information from voluminous data sets, such as computing
similarity between elements, is far from being trivial. It remains nonetheless
a fundamental need. This work proposes a probabilistic data structure based on
a minimal perfect hash function for indexing large sets of keys. Our structure
out-compete the hash table for construction, query times and for memory usage,
in the case of the indexation of a static set. To illustrate the impact of
algorithms performances, we provide two applications based on similarity
computation between collections of sequences, and for which this calculation is
an expensive but required operation. In particular, we show a practical case in
which other bioinformatics tools fail to scale up the tested data set or
provide lower recall quality results.
</dc:description>
 <dc:description>Comment: Submitted to Journal of Discrete Algorithms. arXiv admin note:
  substantial text overlap with arXiv:1605.08319</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00667</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00674</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Matching for Expert Systems with Uncertain Task Types</dc:title>
 <dc:creator>Shah, Virag</dc:creator>
 <dc:creator>Gulikers, Lennart</dc:creator>
 <dc:creator>Massoulie, Laurent</dc:creator>
 <dc:creator>Vojnovic, Milan</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Online two-sided matching markets such as Q&amp;A forums (e.g. StackOverflow,
Quora) and online labour platforms (e.g. Upwork) critically rely on the ability
to propose adequate matches based on imperfect knowledge of the two parties to
be matched. This prompts the following question: Which matching recommendation
algorithms can, in the presence of such uncertainty, lead to efficient platform
operation?
  To answer this question, we develop a model of a task / server matching
system. For this model, we give a necessary and sufficient condition for an
incoming stream of tasks to be manageable by the system. We further identify a
so-called back-pressure policy under which the throughput that the system can
handle is optimized. We show that this policy achieves strictly larger
throughput than a natural greedy policy. Finally, we validate our model and
confirm our theoretical findings with experiments based on logs of
Math.StackExchange, a StackOverflow forum dedicated to mathematics.
</dc:description>
 <dc:description>Comment: A part of it presented at Allerton Conference 2017, 18 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-10-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00676</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unifying View of Explicit and Implicit Feature Maps for Structured
  Data: Systematic Studies of Graph Kernels</dc:title>
 <dc:creator>Kriege, Nils M.</dc:creator>
 <dc:creator>Neumann, Marion</dc:creator>
 <dc:creator>Morris, Christopher</dc:creator>
 <dc:creator>Kersting, Kristian</dc:creator>
 <dc:creator>Mutzel, Petra</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Non-linear kernel methods can be approximated by fast linear ones using
suitable explicit feature maps allowing their application to large scale
problems. To this end, explicit feature maps of kernels for vectorial data have
been extensively studied. As many real-world data is structured, various
kernels for complex data like graphs have been proposed. Indeed, many of them
directly compute feature maps. However, the kernel trick is employed when the
number of features is very large or the individual vertices of graphs are
annotated by real-valued attributes.
  Can we still compute explicit feature maps efficiently under these
circumstances? Triggered by this question, we investigate how general
convolution kernels are composed from base kernels and construct corresponding
feature maps. We apply our results to widely used graph kernels and analyze for
which kernels and graph properties computation by explicit feature maps is
feasible and actually more efficient. In particular, we derive feature maps for
random walk and subgraph matching kernels and apply them to real-world graphs
with discrete labels. Thereby, our theoretical results are confirmed
experimentally by observing a phase transition when comparing running time with
respect to label diversity, walk lengths and subgraph size, respectively.
Moreover, we derive approximative, explicit feature maps for state-of-the-art
kernels supporting real-valued attributes including the GraphHopper and Graph
Invariant kernels. In extensive experiments we show that our approaches often
achieve a classification accuracy close to the exact methods based on the
kernel trick, but require only a fraction of their running time.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00676</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00683</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parity Games, Imperfect Information and Structural Complexity</dc:title>
 <dc:creator>Puchala, Bernd</dc:creator>
 <dc:creator>Rabinovich, Roman</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We address the problem of solving parity games with imperfect information on
finite graphs of bounded structural complexity. It is a major open problem
whether parity games with perfect information can be solved in PTIME.
Restricting the structural complexity of the game arenas, however, often leads
to efficient algorithms for parity games. Such results are known for graph
classes of bounded tree-width, DAG-width, directed path-width, and
entanglement, which we describe in terms of cops and robber games. Conversely,
the introduction of imperfect information makes the problem more difficult, it
becomes EXPTIME-hard. We analyse the interaction of both approaches.
  We use a simple method to measure the amount of &quot;unawareness&quot;' of a player,
the amount of imperfect information. It turns out that if it is unbounded, low
structural complexity does not make the problem simpler. It remains
EXPTIME-hard or PSPACE-hard even on very simple graphs.
  For games with bounded imperfect information we analyse the powerset
construction, which is commonly used to convert a game of imperfect information
into an equivalent game with perfect information. This construction preserves
boundedness of directed path-width and DAG-width, but not of entanglement or of
tree-width. Hence, if directed path-width or DAG-width are bounded, parity
games with bounded imperfect information can be solved in PTIME. For DAG-width
we follow two approaches. One leads to a generalization of the known fact that
perfect information parity games are in PTIME if DAG-width is bounded. We prove
this theorem for non-monotone DAG-width. The other approach introduces a cops
and robbers game (with multiple robbers) on directed graphs, considered
Richerby and Thilikos forundirected graphs. We show a tight linear bound for
the number of additional cops needed to capture an additional robber.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1110.5575</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00683</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00686</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BoxCars: Improving Fine-Grained Recognition of Vehicles using 3D
  Bounding Boxes in Traffic Surveillance</dc:title>
 <dc:creator>Sochor, Jakub</dc:creator>
 <dc:creator>&#x160;pa&#x148;hel, Jakub</dc:creator>
 <dc:creator>Herout, Adam</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we focus on fine-grained recognition of vehicles mainly in
traffic surveillance applications. We propose an approach orthogonal to recent
advancement in fine-grained recognition (automatic part discovery, bilinear
pooling). Also, in contrast to other methods focused on fine-grained
recognition of vehicles, we do not limit ourselves to frontal/rear viewpoint
but allow the vehicles to be seen from any viewpoint. Our approach is based on
3D bounding boxes built around the vehicles. The bounding box can be
automatically constructed from traffic surveillance data. For scenarios where
it is not possible to use the precise construction, we propose a method for
estimation of the 3D bounding box. The 3D bounding box is used to normalize the
image viewpoint by &quot;unpacking&quot; the image into plane. We also propose to
randomly alter the color of the image and add a rectangle with random noise to
random position in the image during training Convolutional Neural Networks. We
have collected a large fine-grained vehicle dataset BoxCars116k, with 116k
images of vehicles from various viewpoints taken by numerous surveillance
cameras. We performed a number of experiments which show that our proposed
method significantly improves CNN classification accuracy (the accuracy is
increased by up to 12 percent points and the error is reduced by up to 50%
compared to CNNs without the proposed modifications). We also show that our
method outperforms state-of-the-art methods for fine-grained recognition.
</dc:description>
 <dc:description>Comment: under review</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00687</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Even faster sorting of (not only) integers</dc:title>
 <dc:creator>Kokot, Marek</dc:creator>
 <dc:creator>Deorowicz, Sebastian</dc:creator>
 <dc:creator>Dlugosz, Maciej</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In this paper we introduce RADULS2, the fastest parallel sorter based on
radix algorithm. It is optimized to process huge amounts of data making use of
modern multicore CPUs. The main novelties include: extremely optimized
algorithm for handling tiny arrays (up to about a hundred of records) that
could appear even billions times as subproblems to handle and improved
processing of larger subarrays with better use of non-temporal memory stores.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00687</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00688</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Walking over Rough Terrains by Nonlinear Predictive Control of
  the Floating-base Inverted Pendulum</dc:title>
 <dc:creator>Caron, St&#xe9;phane</dc:creator>
 <dc:creator>Kheddar, Abderrahmane</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We present a real-time pattern generator for dynamic walking over rough
terrains. Our method automatically finds step durations, a critical issue over
rough terrains where they depend on terrain topology. To achieve this level of
generality, we consider a Floating-base Inverted Pendulum (FIP) model where the
center of mass can translate freely and the zero-tilting moment point is
allowed to leave the contact surface. This model is equivalent to a linear
inverted pendulum with variable center-of-mass height, but its equations of
motion remain linear. Our solution then follows three steps: (i) we
characterize the FIP contact-stability condition; (ii) we compute feedforward
controls by solving a nonlinear optimization over receding-horizon FIP
trajectories. Despite running at 30 Hz in a model-predictive fashion,
simulations show that the latter is too slow to stabilize dynamic motions. To
remedy this, we (iii) linearize FIP feedback control into a constrained
linear-quadratic regulator that runs at 300 Hz. We finally demonstrate our
solution in simulations with a model of the HRP-4 humanoid robot, including
noise and delays over state estimation and foot force control.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00690</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Even better correction of genome sequencing data</dc:title>
 <dc:creator>Dlugosz, Maciej</dc:creator>
 <dc:creator>Deorowicz, Sebastian</dc:creator>
 <dc:creator>Kokot, Marek</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We introduce an improved version of RECKONER, an error corrector for Illumina
whole genome sequencing data. By modifying its workflow we reduce the
computation time even 10 times. We also propose a new method of determination
of $k$-mer length, the key parameter of $k$-spectrum-based family of
correctors. The correction algorithms are examined on huge data sets, i.e.,
human and maize genomes for both Illumina HiSeq and MiSeq instruments.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00696</identifier>
 <datestamp>2017-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Artificial Noise-Aided Biobjective Transmitter Optimization for Service
  Integration in Multi-User MIMO Gaussian Broadcast Channel</dc:title>
 <dc:creator>Mei, Weidong</dc:creator>
 <dc:creator>Chen, Zhi</dc:creator>
 <dc:creator>Fang, Jun</dc:creator>
 <dc:creator>Li, Shaoqian</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper considers an artificial noise (AN)-aided transmit design for
multi-user MIMO systems with integrated services. Specifically, two sorts of
service messages are combined and served simultaneously: one multicast message
intended for all receivers and one confidential message intended for only one
receiver and required to be perfectly secure from other unauthorized receivers.
Our interest lies in the joint design of input covariances of the multicast
message, confidential message and artificial noise (AN), such that the
achievable secrecy rate and multicast rate are simultaneously maximized. This
problem is identified as a secrecy rate region maximization (SRRM) problem in
the context of physical-layer service integration. Since this bi-objective
optimization problem is inherently complex to solve, we put forward two
different scalarization methods to convert it into a scalar optimization
problem. First, we propose to prefix the multicast rate as a constant, and
accordingly, the primal biobjective problem is converted into a secrecy rate
maximization (SRM) problem with quality of multicast service (QoMS) constraint.
By varying the constant, we can obtain different Pareto optimal points. The
resulting SRM problem can be iteratively solved via a provably convergent
difference-of-concave (DC) algorithm. In the second method, we aim to maximize
the weighted sum of the secrecy rate and the multicast rate. Through varying
the weighted vector, one can also obtain different Pareto optimal points. We
show that this weighted sum rate maximization (WSRM) problem can be recast into
a primal decomposable form, which is amenable to alternating optimization (AO).
Then we compare these two scalarization methods in terms of their overall
performance and computational complexity via theoretical analysis as well as
numerical simulation, based on which new insights can be drawn.
</dc:description>
 <dc:description>Comment: 14 pages, 5 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00696</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00699</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact algorithms for the picking problem</dc:title>
 <dc:creator>Pansart, Lucie</dc:creator>
 <dc:creator>Catusse, Nicolas</dc:creator>
 <dc:creator>Cambazard, Hadrien</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Order picking is the problem of collecting a set of products in a warehouse
in a minimum amount of time. It is currently a major bottleneck in supply-chain
because of its cost in time and labor force. This article presents two exact
and effective algorithms for this problem. Firstly, a sparse formulation in
mixed-integer programming is strengthened by preprocessing and valid
inequalities. Secondly, a dynamic programming approach generalizing known
algorithms for two or three cross-aisles is proposed and evaluated
experimentally. Performances of these algorithms are reported and compared with
the Traveling Salesman Problem (TSP) solver Concorde.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-08-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00707</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unveiling Bias Compensation in Turbo-Based Algorithms for (Discrete)
  Compressed Sensing</dc:title>
 <dc:creator>Sparrer, Susanne</dc:creator>
 <dc:creator>Fischer, Robert F. H.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In Compressed Sensing, a real-valued sparse vector has to be recovered from
an underdetermined system of linear equations. In many applications, however,
the elements of the sparse vector are drawn from a finite set. Adapted
algorithms incorporating this additional knowledge are required for the
discrete-valued setup. In this paper, turbo-based algorithms for both cases are
elucidated and analyzed from a communications engineering perspective, leading
to a deeper understanding of the algorithm. In particular, we gain the
intriguing insight that the calculation of extrinsic values is equal to the
unbiasing of a biased estimate and present an improved algorithm.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00707</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00714</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Power Transfer for Distributed Estimation in Sensor Networks</dc:title>
 <dc:creator>Mai, Vien V.</dc:creator>
 <dc:creator>Shin, Won-Yong</dc:creator>
 <dc:creator>Ishibashi, Koji</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper studies power allocation for distributed estimation of an unknown
scalar random source in sensor networks with a multiple-antenna fusion center
(FC), where wireless sensors are equipped with radio-frequency based energy
harvesting technology. The sensors' observation is locally processed by using
an uncoded amplify-and-forward scheme. The processed signals are then sent to
the FC, and are coherently combined at the FC, at which the best linear
unbiased estimator (BLUE) is adopted for reliable estimation. We aim to solve
the following two power allocation problems: 1) minimizing distortion under
various power constraints; and 2) minimizing total transmit power under
distortion constraints, where the distortion is measured in terms of
mean-squared error of the BLUE. Two iterative algorithms are developed to solve
the non-convex problems, which converge at least to a local optimum. In
particular, the above algorithms are designed to jointly optimize the
amplification coefficients, energy beamforming, and receive filtering. For each
problem, a suboptimal design, a single-antenna FC scenario, and a common
harvester deployment for colocated sensors, are also studied. Using the
powerful semidefinite relaxation framework, our result is shown to be valid for
any number of sensors, each with different noise power, and for an arbitrarily
number of antennas at the FC.
</dc:description>
 <dc:description>Comment: 24 pages, 6 figures, To appear in IEEE Journal of Selected Topics in
  Signal Processing</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00714</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2017.2678106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00723</identifier>
 <datestamp>2017-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secrecy and Robustness for Active Attack in Secure Network Coding and
  its Application to Network Quantum Key Distribution</dc:title>
 <dc:creator>Hayashi, Masahito</dc:creator>
 <dc:creator>Owari, Masaki</dc:creator>
 <dc:creator>Kato, Go</dc:creator>
 <dc:creator>Cai, Ning</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  In the network coding, we discuss the effect of sequential error injection on
information leakage. We show that there is no improvement when the network is
composed of linear operations. However, when the network contains non-linear
operations, we find a counterexample to improve Eve's obtained information.
Furthermore, we discuss the asymptotic rate in a linear network under the
secrecy and robustness conditions as well as under the secrecy condition alone.
Finally, we apply our results to network quantum key distribution, which
clarifies the type of network that enables us to realize secure long distance
communication via short distance quantum key distribution.
</dc:description>
 <dc:description>Comment: We fixed several errors</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-11-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00726</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grayscale Image Authentication using Neural Hashing</dc:title>
 <dc:creator>Kutlu, Yakup</dc:creator>
 <dc:creator>Yay&#x131;k, Apdullah</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Many different approaches for neural network based hash functions have been
proposed. Statistical analysis must correlate security of them. This paper
proposes novel neural hashing approach for gray scale image authentication. The
suggested system is rapid, robust, useful and secure. Proposed hash function
generates hash values using neural network one-way property and non-linear
techniques. As a result security and performance analysis are performed and
satisfying results are achieved. These features are dominant reasons for
preferring against traditional ones.
</dc:description>
 <dc:description>Comment: international journal of Natural and Engineering Sciences
  (NESciences.com) : Image Authentication, Cryptology, Hash Function,
  Statistical and Security Analysis</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00726</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00727</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Predictive Policy Training using Reinforcement Learning</dc:title>
 <dc:creator>Ghadirzadeh, Ali</dc:creator>
 <dc:creator>Maki, Atsuto</dc:creator>
 <dc:creator>Kragic, Danica</dc:creator>
 <dc:creator>Bj&#xf6;rkman, M&#xe5;rten</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Skilled robot task learning is best implemented by predictive action policies
due to the inherent latency of sensorimotor processes. However, training such
predictive policies is challenging as it involves finding a trajectory of motor
activations for the full duration of the action. We propose a data-efficient
deep predictive policy training (DPPT) framework with a deep neural network
policy architecture which maps an image observation to a sequence of motor
activations. The architecture consists of three sub-networks referred to as the
perception, policy and behavior super-layers. The perception and behavior
super-layers force an abstraction of visual and motor data trained with
synthetic and simulated training samples, respectively. The policy super-layer
is a small sub-network with fewer parameters that maps data in-between the
abstracted manifolds. It is trained for each task using methods for policy
search reinforcement learning. We demonstrate the suitability of the proposed
architecture and learning framework by training predictive policies for skilled
object grasping and ball throwing on a PR2 robot. The effectiveness of the
method is illustrated by the fact that these tasks are trained using only about
180 real robot attempts with qualitative terminal rewards.
</dc:description>
 <dc:description>Comment: This work is submitted to IEEE/RSJ International Conference on
  Intelligent Robots and Systems 2017 (IROS2017)</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00729</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mixing Complexity and its Applications to Neural Networks</dc:title>
 <dc:creator>Moshkovitz, Michal</dc:creator>
 <dc:creator>Tishby, Naftali</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We suggest analyzing neural networks through the prism of space constraints.
We observe that most training algorithms applied in practice use bounded
memory, which enables us to use a new notion introduced in the study of
space-time tradeoffs that we call mixing complexity. This notion was devised in
order to measure the (in)ability to learn using a bounded-memory algorithm. In
this paper we describe how we use mixing complexity to obtain new results on
what can and cannot be learned using neural networks.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00731</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Voting: Optimal Distributed Node Scheduling Algorithm for Multihop
  Wireless Networks</dc:title>
 <dc:creator>Vergados, Dimitrios J.</dc:creator>
 <dc:creator>Amelina, Natalia</dc:creator>
 <dc:creator>Jiang, Yuming</dc:creator>
 <dc:creator>Kralevska, Katina</dc:creator>
 <dc:creator>Granichin, Oleg</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  An efficient and fair node scheduling is a big challenge in multihop wireless
networks. In this work, we propose a distributed node scheduling algorithm,
called Local Voting. The idea comes from the finding that the shortest delivery
time or delay is obtained when the load is equalized throughout the network.
Simulation results demonstrate that Local Voting achieves better performance in
terms of average delay, maximum delay, and fairness compared to several
representative scheduling algorithms from the literature. Despite being
distributed, Local Voting has a very close performance to a centralized
algorithm that is considered to have the optimal performance.
</dc:description>
 <dc:description>Comment: Accepted at 2017 INFOCOM Poster and Demo</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00731</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00734</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Bayesian Matrix Factorization with Minimal Communication</dc:title>
 <dc:creator>Qin, Xiangju</dc:creator>
 <dc:creator>Blomstedt, Paul</dc:creator>
 <dc:creator>Lepp&#xe4;aho, Eemeli</dc:creator>
 <dc:creator>Parviainen, Pekka</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Bayesian matrix factorization (BMF) is a powerful tool for producing low-rank
representations of matrices, and giving principled predictions of missing
values. However, scaling up MCMC samplers to large matrices has proven to be
difficult with parallel algorithms that require communication between MCMC
iterations. On the other hand, designing communication-free algorithms is
challenging due to the inherent unidentifiability of BMF solutions. We propose
posterior propagation, an embarrassingly parallel inference procedure, which
hierarchically introduces dependencies between data subsets and thus alleviates
the unidentifiability problem.
</dc:description>
 <dc:description>Comment: 10 pages, 11 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00737</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Interference Identification with Convolutional Neural Networks</dc:title>
 <dc:creator>Schmidt, Malte</dc:creator>
 <dc:creator>Block, Dimitri</dc:creator>
 <dc:creator>Meier, Uwe</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The steadily growing use of license-free frequency bands requires reliable
coexistence management for deterministic medium utilization. For interference
mitigation, proper wireless interference identification (WII) is essential. In
this work we propose the first WII approach based upon deep convolutional
neural networks (CNNs). The CNN naively learns its features through
self-optimization during an extensive data-driven GPU-based training process.
We propose a CNN example which is based upon sensing snapshots with a limited
duration of 12.8 {\mu}s and an acquisition bandwidth of 10 MHz. The CNN differs
between 15 classes. They represent packet transmissions of IEEE 802.11 b/g,
IEEE 802.15.4 and IEEE 802.15.1 with overlapping frequency channels within the
2.4 GHz ISM band. We show that the CNN outperforms state-of-the-art WII
approaches and has a classification accuracy greater than 95% for
signal-to-noise ratio of at least -5 dB.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00737</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00745</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Peterson-Gorenstein-Zierler algorithm for skew RS codes</dc:title>
 <dc:creator>G&#xf3;mez-Torrecillas, Jos&#xe9;</dc:creator>
 <dc:creator>Lobillo, F. J.</dc:creator>
 <dc:creator>Navarro, Gabriel</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B15, 94B35, 94B10, 15A03</dc:subject>
 <dc:description>  We design a non-commutative version of the Peterson-Gorenstein-Zierler
decoding algorithm for a class of codes that we call skew RS codes. These codes
are left ideals of a quotient of a skew polynomial ring, which endow them of a
sort of non-commutative cyclic structure. Since we work over an arbitrary
field, our techniques may be applied both to linear block codes and
convolutional codes. In particular, our decoding algorithm applies for block
codes beyond the classical cyclic case.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00745</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00754</identifier>
 <datestamp>2017-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RGBDTAM: A Cost-Effective and Accurate RGB-D Tracking and Mapping System</dc:title>
 <dc:creator>Concha, Alejo</dc:creator>
 <dc:creator>Civera, Javier</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Simultaneous Localization and Mapping using RGB-D cameras has been a fertile
research topic in the latest decade, due to the suitability of such sensors for
indoor robotics. In this paper we propose a direct RGB-D SLAM algorithm with
state-of-the-art accuracy and robustness at a los cost. Our experiments in the
RGB-D TUM dataset [34] effectively show a better accuracy and robustness in CPU
real time than direct RGB-D SLAM systems that make use of the GPU. The key
ingredients of our approach are mainly two. Firstly, the combination of a
semi-dense photometric and dense geometric error for the pose tracking (see
Figure 1), which we demonstrate to be the most accurate alternative. And
secondly, a model of the multi-view constraints and their errors in the mapping
and tracking threads, which adds extra information over other approaches. We
release the open-source implementation of our approach 1 . The reader is
referred to a video with our results 2 for a more illustrative visualization of
its performance.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-08-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00757</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Rankings of Software Verification Competitions</dc:title>
 <dc:creator>Czech, Mike</dc:creator>
 <dc:creator>H&#xfc;llermeier, Eyke</dc:creator>
 <dc:creator>Jakobs, Marie-Christine</dc:creator>
 <dc:creator>Wehrheim, Heike</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:description>  Software verification competitions, such as the annual SV-COMP, evaluate
software verification tools with respect to their effectivity and efficiency.
Typically, the outcome of a competition is a (possibly category-specific)
ranking of the tools. For many applications, such as building portfolio
solvers, it would be desirable to have an idea of the (relative) performance of
verification tools on a given verification task beforehand, i.e., prior to
actually running all tools on the task.
  In this paper, we present a machine learning approach to predicting rankings
of tools on verification tasks. The method builds upon so-called label ranking
algorithms, which we complement with appropriate kernels providing a similarity
measure for verification tasks. Our kernels employ a graph representation for
software source code that mixes elements of control flow and program dependence
graphs with abstract syntax trees. Using data sets from SV-COMP, we demonstrate
our rank prediction technique to generalize well and achieve a rather high
predictive accuracy. In particular, our method outperforms a recently proposed
feature-based approach of Demyanova et al. (when applied to rank predictions).
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00757</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00759</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-time public transport service-level monitoring using passive WiFi:
  a spectral clustering approach for train timetable estimation</dc:title>
 <dc:creator>Song, Baoyang</dc:creator>
 <dc:creator>Wynter, Laura</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  A new area in which passive WiFi analytics have promise for delivering value
is the real-time monitoring of public transport systems. One example is
determining the true (as opposed to the published) timetable of a public
transport system in real-time. In most cases, there are no other
publicly-available sources for this information. Yet, it is indispensable for
the real-time monitoring of public transport service levels. Furthermore, this
information, if accurate and temporally fine-grained, can be used for very
low-latency incident detection. In this work, we propose using spectral
clustering based on trajectories derived from passive WiFi traces of users of a
public transport system to infer the true timetable and two key performance
indicators of the transport service, namely public transport vehicle headway
and in-station dwell time. By detecting anomalous dwell times or headways, we
demonstrate that a fast and accurate real-time incident-detection procedure can
be obtained. The method we introduce makes use of the advantages of the
high-frequency WiFi data, which provides very low-latency,
universally-accessible information, while minimizing the impact of the noise in
the data.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00759</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00760</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sampling Variations of Lead Sheets</dc:title>
 <dc:creator>Roy, Pierre</dc:creator>
 <dc:creator>Papadopoulos, Alexandre</dc:creator>
 <dc:creator>Pachet, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Machine-learning techniques have been recently used with spectacular results
to generate artefacts such as music or text. However, these techniques are
still unable to capture and generate artefacts that are convincingly
structured. In this paper we present an approach to generate structured musical
sequences. We introduce a mechanism for sampling efficiently variations of
musical sequences. Given a input sequence and a statistical model, this
mechanism samples a set of sequences whose distance to the input sequence is
approximately within specified bounds. This mechanism is implemented as an
extension of belief propagation, and uses local fields to bias the generation.
We show experimentally that sampled sequences are indeed closely correlated to
the standard musical similarity measure defined by Mongeau and Sankoff. We then
show how this mechanism can used to implement composition strategies that
enforce arbitrary structure on a musical lead sheet generation problem.
</dc:description>
 <dc:description>Comment: 16 pages, 11 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00760</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00761</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On a class of constacyclic codes over the non-principal ideal ring
  $\mathbb{Z}_{p^s}+u\mathbb{Z}_{p^s}$</dc:title>
 <dc:creator>Cao, Yuan</dc:creator>
 <dc:creator>Cao, Yonglin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  $(1+pw)$-constacyclic codes of arbitrary length over the non-principal ideal
ring $\mathbb{Z}_{p^s} +u\mathbb{Z}_{p^s}$ are studied, where $p$ is a prime,
$w\in \mathbb{Z}_{p^s}^{\times}$ and $s$ an integer satisfying $s\geq 2$.
First, the structure of any $(1+pw)$-constacyclic code over $\mathbb{Z}_{p^s}
+u\mathbb{Z}_{p^s}$ are presented. Then enumerations for the number of all
codes and the number of codewords in each code, and the structure of dual codes
for these codes are given, respectively. Then self-dual $(1+2w)$-constacyclic
codes over $\mathbb{Z}_{2^s} +u\mathbb{Z}_{2^s}$ are investigated, where
$w=2^{s-2}-1$ or $2^{s-1}-1$ if $s\geq 3$, and $w=1$ if $s=2$.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00767</identifier>
 <datestamp>2017-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentive Recurrent Comparators</dc:title>
 <dc:creator>Shyam, Pranav</dc:creator>
 <dc:creator>Gupta, Shubham</dc:creator>
 <dc:creator>Dukkipati, Ambedkar</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Rapid learning requires flexible representations to quickly adopt to new
evidence. We develop a novel class of models called Attentive Recurrent
Comparators (ARCs) that form representations of objects by cycling through them
and making observations. Using the representations extracted by ARCs, we
develop a way of approximating a \textit{dynamic representation space} and use
it for one-shot learning. In the task of one-shot classification on the
Omniglot dataset, we achieve the state of the art performance with an error
rate of 1.5\%. This represents the first super-human result achieved for this
task with a generic model that uses only pixel information.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-06-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00767</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00768</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Causes My Test Alarm? Automatic Cause Analysis for Test Alarms in
  System and Integration Testing</dc:title>
 <dc:creator>Jiang, He</dc:creator>
 <dc:creator>Li, Xiaochen</dc:creator>
 <dc:creator>Yang, Zijiang</dc:creator>
 <dc:creator>Xuan, Jifeng</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Driven by new software development processes and testing in clouds, system
and integration testing nowadays tends to produce enormous number of alarms.
Such test alarms lay an almost unbearable burden on software testing engineers
who have to manually analyze the causes of these alarms. The causes are
critical because they decide which stakeholders are responsible to fix the bugs
detected during the testing. In this paper, we present a novel approach that
aims to relieve the burden by automating the procedure. Our approach, called
Cause Analysis Model, exploits information retrieval techniques to efficiently
infer test alarm causes based on test logs. We have developed a prototype and
evaluated our tool on two industrial datasets with more than 14,000 test
alarms. Experiments on the two datasets show that our tool achieves an accuracy
of 58.3% and 65.8%, respectively, which outperforms the baseline algorithms by
up to 13.3%. Our algorithm is also extremely efficient, spending about 0.1s per
cause analysis. Due to the attractive experimental results, our industrial
partner, a leading information and communication technology company in the
world, has deployed the tool and it achieves an average accuracy of 72% after
two months of running, nearly three times more accurate than a previous
strategy based on regular expressions.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00782</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lock-Free Parallel Perceptron for Graph-based Dependency Parsing</dc:title>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:creator>Ma, Shuming</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Dependency parsing is an important NLP task. A popular approach for
dependency parsing is structured perceptron. Still, graph-based dependency
parsing has the time complexity of $O(n^3)$, and it suffers from slow training.
To deal with this problem, we propose a parallel algorithm called parallel
perceptron. The parallel algorithm can make full use of a multi-core computer
which saves a lot of training time. Based on experiments we observe that
dependency parsing with parallel perceptron can achieve 8-fold faster training
speed than traditional structured perceptron methods when using 10 threads, and
with no loss at all in accuracy.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00782</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00785</identifier>
 <datestamp>2017-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Non-Intrusive Load Monitoring Methodies and Techniques for
  Energy Disaggregation Problem</dc:title>
 <dc:creator>Faustine, Anthony</dc:creator>
 <dc:creator>Mvungi, Nerey Henry</dc:creator>
 <dc:creator>Kaijage, Shubi</dc:creator>
 <dc:creator>Michael, Kisangiri</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  The rapid urbanization of developing countries coupled with explosion in
construction of high rising buildings and the high power usage in them calls
for conservation and efficient energy program. Such a program require
monitoring of end-use appliances energy consumption in real-time. The worldwide
recent adoption of smart-meter in smart-grid, has led to the rise of
Non-Intrusive Load Monitoring (NILM); which enables estimation of
appliance-specific power consumption from building's aggregate power
consumption reading. NILM provides households with cost-effective real-time
monitoring of end-use appliances to help them understand their consumption
pattern and become part and parcel of energy conservation strategy. This paper
presents an up to date overview of NILM system and its associated methods and
techniques for energy disaggregation problem. This is followed by the review of
the state-of-the art NILM algorithms. Furthermore, we review several
performance metrics used by NILM researcher to evaluate NILM algorithms and
discuss existing benchmarking framework for direct comparison of the state of
the art NILM algorithms. Finally, the paper discuss potential NILM use-cases,
presents an overview of the public available dataset and highlight challenges
and future research directions.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00786</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generic Online Parallel Learning Framework for Large Margin Models</dc:title>
 <dc:creator>Ma, Shuming</dc:creator>
 <dc:creator>Sun, Xu</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  To speed up the training process, many existing systems use parallel
technology for online learning algorithms. However, most research mainly focus
on stochastic gradient descent (SGD) instead of other algorithms. We propose a
generic online parallel learning framework for large margin models, and also
analyze our framework on popular large margin algorithms, including MIRA and
Structured Perceptron. Our framework is lock-free and easy to implement on
existing systems. Experiments show that systems with our framework can gain
near linear speed up by increasing running threads, and with no loss in
accuracy.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00786</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00788</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Robust Adaptive Stochastic Gradient Method for Deep Learning</dc:title>
 <dc:creator>Gulcehre, Caglar</dc:creator>
 <dc:creator>Sotelo, Jose</dc:creator>
 <dc:creator>Moczulski, Marcin</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic gradient algorithms are the main focus of large-scale optimization
problems and led to important successes in the recent advancement of the deep
learning algorithms. The convergence of SGD depends on the careful choice of
learning rate and the amount of the noise in stochastic estimates of the
gradients. In this paper, we propose an adaptive learning rate algorithm, which
utilizes stochastic curvature information of the loss function for
automatically tuning the learning rates. The information about the element-wise
curvature of the loss function is estimated from the local statistics of the
stochastic first order gradients. We further propose a new variance reduction
technique to speed up the convergence. In our experiments with deep neural
networks, we obtained better performance compared to the popular stochastic
gradient algorithms.
</dc:description>
 <dc:description>Comment: IJCNN 2017 Accepted Paper, An extension of our paper, &quot;ADASECANT:
  Robust Adaptive Secant Method for Stochastic Gradient&quot;</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00792</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Spatial Filtering with Graph Convolutional Neural Networks</dc:title>
 <dc:creator>Such, Felipe Petroski</dc:creator>
 <dc:creator>Sah, Shagan</dc:creator>
 <dc:creator>Dominguez, Miguel</dc:creator>
 <dc:creator>Pillai, Suhas</dc:creator>
 <dc:creator>Zhang, Chao</dc:creator>
 <dc:creator>Michael, Andrew</dc:creator>
 <dc:creator>Cahill, Nathan</dc:creator>
 <dc:creator>Ptucha, Raymond</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) have recently led to incredible
breakthroughs on a variety of pattern recognition problems. Banks of finite
impulse response filters are learned on a hierarchy of layers, each
contributing more abstract information than the previous layer. The simplicity
and elegance of the convolutional filtering process makes them perfect for
structured problems such as image, video, or voice, where vertices are
homogeneous in the sense of number, location, and strength of neighbors. The
vast majority of classification problems, for example in the pharmaceutical,
homeland security, and financial domains are unstructured. As these problems
are formulated into unstructured graphs, the heterogeneity of these problems,
such as number of vertices, number of connections per vertex, and edge
strength, cannot be tackled with standard convolutional techniques. We propose
a novel neural learning framework that is capable of handling both homogeneous
and heterogeneous data, while retaining the benefits of traditional CNN
successes.
  Recently, researchers have proposed variations of CNNs that can handle graph
data. In an effort to create learnable filter banks of graphs, these methods
either induce constraints on the data or require preprocessing. As opposed to
spectral methods, our framework, which we term Graph-CNNs, defines filters as
polynomials of functions of the graph adjacency matrix. Graph-CNNs can handle
both heterogeneous and homogeneous graph data, including graphs having entirely
different vertex or edge sets. We perform experiments to validate the
applicability of Graph-CNNs to a variety of structured and unstructured
classification problems and demonstrate state-of-the-art results on document
and molecule classification problems.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00792</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2017.2726981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00796</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Steganalysis Based on Artificial Training Sets</dc:title>
 <dc:creator>Lerch-Hostalot, Daniel</dc:creator>
 <dc:creator>Meg&#xed;as, David</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, an unsupervised steganalysis method that combines artificial
training setsand supervised classification is proposed. We provide a formal
framework for unsupervisedclassification of stego and cover images in the
typical situation of targeted steganalysis (i.e.,for a known algorithm and
approximate embedding bit rate). We also present a completeset of experiments
using 1) eight different image databases, 2) image features based on
RichModels, and 3) three different embedding algorithms: Least Significant Bit
(LSB) matching,Highly undetectable steganography (HUGO) and Wavelet Obtained
Weights (WOW). Weshow that the experimental results outperform previous methods
based on Rich Models inthe majority of the tested cases. At the same time, the
proposed approach bypasses theproblem of Cover Source Mismatch -when the
embedding algorithm and bit rate are known-, since it removes the need of a
training database when we have a large enough testing set.Furthermore, we
provide a generic proof of the proposed framework in the machine
learningcontext. Hence, the results of this paper could be extended to other
classification problemssimilar to steganalysis.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00796</dc:identifier>
 <dc:identifier>doi:10.1016/j.engappai.2015.12.013</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00797</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple, Fast and Fully Automated Approach for Midline Shift
  Measurement on Brain Computed Tomography</dc:title>
 <dc:creator>Wang, Huan-Chih</dc:creator>
 <dc:creator>Ho, Shih-Hao</dc:creator>
 <dc:creator>Xiao, Furen</dc:creator>
 <dc:creator>Chou, Jen-Hai</dc:creator>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Brain CT has become a standard imaging tool for emergent evaluation of brain
condition, and measurement of midline shift (MLS) is one of the most important
features to address for brain CT assessment. We present a simple method to
estimate MLS and propose a new alternative parameter to MLS: the ratio of MLS
over the maximal width of intracranial region (MLS/ICWMAX). Three neurosurgeons
and our automated system were asked to measure MLS and MLS/ICWMAX in the same
sets of axial CT images obtained from 41 patients admitted to ICU under
neurosurgical service. A weighted midline (WML) was plotted based on individual
pixel intensities, with higher weighted given to the darker portions. The MLS
could then be measured as the distance between the WML and ideal midline (IML)
near the foramen of Monro. The average processing time to output an automatic
MLS measurement was around 10 seconds. Our automated system achieved an overall
accuracy of 90.24% when the CT images were calibrated automatically, and
performed better when the calibrations of head rotation were done manually
(accuracy: 92.68%). MLS/ICWMAX and MLS both gave results in same confusion
matrices and produced similar ROC curve results. We demonstrated a simple, fast
and accurate automated system of MLS measurement and introduced a new parameter
(MLS/ICWMAX) as a good alternative to MLS in terms of estimating the degree of
brain deformation, especially when non-DICOM images (e.g. JPEG) are more easily
accessed.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00800</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Creative Community Demystified: A Statistical Overview of Behance</dc:title>
 <dc:creator>Kim, Nam Wook</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Online communities are changing the ways that creative professionals such as
artists and designers share ideas, receive feedback, and find inspiration.
While they became increasingly popular, there have been few studies so far. In
this paper, we investigate Behance, an online community site for creatives to
maintain relationships with others and showcase their works from various fields
such as graphic design, illustration, photography, and fashion. We take a
quantitative approach to study three research questions about the site. What
attract followers and appreciation of artworks on Behance? what patterns of
activity exist around topics? And, lastly, does color play a role in attracting
appreciation? In summary, being male suggests more followers and appreciations,
most users focus on a few topics, and grayscale colors mean fewer
appreciations. This work serves as a preliminary overview of a creative
community that later studies can build on.
</dc:description>
 <dc:description>Comment: 10 pages, 8 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00807</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Management and Optimal Pricing in People-Centric Sensing</dc:title>
 <dc:creator>Alsheikh, Mohammad Abu</dc:creator>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Leong, Derek</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  With the emerging sensing technologies such as mobile crowdsensing and
Internet of Things (IoT), people-centric data can be efficiently collected and
used for analytics and optimization purposes. This data is typically required
to develop and render people-centric services. In this paper, we address the
privacy implication, optimal pricing, and bundling of people-centric services.
We first define the inverse correlation between the service quality and privacy
level from data analytics perspectives. We then present the profit maximization
models of selling standalone, complementary, and substitute services.
Specifically, the closed-form solutions of the optimal privacy level and
subscription fee are derived to maximize the gross profit of service providers.
For interrelated people-centric services, we show that cooperation by service
bundling of complementary services is profitable compared to the separate sales
but detrimental for substitutes. We also show that the market value of a
service bundle is correlated with the degree of contingency between the
interrelated services. Finally, we incorporate the profit sharing models from
game theory for dividing the bundling profit among the cooperative service
providers.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00807</dc:identifier>
 <dc:identifier>doi:10.1109/JSAC.2017.2680845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00810</identifier>
 <datestamp>2017-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opening the Black Box of Deep Neural Networks via Information</dc:title>
 <dc:creator>Shwartz-Ziv, Ravid</dc:creator>
 <dc:creator>Tishby, Naftali</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Despite their great success, there is still no comprehensive theoretical
understanding of learning with Deep Neural Networks (DNNs) or their inner
organization. Previous work proposed to analyze DNNs in the \textit{Information
Plane}; i.e., the plane of the Mutual Information values that each layer
preserves on the input and output variables. They suggested that the goal of
the network is to optimize the Information Bottleneck (IB) tradeoff between
compression and prediction, successively, for each layer.
  In this work we follow up on this idea and demonstrate the effectiveness of
the Information-Plane visualization of DNNs. Our main results are: (i) most of
the training epochs in standard DL are spent on {\emph compression} of the
input to efficient representation and not on fitting the training labels. (ii)
The representation compression phase begins when the training errors becomes
small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift
to smaller training error into a stochastic relaxation, or random diffusion,
constrained by the training error value. (iii) The converged layers lie on or
very close to the Information Bottleneck (IB) theoretical bound, and the maps
from the input to any hidden layer and from this hidden layer to the output
satisfy the IB self-consistent equations. This generalization through noise
mechanism is unique to Deep Neural Networks and absent in one layer networks.
(iv) The training time is dramatically reduced when adding more hidden layers.
Thus the main advantage of the hidden layers is computational. This can be
explained by the reduced relaxation time, as this it scales super-linearly
(exponentially for simple diffusion) with the information compression from the
previous layer.
</dc:description>
 <dc:description>Comment: 19 pages, 8 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-04-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00812</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improper Filter Reduction</dc:title>
 <dc:creator>Saberifar, Fatemeh Zahra</dc:creator>
 <dc:creator>Mohades, Ali</dc:creator>
 <dc:creator>Razzazi, Mohammadreza</dc:creator>
 <dc:creator>O'Kane, Jason M.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  Combinatorial filters have been the subject of increasing interest from the
robotics community in recent years. This paper considers automatic reduction of
combinatorial filters to a given size, even if that reduction necessitates
changes to the filter's behavior. We introduce an algorithmic problem called
improper filter reduction, in which the input is a combinatorial filter F along
with an integer k representing the target size. The output is another
combinatorial filter F' with at most k states, such that the difference in
behavior between F and F' is minimal. We present two metrics for measuring the
distance between pairs of filters, describe dynamic programming algorithms for
computing these distances, and show that improper filter reduction is NP-hard
under these metrics. We then describe two heuristic algorithms for improper
filter reduction, one greedy sequential approach, and one randomized global
approach based on prior work on weighted improper graph coloring. We have
implemented these algorithms and analyze the results of three sets of
experiments.
</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00817</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSB Matching Steganalysis Based on Patterns of Pixel Differences and
  Random Embedding</dc:title>
 <dc:creator>Lerch-Hostalot, Daniel</dc:creator>
 <dc:creator>Meg&#xed;as, David</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This paper presents a novel method for detection of LSB matching steganogra-
phy in grayscale images. This method is based on the analysis of the
differences between neighboring pixels before and after random data embedding.
In natu- ral images, there is a strong correlation between adjacent pixels.
This correla- tion is disturbed by LSB matching generating new types of
correlations. The pre- sented method generates patterns from these correlations
and analyzes their varia- tion when random data are hidden. The experiments
performed for two different image databases show that the method yields better
classification accuracy com- pared to prior art for both LSB matching and HUGO
steganography. In addition, although the method is designed for the spatial
domain, some experiments show its applicability also for detecting JPEG
steganography.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00817</dc:identifier>
 <dc:identifier>doi:10.1016/j.cose.2012.11.005.</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00818</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating Singleplayer and Multiplayer in Human Computation Games</dc:title>
 <dc:creator>Siu, Kristin</dc:creator>
 <dc:creator>Guzdial, Matthew</dc:creator>
 <dc:creator>Riedl, Mark O.</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Human computation games (HCGs) can provide novel solutions to intractable
computational problems, help enable scientific breakthroughs, and provide
datasets for artificial intelligence. However, our knowledge about how to
design and deploy HCGs that appeal to players and solve problems effectively is
incomplete. We present an investigatory HCG based on Super Mario Bros. We used
this game in a human subjects study to investigate how different social
conditions---singleplayer and multiplayer---and scoring
mechanics---collaborative and competitive---affect players' subjective
experiences, accuracy at the task, and the completion rate. In doing so, we
demonstrate a novel design approach for HCGs, and discuss the benefits and
tradeoffs of these mechanics in HCG design.
</dc:description>
 <dc:description>Comment: 10 pages, 4 figures, 2 tables</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00830</identifier>
 <datestamp>2017-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General and Robust Communication-Efficient Algorithms for Distributed
  Clustering</dc:title>
 <dc:creator>Awasthi, Pranjal</dc:creator>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>White, Colin</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  As datasets become larger and more distributed, algorithms for distributed
clustering have become more and more important. In this work, we present a
general framework for designing distributed clustering algorithms that are
robust to outliers. Using our framework, we give a distributed approximation
algorithm for k-means, k-median, or generally any L_p objective, with z
outliers and/or balance constraints, using O(m(k+z)(d+log n)) bits of
communication, where m is the number of machines, n is the size of the point
set, and d is the dimension. This generalizes and improves over previous work
of Bateni et al. and Malkomes et al. As a special case, we achieve the first
distributed algorithm for k-median with outliers, answering an open question
posed by Malkomes et al. For distributed k-means clustering, we provide the
first dimension-dependent communication complexity lower bound for finding the
optimal clustering. This improves over the lower bound from Chen et al. which
is dimension-agnostic.
  Furthermore, we give distributed clustering algorithms which return nearly
optimal solutions, provided the data satisfies the approximation stability
condition of Balcan et al. or the spectral stability condition of Kumar and
Kannan.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-10-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00832</identifier>
 <datestamp>2018-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Reconstruction of Deep Face Templates</dc:title>
 <dc:creator>Mai, Guangcan</dc:creator>
 <dc:creator>Cao, Kai</dc:creator>
 <dc:creator>Yuen, Pong C.</dc:creator>
 <dc:creator>Jain, Anil K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  State-of-the-art face recognition systems are based on deep (convolutional)
neural networks. Therefore, it is imperative to determine to what extent face
templates derived from deep networks can be inverted to obtain the original
face image. In this paper, we study the vulnerabilities of a state-of-the-art
face recognition system based on template reconstruction attack. We propose a
neighborly de-convolutional neural network (\textit{NbNet}) to reconstruct face
images from their deep templates. In our experiments, we assumed that no
knowledge about the target subject and the deep network are available. To train
the \textit{NbNet} reconstruction models, we augmented two benchmark face
datasets (VGG-Face and Multi-PIE) with a large collection of images synthesized
using a face generator. The proposed reconstruction was evaluated using type-I
(comparing the reconstructed images against the original face images used to
generate the deep template) and type-II (comparing the reconstructed images
against a different face image of the same subject) attacks. Given the images
reconstructed from \textit{NbNets}, we show that for verification, we achieve
TAR of 95.20\% (58.05\%) on LFW under type-I (type-II) attacks @ FAR of 0.1\%.
Besides, 96.58\% (92.84\%) of the images reconstruction from templates of
partition \textit{fa} (\textit{fb}) can be identified from partition
\textit{fa} in color FERET. Our study demonstrates the need to secure deep
templates in face recognition systems.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2018-01-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00832</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00835</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Skill-centric Testing using Deep Learning</dc:title>
 <dc:creator>Hangl, Simon</dc:creator>
 <dc:creator>Stabinger, Sebastian</dc:creator>
 <dc:creator>Piater, Justus</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Software testing is an important tool to ensure software quality. This is a
hard task in robotics due to dynamic environments and the expensive development
and time-consuming execution of test cases. Most testing approaches use
model-based and / or simulation-based testing to overcome these problems. We
propose model-free skill-centric testing in which a robot autonomously executes
skills in the real world and compares it to previous experiences. The skills
are selected by maximising the expected information gain on the distribution of
erroneous software functions. We use deep learning to model the sensor data
observed during previous successful skill executions and to detect
irregularities. Sensor data is connected to function call profiles such that
certain misbehaviour can be related to specific functions. We evaluate our
approach in simulation and in experiments with a KUKA LWR 4+ robot by
purposefully introducing bugs to the software. We demonstrate that these bugs
can be detected with high accuracy and without the need for the implementation
of specific tests or task-specific models.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00837</identifier>
 <datestamp>2017-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Meta Networks</dc:title>
 <dc:creator>Munkhdalai, Tsendsuren</dc:creator>
 <dc:creator>Yu, Hong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neural networks have been successfully applied in applications with a large
amount of labeled data. However, the task of rapid generalization on new
concepts with small training data while preserving performances on previously
learned ones still presents a significant challenge to neural network models.
In this work, we introduce a novel meta learning method, Meta Networks
(MetaNet), that learns a meta-level knowledge across tasks and shifts its
inductive biases via fast parameterization for rapid generalization. When
evaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve
a near human-level performance and outperform the baseline approaches by up to
6% accuracy. We demonstrate several appealing properties of MetaNet relating to
generalization and continual learning.
</dc:description>
 <dc:description>Comment: Accepted at ICML 2017 - rewrote: the main section; added: MetaNet
  algorithmic procedure; performed: Mini-ImageNet evaluation</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00837</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00838</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SLIM: Semi-Lazy Inference Mechanism for Plan Recognition</dc:title>
 <dc:creator>Mirsky, Retuh</dc:creator>
 <dc:creator>Ya'akov</dc:creator>
 <dc:creator>Gal</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Plan Recognition algorithms require to recognize a complete hierarchy
explaining the agent's actions and goals. While the output of such algorithms
is informative to the recognizer, the cost of its calculation is high in
run-time, space, and completeness. Moreover, performing plan recognition online
requires the observing agent to reason about future actions that have not yet
been seen and maintain a set of hypotheses to support all possible options.
This paper presents a new and efficient algorithm for online plan recognition
called SLIM (Semi-Lazy Inference Mechanism). It combines both a bottom-up and
top-down parsing processes, which allow it to commit only to the minimum
necessary actions in real-time, but still provide complete hypotheses post
factum. We show both theoretically and empirically that although the
computational cost of this process is still exponential, there is a significant
improvement in run-time when compared to a state of the art of plan recognition
algorithm.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00838</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00839</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Encrypted accelerated least squares regression</dc:title>
 <dc:creator>Esperan&#xe7;a, Pedro M.</dc:creator>
 <dc:creator>Aslett, Louis J. M.</dc:creator>
 <dc:creator>Holmes, Chris C.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Information that is stored in an encrypted format is, by definition, usually
not amenable to statistical analysis or machine learning methods. In this paper
we present detailed analysis of coordinate and accelerated gradient descent
algorithms which are capable of fitting least squares and penalised ridge
regression models, using data encrypted under a fully homomorphic encryption
scheme. Gradient descent is shown to dominate in terms of encrypted
computational speed, and theoretical results are proven to give parameter
bounds which ensure correctness of decryption. The characteristics of encrypted
computation are empirically shown to favour a non-standard acceleration
technique. This demonstrates the possibility of approximating conventional
statistical regression methods using encrypted data without compromising
privacy.
</dc:description>
 <dc:description>Comment: Accepted for AISTATS 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00839</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00845</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards CNN Map Compression for camera relocalisation</dc:title>
 <dc:creator>Contreras, Luis</dc:creator>
 <dc:creator>Mayol-Cuevas, Walterio</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a study on the use of Convolutional Neural Networks for
camera relocalisation and its application to map compression. We follow state
of the art visual relocalisation results and evaluate response to different
data inputs -- namely, depth, grayscale, RGB, spatial position and combinations
of these. We use a CNN map representation and introduce the notion of CNN map
compression by using a smaller CNN architecture. We evaluate our proposal in a
series of publicly available datasets. This formulation allows us to improve
relocalisation accuracy by increasing the number of training trajectories while
maintaining a constant-size CNN.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00847</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exact Topology Reconstruction of Radial Dynamical Systems with
  Applications to Distribution System of the Power Grid</dc:title>
 <dc:creator>Talukdar, Saurav</dc:creator>
 <dc:creator>Deka, Deepjyoti</dc:creator>
 <dc:creator>Materassi, Donatello</dc:creator>
 <dc:creator>Salapaka, Murti V.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this article we present a method to reconstruct the interconnectedness of
dynamically related stochastic processes, where the interactions are
bi-directional and the underlying topology is a tree. Our approach is based on
multivariate Wiener filtering which recovers spurious edges apart from the true
edges in the topology reconstruction. The main contribution of this work is to
show that all spurious links obtained using Wiener filtering can be eliminated
if the underlying topology is a tree based on which we present a three stage
network reconstruction procedure for trees. We illustrate the effectiveness of
the method developed by applying it on a typical distribution system of the
electric grid.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00847</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00848</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Image-to-Image Translation Networks</dc:title>
 <dc:creator>Liu, Ming-Yu</dc:creator>
 <dc:creator>Breuel, Thomas</dc:creator>
 <dc:creator>Kautz, Jan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Unsupervised image-to-image translation aims at learning a joint distribution
of images in different domains by using images from the marginal distributions
in individual domains. Since there exists an infinite set of joint
distributions that can arrive the given marginal distributions, one could infer
nothing about the joint distribution from the marginal distributions without
additional assumptions. To address the problem, we make a shared-latent space
assumption and propose an unsupervised image-to-image translation framework
based on Coupled GANs. We compare the proposed framework with competing
approaches and present high quality image translation results on various
challenging unsupervised image translation tasks, including street scene image
translation, animal image translation, and face image translation. We also
apply the proposed framework to domain adaptation and achieve state-of-the-art
performance on benchmark datasets. Code and additional results are available in
https://github.com/mingyuliutw/unit .
</dc:description>
 <dc:description>Comment: NIPS 2017, 11 pages, 6 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-10-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00849</identifier>
 <datestamp>2017-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Node Cooperation with Resource Availability Constraints</dc:title>
 <dc:creator>Corrales, Luis David Alvarez</dc:creator>
 <dc:creator>Giovanidis, Anastasios</dc:creator>
 <dc:creator>Martins, Philippe</dc:creator>
 <dc:creator>Decreusefond, Laurent</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Base station cooperation is a promising scheme to improve network performance
for next generation cellular networks. Up to this point research has focused on
station grouping criteria based solely on geographic proximity. However, for
the cooperation to be meaningful, each station participating in a group should
have sufficient available resources to share with others. In this work we
consider an alternative grouping criterion based on a distance that considers
both geographic proximity and available resources of the stations. When the
network is modelled by a Poisson Point Process, we derive analytical formulas
on the proportion of cooperative pairs or single stations, and the expected sum
interference from each of the groups. The results illustrate that cooperation
gains strongly depend on the distribution of available resources over the
network.
</dc:description>
 <dc:description>Comment: submitted, 12 pages, double-column, 7 figures, 8 sub-figures in total</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00849</dc:identifier>
 <dc:identifier>doi:10.23919/WIOPT.2017.7959946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00854</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning the Structure of Generative Models without Labeled Data</dc:title>
 <dc:creator>Bach, Stephen H.</dc:creator>
 <dc:creator>He, Bryan</dc:creator>
 <dc:creator>Ratner, Alexander</dc:creator>
 <dc:creator>R&#xe9;, Christopher</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Curating labeled training data has become the primary bottleneck in machine
learning. Recent frameworks address this bottleneck with generative models to
synthesize labels at scale from weak supervision sources. The generative
model's dependency structure directly affects the quality of the estimated
labels, but selecting a structure automatically without any labeled data is a
distinct challenge. We propose a structure estimation method that maximizes the
$\ell_1$-regularized marginal pseudolikelihood of the observed data. Our
analysis shows that the amount of unlabeled data required to identify the true
structure scales sublinearly in the number of possible dependencies for a broad
class of models. Simulations show that our method is 100$\times$ faster than a
maximum likelihood approach and selects $1/4$ as many extraneous dependencies.
We also show that our method provides an average of 1.5 F1 points of
improvement over existing, user-developed information extraction applications
on real-world data such as PubMed journal abstracts.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00854</dc:identifier>
 <dc:identifier>Proceedings of the 34th International Conference on Machine
  Learning, Sydney, Australia, PMLR 70, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00856</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Araguaia Medical Vision Lab at ISIC 2017 Skin Lesion Classification
  Challenge</dc:title>
 <dc:creator>Sousa, Rafael Teixeira</dc:creator>
 <dc:creator>de Moraes, Larissa Vasconcellos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper describes the participation of Araguaia Medical Vision Lab at the
International Skin Imaging Collaboration 2017 Skin Lesion Challenge. We
describe the use of deep convolutional neural networks in attempt to classify
images of Melanoma and Seborrheic Keratosis lesions. With use of finetuned
GoogleNet and AlexNet we attained results of 0.950 and 0.846 AUC on Seborrheic
Keratosis and Melanoma respectively.
</dc:description>
 <dc:description>Comment: Abstract submitted as a requirement to ISIC2017 challenge</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00856</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00857</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Friendship Maintenance and Prediction in Multiple Social Networks</dc:title>
 <dc:creator>Lee, Roy Ka-Wei</dc:creator>
 <dc:creator>Lim, Ee-Peng</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Due to the proliferation of online social networks (OSNs), users find
themselves participating in multiple OSNs. These users leave their activity
traces as they maintain friendships and interact with other users in these
OSNs. In this work, we analyze how users maintain friendship in multiple OSNs
by studying users who have accounts in both Twitter and Instagram.
Specifically, we study the similarity of a user's friendship and the evenness
of friendship distribution in multiple OSNs. Our study shows that most users in
Twitter and Instagram prefer to maintain different friendships in the two OSNs,
keeping only a small clique of common friends in across the OSNs. Based upon
our empirical study, we conduct link prediction experiments to predict missing
friendship links in multiple OSNs using the neighborhood features, neighborhood
friendship maintenance features and cross-link features. Our link prediction
experiments shows that un- supervised methods can yield good accuracy in
predicting links in one OSN using another OSN data and the link prediction
accuracy can be further improved using supervised method with friendship
maintenance and others measures as features.
</dc:description>
 <dc:description>Comment: 27th ACM Conference on Hypertext and Social Media (HT'16)</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00862</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binarized Convolutional Landmark Localizers for Human Pose Estimation
  and Face Alignment with Limited Resources</dc:title>
 <dc:creator>Bulat, Adrian</dc:creator>
 <dc:creator>Tzimiropoulos, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Our goal is to design architectures that retain the groundbreaking
performance of CNNs for landmark localization and at the same time are
lightweight, compact and suitable for applications with limited computational
resources. To this end, we make the following contributions: (a) we are the
first to study the effect of neural network binarization on localization tasks,
namely human pose estimation and face alignment. We exhaustively evaluate
various design choices, identify performance bottlenecks, and more importantly
propose multiple orthogonal ways to boost performance. (b) Based on our
analysis, we propose a novel hierarchical, parallel and multi-scale residual
architecture that yields large performance improvement over the standard
bottleneck block while having the same number of parameters, thus bridging the
gap between the original network and its binarized counterpart. (c) We perform
a large number of ablation studies that shed light on the properties and the
performance of the proposed block. (d) We present results for experiments on
the most challenging datasets for human pose estimation and face alignment,
reporting in many cases state-of-the-art performance. Code can be downloaded
from https://www.adrianbulat.com/binary-cnn-landmarks
</dc:description>
 <dc:description>Comment: ICCV 2017 Oral</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00868</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Synthetic Data to Train Neural Networks is Model-Based Reasoning</dc:title>
 <dc:creator>Le, Tuan Anh</dc:creator>
 <dc:creator>Baydin, Atilim Gunes</dc:creator>
 <dc:creator>Zinkov, Robert</dc:creator>
 <dc:creator>Wood, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>68T05, 68T10</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.7.5</dc:subject>
 <dc:description>  We draw a formal connection between using synthetic training data to optimize
neural network parameters and approximate, Bayesian, model-based reasoning. In
particular, training a neural network using synthetic data can be viewed as
learning a proposal distribution generator for approximate inference in the
synthetic-data generative model. We demonstrate this connection in a
recognition task where we develop a novel Captcha-breaking architecture and
train it using synthetic data, demonstrating both state-of-the-art performance
and a way of computing task-specific posterior uncertainty. Using a neural
network trained this way, we also demonstrate successful breaking of real-world
Captchas currently used by Facebook and Wikipedia. Reasoning from these
empirical results and drawing connections with Bayesian modeling, we discuss
the robustness of synthetic data results and suggest important considerations
for ensuring good neural network generalization when training with synthetic
data.
</dc:description>
 <dc:description>Comment: 8 pages, 4 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00874</identifier>
 <datestamp>2017-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Aaronson-Gottesman stabilizer circuit simulation through
  quantum circuit transformations</dc:title>
 <dc:creator>Maslov, Dmitri</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  In this paper we improve the layered implementation of arbitrary stabilizer
circuits introduced by Aaronson and Gottesman in {\it Phys. Rev. A 70(052328)},
2004. In particular, we reduce their 11-stage computation
-H-C-P-C-P-C-H-P-C-P-C- into an 8-stage computation of the form
-H-C-CZ-P-H-P-CZ-C-. We show arguments in support of using -CZ- stages over the
-C- stages: not only the use of -CZ- stages allows a shorter layered
expression, but -CZ- stages are simpler and appear to be easier to implement
compared to the -C- stages. Relying on the 8-stage decomposition we develop a
two-qubit depth-$(14n-4)$ implementation of stabilizer circuits over the gate
library {P,H,CNOT}, executable in the LNN architecture, improving best
previously known depth-$25n$ circuit, also executable in the LNN architecture.
Our constructions rely on folding arbitrarily long sequences $($-P-C-$)^m$ into
a 3-stage computation -P-CZ-C-, as well as efficient implementation of the -CZ-
stage circuits.
</dc:description>
 <dc:description>Comment: Subsumed by arXiv:1705.09176</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00874</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00876</identifier>
 <datestamp>2017-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient algorithm for finding all possible input nodes for
  controlling complex networks</dc:title>
 <dc:creator>Zhang, Xizhe</dc:creator>
 <dc:creator>Han, Jianfei</dc:creator>
 <dc:creator>Zhang, Weixiong</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Understanding structural controllability of a complex network requires to
identify a Minimum Input nodes Set (MIS) of the network. It has been suggested
that finding an MIS is equivalent to computing a maximum matching of the
network, where the unmatched nodes constitute an MIS. However, maximum matching
of a network is often not unique, and finding all MISs may provide deep
insights to the controllability of the network. Finding all possible input
nodes, which form the union of all MISs, is computationally challenging for
large networks. Here we present an efficient enumerative algorithm for the
problem. The main idea is to modify a maximum matching algorithm to make it
efficient for finding all possible input nodes by computing only one MIS. We
rigorously proved the correctness of the new algorithm and evaluated its
performance on synthetic and large real networks. The experimental results
showed that the new algorithm ran several orders of magnitude faster than the
existing method on large real networks.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-04-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00887</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to Escape Saddle Points Efficiently</dc:title>
 <dc:creator>Jin, Chi</dc:creator>
 <dc:creator>Ge, Rong</dc:creator>
 <dc:creator>Netrapalli, Praneeth</dc:creator>
 <dc:creator>Kakade, Sham M.</dc:creator>
 <dc:creator>Jordan, Michael I.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper shows that a perturbed form of gradient descent converges to a
second-order stationary point in a number iterations which depends only
poly-logarithmically on dimension (i.e., it is almost &quot;dimension-free&quot;). The
convergence rate of this procedure matches the well-known convergence rate of
gradient descent to first-order stationary points, up to log factors. When all
saddle points are non-degenerate, all second-order stationary points are local
minima, and our result thus shows that perturbed gradient descent can escape
saddle points almost for free. Our results can be directly applied to many
machine learning applications, including deep learning. As a particular
concrete example of such an application, we show that our results can be used
directly to establish sharp global convergence rates for matrix factorization.
Our results rely on a novel characterization of the geometry around saddle
points, which may be of independent interest to the non-convex optimization
community.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00893</identifier>
 <datestamp>2017-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Being Robust (in High Dimensions) Can Be Practical</dc:title>
 <dc:creator>Diakonikolas, Ilias</dc:creator>
 <dc:creator>Kamath, Gautam</dc:creator>
 <dc:creator>Kane, Daniel M.</dc:creator>
 <dc:creator>Li, Jerry</dc:creator>
 <dc:creator>Moitra, Ankur</dc:creator>
 <dc:creator>Stewart, Alistair</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Robust estimation is much more challenging in high dimensions than it is in
one dimension: Most techniques either lead to intractable optimization problems
or estimators that can tolerate only a tiny fraction of errors. Recent work in
theoretical computer science has shown that, in appropriate distributional
models, it is possible to robustly estimate the mean and covariance with
polynomial time algorithms that can tolerate a constant fraction of
corruptions, independent of the dimension. However, the sample and time
complexity of these algorithms is prohibitively large for high-dimensional
applications. In this work, we address both of these issues by establishing
sample complexity bounds that are optimal, up to logarithmic factors, as well
as giving various refinements that allow the algorithms to tolerate a much
larger fraction of corruptions. Finally, we show on both synthetic and real
data that our algorithms have state-of-the-art performance and suddenly make
high-dimensional robust estimation a realistic possibility.
</dc:description>
 <dc:description>Comment: Appeared in ICML 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00893</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00897</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation</dc:title>
 <dc:creator>Garg, Rohan</dc:creator>
 <dc:creator>Arya, Kapil</dc:creator>
 <dc:creator>Cao, Jiajun</dc:creator>
 <dc:creator>Cooperman, Gene</dc:creator>
 <dc:creator>Evans, Jeff</dc:creator>
 <dc:creator>Garg, Ankit</dc:creator>
 <dc:creator>Rosenberg, Neil A.</dc:creator>
 <dc:creator>Suresh, K.</dc:creator>
 <dc:subject>Computer Science - Operating Systems</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>B.6.3</dc:subject>
 <dc:description>  Checkpoint-restart is now a mature technology. It allows a user to save and
later restore the state of a running process. The new plugin model for the
upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is
described here. This plugin model allows a target application to disconnect
from the hardware emulator at checkpoint time and then re-connect to a possibly
different hardware emulator at the time of restart. The DMTCP plugin model is
important in allowing three distinct parties to seamlessly inter-operate. The
three parties are: the EDA designer, who is concerned with formal verification
of a circuit design; the DMTCP developers, who are concerned with providing
transparent checkpointing during the circuit emulation; and the hardware
emulator vendor, who provides a plugin library that responds to checkpoint,
restart, and other events.
  The new plugin model is an example of process-level virtualization:
virtualization of external abstractions from within a process. This capability
is motivated by scenarios for testing circuit models with the help of a
hardware emulator. The plugin model enables a three-way collaboration: allowing
a circuit designer and emulator vendor to each contribute separate proprietary
plugins while sharing an open source software framework from the DMTCP
developers. This provides a more flexible platform, where different fault
injection models based on plugins can be designed within the DMTCP
checkpointing framework. After initialization, one restarts from a checkpointed
state under the control of the desired plugin. This restart saves the time
spent in simulating the initialization phase, while enabling fault injection
exactly at the region of interest. Upon restart, one can inject faults or
otherwise modify the remainder of the simulation. The work concludes with a
brief survey of checkpointing and process-level virtualization.
</dc:description>
 <dc:description>Comment: 5 pages, 11 figure, 1 listing; SELSE '17, March 21--22, 2017, Boston,
  MA, USA</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00897</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00899</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Addendum to &quot;A Market Framework for Eliciting Private Data&quot;</dc:title>
 <dc:creator>Waggoner, Bo</dc:creator>
 <dc:creator>Frongillo, Rafael</dc:creator>
 <dc:creator>Abernethy, Jacob</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In Waggoner et al. [NIPS 2015], we proposed an elaboration on prediction
markets that preserves differential privacy of transactions. This addendum
gives a simpler, prediction-market focused construction and proofs. It also
shows how to recover forms of a bounded worst-case loss guarantee by
introducing a transaction fee.
</dc:description>
 <dc:description>Comment: 15 pages single-column</dc:description>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00899</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00900</identifier>
 <datestamp>2017-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Deterministic Distributed Matching via Rounding</dc:title>
 <dc:creator>Fischer, Manuela</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present improved deterministic distributed algorithms for a number of
well-studied matching problems, which are simpler, faster, more accurate,
and/or more general than their known counterparts. The common denominator of
these results is a deterministic distributed rounding method for certain linear
programs, which is the first such rounding method, to our knowledge. A sampling
of our end results is as follows.
  -- An $O(\log^2 \Delta\cdot \log n)$-round deterministic distributed
algorithm for computing a maximal matching, in $n$-node graphs with maximum
degree $\Delta$. This is the first improvement in about 20 years over the
celebrated $O(\log^4 n)$-round algorithm of Ha\'n\'ckowiak, Karo\'nski, and
Panconesi [SODA'98, PODC'99].
  -- A deterministic distributed algorithm for computing a
$(2+\varepsilon)$-approximation of maximum matching in $O(\log^2 \Delta \cdot
\log \frac{1}{\varepsilon} + \log^ * n)$ rounds. This is exponentially faster
than the classic $O(\Delta +\log^* n)$-round $2$-approximation of Panconesi and
Rizzi [DIST'01]. With some modifications, the algorithm can also find an
$\varepsilon$-maximal matching which leaves only an $\varepsilon$-fraction of
the edges on unmatched nodes.
  -- An $O(\log^2 \Delta \cdot \log \frac{1}{\varepsilon} + \log^ * n)$-round
deterministic distributed algorithm for computing a
$(2+\varepsilon)$-approximation of a maximum weighted matching, and also for
the more general problem of maximum weighted $b$-matching. These improve over
the $O(\log^4 n \cdot \log_{1+\varepsilon} W)$-round
$(6+\varepsilon)$-approximation algorithm of Panconesi and Sozio [DIST'10],
where $W$ denotes the maximum normalized weight.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-08-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00900</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00919</identifier>
 <datestamp>2017-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Depth Estimation using Modified Cost Function for Occlusion Handling</dc:title>
 <dc:creator>Wegner, Krzysztof</dc:creator>
 <dc:creator>Stankiewicz, Olgierd</dc:creator>
 <dc:creator>Domanski, Marek</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The paper presents a novel approach to occlusion handling problem in depth
estimation using three views. A solution based on modification of similarity
cost function is proposed. During the depth estimation via optimization
algorithms like Graph Cut similarity metric is constantly updated so that only
non-occluded fragments in side views are considered. At each iteration of the
algorithm non-occluded fragments are detected based on side view virtual depth
maps synthesized from the best currently estimated depth map of the center
view. Then similarity metric is updated for correspondence search only in
non-occluded regions of the side views. The experimental results, conducted on
well-known 3D video test sequences, have proved that the depth maps estimated
with the proposed approach provide about 1.25 dB virtual view quality
improvement in comparison to the virtual view synthesized based on depth maps
generated by the state-of-the-art MPEG Depth Estimation Reference Software.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-11-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00919</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00924</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Workload Analysis of Blue Waters</dc:title>
 <dc:creator>Jones, Matthew D.</dc:creator>
 <dc:creator>White, Joseph P.</dc:creator>
 <dc:creator>Innus, Martins</dc:creator>
 <dc:creator>DeLeon, Robert L.</dc:creator>
 <dc:creator>Simakov, Nikolay</dc:creator>
 <dc:creator>Palmer, Jeffrey T.</dc:creator>
 <dc:creator>Gallo, Steven M.</dc:creator>
 <dc:creator>Furlani, Thomas R.</dc:creator>
 <dc:creator>Showerman, Michael</dc:creator>
 <dc:creator>Brunner, Robert</dc:creator>
 <dc:creator>Kot, Andry</dc:creator>
 <dc:creator>Bauer, Gregory</dc:creator>
 <dc:creator>Bode, Brett</dc:creator>
 <dc:creator>Enos, Jeremy</dc:creator>
 <dc:creator>Kramer, William</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68M14, 68M20, 68U20</dc:subject>
 <dc:subject>I.6.3</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:subject>J.5</dc:subject>
 <dc:subject>K.6.4</dc:subject>
 <dc:description>  Blue Waters is a Petascale-level supercomputer whose mission is to enable the
national scientific and research community to solve &quot;grand challenge&quot; problems
that are orders of magnitude more complex than can be carried out on other high
performance computing systems. Given the important and unique role that Blue
Waters plays in the U.S. research portfolio, it is important to have a detailed
understanding of its workload in order to guide performance optimization both
at the software and system configuration level as well as inform architectural
balance tradeoffs. Furthermore, understanding the computing requirements of the
Blue Water's workload (memory access, IO, communication, etc.), which is
comprised of some of the most computationally demanding scientific problems,
will help drive changes in future computing architectures, especially at the
leading edge. With this objective in mind, the project team carried out a
detailed workload analysis of Blue Waters.
</dc:description>
 <dc:description>Comment: 107 pages, &gt;100 figures (figure sizes reduced to save space, contact
  authors for version with full resolution)</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00927</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the asymptotic behavior of the price of anarchy: Is selfish routing
  bad in highly congested networks?</dc:title>
 <dc:creator>Baldeschi, Riccardo Colini</dc:creator>
 <dc:creator>Cominetti, Roberto</dc:creator>
 <dc:creator>Mertikopoulos, Panayotis</dc:creator>
 <dc:creator>Scarsini, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Primary 91A13, secondary 91A43</dc:subject>
 <dc:description>  This paper examines the asymptotic behavior of the price of anarchy as a
function of the total traffic inflow in nonatomic congestion games with
multiple origin-destination pairs. We first show that the price of anarchy may
remain bounded away from 1, even in simple three-link parallel networks with
convex cost functions. On the other hand, empirical studies show that the price
of anarchy is close to 1 in highly congested real-world networks, thus begging
the question: under what assumptions can this behavior be justified
analytically? To that end, we prove a general result showing that for a large
class of cost functions (defined in terms of regular variation and including
all polynomials), the price of anarchy converges to 1 in the high congestion
limit. In particular, specializing to networks with polynomial costs, we show
that this convergence follows a power law whose degree can be computed
explicitly.
</dc:description>
 <dc:description>Comment: 24 pages, 4 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00927</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00938</identifier>
 <datestamp>2017-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Atomic Norm Minimization for Modal Analysis from Random and Compressed
  Samples</dc:title>
 <dc:creator>Li, Shuang</dc:creator>
 <dc:creator>Yang, Dehui</dc:creator>
 <dc:creator>Tang, Gongguo</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Modal analysis is the process of estimating a system's modal parameters such
as its natural frequencies and mode shapes. One application of modal analysis
is in structural health monitoring (SHM), where a network of sensors may be
used to collect vibration data from a physical structure such as a building or
bridge. There is a growing interest in developing automated techniques for SHM
based on data collected in a wireless sensor network. In order to conserve
power and extend battery life, however, it is desirable to minimize the amount
of data that must be collected and transmitted in such a sensor network. In
this paper, we highlight the fact that modal analysis can be formulated as an
atomic norm minimization (ANM) problem, which can be solved efficiently and in
some cases recover perfectly a structure's mode shapes and frequencies. We
survey a broad class of sampling and compression strategies that one might
consider in a physical sensor network, and we provide bounds on the sample
complexity of these compressive schemes in order to recover a structure's mode
shapes and frequencies via ANM. A main contribution of our paper is to
establish a bound on the sample complexity of modal analysis with random
temporal compression, and in this scenario we prove that the samples per sensor
can actually decrease as the number of sensors increases. We also extend an
atomic norm denoising problem to the multiple measurement vector (MMV) setting
in the case of uniform sampling.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00941</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Fine-grained Complexity of One-Dimensional Dynamic Programming</dc:title>
 <dc:creator>K&#xfc;nnemann, Marvin</dc:creator>
 <dc:creator>Paturi, Ramamohan</dc:creator>
 <dc:creator>Schneider, Stefan</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we investigate the complexity of one-dimensional dynamic
programming, or more specifically, of the Least-Weight Subsequence (LWS)
problem: Given a sequence of $n$ data items together with weights for every
pair of the items, the task is to determine a subsequence $S$ minimizing the
total weight of the pairs adjacent in $S$. A large number of natural problems
can be formulated as LWS problems, yielding obvious $O(n^2)$-time solutions.
  In many interesting instances, the $O(n^2)$-many weights can be succinctly
represented. Yet except for near-linear time algorithms for some specific
special cases, little is known about when an LWS instantiation admits a
subquadratic-time algorithm and when it does not. In particular, no lower
bounds for LWS instantiations have been known before. In an attempt to remedy
this situation, we provide a general approach to study the fine-grained
complexity of succinct instantiations of the LWS problem. In particular, given
an LWS instantiation we identify a highly parallel core problem that is
subquadratically equivalent. This provides either an explanation for the
apparent hardness of the problem or an avenue to find improved algorithms as
the case may be.
  More specifically, we prove subquadratic equivalences between the following
pairs (an LWS instantiation and the corresponding core problem) of problems: a
low-rank version of LWS and minimum inner product, finding the longest chain of
nested boxes and vector domination, and a coin change problem which is closely
related to the knapsack problem and (min,+)-convolution. Using these
equivalences and known SETH-hardness results for some of the core problems, we
deduce tight conditional lower bounds for the corresponding LWS instantiations.
We also establish the (min,+)-convolution-hardness of the knapsack problem.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00948</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DAWT: Densely Annotated Wikipedia Texts across multiple languages</dc:title>
 <dc:creator>Spasojevic, Nemanja</dc:creator>
 <dc:creator>Bhargava, Preeti</dc:creator>
 <dc:creator>Hu, Guoning</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In this work, we open up the DAWT dataset - Densely Annotated Wikipedia Texts
across multiple languages. The annotations include labeled text mentions
mapping to entities (represented by their Freebase machine ids) as well as the
type of the entity. The data set contains total of 13.6M articles, 5.0B tokens,
13.8M mention entity co-occurrences. DAWT contains 4.8 times more anchor text
to entity links than originally present in the Wikipedia markup. Moreover, it
spans several languages including English, Spanish, Italian, German, French and
Arabic. We also present the methodology used to generate the dataset which
enriches Wikipedia markup in order to increase number of links. In addition to
the main dataset, we open up several derived datasets including mention entity
co-occurrence counts and entity embeddings, as well as mappings between
Freebase ids and Wikidata item ids. We also discuss two applications of these
datasets and hope that opening them up would prove useful for the Natural
Language Processing and Information Retrieval communities, as well as
facilitate multi-lingual research.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, 7 tables, WWW2017, WWW 2017 Companion proceedings</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00948</dc:identifier>
 <dc:identifier>doi:10.1145/3041021.3053367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00951</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of a Hybrid Downlink-Uplink Cooperative NOMA Scheme</dc:title>
 <dc:creator>Wei, Zhiqiang</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a novel hybrid downlinkuplink cooperative NOMA
(HDU-CNOMA) scheme to achieve a better tradeoff between spectral efficiency and
signal reception reliability than the conventional cooperative NOMA schemes. In
particular, the proposed scheme enables the strong user to perform a
cooperative transmission and an interference-free uplink transmission
simultaneously during the cooperative phase, at the expense of a slightly
decrease in signal reception reliability at the weak user. We analyze the
outage probability, diversity order, and outage throughput of the proposed
scheme. Simulation results not only confirm the accuracy of the developed
analytical results, but also unveil the spectral efficiency gains achieved by
the proposed scheme over a baseline cooperative NOMA scheme and a
non-cooperative NOMA scheme.
</dc:description>
 <dc:description>Comment: 7 pages, accepted for presentation at the IEEE VTC 2017 Spring,
  Sydney, Australia</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00951</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00955</identifier>
 <datestamp>2018-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Controlled Generation of Text</dc:title>
 <dc:creator>Hu, Zhiting</dc:creator>
 <dc:creator>Yang, Zichao</dc:creator>
 <dc:creator>Liang, Xiaodan</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Xing, Eric P.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Generic generation and manipulation of text is challenging and has limited
success compared to recent deep generative modeling in visual domain. This
paper aims at generating plausible natural language sentences, whose attributes
are dynamically controlled by learning disentangled latent representations with
designated semantics. We propose a new neural generative model which combines
variational auto-encoders and holistic attribute discriminators for effective
imposition of semantic structures. With differentiable approximation to
discrete text samples, explicit constraints on independent attribute controls,
and efficient collaborative learning of generator and discriminators, our model
learns highly interpretable representations from even only word annotations,
and produces realistic sentences with desired attributes. Quantitative
evaluation validates the accuracy of sentence and attribute generation.
</dc:description>
 <dc:description>Comment: Fixed typos; ICML 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2018-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00956</identifier>
 <datestamp>2017-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Laplacian Framework for Option Discovery in Reinforcement Learning</dc:title>
 <dc:creator>Machado, Marlos C.</dc:creator>
 <dc:creator>Bellemare, Marc G.</dc:creator>
 <dc:creator>Bowling, Michael</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Representation learning and option discovery are two of the biggest
challenges in reinforcement learning (RL). Proto-value functions (PVFs) are a
well-known approach for representation learning in MDPs. In this paper we
address the option discovery problem by showing how PVFs implicitly define
options. We do it by introducing eigenpurposes, intrinsic reward functions
derived from the learned representations. The options discovered from
eigenpurposes traverse the principal directions of the state space. They are
useful for multiple tasks because they are discovered without taking the
environment's rewards into consideration. Moreover, different options act at
different time scales, making them helpful for exploration. We demonstrate
features of eigenpurposes in traditional tabular domains as well as in Atari
2600 games.
</dc:description>
 <dc:description>Comment: Appearing in the Proceedings of the 34th International Conference on
  Machine Learning (ICML)</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00958</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scaling up the software development process, a case study highlighting
  the complexities of large team software development</dc:title>
 <dc:creator>Basham, Mark</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Diamond Light Source is the UK's National Synchrotron Facility and as such
provides access to world class experimental services for UK and international
researchers. As a user facility, that is one that focuses on providing a good
user experience to our varied visitors, Diamond invests heavily in software
infrastructure and staff. Over 100 members of the 600 strong workforce consider
software development as a significant tool to help them achieve their primary
role. These staff work on a diverse number of different software packages,
providing support for installation and configuration, maintenance and bug
fixing, as well as additional research and development of software when
required.
  This talk focuses on one of the software projects undertaken to unify and
improve the user experience of several experiments. The &quot;mapping project&quot; is a
large 2 year, multi group project targeting the collection and processing
experiments which involve scanning an X-ray beam over a sample and building up
an image of that sample, similar to the way that google maps bring together
small pieces of information to produce a full map of the world. The project
itself is divided into several work packages, ranging from teams of one to 5 or
6 in size, with varying levels of time commitment to the project. This paper
aims to explore one of these work packages as a case study, highlighting the
experiences of the project team, the methodologies employed, their outcomes,
and the lessons learnt from the experience.
</dc:description>
 <dc:description>Comment: 7 Pages, 5 figures, conferece</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00958</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00972</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eliciting Private User Information for Residential Demand Response</dc:title>
 <dc:creator>Zhou, Datong P.</dc:creator>
 <dc:creator>Balandat, Maximilian</dc:creator>
 <dc:creator>Dahleh, Munther A.</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Residential Demand Response has emerged as a viable tool to alleviate supply
and demand imbalances of electricity, particularly during times when the
electric grid is strained due a shortage of supply. Demand Response providers
bid reduction capacity into the wholesale electricity market by asking their
customers under contract to temporarily reduce their consumption in exchange
for a monetary incentive. To contribute to the analysis of consumer behavior in
response to such incentives, this paper formulates Demand Response as a
Mechanism Design problem, where a Demand Response Provider elicits private
information of its rational, profit-maximizing customers who derive positive
expected utility by participating in reduction events. By designing an
incentive compatible and individually rational mechanism to collect users'
price elasticities of demand, the Demand Response provider can target the most
susceptible users to incentives. We measure reductions by comparing the
materialized consumption to the projected consumption, which we model as the
&quot;10-in-10&quot;-baseline, the regulatory standard set by the California Independent
System Operator. Due to the suboptimal performance of this baseline, we show,
using consumption data of residential customers in California, that Demand
Response Providers receive payments for &quot;virtual reductions&quot;, which exist due
to the inaccuracies of the baseline rather than actual reductions. Improving
the accuracy of the baseline diminishes the contribution of these virtual
reductions.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-09-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00972</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00976</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hedging Strategies for Load-Serving Entities in Wholesale Electricity
  Markets</dc:title>
 <dc:creator>Zhou, Datong P.</dc:creator>
 <dc:creator>Dahleh, Munther A.</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Load-serving entities which procure electricity from the wholesale
electricity market to service end-users face significant quantity and price
risks due to the volatile nature of electricity demand and quasi-fixed
residential tariffs at which electricity is sold. This paper investigates
strategies for load serving entities to hedge against such price risks.
Specifically, we compute profit-maximizing portfolios of forward contract and
call options as a function of the uncertain aggregate user demand. We compare
the profit to the case of Demand Response, where users are offered monetary
incentives to temporarily reduce their consumption during periods of supply
shortages. Using smart meter data of residential customers in California, we
simulate optimal portfolios and derive conditions under which Demand Response
outperforms call options and forward contracts.
</dc:description>
 <dc:description>Comment: 8 pages, 7 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00977</identifier>
 <datestamp>2017-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Paced Multitask Learning with Shared Knowledge</dc:title>
 <dc:creator>Murugesan, Keerthiram</dc:creator>
 <dc:creator>Carbonell, Jaime</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces self-paced task selection to multitask learning, where
instances from more closely related tasks are selected in a progression of
easier-to-harder tasks, to emulate an effective human education strategy, but
applied to multitask machine learning. We develop the mathematical foundation
for the approach based on iterative selection of the most appropriate task,
learning the task parameters, and updating the shared knowledge, optimizing a
new bi-convex loss function. This proposed method applies quite generally,
including to multitask feature learning, multitask learning with alternating
structure optimization, etc. Results show that in each of the above
formulations self-paced (easier-to-harder) task selection outperforms the
baseline version of these methods in all the experiments.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-06-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00977</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00978</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional Falsification of Cyber-Physical Systems with Machine
  Learning Components</dc:title>
 <dc:creator>Dreossi, Tommaso</dc:creator>
 <dc:creator>Donz&#xe9;, Alexandre</dc:creator>
 <dc:creator>Seshia, Sanjit A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Cyber-physical systems (CPS), such as automotive systems, are starting to
include sophisticated machine learning (ML) components. Their correctness,
therefore, depends on properties of the inner ML modules. While learning
algorithms aim to generalize from examples, they are only as good as the
examples provided, and recent efforts have shown that they can produce
inconsistent output under small adversarial perturbations. This raises the
question: can the output from learning components can lead to a failure of the
entire CPS? In this work, we address this question by formulating it as a
problem of falsifying signal temporal logic (STL) specifications for CPS with
ML components. We propose a compositional falsification framework where a
temporal logic falsifier and a machine learning analyzer cooperate with the aim
of finding falsifying executions of the considered model. The efficacy of the
proposed technique is shown on an automatic emergency braking system model with
a perception component based on deep neural networks.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-11-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00978</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00980</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Peer Effects Influence Energy Consumption</dc:title>
 <dc:creator>Zhou, Datong P.</dc:creator>
 <dc:creator>Roozbehani, Mardavij</dc:creator>
 <dc:creator>Dahleh, Munther A.</dc:creator>
 <dc:creator>Tomlin, Claire J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper analyzes the impact of peer effects on electricity consumption of
a network of rational, utility-maximizing users. Users derive utility from
consuming electricity as well as consuming less energy than their neighbors.
However, a disutility is incurred for consuming more than their neighbors. To
maximize the profit of the load-serving entity that provides electricity to
such users, we develop a two-stage game-theoretic model, where the entity sets
the prices in the first stage. In the second stage, consumers decide on their
demand in response to the observed price set in the first stage so as to
maximize their utility. To this end, we derive theoretical statements under
which such peer effects reduce aggregate user consumption. Further, we obtain
expressions for the resulting electricity consumption and profit of the load
serving entity for the case of perfect price discrimination and a single price
under complete information, and approximations under incomplete information.
Simulations suggest that exposing only a selected subset of all users to peer
effects maximizes the entity's profit.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00980</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00981</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Restaurant Process Mixture Model for Connectivity Based Parcellation
  of the Cortex</dc:title>
 <dc:creator>Moyer, Daniel</dc:creator>
 <dc:creator>Gutman, Boris A</dc:creator>
 <dc:creator>Jahanshad, Neda</dc:creator>
 <dc:creator>Thompson, Paul M.</dc:creator>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  One of the primary objectives of human brain mapping is the division of the
cortical surface into functionally distinct regions, i.e. parcellation. While
it is generally agreed that at macro-scale different regions of the cortex have
different functions, the exact number and configuration of these regions is not
known. Methods for the discovery of these regions are thus important,
particularly as the volume of available information grows. Towards this end, we
present a parcellation method based on a Bayesian non-parametric mixture model
of cortical connectivity.
</dc:description>
 <dc:description>Comment: In the Proceedings of Information Processing in Medical Imaging 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00983</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ASAP: Prioritizing Attention via Time Series Smoothing</dc:title>
 <dc:creator>Rong, Kexin</dc:creator>
 <dc:creator>Bailis, Peter</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Time series visualization of streaming telemetry (i.e., charting of key
metrics such as server load over time) is increasingly prevalent in modern data
platforms and applications. However, many existing systems simply plot the raw
data streams as they arrive, often obscuring large-scale trends due to
small-scale noise. We propose an alternative: to better prioritize end users'
attention, smooth time series visualizations as much as possible to remove
noise, while retaining large-scale structure to highlight significant
deviations. We develop a new analytics operator called ASAP that automatically
smooths streaming time series by adaptively optimizing the trade-off between
noise reduction (i.e., variance) and trend retention (i.e., kurtosis). We
introduce metrics to quantitatively assess the quality of smoothed plots and
provide an efficient search strategy for optimizing these metrics that combines
techniques from stream processing, user interface design, and signal processing
via autocorrelation-based pruning, pixel-aware preaggregation, and on-demand
refresh. We demonstrate that ASAP can improve users' accuracy in identifying
long-term deviations in time series by up to 38.4% while reducing response
times by up to 44.3%. Moreover, ASAP delivers these results several orders of
magnitude faster than alternative search strategies.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00983</dc:identifier>
 <dc:identifier>Proc. VLDB Endow. Vol. 10, No. 11 pages 1358-1369, 2017</dc:identifier>
 <dc:identifier>doi:10.14778/3137628.3137645</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00985</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Small Superposition Dimension and Active Set Construction for
  Multivariate Integration Under Modest Error Demand</dc:title>
 <dc:creator>Gilbert, Alexander D.</dc:creator>
 <dc:creator>Wasilkowski, Greg W.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Constructing active sets is a key part of the Multivariate Decomposition
Method. An algorithm for constructing optimal or quasi-optimal active sets is
proposed in the paper. By numerical experiments, it is shown that the new
method can provide sets that are significantly smaller than the sets
constructed by the already existing method. The experiments also show that the
superposition dimension could surprisingly be very small, at most 3, when the
error demand is not smaller than $10^{-3}$ and the weights decay sufficiently
fast.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00986</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Belief Propagation in Conditional RBMs for Structured Prediction</dc:title>
 <dc:creator>Ping, Wei</dc:creator>
 <dc:creator>Ihler, Alexander</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Restricted Boltzmann machines~(RBMs) and conditional RBMs~(CRBMs) are popular
models for a wide range of applications. In previous work, learning on such
models has been dominated by contrastive divergence~(CD) and its variants.
Belief propagation~(BP) algorithms are believed to be slow for structured
prediction on conditional RBMs~(e.g., Mnih et al. [2011]), and not as good as
CD when applied in learning~(e.g., Larochelle et al. [2012]). In this work, we
present a matrix-based implementation of belief propagation algorithms on
CRBMs, which is easily scalable to tens of thousands of visible and hidden
units. We demonstrate that, in both maximum likelihood and max-margin learning,
training conditional RBMs with BP as the inference routine can provide
significantly better results than current state-of-the-art CD methods on
structured prediction problems. We also include practical guidelines on
training CRBMs with BP, and some insights on the interaction of learning and
inference algorithms for CRBMs.
</dc:description>
 <dc:description>Comment: Artificial Intelligence and Statistics (AISTATS) 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00986</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00989</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of distributions differences for classification</dc:title>
 <dc:creator>Bonyadi, Mohammad Reza</dc:creator>
 <dc:creator>Tieng, Quang M.</dc:creator>
 <dc:creator>Reutens, David C.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper we introduce a new classification algorithm called Optimization
of Distributions Differences (ODD). The algorithm aims to find a transformation
from the feature space to a new space where the instances in the same class are
as close as possible to one another while the gravity centers of these classes
are as far as possible from one another. This aim is formulated as a
multiobjective optimization problem that is solved by a hybrid of an
evolutionary strategy and the Quasi-Newton method. The choice of the
transformation function is flexible and could be any continuous space function.
We experiment with a linear and a non-linear transformation in this paper. We
show that the algorithm can outperform 6 other state-of-the-art classification
methods, namely naive Bayes, support vector machines, linear discriminant
analysis, multi-layer perceptrons, decision trees, and k-nearest neighbors, in
12 standard classification datasets. Our results show that the method is less
sensitive to the imbalanced number of instances comparing to these methods. We
also show that ODD maintains its performance better than other classification
methods in these datasets, hence, offers a better generalization ability.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00989</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00992</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating the resolution of real images</dc:title>
 <dc:creator>Mizutani, Ryuta</dc:creator>
 <dc:creator>Saiga, Rino</dc:creator>
 <dc:creator>Takekoshi, Susumu</dc:creator>
 <dc:creator>Inomoto, Chie</dc:creator>
 <dc:creator>Nakamura, Naoya</dc:creator>
 <dc:creator>Arai, Makoto</dc:creator>
 <dc:creator>Oshima, Kenichi</dc:creator>
 <dc:creator>Itokawa, Masanari</dc:creator>
 <dc:creator>Takeuchi, Akihisa</dc:creator>
 <dc:creator>Uesugi, Kentaro</dc:creator>
 <dc:creator>Terada, Yasuko</dc:creator>
 <dc:creator>Suzuki, Yoshio</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:description>  Image resolvability is the primary concern in imaging. This paper reports an
estimation of the full width at half maximum of the point spread function from
a Fourier domain plot of real sample images by neither using test objects, nor
defining a threshold criterion. We suggest that this method can be applied to
any type of image, independently of the imaging modality.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00992</dc:identifier>
 <dc:identifier>J. Phys. Conf. Ser. 849, 012042 (2017)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/849/1/012042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00993</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of Word Embeddings for Reading Comprehension</dc:title>
 <dc:creator>Dhingra, Bhuwan</dc:creator>
 <dc:creator>Liu, Hanxiao</dc:creator>
 <dc:creator>Salakhutdinov, Ruslan</dc:creator>
 <dc:creator>Cohen, William W.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The focus of past machine learning research for Reading Comprehension tasks
has been primarily on the design of novel deep learning architectures. Here we
show that seemingly minor choices made on (1) the use of pre-trained word
embeddings, and (2) the representation of out-of-vocabulary tokens at test
time, can turn out to have a larger impact than architectural choices on the
final performance. We systematically explore several options for these choices,
and provide recommendations to researchers working in this area.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.00994</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Clustering for Multitask Learning</dc:title>
 <dc:creator>Murugesan, Keerthiram</dc:creator>
 <dc:creator>Carbonell, Jaime</dc:creator>
 <dc:creator>Yang, Yiming</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper presents a new multitask learning framework that learns a shared
representation among the tasks, incorporating both task and feature clusters.
The jointly-induced clusters yield a shared latent subspace where task
relationships are learned more effectively and more generally than in
state-of-the-art multitask learning methods. The proposed general framework
enables the derivation of more specific or restricted state-of-the-art
multitask methods. The paper also proposes a highly-scalable multitask learning
algorithm, based on the new framework, using conjugate gradient descent and
generalized \textit{Sylvester equations}. Experimental results on synthetic and
benchmark datasets show that the proposed method systematically outperforms
several state-of-the-art multitask learning methods.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.00994</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01006</identifier>
 <datestamp>2017-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Deep Traffic Flow Neural Networks for Urban Traffic Congestion
  Prediction</dc:title>
 <dc:creator>Fouladgar, Mohammadhani</dc:creator>
 <dc:creator>Parchami, Mostafa</dc:creator>
 <dc:creator>Elmasri, Ramez</dc:creator>
 <dc:creator>Ghaderi, Amir</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Tracking congestion throughout the network road is a critical component of
Intelligent transportation network management systems. Understanding how the
traffic flows and short-term prediction of congestion occurrence due to
rush-hour or incidents can be beneficial to such systems to effectively manage
and direct the traffic to the most appropriate detours. Many of the current
traffic flow prediction systems are designed by utilizing a central processing
component where the prediction is carried out through aggregation of the
information gathered from all measuring stations. However, centralized systems
are not scalable and fail provide real-time feedback to the system whereas in a
decentralized scheme, each node is responsible to predict its own short-term
congestion based on the local current measurements in neighboring nodes.
  We propose a decentralized deep learning-based method where each node
accurately predicts its own congestion state in real-time based on the
congestion state of the neighboring stations. Moreover, historical data from
the deployment site is not required, which makes the proposed method more
suitable for newly installed stations. In order to achieve higher performance,
we introduce a regularized Euclidean loss function that favors high congestion
samples over low congestion samples to avoid the impact of the unbalanced
training dataset. A novel dataset for this purpose is designed based on the
traffic data obtained from traffic control stations in northern California.
Extensive experiments conducted on the designed benchmark reflect a successful
congestion prediction.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01006</dc:identifier>
 <dc:identifier>doi:10.1109/IJCNN.2017.7966128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01008</identifier>
 <datestamp>2017-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Task-Completion Neural Dialogue Systems</dc:title>
 <dc:creator>Li, Xiujun</dc:creator>
 <dc:creator>Chen, Yun-Nung</dc:creator>
 <dc:creator>Li, Lihong</dc:creator>
 <dc:creator>Gao, Jianfeng</dc:creator>
 <dc:creator>Celikyilmaz, Asli</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  One of the major drawbacks of modularized task-completion dialogue systems is
that each module is trained individually, which presents several challenges.
For example, downstream modules are affected by earlier modules, and the
performance of the entire system is not robust to the accumulated errors. This
paper presents a novel end-to-end learning framework for task-completion
dialogue systems to tackle such issues. Our neural dialogue system can directly
interact with a structured database to assist users in accessing information
and accomplishing certain tasks. The reinforcement learning based dialogue
manager offers robust capabilities to handle noises caused by other components
of the dialogue system. Our experiments in a movie-ticket booking domain show
that our end-to-end system not only outperforms modularized dialogue system
baselines for both objective and subjective evaluation, but also is robust to
noises as demonstrated by several systematic experiments with different error
granularity and rates specific to the language understanding module.
</dc:description>
 <dc:description>Comment: 11 pages. arXiv admin note: substantial text overlap with
  arXiv:1703.07055</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01009</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Time and Space Construction of Suffix Arrays and LCP Arrays for
  Integer Alphabets</dc:title>
 <dc:creator>Goto, Keisuke</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Suffix arrays and LCP arrays are one of the most fundamental data structures
widely used for various kinds of string processing. Many problems can be solved
efficiently by using suffix arrays, or a pair of suffix arrays and LCP arrays.
In this paper, we consider two problems for a string of length $N$, the
characters of which are represented as integers in $[1, \dots, \sigma]$ for $1
\leq \sigma \leq N$; the string contains $\sigma$ distinct characters, (1)
construction of the suffix array and (2) simultaneous construction of both the
suffix array and the LCP array. In the word RAM model, we propose algorithms to
solve both the problems in $O(N)$ time using $O(1)$ extra words, which are
optimal in time and space. Extra words mean the required space except for the
space of the input string and output suffix array and LCP array. Our
contribution improves the previous most efficient algorithm that runs in $O(N)$
time using $\sigma+O(1)$ extra words for the suffix array construction proposed
by [Nong, TOIS 2013], and it improves the previous most efficient solution that
runs in $O(N)$ time using $\sigma + O(1)$ extra words for both suffix array and
LCP array construction using the combination of [Nong, TOIS 2013] and [Manzini,
SWAT 2004].
  Another optimal time and space algorithm to construct the suffix array was
proposed by [Li et al, arXiv 2016] very recently and independently. Our
algorithm is simpler than theirs, and it allows us to solve the second problem
in optimal time and space.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01012</identifier>
 <datestamp>2017-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Popularity under Promotion: Viral Potential, Forecasting, and the
  Economics of Time</dc:title>
 <dc:creator>Rizoiu, Marian-Andrei</dc:creator>
 <dc:creator>Xie, Lexing</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Modeling the popularity dynamics of an online item is an important open
problem in computational social science. This paper presents an in-depth study
of popularity dynamics under external promotions, especially in predicting
popularity jumps of online videos, and determining effective and efficient
schedules to promote online content. The recently proposed Hawkes Intensity
Process (HIP) models popularity as a non-linear interplay between exogenous
stimuli and the endogenous reactions. Here, we propose two novel metrics based
on HIP: to describe popularity gain per unit of promotion, and to quantify the
time it takes for such effects to unfold. We make increasingly accurate
forecasts of future popularity by including information about the intrinsic
properties of the video, promotions it receives, and the non-linear effects of
popularity ranking. We illustrate by simulation the interplay between the
unfolding of popularity over time, and the time-sensitive value of resources.
Lastly, our model lends a novel explanation of the commonly adopted periodic
and constant promotion strategy in advertising, as increasing the perceived
viral potential. This study provides quantitative guidelines about setting
promotion schedules considering content virality, timing, and economics.
</dc:description>
 <dc:description>Comment: Proceedings of ICWSM '17</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01014</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning for Cost-Sensitive Classification</dc:title>
 <dc:creator>Krishnamurthy, Akshay</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Huang, Tzu-Kuo</dc:creator>
 <dc:creator>Daume III, Hal</dc:creator>
 <dc:creator>Langford, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We design an active learning algorithm for cost-sensitive multiclass
classification: problems where different errors have different costs. Our
algorithm, COAL, makes predictions by regressing to each label's cost and
predicting the smallest. On a new example, it uses a set of regressors that
perform well on past data to estimate possible costs for each label. It queries
only the labels that could be the best, ignoring the sure losers. We prove COAL
can be efficiently implemented for any regression family that admits squared
loss optimization; it also enjoys strong guarantees with respect to predictive
performance and labeling effort. We empirically compare COAL to passive
learning and several active learning baselines, showing significant
improvements in labeling effort and test cost on real-world datasets.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01022</identifier>
 <datestamp>2017-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer-assisted proof of heteroclinic connections in the
  one-dimensional Ohta-Kawasaki model</dc:title>
 <dc:creator>Cyranka, Jacek</dc:creator>
 <dc:creator>Wanner, Thomas</dc:creator>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>35B40, 35B41, 35K55, 65C20, 35Q99, 15B99, 68U20</dc:subject>
 <dc:description>  We present a computer-assisted proof of heteroclinic connections in the
one-dimensional Ohta-Kawasaki model of diblock copolymers. The model is a
fourth-order parabolic partial differential equation subject to homogeneous
Neumann boundary conditions, which contains as a special case the celebrated
Cahn-Hilliard equation. While the attractor structure of the latter model is
completely understood for one-dimensional domains, the diblock copolymer
extension exhibits considerably richer long-term dynamical behavior, which
includes a high level of multistability. In this paper, we establish the
existence of certain heteroclinic connections between the homogeneous
equilibrium state, which represents a perfect copolymer mixture, and all local
and global energy minimizers. In this way, we show that not every solution
originating near the homogeneous state will converge to the global energy
minimizer, but rather is trapped by a stable state with higher energy. This
phenomenon can not be observed in the one-dimensional Cahn-Hillard equation,
where generic solutions are attracted by a global minimizer.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:date>2017-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01024</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exponential Moving Average Model in Parallel Speech Recognition Training</dc:title>
 <dc:creator>Tian, Xu</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Ma, Zejun</dc:creator>
 <dc:creator>He, Yi</dc:creator>
 <dc:creator>Wei, Juan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  As training data rapid growth, large-scale parallel training with multi-GPUs
cluster is widely applied in the neural network model learning currently.We
present a new approach that applies exponential moving average method in
large-scale parallel training of neural network model. It is a non-interference
strategy that the exponential moving average model is not broadcasted to
distributed workers to update their local models after model synchronization in
the training process, and it is implemented as the final model of the training
system. Fully-connected feed-forward neural networks (DNNs) and deep
unidirectional Long short-term memory (LSTM) recurrent neural networks (RNNs)
are successfully trained with proposed method for large vocabulary continuous
speech recognition on Shenma voice search data in Mandarin. The character error
rate (CER) of Mandarin speech recognition further degrades than
state-of-the-art approaches of parallel training.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01025</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Multi-task Deep Learning Model for Skin Lesion Segmentation and
  Classification</dc:title>
 <dc:creator>Yang, Xulei</dc:creator>
 <dc:creator>Zeng, Zeng</dc:creator>
 <dc:creator>Yeo, Si Yong</dc:creator>
 <dc:creator>Tan, Colin</dc:creator>
 <dc:creator>Tey, Hong Liang</dc:creator>
 <dc:creator>Su, Yi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this study, a multi-task deep neural network is proposed for skin lesion
analysis. The proposed multi-task learning model solves different tasks (e.g.,
lesion segmentation and two independent binary lesion classifications) at the
same time by exploiting commonalities and differences across tasks. This
results in improved learning efficiency and potential prediction accuracy for
the task-specific models, when compared to training the individual models
separately. The proposed multi-task deep learning model is trained and
evaluated on the dermoscopic image sets from the International Skin Imaging
Collaboration (ISIC) 2017 Challenge - Skin Lesion Analysis towards Melanoma
Detection, which consists of 2000 training samples and 150 evaluation samples.
The experimental results show that the proposed multi-task deep learning model
achieves promising performances on skin lesion segmentation and classification.
The average value of Jaccard index for lesion segmentation is 0.724, while the
average values of area under the receiver operating characteristic curve (AUC)
on two individual lesion classifications are 0.880 and 0.972, respectively.
</dc:description>
 <dc:description>Comment: Submission to support ISIC 2017 challenge results</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01025</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01026</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Basis Function Adaptation for Reinforcement Learning</dc:title>
 <dc:creator>Barker, Edward W.</dc:creator>
 <dc:creator>Ras, Charl J.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When using reinforcement learning (RL) algorithms to evaluate a policy it is
common, given a large state space, to introduce some form of approximation
architecture for the value function (VF). The exact form of this architecture
can have a significant effect on the accuracy of the VF estimate, however, and
determining a suitable approximation architecture can often be a highly complex
task. Consequently there is a large amount of interest in the potential for
allowing RL algorithms to adaptively generate approximation architectures.
  We investigate a method of adapting approximation architectures which uses
feedback regarding the frequency with which an agent has visited certain states
to guide which areas of the state space to approximate with greater detail.
This method is &quot;unsupervised&quot; in the sense that it makes no direct reference to
reward or the VF estimate. We introduce an algorithm based upon this idea which
adapts a state aggregation approximation architecture on-line.
  A common method of scoring a VF estimate is to weight the squared Bellman
error of each state-action by the probability of that state-action occurring.
Adopting this scoring method, and assuming $S$ states, we demonstrate
theoretically that - provided (1) the number of cells $X$ in the state
aggregation architecture is of order $\sqrt{S}\log_2{S}\ln{S}$ or greater, (2)
the policy and transition function are close to deterministic, and (3) the
prior for the transition function is uniformly distributed - our algorithm,
used in conjunction with a suitable RL algorithm, can guarantee a score which
is arbitrarily close to zero as $S$ becomes large. It is able to do this
despite having only $O(X \log_2S)$ space complexity and negligible time
complexity. The results take advantage of certain properties of the stationary
distributions of Markov chains.
</dc:description>
 <dc:description>Comment: Extended abstract submitted (3 March 2017) for 3rd Multidisciplinary
  Conference on Reinforcement Learning and Decision Making (RLDM) 2017</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01028</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Outlier Cluster Formation in Spectral Clustering</dc:title>
 <dc:creator>Ina, Takuro</dc:creator>
 <dc:creator>Hashimoto, Atsushi</dc:creator>
 <dc:creator>Iiyama, Masaaki</dc:creator>
 <dc:creator>Kasahara, Hidekazu</dc:creator>
 <dc:creator>Mori, Mikihiko</dc:creator>
 <dc:creator>Minoh, Michihiko</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Outlier detection and cluster number estimation is an important issue for
clustering real data. This paper focuses on spectral clustering, a time-tested
clustering method, and reveals its important properties related to outliers.
The highlights of this paper are the following two mathematical observations:
first, spectral clustering's intrinsic property of an outlier cluster
formation, and second, the singularity of an outlier cluster with a valid
cluster number. Based on these observations, we designed a function that
evaluates clustering and outlier detection results. In experiments, we prepared
two scenarios, face clustering in photo album and person re-identification in a
camera network. We confirmed that the proposed method detects outliers and
estimates the number of clusters properly in both problems. Our method
outperforms state-of-the-art methods in both the 128-dimensional sparse space
for face clustering and the 4,096-dimensional non-sparse space for person
re-identification.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures, 2 tables</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01029</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Time-Consistent, Risk-Averse Model Predictive Control:
  Theory and Algorithms</dc:title>
 <dc:creator>Chow, Yin-Lam</dc:creator>
 <dc:creator>Singh, Sumeet</dc:creator>
 <dc:creator>Majumdar, Anirudha</dc:creator>
 <dc:creator>Pavone, Marco</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this paper we present a framework for risk-averse model predictive control
(MPC) of linear systems affected by multiplicative uncertainty. Our key
innovation is to consider time-consistent, dynamic risk metrics as objective
functions to be minimized. This framework is axiomatically justified in terms
of time-consistency of risk assessments, is amenable to dynamic optimization,
and is unifying in the sense that it captures a full range of risk preferences
from risk-neutral to worst case. Within this framework, we propose and analyze
an online risk-averse MPC algorithm that is provably stabilizing. Furthermore,
by exploiting the dual representation of time-consistent, dynamic risk metrics,
we cast the computation of the MPC control law as a convex optimization problem
amenable to real-time implementation. Simulation results are presented and
discussed.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Automatic Control. arXiv admin
  note: text overlap with arXiv:1511.06981</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01030</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deeply AggreVaTeD: Differentiable Imitation Learning for Sequential
  Prediction</dc:title>
 <dc:creator>Sun, Wen</dc:creator>
 <dc:creator>Venkatraman, Arun</dc:creator>
 <dc:creator>Gordon, Geoffrey J.</dc:creator>
 <dc:creator>Boots, Byron</dc:creator>
 <dc:creator>Bagnell, J. Andrew</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Researchers have demonstrated state-of-the-art performance in sequential
decision making problems (e.g., robotics control, sequential prediction) with
deep neural network models. One often has access to near-optimal oracles that
achieve good performance on the task during training. We demonstrate that
AggreVaTeD --- a policy gradient extension of the Imitation Learning (IL)
approach of (Ross &amp; Bagnell, 2014) --- can leverage such an oracle to achieve
faster and better solutions with less training data than a less-informed
Reinforcement Learning (RL) technique. Using both feedforward and recurrent
neural network predictors, we present stochastic gradient procedures on a
sequential prediction task, dependency-parsing from raw image data, as well as
on various high dimensional robotics control problems. We also provide a
comprehensive theoretical study of IL that demonstrates we can expect up to
exponentially lower sample complexity for learning with AggreVaTeD than with RL
algorithms, which backs our empirical findings. Our results and theory indicate
that the proposed approach can achieve superior performance with respect to the
oracle when the demonstrator is sub-optimal.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01038</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ultra-Dense Edge Caching under Spatio-Temporal Demand and Network
  Dynamics</dc:title>
 <dc:creator>Kim, Hyesung</dc:creator>
 <dc:creator>Park, Jihong</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Kim, Seong-Lyun</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates a cellular edge caching design under an extremely
large number of small base stations (SBSs) and users. In this ultra-dense edge
caching network (UDCN), SBS-user distances shrink, and each user can request a
cached content from multiple SBSs. Unfortunately, the complexity of existing
caching controls' mechanisms increases with the number of SBSs, making them
inapplicable for solving the fundamental caching problem: How to maximize local
caching gain while minimizing the replicated content caching? Furthermore,
spatial dynamics of interference is no longer negligible in UDCNs due to the
surge in interference. In addition, the caching control should consider
temporal dynamics of user demands. To overcome such difficulties, we propose a
novel caching algorithm weaving together notions of mean-field game theory and
stochastic geometry. These enable our caching algorithm to become independent
of the number of SBSs and users, while incorporating spatial interference
dynamics as well as temporal dynamics of content popularity and storage
constraints. Numerical evaluation validates the fact that the proposed
algorithm reduces not only the long run average cost by at least 24% but also
the number of replicated content by 56% compared to a popularity-based
algorithm.
</dc:description>
 <dc:description>Comment: to be presented in IEEE International Conference on Communications
  (ICC), Paris, France, 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01040</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Robot Activities from First-Person Human Videos Using
  Convolutional Future Regression</dc:title>
 <dc:creator>Lee, Jangwon</dc:creator>
 <dc:creator>Ryoo, Michael S.</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We design a new approach that allows robot learning of new activities from
unlabeled human example videos. Given videos of humans executing the same
activity from a human's viewpoint (i.e., first-person videos), our objective is
to make the robot learn the temporal structure of the activity as its future
regression network, and learn to transfer such model for its own motor
execution. We present a new deep learning model: We extend the state-of-the-art
convolutional object detection network for the representation/estimation of
human hands in training videos, and newly introduce the concept of using a
fully convolutional network to regress (i.e., predict) the intermediate scene
representation corresponding to the future frame (e.g., 1-2 seconds later).
Combining these allows direct prediction of future locations of human hands and
objects, which enables the robot to infer the motor control plan using our
manipulation network. We experimentally confirm that our approach makes
learning of robot activities from unlabeled human interaction videos possible,
and demonstrate that our robot is able to execute the learned collaborative
activities in real-time directly based on its camera input.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01041</identifier>
 <datestamp>2017-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-Scale Evolution of Image Classifiers</dc:title>
 <dc:creator>Real, Esteban</dc:creator>
 <dc:creator>Moore, Sherry</dc:creator>
 <dc:creator>Selle, Andrew</dc:creator>
 <dc:creator>Saxena, Saurabh</dc:creator>
 <dc:creator>Suematsu, Yutaka Leon</dc:creator>
 <dc:creator>Tan, Jie</dc:creator>
 <dc:creator>Le, Quoc</dc:creator>
 <dc:creator>Kurakin, Alex</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.5.1</dc:subject>
 <dc:subject>I.5.2</dc:subject>
 <dc:description>  Neural networks have proven effective at solving difficult problems but
designing their architectures can be challenging, even for image classification
problems alone. Our goal is to minimize human participation, so we employ
evolutionary algorithms to discover such networks automatically. Despite
significant computational requirements, we show that it is now possible to
evolve models with accuracies within the range of those published in the last
year. Specifically, we employ simple evolutionary techniques at unprecedented
scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting
from trivial initial conditions and reaching accuracies of 94.6% (95.6% for
ensemble) and 77.0%, respectively. To do this, we use novel and intuitive
mutation operators that navigate large search spaces; we stress that no human
participation is required once evolution starts and that the output is a
fully-trained model. Throughout this work, we place special emphasis on the
repeatability of results, the variability in the outcomes and the computational
requirements.
</dc:description>
 <dc:description>Comment: Accepted for publication at ICML 2017 (34th International Conference
  on Machine Learning)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-06-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01042</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Preserving Observation Properties of the Reduced Supervisor in
  Discrete-Event Systems</dc:title>
 <dc:creator>Saeidi, Vahid</dc:creator>
 <dc:creator>Afzalian, Ali A.</dc:creator>
 <dc:creator>Gharavian, Davood</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Supervisor reduction procedure can be used to construct the reduced
supervisor with a reduced number of states in discrete-event systems. The main
concepts which are used in this procedure are control consistency of states,
control cover, induced supervisor, and normality of the reduced supervisor
w.r.t. the original supervisor. In this paper, it is proved that the reduced
supervisor, constructed by the proposed method in [9], preserves the
observation properties, i.e. normality and relative observability, by self
looping corresponding unobservable events at some states of the reduced
supervisor. This property can be applied to find a natural projection, under
which the supervisor is relative observable.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1611.00339</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01046</identifier>
 <datestamp>2017-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Coparanormality in Distributed Supervisory Control of Discrete-Event
  Systems</dc:title>
 <dc:creator>Saeidi, Vahid</dc:creator>
 <dc:creator>Afzalian, Ali A.</dc:creator>
 <dc:creator>Gharavian, Davood</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Decomposition and localization of a supervisor both are reduction methods in
distributed supervisory control of discrete-event systems.Decomposition is
employed to reduce the number of events and localization is used to reduce the
number of states of local controllers.In decomposition of a supervisor both
observation and control scopes are restricted, whereas in localization only
control authority is restricted to the corresponding local controller. In this
paper, we propose a decomposition method by defining coparanormality property,
and by using relative observability property of a monolithic supervisor.
Coparanormality is a coobservation property defined based on paranormality
property for a set of natural projections.It is shown that each supervisor can
be coparanormal, provided a set of appropriate natural projections exist.
Moreover, it is proved that relative observability is a sufficient condition
for decomposition of a supervisor. Furthermore, the supervisor localization
procedure is generalized to find a set of local controllers for any partition
ofthe controllable events set. The implementation of such local controllers may
become easier in industrial systems.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-12-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01048</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Non-blocking Decentralized Supervisory Control Using G-Control
  Consistency</dc:title>
 <dc:creator>Saeidi, Vahid</dc:creator>
 <dc:creator>Afzalian, Ali A.</dc:creator>
 <dc:creator>Gharavian, Davood</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Supervisory control synthesis encounters with computational complexity. This
can be reduced by decentralized supervisory control approach. In this paper, we
define intrinsic control consistency for a pair of states of the plant.
G-control consistency (GCC) is another concept which is defined for a natural
projection w.r.t. the plant. We prove that, if a natural projection is output
control consistent for the closed language of the plant, and is a natural
observer for the marked language of the plant, then it is G-control consistent.
Namely, we relax the conditions for synthesis the optimal non-blocking
decentralized supervisory control by substituting GCC property for L-OCC and
Lm-observer properties of a natural projection. We propose a method to
synthesize the optimal non-blocking decentralized supervisory control based on
GCC property for a natural projection. In fact, we change the approach from
language-based properties of a natural projection to DES-based property by
defining GCC property.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01048</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01049</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deconvolving Feedback Loops in Recommender Systems</dc:title>
 <dc:creator>Sinha, Ayan</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:creator>Ramani, Karthik</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Collaborative filtering is a popular technique to infer users' preferences on
new content based on the collective information of all users preferences.
Recommender systems then use this information to make personalized suggestions
to users. When users accept these recommendations it creates a feedback loop in
the recommender system, and these loops iteratively influence the collaborative
filtering algorithm's predictions over time. We investigate whether it is
possible to identify items affected by these feedback loops. We state
sufficient assumptions to deconvolve the feedback loops while keeping the
inverse solution tractable. We furthermore develop a metric to unravel the
recommender system's influence on the entire user-item rating matrix. We use
this metric on synthetic and real-world datasets to (1) identify the extent to
which the recommender system affects the final rating matrix, (2) rank
frequently recommended items, and (3) distinguish whether a user's rated item
was recommended or an intrinsic preference. Our results indicate that it is
possible to recover the ratings matrix of intrinsic user preferences using a
single snapshot of the ratings matrix without any temporal information.
</dc:description>
 <dc:description>Comment: Neural Information Processing Systems, 2016</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01053</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skin Lesion Classification using Class Activation Map</dc:title>
 <dc:creator>Jia, Xi</dc:creator>
 <dc:creator>Shen, Linlin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We proposed a two stage framework with only one network to analyze skin
lesion images, we firstly trained a convolutional network to classify these
images, and cropped the import regions which the network has the maximum
activation value. In the second stage, we retrained this CNN with the image
regions extracted from stage one and output the final probabilities. The two
stage framework achieved a mean AUC of 0.857 in ISIC-2017 skin lesion
validation set and is 0.04 higher than that of the original inputs, 0.821.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01054</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>When Hashes Met Wedges: A Distributed Algorithm for Finding High
  Similarity Vectors</dc:title>
 <dc:creator>Sharma, Aneesh</dc:creator>
 <dc:creator>Seshadhri, C.</dc:creator>
 <dc:creator>Goel, Ashish</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Finding similar user pairs is a fundamental task in social networks, with
numerous applications in ranking and personalization tasks such as link
prediction and tie strength detection. A common manifestation of user
similarity is based upon network structure: each user is represented by a
vector that represents the user's network connections, where pairwise cosine
similarity among these vectors defines user similarity. The predominant task
for user similarity applications is to discover all similar pairs that have a
pairwise cosine similarity value larger than a given threshold $\tau$. In
contrast to previous work where $\tau$ is assumed to be quite close to 1, we
focus on recommendation applications where $\tau$ is small, but still
meaningful. The all pairs cosine similarity problem is computationally
challenging on networks with billions of edges, and especially so for settings
with small $\tau$. To the best of our knowledge, there is no practical solution
for computing all user pairs with, say $\tau = 0.2$ on large social networks,
even using the power of distributed algorithms.
  Our work directly addresses this challenge by introducing a new algorithm ---
WHIMP --- that solves this problem efficiently in the MapReduce model. The key
insight in WHIMP is to combine the &quot;wedge-sampling&quot; approach of Cohen-Lewis for
approximate matrix multiplication with the SimHash random projection techniques
of Charikar. We provide a theoretical analysis of WHIMP, proving that it has
near optimal communication costs while maintaining computation cost comparable
with the state of the art. We also empirically demonstrate WHIMP's scalability
by computing all highly similar pairs on four massive data sets, and show that
it accurately finds high similarity pairs. In particular, we note that WHIMP
successfully processes the entire Twitter network, which has tens of billions
of edges.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01054</dc:identifier>
 <dc:identifier>doi:10.1145/3038912.3052633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01062</identifier>
 <datestamp>2017-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Full-Duplex Operations in Wireless Powered Communication Networks</dc:title>
 <dc:creator>Ju, Hyungsik</dc:creator>
 <dc:creator>Lee, Yuro</dc:creator>
 <dc:creator>Kim, Tae-Joong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a wireless powered communication network (WPCN) consisting of
a hybrid access point (H-AP) and multiple user equipment (UEs), all of which
operate in full-duplex (FD), is described. We first propose a transceiver
structure that enables FD operation of each UE to simultaneously receive energy
in the downlink (DL) and transmit information in the uplink (UL). We then
provide an energy usage model in the proposed UE transceiver that accounts for
the energy leakage from the transmit chain to the receive chain. It is shown
that the throughput of an FD WPCN using the proposed FD UEs can be maximized by
optimally allocating the UL transmission time to the UEs by solving a convex
optimization problem. Simulation results reveal that the use of the proposed FD
UEs efficiently improves the throughput of a WPCN with practical
self-interference cancellation (SIC) capability at the H-AP. With current SIC
technologies reducing the power of the residual self-interference to the level
of background noise, the proposed FD WPCN using FD UEs achieves 18% and 25 % of
throughput gain as compared to the conventional FD WPCN using HD UEs and HD
WPCN, respectively.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01062</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01065</identifier>
 <datestamp>2017-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Security of Warning Message Dissemination in Vehicular Ad Hoc
  Networks</dc:title>
 <dc:creator>Chen, Jieqiong</dc:creator>
 <dc:creator>Mao, Guoqiang</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Information security is an important issue in vehicular networks as the
accuracy and integrity of information is a prerequisite to satisfactory
performance of almost all vehicular network applications. In this paper, we
study the information security of a vehicular ad hoc network whose message may
be tampered by malicious vehicles. An analytical framework is developed to
analyze the process of message dissemination in a vehicular network with
malicious vehicles randomly distributed in the network. The probability that a
destination vehicle at a fixed distance away can receive the message correctly
from the source vehicle is obtained. Simulations are conducted to validate the
accuracy of the theoretical analysis. Our results demonstrate the impact of
network topology and the distribution of malicious vehicles on the correct
delivery of a message in vehicular ad hoc networks, and may provide insight on
the design of security mechanisms to improve the security of message
dissemination in vehicular networks.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01065</dc:identifier>
 <dc:identifier>Journal of Communications and Information Networks, Vol.2, No.2,
  Jun. 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01072</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>\'Etude sur les portails et agr\'egateurs des ressources p\'edagogiques
  universitaires francophones en acc\`es libre</dc:title>
 <dc:creator>Henda, Mokhtar Ben</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This study responds to the first measure undertaken on July 17, 2015 by
IDNEUF prject, that of an exploratory analysis of the existing portals and
aggregators of free French-language academic resources. The idea is to provide
an overview of the most common trends and practices in the constitution and
organization of digital online learning resource portals. The study of these
trends would help to define the appropriate choices and conditions for
designing the future common French-language portal and to optimize its services
for the conservation, exchange, integration and pooling of educational
resources within the distributed technological framework of French-language
universities. This framework should therefore be interconnected, transparent
and interoperable, reflecting both the linguistic and cultural specificities of
partner institutions and their ambitions for technological and economic
developments. The development of this first exploratory study of portals would
take into account the two technological solutions discussed at the task force
meeting on 17 July 2015.1. The alternative of extending the capabilities of
France's Digital University's search engine to French-language academic
institutions will require that the experience of the UNT (Numerical Thematic
University) be taken into account as a key player in the digital portal In
higher education (supnumerique.gouv.fr). Thus, the present study should first
target the portals of the UNT as models replicable or extensible to the French
context by analyzing their technological choices, their modes of organization
and their modes of use and communication;2. Next, the study will not be limited
to analyzing UNT portals. The proposed hypothesis to create a common portal of
French portals from the existing university portals also requires exploring
this possibility and proposing an analysis of existing portals that function
according to other organizational models.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01072</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01078</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Presence of Green and Sustainable Software Engineering in Higher
  Education Curricula</dc:title>
 <dc:creator>Torre, Damiano</dc:creator>
 <dc:creator>Procaccianti, Giuseppe</dc:creator>
 <dc:creator>Fucci, Davide</dc:creator>
 <dc:creator>Lutovac, Sonja</dc:creator>
 <dc:creator>Scanniello, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Nowadays, software is pervasive in our everyday lives. Its sustainability and
environmental impact have become major factors to be considered in the
development of software systems. Millennials-the newer generation of university
students-are particularly keen to learn about and contribute to a more
sustainable and green society. The need for training on green and sustainable
topics in software engineering has been reflected in a number of recent
studies. The goal of this paper is to get a first understanding of what is the
current state of teaching sustainability in the software engineering community,
what are the motivations behind the current state of teaching, and what can be
done to improve it. To this end, we report the findings from a targeted survey
of 33 academics on the presence of green and sustainable software engineering
in higher education. The major findings from the collected data suggest that
sustainability is under-represented in the curricula, while the current focus
of teaching is on energy efficiency delivered through a fact-based approach.
The reasons vary from lack of awareness, teaching material and suitable
technologies, to the high effort required to teach sustainability. Finally, we
provide recommendations for educators willing to teach sustainability in
software engineering that can help to suit millennial students needs.
</dc:description>
 <dc:description>Comment: The paper will be presented at the 1st International Workshop on
  Software Engineering Curricula for Millennials (SECM2017)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01080</identifier>
 <datestamp>2017-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Good cyclic codes and the uncertainty principle</dc:title>
 <dc:creator>Evra, Shai</dc:creator>
 <dc:creator>Kowalski, Emmanuel</dc:creator>
 <dc:creator>Lubotzky, Alexander</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Mathematics - Representation Theory</dc:subject>
 <dc:description>  A long standing problem in the area of error correcting codes asks whether
there exist good cyclic codes. Most of the known results point in the direction
of a negative answer.
  The uncertainty principle is a classical result of harmonic analysis
asserting that given a non-zero function $f$ on some abelian group, either $f$
or its Fourier transform $\hat{f}$ has large support.
  In this note, we observe a connection between these two subjects. We point
out that even a weak version of the uncertainty principle for fields of
positive characteristic would imply that good cyclic codes do exist. We also
provide some heuristic arguments supporting that this is indeed the case.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01080</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01083</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequential Plan Recognition</dc:title>
 <dc:creator>Mirsky, Reuth</dc:creator>
 <dc:creator>Stern, Roni</dc:creator>
 <dc:creator>Ya'akov</dc:creator>
 <dc:creator>Gal</dc:creator>
 <dc:creator>Kalech, Meir</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Plan recognition algorithms infer agents' plans from their observed actions.
Due to imperfect knowledge about the agent's behavior and the environment, it
is often the case that there are multiple hypotheses about an agent's plans
that are consistent with the observations, though only one of these hypotheses
is correct. This paper addresses the problem of how to disambiguate between
hypotheses, by querying the acting agent about whether a candidate plan in one
of the hypotheses matches its intentions. This process is performed
sequentially and used to update the set of possible hypotheses during the
recognition process. The paper defines the sequential plan recognition process
(SPRP), which seeks to reduce the number of hypotheses using a minimal number
of queries. We propose a number of policies for the SPRP which use maximum
likelihood and information gain to choose which plan to query. We show this
approach works well in practice on two domains from the literature,
significantly reducing the number of hypotheses using fewer queries than a
baseline approach. Our results can inform the design of future plan recognition
systems that interleave the recognition process with intelligent interventions
of their users.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01083</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01086</identifier>
 <datestamp>2017-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Arbitrary-Oriented Scene Text Detection via Rotation Proposals</dc:title>
 <dc:creator>Ma, Jianqi</dc:creator>
 <dc:creator>Shao, Weiyuan</dc:creator>
 <dc:creator>Ye, Hao</dc:creator>
 <dc:creator>Wang, Li</dc:creator>
 <dc:creator>Wang, Hong</dc:creator>
 <dc:creator>Zheng, Yingbin</dc:creator>
 <dc:creator>Xue, Xiangyang</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a novel rotation-based framework for arbitrary-oriented
text detection in natural scene images. We present the Rotation Region Proposal
Networks (RRPN), which is designed to generate inclined proposals with text
orientation angle information. The angle information is then adapted for
bounding box regression to make the proposals more accurately fit into the text
region in orientation. The Rotation Region-of-Interest (RRoI) pooling layer is
proposed to project arbitrary-oriented proposals to the feature map for a text
region classifier. The whole framework is built upon region proposal based
architecture, which ensures the computational efficiency of the
arbitrary-oriented text detection comparing with previous text detection
systems. We conduct experiments using the rotation-based framework on three
real-world scene text detection datasets, and demonstrate its superiority in
terms of effectiveness and efficiency over previous approaches.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01092</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zero-Delay Source-Channel Coding with a One-Bit ADC Front End and
  Correlated Side Information at the Receiver</dc:title>
 <dc:creator>Varasteh, Morteza</dc:creator>
 <dc:creator>Rassouli, Borzoo</dc:creator>
 <dc:creator>Simeone, Osvaldo</dc:creator>
 <dc:creator>Gunduz, Deniz</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Zero-delay transmission of a Gaussian source over an additive white Gaussian
noise (AWGN) channel is considered with a one-bit analog-to-digital converter
(ADC) front end and a correlated side information at the receiver. The design
of the optimal encoder and decoder is studied for two performance criteria,
namely, the mean squared error (MSE) distortion and the distortion outage
probability (DOP), under an average power constraint on the channel input. For
both criteria, necessary optimality conditions for the encoder and the decoder
are derived. Using these conditions, it is observed that the numerically
optimized encoder (NOE) under the MSE distortion criterion is periodic, and its
period increases with the correlation between the source and the receiver side
information. For the DOP, it is instead seen that the NOE mappings periodically
acquire positive and negative values, which decay to zero with increasing
source magnitude, and the interval over which the mapping takes non-zero
values, becomes wider with the correlation between the source and the side
information.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01092</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01093</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Employing Spectral Domain Features for Efficient Collaborative Filtering</dc:title>
 <dc:creator>Shawky, Doaa M.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Collaborative filtering (CF) is a powerful recommender system that generates
a list of recommended items for an active user based on the ratings of similar
users. This paper presents a novel approach to CF by first finding the set of
users similar to the active user by adopting self-organizing maps (SOM),
followed by k-means clustering. Then, the ratings for each item in the cluster
closest to the active user are mapped to the frequency domain using the
Discrete Fourier Transform (DFT). The power spectra of the mapped ratings are
generated, and a new similarity measure based on the coherence of these power
spectra is calculated. The proposed similarity measure is more time efficient
than current state-of-the-art measures. Moreover, it can capture the global
similarity between the profiles of users. Experimental results show that the
proposed approach overcomes the major problems in existing CF algorithms as
follows: First, it mitigates the scalability problem by creating clusters of
similar users and applying the time-efficient similarity measure. Second, its
frequency-based similarity measure is less sensitive to sparsity problems
because the DFT performs efficiently even with sparse data. Third, it
outperforms standard similarity measures in terms of accuracy.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01093</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01101</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adversarial Examples for Semantic Image Segmentation</dc:title>
 <dc:creator>Fischer, Volker</dc:creator>
 <dc:creator>Kumar, Mummadi Chaithanya</dc:creator>
 <dc:creator>Metzen, Jan Hendrik</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Machine learning methods in general and Deep Neural Networks in particular
have shown to be vulnerable to adversarial perturbations. So far this
phenomenon has mainly been studied in the context of whole-image
classification. In this contribution, we analyse how adversarial perturbations
can affect the task of semantic segmentation. We show how existing adversarial
attackers can be transferred to this task and that it is possible to create
imperceptible adversarial perturbations that lead a deep network to misclassify
almost all pixels of a chosen class while leaving network prediction nearly
unchanged outside this class.
</dc:description>
 <dc:description>Comment: ICLR 2017 workshop submission</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01106</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Bayesian Learning on Distributed Data</dc:title>
 <dc:creator>Heikkil&#xe4;, Mikko</dc:creator>
 <dc:creator>Lagerspetz, Eemil</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:creator>Shimizu, Kana</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:creator>Honkela, Antti</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:description>  Many applications of machine learning, for example in health care, would
benefit from methods that can guarantee privacy of data subjects. Differential
privacy (DP) has become established as a standard for protecting learning
results. The standard DP algorithms require a single trusted party to have
access to the entire data, which is a clear weakness. We consider DP Bayesian
learning in a distributed setting, where each party only holds a single sample
or a few samples of the data. We propose a learning strategy based on a secure
multi-party sum function for aggregating summaries from data holders and the
Gaussian mechanism for DP. Our method builds on an asymptotically optimal and
practically efficient DP Bayesian inference with rapidly diminishing extra
cost.
</dc:description>
 <dc:description>Comment: 13 pages, 7 figures. Modified text, changed algorithm used, included
  tests on additional dataset, fixed several errors, added proof of asymptotic
  efficiency to supplement</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01106</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01107</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An intracardiac electrogram model to bridge virtual hearts and
  implantable cardiac devices</dc:title>
 <dc:creator>Ai, Weiwei</dc:creator>
 <dc:creator>Patel, Nitish</dc:creator>
 <dc:creator>Roop, Partha</dc:creator>
 <dc:creator>Malik, Avinash</dc:creator>
 <dc:creator>Allen, Nathan</dc:creator>
 <dc:creator>Trew, Mark L.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  Virtual heart models have been proposed to enhance the safety of implantable
cardiac devices through closed loop validation. To communicate with a virtual
heart, devices have been driven by cardiac signals at specific sites. As a
result, only the action potentials of these sites are sensed. However, the real
device implanted in the heart will sense a complex combination of near and
far-field extracellular potential signals. Therefore many device functions,
such as blanking periods and refractory periods, are designed to handle these
unexpected signals. To represent these signals, we develop an intracardiac
electrogram (IEGM) model as an interface between the virtual heart and the
device. The model can capture not only the local excitation but also far-field
signals and pacing afterpotentials. Moreover, the sensing controller can
specify unipolar or bipolar electrogram (EGM) sensing configurations and
introduce various oversensing and undersensing modes. The simulation results
show that the model is able to reproduce clinically observed sensing problems,
which significantly extends the capabilities of the virtual heart model in the
context of device validation.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01120</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep artifact learning for compressed sensing and parallel MRI</dc:title>
 <dc:creator>Lee, Dongwook</dc:creator>
 <dc:creator>Yoo, Jaejun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Purpose: Compressed sensing MRI (CS-MRI) from single and parallel coils is
one of the powerful ways to reduce the scan time of MR imaging with performance
guarantee. However, the computational costs are usually expensive. This paper
aims to propose a computationally fast and accurate deep learning algorithm for
the reconstruction of MR images from highly down-sampled k-space data.
  Theory: Based on the topological analysis, we show that the data manifold of
the aliasing artifact is easier to learn from a uniform subsampling pattern
with additional low-frequency k-space data. Thus, we develop deep aliasing
artifact learning networks for the magnitude and phase images to estimate and
remove the aliasing artifacts from highly accelerated MR acquisition.
  Methods: The aliasing artifacts are directly estimated from the distorted
magnitude and phase images reconstructed from subsampled k-space data so that
we can get an aliasing-free images by subtracting the estimated aliasing
artifact from corrupted inputs. Moreover, to deal with the globally distributed
aliasing artifact, we develop a multi-scale deep neural network with a large
receptive field.
  Results: The experimental results confirm that the proposed deep artifact
learning network effectively estimates and removes the aliasing artifacts.
Compared to existing CS methods from single and multi-coli data, the proposed
network shows minimal errors by removing the coherent aliasing artifacts.
Furthermore, the computational time is by order of magnitude faster.
  Conclusion: As the proposed deep artifact learning network immediately
generates accurate reconstruction, it has great potential for clinical
applications.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01120</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01121</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Parameterized Complexity of Group Activity Selection Problems on
  Social Networks</dc:title>
 <dc:creator>Igarashi, Ayumi</dc:creator>
 <dc:creator>Bredereck, Robert</dc:creator>
 <dc:creator>Elkind, Edith</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In Group Activity Selection Problem (GASP), players form coalitions to
participate in activities and have preferences over pairs of the form
(activity, group size). Recently, Igarashi et al. have initiated the study of
group activity selection problems on social networks (gGASP): a group of
players can engage in the same activity if the members of the group form a
connected subset of the underlying communication structure. Igarashi et al.
have primarily focused on Nash stable outcomes, and showed that many associated
algorithmic questions are computationally hard even for very simple networks.
In this paper we study the parameterized complexity of gGASP with respect to
the number of activities as well as with respect to the number of players, for
several solution concepts such as Nash stability, individual stability and core
stability. The first parameter we consider in the number of activities. For
this parameter, we propose an FPT algorithm for Nash stability for the case
where the social network is acyclic and obtain a W[1]-hardness result for
cliques (i.e., for classic GASP); similar results hold for individual
stability. In contrast, finding a core stable outcome is hard even if the
number of activities is bounded by a small constant, both for classic GASP and
when the social network is a star. Another parameter we study is the number of
players. While all solution concepts we consider become polynomial-time
computable when this parameter is bounded by a constant, we prove W[1]-hardness
results for cliques (i.e., for classic GASP).
</dc:description>
 <dc:description>Comment: 9 pages, long version of accepted AAMAS-17 paper</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01121</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01122</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>First-Order Logic with Counting: At Least, Weak Hanf Normal Forms Always
  Exist and Can Be Computed!</dc:title>
 <dc:creator>Kuske, Dietrich</dc:creator>
 <dc:creator>Schweikardt, Nicole</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce the logic FOCN(P) which extends first-order logic by counting
and by numerical predicates from a set P, and which can be viewed as a natural
generalisation of various counting logics that have been studied in the
literature.
  We obtain a locality result showing that every FOCN(P)-formula can be
transformed into a formula in Hanf normal form that is equivalent on all finite
structures of degree at most d. A formula is in Hanf normal form if it is a
Boolean combination of formulas describing the neighbourhood around its tuple
of free variables and arithmetic sentences with predicates from P over atomic
statements describing the number of realisations of a type with a single
centre. The transformation into Hanf normal form can be achieved in time
elementary in $d$ and the size of the input formula. From this locality result,
we infer the following applications: (*) The Hanf-locality rank of first-order
formulas of bounded quantifier alternation depth only grows polynomially with
the formula size. (*) The model checking problem for the fragment FOC(P) of
FOCN(P) on structures of bounded degree is fixed-parameter tractable (with
elementary parameter dependence). (*) The query evaluation problem for fixed
queries from FOC(P) over fully dynamic databases of degree at most d can be
solved efficiently: there is a dynamic algorithm that can enumerate the tuples
in the query result with constant delay, and that allows to compute the size of
the query result and to test if a given tuple belongs to the query result
within constant time after every database update.
</dc:description>
 <dc:description>Comment: 41 pages</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01122</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01127</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Behavior of Convolutional Nets for Feature Extraction</dc:title>
 <dc:creator>Garcia-Gasulla, Dario</dc:creator>
 <dc:creator>Par&#xe9;s, Ferran</dc:creator>
 <dc:creator>Vilalta, Armand</dc:creator>
 <dc:creator>Moreno, Jonatan</dc:creator>
 <dc:creator>Ayguad&#xe9;, Eduard</dc:creator>
 <dc:creator>Labarta, Jes&#xfa;s</dc:creator>
 <dc:creator>Cort&#xe9;s, Ulises</dc:creator>
 <dc:creator>Suzumura, Toyotaro</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep neural networks are representation learning techniques. During training,
a deep net is capable of generating a descriptive language of unprecedented
size and detail in machine learning. Extracting the descriptive language coded
within a trained CNN model (in the case of image data), and reusing it for
other purposes is a field of interest, as it provides access to the visual
descriptors previously learnt by the CNN after processing millions of images,
without requiring an expensive training phase. Contributions to this field
(commonly known as feature representation transfer or transfer learning) have
been purely empirical so far, extracting all CNN features from a single layer
close to the output and testing their performance by feeding them to a
classifier. This approach has provided consistent results, although its
relevance is limited to classification tasks. In a completely different
approach, in this paper we statistically measure the discriminative power of
every single feature found within a deep CNN, when used for characterizing
every class of 11 datasets. We seek to provide new insights into the behavior
of CNN features, particularly the ones from convolutional layers, as this can
be relevant for their application to knowledge representation and reasoning.
Our results confirm that low and middle level features may behave differently
to high level features, but only under certain conditions. We find that all CNN
features can be used for knowledge representation purposes both by their
presence or by their absence, doubling the information a single CNN feature may
provide. We also study how much noise these features may include, and propose a
thresholding approach to discard most of it. All these insights have a direct
application to the generation of CNN embedding spaces.
</dc:description>
 <dc:description>Comment: Submitted to Journal of Artificial Intelligence Research Special
  Track on Deep Learning, Knowledge Representation, and Reasoning</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-11-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01127</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01135</identifier>
 <datestamp>2018-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning with Domain Adaptation for Accelerated
  Projection-Reconstruction MR</dc:title>
 <dc:creator>Han, Yo Seob</dc:creator>
 <dc:creator>Yoo, Jaejun</dc:creator>
 <dc:creator>Ye, Jong Chul</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Purpose: The radial k-space trajectory is a well-established sampling
trajectory used in conjunction with magnetic resonance imaging. However, the
radial k-space trajectory requires a large number of radial lines for
high-resolution reconstruction. Increasing the number of radial lines causes
longer acquisition time, making it more difficult for routine clinical use. On
the other hand, if we reduce the number of radial lines, streaking artifact
patterns are unavoidable. To solve this problem, we propose a novel deep
learning approach with domain adaptation to restore high-resolution MR images
from under-sampled k-space data.
  Methods: The proposed deep network removes the streaking artifacts from the
artifact corrupted images. To address the situation given the limited available
data, we propose a domain adaptation scheme that employs a pre-trained network
using a large number of x-ray computed tomography (CT) or synthesized radial MR
datasets, which is then fine-tuned with only a few radial MR datasets.
  Results: The proposed method outperforms existing compressed sensing
algorithms, such as the total variation and PR-FOCUSS methods. In addition, the
calculation time is several orders of magnitude faster than the total variation
and PR-FOCUSS methods.Moreover, we found that pre-training using CT or MR data
from similar organ data is more important than pre-training using data from the
same modality for different organ.
  Conclusion: We demonstrate the possibility of a domain-adaptation when only a
limited amount of MR data is available. The proposed method surpasses the
existing compressed sensing algorithms in terms of the image quality and
computation time.
</dc:description>
 <dc:description>Comment: This paper has been accepted and will soon appear in Magnetic
  Resonance in Medicine</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2018-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01135</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01138</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multiplicative Weights Update with Constant Step-Size in Congestion
  Games: Convergence, Limit Cycles and Chaos</dc:title>
 <dc:creator>Palaiopanos, Gerasimos</dc:creator>
 <dc:creator>Panageas, Ioannis</dc:creator>
 <dc:creator>Piliouras, Georgios</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  The Multiplicative Weights Update (MWU) method is a ubiquitous meta-algorithm
that works as follows: A distribution is maintained on a certain set, and at
each step the probability assigned to element $\gamma$ is multiplied by $(1
-\epsilon C(\gamma))&gt;0$ where $C(\gamma)$ is the &quot;cost&quot; of element $\gamma$ and
then rescaled to ensure that the new values form a distribution. We analyze MWU
in congestion games where agents use \textit{arbitrary admissible constants} as
learning rates $\epsilon$ and prove convergence to \textit{exact Nash
equilibria}. Our proof leverages a novel connection between MWU and the
Baum-Welch algorithm, the standard instantiation of the
Expectation-Maximization (EM) algorithm for hidden Markov models (HMM).
Interestingly, this convergence result does not carry over to the nearly
homologous MWU variant where at each step the probability assigned to element
$\gamma$ is multiplied by $(1 -\epsilon)^{C(\gamma)}$ even for the most
innocuous case of two-agent, two-strategy load balancing games, where such
dynamics can provably lead to limit cycles or even chaotic behavior.
</dc:description>
 <dc:description>Comment: 17 pages, 9 figures</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01138</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01141</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic State Warping</dc:title>
 <dc:creator>Gong, Zhichen</dc:creator>
 <dc:creator>Chen, Huanhuan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The ubiquity of sequences in many domains enhances significant recent
interest in sequence learning, for which a basic problem is how to measure the
distance between sequences. Dynamic time warping (DTW) aligns two sequences by
nonlinear local warping and returns a distance value. DTW shows superior
ability in many applications, e.g. video, image, etc. However, in DTW, two
points are paired essentially based on point-to-point Euclidean distance (ED)
without considering the autocorrelation of sequences. Thus, points with
different semantic meanings, e.g. peaks and valleys, may be matched providing
their coordinate values are similar. As a result, DTW is sensitive to noise and
poorly interpretable. This paper proposes an efficient and flexible sequence
alignment algorithm, dynamic state warping (DSW). DSW converts each time point
into a latent state, which endows point-wise autocorrelation information.
Alignment is performed by using the state sequences. Thus DSW is able to yield
alignment that is semantically more interpretable than that of DTW. Using one
nearest neighbor classifier, DSW shows significant improvement on
classification accuracy in comparison to ED (70/85 wins) and DTW (74/85 wins).
We also empirically demonstrate that DSW is more robust and scales better to
long sequences than ED and DTW.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01141</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01142</identifier>
 <datestamp>2017-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symmetric Laplacians, Quantum Density Matrices and their Von-Neumann
  Entropy</dc:title>
 <dc:creator>Simmons, David E.</dc:creator>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:creator>Datta, Animesh</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We show that the (normalized) symmetric Laplacian of a simple graph can be
obtained from the partial trace over a pure bipartite quantum state that
resides in a bipartite Hilbert space (one part corresponding to the vertices,
the other corresponding to the edges). This suggests an interpretation of the
symmetric Laplacian's Von Neumann entropy as a measure of bipartite
entanglement present between the two parts of the state. We then study extreme
values for a connected graph's generalized R\'enyi-$p$ entropy. Specifically,
we show that
  (1) the complete graph achieves maximum entropy,
  (2) the $2$-regular graph: a) achieves minimum R\'enyi-$2$ entropy among all
$k$-regular graphs, b) is within $\log 4/3$ of the minimum R\'enyi-$2$ entropy
and $\log4\sqrt{2}/3$ of the minimum Von Neumann entropy among all connected
graphs, c) achieves a Von Neumann entropy less than the star graph.
  Point $(2)$ contrasts sharply with similar work applied to (normalized)
combinatorial Laplacians, where it has been shown that the star graph almost
always achieves minimum Von Neumann entropy. In this work we find that the star
graph achieves maximum entropy in the limit as the number of vertices grows
without bound.
  Keywords: Symmetric; Laplacian; Quantum; Entropy; Bounds; R\'enyi.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01142</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01143</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why is it hard to beat $O(n^2)$ for Longest Common Weakly Increasing
  Subsequence?</dc:title>
 <dc:creator>Polak, Adam</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  The Longest Common Weakly Increasing Subsequence problem (LCWIS) is a variant
of the classic Longest Common Subsequence problem (LCS). Both problems can be
solved with simple quadratic time algorithms. A recent line of research led to
a number of matching conditional lower bounds for LCS and other related
problems. However, the status of LCWIS remained open.
  In this paper we show that LCWIS cannot be solved in strongly subquadratic
time unless the Strong Exponential Time Hypothesis (SETH) is false.
  The ideas which we developed can also be used to obtain a lower bound based
on a safer assumption of NC-SETH, i.e. a version of SETH which talks about NC
circuits instead of less expressive CNF formulas.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01143</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01148</identifier>
 <datestamp>2017-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Runtime Optimization of Join Location in Parallel Data Management
  Systems</dc:title>
 <dc:creator>Chandra, Bikash</dc:creator>
 <dc:creator>Sudarshan, S.</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68P15</dc:subject>
 <dc:subject>H.2</dc:subject>
 <dc:description>  Applications running on parallel systems often need to join a streaming
relation or a stored relation with data indexed in a parallel data storage
system. Some applications also compute UDFs on the joined tuples. The join can
be done at the data storage nodes, corresponding to reduce side joins, or by
fetching data from the storage system to compute nodes, corresponding to map
side join. Both may be suboptimal: reduce side joins may cause skew, while map
side joins may lead to a lot of data being transferred and replicated.
  In this paper, we present techniques to make runtime decisions between the
two options on a per key basis, in order to improve the throughput of the join,
accounting for UDF computation if any. Our techniques are based on an extended
ski-rental algorithm and provide worst-case performance guarantees with respect
to the optimal point in the space considered by us. Our techniques use load
balancing taking into account the CPU, network and I/O costs as well as the
load on compute and storage nodes. We have implemented our techniques on
Hadoop, Spark and the Muppet stream processing engine. Our experiments show
that our optimization techniques provide a significant improvement in
throughput over existing techniques.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-07-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01149</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A note on minimum linear arrangement for BC graphs</dc:title>
 <dc:creator>Jiang, Xiaofang</dc:creator>
 <dc:creator>Liu, Qinghui</dc:creator>
 <dc:creator>Parthiban, Natarajan</dc:creator>
 <dc:creator>Rajan, R. Sundara</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C38</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  A linear arrangement is a labeling or a numbering or a linear ordering of the
vertices of a graph. In this paper we solve the minimum linear arrangement
problem for bijective connection graphs (for short BC graphs) which include
hypercubes, M\&quot;{o}bius cubes, crossed cubes, twisted cubes, locally twisted
cube, spined cube, $Z$-cubes, etc. as the subfamilies.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01149</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01161</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FeUdal Networks for Hierarchical Reinforcement Learning</dc:title>
 <dc:creator>Vezhnevets, Alexander Sasha</dc:creator>
 <dc:creator>Osindero, Simon</dc:creator>
 <dc:creator>Schaul, Tom</dc:creator>
 <dc:creator>Heess, Nicolas</dc:creator>
 <dc:creator>Jaderberg, Max</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical
reinforcement learning. Our approach is inspired by the feudal reinforcement
learning proposal of Dayan and Hinton, and gains power and efficacy by
decoupling end-to-end learning across multiple levels -- allowing it to utilise
different resolutions of time. Our framework employs a Manager module and a
Worker module. The Manager operates at a lower temporal resolution and sets
abstract goals which are conveyed to and enacted by the Worker. The Worker
generates primitive actions at every tick of the environment. The decoupled
structure of FuN conveys several benefits -- in addition to facilitating very
long timescale credit assignment it also encourages the emergence of
sub-policies associated with different goals set by the Manager. These
properties allow FuN to dramatically outperform a strong baseline agent on
tasks that involve long-term credit assignment or memorisation. We demonstrate
the performance of our proposed system on a range of tasks from the ATARI suite
and also from a 3D DeepMind Lab environment.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01161</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01164</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nonlinear Model Predictive Control for Multi-Micro Aerial Vehicle Robust
  Collision Avoidance</dc:title>
 <dc:creator>Kamel, Mina</dc:creator>
 <dc:creator>Alonso-Mora, Javier</dc:creator>
 <dc:creator>Siegwart, Roland</dc:creator>
 <dc:creator>Nieto, Juan</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Multiple multirotor Micro Aerial Vehicles sharing the same airspace require a
reliable and robust collision avoidance technique. In this paper we address the
problem of multi-MAV reactive collision avoidance. A model-based controller is
employed to achieve simultaneously reference trajectory tracking and collision
avoidance. Moreover, we also account for the uncertainty of the state estimator
and the other agents position and velocity uncertainties to achieve a higher
degree of robustness. The proposed approach is decentralized, does not require
collision-free reference trajectory and accounts for the full MAV dynamics. We
validated our approach in simulation and experimentally.
</dc:description>
 <dc:description>Comment: Video available on: https://www.youtube.com/watch?v=Ot76i9p2ZZo&amp;t=40s</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01166</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Network Measurements through Approximated Windows</dc:title>
 <dc:creator>Basat, Ran Ben</dc:creator>
 <dc:creator>Einziger, Gil</dc:creator>
 <dc:creator>Friedman, Roy</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Many networking applications require timely access to recent network
measurements, which can be captured using a sliding window model. Maintaining
such measurements is a challenging task due to the fast line speed and scarcity
of fast memory in routers. In this work, we study the efficiency factor that
can be gained by approximating the window size. That is, we allow the algorithm
to dynamically adjust the window size between $W$ and $W(1+\tau)$ where $\tau$
is a small positive parameter. For example, consider the \emph{basic summing}
problem of computing the sum of the last $W$ elements in a stream whose items
are integers in $\{0,1\ldots,R\}$, where $R=\text{poly}(W)$. While it is known
that $\Omega(W\log{R})$ bits are needed in the exact window model, we show that
approximate windows allow an exponential space reduction for constant $\tau$.
  Specifically, we present a lower bound of $\Omega(\tau^{-1}\log(RW\tau))$
bits for the basic summing problem. Further, an $(1+\epsilon)$ multiplicative
approximation of this problem requires $\Omega(\log({W/\epsilon}+\log\log{R}))$
bits for constant $\tau$. Additionally, for $RW\epsilon$ additive
approximations, we show an
$\Omega(\tau^{-1}\log\lfloor{1+\tau/\epsilon}\rfloor+\log({W/\epsilon}))$ lower
bound~\footnote{ We also provide an optimal bound and algorithm for the
$\tau&lt;\epsilon$ case.}. For all three settings, we provide memory optimal
algorithms that operate in constant time. Finally, we demonstrate the
generality of the approximated window model by applying it to counting the
number of distinct flows in a sliding window over a network stream. We present
an algorithm that solves this problem while requiring asymptotically less space
than previous sliding window methods when $\tau=O(1)$.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01167</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A compact Verilog-A ReRAM switching model</dc:title>
 <dc:creator>Messaris, Ioannis</dc:creator>
 <dc:creator>Serb, Alexander</dc:creator>
 <dc:creator>Khiat, Ali</dc:creator>
 <dc:creator>Nikolaidis, Spyridon</dc:creator>
 <dc:creator>Prodromakis, Themistoklis</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  The translation of emerging application concepts that exploit Resistive
Random Access Memory (ReRAM) into large-scale practical systems requires
realistic, yet computationally efficient, empirical models that can capture all
observed physical devices. Here, we present a Verilog-A ReRAM model built upon
experimental routines performed on TiOx-based prototypes. This model was based
on custom biasing protocols, specifically designed to reveal device switching
rate dependencies on a) bias voltage and b) initial resistive state. Our model
is based on the assumption that a stationary switching rate surface m(R,v)
exists for sufficiently low voltage stimulation. The proposed model comes in
compact form as it is expressed by a simple voltage dependent exponential
function multiplied with a voltage and initial resistive state dependent second
order polynomial expression, which makes it suitable for fast and/or
large-scale simulations.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01167</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01168</identifier>
 <datestamp>2017-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sum-set Inequalities from Aligned Image Sets: Instruments for Robust
  GDoF Bounds</dc:title>
 <dc:creator>Davoodi, Arash Gholami</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present sum-set inequalities specialized to the generalized degrees of
freedom (GDoF) framework. These are information theoretic lower bounds on the
entropy of bounded density linear combinations of discrete, power-limited
dependent random variables in terms of the joint entropies of arbitrary linear
combinations of new random variables that are obtained by power level
partitioning of the original random variables. These bounds generalize the
aligned image sets approach, and are useful instruments to obtain GDoF
characterizations for wireless networks, especially with multiple antenna
nodes, subject to arbitrary channel strength and channel uncertainty levels. To
demonstrate the utility of these bounds, we consider a non-trivial instance of
wireless networks - a two user interference channel with different number of
antennas at each node, and different levels of partial channel knowledge
available to the transmitters. We obtain tight GDoF characterization for
specific instance of this channel with the aid of sum-set inequalities.
</dc:description>
 <dc:description>Comment: 35 pages, 7 figures</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-08-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01170</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey on Content-Aware Video Analysis for Sports</dc:title>
 <dc:creator>Shih, Huang-Chia</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Sports data analysis is becoming increasingly large-scale, diversified, and
shared, but difficulty persists in rapidly accessing the most crucial
information. Previous surveys have focused on the methodologies of sports video
analysis from the spatiotemporal viewpoint instead of a content-based
viewpoint, and few of these studies have considered semantics. This study
develops a deeper interpretation of content-aware sports video analysis by
examining the insight offered by research into the structure of content under
different scenarios. On the basis of this insight, we provide an overview of
the themes particularly relevant to the research on content-aware systems for
broadcast sports. Specifically, we focus on the video content analysis
techniques applied in sportscasts over the past decade from the perspectives of
fundamentals and general review, a content hierarchical model, and trends and
challenges. Content-aware analysis methods are discussed with respect to
object-, event-, and context-oriented groups. In each group, the gap between
sensation and content excitement must be bridged using proper strategies. In
this regard, a content-aware approach is required to determine user demands.
Finally, the paper summarizes the future trends and challenges for sports video
analysis. We believe that our findings can advance the field of research on
content-aware video analysis for broadcast sports.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Circuits and Systems
  for Video Technology (TCSVT)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01170</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2017.2655624</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01190</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multicast Transmissions in Directional mmWave Communications</dc:title>
 <dc:creator>Biason, Alessandro</dc:creator>
 <dc:creator>Zorzi, Michele</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Multicast transmissions have been widely analyzed in traditional networks as
a way to improve spectrum efficiency when multiple users are interested in the
same data. However, their application to mmWave communications has been studied
only marginally so far. The goal of this paper is to partially fill this gap by
investigating optimal and suboptimal multicast schemes for mmWave
communications with directional beams. In particular, we propose a Markov setup
to model the retransmission status of the unsuccessfully transmitted packets
and, because of the computational complexity of the optimal solution, we
introduce a suboptimal hierarchical optimization procedure, which is much
easier to derive. Finally, we numerically show that restricting the link to
unicast beams is strongly suboptimal, especially when many packets have to be
transmitted.
</dc:description>
 <dc:description>Comment: 8 pages, 5 figures, submitted to European Wireless (EW), Feb. 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01192</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tree Notation: an antifragile program notation</dc:title>
 <dc:creator>Yunits, Breck</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  This paper presents Tree Notation, a new simple, universal syntax. Language
designers can invent new programming languages, called Tree Languages, on top
of Tree Notation. Tree Languages have a number of advantages over traditional
programming languages.
  We include a Visual Abstract to succinctly display the problem and discovery.
Then we describe the problem--the BNF to abstract syntax tree (AST) parse
step--and introduce the novel solution we discovered: a new family of 2D
programming languages that are written directly as geometric trees.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-10-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01195</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Why Smart Appliances May Result in a Stupid Energy Grid?</dc:title>
 <dc:creator>Nardelli, Pedro H. J.</dc:creator>
 <dc:creator>K&#xfc;hnlenz, Florian</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This article discusses unexpected consequences of idealistic conceptions
about the modernization of power grids. We will focus our analysis on
demand-response policies based on automatic decisions by the so-called smart
home appliances. Following the usual design approach, each individual appliance
has access to a universal signal (e.g. grid frequency or electricity price)
that is believed to indicate the system state. Such information is then used as
the basis of the appliances' individual decisions. While each single device has
a negligible impact in the system, the aggregate effect of the distributed
appliances' reactions is expect to bring improvements in the system efficiency;
this effect is the demand-response policy goal. The smartness of such an ideal
system, composed by isolated appliances with their individual decisions, but
connected in the same physical grid, may worsen the system stability. This
first-sight undesirable outcome comes as a consequence of synchronization among
agents that are subject to the same signal. We argue that this effect is in
fact byproduct of methodological choices, which are many times implicit. To
support this claim, we employ a different approach that understands the
electricity system as constituted by physical, informational and regulatory
(networked and structured) layers that cannot be reduced to only one or two of
them, but have to be viewed as an organic whole. By classifying its structure
under this lens, more appropriate management tools can be designed by looking
at the system totality in action. Two examples are provided to illustrate the
strength of this modeling.
</dc:description>
 <dc:date>2017-03-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01195</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01196</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Identifiable Gaussian Bayesian Networks in Polynomial Time and
  Sample Complexity</dc:title>
 <dc:creator>Ghoshal, Asish</dc:creator>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Learning the directed acyclic graph (DAG) structure of a Bayesian network
from observational data is a notoriously difficult problem for which many
hardness results are known. In this paper we propose a provably polynomial-time
algorithm for learning sparse Gaussian Bayesian networks with equal noise
variance --- a class of Bayesian networks for which the DAG structure can be
uniquely identified from observational data --- under high-dimensional
settings. We show that $O(k^4 \log p)$ number of samples suffices for our
method to recover the true DAG structure with high probability, where $p$ is
the number of variables and $k$ is the maximum Markov blanket size. We obtain
our theoretical guarantees under a condition called Restricted Strong Adjacency
Faithfulness, which is strictly weaker than strong faithfulness --- a condition
that other methods based on conditional independence testing need for their
success. The sample complexity of our method matches the information-theoretic
limits in terms of the dependence on $p$. We show that our method out-performs
existing state-of-the-art methods for learning Gaussian Bayesian networks in
terms of recovering the true DAG structure while being comparable in speed to
heuristic methods.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01200</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Everware toolkit. Supporting reproducible science and challenge-driven
  education</dc:title>
 <dc:creator>Ustyuzhanin, Andrey</dc:creator>
 <dc:creator>Head, Timothy Daniel</dc:creator>
 <dc:creator>Babuschkin, Igor</dc:creator>
 <dc:creator>Tiunov, Alexander</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Modern science clearly demands for a higher level of reproducibility and
collaboration. To make research fully reproducible one has to take care of
several aspects: research protocol description, data access, environment
preservation, workflow pipeline, and analysis script preservation. Version
control systems like git help with the workflow and analysis scripts part.
Virtualization techniques like Docker or Vagrant can help deal with
environments. Jupyter notebooks are a powerful platform for conducting research
in a collaborative manner. We present project Everware that seamlessly
integrates git repository management systems such as Github or Gitlab, Docker
and Jupyter helping with a) sharing results of real research and b) boosts
education activities. With the help of Everware one can not only share the
final artifacts of research but all the depth of the research process. This
been shown to be extremely helpful during organization of several data analysis
hackathons and machine learning schools. Using Everware participants could
start from an existing solution instead of starting from scratch. They could
start contributing immediately. Everware allows its users to make use of their
own computational resources to run the workflows they are interested in, which
leads to higher scalability of the toolkit.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01200</dc:identifier>
 <dc:identifier>doi:10.1088/1742-6596/898/7/072051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01202</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel energy-stable phase field crystal simulations based on domain
  decomposition methods</dc:title>
 <dc:creator>Wei, Ying</dc:creator>
 <dc:creator>Yang, Chao</dc:creator>
 <dc:creator>Huang, Jizu</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  In this paper, we present a parallel numerical algorithm for solving the
phase field crystal equation. In the algorithm, a semi-implicit finite
difference scheme is derived based on the discrete variational derivative
method. Theoretical analysis is provided to show that the scheme is
unconditionally energy stable and can achieve second-order accuracy in both
space and time. An adaptive time step strategy is adopted such that the time
step size can be flexibly controlled based on the dynamical evolution of the
problem. At each time step, a nonlinear algebraic system is constructed from
the discretization of the phase field crystal equation and solved by a domain
decomposition based, parallel Newton--Krylov--Schwarz method with improved
boundary conditions for subdomain problems. Numerical experiments with several
two and three dimensional test cases show that the proposed algorithm is
second-order accurate in both space and time, energy stable with large time
steps, and highly scalable to over ten thousands processor cores on the Sunway
TaihuLight supercomputer.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01203</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Separation Theorems</dc:title>
 <dc:creator>Gorban, A. N.</dc:creator>
 <dc:creator>Tyukin, I. Y.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T10</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  The problem of non-iterative one-shot and non-destructive correction of
unavoidable mistakes arises in all Artificial Intelligence applications in the
real world. Its solution requires robust separation of samples with errors from
samples where the system works properly. We demonstrate that in (moderately)
high dimension this separation could be achieved with probability close to one
by linear discriminants. Surprisingly, separation of a new image from a very
large set of known images is almost always possible even in moderately high
dimensions by linear functionals, and coefficients of these functionals can be
found explicitly. Based on fundamental properties of measure concentration, we
show that for $M&lt;a\exp(b{n})$ random $M$-element sets in $\mathbb{R}^n$ are
linearly separable with probability $p$, $p&gt;1-\vartheta$, where $1&gt;\vartheta&gt;0$
is a given small constant. Exact values of $a,b&gt;0$ depend on the probability
distribution that determines how the random $M$-element sets are drawn, and on
the constant $\vartheta$. These {\em stochastic separation theorems} provide a
new instrument for the development, analysis, and assessment of machine
learning methods and algorithms in high dimension. Theoretical statements are
illustrated with numerical examples.
</dc:description>
 <dc:description>Comment: 6 pages, accepted for publication in Neural Networks (Letter section)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01203</dc:identifier>
 <dc:identifier>Neural Networks 94 (2017), 255-259</dc:identifier>
 <dc:identifier>doi:10.1016/j.neunet.2017.07.014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01204</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Custom Hypergraph Categories via Generalized Relations</dc:title>
 <dc:creator>Marsden, Dan</dc:creator>
 <dc:creator>Genovese, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:description>  Process theories combine a graphical language for compositional reasoning
with an underlying categorical semantics. They have been successfully applied
to fields such as quantum computation, natural language processing, linear
dynamical systems and network theory. When investigating a new application, the
question arises of how to identify a suitable process theoretic model.
  We present a conceptually motivated parameterized framework for the
construction of models for process theories. Our framework generalizes the
notion of binary relation along four axes of variation, the truth values, a
choice of algebraic structure, the ambient mathematical universe and the choice
of proof relevance or provability. The resulting categories are
preorder-enriched and provide analogues of relational converse and taking
graphs of maps. Our constructions are functorial in the parameter choices,
establishing mathematical connections between different application domains. We
illustrate our techniques by constructing many existing models from the
literature, and new models that open up ground for further development.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01204</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01208</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preserving Confidentiality in The Gaussian Broadcast Channel Using
  Compute-and-Forward</dc:title>
 <dc:creator>Babaheidarian, Parisa</dc:creator>
 <dc:creator>Salimi, Somayeh</dc:creator>
 <dc:creator>Papadimitratos, Panos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the transmission of confidential messages across a wireless
broadcast channel with K&gt;2 receivers and K helpers. The goal is to transmit all
messages reliably to their intended receivers while keeping them confidential
from the unintended receivers. We design a codebook based on nested lattice
structure, cooperative jamming, lattice alignment, and i.i.d. coding. Moreover,
we exploit the asymmetric compute-and-forward decoding strategy to handle
finite SNR regimes. Unlike previous alignment schemes, our achievable rates are
attainable at any finite SNR value. Also, we show that our scheme achieves the
optimal sum secure degrees of freedom of 1 for the K-receiver Gaussian
broadcast channel with K confidential messages and K helpers.
</dc:description>
 <dc:description>Comment: 6 pages, accepted to CISS 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01210</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EmotioNet Challenge: Recognition of facial expressions of emotion in the
  wild</dc:title>
 <dc:creator>Benitez-Quiroz, C. Fabian</dc:creator>
 <dc:creator>Srinivasan, Ramprakash</dc:creator>
 <dc:creator>Feng, Qianli</dc:creator>
 <dc:creator>Wang, Yan</dc:creator>
 <dc:creator>Martinez, Aleix M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper details the methodology and results of the EmotioNet challenge.
This challenge is the first to test the ability of computer vision algorithms
in the automatic analysis of a large number of images of facial expressions of
emotion in the wild. The challenge was divided into two tracks. The first track
tested the ability of current computer vision algorithms in the automatic
detection of action units (AUs). Specifically, we tested the detection of 11
AUs. The second track tested the algorithms' ability to recognize emotion
categories in images of facial expressions. Specifically, we tested the
recognition of 16 basic and compound emotion categories. The results of the
challenge suggest that current computer vision and machine learning algorithms
are unable to reliably solve these two tasks. The limitations of current
algorithms are more apparent when trying to recognize emotion. We also show
that current algorithms are not affected by mild resolution changes, small
occluders, gender or age, but that 3D pose is a major limiting factor on
performance. We provide an in-depth discussion of the points that need special
attention moving forward.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01212</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Universal Fragment of Presburger Arithmetic with Unary Uninterpreted
  Predicates is Undecidable</dc:title>
 <dc:creator>Horbach, Matthias</dc:creator>
 <dc:creator>Voigt, Marco</dc:creator>
 <dc:creator>Weidenbach, Christoph</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  The first-order theory of addition over the natural numbers, known as
Presburger arithmetic, is decidable in double exponential time. Adding an
uninterpreted unary predicate to the language leads to an undecidable theory.
We sharpen the known boundary between decidable and undecidable in that we show
that the purely universal fragment of the extended theory is already
undecidable. Our proof is based on a reduction of the halting problem for
two-counter machines to unsatisfiability of sentences in the extended language
of Presburger arithmetic that does not use existential quantification. On the
other hand, we argue that a single $\forall\exists$ quantifier alternation
turns the set of satisfiable sentences of the extended language into a
$\Sigma^1_1$-complete set. Some of the mentioned results can be transfered to
the realm of linear arithmetic over the ordered real numbers. This concerns the
undecidability of the purely universal fragment and the $\Sigma^1_1$-hardness
for sentences with at least one quantifier alternation. Finally, we discuss the
relevance of our results to verification. In particular, we derive
undecidability results for quantified fragments of separation logic, the theory
of arrays, and combinations of the theory of equality over uninterpreted
functions with restricted forms of integer arithmetic. In certain cases our
results even imply the absence of sound and complete deductive calculi.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01212</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01218</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Graphical Games from Behavioral Data: Sufficient and Necessary
  Conditions</dc:title>
 <dc:creator>Ghoshal, Asish</dc:creator>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper we obtain sufficient and necessary conditions on the number of
samples required for exact recovery of the pure-strategy Nash equilibria (PSNE)
set of a graphical game from noisy observations of joint actions. We consider
sparse linear influence games --- a parametric class of graphical games with
linear payoffs, and represented by directed graphs of n nodes (players) and
in-degree of at most k. We show that one can efficiently recover the PSNE set
of a linear influence game with $O(k^2 \log n)$ samples, under very general
observation models. On the other hand, we show that $\Omega(k \log n)$ samples
are necessary for any procedure to recover the PSNE set from observations of
joint actions.
</dc:description>
 <dc:description>Comment: Accepted to AISTATS 2017, Florida. arXiv admin note: substantial text
  overlap with arXiv:1607.02959</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01220</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Denoising Adversarial Autoencoders</dc:title>
 <dc:creator>Creswell, Antonia</dc:creator>
 <dc:creator>Bharath, Anil Anthony</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Unsupervised learning is of growing interest because it unlocks the potential
held in vast amounts of unlabelled data to learn useful representations for
inference. Autoencoders, a form of generative model, may be trained by learning
to reconstruct unlabelled input data from a latent representation space. More
robust representations may be produced by an autoencoder if it learns to
recover clean input samples from corrupted ones. Representations may be further
improved by introducing regularisation during training to shape the
distribution of the encoded data in latent space. We suggest denoising
adversarial autoencoders, which combine denoising and regularisation, shaping
the distribution of latent space using adversarial training. We introduce a
novel analysis that shows how denoising may be incorporated into the training
and sampling of adversarial autoencoders. Experiments are performed to assess
the contributions that denoising makes to the learning of representations for
classification and sample synthesis. Our results suggest that autoencoders
trained using a denoising criterion achieve higher classification performance,
and can synthesise samples that are more consistent with the input data than
those trained without a corruption process.
</dc:description>
 <dc:description>Comment: submitted to journal</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01224</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure and Reconfigurable Network Design for Critical Information
  Dissemination in the Internet of Battlefield Things (IoBT)</dc:title>
 <dc:creator>Farooq, Muhammad Junaid</dc:creator>
 <dc:creator>Zhu, Quanyan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Internet of things (IoT) is revolutionizing the management and control of
automated systems leading to a paradigm shift in areas such as smart homes,
smart cities, health care, transportation, etc. The IoT technology is also
envisioned to play an important role in improving the effectiveness of military
operations in battlefields. The interconnection of combat equipment and other
battlefield resources for coordinated automated decisions is referred to as the
Internet of battlefield things (IoBT). IoBT networks are significantly
different from traditional IoT networks due to the battlefield specific
challenges such as the absence of communication infrastructure, and the
susceptibility of devices to cyber and physical attacks. The combat efficiency
and coordinated decision-making in war scenarios depends highly on real-time
data collection, which in turn relies on the connectivity of the network and
the information dissemination in the presence of adversaries. This work aims to
build the theoretical foundations of designing secure and reconfigurable IoBT
networks. Leveraging the theories of stochastic geometry and mathematical
epidemiology, we develop an integrated framework to study the communication of
mission-critical data among different types of network devices and consequently
design the network in a cost effective manner.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01225</identifier>
 <datestamp>2017-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Dynamic Model for Aggressive, Near-Limits Trajectory Planning</dc:title>
 <dc:creator>Altch&#xe9;, Florent</dc:creator>
 <dc:creator>Polack, Philip</dc:creator>
 <dc:creator>de La Fortelle, Arnaud</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In normal on-road situations, autonomous vehicles will be expected to have
smooth trajectories with relatively little demand on the vehicle dynamics to
ensure passenger comfort and driving safety. However, the occurrence of
unexpected events may require vehicles to perform aggressive maneuvers, near
the limits of their dynamic capacities. In order to ensure the occupant's
safety in these situations, the ability to plan controllable but near-limits
trajectories will be of very high importance. One of the main issues in
planning aggressive maneuvers lies in the high complexity of the vehicle
dynamics near the handling limits, which effectively makes state-of-the-art
methods such as Model Predictive Control difficult to use. This article studies
a highly precise model of the vehicle body to derive a simpler, constrained
second-order integrator dynamic model which remains precise even near the
handling limits of the vehicle. Preliminary simulation results indicate that
our model provides better accuracy without increasing computation time compared
to a more classical kinematic bicycle model. The proposed model can find
applications for contingency planning, which may require aggressive maneuvers,
or for trajectory planning at high speed, for instance in racing applications.
</dc:description>
 <dc:description>Comment: Published in the IEEE IV 2017 conference</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-06-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01226</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context Aware Query Image Representation for Particular Object Retrieval</dc:title>
 <dc:creator>Laskar, Zakaria</dc:creator>
 <dc:creator>Kannala, Juho</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  The current models of image representation based on Convolutional Neural
Networks (CNN) have shown tremendous performance in image retrieval. Such
models are inspired by the information flow along the visual pathway in the
human visual cortex. We propose that in the field of particular object
retrieval, the process of extracting CNN representations from query images with
a given region of interest (ROI) can also be modelled by taking inspiration
from human vision. Particularly, we show that by making the CNN pay attention
on the ROI while extracting query image representation leads to significant
improvement over the baseline methods on challenging Oxford5k and Paris6k
datasets. Furthermore, we propose an extension to a recently introduced
encoding method for CNN representations, regional maximum activations of
convolutions (R-MAC). The proposed extension weights the regional
representations using a novel saliency measure prior to aggregation. This leads
to further improvement in retrieval accuracy.
</dc:description>
 <dc:description>Comment: 14 pages, Extended version of a manuscript submitted to SCIA 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01229</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Collaborative Learning for Visual Recognition</dc:title>
 <dc:creator>Wang, Yan</dc:creator>
 <dc:creator>Xie, Lingxi</dc:creator>
 <dc:creator>Zhang, Ya</dc:creator>
 <dc:creator>Zhang, Wenjun</dc:creator>
 <dc:creator>Yuille, Alan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Deep neural networks are playing an important role in state-of-the-art visual
recognition. To represent high-level visual concepts, modern networks are
equipped with large convolutional layers, which use a large number of filters
and contribute significantly to model complexity. For example, more than half
of the weights of AlexNet are stored in the first fully-connected layer (4,096
filters).
  We formulate the function of a convolutional layer as learning a large visual
vocabulary, and propose an alternative way, namely Deep Collaborative Learning
(DCL), to reduce the computational complexity. We replace a convolutional layer
with a two-stage DCL module, in which we first construct a couple of smaller
convolutional layers individually, and then fuse them at each spatial position
to consider feature co-occurrence. In mathematics, DCL can be explained as an
efficient way of learning compositional visual concepts, in which the
vocabulary size increases exponentially while the model complexity only
increases linearly. We evaluate DCL on a wide range of visual recognition
tasks, including a series of multi-digit number classification datasets, and
some generic image classification datasets such as SVHN, CIFAR and ILSVRC2012.
We apply DCL to several state-of-the-art network structures, improving the
recognition accuracy meanwhile reducing the number of parameters (16.82% fewer
in AlexNet).
</dc:description>
 <dc:description>Comment: Submitted to CVPR 2017 (10 pages, 5 figures)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01243</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Augmented Reality for Depth Cues in Monocular Minimally Invasive Surgery</dc:title>
 <dc:creator>Chen, Long</dc:creator>
 <dc:creator>Tang, Wen</dc:creator>
 <dc:creator>John, Nigel W.</dc:creator>
 <dc:creator>Wan, Tao Ruan</dc:creator>
 <dc:creator>Zhang, Jian Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  One of the major challenges in Minimally Invasive Surgery (MIS) such as
laparoscopy is the lack of depth perception. In recent years, laparoscopic
scene tracking and surface reconstruction has been a focus of investigation to
provide rich additional information to aid the surgical process and compensate
for the depth perception issue. However, robust 3D surface reconstruction and
augmented reality with depth perception on the reconstructed scene are yet to
be reported. This paper presents our work in this area. First, we adopt a
state-of-the-art visual simultaneous localization and mapping (SLAM) framework
- ORB-SLAM - and extend the algorithm for use in MIS scenes for reliable
endoscopic camera tracking and salient point mapping. We then develop a robust
global 3D surface reconstruction frame- work based on the sparse point clouds
extracted from the SLAM framework. Our approach is to combine an outlier
removal filter within a Moving Least Squares smoothing algorithm and then
employ Poisson surface reconstruction to obtain smooth surfaces from the
unstructured sparse point cloud. Our proposed method has been quantitatively
evaluated compared with ground-truth camera trajectories and the organ model
surface we used to render the synthetic simulation videos. In vivo laparoscopic
videos used in the tests have demonstrated the robustness and accuracy of our
proposed framework on both camera tracking and surface reconstruction,
illustrating the potential of our algorithm for depth augmentation and
depth-corrected augmented reality in MIS with monocular endoscopes.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01248</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Incident Light Frequency-based Image Defogging Algorithm</dc:title>
 <dc:creator>Zhang, Wenbo</dc:creator>
 <dc:creator>Hou, Xiaorong</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Considering the problem of color distortion caused by the defogging algorithm
based on dark channel prior, an improved algorithm was proposed to calculate
the transmittance of all channels respectively. First, incident light
frequency's effect on the transmittance of various color channels was analyzed
according to the Beer-Lambert's Law, from which a proportion among various
channel transmittances was derived; afterwards, images were preprocessed by
down-sampling to refine transmittance, and then the original size was restored
to enhance the operational efficiency of the algorithm; finally, the
transmittance of all color channels was acquired in accordance with the
proportion, and then the corresponding transmittance was used for image
restoration in each channel. The experimental results show that compared with
the existing algorithm, this improved image defogging algorithm could make
image colors more natural, solve the problem of slightly higher color
saturation caused by the existing algorithm, and shorten the operation time by
four to nine times.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01250</identifier>
 <datestamp>2017-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual vs. Real: Trading Off Simulations and Physical Experiments in
  Reinforcement Learning with Bayesian Optimization</dc:title>
 <dc:creator>Marco, Alonso</dc:creator>
 <dc:creator>Berkenkamp, Felix</dc:creator>
 <dc:creator>Hennig, Philipp</dc:creator>
 <dc:creator>Schoellig, Angela P.</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:creator>Schaal, Stefan</dc:creator>
 <dc:creator>Trimpe, Sebastian</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In practice, the parameters of control policies are often tuned manually.
This is time-consuming and frustrating. Reinforcement learning is a promising
alternative that aims to automate this process, yet often requires too many
experiments to be practical. In this paper, we propose a solution to this
problem by exploiting prior knowledge from simulations, which are readily
available for most robotic platforms. Specifically, we extend Entropy Search, a
Bayesian optimization algorithm that maximizes information gain from each
experiment, to the case of multiple information sources. The result is a
principled way to automatically combine cheap, but inaccurate information from
simulations with expensive and accurate physical experiments in a
cost-effective manner. We apply the resulting method to a cart-pole system,
which confirms that the algorithm can find good control policies with fewer
experiments than standard Bayesian optimization on the physical system only.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, to appear in IEEE 2017 International Conference
  on Robotics and Automation (ICRA)</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01250</dc:identifier>
 <dc:identifier>doi:10.1109/ICRA.2017.7989186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01253</identifier>
 <datestamp>2017-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Machine Learning on Sequential Data Using a Recurrent Weighted Average</dc:title>
 <dc:creator>Ostmeyer, Jared</dc:creator>
 <dc:creator>Cowell, Lindsay</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recurrent Neural Networks (RNN) are a type of statistical model designed to
handle sequential data. The model reads a sequence one symbol at a time. Each
symbol is processed based on information collected from the previous symbols.
With existing RNN architectures, each symbol is processed using only
information from the previous processing step. To overcome this limitation, we
propose a new kind of RNN model that computes a recurrent weighted average
(RWA) over every past processing step. Because the RWA can be computed as a
running average, the computational overhead scales like that of any other RNN
architecture. The approach essentially reformulates the attention mechanism
into a stand-alone model. The performance of the RWA model is assessed on the
variable copy problem, the adding problem, classification of artificial
grammar, classification of sequences by length, and classification of the MNIST
images (where the pixels are read sequentially one at a time). On almost every
task, the RWA model is found to outperform a standard LSTM model.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01253</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01256</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Global Optimization Geometry of Low-Rank Matrix Optimization</dc:title>
 <dc:creator>Zhu, Zhihui</dc:creator>
 <dc:creator>Li, Qiuwei</dc:creator>
 <dc:creator>Tang, Gongguo</dc:creator>
 <dc:creator>Wakin, Michael B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  This paper considers general rank-constrained optimization problems that
minimize a general objective function $f(X)$ over the set of rectangular
$n\times m$ matrices that have rank at most $r$. To tackle the rank constraint
and also to reduce the computational burden, we factorize $X$ into $UV^T$ where
$U$ and $V$ are $n\times r$ and $m\times r$ matrices, respectively, and then
optimize over the small matrices $U$ and $V$. We characterize the global
optimization geometry of the nonconvex factored problem and show that the
corresponding objective function satisfies the robust strict saddle property as
long as the original objective function $f$ satisfies restricted strong
convexity and smoothness properties, ensuring global convergence of many local
search algorithms (such as noisy gradient descent) in polynomial time for
solving the factored problem. We also provide a comprehensive analysis for the
optimization geometry of a matrix factorization problem where we aim to find
$n\times r$ and $m\times r$ matrices $U$ and $V$ such that $UV^T$ approximates
a given matrix $X^\star$. Aside from the robust strict saddle property, we show
that the objective function of the matrix factorization problem has no spurious
local minima and obeys the strict saddle property not only for the
exact-parameterization case where $rank(X^\star) = r$, but also for the
over-parameterization case where $rank(X^\star) &lt; r$ and the
under-parameterization case where $rank(X^\star) &gt; r$. These geometric
properties imply that a number of iterative optimization algorithms (such as
gradient descent) converge to a global solution with random initialization.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2018-01-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01257</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model Checking Cyber-Physical Systems using Particle Swarm Optimization</dc:title>
 <dc:creator>Phan, Dung</dc:creator>
 <dc:creator>Smolka, Scott A.</dc:creator>
 <dc:creator>Grosu, Radu</dc:creator>
 <dc:creator>Mehmood, Usama</dc:creator>
 <dc:creator>Stoller, Scott D.</dc:creator>
 <dc:creator>Yang, Junxing</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a novel approach to the problem of model checking cyber-physical
systems. We transform the model checking problem to an optimization one by
designing an objective function that measures how close a state is to a
violation of a property. We use particle swarm optimization (PSO) to
effectively search for a state that minimizes the objective function. Such
states, if found, are counter-examples describing safe states from which the
system can reach an unsafe state in one time step. We illustrate our approach
with a controller for the Quickbot ground rover. Our PSO model checker quickly
found a bug in the controller that could cause the rover to collide with an
obstacle.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01257</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01260</identifier>
 <datestamp>2017-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EX2: Exploration with Exemplar Models for Deep Reinforcement Learning</dc:title>
 <dc:creator>Fu, Justin</dc:creator>
 <dc:creator>Co-Reyes, John D.</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Deep reinforcement learning algorithms have been shown to learn complex tasks
using highly general policy classes. However, sparse reward problems remain a
significant challenge. Exploration methods based on novelty detection have been
particularly successful in such settings but typically require generative or
predictive models of the observations, which can be difficult to train when the
observations are very high-dimensional and complex, as in the case of raw
images. We propose a novelty detection algorithm for exploration that is based
entirely on discriminatively trained exemplar models, where classifiers are
trained to discriminate each visited state against all others. Intuitively,
novel states are easier to distinguish against other states seen during
training. We show that this kind of discriminative modeling corresponds to
implicit density estimation, and that it can be combined with count-based
exploration to produce competitive results on a range of popular benchmark
tasks, including state-of-the-art results on challenging egocentric
observations in the vizDoom benchmark.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01261</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Percentile Policies for Tracking of Markovian Random Processes with
  Asymmetric Cost and Observation</dc:title>
 <dc:creator>Mansourifard, Parisa</dc:creator>
 <dc:creator>Javidi, Tara</dc:creator>
 <dc:creator>Krishnamachari, Bhaskar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by wide-ranging applications such as video delivery over networks
using Multiple Description Codes, congestion control, and inventory management,
we study the state-tracking of a Markovian random process with a known
transition matrix and a finite ordered state set. The decision-maker must
select a state as an action at each time step to minimize the total expected
cost. The decision-maker is faced with asymmetries both in cost and
observation: in case the selected state is less than the actual state of the
Markovian process, an under-utilization cost occurs and only partial
observation about the actual state is revealed; otherwise, the decision incurs
an over-utilization cost and reveals full information about the actual state.
We can formulate this problem as a Partially Observable Markov Decision Process
which can be expressed as a dynamic program based on the last full observed
state and the time of full observation. This formulation determines the
sequence of actions to be taken between any two consecutive full observations
of the actual state. However, this DP grows exponentially in the number of
states, with little hope for a computationally feasible solution. We present an
interesting class of computationally tractable policies with a percentile
structure. A generalization of binary search, this class of policies attempt at
any given time to reduce the uncertainty by a given percentage. Among all
percentile policies, we search for the one with the minimum expected cost. The
result of this search is a heuristic policy which we evaluate through numerical
simulations. We show that it outperforms the myopic policies and under some
conditions performs close to the optimal policies. Furthermore, we derive a
lower bound on the cost of the optimal policy which can be computed with low
complexity and give a measure for how close our heuristic policy is to the
optimal policy.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01267</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On squares of cyclic codes</dc:title>
 <dc:creator>Cascudo, Ignacio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The square $C^{*2}$ of a linear error correcting code $C$ is the linear code
spanned by the component-wise products of every pair of (non-necessarily
distinct) words in $C$. Squares of codes have gained attention for several
applications mainly in the area of cryptography, and typically in those
applications one is concerned about some of the parameters (dimension, minimum
distance) of both $C^{*2}$ and $C$. In this paper, motivated mostly by the
study of this problem in the case of linear codes defined over the binary
field, squares of cyclic codes are considered. General results on the minimum
distance of the squares of cyclic codes are obtained and constructions of
cyclic codes $C$ with relatively large dimension of $C$ and minimum distance of
the square $C^{*2}$ are discussed. In some cases, the constructions lead to
codes $C$ such that both $C$ and $C^{*2}$ simultaneously have the largest
possible minimum distances for their length and dimensions.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01270</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Baxter's Homunculus: Virtual Reality Spaces for Teleoperation in
  Manufacturing</dc:title>
 <dc:creator>Lipton, Jeffrey I</dc:creator>
 <dc:creator>Fay, Aidan J</dc:creator>
 <dc:creator>Rus, Daniela</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Expensive specialized systems have hampered development of telerobotic
systems for manufacturing systems. In this paper we demonstrate a telerobotic
system which can reduce the cost of such system by leveraging commercial
virtual reality(VR) technology and integrating it with existing robotics
control software. The system runs on a commercial gaming engine using off the
shelf VR hardware. This system can be deployed on multiple network
architectures from a wired local network to a wireless network connection over
the Internet. The system is based on the homunculus model of mind wherein we
embed the user in a virtual reality control room. The control room allows for
multiple sensor display, dynamic mapping between the user and robot, does not
require the production of duals for the robot, or its environment. The control
room is mapped to a space inside the robot to provide a sense of co-location
within the robot. We compared our system with state of the art automation
algorithms for assembly tasks, showing a 100% success rate for our system
compared with a 66% success rate for automated systems. We demonstrate that our
system can be used for pick and place, assembly, and manufacturing tasks.
</dc:description>
 <dc:description>Comment: 8 pages 6 figures, submitted to IROS 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01274</identifier>
 <datestamp>2017-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Actor-Critic Reinforcement Learning with Simultaneous Human Control and
  Feedback</dc:title>
 <dc:creator>Mathewson, Kory W.</dc:creator>
 <dc:creator>Pilarski, Patrick M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper contributes a first study into how different human users deliver
simultaneous control and feedback signals during human-robot interaction. As
part of this work, we formalize and present a general interactive learning
framework for online cooperation between humans and reinforcement learning
agents. In many human-machine interaction settings, there is a growing gap
between the degrees-of-freedom of complex semi-autonomous systems and the
number of human control channels. Simple human control and feedback mechanisms
are required to close this gap and allow for better collaboration between
humans and machines on complex tasks. To better inform the design of concurrent
control and feedback interfaces, we present experimental results from a
human-robot collaborative domain wherein the human must simultaneously deliver
both control and feedback signals to interactively train an actor-critic
reinforcement learning robot. We compare three experimental conditions: 1)
human delivered control signals, 2) reward-shaping feedback signals, and 3)
simultaneous control and feedback. Our results suggest that subjects provide
less feedback when simultaneously delivering feedback and control signals and
that control signal quality is not significantly diminished. Our data suggest
that subjects may also modify when and how they provide feedback. Through
algorithmic development and tuning informed by this study, we expect
semi-autonomous actions of robotic agents can be better shaped by human
feedback, allowing for seamless collaboration and improved performance in
difficult interactive domains.
</dc:description>
 <dc:description>Comment: 10 pages, 2 pages of references, 8 figures. Under review for the 34th
  International Conference on Machine Learning, Sydney, Australia, 2017.
  Copyright 2017 by the authors</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01274</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01279</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink Cellular Network Analysis with LOS/NLOS Propagation and
  Elevated Base Stations</dc:title>
 <dc:creator>Atzeni, Italo</dc:creator>
 <dc:creator>Arnau, Jes&#xfa;s</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we investigate the downlink performance of dense cellular
networks with elevated base stations (BSs) using a channel model that
incorporates line-of-sight (LOS)/non-line-of-sight (NLOS) propagation in both
small-scale and large-scale fading. Modeling LOS fading with Nakagami-$m$
fading, we provide a unified framework based on stochastic geometry that
encompasses both closest and strongest BS association. Our study is
particularized to two distance-dependent LOS/NLOS models of practical interest.
Considering the effect of LOS propagation alone, we derive closed-form
expressions for the coverage probability with Nakagami-$m$ fading, showing that
the performance for strongest BS association is the same as in the case of
Rayleigh fading, whereas for closest BS association it monotonically increases
with the shape parameter $m$. Then, focusing on the effect of elevated BSs, we
show that network densification eventually leads to near-universal outage even
for moderately low BS densities: in particular, the maximum area spectral
efficiency is proportional to the inverse of the squared BS height.
</dc:description>
 <dc:description>Comment: Submitted to the IEEE for possible publication</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01281</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Extended Consideration of Joint Exploration and Tracking: JET</dc:title>
 <dc:creator>Ivanov, Alexander</dc:creator>
 <dc:creator>Campbell, Mark</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Autonomous exploration and multi-object tracking by a team of agents have
traditionally been considered as two separate, yet related, problems which are
usually solved in two phases: an exploration phase then a tracking phase. The
exploration problem is usually viewed through an information theoretic
framework where a robotic agent attempts to gather as much information about
the environment or an Object of Interest (OI). Conversely, the tracking problem
attempts to maintain precise location information about an OI over time. This
work proposes a single framework which enables the multi-robot multi-object
problem to be solved simultaneously. A hierarchical architecture is used to
coordinate robotic agents in the tracking of multiple OIs while simultaneously
allowing the task to remain computationally efficient. The primary
contributions of this work are a probabilistic constraint on the tracked OIs'
covariances guarantees tracking performance throughout the entire mission. The
automatic discovery of new OIs, a seamless transition to guaranteed tracking of
discovered OIs, and the automatic balancing of exploration with the
requirements of tracking.
</dc:description>
 <dc:description>Comment: 12 pages, 4 figures, extended conference/journal</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01284</identifier>
 <datestamp>2017-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investcoin: A System for Privacy-Preserving Investments</dc:title>
 <dc:creator>Valovich, Filipp</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This work presents a new framework for Privacy-Preserving Investment systems
in a distributed model. In this model, independent investors can transfer funds
to independent projects, in the same way as it works on crowdfunding platforms.
The framework protects the investors' single payments from being detected (by
any other party), only the sums of each investor's payments are revealed.
Likewise, the projects' single incoming payments are concealed and only the
final sums of the incoming payments for every project are revealed. In this
way, no other party than the investor (not even the system administration) can
detect how much she paid to any single project. Though it is still possible to
confidentially exchange any part of an investment between any pair of
investors, such that market liquidity is unaffected by the system. On top, our
framework allows a privacy-preserving return of a multiple of all the held
investments (e.g. interest payments or dividends) to the indivdual investors
while still revealing nothing else than the sum of all returns for every
investor. We provide reasonable security guarantees for this framework that are
based on common notions from the Secure Multi-Party Computation literature. As
instantiation for this framework we present Investcoin. It is a proper
combination of three cryptographic protocols, namely a Private Stream
Aggregation scheme, a Commitment scheme and a Range test and it is usable in
connection with any existing currency. The security of these protocols is based
on the DDH assumption. By a composition theorem from the SMPC literature, the
security of the resulting Investcoin protocol is also based on the DDH
assumption. Furthermore, we provide a simple decentralised key generation
protocol for Investcoin supporting dynamic join/leave and fault-tolarance of
investors and moreover achieves some security guarantees against malicious
investors.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01284</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01286</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Layered Architecture for Erasure-Coded Consistent Distributed Storage</dc:title>
 <dc:creator>Konwar, Kishori M.</dc:creator>
 <dc:creator>Prakash, N.</dc:creator>
 <dc:creator>Lynch, Nancy</dc:creator>
 <dc:creator>Medard, Muriel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Motivated by emerging applications to the edge computing paradigm, we
introduce a two-layer erasure-coded fault-tolerant distributed storage system
offering atomic access for read and write operations. In edge computing,
clients interact with an edge-layer of servers that is geographically near; the
edge-layer in turn interacts with a back-end layer of servers. The edge-layer
provides low latency access and temporary storage for client operations, and
uses the back-end layer for persistent storage. Our algorithm, termed Layered
Data Storage (LDS) algorithm, offers several features suitable for
edge-computing systems, works under asynchronous message-passing environments,
supports multiple readers and writers, and can tolerate $f_1 &lt; n_1/2$ and $f_2
&lt; n_2/3$ crash failures in the two layers having $n_1$ and $n_2$ servers,
respectively. We use a class of erasure codes known as regenerating codes for
storage of data in the back-end layer. The choice of regenerating codes,
instead of popular choices like Reed-Solomon codes, not only optimizes the cost
of back-end storage, but also helps in optimizing communication cost of read
operations, when the value needs to be recreated all the way from the back-end.
The two-layer architecture permits a modular implementation of atomicity and
erasure-code protocols; the implementation of erasure-codes is mostly limited
to interaction between the two layers. We prove liveness and atomicity of LDS,
and also compute performance costs associated with read and write operations.
Further, in a multi-object system running $N$ independent instances of LDS,
where only a small fraction of the objects undergo concurrent accesses at any
point during the execution, the overall storage cost is dominated by that of
persistent storage in the back-end layer, and is given by $\Theta(N)$.
</dc:description>
 <dc:description>Comment: To appear in ACM PODC 2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01287</identifier>
 <datestamp>2017-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the MISO Channel with Feedback: Can Infinitely Massive Antennas
  Achieve Infinite Capacity?</dc:title>
 <dc:creator>Chen, Jinyuan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider communication over a multiple-input single-output (MISO) block
fading channel in the presence of an independent noiseless feedback link. We
assume that the transmitter and receiver have no prior knowledge of the channel
state realizations, but the transmitter and receiver can acquire the channel
state information (CSIT/CSIR) via downlink training and feedback. For this
channel, we show that increasing the number of transmit antennas to infinity
will not achieve an infinite capacity, for a finite channel coherence and a
finite input constraint on the second or fourth moment. This insight follows
from our new capacity bounds that hold for any linear and nonlinear coding
strategies, and any channel training schemes. In addition to the channel
capacity bounds, we also provide a characterization on the beamforming gain
that is also known as array gain or power gain, at the regime with large number
of antennas.
</dc:description>
 <dc:description>Comment: The conjecture stated in the previous version has been solved in this
  new version. This work will be presented in part at ISIT2017</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:date>2017-05-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1703.01288</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Intensionality, Intensional Recursion, and the G\&quot;odel-L\&quot;ob axiom</dc:title>
 <dc:creator>Kavvos, G. A.</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The use of a necessity-like modality in a typed $\lambda$-calculus can be
used as a device for separating the calculus in two separate regions. These can
be thought of as intensional vs. extensional data: data in the first region,
the modal one, are available as code, and their description can be examined,
whereas data in the second region are only available as values up to ordinary
equality. This allows us to add seemingly non-functional operations at modal
types, whilst maintaining consistency. In this setting the G\&quot;odel-L\&quot;ob axiom
acquires a novel constructive reading: it affords the programmer the
possibility of a very strong kind of recursion, by enabling him to write
programs that have access to their own code. This is a type of computational
reflection that is strongly reminiscent of Kleene's Second Recursion Theorem.
We prove that it is consistent with the rest of the system.
</dc:description>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1703.01288</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="117000" completeListSize="155308">2369777|118001</resumptionToken>
</ListRecords>
</OAI-PMH>
