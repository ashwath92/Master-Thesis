<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2018-01-29T03:03:23Z</responseDate>
<request verb="ListRecords" resumptionToken="2369777|91001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07233</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Drug Interactions and Mutagenicity with Ensemble Classifiers
  on Subgraphs of Molecules</dc:title>
 <dc:creator>Schaumberg, Andrew</dc:creator>
 <dc:creator>Yu, Angela</dc:creator>
 <dc:creator>Koshi, Tatsuhiro</dc:creator>
 <dc:creator>Zong, Xiaochan</dc:creator>
 <dc:creator>Rayadhurgam, Santoshkalyan</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>I.2.1</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  In this study, we intend to solve a mutual information problem in interacting
molecules of any type, such as proteins, nucleic acids, and small molecules.
Using machine learning techniques, we accurately predict pairwise interactions,
which can be of medical and biological importance. Graphs are are useful in
this problem for their generality to all types of molecules, due to the
inherent association of atoms through atomic bonds. Subgraphs can represent
different molecular domains. These domains can be biologically significant as
most molecules only have portions that are of functional significance and can
interact with other domains. Thus, we use subgraphs as features in different
machine learning algorithms to predict if two drugs interact and predict
potential single molecule effects.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07233</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07239</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis based on Density Evolution on Fault Erasure Belief
  Propagation Decoder</dc:title>
 <dc:creator>Mori, Hiroki</dc:creator>
 <dc:creator>Wadayama, Tadashi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we will present an analysis on the fault erasure BP decoders
based on the density evolution. In the fault BP decoder, messages exchanged in
a BP process are stochastically corrupted due to unreliable logic gates and
flip-flops; i.e., we assume circuit components with transient faults. We
derived a set of the density evolution equations for the fault erasure BP
processes. Our density evolution analysis reveals the asymptotic behaviors of
the estimation error probability of the fault erasure BP decoders. In contrast
to the fault free cases, it is observed that the error probabilities of the
fault erasure BP decoder converge to positive values, and that there exists a
discontinuity in an error curve corresponding to the fault BP threshold. It is
also shown that an message encoding technique provides higher fault BP
thresholds than those of the original decoders at the cost of increased circuit
size.
</dc:description>
 <dc:description>Comment: 12 pages, submitted to ISIT 2016</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07239</dc:identifier>
 <dc:identifier>doi:10.1587/transfun.E99.A.2155</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07241</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Discovery In GIS Data</dc:title>
 <dc:creator>Taha, Ayman</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Intelligent geographic information system (IGIS) is one of the promising
topics in GIS field. It aims at making GIS tools more sensitive for large
volumes of data stored inside GIS systems by integrating GIS with other
computer sciences such as Expert system (ES) Data Warehouse (DW), Decision
Support System (DSS), or Knowledge Discovery Database (KDD). One of the main
branches of IGIS is the Geographic Knowledge Discovery (GKD) which tries to
discover the implicit knowledge in the spatial databases. The main difference
between traditional KDD techniques and GKD techniques is hidden in the nature
of spatial data sets. In other words in the traditional data set the values of
each object are supposed to be independent from other objects in the same data
set, whereas the spatial dataset tends to be highly correlated according to the
first law of geography. The spatial outlier detection is one of the most
popular spatial data mining techniques which is used to detect spatial objects
whose non-spatial attributes values are extremely different from those of their
neighboring objects. Analyzing the behavior of these objects may produce an
interesting knowledge, which has an effective role in the decision-making
process. In this thesis, a new definition for the spatial neighborhood
relationship by is proposed considering the weights of the most effective
parameters of neighboring objects in a given spatial dataset. The spatial
parameters taken into our consideration are; distance, cost, and number of
direct connections between neighboring objects. A new model to detect spatial
outliers is also presented based on the new definition of the spatial
neighborhood relationship. This model is adapted to be applied to polygonal
objects. The proposed model is applied to an existing project for supporting
literacy in Fayoum governorate in Arab Republic of Egypt (ARE).
</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07243</identifier>
 <datestamp>2017-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Sample Complexity of Learning Graphical Games</dc:title>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We analyze the sample complexity of learning graphical games from purely
behavioral data. We assume that we can only observe the players' joint actions
and not their payoffs. We analyze the sufficient and necessary number of
samples for the correct recovery of the set of pure-strategy Nash equilibria
(PSNE) of the true game. Our analysis focuses on directed graphs with $n$ nodes
and at most $k$ parents per node. Sparse graphs correspond to ${k \in O(1)}$
with respect to $n$, while dense graphs correspond to ${k \in O(n)}$. By using
VC dimension arguments, we show that if the number of samples is greater than
${O(k n \log^2{n})}$ for sparse graphs or ${O(n^2 \log{n})}$ for dense graphs,
then maximum likelihood estimation correctly recovers the PSNE with high
probability. By using information-theoretic arguments, we show that if the
number of samples is less than ${\Omega(k n \log^2{n})}$ for sparse graphs or
${\Omega(n^2 \log{n})}$ for dense graphs, then any conceivable method fails to
recover the PSNE with arbitrary probability.
</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:date>2017-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07250</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Living Innovation Laboratory Model Design and Implementation</dc:title>
 <dc:creator>Zheng, Yuting</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Living Innovation Laboratory (LIL) is an open and recyclable way for
multidisciplinary researchers to remote control resources and co-develop user
centered projects. In the past few years, there were several papers about LIL
published and trying to discuss and define the model and architecture of LIL.
People all acknowledge about the three characteristics of LIL: user centered,
co-creation, and context aware, which make it distinguished from test platform
and other innovation approaches. Its existing model consists of five phases:
initialization, preparation, formation, development, and evaluation.
  Goal Net is a goal-oriented methodology to formularize a progress. In this
thesis, Goal Net is adopted to subtract a detailed and systemic methodology for
LIL. LIL Goal Net Model breaks the five phases of LIL into more detailed steps.
Big data, crowd sourcing, crowd funding and crowd testing take place in
suitable steps to realize UUI, MCC and PCA throughout the innovation process in
LIL 2.0. It would become a guideline for any company or organization to develop
a project in the form of an LIL 2.0 project.
  To prove the feasibility of LIL Goal Net Model, it was applied to two real
cases. One project is a Kinect game and the other one is an Internet product.
They were both transformed to LIL 2.0 successfully, based on LIL goal net based
methodology. The two projects were evaluated by phenomenography, which was a
qualitative research method to study human experiences and their relations in
hope of finding the better way to improve human experiences. Through
phenomenographic study, the positive evaluation results showed that the new
generation of LIL had more advantages in terms of effectiveness and efficiency.
</dc:description>
 <dc:description>Comment: This is a book draft</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07252</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Font Identification in Historical Documents Using Active Learning</dc:title>
 <dc:creator>Gupta, Anshul</dc:creator>
 <dc:creator>Gutierrez-Osuna, Ricardo</dc:creator>
 <dc:creator>Christy, Matthew</dc:creator>
 <dc:creator>Furuta, Richard</dc:creator>
 <dc:creator>Mandell, Laura</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.2</dc:subject>
 <dc:description>  Identifying the type of font (e.g., Roman, Blackletter) used in historical
documents can help optical character recognition (OCR) systems produce more
accurate text transcriptions. Towards this end, we present an active-learning
strategy that can significantly reduce the number of labeled samples needed to
train a font classifier. Our approach extracts image-based features that
exploit geometric differences between fonts at the word level, and combines
them into a bag-of-word representation for each page in a document. We evaluate
six sampling strategies based on uncertainty, dissimilarity and diversity
criteria, and test them on a database containing over 3,000 historical
documents with Blackletter, Roman and Mixed fonts. Our results show that a
combination of uncertainty and diversity achieves the highest predictive
accuracy (89% of test cases correctly classified) while requiring only a small
fraction of the data (17%) to be labeled. We discuss the implications of this
result for mass digitization projects of historical documents.
</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07252</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07254</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Target Localization using Low-Rank Matrix Completion and Unimodal
  Regression</dc:title>
 <dc:creator>Choudhary, Sunav</dc:creator>
 <dc:creator>Kumar, Naveen</dc:creator>
 <dc:creator>Narayanan, Srikanth</dc:creator>
 <dc:creator>Mitra, Urbashi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The detection and localization of a target from samples of its generated
field is a problem of interest in a broad range of applications. Often, the
target field admits structural properties that enable the design of lower
sample detection strategies with good performance. This paper designs a
sampling and localization strategy which exploits separability and unimodality
in target fields and theoretically analyzes the trade-off achieved between
sampling density, noise level and convergence rate of localization. In
particular, the strategy adopts an exploration-exploitation approach to target
detection and utilizes the theory of low-rank matrix completion, coupled with
unimodal regression, on decaying and approximately separable target fields. The
assumptions on the field are fairly generic and are applicable to many decay
profiles since no specific knowledge of the field is necessary, besides its
admittance of an approximately rank-one representation. Extensive numerical
experiments and comparisons are performed to test the efficacy and robustness
of the presented approach. Numerical results suggest that the proposed strategy
outperforms algorithms based on mean-shift clustering, surface interpolation
and naive low-rank matrix completion with peak detection, under low sampling
density.
</dc:description>
 <dc:description>Comment: 24 pages, 10 figures</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07254</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07255</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PersonNet: Person Re-identification with Deep Convolutional Neural
  Networks</dc:title>
 <dc:creator>Wu, Lin</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Hengel, Anton van den</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a deep end-to-end neu- ral network to
simultaneously learn high-level features and a corresponding similarity metric
for person re-identification. The network takes a pair of raw RGB images as
input, and outputs a similarity value indicating whether the two input images
depict the same person. A layer of computing neighborhood range differences
across two input images is employed to capture local relationship between
patches. This operation is to seek a robust feature from input images. By
increasing the depth to 10 weight layers and using very small (3$\times$3)
convolution filters, our architecture achieves a remarkable improvement on the
prior-art configurations. Meanwhile, an adaptive Root- Mean-Square (RMSProp)
gradient decent algorithm is integrated into our architecture, which is
beneficial to deep nets. Our method consistently outperforms state-of-the-art
on two large datasets (CUHK03 and Market-1501), and a medium-sized data set
(CUHK01).
</dc:description>
 <dc:description>Comment: 7 pages. Fixed Figure 4 (a)</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:date>2016-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07258</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Integral Image Estimation at 1% measurement rate</dc:title>
 <dc:creator>Kulkarni, Kuldeep</dc:creator>
 <dc:creator>Turaga, Pavan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We propose a framework called ReFInE to directly obtain integral image
estimates from a very small number of spatially multiplexed measurements of the
scene without iterative reconstruction of any auxiliary image, and demonstrate
their practical utility in visual object tracking. Specifically, we design
measurement matrices which are tailored to facilitate extremely fast estimation
of the integral image, by using a single-shot linear operation on the measured
vector. Leveraging a prior model for the images, we formulate a nuclear norm
minimization problem with second order conic constraints to jointly obtain the
measurement matrix and the linear operator. Through qualitative and
quantitative experiments, we show that high quality integral image estimates
can be obtained using our framework at very low measurement rates. Further, on
a standard dataset of 50 videos, we present object tracking results which are
comparable to the state-of-the-art methods, even at an extremely low
measurement rate of 1%.
</dc:description>
 <dc:description>Comment: Submitted to TPAMI</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07260</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quiver: Using Control Perturbations to Increase the Observability of
  Sensor Data in Smart Buildings</dc:title>
 <dc:creator>Koh, Jason</dc:creator>
 <dc:creator>Balaji, Bharathan</dc:creator>
 <dc:creator>Akhlaghi, Vahideh</dc:creator>
 <dc:creator>Agarwal, Yuvraj</dc:creator>
 <dc:creator>Gupta, Rajesh</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Modern buildings consist of hundreds of sensors and actuators for monitoring
and operation of systems such as HVAC, light and security. To enable portable
applications in next generation smart buildings, we need models and
standardized ontologies that represent these sensors across diverse types of
buildings. Recent research has shown that extracting information such as sensor
type with available metadata and timeseries data analysis is difficult due to
heterogeneity of systems and lack of support for interoperability. We propose
perturbations in the control system as a mechanism to increase the
observability of building systems to extract contextual information and develop
standardized models. We design Quiver, an experimental framework for actuation
of building HVAC system that enables us to perturb the control system safely.
Using Quiver, we demonstrate three applications using empirical experiments on
a real commercial building: colocation of data points, identification of point
type and mapping of dependency between actuators. Our results show that we can
colocate data points in HVAC terminal units with 98.4 % accuracy and 63 %
coverage. We can identify point types of the terminal units with 85.3 %
accuracy. Finally, we map the dependency links between actuators with an
accuracy of 73.5 %, with 8.1 % and 18.4 % false positives and false negatives
respectively.
</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07262</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting copy-move forgery detection by considering realistic image
  with similar but genuine objects</dc:title>
 <dc:creator>Zhu, Ye</dc:creator>
 <dc:creator>Ng, Tian-Tsong</dc:creator>
 <dc:creator>Shen, Xuanjing</dc:creator>
 <dc:creator>Wen, Bihan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Many images, of natural or man-made scenes often contain Similar but Genuine
Objects (SGO). This poses a challenge to existing Copy-Move Forgery Detection
(CMFD) methods which match the key points / blocks, solely based on the pair
similarity in the scene. To address such issue, we propose a novel CMFD method
using Scaled Harris Feature Descriptors (SHFD) that preform consistently well
on forged images with SGO. It involves the following main steps: (i) Pyramid
scale space and orientation assignment are used to keep scaling and rotation
invariance; (ii) Combined features are applied for precise texture description;
(iii) Similar features of two points are matched and RANSAC is used to remove
the false matches. The experimental results indicate that the proposed
algorithm is effective in detecting SGO and copy-move forgery, which compares
favorably to existing methods. Our method exhibits high robustness even when an
image is operated by geometric transformation and post-processing
</dc:description>
 <dc:description>Comment: The version of ICASSP2016 submission</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07264</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Persuasive Teachable Agent for Intergenerational Learning</dc:title>
 <dc:creator>Lim, Su Fang</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Teachable agents are computer agents based on the pedagogical concept of
learning-by-teaching. During the tutoring process, where students take on the
role of the tutor to teach a computer agent tutee, learners have been observed
to gain deeper understanding of the subject matter. Teachable agents are
commonly used in the areas of science and mathematics learning where learners
are able to learn complex concepts and deep reasoning by teaching the teachable
agent through graphic representation such as concept maps.
  Literature review on teachable agents as well as observations during field
studies conducted by the researcher, have shown that many current teachable
agents lack the interaction abilities required to keep learners engage in
learning tasks. The result of this is learners deviating from the teaching
process, and thus the learners are unable to benefit fully from learning with
the teachable agent. The applications of teachable agents are restricted to the
learning of academic subjects such as mathematics and science.
  In this book, we have proposed the Persuasive Teachable Agent (PTA), a
teachable agent based on the theoretical framework of persuasion, computational
and goal-oriented agent modelling. We argue that the PTA, an autonomous agent,
capable of encouraging attitude and behavioural change can offer a more
meaningful and engaging learning experiences for learners from different age
groups. Based on the findings from our research we argue that persuasive
feedback actions generated by the PTA provide significant influence over
learner's decision to participate in intergenerational learning. The PTA plays
a crucial role in the development of future persuasive technologies in
artificially intelligent agents.
</dc:description>
 <dc:description>Comment: This is a book draft</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07265</identifier>
 <datestamp>2016-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Driven Visual Path Prediction from a Single Image</dc:title>
 <dc:creator>Huang, Siyu</dc:creator>
 <dc:creator>Li, Xi</dc:creator>
 <dc:creator>Zhang, Zhongfei</dc:creator>
 <dc:creator>He, Zhouzhou</dc:creator>
 <dc:creator>Wu, Fei</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Tang, Jinhui</dc:creator>
 <dc:creator>Zhuang, Yueting</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Capabilities of inference and prediction are significant components of visual
systems. In this paper, we address an important and challenging task of them:
visual path prediction. Its goal is to infer the future path for a visual
object in a static scene. This task is complicated as it needs high-level
semantic understandings of both the scenes and motion patterns underlying video
sequences. In practice, cluttered situations have also raised higher demands on
the effectiveness and robustness of the considered models. Motivated by these
observations, we propose a deep learning framework which simultaneously
performs deep feature learning for visual representation in conjunction with
spatio-temporal context modeling. After that, we propose a unified path
planning scheme to make accurate future path prediction based on the analytic
results of the context models. The highly effective visual representation and
deep context models ensure that our framework makes a deep semantic
understanding of the scene and motion pattern, consequently improving the
performance of the visual path prediction task. In order to comprehensively
evaluate the model's performance on the visual path prediction task, we
construct two large benchmark datasets from the adaptation of video tracking
datasets. The qualitative and quantitative experimental results show that our
approach outperforms the existing approaches and owns a better generalization
capability.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07265</dc:identifier>
 <dc:identifier>IEEE Transactions on Image Processing, vol. 25, no. 12, pp.
  5892-5904, Dec. 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2613686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07267</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolutionary stability implies asymptotic stability under multiplicative
  weights</dc:title>
 <dc:creator>Avramopoulos, Ioannis</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We show that evolutionarily stable states in general (nonlinear) population
games (which can be viewed as continuous vector fields constrained on a
polytope) are asymptotically stable under a multiplicative weights dynamic
(under appropriate choices of a parameter called the learning rate or step
size, which we demonstrate to be crucial to achieve convergence, as otherwise
even chaotic behavior is possible to manifest). Our result implies that
evolutionary theories based on multiplicative weights are compatible (in
principle, more general) with those based on the notion of evolutionary
stability. However, our result further establishes multiplicative weights as a
nonlinear programming primitive (on par with standard nonlinear programming
methods) since various nonlinear optimization problems, such as finding
Nash/Wardrop equilibria in nonatomic congestion games, which are well-known to
be equipped with a convex potential function, and finding strict local maxima
of quadratic programming problems, are special cases of the problem of
computing evolutionarily stable states in nonlinear population games.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07267</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07270</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comprehensive Feature-based Robust Video Fingerprinting Using Tensor
  Model</dc:title>
 <dc:creator>Nie, Xiushan</dc:creator>
 <dc:creator>Yin, Yilong</dc:creator>
 <dc:creator>Sun, Jiande</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Content-based near-duplicate video detection (NDVD) is essential for
effective search and retrieval, and robust video fingerprinting is a good
solution for NDVD. Most existing video fingerprinting methods use a single
feature or concatenating different features to generate video fingerprints, and
show a good performance under single-mode modifications such as noise addition
and blurring. However, when they suffer combined modifications, the performance
is degraded to a certain extent because such features cannot characterize the
video content completely. By contrast, the assistance and consensus among
different features can improve the performance of video fingerprinting.
Therefore, in the present study, we mine the assistance and consensus among
different features based on tensor model, and present a new comprehensive
feature to fully use them in the proposed video fingerprinting framework. We
also analyze what the comprehensive feature really is for representing the
original video. In this framework, the video is initially set as a high-order
tensor that consists of different features, and the video tensor is decomposed
via the Tucker model with a solution that determines the number of components.
Subsequently, the comprehensive feature is generated by the low-order tensor
obtained from tensor decomposition. Finally, the video fingerprint is computed
using this feature. A matching strategy used for narrowing the search is also
proposed based on the core tensor. The robust video fingerprinting framework is
resistant not only to single-mode modifications, but also to the combination of
them.
</dc:description>
 <dc:description>Comment: 13pages</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07270</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07273</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Method to Support Difficult Re-finding Tasks</dc:title>
 <dc:creator>Liu, Gangli</dc:creator>
 <dc:creator>Feng, Ling</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  Re-finding electronic documents from a personal computer is a frequent demand
to users. In a simple re-finding task, people can use many methods to retrieve
a document, such as navigating directly to the document's folder, searching
with a desktop search engine, or checking the Recent Files List. However, when
encountering a difficult re-finding task, people usually cannot remember the
attributes used by conventional re-finding methods, such as file path, file
name, keywords etc., the re-finding would fail. We propose a new method to
support difficult re-finding tasks. When a user is reading a document, we
collect all kinds of possible memory pieces of the user about the document,
such as number of pages, number of images, number of math formulas, cumulative
reading time, reading frequency, printing experiences etc. If the user wants to
re-find a document later, we use these collected attributes to filter out the
target document. To alleviate the user's cognitive burden, we use a question
and answer wizard interface and provide recommendations to the answers for the
user, the recommendations are generated by analyzing the collected attributes
of each document and the user's experiences about them.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07275</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Power Distribution Control for a Network of Fuel Cell Stacks</dc:title>
 <dc:creator>P, Resmi Suresh M</dc:creator>
 <dc:creator>Sankaran, Ganesh</dc:creator>
 <dc:creator>Joopudi, Sreeram</dc:creator>
 <dc:creator>Narasimhan, Shankar</dc:creator>
 <dc:creator>Choudhury, Suman Roy</dc:creator>
 <dc:creator>Rengaswamy, Raghunathan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In power networks where multiple fuel cell stacks are employed to deliver the
required power, optimal sharing of the power demand between different stacks is
an important problem. This is because the total current collectively produced
by all the stacks is directly proportional to the fuel utilization, through
stoichiometry. As a result, one would like to produce the required power while
minimizing the total current produced. In this paper, an optimization
formulation is proposed for this power distribution control problem. An
algorithm that identifies the globally optimal solution for this problem is
developed. Through an analysis of the KKT conditions, the solution to the
optimization problem is decomposed into on-line and on-line computations. The
on-line computations reduce to simple equation solving. For an application with
a specific v-i function derived from data, we show that analytical solutions
exist for on-line computations. We also discuss the wider applicability of the
proposed approach for similar problems in other domains.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07279</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Myopic Policy Bounds for Information Acquisition POMDPs</dc:title>
 <dc:creator>Lauri, Mikko</dc:creator>
 <dc:creator>Atanasov, Nikolay</dc:creator>
 <dc:creator>Pappas, George J.</dc:creator>
 <dc:creator>Ritala, Risto</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>90C40</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  This paper addresses the problem of optimal control of robotic sensing
systems aimed at autonomous information gathering in scenarios such as
environmental monitoring, search and rescue, and surveillance and
reconnaissance. The information gathering problem is formulated as a partially
observable Markov decision process (POMDP) with a reward function that captures
uncertainty reduction. Unlike the classical POMDP formulation, the resulting
reward structure is nonlinear in the belief state and the traditional
approaches do not apply directly. Instead of developing a new approximation
algorithm, we show that if attention is restricted to a class of problems with
certain structural properties, one can derive (often tight) upper and lower
bounds on the optimal policy via an efficient myopic computation. These policy
bounds can be applied in conjunction with an online branch-and-bound algorithm
to accelerate the computation of the optimal policy. We obtain informative
lower and upper policy bounds with low computational effort in a target
tracking domain. The performance of branch-and-bounding is demonstrated and
compared with exact value iteration.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07279</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07283</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Balanced Reed-Solomon Codes</dc:title>
 <dc:creator>Halbawi, Wael</dc:creator>
 <dc:creator>Liu, Zihan</dc:creator>
 <dc:creator>Hassibi, Babak</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of constructing linear Maximum Distance Separable
(MDS) error-correcting codes with generator matrices that are sparsest and
balanced. In this context, sparsest means that every row has the least possible
number of non-zero entries, and balanced means that every column contains the
same number of non-zero entries. Codes with this structure minimize the maximal
computation time of computing any code symbol, a property that is appealing to
systems where computational load-balancing is critical. The problem was studied
before by Dau et al. where it was shown that there always exists an MDS code
over a sufficiently large field such that its generator matrix is both sparsest
and balanced. However, the construction is not explicit and more importantly,
the resulting MDS codes do not lend themselves to efficient error correction.
With an eye towards explicit constructions with efficient decoding, we show in
this paper that the generator matrix of a cyclic Reed-Solomon code of length
$n$ and dimension $k$ can always be transformed to one that is both sparsest
and balanced, for all parameters $n$ and $k$ where $\frac{k}{n}(n - k + 1)$ is
an integer.
</dc:description>
 <dc:description>Comment: Submitted to ISIT 2016</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07285</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fairness in Communication for Omniscience</dc:title>
 <dc:creator>Ding, Ni</dc:creator>
 <dc:creator>Chan, Chung</dc:creator>
 <dc:creator>Zhou, Qiaoqiao</dc:creator>
 <dc:creator>Kennedy, Rodney A.</dc:creator>
 <dc:creator>Sadeghi, Parastoo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of how to fairly distribute the minimum sum-rate
among the users in communication for omniscience (CO). We formulate a problem
of minimizing a weighted quadratic function over a submodular base polyhedron
which contains all achievable rate vectors, or transmission strategies, for CO
that have the same sum-rate. By solving it, we can determine the rate vector
that optimizes the Jain's fairness measure, a more commonly used fairness index
than the Shapley value in communications engineering. We show that the
optimizer is a lexicographically optimal (lex-optimal) base and can be
determined by a decomposition algorithm (DA) that is based on submodular
function minimization (SFM) algorithm and completes in strongly polynomial
time. We prove that the lex-optimal minimum sum-rate strategy for CO can be
determined by finding the lex-optimal base in each user subset in the
fundamental partition and the complexity can be reduced accordingly.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07300</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recollection: an Alternative Restoration Technique for Constraint
  Programming Systems</dc:title>
 <dc:creator>Lin, Yong</dc:creator>
 <dc:creator>Henz, Martin</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Search is a key service within constraint programming systems, and it demands
the restoration of previously accessed states during the exploration of a
search tree. Restoration proceeds either bottom-up within the tree to roll back
previously performed operations using a trail, or top-down to redo them,
starting from a previously stored state and using suitable information stored
along the way. In this paper, we elucidate existing restoration techniques
using a pair of abstract methods and employ them to present a new technique
that we call recollection. The proposed technique stores the variables that
were affected by constraint propagation during fix points reasoning steps, and
it conducts neither operation roll-back nor recomputation, while consuming much
less memory than storing previous visited states. We implemented this idea as a
prototype within the Gecode solver. An empirical evaluation reveals that
constraint problems with expensive propagation and frequent failures can
benefit from recollection with respect to runtime at the expense of a marginal
increase in memory consumption, comparing with the most competitive variant of
recomputation.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07300</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07315</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Downlink Outage Performance of Heterogeneous Cellular Networks</dc:title>
 <dc:creator>Ak, Serkan</dc:creator>
 <dc:creator>Inaltekin, Hazer</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper derives tight performance upper and lower bounds on the downlink
outage efficiency of K-tier heterogeneous cellular networks (HCNs) for general
signal propagation models with Poisson distributed base stations in each tier.
In particular, the proposed approach to analyze the outage metrics in a K-tier
HCN allows for the use of general bounded path-loss functions and random fading
processes of general distributions. Considering two specific base station (BS)
association policies, it is shown that the derived performance bounds track the
actual outage metrics reasonably well for a wide range of BS densities, with
the gap among them becoming negligibly small for denser HCN deployments. A
simulation study is also performed for 2-tier and 3-tier HCN scenarios to
illustrate the closeness of the derived bounds to the actual outage performance
with various selections of the HCN parameters.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07315</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07322</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Optimal Geographical Caching in Heterogeneous Cellular Networks</dc:title>
 <dc:creator>Serbetci, Berksan</dc:creator>
 <dc:creator>Goseling, Jasper</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work we investigate optimal geographical caching in heterogeneous
cellular networks where different types of base stations (BSs) have different
cache capacities. Users request files from a content library according to a
known probability distribution. The performance metric is the total hit
probability, which is the probability that a user at an arbitrary location in
the plane will find the content that it requires in one of the BSs that it is
covered by.
  We consider the problem of optimally placing content in all BSs jointly. As
this problem is not convex, we provide a heuristic scheme by finding the
optimal placement policy for one type of base station conditioned on the
placement in all other types. We demonstrate that these individual optimization
problems are convex and we provide an analytical solution. As an illustration,
we find the optimal placement policy of the small base stations (SBSs)
depending on the placement policy of the macro base stations (MBSs). We show
how the hit probability evolves as the deployment density of the SBSs varies.
We show that the heuristic of placing the most popular content in the MBSs is
almost optimal after deploying the SBSs with optimal placement policies. Also,
for the SBSs no such heuristic can be used; the optimal placement is
significantly better than storing the most popular content. Finally, we show
that solving the individual problems to find the optimal placement policies for
different types of BSs iteratively, namely repeatedly updating the placement
policies, does not improve the performance.
</dc:description>
 <dc:description>Comment: The article has 6 pages, 7 figures and is accepted to be presented at
  IEEE Wireless Communications and Networking Conference (WCNC) 2017, 19 - 22
  March 2017, San Francisco, CA, USA</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07325</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DoF Analysis of the MIMO Broadcast Channel with Alternating/Hybrid CSIT</dc:title>
 <dc:creator>Rassouli, Borzoo</dc:creator>
 <dc:creator>Hao, Chenxi</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a $K$-user multiple-input single-output (MISO) broadcast channel
(BC) where the channel state information (CSI) of user $i(i=1,2,\ldots,K)$ may
be instantaneously perfect (P), delayed (D) or not known (N) at the transmitter
with probabilities $\lambda_P^i$, $\lambda_D^i$ and $\lambda_N^i$,
respectively. In this setting, according to the three possible CSIT for each
user, knowledge of the joint CSIT of the $K$ users could have at most $3^K$
states. In this paper, given the marginal probabilities of CSIT (i.e.,
$\lambda_P^i$, $\lambda_D^i$ and $\lambda_N^i$), we derive an outer bound for
the DoF region of the $K$-user MISO BC. Subsequently, we tighten this outer
bound by taking into account a set of inequalities that capture some of the
$3^K$ states of the joint CSIT. One of the consequences of this set of
inequalities is that for $K\geq3$, it is shown that the DoF region is not
completely characterized by the marginal probabilities in contrast to the
two-user case. Afterwards, the tightness of these bounds are investigated
through the discussion on the achievability. Finally, a two user MIMO BC having
CSIT among P and N is considered in which an outer bound for the DoF region is
provided and it is shown that in some scenarios it is tight.
</dc:description>
 <dc:description>Comment: 14 pages, accepted for publication in IEEE Trans. on Information
  Theory. arXiv admin note: substantial text overlap with arXiv:1311.6647</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07325</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2517060</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07333</identifier>
 <datestamp>2016-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OneClock to Rule Them All: Using Time in Networked Applications</dc:title>
 <dc:creator>Mizrahi, Tal</dc:creator>
 <dc:creator>Moses, Yoram</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper introduces OneClock, a generic approach for using time in
networked applications. OneClock provides two basic time-triggered primitives:
the ability to schedule an operation at a remote host or device, and the
ability to receive feedback about the time at which an event occurred or an
operation was executed at a remote host or device. We introduce a novel
prediction-based scheduling approach that uses timing information collected at
runtime to accurately schedule future operations.
  Our work includes an extension to the Network Configuration protocol
(NETCONF), which enables OneClock in real-life systems. This extension has been
published as an Internet Engineering Task Force (IETF) RFC, and a prototype of
our NETCONF time extension is publicly available as open source.
  Experimental evaluation shows that our prediction-based approach allows
accurate scheduling in diverse and heterogeneous environments, with various
hardware capabilities and workloads. OneClock is a generic approach that can be
applied to any managed device: sensors, actuators, Internet of Things (IoT)
devices, routers, or toasters.
</dc:description>
 <dc:description>Comment: This technical report is an extended version of &quot;OneClock to Rule
  Them All: Using Time in Networked Applications&quot;, which was accepted to
  IEEE/IFIP NOMS 2016</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07333</dc:identifier>
 <dc:identifier>NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management
  Symposium, Istanbul, Turkey, 2016, pp. 679-685</dc:identifier>
 <dc:identifier>doi:10.1109/NOMS.2016.7502876</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07336</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neighborhood Preserved Sparse Representation for Robust Classification
  on Symmetric Positive Definite Matrices</dc:title>
 <dc:creator>Yin, Ming</dc:creator>
 <dc:creator>Xie, Shengli</dc:creator>
 <dc:creator>Guo, Yi</dc:creator>
 <dc:creator>Gao, Junbin</dc:creator>
 <dc:creator>Zhang, Yun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Due to its promising classification performance, sparse representation based
classification(SRC) algorithm has attracted great attention in the past few
years. However, the existing SRC type methods apply only to vector data in
Euclidean space. As such, there is still no satisfactory approach to conduct
classification task for symmetric positive definite (SPD) matrices which is
very useful in computer vision. To address this problem, in this paper, a
neighborhood preserved kernel SRC method is proposed on SPD manifolds.
Specifically, by embedding the SPD matrices into a Reproducing Kernel Hilbert
Space (RKHS), the proposed method can perform classification on SPD manifolds
through an appropriate Log-Euclidean kernel. Through exploiting the geodesic
distance between SPD matrices, our method can effectively characterize the
intrinsic local Riemannian geometry within data so as to well unravel the
underlying sub-manifold structure. Despite its simplicity, experimental results
on several famous database demonstrate that the proposed method achieves better
classification results than the state-of-the-art approaches.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1601.00414</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07336</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07340</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Alternating Minimization Algorithms for Hybrid Precoding in Millimeter
  Wave MIMO Systems</dc:title>
 <dc:creator>Yu, Xianghao</dc:creator>
 <dc:creator>Shen, Juei-Chin</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Letaief, Khaled B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communications has been regarded as a key enabling
technology for 5G networks. In contrast to conventional
multiple-input-multiple-output (MIMO) systems, precoding in mmWave MIMO cannot
be performed entirely at baseband using digital precoders, as only a limited
number of signal mixers and analog-to-digital converters (ADCs) can be
supported considering their cost and power consumption. As a cost-effective
alternative, a hybrid precoding transceiver architecture, combining a digital
precoder and an analog precoder, has recently received considerable attention.
However, the optimal design of such hybrid precoders has not been fully
understood. In this paper, treating the hybrid precoder design as a matrix
factorization problem, effective alternating minimization (AltMin) algorithms
will be proposed for two different hybrid precoding structures, i.e., the
fully-connected and partially-connected structures. In particular, for the
fully-connected structure, an AltMin algorithm based on manifold optimization
is proposed to approach the performance of the fully digital precoder, which,
however, has a high complexity. Thus, a low-complexity AltMin algorithm is then
proposed, by enforcing an orthogonal constraint on the digital precoder.
Furthermore, for the partially-connected structure, an AltMin algorithm is also
developed with the help of semidefinite relaxation. For practical
implementation, the proposed AltMin algorithms are further extended to the
broadband setting with orthogonal frequency division multiplexing (OFDM)
modulation. Simulation results will demonstrate significant performance gains
of the proposed AltMin algorithms over existing hybrid precoding algorithms.
Moreover, based on the proposed algorithms, simulation comparisons between the
two hybrid precoding structures will provide valuable design insights.
</dc:description>
 <dc:description>Comment: 16 pages,8 figures, to appear in IEEE Journal of Selected Topics in
  Signal Processing</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07340</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2016.2523903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07341</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Providing Probabilistic Robustness Guarantee for Crowdsensing</dc:title>
 <dc:creator>Qu, Yuben</dc:creator>
 <dc:creator>Tang, Shaojie</dc:creator>
 <dc:creator>Dong, Chao</dc:creator>
 <dc:creator>Li, Peng</dc:creator>
 <dc:creator>Guo, Song</dc:creator>
 <dc:creator>Tian, Chang</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Due to its flexible and pervasive sensing ability, crowdsensing has been
extensively studied recently in research communities. However, the fundamental
issue of how to meet the requirement of sensing robustness in crowdsensing
remains largely unsolved. Specifically, from the task owner's perspective, how
to minimize the total payment in crowdsensing while guaranteeing the sensing
data quality is a critical issue to be resolved. We elegantly model the
robustness requirement over sensing data quality as chance constraints, and
investigate both hard and soft chance constraints for different crowdsensing
applications. For the former, we reformulate the problem through Boole's
Inequality, and explore the optimal value gap between the original problem and
the reformulated problem. For the latter, we study a serial of a general
payment minimization problem, and propose a binary search algorithm that
achieves both feasibility and low payment. The performance gap between our
solution and the optimal solution is also theoretically analyzed. Extensive
simulations validate our theoretical analysis.
</dc:description>
 <dc:description>Comment: 33 pages, 4 figures, 1 table</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07341</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07343</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On extremal double circulant self-dual codes of lengths $90$-$96$</dc:title>
 <dc:creator>Gulliver, T. Aaron</dc:creator>
 <dc:creator>Harada, Masaaki</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94B</dc:subject>
 <dc:description>  A classification of extremal double circulant self-dual codes of lengths up
to $88$ is known. We give a classification of extremal double circulant
self-dual codes of lengths $90,92,94$ and $96$. We also classify double
circulant self-dual codes with parameters $[90,45,14]$ and $[96,48,16]$. In
addition, we demonstrate that no double circulant self-dual $[90,45,14]$ code
has an extremal self-dual neighbor, and no double circulant self-dual
$[96,45,16]$ code has a self-dual neighbor with minimum weight at least $18$.
</dc:description>
 <dc:description>Comment: 15 pages</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07352</identifier>
 <datestamp>2016-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CoVer-ability: Consistent Versioning for Concurrent Objects</dc:title>
 <dc:creator>Nicolaou, Nicolas</dc:creator>
 <dc:creator>Anta, Antonio Fern&#xe1;ndez</dc:creator>
 <dc:creator>Georgiou, Chryssis</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  An object type characterizes the domain space and the operations that can be
invoked on an object of that type. In this paper we introduce a new property
for concurrent objects, we call coverability, that aims to provide precise
guarantees on the consistent evolution of an object. This new property is
suitable for a variety of distributed objects including concurrent file objects
that demand operations to manipulate the latest version of the object. We
propose two levels of coverability: (i) strong coverability and (ii) weak
coverability. Strong coverability requires that only a single operation can
modify the latest version of the object, i.e. &quot;covers&quot; the latest version with
a new version, imposing a total order on object modifications. Weak
coverability relaxes the strong requirements of strong coverability and allows
multiple operations to modify the same version of an object, where each
modification leads to a different version. Weak coverability preserves
consistent evolution of the object, by demanding any subsequent operation to
only modify one of the newly introduced versions. Coverability combined with
atomic guarantees yield to coverable atomic read/write registers. We also show
that strongly coverable atomic registers are equivalent in power to consensus.
Thus, we focus on weakly coverable registers, and we demonstrate their
importance by showing that they cannot be implemented using similar types of
registers, like ranked-registers. Furthermore we show that weakly coverable
registers may be used to implement basic (weak) read-modify-write and file
objects. Finally, we implement weakly coverable registers by modifying an
existing MWMR atomic register implementation.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07355</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitoring in the Clouds: Comparison of ECO2Clouds and EXCESS Monitoring
  Approaches</dc:title>
 <dc:creator>Skvortsov, Pavel</dc:creator>
 <dc:creator>Hoppe, Dennis</dc:creator>
 <dc:creator>Tenschert, Axel</dc:creator>
 <dc:creator>Gienger, Michael</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  With the increasing adoption of private cloud infrastructures by providers
and enterprises, the monitoring of these infrastructures is becoming crucial.
The rationale behind monitoring is manifold: reasons include saving energy,
lowering costs, and better maintenance. In the e-Science sector, moreover, the
collection of infrastructure and application-specific data at high resolutions
is immanent. In this paper, we present two monitoring approaches implemented
throughout two European projects: ECO2Clouds and EXCESS. The ECO2Clouds project
aims to minimize CO2 emissions caused by the execution of applications on the
cloud infrastructure. In order to allow for eco-aware deployment and scheduling
of applications, the ECO2Clouds monitoring framework provides the necessary set
of metrics on different layers including physical, virtual and application
layer. In turn, the EXCESS project introduces new energy-aware execution models
that improve energy-efficiency on a software level. Having in-depth knowledge
about the energy consumption and overall behavior of applications on a given
infrastructure, subsequent executions can be optimized to save energy. To
achieve this goal, the EXCESS monitoring framework provides APIs allowing
developers to collect application-specific data in addition to infrastructure
data at run-time. We perform a comparative analysis of both monitoring
approaches, and highlighting use cases including a hybrid approach which
benefits from both monitoring solutions.
</dc:description>
 <dc:description>Comment: 2nd International Workshop on Dynamic Resource Allocation and
  Management in Embedded, High Performance and Cloud Computing DREAMCloud 2016
  (arXiv:cs/1601.04675)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07358</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum machine learning with glow for episodic tasks and decision games</dc:title>
 <dc:creator>Clausen, Jens</dc:creator>
 <dc:creator>Briegel, Hans J.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a general class of models, where a reinforcement learning (RL)
agent learns from cyclic interactions with an external environment via
classical signals. Perceptual inputs are encoded as quantum states, which are
subsequently transformed by a quantum channel representing the agent's memory,
while the outcomes of measurements performed at the channel's output determine
the agent's actions. The learning takes place via stepwise modifications of the
channel properties. They are described by an update rule that is inspired by
the projective simulation (PS) model and equipped with a glow mechanism that
allows for a backpropagation of policy changes, analogous to the eligibility
traces in RL and edge glow in PS. In this way, the model combines features of
PS with the ability for generalization, offered by its physical embodiment as a
quantum system. We apply the agent to various setups of an invasion game and a
grid world, which serve as elementary model tasks allowing a direct comparison
with a basic classical PS agent.
</dc:description>
 <dc:description>Comment: 20 pages, 14 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07376</identifier>
 <datestamp>2016-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variational Problems Involving a Caputo-Type Fractional Derivative</dc:title>
 <dc:creator>Almeida, Ricardo</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The aim of this paper is to study certain problems of calculus of variations,
that are dependent upon a Lagrange function on a Caputo-type fractional
derivative. This type of fractional operator is a generalization of the Caputo
and the Caputo--Hadamard fractional derivatives, that are dependent on a real
parameter ro. Sufficient and necessary conditions of the first and second order
are presented. The cases of integral and holonomic constraints are also
considered.
</dc:description>
 <dc:description>Comment: This is a preprint of a paper whose final and definite form will be
  published in Journal of Optimization Theory and Applications</dc:description>
 <dc:date>2016-01-24</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07377</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Energy Management for SmartGrids Considering Thermal Load and
  Dynamic Pricing</dc:title>
 <dc:creator>Nguyen, Duong Tung</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  More active participation of the demand side and efficient integration of
distributed energy resources (DERs) such as electric vehicles (trVs), energy
storage (ES), and renewable energy sources (RESs) into the existing power
systems are important design objectives of the future smart grid. In general,
effective demand side management (DSM) would benefit both system operators
(e.g., peak demand reduction) and electricity customers (e.g., cost saving).
For building and home energy scheduling design, heating, ventilation, and
air-conditioning (HVAC) systems play a very important role since HVAC power
consumption is very significant and the HVAC load can be scheduled flexibly
while still maintaining user comfort requirements. This thesis focuses on
energy scheduling design for two different application scenarios where HVAC and
various DERs are considered to optimize the benefits electric users.
</dc:description>
 <dc:description>Comment: This is my Master thesis</dc:description>
 <dc:date>2016-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07381</identifier>
 <datestamp>2016-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating echo state networks dynamics by means of recurrence
  analysis</dc:title>
 <dc:creator>Bianchi, Filippo Maria</dc:creator>
 <dc:creator>Livi, Lorenzo</dc:creator>
 <dc:creator>Alippi, Cesare</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:description>  In this paper, we elaborate over the well-known interpretability issue in
echo state networks. The idea is to investigate the dynamics of reservoir
neurons with time-series analysis techniques taken from research on complex
systems. Notably, we analyze time-series of neuron activations with Recurrence
Plots (RPs) and Recurrence Quantification Analysis (RQA), which permit to
visualize and characterize high-dimensional dynamical systems. We show that
this approach is useful in a number of ways. First, the two-dimensional
representation offered by RPs provides a way for visualizing the
high-dimensional dynamics of a reservoir. Our results suggest that, if the
network is stable, reservoir and input denote similar line patterns in the
respective RPs. Conversely, the more unstable the ESN, the more the RP of the
reservoir presents instability patterns. As a second result, we show that the
$\mathrm{L_{max}}$ measure is highly correlated with the well-established
maximal local Lyapunov exponent. This suggests that complexity measures based
on RP diagonal lines distribution provide a valuable tool to quantify the
degree of network stability. Finally, our analysis shows that all RQA measures
fluctuate on the proximity of the so-called edge of stability, where an ESN
typically achieves maximum computational capability. We verify that the
determination of the edge of stability provided by such RQA measures is more
accurate than two well-known criteria based on the Jacobian matrix of the
reservoir. Therefore, we claim that RPs and RQA-based analyses can be used as
valuable tools to design an effective network given a specific problem.
</dc:description>
 <dc:description>Comment: Revised version. 24 pages; 12 figures</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:date>2016-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07381</dc:identifier>
 <dc:identifier>doi:10.1109/TNNLS.2016.2630802</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07392</identifier>
 <datestamp>2016-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nmag micromagnetic simulation tool - software engineering lessons
  learned</dc:title>
 <dc:creator>Fangohr, Hans</dc:creator>
 <dc:creator>Albert, Maximilian</dc:creator>
 <dc:creator>Franchin, Matteo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We review design and development decisions and their impact for the open
source code Nmag from a software engineering in computational science point of
view. We summarise lessons learned and recommendations for future computational
science projects. Key lessons include that encapsulating the simulation
functionality in a library of a general purpose language, here Python, provides
great flexibility in using the software. The choice of Python for the top-level
user interface was very well received by users from the science and engineering
community. The from-source installation in which required external libraries
and dependencies are compiled from a tarball was remarkably robust. In places,
the code is a lot more ambitious than necessary, which introduces unnecessary
complexity and reduces main- tainability. Tests distributed with the package
are useful, although more unit tests and continuous integration would have been
desirable. The detailed documentation, together with a tutorial for the usage
of the system, was perceived as one of its main strengths by the community.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures, Software Engineering for Science, ICSE2016</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07392</dc:identifier>
 <dc:identifier>Proceedings of the International Workshop on Software Engineering
  for Science, Pages 1-7, (2016)</dc:identifier>
 <dc:identifier>doi:10.1145/2897676.2897677</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07399</identifier>
 <datestamp>2016-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DoF-Robust Strategies for the K-user Distributed Broadcast Channel with
  Weak CSI</dc:title>
 <dc:creator>de Kerret, Paul</dc:creator>
 <dc:creator>Gesbert, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the Network MIMO channel under the so-called
Distributed Channel State Information at the Transmitters (D-CSIT)
configuration. In this setting, the precoder is designed in a distributed
manner at each Transmitter (TX) on the basis of the locally available
multi-user channel estimate. Although the use of simple Zero-Forcing (ZF) was
recently shown to reach the optimal DoF for a Broadcast Channel (BC) under
noisy, yet centralized, CSIT, it can turn very inefficient in the distributed
setting as the achieved number of Degrees-of-Freedom (DoF) is then limited by
the worst CSI accuracy across all TXs. To circumvent this effect, we develop a
new robust transmission scheme improving the DoF. A surprising result is
uncovered by which, in the regime of so-called weak CSIT, the proposed scheme
is shown to achieve the centralized outerbound obtained under a genie-aided
centralized setting in which the CSI versions available at all TXs are shared
among them. Building upon the insight obtained in the weak CSIT regime, we
develop a general D-CSI robust scheme which improves over the DoF obtained by
conventional ZF approach in an arbitrary CSI quality regime and is shown to
achieve the centralized outerbound in some other practically relevant CSIT
configurations.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transaction on Information Theory, November 2016</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-11-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07400</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving virtual host efficiency through resource and interference
  aware scheduling</dc:title>
 <dc:creator>Angelou, Evangelos</dc:creator>
 <dc:creator>Kaffes, Konstantinos</dc:creator>
 <dc:creator>Asiki, Athanasia</dc:creator>
 <dc:creator>Goumas, Georgios</dc:creator>
 <dc:creator>Koziris, Nectarios</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Modern Infrastructure-as-a-Service Clouds operate in a competitive
environment that caters to any user's requirements for computing resources. The
sharing of the various types of resources by diverse applications poses a
series of challenges in order to optimize resource utilization while avoiding
performance degradation caused by application interference. In this paper, we
present two scheduling methodologies enforcing consolidation techniques on
multicore physical machines. Our resource-aware and interference-aware
scheduling schemes aim at improving physical host efficiency while preserving
the application performance by taking into account host oversubscription and
the resulting workload interference. We validate our fully operational
framework through a set of real-life workloads representing a wide class of
modern cloud applications. The experimental results prove the efficiency of our
system in optimizing resource utilization and thus energy consumption even in
the presence of oversubscription. Both methodologies achieve significant
reductions of the CPU time consumed, reaching up to 50%, while at the same time
maintaining workload performance compared to widely used scheduling schemes
under a variety of representative cloud platform scenarios.
</dc:description>
 <dc:description>Comment: 2nd International Workshop on Dynamic Resource Allocation and
  Management in Embedded, High Performance and Cloud Computing DREAMCloud 2016
  (arXiv:cs/1601.04675)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07400</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07403</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphs of finite algebras, edges, and connectivity</dc:title>
 <dc:creator>Bulatov, Andrei A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We refine and advance the study of the local structure of idempotent finite
algebras started in [A.Bulatov, The Graph of a Relational Structure and
Constraint Satisfaction Problems, LICS, 2004]. We introduce a graph-like
structure on an arbitrary finite idempotent algebra omitting type 1. We show
that this graph is connected, its edges can be classified into 3 types
corresponding to the local behavior (semilattice, majority, or affine) of
certain term operations, and that the structure of the algebra can be
`improved' without introducing type 1 by choosing an appropriate reduct of the
original algebra. Then we refine this structure demonstrating that the edges of
the graph of an algebra can be made `thin', that is, there are term operations
that behave very similar to semilattice, majority, or affine operations on
2-element subsets of the algebra. Finally, we prove certain connectivity
properties of the refined structures.
  This research is motivated by the study of the Constraint Satisfaction
Problem, although the problem itself does not really show up in this paper.
</dc:description>
 <dc:date>2016-01-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07409</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Object Reasoning with Constrained Goal Models</dc:title>
 <dc:creator>Nguyen, Chi Mai</dc:creator>
 <dc:creator>Sebastiani, Roberto</dc:creator>
 <dc:creator>Giorgini, Paolo</dc:creator>
 <dc:creator>Mylopoulos, John</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Goal models have been widely used in Computer Science to represent software
requirements, business objectives, and design qualities. Existing goal
modelling techniques, however, have shown limitations of expressiveness and/or
tractability in coping with complex real-world problems. In this work, we
exploit advances in automated reasoning technologies, notably Satisfiability
and Optimization Modulo Theories (SMT/OMT), and we propose and formalize: (i)
an extended modelling language for goals, namely the Constrained Goal Model
(CGM), which makes explicit the notion of goal refinement and of domain
assumption, allows for expressing preferences between goals and refinements,
and allows for associating numerical attributes to goals and refinements for
defining constraints and optimization goals over multiple objective functions,
refinements and their numerical attributes; (ii) a novel set of automated
reasoning functionalities over CGMs, allowing for automatically generating
suitable refinements of input CGMs, under user-specified assumptions and
constraints, that also maximize preferences and optimize given objective
functions. We have implemented these modelling and reasoning functionalities in
a tool, named CGM-Tool, using the OMT solver OptiMathSAT as automated reasoning
backend. Moreover, we have conducted an experimental evaluation on large CGMs
to support the claim that our proposal scales well for goal models with
thousands of elements.
</dc:description>
 <dc:description>Comment: 52 pages (with appendices). Under journal submission</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-11-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07409</dc:identifier>
 <dc:identifier>doi:10.1007/s00766-016-0263-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07414</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Location Games on Networks: Existence and Efficiency of Equilibria</dc:title>
 <dc:creator>Fournier, Ga&#xeb;tan</dc:creator>
 <dc:creator>Scarsini, Marco</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Primary 91A43, secondary 91A06</dc:subject>
 <dc:description>  We consider a game where a finite number of retailers choose a location,
given that their potential consumers are distributed on a network. Retailers do
not compete on price but only on location, therefore each consumer shops at the
closest store. We show that when the number of retailers is large enough, the
game admits a pure Nash equilibrium and we construct it. We then compare the
equilibrium cost borne by the consumers with the cost that could be achieved if
the retailers followed the dictate of a benevolent planner. We perform this
comparison in term of the price of anarchy, i.e., the ratio of the worst
equilibrium cost and the optimal cost, and the price of stability, i.e., the
ratio of the best equilibrium cost and the optimal cost. We show that,
asymptotically in the number of retailers, these ratios are bounded by two and
one, respectively.
</dc:description>
 <dc:description>Comment: 38 pages, 10 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-04-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07416</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QRKE: Resistance to Attacks using the Inverse of the Cosine
  Representation of Chebyshev Polynomials</dc:title>
 <dc:creator>Brands, G.</dc:creator>
 <dc:creator>Roellgen, C. B.</dc:creator>
 <dc:creator>Vogel, K. U.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We've been able to show recently that Permutable Chebyshev polynomials (T
polynomials) defined over the field of real numbers can be used to create a
Diffie-Hellman-like key exchange algorithm and certificates. The cryptosystem
was theoretically proven to withstand attacks using quantum computers. We
additionally prove that attacks based on the inverse of the cosine
representation of T polynomials fail.
</dc:description>
 <dc:description>Comment: Algorithm has been broken</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07417</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy-Aware MMSE Estimation</dc:title>
 <dc:creator>Asoodeh, Shahab</dc:creator>
 <dc:creator>Alajaji, Fady</dc:creator>
 <dc:creator>Linder, Tam&#xe1;s</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We investigate the problem of the predictability of random variable $Y$ under
a privacy constraint dictated by random variable $X$, correlated with $Y$,
where both predictability and privacy are assessed in terms of the minimum
mean-squared error (MMSE). Given that $X$ and $Y$ are connected via a
binary-input symmetric-output (BISO) channel, we derive the \emph{optimal}
random mapping $P_{Z|Y}$ such that the MMSE of $Y$ given $Z$ is minimized while
the MMSE of $X$ given $Z$ is greater than $(1-\epsilon)\mathsf{var}(X)$ for a
given $\epsilon\geq 0$. We also consider the case where $(X,Y)$ are continuous
and $P_{Z|Y}$ is restricted to be an additive noise channel.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07420</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Workflow for Fast Evaluation of Mapping Heuristics Targeting Cloud
  Infrastructures</dc:title>
 <dc:creator>Ursu, Roman</dc:creator>
 <dc:creator>Latif, Khalid</dc:creator>
 <dc:creator>Novo, David</dc:creator>
 <dc:creator>Selva, Manuel</dc:creator>
 <dc:creator>Gamatie, Abdoulaye</dc:creator>
 <dc:creator>Sassatelli, Gilles</dc:creator>
 <dc:creator>Khabi, Dmitry</dc:creator>
 <dc:creator>Cheptsov, Alexey</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Resource allocation is today an integral part of cloud infrastructures
management to efficiently exploit resources. Cloud infrastructures centers
generally use custom built heuristics to define the resource allocations. It is
an immediate requirement for the management tools of these centers to have a
fast yet reasonably accurate simulation and evaluation platform to define the
resource allocation for cloud applications. This work proposes a framework
allowing users to easily specify mappings for cloud applications described in
the AMALTHEA format used in the context of the DreamCloud European project and
to assess the quality for these mappings. The two quality metrics provided by
the framework are execution time and energy consumption.
</dc:description>
 <dc:description>Comment: 2nd International Workshop on Dynamic Resource Allocation and
  Management in Embedded, High Performance and Cloud Computing DREAMCloud 2016
  (arXiv:cs/1601.04675)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07420</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07424</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Object-oriented Packet Caching for ICN</dc:title>
 <dc:creator>Thomas, Yannis</dc:creator>
 <dc:creator>Xylomenos, George</dc:creator>
 <dc:creator>Tsilopoulos, Christos</dc:creator>
 <dc:creator>Polyzos, George C.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  One of the most discussed features offered by Information-centric Networking
(ICN) architectures is the ability to support packet-level caching at every
node in the network. By individually naming each packet, ICN allows routers to
turn their queueing buffers into packet caches, thus exploiting the network's
existing storage resources. However, the performance of packet caching at
commodity routers is restricted by the small capacity of their SRAM, which
holds the index for the packets stored at the, slower, DRAM. We therefore
propose Object-oriented Packet Caching (OPC), a novel caching scheme that
overcomes the SRAM bottleneck, by combining object-level indexing in the SRAM
with packet-level storage in the DRAM. We implemented OPC and experimentally
evaluated it over various cache placement policies, showing that it can enhance
the impact of ICN packet-level caching, reducing both network and server load.
</dc:description>
 <dc:description>Comment: 2nd International Conference on Information-Centric Networking, ACM,
  2015</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07435</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Co-Occurrence Patterns in the Voynich Manuscript</dc:title>
 <dc:creator>Timm, Torsten</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The Voynich Manuscript is a medieval book written in an unknown script. This
paper studies the distribution of similarly spelled words in the Voynich
Manuscript. It shows that the distribution of words within the manuscript is
not compatible with natural languages.
</dc:description>
 <dc:description>Comment: 19 pages; tables for sections of the VMS added; 'The Towneley plays'
  as example for English poetry added; revised version</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07444</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless distance estimation with low-power standard components in
  wireless sensor nodes</dc:title>
 <dc:creator>J&#xf6;rger, Thorbj&#xf6;rn</dc:creator>
 <dc:creator>H&#xf6;flinger, Fabian</dc:creator>
 <dc:creator>Gamm, Gerd Ulrich</dc:creator>
 <dc:creator>Reindl, Leonhard M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>B.1.m</dc:subject>
 <dc:description>  In the context of increasing use of moving wireless sensor nodes the interest
in localizing these nodes in their application environment is strongly rising.
For many applications, it is necessary to know the exact position of the nodes
in two- or three-dimensional space. Commonly used nodes use state-of-the-art
transceivers like the CC430 from Texas Instruments with integrated signal
strength measurement for this purpose. This has the disadvantage, that the
signal strength measurement is strongly dependent on the orientation of the
node through the antennas inhomogeneous radiation pattern as well as it has a
small accuracy on long ranges. Also, the nodes overall attenuation and output
power has to be calibrated and interference and multipath effects appear in
closed environments. Another possibility to trilaterate the position of a
sensor node is the time of flight measurement. This has the advantage, that the
position can also be estimated on long ranges, where signal strength methods
give only poor accuracy. In this paper we present an investigation of the
suitability of the state-of-the-art transceiver CC430 for a system based on
time of flight methods and give an overview of the optimal settings under
various circumstances for the in-field application. For this investigation, the
systematic and statistical errors in the time of flight measurements with the
CC430 have been investigated under a multitude of parameters. Our basic system
does not use any additional components but only the given standard hardware,
which can be found on the Texas Instruments evaluation board for a CC430. Thus,
it can be implemented on already existent sensor node networks by a simple
software upgrade.
</dc:description>
 <dc:description>Comment: 8 pages, Proceedings of the 14th Mechatronics Forum International
  Conference, Mechatronics 2014</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07444</dc:identifier>
 <dc:identifier>Proceedings of the 14th Mechatronics Forum International
  Conference, Mechatronics 2014, 502-509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07446</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A First Attempt to Cloud-Based User Verification in Distributed System</dc:title>
 <dc:creator>Wozniak, Marcin</dc:creator>
 <dc:creator>Polap, Dawid</dc:creator>
 <dc:creator>Borowik, Grzegorz</dc:creator>
 <dc:creator>Napoli, Christian</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>68T05, 68T10, 68T45, 68U10, 68W25, 68W99</dc:subject>
 <dc:subject>I.2.6, I.2.10, I.4.8</dc:subject>
 <dc:description>  In this paper, the idea of client verification in distributed systems is
presented. The proposed solution presents a sample system where client
verification through cloud resources using input signature is discussed. For
different signatures the proposed method has been examined. Research results
are presented and discussed to show potential advantages.
</dc:description>
 <dc:description>Comment: Final version published on: Asia-Pacific Conference on Computer Aided
  System Engineering (APCASE), pp. 226-231 (2015)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07446</dc:identifier>
 <dc:identifier>Asia-Pacific Conference on Computer Aided System Engineering
  (APCASE), pp. 226-231 (2015)</dc:identifier>
 <dc:identifier>doi:10.1109/APCASE.2015.47</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07457</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gondola: a Parametric Robot Infrastructure for Repeatable Mobile
  Experiments</dc:title>
 <dc:creator>Cattani, Marco</dc:creator>
 <dc:creator>Protonotarios, Ioannis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  When deploying a testbed infrastructure for Wireless Sensor Networks (WSNs),
one of the most challenging feature is to provide repeatable mobility. Wheeled
robots, usually employed for such tasks, strive to adapt to the wide range of
environments where WSNs are deployed, from chaotic office spaces to potato
fields in the farmland. For this reson, these robot systems often require
expensive customization steps that, for example, adapt their localization and
navigation system. To avoid these issues, in this paper we present the design
of Gondola, a parametric robot infrastructure based on pulling wires, rather
than wheels, that avoids the most common problems of wheeled robot and easily
adapts to many WSN's scenarios. Different from wheeled robots, wich movements
are constrained on a 2-dimensional plane, Gondola can easily move in
3-dimensional spaces with no need of a complex localization system and an
accuracy that is comparable with off-the-shelf wheeled robots.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07457</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07460</identifier>
 <datestamp>2017-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-theoretic limits of Bayesian network structure learning</dc:title>
 <dc:creator>Ghoshal, Asish</dc:creator>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we study the information-theoretic limits of learning the
structure of Bayesian networks (BNs), on discrete as well as continuous random
variables, from a finite number of samples. We show that the minimum number of
samples required by any procedure to recover the correct structure grows as
$\Omega(m)$ and $\Omega(k \log m + (k^2/m))$ for non-sparse and sparse BNs
respectively, where $m$ is the number of variables and $k$ is the maximum
number of parents per node. We provide a simple recipe, based on an extension
of the Fano's inequality, to obtain information-theoretic limits of structure
recovery for any exponential family BN. We instantiate our result for specific
conditional distributions in the exponential family to characterize the
fundamental limits of learning various commonly used BNs, such as conditional
probability table based networks, gaussian BNs, noisy-OR networks, and logistic
regression networks. En route to obtaining our main results, we obtain tight
bounds on the number of sparse and non-sparse essential-DAGs. Finally, as a
byproduct, we recover the information-theoretic limits of sparse variable
selection for logistic regression.
</dc:description>
 <dc:description>Comment: Accepted to AISTATS 2017, Florida</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07460</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07468</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massive MIMO Combining with Switches</dc:title>
 <dc:creator>Alkhateeb, Ahmed</dc:creator>
 <dc:creator>Nam, Young-Han</dc:creator>
 <dc:creator>Zhang, Jianzhong</dc:creator>
 <dc:creator>Heath Jr, Robert W.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive multiple-input multiple-output (MIMO) is expected to play a central
role in future wireless systems. The deployment of large antenna arrays at the
base station and the mobile users offers multiplexing and beamforming gains
that boost system spectral efficiency. Unfortunately, the high cost and power
consumption of components like analog-to-digital converters makes assigning an
RF chain per antenna and applying typical fully digital precoding/combining
solutions difficult. In this paper, a novel architecture for massive MIMO
receivers, consisting of arrays of switches and constant (non-tunable) phase
shifters, is proposed. This architecture applies a quasi-coherent combining in
the RF domain to reduce the number of required RF chains. An algorithm that
designs the RF combining for this architecture is developed and analyzed.
Results show that the proposed massive MIMO combining model can achieve a
comparable performance to the fully-digital receiver architecture in
single-user and multi-user massive MIMO setups.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, accepted in IEEE Wireless Communications Letters</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07468</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2016.2522963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07471</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Shape Distributions of Nonlinear Dynamical Systems for Video-based
  Inference</dc:title>
 <dc:creator>Venkataraman, Vinay</dc:creator>
 <dc:creator>Turaga, Pavan</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a shape-theoretic framework for dynamical analysis of
nonlinear dynamical systems which appear frequently in several video-based
inference tasks. Traditional approaches to dynamical modeling have included
linear and nonlinear methods with their respective drawbacks. A novel approach
we propose is the use of descriptors of the shape of the dynamical attractor as
a feature representation of nature of dynamics. The proposed framework has two
main advantages over traditional approaches: a) representation of the dynamical
system is derived directly from the observational data, without any inherent
assumptions, and b) the proposed features show stability under different
time-series lengths where traditional dynamical invariants fail. We illustrate
our idea using nonlinear dynamical models such as Lorenz and Rossler systems,
where our feature representations (shape distribution) support our hypothesis
that the local shape of the reconstructed phase space can be used as a
discriminative feature. Our experimental analyses on these models also indicate
that the proposed framework show stability for different time-series lengths,
which is useful when the available number of samples are small/variable. The
specific applications of interest in this paper are: 1) activity recognition
using motion capture and RGBD sensors, 2) activity quality assessment for
applications in stroke rehabilitation, and 3) dynamical scene classification.
We provide experimental validation through action and gesture recognition
experiments on motion capture and Kinect datasets. In all these scenarios, we
show experimental evidence of the favorable properties of the proposed
representation.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Pattern Analysis and Machine Intelligence</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07471</dc:identifier>
 <dc:identifier>doi:10.1109/TPAMI.2016.2533388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07472</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formalized linear algebra over Elementary Divisor Rings in Coq</dc:title>
 <dc:creator>Cano, Guillaume</dc:creator>
 <dc:creator>Cohen, Cyril</dc:creator>
 <dc:creator>D&#xe9;n&#xe8;s, Maxime</dc:creator>
 <dc:creator>M&#xf6;rtberg, Anders</dc:creator>
 <dc:creator>Siles, Vincent</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  This paper presents a Coq formalization of linear algebra over elementary
divisor rings, that is, rings where every matrix is equivalent to a matrix in
Smith normal form. The main results are the formalization that these rings
support essential operations of linear algebra, the classification theorem of
finitely presented modules over such rings and the uniqueness of the Smith
normal form up to multiplication by units. We present formally verified
algorithms computing this normal form on a variety of coefficient structures
including Euclidean domains and constructive principal ideal domains. We also
study different ways to extend B\'ezout domains in order to be able to compute
the Smith normal form of matrices. The extensions we consider are: adequacy
(i.e. the existence of a gdco operation), Krull dimension $\leq 1$ and
well-founded strict divisibility.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07472</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 2 (June 22,
  2016) lmcs:1639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07473</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Streaming Space Complexity of Nearly All Functions of One Variable on
  Frequency Vectors</dc:title>
 <dc:creator>Braverman, Vladimir</dc:creator>
 <dc:creator>Chestnut, Stephen R.</dc:creator>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:creator>Yang, Lin F.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  A central problem in the theory of algorithms for data streams is to
determine which functions on a stream can be approximated in sublinear, and
especially sub-polynomial or poly-logarithmic, space. Given a function $g$, we
study the space complexity of approximating $\sum_{i=1}^n g(|f_i|)$, where
$f\in\mathbb{Z}^n$ is the frequency vector of a turnstile stream. This is a
generalization of the well-known frequency moments problem, and previous
results apply only when $g$ is monotonic or has a special functional form. Our
contribution is to give a condition such that, except for a narrow class of
functions $g$, there is a space-efficient approximation algorithm for the sum
if and only if $g$ satisfies the condition. The functions $g$ that we are able
to characterize include all convex, concave, monotonic, polynomial, and
trigonometric functions, among many others, and is the first such
characterization for non-monotonic functions. Thus, for nearly all functions of
one variable, we answer the open question from the celebrated paper of Alon,
Matias and Szegedy (1996).
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07473</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07482</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Learning in Neuromemristive Systems</dc:title>
 <dc:creator>Merkel, Cory</dc:creator>
 <dc:creator>Kudithipudi, Dhireesha</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Neuromemristive systems (NMSs) currently represent the most promising
platform to achieve energy efficient neuro-inspired computation. However, since
the research field is less than a decade old, there are still countless
algorithms and design paradigms to be explored within these systems. One
particular domain that remains to be fully investigated within NMSs is
unsupervised learning. In this work, we explore the design of an NMS for
unsupervised clustering, which is a critical element of several machine
learning algorithms. Using a simple memristor crossbar architecture and
learning rule, we are able to achieve performance which is on par with MATLAB's
k-means clustering.
</dc:description>
 <dc:description>Comment: To appear in the proceedings of the National Aerospace &amp; Electronics
  Conference &amp; Ohio Innovation Summit (NAECON-OIS'15)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07483</identifier>
 <datestamp>2016-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning and Tuning Meta-heuristics in Plan Space Planning</dc:title>
 <dc:creator>Shekhar, Shashank</dc:creator>
 <dc:creator>Khemani, Deepak</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In recent years, the planning community has observed that techniques for
learning heuristic functions have yielded improvements in performance. One
approach is to use offline learning to learn predictive models from existing
heuristics in a domain dependent manner. These learned models are deployed as
new heuristic functions. The learned models can in turn be tuned online using a
domain independent error correction approach to further enhance their
informativeness. The online tuning approach is domain independent but instance
specific, and contributes to improved performance for individual instances as
planning proceeds. Consequently it is more effective in larger problems.
  In this paper, we mention two approaches applicable in Partial Order Causal
Link (POCL) Planning that is also known as Plan Space Planning. First, we
endeavor to enhance the performance of a POCL planner by giving an algorithm
for supervised learning. Second, we then discuss an online error minimization
approach in POCL framework to minimize the step-error associated with the
offline learned models thus enhancing their informativeness. Our evaluation
shows that the learning approaches scale up the performance of the planner over
standard benchmarks, specially for larger problems.
</dc:description>
 <dc:description>Comment: AAAI format, (9 pages), (1 figure), (4 tables)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07488</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On weighted Fisher information matrix properties</dc:title>
 <dc:creator>Kelbert, Mark</dc:creator>
 <dc:creator>Suhov, Yuri</dc:creator>
 <dc:creator>Sekeh, Salimeh Yasaei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60A10, 60B05, 60C05</dc:subject>
 <dc:description>  In this paper, we review Fisher information matrices properties in weighted
version and discuss inequalities/bounds on it by using reduced weight
functions. In particular, an extended form of the Fisher information inequality
previously established in [6] is given. Further, along with generalized
De-Bruijn's identity, we provide new interpretation of the concavity for the
entropy power.
</dc:description>
 <dc:description>Comment: The paper is wihdrawn as it needs improvement</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07498</identifier>
 <datestamp>2016-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Equivalence of additive-combinatorial linear inequalities for Shannon
  entropy and differential entropy</dc:title>
 <dc:creator>Makkuva, Ashok Vardhan</dc:creator>
 <dc:creator>Wu, Yihong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses the correspondence between linear inequalities of
Shannon entropy and differential entropy for sums of independent group-valued
random variables. We show that any balanced (with the sum of coefficients being
zero) linear inequality of Shannon entropy holds if and only if its
differential entropy counterpart also holds; moreover, any linear inequality
for differential entropy must be balanced. In particular, our result shows that
recently proved differential entropy inequalities by Kontoyiannis and Madiman
\cite{KM14} can be deduced from their discrete counterparts due to Tao
\cite{Tao10} in a unified manner. Generalizations to certain abelian groups are
also obtained.
  Our proof of extending inequalities of Shannon entropy to differential
entropy relies on a result of R\'enyi \cite{Renyi59} which relates the Shannon
entropy of a finely discretized random variable to its differential entropy and
also helps in establishing the entropy of the sum of quantized random variables
is asymptotically equal to that of the quantized sum; the converse uses the
asymptotics of the differential entropy of convolutions with weak additive
noise.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-09-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07505</identifier>
 <datestamp>2016-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Game Theoretic Analysis of Tree Based Referrals for Crowd Sensing Social
  Systems with Passive Rewards</dc:title>
 <dc:creator>Kandhway, Kundan</dc:creator>
 <dc:creator>Kotnis, Bhushan</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Participatory crowd sensing social systems rely on the participation of large
number of individuals. Since humans are strategic by nature, effective
incentive mechanisms are needed to encourage participation. A popular mechanism
to recruit individuals is through referrals and passive incentives such as
geometric incentive mechanisms used by the winning team in the 2009 DARPA
Network Challenge and in multi level marketing schemes. The effect of such
recruitment schemes on the effort put in by recruited strategic individuals is
not clear. This paper attempts to fill this gap. Given a referral tree and the
direct and passive reward mechanism, we formulate a network game where agents
compete for finishing crowd sensing tasks. We characterize the Nash equilibrium
efforts put in by the agents and derive closed form expressions for the same.
We discover free riding behavior among nodes who obtain large passive rewards.
This work has implications on designing effective recruitment mechanisms for
crowd sourced tasks. For example, usage of geometric incentive mechanisms to
recruit large number of individuals may not result in proportionate effort
because of free riding.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures. Presented in Social Networking Workshop at
  International Conference on Communication Systems and Networks (COMSNETS),
  Bangalore, India, January 2016</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07505</dc:identifier>
 <dc:identifier>doi:10.1109/COMSNETS.2016.7439947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07513</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secret-Key Generation Using Compound Sources and One-Way Public
  Communication</dc:title>
 <dc:creator>Tavangaran, Nima</dc:creator>
 <dc:creator>Boche, Holger</dc:creator>
 <dc:creator>Schaefer, Rafael F.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the classical Secret-Key generation model, Common Randomness is generated
by two terminals based on the observation of correlated components of a common
source, while keeping it secret from a non-legitimate observer. It is assumed
that the statistics of the source are known to all participants. In this work,
the Secret-Key generation based on a compound source is studied where the
realization of the source statistic is unknown. The protocol should guarantee
the security and reliability of the generated Secret-Key, simultaneously for
all possible realizations of the compound source. A single-letter lower-bound
of the Secret-Key capacity for a finite compound source is derived as a
function of the public communication rate constraint. A multi-letter capacity
formula is further computed for a finite compound source for the case in which
the public communication is unconstrained. Finally a single-letter capacity
formula is derived for a degraded compound source with an arbitrary set of
source states and a finite set of marginal states.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07513</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07518</identifier>
 <datestamp>2017-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximating permanents and hafnians</dc:title>
 <dc:creator>Barvinok, Alexander</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>15A15, 68C25, 68W25</dc:subject>
 <dc:description>  We prove that the logarithm of the permanent of an nxn real matrix A and the
logarithm of the hafnian of a 2nx2n real symmetric matrix A can be approximated
within an additive error 1 &gt; epsilon &gt; 0 by a polynomial p in the entries of A
of degree O(ln n - ln epsilon) provided the entries a_ij of A satisfy delta &lt;
a_ij &lt; 1 for an arbitrarily small delta &gt; 0, fixed in advance. Moreover, the
polynomial p can be computed in n^{O(ln n - ln epsilon)} time. We also improve
bounds for approximating ln per A, ln haf A and logarithms of multi-dimensional
permanents for complex matrices and tensors A.
</dc:description>
 <dc:description>Comment: The article number (for &quot;Discrete Analysis&quot;) is corrected</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-01-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07518</dc:identifier>
 <dc:identifier>Discrete Analysis, 2017:2, 34 pp</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07532</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Extract Motion from Videos in Convolutional Neural Networks</dc:title>
 <dc:creator>Teney, Damien</dc:creator>
 <dc:creator>Hebert, Martial</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper shows how to extract dense optical flow from videos with a
convolutional neural network (CNN). The proposed model constitutes a potential
building block for deeper architectures to allow using motion without resorting
to an external algorithm, \eg for recognition in videos. We derive our network
architecture from signal processing principles to provide desired invariances
to image contrast, phase and texture. We constrain weights within the network
to enforce strict rotation invariance and substantially reduce the number of
parameters to learn. We demonstrate end-to-end training on only 8 sequences of
the Middlebury dataset, orders of magnitude less than competing CNN-based
motion estimation methods, and obtain comparable performance to classical
methods on the Middlebury benchmark. Importantly, our method outputs a
distributed representation of motion that allows representing multiple,
transparent motions, and dynamic textures. Our contributions on network design
and rotation invariance offer insights nonspecific to motion estimation.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07533</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Osteoporotic and Neoplastic Compression Fracture Classification on
  Longitudinal CT</dc:title>
 <dc:creator>Wang, Yinong</dc:creator>
 <dc:creator>Yao, Jianhua</dc:creator>
 <dc:creator>Burns, Joseph E.</dc:creator>
 <dc:creator>Summers, Ronald M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  Classification of vertebral compression fractures (VCF) having osteoporotic
or neoplastic origin is fundamental to the planning of treatment. We developed
a fracture classification system by acquiring quantitative morphologic and bone
density determinants of fracture progression through the use of automated
measurements from longitudinal studies. A total of 250 CT studies were acquired
for the task, each having previously identified VCFs with osteoporosis or
neoplasm. Thirty-six features or each identified VCF were computed and
classified using a committee of support vector machines. Ten-fold cross
validation on 695 identified fractured vertebrae showed classification
accuracies of 0.812, 0.665, and 0.820 for the measured, longitudinal, and
combined feature sets respectively.
</dc:description>
 <dc:description>Comment: Contributed 4-Page Paper to be presented at the 2016 IEEE
  International Symposium on Biomedical Imaging (ISBI), April 13-16, 2016,
  Prague, Czech Republic</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07533</dc:identifier>
 <dc:identifier>doi:10.1109/ISBI.2016.7493477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07539</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QFix: Diagnosing errors through query histories</dc:title>
 <dc:creator>Wang, Xiaolan</dc:creator>
 <dc:creator>Meliou, Alexandra</dc:creator>
 <dc:creator>Wu, Eugene</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Data-driven applications rely on the correctness of their data to function
properly and effectively. Errors in data can be incredibly costly and
disruptive, leading to loss of revenue, incorrect conclusions, and misguided
policy decisions. While data cleaning tools can purge datasets of many errors
before the data is used, applications and users interacting with the data can
introduce new errors. Subsequent valid updates can obscure these errors and
propagate them through the dataset causing more discrepancies. Even when some
of these discrepancies are discovered, they are often corrected superficially,
on a case-by-case basis, further obscuring the true underlying cause, and
making detection of the remaining errors harder. In this paper, we propose
QFix, a framework that derives explanations and repairs for discrepancies in
relational data, by analyzing the effect of queries that operated on the data
and identifying potential mistakes in those queries. QFix is flexible, handling
scenarios where only a subset of the true discrepancies is known, and robust to
different types of update workloads. We make four important contributions: (a)
we formalize the problem of diagnosing the causes of data errors based on the
queries that operated on and introduced errors to a dataset; (b) we develop
exact methods for deriving diagnoses and fixes for identified errors using
state-of-the-art tools; (c) we present several optimization techniques that
improve our basic approach without compromising accuracy, and (d) we leverage a
tradeoff between accuracy and performance to scale diagnosis to large datasets
and query logs, while achieving near-optimal results. We demonstrate the
effectiveness of QFix through extensive evaluation over benchmark and synthetic
data.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07572</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis and Evaluation for the Performance of the Communication
  Infrastructure for Real Wide Area Monitoring Systems (WAMS) Based on 3G
  Technology</dc:title>
 <dc:creator>Eissa, M. M.</dc:creator>
 <dc:creator>Elmesalawy, Mahmoud M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wide Area Monitoring Systems (WAMS) utilizing synchrophasor measurements is
considered one of the essential parts in smart grids that enable system
operators to monitor, operate, and control power systems in wide geographical
area. On the other hand, high-speed, reliable and scalable data communication
infrastructure is crucial in both construction and operation of WAMS. Universal
mobile Telecommunication System (UMTS), the 3G standard for mobile
communication networks, was developed to provide high speed data transmission
with reliable service performance for mobile users. Therefore, UMTS is
considered a promising solution for providing a communication infrastructure
for WAMS. 3G based EWAMS (Egyptian wide area Monitoring System) is designed and
implemented in Egypt through deployment a number of frequency disturbance
recorders (FDRs) devices on a live 220kV/500kV Egyptian grid in cooperation
with the Egyptian Electricity Transmission Company (EETC). The developed EWAMS
can gather information from 11 FDRs devices which are geographically dispersed
throughout the boundary of the Egyptian power grid and to a remote data
management center located at Helwan University. The communication performance
for the developed EWAMS in terms of communication time delay, throughput, and
percentage of wasted bandwidth are studied in this paper. The results showed
that the system can achieve successfully the communication requirements needed
by various wide area monitoring applications.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Smart Energy Grid Engineering
  (SEGE14), UOIT, Oshawa, ON, 11-13 August, 2014</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07576</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally-Supervised Deep Hybrid Model for Scene Recognition</dc:title>
 <dc:creator>Guo, Sheng</dc:creator>
 <dc:creator>Huang, Weilin</dc:creator>
 <dc:creator>Wang, Limin</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural networks (CNN) have recently achieved remarkable
successes in various image classification and understanding tasks. The deep
features obtained at the top fully-connected layer of the CNN (FC-features)
exhibit rich global semantic information and are extremely effective in image
classification. On the other hand, the convolutional features in the middle
layers of the CNN also contain meaningful local information, but are not fully
explored for image representation. In this paper, we propose a novel
Locally-Supervised Deep Hybrid Model (LS-DHM) that effectively enhances and
explores the convolutional features for scene recognition. Firstly, we notice
that the convolutional features capture local objects and fine structures of
scene images, which yield important cues for discriminating ambiguous scenes,
whereas these features are significantly eliminated in the highly-compressed FC
representation. Secondly, we propose a new Local Convolutional Supervision
(LCS) layer to enhance the local structure of the image by directly propagating
the label information to the convolutional layers. Thirdly, we propose an
efficient Fisher Convolutional Vector (FCV) that successfully rescues the
orderless mid-level semantic information (e.g. objects and textures) of scene
image. The FCV encodes the large-sized convolutional maps into a fixed-length
mid-level representation, and is demonstrated to be strongly complementary to
the high-level FC-features. Finally, both the FCV and FC-features are
collaboratively employed in the LSDHM representation, which achieves
outstanding performance in our experiments. It obtains 83.75% and 67.56%
accuracies respectively on the heavily benchmarked MIT Indoor67 and SUN397
datasets, advancing the stat-of-the-art substantially.
</dc:description>
 <dc:description>Comment: To appear in IEEE Trans. on Image Processing, 2017</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-12-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07576</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2629443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07586</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic communicability and epidemic spread: a case study on an
  empirical dynamic contact network</dc:title>
 <dc:creator>Chen, Isabel</dc:creator>
 <dc:creator>Benzi, Michele</dc:creator>
 <dc:creator>Chang, Howard H.</dc:creator>
 <dc:creator>Hertzberg, Vicki S.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We analyze a recently proposed temporal centrality measure applied to an
empirical network based on person-to-person contacts in an emergency department
of a busy urban hospital. We show that temporal centrality identifies a
distinct set of top-spreaders than centrality based on the time-aggregated
binarized contact matrix, so that taken together, the accuracy of capturing
top-spreaders improves significantly. However, with respect to predicting
epidemic outcome, the temporal measure does not necessarily outperform less
complex measures. Our results also show that other temporal markers such as
duration observed and the time of first appearance in the the network can be
used in a simple predictive model to generate predictions that capture the
trend of the observed data remarkably well.
</dc:description>
 <dc:description>Comment: 31 pages, 15 figures, 11 tables; typos corrected; references added;
  Figure 3 added; some changes to the conclusion and introduction</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07593</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sufficiency on the Stock Market</dc:title>
 <dc:creator>Harremo&#xeb;s, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Finance - Portfolio Management</dc:subject>
 <dc:subject>91B25</dc:subject>
 <dc:description>  It is well-known that there are a number of relations between theoretical
finance theory and information theory. Some of these relations are exact and
some are approximate. In this paper we will explore some of these relations and
determine under which conditions the relations are exact. It turns out that
portfolio theory always leads to Bregman divergences. The Bregman divergence is
only proportional to information divergence in situations that are essentially
equal to the type of gambling studied by Kelly. This can be related an abstract
sufficiency condition.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07593</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07596</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Hill-Climber for Multi-Objective Pseudo-Boolean Optimization</dc:title>
 <dc:creator>Chicano, Francisco</dc:creator>
 <dc:creator>Whitley, Darrell</dc:creator>
 <dc:creator>Tinos, Renato</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Local search algorithms and iterated local search algorithms are a basic
technique. Local search can be a stand along search methods, but it can also be
hybridized with evolutionary algorithms. Recently, it has been shown that it is
possible to identify improving moves in Hamming neighborhoods for k-bounded
pseudo-Boolean optimization problems in constant time. This means that local
search does not need to enumerate neighborhoods to find improving moves. It
also means that evolutionary algorithms do not need to use random mutation as a
operator, except perhaps as a way to escape local optima. In this paper, we
show how improving moves can be identified in constant time for multiobjective
problems that are expressed as k-bounded pseudo-Boolean functions. In
particular, multiobjective forms of NK Landscapes and Mk Landscapes are
considered.
</dc:description>
 <dc:description>Comment: Paper accepted for publication in the 16th European Conference on
  Evolutionary Computation for Combinatorial Optimisation (EvoCOP 2016)</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07597</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Flow Control and Scheduling for Shared FIFO Queues over Wireless
  Networks</dc:title>
 <dc:creator>Zhou, Shanyu</dc:creator>
 <dc:creator>Seferoglu, Hulya</dc:creator>
 <dc:creator>Koyuncu, Erdem</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We investigate the performance of First-In, First-Out (FIFO) queues over
wireless networks. We characterize the stability region of a general scenario
where an arbitrary number of FIFO queues, which are served by a wireless
medium, are shared by an arbitrary number of flows. In general, the stability
region of this system is non-convex. Thus, we develop a convex inner-bound on
the stability region, which is provably tight in certain cases. The convexity
of the inner bound allows us to develop a resource allocation scheme; dFC.
Based on the structure of dFC, we develop a stochastic flow control and
scheduling algorithm; qFC. We show that qFC achieves optimal operating point in
the convex inner bound. Simulation results show that our algorithms
significantly improve the throughput of wireless networks with FIFO queues, as
compared to the well-known queue-based flow control and max-weight scheduling.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07597</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07604</identifier>
 <datestamp>2017-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum distance functions of complete intersections</dc:title>
 <dc:creator>Pitones, Yuriko</dc:creator>
 <dc:creator>Martinez-Bernal, Jose</dc:creator>
 <dc:creator>Villarreal, Rafael H.</dc:creator>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>13P25, 94B60, 11T71</dc:subject>
 <dc:description>  We study the footprint function, with respect to a monomial order, of
complete intersection graded ideals in a polynomial ring with coefficients in a
field. For graded ideals of dimension one, whose initial ideal is a complete
intersection, we give a formula for the footprint function and a sharp lower
bound for the corresponding minimum distance function. This allows us to
recover a formula for the minimum distance of an affine cartesian code and the
fact that in this case the minimum distance and the footprint functions
coincide. Then we present an extension of a result of Alon and F\&quot;uredi, about
coverings of the cube $\{0,1\}^n$ by affine hyperplanes, in terms of the
regularity of a vanishing ideal.
</dc:description>
 <dc:description>Comment: Journal of Algebra and its Applications, to appear. arXiv admin note:
  text overlap with arXiv:1512.06868</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07604</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07613</identifier>
 <datestamp>2017-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Edge coloring in unstructured CFD codes</dc:title>
 <dc:creator>Giuliani, Andrew</dc:creator>
 <dc:creator>Krivodonova, Lilia</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We propose a way of preventing race conditions in the evaluation of the
surface integral contribution in discontinuous Galerkin and finite volume flow
solvers by coloring the edges (or faces) of the computational mesh. In this
work we use a partitioning algorithm that separates the edges of triangular
elements into three groups and the faces of quadrangular and tetrahedral
elements into four groups; we then extend this partitioning to adaptively
refined, nonconforming meshes. We use the ascribed coloring to reduce code
memory requirements and optimize accessing the elemental data in memory. This
process reduces memory access latencies and speeds up computations on graphics
processing units.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2017-04-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07613</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07621</identifier>
 <datestamp>2017-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revealing Fundamental Physics from the Daya Bay Neutrino Experiment
  using Deep Neural Networks</dc:title>
 <dc:creator>Racah, Evan</dc:creator>
 <dc:creator>Ko, Seyoon</dc:creator>
 <dc:creator>Sadowski, Peter</dc:creator>
 <dc:creator>Bhimji, Wahid</dc:creator>
 <dc:creator>Tull, Craig</dc:creator>
 <dc:creator>Oh, Sang-Yun</dc:creator>
 <dc:creator>Baldi, Pierre</dc:creator>
 <dc:creator>Prabhat</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Experiments in particle physics produce enormous quantities of data that must
be analyzed and interpreted by teams of physicists. This analysis is often
exploratory, where scientists are unable to enumerate the possible types of
signal prior to performing the experiment. Thus, tools for summarizing,
clustering, visualizing and classifying high-dimensional data are essential. In
this work, we show that meaningful physical content can be revealed by
transforming the raw data into a learned high-level representation using deep
neural networks, with measurements taken at the Daya Bay Neutrino Experiment as
a case study. We further show how convolutional deep neural networks can
provide an effective classification filter with greater than 97% accuracy
across different classes of physics events, significantly better than other
machine learning approaches.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-12-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07621</dc:identifier>
 <dc:identifier>doi:10.1109/ICMLA.2016.0160</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07625</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Method for RFO Estimation Using Phase Analysis of Pilot Symbols in
  OFDM Systems</dc:title>
 <dc:creator>Lee, Yong Chan</dc:creator>
 <dc:creator>Jang, Won Chol</dc:creator>
 <dc:creator>Sin, Yong Hak</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In this paper, a method for CFO/RFO estimation based on proportional
coefficients extraction in OFDM system is proposed, which may be applied to any
pilot symbol pattern.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07629</identifier>
 <datestamp>2016-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Computational Complexity of Duality</dc:title>
 <dc:creator>Friedland, Shmuel</dc:creator>
 <dc:creator>Lim, Lek-Heng</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>15B48, 52A41, 65F35, 90C46, 90C60</dc:subject>
 <dc:description>  We show that for any given norm ball or proper cone, weak membership in its
dual ball or dual cone is polynomial-time reducible to weak membership in the
given ball or cone. A consequence is that the weak membership or membership
problem for a ball or cone is NP-hard if and only if the corresponding problem
for the dual ball or cone is NP-hard. In a similar vein, we show that
computation of the dual norm of a given norm is polynomial-time reducible to
computation of the given norm. This extends to convex functions satisfying a
polynomial growth condition: for such a given function, computation of its
Fenchel dual/conjugate is polynomial-time reducible to computation of the given
function. Hence the computation of a norm or a convex function of
polynomial-growth is NP-hard if and only if the computation of its dual norm or
Fenchel dual is NP-hard. We discuss implications of these results on the weak
membership problem for a symmetric convex body and its polar dual, the
polynomial approximability of Mahler volume, and the weak membership problem
for the epigraph of a convex function with polynomial growth and that of its
Fenchel dual.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-07-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07630</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining Maps and Street Level Images for Building Height and Facade
  Estimation</dc:title>
 <dc:creator>Yuan, Jiangye</dc:creator>
 <dc:creator>Cheriyadat, Anil M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a method that integrates two widely available data sources,
building footprints from 2D maps and street level images, to derive valuable
information that is generally difficult to acquire -- building heights and
building facade masks in images. Building footprints are elevated in world
coordinates and projected onto images. Building heights are estimated by
scoring projected footprints based on their alignment with building features in
images. Building footprints with estimated heights can be converted to simple
3D building models, which are projected back to images to identify buildings.
In this procedure, accurate camera projections are critical. However, camera
position errors inherited from external sensors commonly exist, which adversely
affect results. We derive a solution to precisely locate cameras on maps using
correspondence between image features and building footprints. Experiments on
real-world datasets show the promise of our method.
</dc:description>
 <dc:description>Comment: UrbanGIS '16 Proceedings of the 2nd ACM SIGSPATIAL Workshop on Smart
  Cities and Urban Analytics</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:date>2016-12-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07633</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Generalized Reed-Muller codes and the radical powers of a modular
  algebra</dc:title>
 <dc:creator>Andriatahiny, Harinaivo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>16N40, 94B05, 12E05</dc:subject>
 <dc:description>  First, a new proof of Berman and Charpin's characterization of the
Reed-Muller codes over the binary field or over an arbitrary prime field is
presented. These codes are considered as the powers of the radical of a modular
algebra. Secondly, the same method is used for the study of the Generalized
Reed-Muller codes over a non prime field.
</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07648</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Grassmannian Graph Approach to Affine Invariant Feature Matching</dc:title>
 <dc:creator>Moyou, Mark</dc:creator>
 <dc:creator>Corring, John</dc:creator>
 <dc:creator>Peter, Adrian</dc:creator>
 <dc:creator>Rangarajan, Anand</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present a novel and practical approach to address one of the
longstanding problems in computer vision: 2D and 3D affine invariant feature
matching. Our Grassmannian Graph (GrassGraph) framework employs a two stage
procedure that is capable of robustly recovering correspondences between two
unorganized, affinely related feature (point) sets. The first stage maps the
feature sets to an affine invariant Grassmannian representation, where the
features are mapped into the same subspace. It turns out that coordinate
representations extracted from the Grassmannian differ by an arbitrary
orthonormal matrix. In the second stage, by approximating the Laplace-Beltrami
operator (LBO) on these coordinates, this extra orthonormal factor is
nullified, providing true affine-invariant coordinates which we then utilize to
recover correspondences via simple nearest neighbor relations. The resulting
GrassGraph algorithm is empirically shown to work well in non-ideal scenarios
with noise, outliers, and occlusions. Our validation benchmarks use an
unprecedented 440,000+ experimental trials performed on 2D and 3D datasets,
with a variety of parameter settings and competing methods. State-of-the-art
performance in the majority of these extensive evaluations confirm the utility
of our method.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07649</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Training of Deep Fully-connected Continuous CRF with
  Task-specific Loss</dc:title>
 <dc:creator>Liu, Fayao</dc:creator>
 <dc:creator>Lin, Guosheng</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent works on deep conditional random fields (CRF) have set new records on
many vision tasks involving structured predictions. Here we propose a
fully-connected deep continuous CRF model for both discrete and continuous
labelling problems. We exemplify the usefulness of the proposed model on
multi-class semantic labelling (discrete) and the robust depth estimation
(continuous) problems.
  In our framework, we model both the unary and the pairwise potential
functions as deep convolutional neural networks (CNN), which are jointly
learned in an end-to-end fashion. The proposed method possesses the main
advantage of continuously-valued CRF, which is a closed-form solution for the
Maximum a posteriori (MAP) inference.
  To better adapt to different tasks, instead of using the commonly employed
maximum likelihood CRF parameter learning protocol, we propose task-specific
loss functions for learning the CRF parameters.
  It enables direct optimization of the quality of the MAP estimates during the
course of learning.
  Specifically, we optimize the multi-class classification loss for the
semantic labelling task and the Turkey's biweight loss for the robust depth
estimation problem.
  Experimental results on the semantic labelling and robust depth estimation
tasks demonstrate that the proposed method compare favorably against both
baseline and state-of-the-art methods.
  In particular, we show that although the proposed deep CRF model is
continuously valued, with the equipment of task-specific loss, it achieves
impressive results even on discrete labelling tasks.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07649</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2017.2675166</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07661</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DehazeNet: An End-to-End System for Single Image Haze Removal</dc:title>
 <dc:creator>Cai, Bolun</dc:creator>
 <dc:creator>Xu, Xiangmin</dc:creator>
 <dc:creator>Jia, Kui</dc:creator>
 <dc:creator>Qing, Chunmei</dc:creator>
 <dc:creator>Tao, Dacheng</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Single image haze removal is a challenging ill-posed problem. Existing
methods use various constraints/priors to get plausible dehazing solutions. The
key to achieve haze removal is to estimate a medium transmission map for an
input hazy image. In this paper, we propose a trainable end-to-end system
called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy
image as input, and outputs its medium transmission map that is subsequently
used to recover a haze-free image via atmospheric scattering model. DehazeNet
adopts Convolutional Neural Networks (CNN) based deep architecture, whose
layers are specially designed to embody the established assumptions/priors in
image dehazing. Specifically, layers of Maxout units are used for feature
extraction, which can generate almost all haze-relevant features. We also
propose a novel nonlinear activation function in DehazeNet, called Bilateral
Rectified Linear Unit (BReLU), which is able to improve the quality of
recovered haze-free image. We establish connections between components of the
proposed DehazeNet and those used in existing methods. Experiments on benchmark
images show that DehazeNet achieves superior performance over existing methods,
yet keeps efficient and easy to use.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07661</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2598681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07670</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deterministic sub-linear space LCE data structures with efficient
  construction</dc:title>
 <dc:creator>Tanimura, Yuka</dc:creator>
 <dc:creator>I, Tomohiro</dc:creator>
 <dc:creator>Bannai, Hideo</dc:creator>
 <dc:creator>Inenaga, Shunsuke</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:creator>Takeda, Masayuki</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a string $S$ of $n$ symbols, a longest common extension query
$\mathsf{LCE}(i,j)$ asks for the length of the longest common prefix of the
$i$th and $j$th suffixes of $S$. LCE queries have several important
applications in string processing, perhaps most notably to suffix sorting.
Recently, Bille et al. (J. Discrete Algorithms 25:42-50, 2014, Proc. CPM 2015:
65-76) described several data structures for answering LCE queries that offers
a space-time trade-off between data structure size and query time. In
particular, for a parameter $1 \leq \tau \leq n$, their best deterministic
solution is a data structure of size $O(n/\tau)$ which allows LCE queries to be
answered in $O(\tau)$ time. However, the construction time for all
deterministic versions of their data structure is quadratic in $n$. In this
paper, we propose a deterministic solution that achieves a similar space-time
trade-off of $O(\tau\min\{\log\tau,\log\frac{n}{\tau}\})$ query time using
$O(n/\tau)$ space, but significantly improve the construction time to
$O(n\tau)$.
</dc:description>
 <dc:description>Comment: updated title</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07678</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extremal Relations Between Shannon Entropy and $\ell_{\alpha}$-Norm</dc:title>
 <dc:creator>Sakai, Yuta</dc:creator>
 <dc:creator>Iwata, Ken-ichi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The paper examines relationships between the Shannon entropy and the
$\ell_{\alpha}$-norm for $n$-ary probability vectors, $n \ge 2$. More
precisely, we investigate the tight bounds of the $\ell_{\alpha}$-norm with a
fixed Shannon entropy, and vice versa. As applications of the results, we
derive the tight bounds between the Shannon entropy and several information
measures which are determined by the $\ell_{\alpha}$-norm, e.g., R\'{e}nyi
entropy, Tsallis entropy, the $R$-norm information, and some diversity indices.
Moreover, we apply these results to uniformly focusing channels. Then, we show
the tight bounds of Gallager's $E_{0}$ functions with a fixed mutual
information under a uniform input distribution.
</dc:description>
 <dc:description>Comment: a short version was submitted to ISIT'2016</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07679</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complex Contagion of Campaign Donations</dc:title>
 <dc:creator>Traag, V. A.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Money is central in US politics, and most campaign contributions stem from a
tiny, wealthy elite. Like other political acts, campaign donations are known to
be socially contagious. We study how campaign donations diffuse through a
network of more than 50 000 elites and examine how connectivity among previous
donors reinforces contagion. We find that the diffusion of donations is driven
by independent reinforcement contagion: people are more likely to donate when
exposed to donors from different social groups than when they are exposed to
equally many donors from the same group. Counter-intuitively, being exposed to
one side may increase donations to the other side. Although the effect is weak,
simultaneous cross-cutting exposure makes donation somewhat less likely.
Finally, the independence of donors in the beginning of a campaign predicts the
amount of money that is raised throughout a campaign. We theorize that people
infer population-wide estimates from their local observations, with elites
assessing the viability of candidates, possibly opposing candidates in response
to local support. Our findings suggest that theories of complex contagions need
refinement and that political campaigns should target multiple communities.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07679</dc:identifier>
 <dc:identifier>PLoS ONE 2016, 11(4): e0153539</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0153539</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07686</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convergence and Density Evolution of a Low-Complexity MIMO Detector
  based on Forward-Backward Recursion over a Ring</dc:title>
 <dc:creator>Yoon, Seokhyun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Convergence and density evolution of a low complexity, iterative MIMO
detection based on belief propagation (BP) over a ring-type pair-wise graph are
presented in this paper. The detection algorithm to be considered is
effectively a forward-backward recursion and was originally proposed in [13],
where the link level performance and the convergence for Gaussian input were
analyzed. Presented here are the convergence proof for discrete alphabet and
the density evolution framework for binary input to give an asymptotic
performance in terms of average SINR and bit error rate (BER) without channel
coding. The BER curve obtained via density evolution shows a good match with
simulation results, verifying the effectiveness of the density evolution
analysis and the performance of the detection algorithm.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07699</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Models for Metamath</dc:title>
 <dc:creator>Carneiro, Mario</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>03C95 (Primary), 03B22, 03B70 (Secondary)</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.3</dc:subject>
 <dc:description>  Although some work has been done on the metamathematics of Metamath, there
has not been a clear definition of a model for a Metamath formal system. We
define the collection of models of an arbitrary Metamath formal system, both
for tree-based and string-based representations. This definition is
demonstrated with examples for propositional calculus, $\textsf{ZFC}$ set
theory with classes, and Hofstadter's MIU system, with applications for proving
that statements are not provable, showing consistency of the main Metamath
database (assuming $\textsf{ZFC}$ has a model), developing new independence
proofs, and proving a form of G\&quot;odel's completeness theorem.
</dc:description>
 <dc:description>Comment: 15 pages, 0 figures; submitted to CICM 2016</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07699</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07700</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying Influential Spreaders of Epidemics on Community Networks</dc:title>
 <dc:creator>Luo, Shi-Long</dc:creator>
 <dc:creator>Gong, Kai</dc:creator>
 <dc:creator>Kang, Li</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  An efficient strategy for the identification of influential spreaders that
could be used to control epidemics within populations would be of considerable
importance. Generally, populations are characterized by its community
structures and by the heterogeneous distributions of weak ties among nodes
bridging over communities. A strategy for community networks capable of
identifying influential spreaders that accelerate the spread of disease is here
proposed. In this strategy, influential spreaders serve as target nodes. This
is based on the idea that, in k-shell decomposition, weak ties and strong ties
are processed separately. The strategy was used on empirical networks
constructed from online social networks, and results indicated that this
strategy is more accurate than other strategies. Its effectiveness stems from
the patterns of connectivity among neighbors, and it successfully identified
the important nodes. In addition, the performance of the strategy remained
robust even when there were errors in the structure of the network.
</dc:description>
 <dc:description>Comment: 10 pages, 7 figures, 1 table</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07701</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Near-Optimal Signal Detector Based on Structured Compressive Sensing for
  Massive SM-MIMO</dc:title>
 <dc:creator>Gao, Zhen</dc:creator>
 <dc:creator>Dai, Linglong</dc:creator>
 <dc:creator>Qi, Chenhao</dc:creator>
 <dc:creator>Yuen, Chau</dc:creator>
 <dc:creator>Wang, Zhaocheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Massive spatial modulation (SM)-MIMO, which employs massive low-cost antennas
but few power-hungry transmit radio frequency (RF) chains at the transmitter,
is recently proposed to provide both high spectrum efficiency and energy
efficiency for future green communications. However, in massive SM-MIMO, the
optimal maximum likelihood (ML) detector has the prohibitively high complexity,
while state-of-the-art low-complexity detectors for conventional small-scale
SM-MIMO suffer from an obvious performance loss. In this paper, by exploiting
the structured sparsity of multiple SM signals, we propose a low-complexity
signal detector based on structured compressive sensing (SCS) to improve the
signal detection performance. Specifically, we first propose the grouped
transmission scheme at the transmitter, where multiple SM signals in several
continuous time slots are grouped to carry the common spatial constellation
symbol to introduce the desired structured sparsity. Accordingly, a structured
subspace pursuit (SSP) algorithm is proposed at the receiver to jointly detect
multiple SM signals by leveraging the structured sparsity. In addition, we also
propose the SM signal interleaving to permute SM signals in the same
transmission group, whereby the channel diversity can be exploited to further
improve the signal detection performance. Theoretical analysis quantifies the
performance gain from SM signal interleaving, and simulation results
demonstrate the near-optimal performance of the proposed scheme.
</dc:description>
 <dc:description>Comment: 8 pages 7 figures, accepted by IEEE Transactions on Vehicular
  Technology. Keywords: Spatial modulation (SM), massive MIMO, signal
  detection, compressive sensing (CS), signal interleaving</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-04-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07701</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2557625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07702</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correlated and Coarse equilibria of Single-item auctions</dc:title>
 <dc:creator>Feldman, Michal</dc:creator>
 <dc:creator>Lucier, Brendan</dc:creator>
 <dc:creator>Nisan, Noam</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study correlated equilibria and coarse equilibria of simple first-price
single-item auctions in the simplest auction model of full information. Nash
equilibria are known to always yield full efficiency and a revenue that is at
least the second-highest value. We prove that the same is true for all
correlated equilibria, even those in which agents overbid -- i.e., bid above
their values.
  Coarse equilibria, in contrast, may yield lower efficiency and revenue. We
show that the revenue can be as low as 26% of the second-highest value in a
coarse equilibrium, even if agents are assumed not to overbid, and this is
tight. We also show that when players do not overbid, the worst-case bound on
social welfare at coarse equilibrium improves from 63% of the highest value to
81%, and this bound is tight as well.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07702</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07709</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Categorization of Stringed Instruments with Multifractal Detrended
  Fluctuation Analysis</dc:title>
 <dc:creator>Banerjee, Archi</dc:creator>
 <dc:creator>Sanyal, Shankha</dc:creator>
 <dc:creator>Guhathakurata, Tarit</dc:creator>
 <dc:creator>Sengupta, Ranjan</dc:creator>
 <dc:creator>Ghosh, Dipak</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Nonlinear Sciences - Chaotic Dynamics</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Categorization is crucial for content description in archiving of music
signals. On many occasions, human brain fails to classify the instruments
properly just by listening to their sounds which is evident from the human
response data collected during our experiment. Some previous attempts to
categorize several musical instruments using various linear analysis methods
required a number of parameters to be determined. In this work, we attempted to
categorize a number of string instruments according to their mode of playing
using latest-state-of-the-art robust non-linear methods. For this, 30 second
sound signals of 26 different string instruments from all over the world were
analyzed with the help of non linear multifractal analysis (MFDFA) technique.
The spectral width obtained from the MFDFA method gives an estimate of the
complexity of the signal. From the variation of spectral width, we observed
distinct clustering among the string instruments according to their mode of
playing. Also there is an indication that similarity in the structural
configuration of the instruments is playing a major role in the clustering of
their spectral width. The observations and implications are discussed in
detail.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figures; Presented in Frontiers of Research in Speech and
  Music, held at IIT Kharagpur, 23-24 November 2015</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07709</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07714</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Log-Normal Matrix Completion for Large Scale Link Prediction</dc:title>
 <dc:creator>Mohtashemi, Brian</dc:creator>
 <dc:creator>Ketseoglou, Thomas</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The ubiquitous proliferation of online social networks has led to the
widescale emergence of relational graphs expressing unique patterns in link
formation and descriptive user node features. Matrix Factorization and
Completion have become popular methods for Link Prediction due to the low rank
nature of mutual node friendship information, and the availability of parallel
computer architectures for rapid matrix processing. Current Link Prediction
literature has demonstrated vast performance improvement through the
utilization of sparsity in addition to the low rank matrix assumption. However,
the majority of research has introduced sparsity through the limited L1 or
Frobenius norms, instead of considering the more detailed distributions which
led to the graph formation and relationship evolution. In particular, social
networks have been found to express either Pareto, or more recently discovered,
Log Normal distributions. Employing the convexity-inducing Lovasz Extension, we
demonstrate how incorporating specific degree distribution information can lead
to large scale improvements in Matrix Completion based Link prediction. We
introduce Log-Normal Matrix Completion (LNMC), and solve the complex
optimization problem by employing Alternating Direction Method of Multipliers.
Using data from three popular social networks, our experiments yield up to 5%
AUC increase over top-performing non-structured sparsity based methods.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07714</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07721</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Low Rank Approximation of Implicit Functions of a Matrix</dc:title>
 <dc:creator>Woodruff, David P.</dc:creator>
 <dc:creator>Zhong, Peilin</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We study distributed low rank approximation in which the matrix to be
approximated is only implicitly represented across the different servers. For
example, each of $s$ servers may have an $n \times d$ matrix $A^t$, and we may
be interested in computing a low rank approximation to $A = f(\sum_{t=1}^s
A^t)$, where $f$ is a function which is applied entrywise to the matrix
$\sum_{t=1}^s A^t$. We show for a wide class of functions $f$ it is possible to
efficiently compute a $d \times d$ rank-$k$ projection matrix $P$ for which
$\|A - AP\|_F^2 \leq \|A - [A]_k\|_F^2 + \varepsilon \|A\|_F^2$, where $AP$
denotes the projection of $A$ onto the row span of $P$, and $[A]_k$ denotes the
best rank-$k$ approximation to $A$ given by the singular value decomposition.
The communication cost of our protocols is $d \cdot (sk/\varepsilon)^{O(1)}$,
and they succeed with high probability. Our framework allows us to efficiently
compute a low rank approximation to an entry-wise softmax, to a Gaussian kernel
expansion, and to $M$-Estimators applied entrywise (i.e., forms of robust low
rank approximation). We also show that our additive error approximation is best
possible, in the sense that any protocol achieving relative error for these
problems requires significantly more communication. Finally, we experimentally
validate our algorithms on real datasets.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07723</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-overlapping matrices</dc:title>
 <dc:creator>Barcucci, Elena</dc:creator>
 <dc:creator>Bernini, Antonio</dc:creator>
 <dc:creator>Bilotta, Stefano</dc:creator>
 <dc:creator>Pinzani, Renzo</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Two matrices are said non-overlapping if one of them can not be put on the
other one in a way such that the corresponding entries coincide. We provide a
set of non-overlapping binary matrices and a formula to enumerate it which
involves the $k$-generalized Fibonacci numbers. Moreover, the generating
function for the enumerating sequence is easily seen to be rational.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07723</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07724</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Certified Context-Free Parsing: A formalisation of Valiant's Algorithm
  in Agda</dc:title>
 <dc:creator>Bernardy, Jean-Philippe</dc:creator>
 <dc:creator>Jansson, Patrik</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>F.4.2</dc:subject>
 <dc:description>  Valiant (1975) has developed an algorithm for recognition of context free
languages. As of today, it remains the algorithm with the best asymptotic
complexity for this purpose. In this paper, we present an algebraic
specification, implementation, and proof of correctness of a generalisation of
Valiant's algorithm. The generalisation can be used for recognition, parsing or
generic calculation of the transitive closure of upper triangular matrices. The
proof is certified by the Agda proof assistant. The certification is
representative of state-of-the-art methods for specification and proofs in
proof assistants based on type-theory. As such, this paper can be read as a
tutorial for the Agda system.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07724</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 2 (June 14,
  2016) lmcs:1638</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07741</identifier>
 <datestamp>2016-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Touristic site attractiveness seen through Twitter</dc:title>
 <dc:creator>Bassolas, Aleix</dc:creator>
 <dc:creator>Lenormand, Maxime</dc:creator>
 <dc:creator>Tugores, Ant&#xf2;nia</dc:creator>
 <dc:creator>Gon&#xe7;alves, Bruno</dc:creator>
 <dc:creator>Ramasco, Jos&#xe9; J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Tourism is becoming a significant contributor to medium and long range
travels in an increasingly globalized world. Leisure traveling has an important
impact on the local and global economy as well as on the environment. The study
of touristic trips is thus raising a considerable interest. In this work, we
apply a method to assess the attractiveness of 20 of the most popular touristic
sites worldwide using geolocated tweets as a proxy for human mobility. We first
rank the touristic sites based on the spatial distribution of the visitors'
place of residence. The Taj Mahal, the Pisa Tower and the Eiffel Tower appear
consistently in the top 5 in these rankings. We then pass to a coarser scale
and classify the travelers by country of residence. Touristic site's visiting
figures are then studied by country of residence showing that the Eiffel Tower,
Times Square and the London Tower welcome the majority of the visitors of each
country. Finally, we build a network linking sites whenever a user has been
detected in more than one site. This allow us to unveil relations between
touristic sites and find which ones are more tightly interconnected.
</dc:description>
 <dc:description>Comment: 8 pages and 5 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07741</dc:identifier>
 <dc:identifier>EPJ Data Science 5, 12 (2016)</dc:identifier>
 <dc:identifier>doi:10.1140/epjds/s13688-016-0073-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07742</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing Object-oriented Software for Understanding and Documentation</dc:title>
 <dc:creator>AL-msie'deen, Ra'Fat</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Understanding or comprehending source code is one of the core activities of
software engineering. Understanding object-oriented source code is essential
and required when a programmer maintains, migrates, reuses, documents or
enhances source code. The source code that is not comprehended cannot be
changed. The comprehension of object-oriented source code is a difficult
problem solving process. In order to document object-oriented software system
there are needs to understand its source code. To do so, it is necessary to
mine source code dependencies in addition to quantitative information in source
code such as the number of classes. This paper proposes an automatic approach,
which aims to document object-oriented software by visualizing its source code.
The design of the object-oriented source code and its main characteristics are
represented in the visualization. Package content, class information,
relationships between classes, dependencies between methods and software
metrics is displayed. The extracted views are very helpful to understand and
document the object-oriented software. The novelty of this approach is the
exploiting of code dependencies and quantitative information in source code to
document object-oriented software efficiently by means of a set of graphs. To
validate the approach, it has been applied to several case studies. The results
of this evaluation showed that most of the object-oriented software systems
have been documented correctly.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07742</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 13, No. 5, 2015</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07754</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning Based Semantic Video Indexing and Retrieval</dc:title>
 <dc:creator>Podlesnaya, Anna</dc:creator>
 <dc:creator>Podlesnyy, Sergey</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We share the implementation details and testing results for video retrieval
system based exclusively on features extracted by convolutional neural
networks. We show that deep learned features might serve as universal signature
for semantic content of video useful in many search and retrieval tasks. We
further show that graph-based storage structure for video index allows to
efficiently retrieving the content with complicated spatial and temporal search
queries.
</dc:description>
 <dc:description>Comment: 7 pages, 5 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07754</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07765</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SculptStat: Statistical Analysis of Digital Sculpting Workflows</dc:title>
 <dc:creator>Santoni, Christian</dc:creator>
 <dc:creator>Calabrese, Claudio</dc:creator>
 <dc:creator>Di Renzo, Francesco</dc:creator>
 <dc:creator>Pellacini, Fabio</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Targeted user studies are often employed to measure how well artists can
perform specific tasks. But these studies cannot properly describe editing
workflows as wholes, since they guide the artists both by choosing the tasks
and by using simplified interfaces. In this paper, we investigate digital
sculpting workflows used to produce detailed models. In our experiment design,
artists can choose freely what and how to model. We recover whole-workflow
trends with sophisticated statistical analyzes and validate these trends with
goodness-of-fits measures. We record brush strokes and mesh snapshots by
instrumenting a sculpting program and analyze the distribution of these
properties and their spatial and temporal characteristics. We hired expert
artists that can produce relatively sophisticated models in short time, since
their workflows are representative of best practices. We analyze 13 meshes
corresponding to roughly 25 thousand strokes in total. We found that artists
work mainly with short strokes, with average stroke length dependent on model
features rather than the artist itself. Temporally, artists do not work
coarse-to-fine but rather in bursts. Spatially, artists focus on some selected
regions by dedicating different amounts of edits and by applying different
techniques. Spatio-temporally, artists return to work on the same area multiple
times without any apparent periodicity. We release the entire dataset and all
code used for the analyzes as reference for the community.
</dc:description>
 <dc:description>Comment: 9 pages, 8 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07765</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07768</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Capacity of Retransmission Schemes - A Recurrence Relation
  Approach</dc:title>
 <dc:creator>Larsson, Peter</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:creator>Al-Zubaidy, Hussein</dc:creator>
 <dc:creator>Rasmussen, Lars K.</dc:creator>
 <dc:creator>Skoglund, Mikael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the effective capacity performance measure of persistent- and
truncated-retransmission schemes that can involve any combination of multiple
transmissions per packet, multiple communication modes, or multiple packet
communication. We present a structured unified analytical approach, based on a
random walk model and recurrence relation formulation, and give exact effective
capacity expressions for persistent hybrid automatic repeat request (HARQ) and
for truncated-retransmission schemes. For the latter, effective capacity
expressions are given for systems with finite (infinite) time horizon on an
algebraic (spectral radius-based) form of a special block companion matrix. In
contrast to prior HARQ models, assuming infinite time horizon, the proposed
method does not involve a non-trivial per case modeling step. We give effective
capacity expressions for several important cases that have not been addressed
before, e.g. persistent-HARQ, truncated-HARQ, network-coded ARQ (NC-ARQ),
two-mode-ARQ, and multilayer-ARQ. We propose an alternative QoS parameter
(instead of the commonly used moment generating function parameter) that
represents explicitly the target delay and the delay violation probability.
This also enables closed-form expressions for many of the studied systems.
Moreover, we use the recently proposed matrix-exponential distributed (MED)
modeling of wireless fading channels to provide the basis for numerous new
effective capacity results for HARQ.
</dc:description>
 <dc:description>Comment: 17 pages, 10 figures, revised/compacted version of the one submitted
  to Trans. on Comm</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07776</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The ecology of social interactions in online and offline environments</dc:title>
 <dc:creator>Antoci, Angelo</dc:creator>
 <dc:creator>Delfino, Alexia</dc:creator>
 <dc:creator>Paglieri, Fabio</dc:creator>
 <dc:creator>Sabatini, Fabio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Quantitative Finance - General Finance</dc:subject>
 <dc:description>  The rise in online social networking has brought about a revolution in social
relations. However, its effects on offline interactions and its implications
for collective well-being are still not clear and are under-investigated. We
study the ecology of online and offline interaction in an evolutionary game
framework where individuals can adopt different strategies of socialization.
Our main result is that the spreading of self-protective behaviors to cope with
hostile social environments can lead the economy to non-socially optimal
stationary states.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07776</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07783</identifier>
 <datestamp>2016-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stochastic Battery Model for Aggregation of Thermostatically Controlled
  Loads</dc:title>
 <dc:creator>Khan, Sohail</dc:creator>
 <dc:creator>Shahzad, Mohsin</dc:creator>
 <dc:creator>Habib, Usman</dc:creator>
 <dc:creator>Gawlik, Wolfgang</dc:creator>
 <dc:creator>Palensky, Peter</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The potential of demand side as a frequency reserve proposes interesting
opportunity in handling imbalances due to intermittent renewable energy
sources. This paper proposes a novel approach for computing the parameters of a
stochastic battery model representing the aggregation of Thermostatically
Controlled Loads (TCLs). A hysteresis based non-disruptive control is used
using priority stack algorithm to track the reference regulation signal. The
parameters of admissible ramp-rate and the charge limits of the battery are
dynamically calculated using the information from TCLs that is the status
(on/off), availability and relative temperature distance till the switching
boundary. The approach builds on and improves on the existing research work by
providing a straight-forward mechanism for calculation of stochastic parameters
of equivalent battery model. The effectiveness of proposed approach is
demonstrated by a test case having a large number of residential TCLs tracking
a scaled down real frequency regulation signal.
</dc:description>
 <dc:description>Comment: IEEE ICIT 2016 conference</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07783</dc:identifier>
 <dc:identifier>doi:10.1109/ICIT.2016.7474812</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07789</identifier>
 <datestamp>2017-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Vectorization of Multibyte Floating Point Data Formats</dc:title>
 <dc:creator>Anderson, Andrew</dc:creator>
 <dc:creator>Gregg, David</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>B.2.4</dc:subject>
 <dc:subject>I.4.2</dc:subject>
 <dc:description>  We propose a scheme for reduced-precision representation of floating point
data on a continuum between IEEE-754 floating point types. Our scheme enables
the use of lower precision formats for a reduction in storage space
requirements and data transfer volume. We describe how our scheme can be
accelerated using existing hardware vector units on a general-purpose processor
(GPP). Exploiting native vector hardware allows us to support reduced precision
floating point with low overhead. We demonstrate that supporting reduced
precision in the compiler as opposed to using a library approach can yield a
low overhead solution for GPPs.
</dc:description>
 <dc:date>2016-01-26</dc:date>
 <dc:date>2016-07-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07789</dc:identifier>
 <dc:identifier>doi:10.1145/2967938.2967966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07790</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Topology Recognition and Leader Election in Colored Networks</dc:title>
 <dc:creator>Dereniowski, Dariusz</dc:creator>
 <dc:creator>Pelc, Andrzej</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Topology recognition and leader election are fundamental tasks in distributed
computing in networks. The first of them requires each node to find a labeled
isomorphic copy of the network, while the result of the second one consists in
a single node adopting the label 1 (leader), with all other nodes adopting the
label 0 and learning a path to the leader. We consider both these problems in
networks whose nodes are equipped with not necessarily distinct labels called
colors, and ports at each node of degree $d$ are arbitrarily numbered
$0,1,\dots, d-1$. Colored networks are generalizations both of labeled networks
and anonymous networks.
  In colored networks, topology recognition and leader election are not always
feasible. Hence we study two more general problems. The aim of the problem TOP
(resp. LE), for a colored network and for input $I$ given to its nodes, is to
solve topology recognition (resp. leader election) in this network, if this is
possible under input $I$, and to have all nodes answer &quot;unsolvable&quot; otherwise.
  We show that nodes of a network can solve problems TOP and LE, if they are
given, as input $I$, an upper bound $k$ on the number of nodes of a given
color, called the size of this color. On the other hand we show that, if the
nodes are given an input that does not bound the size of any color, then the
answer to TOP and LE must be &quot;unsolvable&quot;, even for the class of rings.
  Under the assumption that nodes are given an upper bound $k$ on the size of a
given color, we study the time of solving problems TOP and LE in the $LOCAL$.
We give an algorithm to solve each of these problems in arbitrary $n$-node
networks of diameter $D$ in time $O(kD+D\log(n/D))$. We also show that this
time is optimal, by exhibiting classes of networks in which every algorithm
solving problems TOP or LE must use time $\Omega(kD+D\log(n/D))$.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07790</dc:identifier>
 <dc:identifier>Theoretical Computer Science 621 (2016) 92-102</dc:identifier>
 <dc:identifier>doi:10.1016/j.tcs.2016.01.037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07792</identifier>
 <datestamp>2016-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Human Cooperation</dc:title>
 <dc:creator>Nay, John J.</dc:creator>
 <dc:creator>Vorobeychik, Yevgeniy</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:description>  The Prisoner's Dilemma has been a subject of extensive research due to its
importance in understanding the ever-present tension between individual
self-interest and social benefit. A strictly dominant strategy in a Prisoner's
Dilemma (defection), when played by both players, is mutually harmful.
Repetition of the Prisoner's Dilemma can give rise to cooperation as an
equilibrium, but defection is as well, and this ambiguity is difficult to
resolve. The numerous behavioral experiments investigating the Prisoner's
Dilemma highlight that players often cooperate, but the level of cooperation
varies significantly with the specifics of the experimental predicament. We
present the first computational model of human behavior in repeated Prisoner's
Dilemma games that unifies the diversity of experimental observations in a
systematic and quantitatively reliable manner. Our model relies on data we
integrated from many experiments, comprising 168,386 individual decisions. The
computational model is composed of two pieces: the first predicts the
first-period action using solely the structural game parameters, while the
second predicts dynamic actions using both game parameters and history of play.
Our model is extremely successful not merely at fitting the data, but in
predicting behavior at multiple scales in experimental designs not used for
calibration, using only information about the game structure. We demonstrate
the power of our approach through a simulation analysis revealing how to best
promote human cooperation.
</dc:description>
 <dc:description>Comment: Added references. New inline citation style. Added small portions of
  text. Re-compiled Rmarkdown file with updated ggplot2 so small aesthetic
  changes to plots</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07792</dc:identifier>
 <dc:identifier>PLoS ONE 11(5): e0155656 (2016)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0155656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07793</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer Science Programs, Goals, Student Learning Outcomes and their
  Assessment</dc:title>
 <dc:creator>Kanabar, Vijay</dc:creator>
 <dc:creator>Temkin, Anatoly</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>K.3.2, K.3.m</dc:subject>
 <dc:description>  In this paper we describe the process used by MET Computer Science to
identify programs, goals, and student learning outcomes for all our programs
and graduate certificates. We illustrate how we started the process of
assessing learning outcomes for our programs and present actual assessment
results from the data collected for two programs that went through
accreditation--it describes sample direct and indirect assessment data from two
of our programs.
</dc:description>
 <dc:description>Comment: 20 pages, 5 figure, Proceedings of the 11th Annual CSECS Conference,
  Boston, USA. ISSN 1313-8624</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07793</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07795</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed User Association in Energy Harvesting Small Cell Networks: A
  Probabilistic Model</dc:title>
 <dc:creator>Maghsudi, Setareh</dc:creator>
 <dc:creator>Hossain, Ekram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider a distributed downlink user association problem in a small cell
network, where small cells obtain the required energy for providing wireless
services to users through ambient energy harvesting. Since energy harvesting is
opportunistic in nature, the amount of harvested energy is a random variable,
without any a priori known characteristics. Moreover, since users arrive in the
network randomly and require different wireless services, the energy
consumption is a random variable as well. In this paper, we propose a
probabilistic framework to mathematically model and analyze the random behavior
of energy harvesting and energy consumption in dense small cell networks.
Furthermore, as acquiring (even statistical) channel and network knowledge is
very costly in a distributed dense network, we develop a bandit-theoretical
formulation for distributed user association when no information is available
at users
</dc:description>
 <dc:description>Comment: 27 Pages, Single-Column</dc:description>
 <dc:date>2016-01-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07795</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2647946</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07797</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reachability Oracles for Directed Transmission Graphs</dc:title>
 <dc:creator>Kaplan, Haim</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:creator>Roditty, Liam</dc:creator>
 <dc:creator>Seiferth, Paul</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Let $P \subset \mathbb{R}^d$ be a set of $n$ points in the $d$ dimensions
such that each point $p \in P$ has an associated radius $r_p &gt; 0$. The
transmission graph $G$ for $P$ is the directed graph with vertex set $P$ such
that there is an edge from $p$ to $q$ if and only if $d(p, q) \leq r_p$, for
any $p, q \in P$.
  A reachability oracle is a data structure that decides for any two vertices
$p, q \in G$ whether $G$ has a path from $p$ to $q$. The quality of the oracle
is measured by the space requirement $S(n)$, the query time $Q(n)$, and the
preprocessing time. For transmission graphs of one-dimensional point sets, we
can construct in $O(n \log n)$ time an oracle with $Q(n) = O(1)$ and $S(n) =
O(n)$. For planar point sets, the ratio $\Psi$ between the largest and the
smallest associated radius turns out to be an important parameter. We present
three data structures whose quality depends on $\Psi$: the first works only for
$\Psi &lt; \sqrt{3}$ and achieves $Q(n) = O(1)$ with $S(n) = O(n)$ and
preprocessing time $O(n\log n)$; the second data structure gives $Q(n) =
O(\Psi^3 \sqrt{n})$ and $S(n) = O(\Psi^5 n^{3/2})$; the third data structure is
randomized with $Q(n) = O(n^{2/3}\log^{1/3} \Psi \log^{2/3} n)$ and $S(n) =
O(n^{5/3}\log^{1/3} \Psi \log^{2/3} n)$ and answers queries correctly with high
probability.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in SoCG 2015</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07797</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07798</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spanners for Directed Transmission Graphs</dc:title>
 <dc:creator>Kaplan, Haim</dc:creator>
 <dc:creator>Mulzer, Wolfgang</dc:creator>
 <dc:creator>Roditty, Liam</dc:creator>
 <dc:creator>Seiferth, Paul</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Let $P \subset \mathbb{R}^2$ be a planar $n$-point set such that each point
$p \in P$ has an associated radius $r_p &gt; 0$. The transmission graph $G$ for
$P$ is the directed graph with vertex set $P$ such that for any $p, q \in P$,
there is an edge from $p$ to $q$ if and only if $d(p, q) \leq r_p$.
  Let $t &gt; 1$ be a constant. A $t$-spanner for $G$ is a subgraph $H \subseteq
G$ with vertex set $P$ so that for any two vertices $p,q \in P$, we have
$d_H(p, q) \leq t d_G(p, q)$, where $d_H$ and $d_G$ denote the shortest path
distance in $H$ and $G$, respectively (with Euclidean edge lengths). We show
how to compute a $t$-spanner for $G$ with $O(n)$ edges in $O(n (\log n + \log
\Psi))$ time, where $\Psi$ is the ratio of the largest and smallest radius of a
point in $P$. Using more advanced data structures, we obtain a construction
that runs in $O(n \log^6 n)$ time, independent of $\Psi$.
  We give two applications for our spanners. First, we show how to use our
spanner to find a BFS tree from any given start vertex in $O(n \log n)$ time
(in addition to the time it takes to build the spanner). Second, we show how to
use our spanner to extend a reachability oracle to answer geometric
reachability queries. In a geometric reachability query we ask whether a vertex
$p$ in $G$ can &quot;reach&quot; a target $q$ which is an arbitrary point the plane
(rather than restricted to be another vertex $q$ of $G$ in a standard
reachability query). Our spanner allows the reachability oracle to answer
geometric reachability queries with an additive overhead of $O(\log n\log
\Psi)$ to the query time and $O(n \log \Psi)$ to the space.
</dc:description>
 <dc:description>Comment: A preliminary version appeared in SoCG 2015</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07800</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weighted tensor decomposition for approximate decoupling of multivariate
  polynomials</dc:title>
 <dc:creator>Hollander, Gabriel</dc:creator>
 <dc:creator>Dreesen, Philippe</dc:creator>
 <dc:creator>Ishteva, Mariya</dc:creator>
 <dc:creator>Schoukens, Johan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Multivariate polynomials arise in many different disciplines. Representing
such a polynomial as a vector of univariate polynomials can offer useful
insight, as well as more intuitive understanding. For this, techniques based on
tensor methods are known, but these have only been studied in the exact case.
In this paper, we generalize an existing method to the noisy case, by
introducing a weight factor in the tensor decomposition. Finally, we apply the
proposed weighted decoupling algorithm in the domain of system identification,
and observe smaller model errors.
</dc:description>
 <dc:description>Comment: 17 pages, 8 figures. General results were presented at the Tensor
  Decompositions and Applications workshop in January 2016, Leuven, Belgium,
  organized by ESAT, Katholieke Universiteit Leuven</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07804</identifier>
 <datestamp>2017-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Sensing Matrix and Sparsifying Dictionary Optimization for Tensor
  Compressive Sensing</dc:title>
 <dc:creator>Ding, Xin</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Wassell, Ian J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Tensor Compressive Sensing (TCS) is a multidimensional framework of
Compressive Sensing (CS), and it is advantageous in terms of reducing the
amount of storage, easing hardware implementations and preserving
multidimensional structures of signals in comparison to a conventional CS
system. In a TCS system, instead of using a random sensing matrix and a
predefined dictionary, the average-case performance can be further improved by
employing an optimized multidimensional sensing matrix and a learned
multilinear sparsifying dictionary. In this paper, we propose a joint
optimization approach of the sensing matrix and dictionary for a TCS system.
For the sensing matrix design in TCS, an extended separable approach with a
closed form solution and a novel iterative non-separable method are proposed
when the multilinear dictionary is fixed. In addition, a multidimensional
dictionary learning method that takes advantages of the multidimensional
structure is derived, and the influence of sensing matrices is taken into
account in the learning process. A joint optimization is achieved via
alternately iterating the optimization of the sensing matrix and dictionary.
Numerical experiments using both synthetic data and real images demonstrate the
superiority of the proposed approaches.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07804</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2699639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07810</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Unfitted Discontinuous Galerkin Method for Solving the EEG Forward
  Problem</dc:title>
 <dc:creator>N&#xfc;&#xdf;ing, Andreas</dc:creator>
 <dc:creator>Wolters, Carsten H.</dc:creator>
 <dc:creator>Brinck, Heinrich</dc:creator>
 <dc:creator>Engwer, Christian</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:subject>35J25, 35J75, 35Q92, 65N30, 68U20, 92C50</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.1.10</dc:subject>
 <dc:subject>I.6.0</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  Objective: The purpose of this study is to introduce and evaluate the
unfitted discontinuous Galerkin finite element method (UDG-FEM) for solving the
electroencephalography (EEG) forward problem. Methods: This new approach for
source analysis does not use a geometry conforming volume triangulation, but
instead uses a structured mesh that does not resolve the geometry. The geometry
is described using level set functions and is incorporated implicitly in its
mathematical formulation. As no triangulation is necessary, the complexity of a
simulation pipeline and the need for manual interaction for patient specific
simulations can be reduced and is comparable with that of the FEM for
hexahedral meshes. In addition, it maintains conservation laws on a discrete
level. Here, we present the theory for UDG-FEM forward modeling, its
verification using quasi-analytical solutions in multi-layer sphere models and
an evaluation in a comparison with a discontinuous Galerkin (DG-FEM) method on
hexahedral and on conforming tetrahedral meshes. We furthermore apply the
UDG-FEM forward approach in a realistic head model simulation study. Results:
The given results show convergence and indicate a good overall accuracy of the
UDG-FEM approach. UDG-FEM performs comparable or even better than DG-FEM on a
conforming tetrahedral mesh while providing a less complex simulation pipeline.
When compared to DG-FEM on hexahedral meshes, an overall better accuracy is
achieved. Conclusion: The UDG-FEM approach is an accurate, flexible and
promising method to solve the EEG forward problem. Significance: This study
shows the first application of the UDG-FEM approach to the EEG forward problem.
</dc:description>
 <dc:description>Comment: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07811</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Pilot Alignment Pattern Design in OFDM Systems</dc:title>
 <dc:creator>Lee, Yong Chan</dc:creator>
 <dc:creator>Jang, Won Chol</dc:creator>
 <dc:creator>Choe, Un Kyong</dc:creator>
 <dc:creator>Leem, Gyong Chol</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In this paper, we propose optimal pilot pattern of downlink OFDM (Orthogonal
Frequency Division Multiplexing) communication system.
</dc:description>
 <dc:description>Comment: 11 pages, 13 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07811</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07815</identifier>
 <datestamp>2017-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Optimization of Real Time SoC</dc:title>
 <dc:creator>Yavits, L.</dc:creator>
 <dc:creator>Morad, A.</dc:creator>
 <dc:creator>Ginosar, R.</dc:creator>
 <dc:creator>Weiser, U.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Convex optimization methods are employed to optimize a real-time (RT)
system-on-chip (SoC) under a variety of physical resource-driven constraints,
demonstrated on an industry MPEG2 encoder SoC. The power optimization is
compared to conventional performance-optimization framework, showing a factor
of two and a half saving in power. Convex optimization is shown to be very
efficient in a high-level early stage design exploration, guiding computer
architects as to the choice of area, voltage, and frequency of the individual
components of the Chip Multiprocessor (CMP).
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2017-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07843</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Melanoma Detection in Dermoscopy Images Using Image
  Processing and Machine Learning</dc:title>
 <dc:creator>Mishra, Nabin K.</dc:creator>
 <dc:creator>Celebi, M. Emre</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:subject>J.3</dc:subject>
 <dc:description>  The incidence of malignant melanoma continues to increase worldwide. This
cancer can strike at any age; it is one of the leading causes of loss of life
in young persons. Since this cancer is visible on the skin, it is potentially
detectable at a very early stage when it is curable. New developments have
converged to make fully automatic early melanoma detection a real possibility.
First, the advent of dermoscopy has enabled a dramatic boost in clinical
diagnostic ability to the point that melanoma can be detected in the clinic at
the very earliest stages. The global adoption of this technology has allowed
accumulation of large collections of dermoscopy images of melanomas and benign
lesions validated by histopathology. The development of advanced technologies
in the areas of image processing and machine learning have given us the ability
to allow distinction of malignant melanoma from the many benign mimics that
require no biopsy. These new technologies should allow not only earlier
detection of melanoma, but also reduction of the large number of needless and
costly biopsy procedures. Although some of the new systems reported for these
technologies have shown promise in preliminary trials, widespread
implementation must await further technical progress in accuracy and
reproducibility. In this paper, we provide an overview of computerized
detection of melanoma in dermoscopy images. First, we discuss the various
aspects of lesion segmentation. Then, we provide a brief overview of clinical
feature segmentation. Finally, we discuss the classification stage where
machine learning algorithms are applied to the attributes generated from the
segmented features to predict the existence of melanoma.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07843</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07858</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Aggregation and Linking of Observational Metadata in the ADS</dc:title>
 <dc:creator>Accomazzi, Alberto</dc:creator>
 <dc:creator>Kurtz, Michael J.</dc:creator>
 <dc:creator>Henneken, Edwin A.</dc:creator>
 <dc:creator>Grant, Carolyn S.</dc:creator>
 <dc:creator>Thompson, Donna M.</dc:creator>
 <dc:creator>Chyla, Roman</dc:creator>
 <dc:creator>Holachek, Alexandra</dc:creator>
 <dc:creator>Elliott, Jonathan</dc:creator>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  We discuss current efforts behind the curation of observing proposals,
archive bibliographies, and data links in the NASA Astrophysics Data System
(ADS). The primary data in the ADS is the bibliographic content from scholarly
articles in Astronomy and Physics, which ADS aggregates from publishers, arXiv
and conference proceeding sites. This core bibliographic information is then
further enriched by ADS via the generation of citations and usage data, and
through the aggregation of external resources from astronomy data archives and
libraries. Important sources of such additional information are the metadata
describing observing proposals and high level data products, which, once
ingested in ADS, become easily discoverable and citeable by the science
community. Bibliographic studies have shown that the integration of links
between data archives and the ADS provides greater visibility to data products
and increased citations to the literature associated with them.
</dc:description>
 <dc:description>Comment: 4 pages, Proceedings of the ADASS XXV conference</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07862</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evolution of the number of GitHub users in Spain</dc:title>
 <dc:creator>Merelo, JJ</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Since we started measuring the community of GitHub users in Spain, it has
kept increasing in numbers in such a way that it has grown almost 50%, to the
current 12000, in less than one year. However, the reasons for this are not
clear. In this paper we will try to find out what are the different components
in this growth, or at least those that can be measured, in order to find out
which ones are due to the measurement itself and which might be due to other
reasons. In this paper we make an advance towards finding out the reasons for
this growth.
</dc:description>
 <dc:description>Comment: Report to support FLOSSMETRICS flash talks The third version updated
  to the end of January</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07865</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grid Energy Consumption and QoS Tradeoff in Hybrid Energy Supply
  Wireless Networks</dc:title>
 <dc:creator>Mao, Yuyi</dc:creator>
 <dc:creator>Zhang, Jun</dc:creator>
 <dc:creator>Letaief, Khaled B.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Hybrid energy supply (HES) wireless networks have recently emerged as a new
paradigm to enable green networks, which are powered by both the electric grid
and harvested renewable energy. In this paper, we will investigate two critical
but conflicting design objectives of HES networks, i.e., the grid energy
consumption and quality of service (QoS). Minimizing grid energy consumption by
utilizing the harvested energy will make the network environmentally friendly,
but the achievable QoS may be degraded due to the intermittent nature of energy
harvesting. To investigate the tradeoff between these two aspects, we introduce
the total service cost as the performance metric, which is the weighted sum of
the grid energy cost and the QoS degradation cost. Base station assignment and
power control is adopted as the main strategy to minimize the total service
cost, while both cases with non-causal and causal side information are
considered. With non-causal side information, a Greedy Assignment algorithm
with low complexity and near-optimal performance is proposed. With causal side
information, the design problem is formulated as a discrete Markov decision
problem. Interesting solution structures are derived, which shall help to
develop an efficient monotone backward induction algorithm. To further reduce
complexity, a Look-Ahead policy and a Threshold-based Heuristic policy are also
proposed. Simulation results shall validate the effectiveness of the proposed
algorithms and demonstrate the unique grid energy consumption and QoS tradeoff
in HES networks.
</dc:description>
 <dc:description>Comment: 14 pages, 7 figures, to appear in IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07865</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2523981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07883</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards the Design of an End-to-End Automated System for Image and
  Video-based Recognition</dc:title>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:creator>Chen, Jun-Cheng</dc:creator>
 <dc:creator>Ranjan, Rajeev</dc:creator>
 <dc:creator>Sankaranarayanan, Swami</dc:creator>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:creator>Patel, Vishal M.</dc:creator>
 <dc:creator>Castillo, Carlos D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Over many decades, researchers working in object recognition have longed for
an end-to-end automated system that will simply accept 2D or 3D image or videos
as inputs and output the labels of objects in the input data. Computer vision
methods that use representations derived based on geometric, radiometric and
neural considerations and statistical and structural matchers and artificial
neural network-based methods where a multi-layer network learns the mapping
from inputs to class labels have provided competing approaches for image
recognition problems. Over the last four years, methods based on Deep
Convolutional Neural Networks (DCNNs) have shown impressive performance
improvements on object detection/recognition challenge problems. This has been
made possible due to the availability of large annotated data, a better
understanding of the non-linear mapping between image and class labels as well
as the affordability of GPUs. In this paper, we present a brief history of
developments in computer vision and artificial neural networks over the last
forty years for the problem of image-based recognition. We then present the
design details of a deep learning system for end-to-end unconstrained face
verification/recognition. Some open issues regarding DCNNs for object
recognition problems are then discussed. We caution the readers that the views
expressed in this paper are from the authors and authors only!
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07884</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geo-distinctive Visual Element Matching for Location Estimation of
  Images</dc:title>
 <dc:creator>Li, Xinchao</dc:creator>
 <dc:creator>Larson, Martha A.</dc:creator>
 <dc:creator>Hanjalic, Alan</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose an image representation and matching approach that substantially
improves visual-based location estimation for images. The main novelty of the
approach, called distinctive visual element matching (DVEM), is its use of
representations that are specific to the query image whose location is being
predicted. These representations are based on visual element clouds, which
robustly capture the connection between the query and visual evidence from
candidate locations. We then maximize the influence of visual elements that are
geo-distinctive because they do not occur in images taken at many other
locations. We carry out experiments and analysis for both geo-constrained and
geo-unconstrained location estimation cases using two large-scale,
publicly-available datasets: the San Francisco Landmark dataset with $1.06$
million street-view images and the MediaEval '15 Placing Task dataset with
$5.6$ million geo-tagged images from Flickr. We present examples that
illustrate the highly-transparent mechanics of the approach, which are based on
common sense observations about the visual patterns in image collections. Our
results show that the proposed method delivers a considerable performance
improvement compared to the state of the art.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07884</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07885</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blind Interference Alignment for Private Information Retrieval</dc:title>
 <dc:creator>Sun, Hua</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Blind interference alignment (BIA) refers to interference alignment schemes
that are designed only based on channel coherence pattern knowledge at the
transmitters (the &quot;blind&quot; transmitters do not know the exact channel values).
Private information retrieval (PIR) refers to the problem where a user
retrieves one out of K messages from N non-communicating databases (each holds
all K messages) without revealing anything about the identity of the desired
message index to any individual database. In this paper, we identify an
intriguing connection between PIR and BIA. Inspired by this connection, we
characterize the information theoretic optimal download cost of PIR, when we
have K = 2 messages and the number of databases, N, is arbitrary.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07888</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stabilization of systems with asynchronous sensors and controllers</dc:title>
 <dc:creator>Wakaiki, Masashi</dc:creator>
 <dc:creator>Okano, Kunihisa</dc:creator>
 <dc:creator>Hespanha, Joao P.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We study the stabilization of networked control systems with asynchronous
sensors and controllers. Offsets between the sensor and controller clocks are
unknown and modeled as parametric uncertainty. First we consider multi-input
linear systems and provide a sufficient condition for the existence of linear
time-invariant controllers that are capable of stabilizing the closed-loop
system for every clock offset in a given range of admissible values. For
first-order systems, we next obtain the maximum length of the offset range for
which the system can be stabilized by a single controller. Finally, this bound
is compared with the offset bounds that would be allowed if we restricted our
attention to static output feedback controllers.
</dc:description>
 <dc:description>Comment: 32 pages, 6 figures. This paper was partially presented at the 2015
  American Control Conference, July 1-3, 2015, the USA</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07913</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterized Machine Learning for High-Energy Physics</dc:title>
 <dc:creator>Baldi, Pierre</dc:creator>
 <dc:creator>Cranmer, Kyle</dc:creator>
 <dc:creator>Faucett, Taylor</dc:creator>
 <dc:creator>Sadowski, Peter</dc:creator>
 <dc:creator>Whiteson, Daniel</dc:creator>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:description>  We investigate a new structure for machine learning classifiers applied to
problems in high-energy physics by expanding the inputs to include not only
measured features but also physics parameters. The physics parameters represent
a smoothly varying learning task, and the resulting parameterized classifier
can smoothly interpolate between them and replace sets of classifiers trained
at individual values. This simplifies the training process and gives improved
performance at intermediate values, even for complex problems requiring deep
learning. Applications include tools parameterized in terms of theoretical
model parameters, such as the mass of a particle, which allow for a single
network to provide improved discrimination across a range of masses. This
concept is simple to implement and allows for optimized interpolatable results.
</dc:description>
 <dc:description>Comment: For submission to PRD</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07913</dc:identifier>
 <dc:identifier>doi:10.1140/epjc/s10052-016-4099-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07925</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automating biomedical data science through tree-based pipeline
  optimization</dc:title>
 <dc:creator>Olson, Randal S.</dc:creator>
 <dc:creator>Urbanowicz, Ryan J.</dc:creator>
 <dc:creator>Andrews, Peter C.</dc:creator>
 <dc:creator>Lavender, Nicole A.</dc:creator>
 <dc:creator>Kidd, La Creis</dc:creator>
 <dc:creator>Moore, Jason H.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Over the past decade, data science and machine learning has grown from a
mysterious art form to a staple tool across a variety of fields in academia,
business, and government. In this paper, we introduce the concept of tree-based
pipeline optimization for automating one of the most tedious parts of machine
learning---pipeline design. We implement a Tree-based Pipeline Optimization
Tool (TPOT) and demonstrate its effectiveness on a series of simulated and
real-world genetic data sets. In particular, we show that TPOT can build
machine learning pipelines that achieve competitive classification accuracy and
discover novel pipeline operators---such as synthetic feature
constructors---that significantly improve classification accuracy on these data
sets. We also highlight the current challenges to pipeline optimization, such
as the tendency to produce pipelines that overfit the data, and suggest future
research paths to overcome these challenges. As such, this work represents an
early step toward fully automating machine learning pipeline design.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures, to appear in EvoBIO 2016 proceedings</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07929</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Models for Computerized Adaptive Testing: Experiments</dc:title>
 <dc:creator>Plajner, Martin</dc:creator>
 <dc:creator>Vomlel, Ji&#x159;&#xed;</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  This paper follows previous research we have already performed in the area of
Bayesian networks models for CAT. We present models using Item Response Theory
(IRT - standard CAT method), Bayesian networks, and neural networks. We
conducted simulated CAT tests on empirical data. Results of these tests are
presented for each model separately and compared.
</dc:description>
 <dc:description>Comment: 9 pages, v2: language corrections</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07932</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Theoretic Lower Bounds for Recovery of Diffusion Network
  Structures</dc:title>
 <dc:creator>Park, Keehwan</dc:creator>
 <dc:creator>Honorio, Jean</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the information-theoretic lower bound of the sample complexity of
the correct recovery of diffusion network structures. We introduce a
discrete-time diffusion model based on the Independent Cascade model for which
we obtain a lower bound of order $\Omega(k \log p)$, for directed graphs of $p$
nodes, and at most $k$ parents per node. Next, we introduce a continuous-time
diffusion model, for which a similar lower bound of order $\Omega(k \log p)$ is
obtained. Our results show that the algorithm of Pouget-Abadie et al. is
statistically optimal for the discrete-time regime. Our work also opens the
question of whether it is possible to devise an optimal algorithm for the
continuous-time regime.
</dc:description>
 <dc:description>Comment: ISIT'16</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07941</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic calibration of damping layers in finite element time domain
  simulations</dc:title>
 <dc:creator>Vandekerckhove, Steven</dc:creator>
 <dc:creator>Wells, Garth N.</dc:creator>
 <dc:creator>De Gersem, Herbert</dc:creator>
 <dc:creator>Abeele, Koen Van Den</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>35L05, 65M60</dc:subject>
 <dc:description>  Matched layers are commonly used in numerical simulations of wave propagation
to model (semi-)infinite domains. Attenuation functions describe the damping in
layers, and provide a matching of the wave impedance at the interface between
the domain of interest and the absorbing region. Selecting parameters in the
attenuation functions is non-trivial. In this work, an optimisation procedure
for automatically calibrating matched layers is presented. The procedure is
based on solving optimisation problems constrained by partial differential
equations with polynomial and piecewise-constant attenuation functions. We show
experimentally that, for finite element time domain simulations,
piecewise-constant attenuation function are at least as efficient as quadratic
attenuation functions. This observation leads us to introduce consecutive
matched layers as an alternative to perfectly matched layers, which can easily
be employed for problems with arbitrary geometries. Moreover, the use of
consecutive matched layers leads to a reduction in computational cost compared
to perfectly matched layers. Examples are presented for acoustic, elastodynamic
and electromagnetic problems. Numerical simulations are performed with the
libraries FEniCS/DOLFIN and dolfin-adjoint, and the computer code to reproduce
all numerical examples is made freely available.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07941</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07944</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discontinuous Galerkin methods on graphics processing units for
  nonlinear hyperbolic conservation laws</dc:title>
 <dc:creator>Fuhry, Martin</dc:creator>
 <dc:creator>Giuliani, Andrew</dc:creator>
 <dc:creator>Krivodonova, Lilia</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  We present a novel implementation of the modal discontinuous Galerkin (DG)
method for hyperbolic conservation laws in two dimensions on graphics
processing units (GPUs) using NVIDIA's Compute Unified Device Architecture
(CUDA). Both flexible and highly accurate, DG methods accommodate parallel
architectures well as their discontinuous nature produces element-local
approximations. High performance scientific computing suits GPUs well, as these
powerful, massively parallel, cost-effective devices have recently included
support for double-precision floating point numbers. Computed examples for
Euler equations over unstructured triangle meshes demonstrate the effectiveness
of our implementation on an NVIDIA GTX 580 device. Profiling of our method
reveals performance comparable to an existing nodal DG-GPU implementation for
linear problems.
</dc:description>
 <dc:description>Comment: 36 pages, 14 figures, 6 tables</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07944</dc:identifier>
 <dc:identifier>International Journal for Numerical Methods in Fluids, 76(12),
  982-1003 (2014)</dc:identifier>
 <dc:identifier>doi:10.1002/fld.3963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07947</identifier>
 <datestamp>2017-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Large-scale Kernel-based Feature Extraction via Budgeted Nonlinear
  Subspace Tracking</dc:title>
 <dc:creator>Sheikholeslami, Fatemeh</dc:creator>
 <dc:creator>Berberidis, Dimitris</dc:creator>
 <dc:creator>Giannakis, Georgios B.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Kernel-based methods enjoy powerful generalization capabilities in handling a
variety of learning tasks. When such methods are provided with sufficient
training data, broadly-applicable classes of nonlinear functions can be
approximated with desired accuracy. Nevertheless, inherent to the nonparametric
nature of kernel-based estimators are computational and memory requirements
that become prohibitive with large-scale datasets. In response to this
formidable challenge, the present work puts forward a low-rank, kernel-based,
feature extraction approach that is particularly tailored for online operation,
where data streams need not be stored in memory. A novel generative model is
introduced to approximate high-dimensional (possibly infinite) features via a
low-rank nonlinear subspace, the learning of which leads to a direct kernel
function approximation. Offline and online solvers are developed for the
subspace learning task, along with affordable versions, in which the number of
stored data vectors is confined to a predefined budget. Analytical results
provide performance bounds on how well the kernel matrix as well as
kernel-based classification and regression tasks can be approximated by
leveraging budgeted online subspace learning and feature extraction schemes.
Tests on synthetic and real datasets demonstrate and benchmark the efficiency
of the proposed method when linear classification and regression is applied to
the extracted features.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2017-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07950</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Alignment by Local Deep Descriptor Regression</dc:title>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:creator>Ranjan, Rajeev</dc:creator>
 <dc:creator>Patel, Vishal</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an algorithm for extracting key-point descriptors using deep
convolutional neural networks (CNN). Unlike many existing deep CNNs, our model
computes local features around a given point in an image. We also present a
face alignment algorithm based on regression using these local descriptors. The
proposed method called Local Deep Descriptor Regression (LDDR) is able to
localize face landmarks of varying sizes, poses and occlusions with high
accuracy. Deep Descriptors presented in this paper are able to uniquely and
efficiently describe every pixel in the image and therefore can potentially
replace traditional descriptors such as SIFT and HOG. Extensive evaluations on
five publicly available unconstrained face alignment datasets show that our
deep descriptor network is able to capture strong local features around a given
landmark and performs significantly better than many competitive and
state-of-the-art face alignment algorithms.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07953</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boolean Operations using Generalized Winding Numbers</dc:title>
 <dc:creator>Jacobson, Alec</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  The generalized winding number function measures insideness for arbitrary
oriented triangle meshes. Exploiting this, I similarly generalize binary
boolean operations to act on such meshes. The resulting operations for union,
intersection, difference, etc. avoid volumetric discretization or
pre-processing.
</dc:description>
 <dc:description>Comment: 1 page, 1 figure</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07953</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07962</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DoubleTake: Fast and Precise Error Detection via Evidence-Based Dynamic
  Analysis</dc:title>
 <dc:creator>Liu, Tongping</dc:creator>
 <dc:creator>Curtsinger, Charlie</dc:creator>
 <dc:creator>Berger, Emery D.</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>D.2.5</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>D.3.4</dc:subject>
 <dc:description>  This paper presents evidence-based dynamic analysis, an approach that enables
lightweight analyses--under 5% overhead for these bugs--making it practical for
the first time to perform these analyses in deployed settings. The key insight
of evidence-based dynamic analysis is that for a class of errors, it is
possible to ensure that evidence that they happened at some point in the past
remains for later detection. Evidence-based dynamic analysis allows execution
to proceed at nearly full speed until the end of an epoch (e.g., a heavyweight
system call). It then examines program state to check for evidence that an
error occurred at some time during that epoch. If so, it rolls back execution
and re-executes the code with instrumentation activated to pinpoint the error.
  We present DoubleTake, a prototype evidence-based dynamic analysis framework.
DoubleTake is practical and easy to deploy, requiring neither custom hardware,
compiler, nor operating system support. We demonstrate DoubleTake's generality
and efficiency by building dynamic analyses that find buffer overflows, memory
use-after-free errors, and memory leaks. Our evaluation shows that DoubleTake
is efficient, imposing just 4% overhead on average, making it the fastest such
system to date. It is also precise: DoubleTake pinpoints the location of these
errors to the exact line and memory addresses where they occur, providing
valuable debugging information to programmers.
</dc:description>
 <dc:description>Comment: Pre-print, accepted to appear at ICSE 2016</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07965</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Decision Support in Reciprocation</dc:title>
 <dc:creator>Polevoy, Gleb</dc:creator>
 <dc:creator>de Weerdt, Mathijs</dc:creator>
 <dc:creator>Jonker, Catholijn</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  People often interact repeatedly: with relatives, through file sharing, in
politics, etc. Many such interactions are reciprocal: reacting to the actions
of the other. In order to facilitate decisions regarding reciprocal
interactions, we analyze the development of reciprocation over time. To this
end, we propose a model for such interactions that is simple enough to enable
formal analysis, but is sufficient to predict how such interactions will
evolve. Inspired by existing models of international interactions and arguments
between spouses, we suggest a model with two reciprocating attitudes where an
agent's action is a weighted combination of the others' last actions (reacting)
and either i) her innate kindness, or ii) her own last action (inertia). We
analyze a network of repeatedly interacting agents, each having one of these
attitudes, and prove that their actions converge to specific limits.
Convergence means that the interaction stabilizes, and the limits indicate the
behavior after the stabilization. For two agents, we describe the interaction
process and find the limit values. For a general connected network, we find
these limit values if all the agents employ the second attitude, and show that
the agents' actions then all become equal. In the other cases, we study the
limit values using simulations. We discuss how these results predict the
development of the interaction and can be used to help agents decide on their
behavior.
</dc:description>
 <dc:description>Comment: An extended abstract is published at AAMAS'16(forthcoming)</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-02-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07965</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07969</identifier>
 <datestamp>2016-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Zipf's law is a consequence of coherent language production</dc:title>
 <dc:creator>Williams, Jake Ryland</dc:creator>
 <dc:creator>Bagrow, James P.</dc:creator>
 <dc:creator>Reagan, Andrew J.</dc:creator>
 <dc:creator>Alajajian, Sharon E.</dc:creator>
 <dc:creator>Danforth, Christopher M.</dc:creator>
 <dc:creator>Dodds, Peter Sheridan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The task of text segmentation may be undertaken at many levels in text
analysis---paragraphs, sentences, words, or even letters. Here, we focus on a
relatively fine scale of segmentation, hypothesizing it to be in accord with a
stochastic model of language generation, as the smallest scale where
independent units of meaning are produced. Our goals in this letter include the
development of methods for the segmentation of these minimal independent units,
which produce feature-representations of texts that align with the independence
assumption of the bag-of-terms model, commonly used for prediction and
classification in computational text analysis. We also propose the measurement
of texts' association (with respect to realized segmentations) to the model of
language generation. We find (1) that our segmentations of phrases exhibit much
better associations to the generation model than words and (2), that texts
which are well fit are generally topically homogeneous. Because our generative
model produces Zipf's law, our study further suggests that Zipf's law may be a
consequence of homogeneity in language production.
</dc:description>
 <dc:description>Comment: 5 pages, 4 figures</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:date>2016-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07975</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perfect Necklaces</dc:title>
 <dc:creator>&#xc1;lvarez, Nicol&#xe1;s</dc:creator>
 <dc:creator>Becher, Ver&#xf3;nica</dc:creator>
 <dc:creator>Ferrari, Pablo A.</dc:creator>
 <dc:creator>Yuhjtman, Sergio A.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We introduce a variant of de Bruijn words that we call perfect necklaces. Fix
a finite alphabet. Recall that a word is a finite sequence of symbols in the
alphabet and a circular word, or necklace, is the equivalence class of a word
under rotations. For positive integers k and n, we call a necklace
(k,n)-perfect if each word of length k occurs exactly n times at positions
which are different modulo n for any convention on the starting point. We call
a necklace perfect if it is (k,k)-perfect for some k. We prove that every
arithmetic sequence with difference coprime with the alphabet size induces a
perfect necklace. In particular, the concatenation of all words of the same
length in lexicographic order yields a perfect necklace. For each k and n, we
give a closed formula for the number of (k,n)-perfect necklaces. Finally, we
prove that every infinite periodic sequence whose period coincides with some
(k,n)-perfect necklace for any n, passes all statistical tests of size up to k,
but not all larger tests. This last theorem motivated this work.
</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07975</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07976</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Algorithms for Complete and Partial Information Games on
  Interference Channels</dc:title>
 <dc:creator>A, Krishna Chaitanya</dc:creator>
 <dc:creator>Mukherji, Utpal</dc:creator>
 <dc:creator>Sharma, Vinod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a Gaussian interference channel with independent direct and cross
link channel gains, each of which is independent and identically distributed
across time. Each transmitter-receiver user pair aims to maximize its long-term
average transmission rate subject to an average power constraint. We formulate
a stochastic game for this system in three different scenarios. First, we
assume that each user knows all direct and cross link channel gains. Later, we
assume that each user knows channel gains of only the links that are incident
on its receiver. Lastly, we assume that each user knows only its own direct
link channel gain. In all cases, we formulate the problem of finding a Nash
equilibrium (NE) as a variational inequality (VI) problem. We present a novel
heuristic for solving a VI. We use this heuristic to solve for a NE of power
allocation games with partial information. We also present a lower bound on the
utility for each user at any NE in the case of the games with partial
information. We obtain this lower bound using a water-filling like power
allocation that requires only knowledge of the distribution of a user's own
channel gains and average power constraints of all the users. We also provide a
distributed algorithm to compute Pareto optimal solutions for the proposed
games. Finally, we use Bayesian learning to obtain an algorithm that converges
to an $\epsilon$-Nash equilibrium for the incomplete information game with
direct link channel gain knowledge only without requiring the knowledge of the
power policies of the other users.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1501.04412</dc:description>
 <dc:date>2016-01-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07976</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07977</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid CNN and Dictionary-Based Models for Scene Recognition and Domain
  Adaptation</dc:title>
 <dc:creator>Xie, Guo-Sen</dc:creator>
 <dc:creator>Zhang, Xu-Yao</dc:creator>
 <dc:creator>Yan, Shuicheng</dc:creator>
 <dc:creator>Liu, Cheng-Lin</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional neural network (CNN) has achieved state-of-the-art performance
in many different visual tasks. Learned from a large-scale training dataset,
CNN features are much more discriminative and accurate than the hand-crafted
features. Moreover, CNN features are also transferable among different domains.
On the other hand, traditional dictionarybased features (such as BoW and SPM)
contain much more local discriminative and structural information, which is
implicitly embedded in the images. To further improve the performance, in this
paper, we propose to combine CNN with dictionarybased models for scene
recognition and visual domain adaptation. Specifically, based on the well-tuned
CNN models (e.g., AlexNet and VGG Net), two dictionary-based representations
are further constructed, namely mid-level local representation (MLR) and
convolutional Fisher vector representation (CFV). In MLR, an efficient
two-stage clustering method, i.e., weighted spatial and feature space spectral
clustering on the parts of a single image followed by clustering all
representative parts of all images, is used to generate a class-mixture or a
classspecific part dictionary. After that, the part dictionary is used to
operate with the multi-scale image inputs for generating midlevel
representation. In CFV, a multi-scale and scale-proportional GMM training
strategy is utilized to generate Fisher vectors based on the last convolutional
layer of CNN. By integrating the complementary information of MLR, CFV and the
CNN features of the fully connected layer, the state-of-the-art performance can
be achieved on scene recognition and domain adaptation problems. An interested
finding is that our proposed hybrid representation (from VGG net trained on
ImageNet) is also complementary with GoogLeNet and/or VGG-11 (trained on
Place205) greatly.
</dc:description>
 <dc:description>Comment: Accepted by TCSVT on Sep.2015</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07977</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2015.2511543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07985</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online (and Offline) Robust PCA: Novel Algorithms and Performance
  Guarantees</dc:title>
 <dc:creator>Zhan, Jinchun</dc:creator>
 <dc:creator>Lois, Brian</dc:creator>
 <dc:creator>Vaswani, Namrata</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study the online robust principal components' analysis
(RPCA) problem. In recent work, RPCA has been defined as a problem of
separating a low-rank matrix (true data), $L$, and a sparse matrix (outliers),
$S$, from their sum, $M:=L + S$. A more general version of this problem is to
recover $L$ and $S$ from $M:=L + S + W$ where $W$ is the matrix of unstructured
small noise/corruptions. An important application where this problem occurs is
in video analytics in trying to separate sparse foregrounds (e.g., moving
objects) from slowly changing backgrounds. While there has been a large amount
of recent work on solutions and guarantees for the batch RPCA problem, the
online problem is largely open.&quot;Online&quot; RPCA is the problem of doing the above
on-the-fly with the extra assumptions that the initial subspace is accurately
known and that the subspace from which $l_t$ is generated changes slowly over
time. We develop and study a novel &quot;online&quot; RPCA algorithm based on the
recently introduced Recursive Projected Compressive Sensing (ReProCS)
framework. Our algorithm improves upon the original ReProCS algorithm and it
also returns even more accurate offline estimates. The key contribution of this
work is a correctness result (complete performance guarantee) for this
algorithm under reasonably mild assumptions. By using extra assumptions --
accurate initial subspace knowledge, slow subspace change, and clustered
eigenvalues -- we are able to remove one important limitation of batch RPCA
results and two key limitations of a recent result for ReProCS for online RPCA.
To our knowledge, this work is among the first few correctness results for
online RPCA. Most earlier results were only partial results, i.e., they
required an assumption on intermediate algorithm estimates.
</dc:description>
 <dc:description>Comment: A shorter version of this work will be presented at AISTATS 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07995</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local cascades induced global contagion: How heterogeneous thresholds,
  exogenous effects, and unconcerned behaviour govern online adoption spreading</dc:title>
 <dc:creator>Karsai, M&#xe1;rton</dc:creator>
 <dc:creator>I&#xf1;iguez, Gerardo</dc:creator>
 <dc:creator>Kikas, Riivo</dc:creator>
 <dc:creator>Kaski, Kimmo</dc:creator>
 <dc:creator>Kert&#xe9;sz, J&#xe1;nos</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  Adoption of innovations, products or online services is commonly interpreted
as a spreading process driven to large extent by social influence and
conditioned by the needs and capacities of individuals. To model this process
one usually introduces behavioural threshold mechanisms, which can give rise to
the evolution of global cascades if the system satisfies a set of conditions.
However, these models do not address temporal aspects of the emerging cascades,
which in real systems may evolve through various pathways ranging from slow to
rapid patterns. Here we fill this gap through the analysis and modelling of
product adoption in the world's largest voice over internet service, the social
network of Skype. We provide empirical evidence about the heterogeneous
distribution of fractional behavioural thresholds, which appears to be
independent of the degree of adopting egos. We show that the structure of
real-world adoption clusters is radically different from previous theoretical
expectations, since vulnerable adoptions --induced by a single adopting
neighbour-- appear to be important only locally, while spontaneous adopters
arriving at a constant rate and the involvement of unconcerned individuals
govern the global emergence of social spreading.
</dc:description>
 <dc:description>Comment: 28 pages, 10 figures</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.07996</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection: A Data Perspective</dc:title>
 <dc:creator>Li, Jundong</dc:creator>
 <dc:creator>Cheng, Kewei</dc:creator>
 <dc:creator>Wang, Suhang</dc:creator>
 <dc:creator>Morstatter, Fred</dc:creator>
 <dc:creator>Trevino, Robert P.</dc:creator>
 <dc:creator>Tang, Jiliang</dc:creator>
 <dc:creator>Liu, Huan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Feature selection, as a data preprocessing strategy, has been proven to be
effective and efficient in preparing high-dimensional data for data mining and
machine learning problems. The objectives of feature selection include:
building simpler and more comprehensible models, improving data mining
performance, and preparing clean, understandable data. The recent proliferation
of big data has presented some substantial challenges and opportunities for
feature selection research. In this survey, we provide a comprehensive and
structured overview of recent advances in feature selection research. Motivated
by current challenges and opportunities in the big data age, we revisit feature
selection research from a data perspective, and review representative feature
selection algorithms for generic data, structured data, heterogeneous data and
streaming data. Methodologically, to emphasize the differences and similarities
of most existing feature selection algorithms for generic data, we generally
categorize them into four groups: similarity based, information theoretical
based, sparse learning based and statistical based methods. Finally, to
facilitate and promote the research in this community, we also present an
open-source feature selection repository that consists of most of the popular
feature selection algorithms (\url{http://featureselection.asu.edu/}). At the
end of this survey, we also have a discussion about some open problems and
challenges that need to be paid more attention in future research.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-09-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.07996</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08003</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Robust Mean Value Calculation of 1D Features</dc:title>
 <dc:creator>Jonsson, Erik</dc:creator>
 <dc:creator>Felsberg, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A robust mean value is often a good alternative to the standard mean value
when dealing with data containing many outliers. An efficient method for
samples of one-dimensional features and the truncated quadratic error norm is
presented and compared to the method of channel averaging (soft histograms).
</dc:description>
 <dc:description>Comment: Presented at the SSBA Symposium 2005, Malm\&quot;o, Sweden</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08011</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Concise Network-Centric Survey of IP Traceback Schemes based on
  Probabilistic Packet Marking</dc:title>
 <dc:creator>Brust, Matthias R.</dc:creator>
 <dc:creator>Kiremire, Ankunda R.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Multiple probabilistic packet marking (PPM) schemes for IP traceback have
been proposed to deal with Distributed Denial of Service (DDoS) attacks by
reconstructing their attack graphs and identifying the attack sources. In this
paper, ten PPM-based IP traceback schemes are compared and analyzed in terms of
features such as convergence time, performance evaluation, underlying
topologies, incremental deployment, re-marking, and upstream graph. Our
analysis shows that the considered schemes exhibit a significant discrepancy in
performance as well as performance assessment. We concisely demonstrate this by
providing a table showing that (a) different metrics are used for many schemes
to measure their performance and, (b) most schemes are evaluated on different
classes of underlying network topologies. Our results reveal that both the
value and arrangement of the PPM-based scheme convergence times vary depending
on exactly the underlying network topology. As a result, this paper shows that
a side-by-side comparison of the scheme performance a complicated and turns out
to be a crucial open problem in this research area.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08011</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08021</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Biologically Inspired Model of Distributed Online Communication
  Supporting Efficient Search and Diffusion of Innovation</dc:title>
 <dc:creator>Banerjee, Soumya</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We inhabit a world that is not only small but supports efficient
decentralized search - an individual using local information can establish a
line of communication with another completely unknown individual. Here we
augment a hierarchical social network model with communication between and
within communities. We argue that organization into communities would decrease
overall decentralized search times. We take inspiration from the biological
immune system which organizes search for pathogens in a hybrid modular
strategy. Our strategy has relevance in search for rare amounts of information
in online social networks. Our work also has implications for design of
efficient online networks that could have an impact on networks of human
collaboration, scientific collaboration and networks used in targeted manhunts.
Real world systems, like online social networks, have high associated delays
for long-distance links, since they are built on top of physical networks. Such
systems have been shown to densify. Hence such networks will have a
communication cost due to space and the requirement of maintaining connections.
We have incorporated such a non-spatial cost to communication. We introduce the
notion of a community size that increases with the size of the system, which is
shown to reduce the time to search for information in networks. Our final
strategy balances search times and participation costs and is shown to decrease
time to find information in decentralized search in online social networks. Our
strategy also balances strong-ties and weak-ties over long distances and may
ultimately lead to more productive and innovative networks of human
communication and enterprise. We hope that this work will lay the foundation
for strategies aimed at producing global scale human interaction networks that
are sustainable and lead to a more networked, diverse and prosperous society.
</dc:description>
 <dc:description>Comment: 16 pages, 1 figure</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08021</dc:identifier>
 <dc:identifier>doi:10.7906/indecs.14.1.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08027</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TrAD: Traffic Adaptive Data Dissemination Protocol for Both Urban and
  Highway VANETs</dc:title>
 <dc:creator>Tian, Bin</dc:creator>
 <dc:creator>Hou, K. M.</dc:creator>
 <dc:creator>Li, Jianjin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Vehicular Ad hoc Networks (VANETs) aim to improve transportation activities
that include traffic safety, transport efficiency and even infotainment on the
wheels, in which a great number of traffic event-driven messages are needed to
disseminate in a region of interest timely. However, due to the nature of
VANETs, highly dynamic mobility and frequent disconnection, data dissemination
faces great challenges. Inter-Vehicle Communication (IVC) protocols are the key
technology to mitigate this issue. Therefore, we propose an infrastructure-less
Traffic Adaptive data Dissemination (TrAD) protocol that considers road traffic
and network traffic status for both highway and urban scenarios. TrAD is
flexible to fit the irregular road topology and owns double broadcast
suppression techniques. Three state-of-the-art IVC protocols have been compared
with TrAD by means of realistic simulations. The performance of all protocols
is quantitatively evaluated with different real city maps and traffic routes.
Finally, TrAD gets an outstanding overall performance in terms of several
metrics, even though under the worse condition of GPS drift.
</dc:description>
 <dc:description>Comment: Accepted by the 30-th IEEE International Conference on Advanced
  Information Networking and Applications (AINA-2016)</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08030</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What if we considered awareness for sustainable Kwowledge Management ?
  Towards a model for self regulated knowledge management systems based on
  acceptance models of technologies and awareness</dc:title>
 <dc:creator>Tour&#xe9;, Carine</dc:creator>
 <dc:creator>Michel, Christine</dc:creator>
 <dc:creator>Marty, Jean-Charles</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We propose, in this paper, a model of continuous use of corporate
collaborative KMS. Companies do not always have the guaranty that their KMS
will be continuously used. This statement can constitute an important obstacle
for knowledge management processes. Our work is based on the analysis of
classical models for initial and continuous use of technologies. We also
analyse the regulation concept and explain how it is valuable to support a
continuous use of KMS. We observed that awareness may be a regulation means
that allows taking this problem into account. Awareness is a concept, which has
been profusely used to improve user experience in collaborative environments.
It is an important element for regulation of activity. In our model, we assume
that one can integrate awareness in information systems to positively influence
beliefs about them. The final objective of our work is to refine some concepts
to fit the particularities of collaborative KMS and to propose an awareness
regulation process using the traces of the users' interactions with the
systems.
</dc:description>
 <dc:description>Comment: Knowledge Management and Information Sharing (KMIS), Oct 2014, Rome,
  Italy. 2014</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08031</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identity Testing for constant-width, and commutative, read-once
  oblivious ABPs</dc:title>
 <dc:creator>Gurjar, Rohit</dc:creator>
 <dc:creator>Korwar, Arpita</dc:creator>
 <dc:creator>Saxena, Nitin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We give improved hitting-sets for two special cases of Read-once Oblivious
Arithmetic Branching Programs (ROABP). First is the case of an ROABP with known
variable order. The best hitting-set known for this case had cost $(nw)^{O(\log
n)}$, where $n$ is the number of variables and $w$ is the width of the ROABP.
Even for a constant-width ROABP, nothing better than a quasi-polynomial bound
was known. We improve the hitting-set complexity for the known-order case to
$n^{O(\log w)}$. In particular, this gives the first polynomial time
hitting-set for constant-width ROABP (known-order). However, our hitting-set
works only over those fields whose characteristic is zero or large enough. To
construct the hitting-set, we use the concept of the rank of partial derivative
matrix. Unlike previous approaches whose basic building block is a monomial
map, we use a polynomial map.
  The second case we consider is that of commutative ROABP. The best known
hitting-set for this case had cost $d^{O(\log w)}(nw)^{O(\log \log w)}$, where
$d$ is the individual degree. We improve this hitting-set complexity to
$(ndw)^{O(\log \log w)}$. We get this by achieving rank concentration more
efficiently.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08032</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Re-designing knowledge management systems : Towards user-centred design
  methods integrating information architecture</dc:title>
 <dc:creator>Tour&#xe9;, Carine</dc:creator>
 <dc:creator>Michel, Christine</dc:creator>
 <dc:creator>Marty, Jean-Charles</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The work presented in this paper focuses on the improvement of corporate
knowledge management systems. For the implementation of such systems, companies
deploy can important means for small gains. Indeed, management services often
notice very limited use compared to what they actually expect. We present a
five-step redesigning approach which takes into account different factors to
increase the use of these systems. We use as an example the knowledge sharing
platform implemented for the employees of Soci{\'e}t{\'e} du Canal de Provence
(SCP). This system was taken into production but very occasionally used. We
describe the reasons for this limited use and we propose a design methodology
adapted to the context. Promoting the effective use of the system, our approach
has been experimented and evaluated with a panel of users working at SCP.
</dc:description>
 <dc:description>Comment: in Knowledge Management and Information Sharing, Oct 2014, Rome,
  Italy</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08039</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Distributed Snapshot Algorithms</dc:title>
 <dc:creator>Srivatsa, Sharath</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Snapshot recording durations at each process contribute to the overall
efficiency of the algorithm. In this paper we are presenting the observed
variations in snapshot recording durations at processes in a distributed
system. We conclude with key characteristics of a reliable and effective
snapshot algorithm. Simulations were achieved using SimGrid Java API.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08039</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08046</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Formal Approach to Power Optimization in CPSs with Delay-Workload
  Dependence Awareness</dc:title>
 <dc:creator>An, Hyung-Chan</dc:creator>
 <dc:creator>Yang, Hoeseok</dc:creator>
 <dc:creator>Ha, Soonhoi</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:subject>C.3</dc:subject>
 <dc:description>  The design of cyber-physical systems (CPSs) faces various new challenges that
are unheard of in the design of classical real-time systems. Power optimization
is one of the major design goals that is witnessing such new challenges. The
presence of interaction between the cyber and physical components of a CPS
leads to dependence between the time delay of a computational task and the
amount of workload in the next iteration. We demonstrate that it is essential
to take this delay-workload dependence into consideration in order to achieve
low power consumption.
  In this paper, we identify this new challenge, and present the first formal
and comprehensive model to enable rigorous investigations on this topic. We
propose a simple power management policy, and show that this policy achieves a
best possible notion of optimality. In fact, we show that the optimal power
consumption is attained in a &quot;steady-state&quot; operation and a simple policy of
finding and entering this steady state suffices, which can be quite surprising
considering the added complexity of this problem. Finally, we validated the
efficiency of our policy with experiments.
</dc:description>
 <dc:description>Comment: 27 pages, 8 figures, 3 tables</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08049</identifier>
 <datestamp>2016-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Individual Bibliometric Assessment @ University of Vienna: From Numbers
  to Multidimensional Profiles</dc:title>
 <dc:creator>Gorraiz, Juan</dc:creator>
 <dc:creator>Wieland, Martin</dc:creator>
 <dc:creator>Gumpenberger, Christian</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This paper shows how bibliometric assessment can be implemented at individual
level. This has been successfully done at the University of Vienna carried out
by the Bibliometrics and Publication Strategies Department of the Vienna
University Library. According to the department's philosophy, bibliometrics is
not only a helpful evaluation instrument in order to complement the peer review
system. It is also meant as a compass for researchers in the &quot;publish or
perish&quot; dilemma in order to increase general visibility and to optimize
publication strategies. The individual assessment comprises of an interview
with the researcher under evaluation, the elaboration of a bibliometric report
of the researcher's publication output, the discussion and validation of the
obtained results with the researcher under evaluation as well as further
optional analyses. The produced bibliometric reports are provided to the
researchers themselves and inform them about the quantitative aspects of their
research output. They also serve as a basis for further discussion concerning
their publication strategies. These reports are eventually intended for
informed peer review practices, and are therefore forwarded to the quality
assurance and the rector's office and finally sent to the peers. The most
important feature of the generated bibliometric report is its multidimensional
and individual character. It relies on a variety of basic indicators and
further control parameters in order to foster comprehensibility. Researchers,
administrative staff and peers alike have confirmed the usefulness of this
bibliometric approach. An increasing demand is noticeable. In total, 33
bibliometric reports have been delivered so far. Moreover, similar reports have
also been produced for the bibliometric assessment of two faculties with great
success.
</dc:description>
 <dc:description>Comment: Preprint</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08049</dc:identifier>
 <dc:identifier>doi:10.5281/zenodo.45402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08051</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimal Suffix and Rotation of a Substring in Optimal Time</dc:title>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W32 (Primary), 68P05, 68R15 (Secondary)</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  For a text given in advance, the substring minimal suffix queries ask to
determine the lexicographically minimal non-empty suffix of a substring
specified by the location of its occurrence in the text. We develop a data
structure answering such queries optimally: in constant time after linear-time
preprocessing. This improves upon the results of Babenko et al. (CPM 2014),
whose trade-off solution is characterized by $\Theta(n\log n)$ product of these
time complexities. Next, we extend our queries to support concatenations of
$O(1)$ substrings, for which the construction and query time is preserved. We
apply these generalized queries to compute lexicographically minimal and
maximal rotations of a given substring in constant time after linear-time
preprocessing.
  Our data structures mainly rely on properties of Lyndon words and Lyndon
factorizations. We combine them with further algorithmic and combinatorial
tools, such as fusion trees and the notion of order isomorphism of strings.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08051</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08059</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploration and Visualization in the Web of Big Linked Data: A Survey of
  the State of the Art</dc:title>
 <dc:creator>Bikakis, Nikos</dc:creator>
 <dc:creator>Sellis, Timos</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>97R50, 68P05, 68P15</dc:subject>
 <dc:subject>E.1</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:subject>H.5.2</dc:subject>
 <dc:subject>H.4</dc:subject>
 <dc:description>  Data exploration and visualization systems are of great importance in the Big
Data era. Exploring and visualizing very large datasets has become a major
research challenge, of which scalability is a vital requirement. In this
survey, we describe the major prerequisites and challenges that should be
addressed by the modern exploration and visualization systems. Considering
these challenges, we present how state-of-the-art approaches from the Database
and Information Visualization communities attempt to handle them. Finally, we
survey the systems developed by Semantic Web community in the context of the
Web of Linked Data, and discuss to which extent these satisfy the contemporary
requirements.
</dc:description>
 <dc:description>Comment: 6th International Workshop on Linked Web Data Management (LWDM 2016)</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08062</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis for Pilot-based 1-bit Channel Estimation with
  Unknown Quantization Threshold</dc:title>
 <dc:creator>Stein, Manuel</dc:creator>
 <dc:creator>Bar, Shahar</dc:creator>
 <dc:creator>Nossek, Josef A.</dc:creator>
 <dc:creator>Tabrikian, Joseph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Parameter estimation using quantized observations is of importance in many
practical applications. Under a symmetric $1$-bit setup, consisting of a
zero-threshold hard-limiter, it is well known that the large sample performance
loss for low signal-to-noise ratios (SNRs) is moderate ($\frac{2}{\pi}$ or
$-1.96$dB). This makes low-complexity analog-to-digital converters (ADCs) with
$1$-bit resolution a promising solution for future wireless communications and
signal processing devices. However, hardware imperfections and external effects
introduce the quantizer with an unknown hard-limiting level different from
zero. In this paper, the performance loss associated with pilot-based channel
estimation, subject to an asymmetric hard limiter with unknown offset, is
studied under two setups. The analysis is carried out via the Cram\'{e}r-Rao
lower bound (CRLB) and an expected CRLB for a setup with random parameter. Our
findings show that the unknown threshold leads to an additional information
loss, which vanishes for low SNR values or when the offset is close to zero.
</dc:description>
 <dc:description>Comment: IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), Shanghai, China, 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08062</dc:identifier>
 <dc:identifier>doi:10.1109/ICASSP.2016.7472499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08067</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relaxed Byzantine Vector Consensus</dc:title>
 <dc:creator>Xiang, Zhuolun</dc:creator>
 <dc:creator>Vaidya, Nitin H.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Exact Byzantine consensus problem requires that non-faulty processes reach
agreement on a decision (or output) that is in the convex hull of the inputs at
the non-faulty processes. It is well-known that exact consensus is impossible
in an asynchronous system in presence of faults, and in a synchronous system,
n&gt;=3f+1 is tight on the number of processes to achieve exact Byzantine
consensus with scalar inputs, in presence of up to f Byzantine faulty
processes. Recent work has shown that when the inputs are d-dimensional vectors
of reals, n&gt;=max(3f+1,(d+1)f+1) is tight to achieve exact Byzantine consensus
in synchronous systems, and n&gt;= (d+2)f+1 for approximate Byzantine consensus in
asynchronous systems.
  Due to the dependence of the lower bound on vector dimension d, the number of
processes necessary becomes large when the vector dimension is large. With the
hope of reducing the lower bound on n, we consider two relaxed versions of
Byzantine vector consensus: k-Relaxed Byzantine vector consensus and
(delta,p)-Relaxed Byzantine vector consensus. In k-relaxed consensus, the
validity condition requires that the output must be in the convex hull of
projection of the inputs onto any subset of k-dimensions of the vectors. For
(delta,p)-consensus the validity condition requires that the output must be
within distance delta of the convex hull of the inputs of the non-faulty
processes, where L_p norm is used as the distance metric. For
(delta,p)-consensus, we consider two versions: in one version, delta is a
constant, and in the second version, delta is a function of the inputs
themselves.
  We show that for k-relaxed consensus and (delta,p)-consensus with constant
delta&gt;=0, the bound on n is identical to the bound stated above for the
original vector consensus problem. On the other hand, when delta depends on the
inputs, we show that the bound on n is smaller when d&gt;=3.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08068</identifier>
 <datestamp>2017-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>System Identification through Online Sparse Gaussian Process Regression
  with Input Noise</dc:title>
 <dc:creator>Bijl, Hildo</dc:creator>
 <dc:creator>Sch&#xf6;n, Thomas B.</dc:creator>
 <dc:creator>van Wingerden, Jan-Willem</dc:creator>
 <dc:creator>Verhaegen, Michel</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  There has been a growing interest in using non-parametric regression methods
like Gaussian Process (GP) regression for system identification. GP regression
does traditionally have three important downsides: (1) it is computationally
intensive, (2) it cannot efficiently implement newly obtained measurements
online, and (3) it cannot deal with stochastic (noisy) input points. In this
paper we present an algorithm tackling all these three issues simultaneously.
The resulting Sparse Online Noisy Input GP (SONIG) regression algorithm can
incorporate new noisy measurements in constant runtime. A comparison has shown
that it is more accurate than similar existing regression algorithms. When
applied to non-linear black-box system modeling, its performance is competitive
with existing non-linear ARX models.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2017-08-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08084</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generalized bent functions - sufficient conditions and related
  constructions</dc:title>
 <dc:creator>Hod&#x17e;i&#x107;, S.</dc:creator>
 <dc:creator>Pasalic, E.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The necessary and sufficient conditions for a class of functions
$f:\mathbb{Z}_2^n \rightarrow \mathbb{Z}_q$, where $q \geq 2$ is an even
positive integer, have been recently identified for $q=4$ and $q=8$. In this
article we give an alternative characterization of the generalized
Walsh-Hadamard transform in terms of the Walsh spectra of the component Boolean
functions of $f$, which then allows us to derive sufficient conditions that $f$
is generalized bent for any even $q$. The case when $q$ is not a power of two,
which has not been addressed previously, is treated separately and a suitable
representation in terms of the component functions is employed. Consequently,
the derived results lead to generic construction methods of this class of
functions. The main remaining task, which is not answered in this article, is
whether the sufficient conditions are also necessary. There are some
indications that this might be true which is also formally confirmed for
generalized bent functions that belong to the class of generalized
Maiorana-McFarland functions (GMMF), but still we were unable to completely
specify (in terms of necessity) gbent conditions.
</dc:description>
 <dc:description>Comment: 20 pages</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08091</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the validity of tidal turbine array configurations obtained from
  steady-state adjoint optimisation</dc:title>
 <dc:creator>Jacobs, Christian T.</dc:creator>
 <dc:creator>Piggott, Matthew D.</dc:creator>
 <dc:creator>Kramer, Stephan C.</dc:creator>
 <dc:creator>Funke, Simon W.</dc:creator>
 <dc:subject>Physics - Fluid Dynamics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Extracting the optimal amount of power from an array of tidal turbines
requires an intricate understanding of tidal dynamics and the effects of
turbine placement on the local and regional scale flow. Numerical models have
contributed significantly towards this understanding, and more recently,
adjoint-based modelling has been employed to optimise the positioning of the
turbines in an array in an automated way and improve on simple, regular
man-made configurations. Adjoint-based optimisation of high-resolution and
ideally 3D transient models is generally a very computationally expensive
problem. As a result, existing work on the adjoint optimisation of tidal
turbine placement has been mostly limited to steady-state simulations in which
very high, non-physical values of the background viscosity are required to
ensure that a steady-state solution exists. However, such compromises may
affect the reliability of the modelled turbines, their wakes and interactions,
and thus bring into question the validity of the computed optimal turbine
positions. This work considers a suite of idealised simulations of flow past
tidal turbine arrays in a 2D channel. It compares four regular array
configurations, detailed by Divett et al. (2013), with the configuration found
through adjoint optimisation in a steady-state, high-viscosity setup. The
optimised configuration produces considerably more power. The same
configurations are then used to produce a suite of transient simulations that
do not use constant high-viscosity, and instead use large eddy simulation (LES)
to parameterise the resulting turbulent structures. It is shown that the LES
simulations produce less power than that predicted by the constant
high-viscosity runs. Nevertheless, they still follow the same trends in the
power curve throughout time, with optimised layouts continuing to perform
significantly better than simplified configurations.
</dc:description>
 <dc:description>Comment: Conference paper comprising 15 pages and 13 figures. Submitted to the
  Proceedings of the ECCOMAS Congress 2016 (VII European Congress on
  Computational Methods in Applied Sciences and Engineering), held in Crete,
  Greece on 5-10 June 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08111</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Two-Phase Algorithm for Bin Stretching with Stretching Factor 1.5</dc:title>
 <dc:creator>B&#xf6;hm, Martin</dc:creator>
 <dc:creator>Sgall, Ji&#x159;&#xed;</dc:creator>
 <dc:creator>van Stee, Rob</dc:creator>
 <dc:creator>Vesel&#xfd;, Pavel</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W27, 68W40</dc:subject>
 <dc:description>  Online Bin Stretching is a semi-online variant of bin packing in which the
algorithm has to use the same number of bins as an optimal packing, but is
allowed to slightly overpack the bins. The goal is to minimize the amount of
overpacking, i.e., the maximum size packed into any bin.
  We give an algorithm for Online Bin Stretching with a stretching factor of
1.5 for any number of bins. We build on previous algorithms and use a two-phase
approach. However, our analysis is technically more complicated and uses
amortization over the bins with the help of two weight functions.
</dc:description>
 <dc:description>Comment: Preprint of a journal version; updated title and some minor edits.
  The conference version can be found at arXiv:1404.5569 version 2</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-08-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08112</identifier>
 <datestamp>2016-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Channel Pre-Inversion and max-SINR Vector Perturbation for Large-Scale
  Broadcast Channels</dc:title>
 <dc:creator>Karpuk, David A.</dc:creator>
 <dc:creator>Moss, Peter</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study channel pre-inversion and vector perturbation (VP) schemes for
large-scale broadcast channels, wherein a transmitter has $M$ transmit antennas
and is transmitting to $K$ single-antenna non-cooperating receivers. We provide
results which predict the capacity of MMSE pre-inversion as
$K\rightarrow\infty$. We construct a new VP strategy, max-SINR vector
perturbation (MSVP), which maximizes a sharp estimate of the
signal-to-interference-plus-noise ratio. We provide results which predict the
performance of MSVP and demonstrate that MSVP outperforms other VP methods.
Lastly, we combine MSVP with the low-complexity Sorted QR Precoding method to
show that MSVP has the potential to efficiently deliver data to a very large
number of users at close to channel capacity.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-09-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08112</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08116</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Densifying the sparse cloud SimSaaS: The need of a synergy among
  agent-directed simulation, SimSaaS and HLA</dc:title>
 <dc:creator>Azevedo, Tiago</dc:creator>
 <dc:creator>Rossetti, Rosaldo J. F.</dc:creator>
 <dc:creator>Barbosa, Jorge G.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Modelling &amp; Simulation (M&amp;S) is broadly used in real scenarios where making
physical modifications could be highly expensive. With the so-called Simulation
Software-as-a-Service (SimSaaS), researchers could take advantage of the huge
amount of resource that cloud computing provides. Even so, studying and
analysing a problem through simulation may need several simulation tools, hence
raising interoperability issues. Having this in mind, IEEE developed a standard
for interoperability among simulators named High Level Architecture (HLA).
Moreover, the multi-agent system approach has become recognised as a convenient
approach for modelling and simulating complex systems. Despite all the recent
works and acceptance of these technologies, there is still a great lack of work
regarding synergies among them. This paper shows by means of a literature
review this lack of work or, in other words, the sparse Cloud SimSaaS. The
literature review and the resulting taxonomy are the main contributions of this
paper, as they provide a research agenda illustrating future research
opportunities and trends.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08116</dc:identifier>
 <dc:identifier>Proceedings of the 5th International Conference on Simulation and
  Modeling Methodologies, Technologies and Applications (2015) 172-177</dc:identifier>
 <dc:identifier>doi:10.5220/0005542801720177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08117</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measurement-driven Quality Assessment of Nonlinear Systems by
  Exponential Replacement</dc:title>
 <dc:creator>Stein, Manuel</dc:creator>
 <dc:creator>Nossek, Josef A.</dc:creator>
 <dc:creator>Barb&#xe9;, Kurt</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We discuss the problem how to determine the quality of a nonlinear system
with respect to a measurement task. Due to amplification, filtering,
quantization and internal noise sources physical measurement equipment in
general exhibits a nonlinear and random input-to-output behaviour. This usually
makes it impossible to accurately describe the underlying statistical system
model. When the individual operations are all known and deterministic, one can
resort to approximations of the input-to-output function. The problem becomes
challenging when the processing chain is not exactly known or contains
nonlinear random effects. Then one has to approximate the output distribution
in an empirical way. Here we show that by measuring the first two sample
moments of an arbitrary set of output transformations in a calibrated setup,
the output distribution of the actual system can be approximated by an
equivalent exponential family distribution. This method has the property that
the resulting approximation of the statistical system model is guaranteed to be
pessimistic in an estimation theoretic sense. We show this by proving that an
equivalent exponential family distribution in general exhibits a lower Fisher
information measure than the original system model. With various examples and a
model matching step we demonstrate how this estimation theoretic aspect can be
exploited in practice in order to obtain a conservative measurement-driven
quality assessment method for nonlinear measurement systems.
</dc:description>
 <dc:description>Comment: IEEE International Instrumentation and Measurement Technology
  Conference (I2MTC), Taipei, Taiwan, 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08117</dc:identifier>
 <dc:identifier>doi:10.1109/I2MTC.2016.7520370</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08123</identifier>
 <datestamp>2016-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space-Time Index Modulation</dc:title>
 <dc:creator>Jacob, Swaroop</dc:creator>
 <dc:creator>Narasimhan, T. Lakshmi</dc:creator>
 <dc:creator>Chockalingam, A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present a new multi-antenna modulation scheme, termed as
{\em space-time index modulation (STIM)}. In STIM, information bits are
conveyed through antenna indexing in the spatial domain, slot indexing in the
time domain, and $M$-ary modulation symbols. A time slot in a given frame can
be used or unused, and the choice of the slots used for transmission conveys
slot index bits. In addition, antenna index bits are conveyed in every used
time slot by activating one among the available antennas. $M$-ary symbols are
sent on the active antenna in a used time slot. We study STIM in a
cyclic-prefixed single-carrier (CPSC) system in frequency-selective fading
channels. It is shown that, for the same spectral efficiency, STIM can achieve
better performance compared to conventional orthogonal frequency division
multiplexing (OFDM). Low-complexity iterative algorithms for the detection of
large-dimensional STIM signals are also presented.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-09-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08132</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interference Management in Heterogeneous Networks with Blind
  Transmitters</dc:title>
 <dc:creator>Kalokidou, Vaia</dc:creator>
 <dc:creator>Johnson, Oliver</dc:creator>
 <dc:creator>Piechocki, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Future multi-tier communication networks will require enhanced network
capacity and reduced overhead. In the absence of Channel State Information
(CSI) at the transmitters, Blind Interference Alignment (BIA) and Topological
Interference Management (TIM) can achieve optimal Degrees of Freedom (DoF),
minimising network's overhead. In addition, Non-Orthogonal Multiple Access
(NOMA) can increase the sum rate of the network, compared to orthogonal radio
access techniques currently adopted by 4G networks. Our contribution is two
interference management schemes, BIA and a hybrid TIM-NOMA scheme, employed in
heterogeneous networks by applying user-pairing and Kronecker Product
representation. BIA manages inter- and intra-cell interference by antenna
selection and appropriate message scheduling. The hybrid scheme manages
intra-cell interference based on NOMA and inter-cell interference based on TIM.
We show that both schemes achieve at least double the rate of TDMA. The hybrid
scheme always outperforms TDMA and BIA in terms of Degrees of Freedom (DoF).
Comparing the two proposed schemes, BIA achieves more DoF than TDMA under
certain restrictions, and provides better Bit-Error-Rate (BER) and sum rate
performance to macrocell users, whereas the hybrid scheme improves the
performance of femtocell users.
</dc:description>
 <dc:description>Comment: 30 pages, 18 figures</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08132</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08139</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantitative Evaluation of Chaotic CBC Mode of Operation</dc:title>
 <dc:creator>Abidi, Abdessalem</dc:creator>
 <dc:creator>Wang, Qianxue</dc:creator>
 <dc:creator>Bouall&#xe8;gue, Belgacem</dc:creator>
 <dc:creator>Machhout, Mohsen</dc:creator>
 <dc:creator>Gyeux, Christophe</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The cipher block chaining (CBC) block cipher mode of operation presents a
very popular way of encrypting which is used in various applications. In
previous research work, we have mathematically proven that, under some
conditions, this mode of operation can admit a chaotic behavior according to
Devaney. Proving that CBC mode is chaotic is only the beginning of the study of
its security. The next step, which is the purpose of this paper, is to develop
the quantitative study of the chaotic CBC mode of operation by evaluating the
level of sensibility and expansivity for this mode.
</dc:description>
 <dc:description>Comment: in International Conference on Advanced Technologies for Signal &amp;
  Images Processing ATSIP'2016 , Mar 2016, Monastir, Tunisia</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08154</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>JADE, TraSMAPI and SUMO: A tool-chain for simulating traffic light
  control</dc:title>
 <dc:creator>Azevedo, Tiago</dc:creator>
 <dc:creator>de Ara&#xfa;jo, Paulo J. M.</dc:creator>
 <dc:creator>Rossetti, Rosaldo J. F.</dc:creator>
 <dc:creator>Rocha, Ana Paula C.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Increased stress, fuel consumption, air pollution, accidents and delays are
some of the consequences of traffic congestion usually incurring in tremendous
economic impacts, which society aims to remedy in order to leverage a
sustainable development. Recently, unconventional means for modeling and
controlling such complex traffic systems relying on multi-agent systems have
arisen. This paper contributes to the understanding of such complex and highly
dynamic systems by proposing an open-source tool-chain to implement
multi-agent-based solutions in traffic and transportation. The proposed
approach relies on two very popular tools in both domains, with focus on
traffic light control. This tool-chain consists in combining JADE (Java Agent
DEvelopment Framework), for the implementation of multi-agent systems, with
SUMO (Simulation of Urban MObility), for the microscopic simulation of traffic
interactions. TraSMAPI (Traffic Simulation Manager Application Programming
Interface) is used to combine JADE and SUMO allowing communication between
them. A demonstration of the concept is presented to illustrate the main
features of this tool-chain, using Q-Learning as the reinforcement learning
method for each traffic light agent in a simulated network. Results demonstrate
the feasibility of the proposed framework as a practical means to experiment
with different agent-based designs of intelligent transportation solutions.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08154</dc:identifier>
 <dc:identifier>Proceedings of the 8th International Workshop on Agents in Traffic
  and Transportation, ATT'14, held at the Thirteenth International Joint
  Conference on Autonomous Agents and Multiagent Systems, AAMAS'14 (2014) 8-15</dc:identifier>
 <dc:identifier>doi:10.13140/2.1.2739.4886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08158</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Localization in the PCL library</dc:title>
 <dc:creator>Mart&#xed;nez-G&#xf3;mez, Jes&#xfa;s</dc:creator>
 <dc:creator>Morell, Vicente</dc:creator>
 <dc:creator>Cazorla, Miguel</dc:creator>
 <dc:creator>Garc&#xed;a-Varea, Ismael</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The semantic localization problem in robotics consists in determining the
place where a robot is located by means of semantic categories. The problem is
usually addressed as a supervised classification process, where input data
correspond to robot perceptions while classes to semantic categories, like
kitchen or corridor.
  In this paper we propose a framework, implemented in the PCL library, which
provides a set of valuable tools to easily develop and evaluate semantic
localization systems. The implementation includes the generation of 3D global
descriptors following a Bag-of-Words approach. This allows the generation of
dimensionality-fixed descriptors from any type of keypoint detector and feature
extractor combinations. The framework has been designed, structured and
implemented in order to be easily extended with different keypoint detectors,
feature extractors as well as classification models.
  The proposed framework has also been used to evaluate the performance of a
set of already implemented descriptors, when used as input for a specific
semantic localization system. The results obtained are discussed paying special
attention to the internal parameters of the BoW descriptor generation process.
Moreover, we also review the combination of some keypoint detectors with
different 3D descriptor generation techniques.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures, ISSN 0921-8890</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08158</dc:identifier>
 <dc:identifier>Robotics and Autonomous Systems, Volume 75, Part B, January 2016,
  Pages 641-648</dc:identifier>
 <dc:identifier>doi:10.1016/j.robot.2015.09.006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08162</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A State-of-the-art Integrated Transportation Simulation Platform</dc:title>
 <dc:creator>Azevedo, Tiago</dc:creator>
 <dc:creator>Rossetti, Rosaldo J. F.</dc:creator>
 <dc:creator>Barbosa, Jorge G.</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Nowadays, universities and companies have a huge need for simulation and
modelling methodologies. In the particular case of traffic and transportation,
making physical modifications to the real traffic networks could be highly
expensive, dependent on political decisions and could be highly disruptive to
the environment. However, while studying a specific domain or problem,
analysing a problem through simulation may not be trivial and may need several
simulation tools, hence raising interoperability issues. To overcome these
problems, we propose an agent-directed transportation simulation platform,
through the cloud, by means of services. We intend to use the IEEE standard HLA
(High Level Architecture) for simulators interoperability and agents for
controlling and coordination. Our motivations are to allow multiresolution
analysis of complex domains, to allow experts to collaborate on the analysis of
a common problem and to allow co-simulation and synergy of different
application domains. This paper will start by presenting some preliminary
background concepts to help better understand the scope of this work. After
that, the results of a literature review is shown. Finally, the general
architecture of a transportation simulation platform is proposed.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08162</dc:identifier>
 <dc:identifier>Proceedings of the 4th International Conference on Models and
  Technologies for Intelligent Transportation Systems (2015) 340-347</dc:identifier>
 <dc:identifier>doi:10.1109/MTITS.2015.7223277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08165</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mapping Tractography Across Subjects</dc:title>
 <dc:creator>Nguyen, Thien Bao</dc:creator>
 <dc:creator>Olivetti, Emanuele</dc:creator>
 <dc:creator>Avesani, Paolo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Diffusion magnetic resonance imaging (dMRI) and tractography provide means to
study the anatomical structures within the white matter of the brain. When
studying tractography data across subjects, it is usually necessary to align,
i.e. to register, tractographies together. This registration step is most often
performed by applying the transformation resulting from the registration of
other volumetric images (T1, FA). In contrast with registration methods that
&quot;transform&quot; tractographies, in this work, we try to find which streamline in
one tractography correspond to which streamline in the other tractography,
without any transformation. In other words, we try to find a &quot;mapping&quot; between
the tractographies. We propose a graph-based solution for the tractography
mapping problem and we explain similarities and differences with the related
well-known graph matching problem. Specifically, we define a loss function
based on the pairwise streamline distance and reformulate the mapping problem
as combinatorial optimization of that loss function. We show preliminary
promising results where we compare the proposed method, implemented with
simulated annealing, against a standard registration techniques in a task of
segmentation of the corticospinal tract.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08169</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Kernels for sequentially ordered data</dc:title>
 <dc:creator>Kir&#xe1;ly, Franz J</dc:creator>
 <dc:creator>Oberhauser, Harald</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  We present a novel framework for kernel learning with sequential data of any
kind, such as time series, sequences of graphs, or strings. Our approach is
based on signature features which can be seen as an ordered variant of sample
(cross-)moments; it allows to obtain a &quot;sequentialized&quot; version of any static
kernel. The sequential kernels are efficiently computable for discrete
sequences and are shown to approximate a continuous moment form in a sampling
sense.
  A number of known kernels for sequences arise as &quot;sequentializations&quot; of
suitable static kernels: string kernels may be obtained as a special case, and
alignment kernels are closely related up to a modification that resolves their
open non-definiteness issue. Our experiments indicate that our signature-based
sequential kernel framework may be a promising approach to learning with
sequential data, such as time series, that allows to avoid extensive manual
pre-processing.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08176</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weakly Mutually Uncorrelated Codes</dc:title>
 <dc:creator>Yazdi, S. M. Hossein Tabatabaei</dc:creator>
 <dc:creator>Kiah, Han Mao</dc:creator>
 <dc:creator>Milenkovic, Olgica</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We introduce the notion of weakly mutually uncorrelated (WMU) sequences,
motivated by applications in DNA-based storage systems and synchronization
protocols. WMU sequences are characterized by the property that no sufficiently
long suffix of one sequence is the prefix of the same or another sequence. In
addition, WMU sequences used in DNA-based storage systems are required to have
balanced compositions of symbols and to be at large mutual Hamming distance
from each other. We present a number of constructions for balanced,
error-correcting WMU codes using Dyck paths, Knuth's balancing principle,
prefix synchronized and cyclic codes.
</dc:description>
 <dc:description>Comment: 1 table</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08179</identifier>
 <datestamp>2017-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Factorizing the factorization - a spectral-element solver for elliptic
  equations with linear operation count</dc:title>
 <dc:creator>Huismann, Immo</dc:creator>
 <dc:creator>Stiller, J&#xf6;rg</dc:creator>
 <dc:creator>Fr&#xf6;hlich, Jochen</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  High-order methods gain more and more attention in computational fluid
dynamics. However, the potential advantage of these methods depends critically
on the availability of efficient elliptic solvers. With spectral-element
methods, static condensation is a common approach to reduce the number of
degree of freedoms and to improve the condition of the algebraic equations. The
resulting system is block-structured and the face-based operator well suited
for matrix-matrix multiplications. However, a straight-forward implementation
scales super-linearly with the number of unknowns and, therefore, prohibits the
application to high polynomial degrees. This paper proposes a novel
factorization technique, which yields a linear operation count of just 13N
multiplications, where N is the total number of unknowns. In comparison to
previous work it saves a factor larger than 3 and clearly outpaces unfactored
variants for all polynomial degrees. Using the new technique as a building
block for a preconditioned conjugate gradient method resulted in a runtime
scaling linearly with N for polynomial degrees $2 \leq p \leq 32$ . Moreover
the solver proved remarkably robust for aspect ratios up to 128.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08179</dc:identifier>
 <dc:identifier>doi:10.1016/j.jcp.2017.06.012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08188</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lipreading with Long Short-Term Memory</dc:title>
 <dc:creator>Wand, Michael</dc:creator>
 <dc:creator>Koutn&#xed;k, Jan</dc:creator>
 <dc:creator>Schmidhuber, J&#xfc;rgen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Lipreading, i.e. speech recognition from visual-only recordings of a
speaker's face, can be achieved with a processing pipeline based solely on
neural networks, yielding significantly better accuracy than conventional
methods. Feed-forward and recurrent neural network layers (namely Long
Short-Term Memory; LSTM) are stacked to form a single structure which is
trained by back-propagating error gradients through all the layers. The
performance of such a stacked network was experimentally evaluated and compared
to a standard Support Vector Machine classifier using conventional computer
vision features (Eigenlips and Histograms of Oriented Gradients). The
evaluation was performed on data from 19 speakers of the publicly available
GRID corpus. With 51 different words to classify, we report a best word
accuracy on held-out evaluation speakers of 79.6% using the end-to-end neural
network-based solution (11.6% improvement over the best feature-based solution
evaluated).
</dc:description>
 <dc:description>Comment: Accepted for publication at ICASSP 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08188</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08189</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Right Way to Search Evolving Graphs</dc:title>
 <dc:creator>Chen, Jiahao</dc:creator>
 <dc:creator>Zhang, Weijian</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>05C82, 91D30</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Evolving graphs arise in problems where interrelations between data change
over time. We present a breadth first search (BFS) algorithm for evolving
graphs that computes the most direct influences between nodes at two different
times. Using simple examples, we show that naive unfoldings of adjacency
matrices miscount the number of temporal paths. By mapping an evolving graph to
an adjacency matrix of an equivalent static graph, we prove that our
generalization of the BFS algorithm correctly accounts for paths that traverse
both space and time. Finally, we demonstrate how the BFS over evolving graphs
can be applied to mine citation networks.
</dc:description>
 <dc:description>Comment: 10 pages, 5 figures</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-03-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08189</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08190</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On MBR codes with replication</dc:title>
 <dc:creator>Krishnan, M. Nikhil</dc:creator>
 <dc:creator>Kumar, P. Vijay</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  An early paper by Rashmi et. al. presented the construction of an
$(n,k,d=n-1)$ MBR regenerating code featuring the inherent double replication
of all code symbols and repair-by-transfer (RBT), both of which are important
in practice. We first show that no MBR code can contain even a single code
symbol that is replicated more than twice. We then go on to present two new
families of MBR codes which feature double replication of all systematic
message symbols. The codes also possess a set of $d$ nodes whose contents
include the message symbols and which can be repaired through help-by-transfer
(HBT). As a corollary, we obtain systematic RBT codes for the case $d=(n-1)$
that possess inherent double replication of all code symbols and having a field
size of $O(n)$ in comparison with the general, $O(n^2)$ field size requirement
of the earlier construction by Rashmi et. al. For the cases $(k=d=n-2)$ or
$(k+1=d=n-2)$, the field size can be reduced to $q=2$, and hence the codes can
be binary. We also give a necessary and sufficient condition for the existence
of MBR codes having double replication of all code symbols and also suggest
techniques which will enable an arbitrary MBR code to be converted to one with
double replication of all code symbols.
</dc:description>
 <dc:description>Comment: Submitted to ISIT 2016</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08190</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08201</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrally Grouped Total Variation Reconstruction for Scatter Imaging
  Using ADMM</dc:title>
 <dc:creator>Odinaka, Ikenna</dc:creator>
 <dc:creator>Kaganovsky, Yan</dc:creator>
 <dc:creator>Greenberg, Joel A.</dc:creator>
 <dc:creator>Hassan, Mehadi</dc:creator>
 <dc:creator>Politte, David G.</dc:creator>
 <dc:creator>O'Sullivan, Joseph A.</dc:creator>
 <dc:creator>Carin, Lawrence</dc:creator>
 <dc:creator>Brady, David J.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We consider X-ray coherent scatter imaging, where the goal is to reconstruct
momentum transfer profiles (spectral distributions) at each spatial location
from multiplexed measurements of scatter. Each material is characterized by a
unique momentum transfer profile (MTP) which can be used to discriminate
between different materials. We propose an iterative image reconstruction
algorithm based on a Poisson noise model that can account for photon-limited
measurements as well as various second order statistics of the data. To improve
image quality, previous approaches use edge-preserving regularizers to promote
piecewise constancy of the image in the spatial domain while treating each
spectral bin separately. Instead, we propose spectrally grouped regularization
that promotes piecewise constant images along the spatial directions but also
ensures that the MTPs of neighboring spatial bins are similar, if they contain
the same material. We demonstrate that this group regularization results in
improvement of both spectral and spatial image quality. We pursue an
optimization transfer approach where convex decompositions are used to lift the
problem such that all hyper-voxels can be updated in parallel and in
closed-form. The group penalty introduces a challenge since it is not directly
amendable to these decompositions. We use the alternating directions method of
multipliers (ADMM) to replace the original problem with an equivalent sequence
of sub-problems that are amendable to convex decompositions, leading to a
highly parallel algorithm. We demonstrate the performance on real data.
</dc:description>
 <dc:description>Comment: Presented at IEEE Nuclear Science Symposium and Medical Imaging
  Conference (NSS/MIC) 2015. 4 pages, 2 figures</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08201</dc:identifier>
 <dc:identifier>doi:10.1109/NSSMIC.2015.7582220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08221</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WiSeDB: A Learning-based Workload Management Advisor for Cloud Databases</dc:title>
 <dc:creator>Marcus, Ryan</dc:creator>
 <dc:creator>Papaemmanouil, Olga</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Workload management for cloud databases must deal with the tasks of resource
provisioning, query placement and query scheduling in a manner that meets the
application's performance goals while minimizing the cost of using cloud
resources. Existing solutions have approached these three challenges in
isolation, and with only a particular type of performance goal in mind. In this
paper, we introduce WiSeDB, a learning-based framework for generating holistic
workload management solutions customized to application-defined performance
metrics and workload characteristics. Our approach relies on supervised
learning to train cost-effective decision tree models for guiding query
placement, scheduling, and resource provisioning decisions. Applications can
use these models for both batch and online scheduling of incoming workloads. A
unique feature of our system is that it can adapt its offline model to
stricter/looser performance goals with minimal re-training. This allows us to
present alternative workload management strategies that address the typical
performance vs. cost trade-off of cloud services. Experimental results show
that our approach has very low training overhead while offering low cost
strategies for a variety of performance goals and workload characteristics.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-04-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08221</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08224</identifier>
 <datestamp>2016-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New classes of degree sequences with fast mixing swap Markov chain
  sampling</dc:title>
 <dc:creator>Erd&#x151;s, P&#xe9;ter L.</dc:creator>
 <dc:creator>Mikl&#xf3;s, Istv&#xe1;n</dc:creator>
 <dc:creator>Toroczkai, Zolt&#xe1;n</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C07, 05C30, 05C81, 68R10</dc:subject>
 <dc:description>  In network modeling of complex systems one is often required to sample random
realizations of networks that obey a given set of constraints, usually in form
of graph measures. A much studied class of problems targets uniform sampling of
simple graphs with given degree sequence or also with given degree correlations
expressed in the form of a joint degree matrix. One approach is to use Markov
chains based on edge switches (swaps) that preserve the constraints, are
irreducible (ergodic) and fast mixing. In 1999, Kannan, Tetali and Vempala
(KTV) proposed a simple swap Markov chain for sampling graphs with given degree
sequence and conjectured that it mixes rapidly (in poly-time) for arbitrary
degree sequences. While the conjecture is still open, it was proven for special
degree sequences, in particular, for those of undirected and directed regular
simple graphs, of half-regular bipartite graphs, and of graphs with certain
bounded maximum degrees. Here we prove the fast mixing KTV conjecture for
novel, exponentially large classes of irregular degree sequences. Our method is
based on a canonical decomposition of degree sequences into split graph degree
sequences, a structural theorem for the space of graph realizations and on a
factorization theorem for Markov chains. After introducing bipartite splitted
degree sequences, we also generalize the canonical split graph decomposition
for bipartite and directed graphs.
</dc:description>
 <dc:description>Comment: submitted</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-12-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08227</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Reed-Solomon codes in the $\left( U\mid U+V\right)$ construction
  and an application to cryptography</dc:title>
 <dc:creator>M&#xe1;rquez-Corbella, Irene</dc:creator>
 <dc:creator>Tillich, Jean-Pierre</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we present a modification of Reed-Solomon codes that beats the
Guruwami-Sudan $1-\sqrt{R}$ decoding radius of Reed-Solomon codes at low rates
$R$. The idea is to choose Reed-Solomon codes $U$ and $V$ with appropriate
rates in a $\left( U\mid U+V\right)$ construction and to decode them with the
Koetter-Vardy soft information decoder. We suggest to use a slightly more
general version of these codes (but which has the same decoding performances as
the $\left( U\mid U+V\right)$-construction) for code-based cryptography, namely
to build a McEliece scheme. The point is here that these codes not only perform
nearly as well (or even better in the low rate regime) as Reed-Solomon codes,
their structure seems to avoid the Sidelnikov-Shestakov attack which broke a
previous McEliece proposal based on generalized Reed-Solomon codes.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08227</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08229</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the geometry of border rank algorithms for matrix multiplication and
  other tensors with symmetry</dc:title>
 <dc:creator>Landsberg, J. M.</dc:creator>
 <dc:creator>Micha&#x142;ek, Mateusz</dc:creator>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We establish basic information about border rank algorithms for the matrix
multiplication tensor and other tensors with symmetry. We prove that border
rank algorithms for tensors with symmetry (such as matrix multiplication and
the determinant polynomial) come in families that include representatives with
normal forms. These normal forms will be useful both to develop new efficient
algorithms and to prove lower complexity bounds. We derive a border rank
version of the substitution method used in proving lower bounds for tensor
rank. We use this border-substitution method and a normal form to improve the
lower bound on the border rank of matrix multiplication by one, to 2n^2- n+1.
We also point out difficulties that will be formidable obstacles to future
progress on lower complexity bounds for tensors because of the &quot;wild&quot; structure
of the Hilbert scheme of points.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08229</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1601.08237</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The omega-inequality problem for concatenation hierarchies of star-free
  languages</dc:title>
 <dc:creator>Almeida, J.</dc:creator>
 <dc:creator>Kl&#xed;ma, O.</dc:creator>
 <dc:creator>Kunc, M.</dc:creator>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Primary 20M05, 20M07, Secondary 20M35, 68Q70</dc:subject>
 <dc:description>  The problem considered in this paper is whether an inequality of omega-terms
is valid in a given level of a concatenation hierarchy of star-free languages.
The main result shows that this problem is decidable for all (integer and half)
levels of the Straubing-Th\'erien hierarchy.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2017-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1601.08237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00020</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep convolutional networks for automated detection of posterior-element
  fractures on spine CT</dc:title>
 <dc:creator>Roth, Holger R.</dc:creator>
 <dc:creator>Wang, Yinong</dc:creator>
 <dc:creator>Yao, Jianhua</dc:creator>
 <dc:creator>Lu, Le</dc:creator>
 <dc:creator>Burns, Joseph E.</dc:creator>
 <dc:creator>Summers, Ronald M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Injuries of the spine, and its posterior elements in particular, are a common
occurrence in trauma patients, with potentially devastating consequences.
Computer-aided detection (CADe) could assist in the detection and
classification of spine fractures. Furthermore, CAD could help assess the
stability and chronicity of fractures, as well as facilitate research into
optimization of treatment paradigms.
  In this work, we apply deep convolutional networks (ConvNets) for the
automated detection of posterior element fractures of the spine. First, the
vertebra bodies of the spine with its posterior elements are segmented in spine
CT using multi-atlas label fusion. Then, edge maps of the posterior elements
are computed. These edge maps serve as candidate regions for predicting a set
of probabilities for fractures along the image edges using ConvNets in a 2.5D
fashion (three orthogonal patches in axial, coronal and sagittal planes). We
explore three different methods for training the ConvNet using 2.5D patches
along the edge maps of 'positive', i.e. fractured posterior-elements and
'negative', i.e. non-fractured elements.
  An experienced radiologist retrospectively marked the location of 55
displaced posterior-element fractures in 18 trauma patients. We randomly split
the data into training and testing cases. In testing, we achieve an
area-under-the-curve of 0.857. This corresponds to 71% or 81% sensitivities at
5 or 10 false-positives per patient, respectively. Analysis of our set of
trauma patients demonstrates the feasibility of detecting posterior-element
fractures in spine CT images using computer vision techniques such as deep
convolutional networks.
</dc:description>
 <dc:description>Comment: To be presented at SPIE Medical Imaging, 2016, San Diego</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00020</dc:identifier>
 <dc:identifier>doi:10.1117/12.2217146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00023</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Prefix Free Codes With Partial Sorting</dc:title>
 <dc:creator>Barbay, J&#xe9;r&#xe9;my</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We describe an algorithm computing an optimal prefix free code for $n$
unsorted positive weights in time within $O(n(1+\lg \alpha))\subseteq O(n\lg
n)$, where the alternation $\alpha\in[1..n-1]$ measures the amount of sorting
required by the computation. This asymptotical complexity is within a constant
factor of the optimal in the algebraic decision tree computational model, in
the worst case over all instances of size $n$ and alternation $\alpha$. Such
results refine the state of the art complexity of $\Theta(n\lg n)$ in the worst
case over instances of size $n$ in the same computational model, a landmark in
compression and coding since 1952, by the mere combination of van Leeuwen's
algorithm to compute optimal prefix free codes from sorted weights (known since
1976), with Deferred Data Structures to partially sort a multiset depending on
the queries on it (known since 1988).
</dc:description>
 <dc:description>Comment: 13 pages, no figures. arXiv admin note: text overlap with
  arXiv:1204.5801</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00032</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What Can I Do Around Here? Deep Functional Scene Understanding for
  Cognitive Robots</dc:title>
 <dc:creator>Ye, Chengxi</dc:creator>
 <dc:creator>Yang, Yezhou</dc:creator>
 <dc:creator>Fermuller, Cornelia</dc:creator>
 <dc:creator>Aloimonos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  For robots that have the capability to interact with the physical environment
through their end effectors, understanding the surrounding scenes is not merely
a task of image classification or object recognition. To perform actual tasks,
it is critical for the robot to have a functional understanding of the visual
scene. Here, we address the problem of localizing and recognition of functional
areas from an arbitrary indoor scene, formulated as a two-stage deep learning
based detection pipeline. A new scene functionality testing-bed, which is
complied from two publicly available indoor scene datasets, is used for
evaluation. Our method is evaluated quantitatively on the new dataset,
demonstrating the ability to perform efficient recognition of functional areas
from arbitrary indoor scenes. We also demonstrate that our detection model can
be generalized onto novel indoor scenes by cross validating it with the images
from two different datasets.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00033</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast In-Memory SQL Analytics on Graphs</dc:title>
 <dc:creator>Lin, Chunbin</dc:creator>
 <dc:creator>Mandel, Benjamin</dc:creator>
 <dc:creator>Papakonstantinou, Yannis</dc:creator>
 <dc:creator>Springer, Matthias</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We study a class of graph analytics SQL queries, which we call relationship
queries. Relationship queries are a wide superset of fixed-length graph
reachability queries and of tree pattern queries. Intuitively, it discovers
target entities that are reachable from source entities specified by the query.
It usually also finds aggregated scores, which correspond to the target
entities and are calculated by applying aggregation functions on measure
attributes, which are found on the target entities, the source entities and the
paths from the sources to the targets. We present real-world OLAP scenarios,
where efficient relationship queries are needed. However, row stores, column
stores and graph databases are unacceptably slow in such OLAP scenarios. We
briefly comment on the straightforward extension of relationship queries that
allows accessing arbitrary schemas.
  The GQ-Fast in-memory analytics engine utilizes a bottom-up fully pipelined
query execution model running on a novel data organization that combines
salient features of column-based organization, indexing and compression.
Furthermore, GQ-Fast compiles its query plans into executable C++ source codes.
Besides achieving runtime efficiency, GQ-Fast also reduces main memory
requirements because, unlike column databases, GQ-Fast selectively allows more
dense forms of compression including heavy-weighted compressions, which do not
support random access.
  We used GQ-Fast to accelerate queries for two OLAP dashboards in the
biomedical field. It outperforms Postgres by 2-4 orders of magnitude and
outperforms MonetDB and Neo4j by 1-3 orders of magnitude when all of them are
running on RAM. In addition, it generally saves space due to the appropriate
use of compression methods.
</dc:description>
 <dc:description>Comment: 22 pages</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00036</identifier>
 <datestamp>2017-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Automorphism Groups of the Z2Z4-Linear 1-Perfect and
  Preparata-Like Codes</dc:title>
 <dc:creator>Krotov, Denis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>94B25</dc:subject>
 <dc:description>  We consider the symmetry group of a $Z_2Z_4$-linear code with parameters of a
$1$-perfect, extended $1$-perfect, or Preparata-like code. We show that,
provided the code length is greater than $16$, this group consists only of
symmetries that preserve the $Z_2Z_4$ structure. We find the orders of the
symmetry groups of the $Z_2Z_4$-linear (extended) $1$-perfect codes. Keywords:
additive codes, $Z_2Z_4$-linear codes, $1$-perfect codes, Preparata-like codes,
automorphism group, symmetry group.
</dc:description>
 <dc:description>Comment: 10pp, subm. to Des. Codes Crypt</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00036</dc:identifier>
 <dc:identifier>Des. Codes Cryptogr. 83(1) 2017, 169-177</dc:identifier>
 <dc:identifier>doi:10.1007/s10623-016-0218-3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00043</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Symmetries and the Capacity Achieving Input Covariance Matrices
  of Multiantenna Channels</dc:title>
 <dc:creator>Diaz, Mario</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper we study the capacity achieving input covariance matrices of a
single user multiantenna channel based solely on the group of symmetries of its
matrix of propagation coefficients. Our main result, which unifies and improves
the techniques used in a variety of classical capacity theorems, uses the Haar
(uniform) measure on the group of symmetries to establish the existence of a
capacity achieving input covariance matrix in a very particular subset of the
covariance matrices. This result allows us to provide simple proofs for old and
new capacity theorems. Among other results, we show that for channels with two
or more standard symmetries, the isotropic input is optimal. Overall, this
paper provides a precise explanation of why the capacity achieving input
covariance matrices of a channel depend more on the symmetries of the matrix of
propagation coefficients than any other distributional assumption.
</dc:description>
 <dc:description>Comment: 16 pages, presented at the 2016 IEEE International Symposium on
  Information Theory</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-07-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00043</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00057</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Separation of Signals Consisting of Amplitude and Instantaneous
  Frequency RRC Pulses Using SNR Uniform Training</dc:title>
 <dc:creator>Bari, Mohammad</dc:creator>
 <dc:creator>Doroslovacki, Milos</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work presents sample mean and sample variance based features that
distinguish continuous phase FSK from QAM and PSK modulations. Root raised
cosine pulses are used for signal generation. Support vector machines are
employed for signals separation. They are trained for only one value of SNR and
used to classify the signals from a wide range of SNR. A priori information
about carrier amplitude, carrier phase, carrier offset, roll-off factor and
initial symbol phase is relaxed. Effectiveness of the method is tested by
observing the joint effects of AWGN, carrier offset, lack of symbol and
sampling synchronization, and fast fading.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00061</identifier>
 <datestamp>2017-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Estimation from Samples</dc:title>
 <dc:creator>Kong, Weihao</dc:creator>
 <dc:creator>Valiant, Gregory</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>62H12, 62H10</dc:subject>
 <dc:description>  We consider the problem of approximating the set of eigenvalues of the
covariance matrix of a multivariate distribution (equivalently, the problem of
approximating the &quot;population spectrum&quot;), given access to samples drawn from
the distribution. The eigenvalues of the covariance of a distribution contain
basic information about the distribution, including the presence or lack of
structure in the distribution, the effective dimensionality of the
distribution, and the applicability of higher-level machine learning and
multivariate statistical tools. We consider this fundamental recovery problem
in the regime where the number of samples is comparable, or even sublinear in
the dimensionality of the distribution in question. First, we propose a
theoretically optimal and computationally efficient algorithm for recovering
the moments of the eigenvalues of the population covariance matrix. We then
leverage this accurate moment recovery, via a Wasserstein distance argument, to
show that the vector of eigenvalues can be accurately recovered. We provide
finite--sample bounds on the expected error of the recovered eigenvalues, which
imply that our estimator is asymptotically consistent as the dimensionality of
the distribution and sample size tend towards infinity, even in the sublinear
sample regime where the ratio of the sample size to the dimensionality tends to
zero. In addition to our theoretical results, we show that our approach
performs well in practice for a broad range of distributions and sample sizes.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2017-07-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00066</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Skolem Sequence Based Self-adaptive Broadcast Protocol in Cognitive
  Radio Networks</dc:title>
 <dc:creator>Chen, Lin</dc:creator>
 <dc:creator>Xiao, Zhiping</dc:creator>
 <dc:creator>Bian, Kaigui</dc:creator>
 <dc:creator>Shi, Shuyu</dc:creator>
 <dc:creator>Li, Rui</dc:creator>
 <dc:creator>Ji, Yusheng</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The base station (BS) in a multi-channel cognitive radio (CR) network has to
broadcast to secondary (or unlicensed) receivers/users on more than one
broadcast channels via channel hopping (CH), because a single broadcast channel
can be reclaimed by the primary (or licensed) user, leading to broadcast
failures. Meanwhile, a secondary receiver needs to synchronize its clock with
the BS's clock to avoid broadcast failures caused by the possible clock drift
between the CH sequences of the secondary receiver and the BS. In this paper,
we propose a CH-based broadcast protocol called SASS, which enables a BS to
successfully broadcast to secondary receivers over multiple broadcast channels
via channel hopping. Specifically, the CH sequences are constructed on basis of
a mathematical construct---the Self-Adaptive Skolem sequence. Moreover, each
secondary receiver under SASS is able to adaptively synchronize its clock with
that of the BS without any information exchanges, regardless of any amount of
clock drift.
</dc:description>
 <dc:description>Comment: A full version with technical proofs. Accepted by IEEE VTC 2016
  Spring</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00066</dc:identifier>
 <dc:identifier>doi:10.1109/VTCSpring.2016.7504475</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00067</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework to Prevent QR Code Based Phishing Attacks</dc:title>
 <dc:creator>Dayaratne, T. T.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Though the rapid development and spread of Information and Communication
Technology (ICT) making people's life much more easier, on the other hand it
causing some serious threats to the society. Phishing is one of the most common
cyber threat, that most users falls in. This research investigate on QR code
based phishing attacks which is a newly adopted intrusive method and how to
enhance the awareness and avoidance behavior of QR based phishing attacks
through the user centric security education approaches using game based
learning.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00067</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00069</identifier>
 <datestamp>2017-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Consensus conditions of continuous-time multi-agent systems with
  time-delays and measurement noises</dc:title>
 <dc:creator>Zong, Xiaofeng</dc:creator>
 <dc:creator>Li, Tao</dc:creator>
 <dc:creator>Zhang, Ji-Feng</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>93E03, 93E15, 60H10, 94C15</dc:subject>
 <dc:description>  This work is concerned with stochastic consensus conditions of multi-agent
systems with both time-delays and measurement noises. For the case of additive
noises, we develop some necessary conditions and sufficient conditions for
stochastic weak consensus by estimating the differential resolvent function for
delay equations. By the martingale convergence theorem, we obtain necessary
conditions and sufficient conditions for stochastic strong consensus. For the
case of multiplicative noises, we consider two kinds of time-delays, appeared
in the measurement term and the noise term, respectively. We first show that
stochastic weak consensus with the exponential convergence rate implies
stochastic strong consensus. Then by constructing degenerate Lyapunov
functional, we find the sufficient consensus conditions and show that
stochastic consensus can be achieved by carefully choosing the control gain
according to the noise intensities and the time-delay in the measurement term.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2017-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00069</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00070</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying a set of influential spreaders in complex networks</dc:title>
 <dc:creator>Zhang, Jian-Xiong</dc:creator>
 <dc:creator>Chen, Duan-Bing</dc:creator>
 <dc:creator>Dong, Qiang</dc:creator>
 <dc:creator>Zhao, Zhi-Dan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Identifying a set of influential spreaders in complex networks plays a
crucial role in effective information spreading. A simple strategy is to choose
top-$r$ ranked nodes as spreaders according to influence ranking method such as
PageRank, ClusterRank and $k$-shell decomposition. Besides, some heuristic
methods such as hill-climbing, SPIN, degree discount and independent set based
are also proposed. However, these approaches suffer from a possibility that
some spreaders are so close together that they overlap sphere of influence or
time consuming. In this report, we present a simply yet effectively iterative
method named VoteRank to identify a set of decentralized spreaders with the
best spreading ability. In this approach, all nodes vote in a spreader in each
turn, and the voting ability of neighbors of elected spreader will be decreased
in subsequent turn. Experimental results on four real networks show that under
Susceptible-Infected-Recovered (SIR) model, VoteRank outperforms the
traditional benchmark methods on both spreading speed and final affected scale.
What's more, VoteRank is also superior to other group-spreader identifying
methods on computational time.
</dc:description>
 <dc:description>Comment: 13 pages, 6 Figures, 37 references</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00078</identifier>
 <datestamp>2017-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent common manifold learning with alternating diffusion: analysis and
  applications</dc:title>
 <dc:creator>Talmon, Ronen</dc:creator>
 <dc:creator>Wu, Hau-tieng</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The analysis of data sets arising from multiple sensors has drawn significant
research attention over the years. Traditional methods, including kernel-based
methods, are typically incapable of capturing nonlinear geometric structures.
We introduce a latent common manifold model underlying multiple sensor
observations for the purpose of multimodal data fusion. A method based on
alternating diffusion is presented and analyzed; we provide theoretical
analysis of the method under the latent common manifold model. To exemplify the
power of the proposed framework, experimental results in several applications
are reported.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2017-08-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00079</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unit Commitment with N-1 Security and Wind Uncertainty</dc:title>
 <dc:creator>Sundar, Kaarthik</dc:creator>
 <dc:creator>Nagarajan, Harsha</dc:creator>
 <dc:creator>Lubin, Miles</dc:creator>
 <dc:creator>Roald, Line</dc:creator>
 <dc:creator>Misra, Sidhant</dc:creator>
 <dc:creator>Bent, Russell</dc:creator>
 <dc:creator>Bienstock, Daniel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  As renewable wind energy penetration rates continue to increase, one of the
major challenges facing grid operators is the question of how to control
transmission grids in a reliable and a cost-efficient manner. The stochastic
nature of wind forces an alteration of traditional methods for solving
day-ahead and look-ahead unit commitment and dispatch. In particular,
uncontrollable wind generation increases the risk of random component failures.
To address these questions, we present an N-1 Security and Chance-Constrained
Unit Commitment (SCCUC) that includes the modeling of generation reserves that
respond to wind fluctuations and tertiary reserves to account for single
component outages. The basic formulation is reformulated as a mixed-integer
second-order cone problem to limit the probability of failure. We develop three
different algorithms to solve the problem to optimality and present a detailed
case study on the IEEE RTS-96 single area system. The case study assesses the
economic impacts due to contingencies and various degrees of wind power
penetration into the system and also corroborates the effectiveness of the
algorithms.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00079</dc:identifier>
 <dc:identifier>doi:10.1109/PSCC.2016.7540910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00093</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network nestedness as generalized core-periphery structures</dc:title>
 <dc:creator>Lee, Sang Hoon</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The concept of nestedness, in particular for ecological and economical
networks, has been introduced as a structural characteristic of real
interacting systems. We suggest that the nestedness is in fact another way to
express a mesoscale network property called the core-periphery structure. With
real ecological mutualistic networks and synthetic model networks, we reveal
the strong correlation between the nestedness and core-periphery-ness (likeness
to the core-periphery structure), by defining the network-level measures for
nestedness and core-periphery-ness in the case of weighted and bipartite
networks. However, at the same time, via more sophisticated null-model
analysis, we also discover that the degree (the number of connected neighbors
of a node) distribution poses quite severe restrictions on the possible
nestedness and core-periphery parameter space. Therefore, there must exist
structurally interwoven properties in more fundamental levels of network
formation, behind this seemingly obvious relation between nestedness and
core-periphery structures.
</dc:description>
 <dc:description>Comment: 7 pages, 8 figures</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00093</dc:identifier>
 <dc:identifier>Phys. Rev. E 93, 022306 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevE.93.022306</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00095</identifier>
 <datestamp>2018-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Walsh Sampling with Incomplete Noisy Signals</dc:title>
 <dc:creator>Lu, Yi Janet</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  With the advent of massive data outputs at a regular rate, admittedly, signal
processing technology plays an increasingly key role. Nowadays, signals are not
merely restricted to physical sources, they have been extended to digital
sources as well.
  Under the general assumption of discrete statistical signal sources, we
propose a practical problem of sampling incomplete noisy signals for which we
do not know a priori and the sampling size is bounded. We approach this
sampling problem by Shannon's channel coding theorem. Our main results
demonstrate that it is the large Walsh coefficient(s) that characterize(s)
discrete statistical signals, regardless of the signal sources. By the
connection of Shannon's theorem, we establish the necessary and sufficient
condition for our generic sampling problem for the first time. Our generic
sampling results find practical and powerful applications in not only
statistical cryptanalysis, but software system performance optimization.
</dc:description>
 <dc:description>Comment: to appear in proceedings of Future of Information and Communications
  Conference (FICC) 2018, IEEE</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2018-01-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00097</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Virtual Machine Management via Approximate Markov Decision
  Process</dc:title>
 <dc:creator>Han, Zhenhua</dc:creator>
 <dc:creator>Tan, Haisheng</dc:creator>
 <dc:creator>Chen, Guihai</dc:creator>
 <dc:creator>Wang, Rui</dc:creator>
 <dc:creator>Chen, Yifan</dc:creator>
 <dc:creator>Lau, Francis C. M.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Efficient virtual machine (VM) management can dramatically reduce energy
consumption in data centers. Existing VM management algorithms fall into two
categories based on whether the VMs' resource demands are assumed to be static
or dynamic. The former category fails to maximize the resource utilization as
they cannot adapt to the dynamic nature of VMs' resource demands. Most
approaches in the latter category are heuristical and lack theoretical
performance guarantees. In this work, we formulate dynamic VM management as a
large-scale Markov Decision Process (MDP) problem and derive an optimal
solution. Our analysis of real-world data traces supports our choice of the
modeling approach. However, solving the large-scale MDP problem suffers from
the curse of dimensionality. Therefore, we further exploit the special
structure of the problem and propose an approximate MDP-based dynamic VM
management method, called MadVM. We prove the convergence of MadVM and analyze
the bound of its approximation error. Moreover, MadVM can be implemented in a
distributed system, which should suit the needs of real data centers. Extensive
simulations based on two real-world workload traces show that MadVM achieves
significant performance gains over two existing baseline approaches in power
consumption, resource shortage and the number of VM migrations. Specifically,
the more intensely the resource demands fluctuate, the more MadVM outperforms.
</dc:description>
 <dc:description>Comment: Full version for the paper appeared in INFOCOM'16 with the same title</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00101</identifier>
 <datestamp>2016-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible Logic Circuit Complexity Analysis via Functional
  Decomposition</dc:title>
 <dc:creator>Chattopadhyay, Anupam</dc:creator>
 <dc:creator>Baksi, Anubhab</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  Reversible computation is gaining increasing relevance in the context of
several post-CMOS technologies, the most prominent of those being Quantum
computing. One of the key theoretical problem pertaining to reversible logic
synthesis is the upper bound of the gate count. Compared to the known bounds,
the results obtained by optimal synthesis methods are significantly less. In
this paper, we connect this problem with the multiplicative complexity analysis
of classical Boolean functions. We explore the possibility of relaxing the
ancilla and if that approach makes the upper bound tighter. Our results are
negative. The ancilla-free synthesis methods by using transformations and by
starting from an Exclusive Sum-of-Product (ESOP) formulation remain,
theoretically, the synthesis methods for achieving least gate count for the
cases where the number of variables $n$ is $&lt; 8$ and otherwise, respectively.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-03-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00104</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Extracting Keyword for Disambiguating Name Based on the Overlap
  Principle</dc:title>
 <dc:creator>Nasution, Mahyuddin K. M.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Name disambiguation has become one of the main themes in the Semantic Web
agenda. The semantic web is an extension of the current Web in which
information is not only given well-defined meaning, but also has many purposes
that contain the ambiguous naturally or a lot of thing came with the overlap,
mainly deals with the persons name. Therefore, we develop an approach to
extract keywords from web snippet with utilizing the overlap principle, a
concept to understand things with ambiguous, whereby features of person are
generated for dealing with the variety of web, the web is steadily gaining
ground in the semantic research.
</dc:description>
 <dc:description>Comment: 7 pages, Proceeding of International Conference on Information
  Technology and Engineering Application (4-th ICIBA), Book 1, 119-125,
  February 20-21, 2015. arXiv admin note: text overlap with arXiv:1212.3023</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00110</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DNA-inspired online behavioral modeling and its application to spambot
  detection</dc:title>
 <dc:creator>Cresci, Stefano</dc:creator>
 <dc:creator>Di Pietro, Roberto</dc:creator>
 <dc:creator>Petrocchi, Marinella</dc:creator>
 <dc:creator>Spognardi, Angelo</dc:creator>
 <dc:creator>Tesconi, Maurizio</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.2.8.d</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:description>  We propose a strikingly novel, simple, and effective approach to model online
user behavior: we extract and analyze digital DNA sequences from user online
actions and we use Twitter as a benchmark to test our proposal. We obtain an
incisive and compact DNA-inspired characterization of user actions. Then, we
apply standard DNA analysis techniques to discriminate between genuine and
spambot accounts on Twitter. An experimental campaign supports our proposal,
showing its effectiveness and viability. To the best of our knowledge, we are
the first ones to identify and adapt DNA-inspired techniques to online user
behavioral modeling. While Twitter spambot detection is a specific use case on
a specific social media, our proposed methodology is platform and technology
agnostic, hence paving the way for diverse behavioral characterization tasks.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00110</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00132</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Source and Physical-Layer Network Coding for Correlated Two-Way Relaying</dc:title>
 <dc:creator>Huo, Qiang</dc:creator>
 <dc:creator>Song, Lingyang</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Jiao, Bingli</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study a half-duplex two-way relay channel (TWRC) with
correlated sources exchanging bidirectional information. In the case, when both
sources have the knowledge of correlation statistics, a source compression with
physical-layer network coding (SCPNC) scheme is proposed to perform the
distributed compression at each source node. When only the relay has the
knowledge of correlation statistics, we propose a relay compression with
physical-layer network coding (RCPNC) scheme to compress the bidirectional
messages at the relay. The closed-form block error rate (BLER) expressions of
both schemes are derived and verified through simulations. It is shown that the
proposed schemes achieve considerable improvements in both error performance
and throughput compared with the conventional non-compression scheme in
correlated two-way relay networks (CTWRNs).
</dc:description>
 <dc:description>Comment: 15 pages, 6 figures. IET Communications, 2016</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00132</dc:identifier>
 <dc:identifier>doi:10.1049/iet-com.2015.0572</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00133</identifier>
 <datestamp>2016-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SCOPE: Scalable Composite Optimization for Learning on Spark</dc:title>
 <dc:creator>Zhao, Shen-Yi</dc:creator>
 <dc:creator>Xiang, Ru</dc:creator>
 <dc:creator>Shi, Ying-Hao</dc:creator>
 <dc:creator>Gao, Peng</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Many machine learning models, such as logistic regression~(LR) and support
vector machine~(SVM), can be formulated as composite optimization problems.
Recently, many distributed stochastic optimization~(DSO) methods have been
proposed to solve the large-scale composite optimization problems, which have
shown better performance than traditional batch methods. However, most of these
DSO methods are not scalable enough. In this paper, we propose a novel DSO
method, called \underline{s}calable \underline{c}omposite
\underline{op}timization for l\underline{e}arning~({SCOPE}), and implement it
on the fault-tolerant distributed platform \mbox{Spark}. SCOPE is both
computation-efficient and communication-efficient. Theoretical analysis shows
that SCOPE is convergent with linear convergence rate when the objective
function is convex. Furthermore, empirical results on real datasets show that
SCOPE can outperform other state-of-the-art distributed learning methods on
Spark, including both batch learning methods and DSO methods.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-12-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00133</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00134</identifier>
 <datestamp>2016-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convolutional Pose Machines</dc:title>
 <dc:creator>Wei, Shih-En</dc:creator>
 <dc:creator>Ramakrishna, Varun</dc:creator>
 <dc:creator>Kanade, Takeo</dc:creator>
 <dc:creator>Sheikh, Yaser</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Pose Machines provide a sequential prediction framework for learning rich
implicit spatial models. In this work we show a systematic design for how
convolutional networks can be incorporated into the pose machine framework for
learning image features and image-dependent spatial models for the task of pose
estimation. The contribution of this paper is to implicitly model long-range
dependencies between variables in structured prediction tasks such as
articulated pose estimation. We achieve this by designing a sequential
architecture composed of convolutional networks that directly operate on belief
maps from previous stages, producing increasingly refined estimates for part
locations, without the need for explicit graphical model-style inference. Our
approach addresses the characteristic difficulty of vanishing gradients during
training by providing a natural learning objective function that enforces
intermediate supervision, thereby replenishing back-propagated gradients and
conditioning the learning procedure. We demonstrate state-of-the-art
performance and outperform competing methods on standard benchmarks including
the MPII, LSP, and FLIC datasets.
</dc:description>
 <dc:description>Comment: camera ready</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00134</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00139</identifier>
 <datestamp>2017-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>One generator quasi-cyclic codes over F2 + uF2 + vF2 + uvF2</dc:title>
 <dc:creator>B, Srinivasulu</dc:creator>
 <dc:creator>Bhaintwal, Maheshanand</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the structure of 1-generator quasi-cyclic codes over
the ring R = F2 + uF2 + vF2 + uvF2, with u2 = v2 = 0 and uv = vu. We determine
the minimal spanning sets for these codes. As a generalization of these codes,
we also investigate the structure of 1-generator generalized quasi-cyclic codes
over R and determine a BCH type bound for them.
</dc:description>
 <dc:description>Comment: The main result needs some modifications</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2017-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00145</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Analysis and Optimization of Wireless-Powered Multiple
  Antenna Full-Duplex Relay Systems</dc:title>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Chalise, Batu K.</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:creator>Zhong, Caijun</dc:creator>
 <dc:creator>Zheng, Gan</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a full-duplex (FD) decode-and-forward system in which the
time-switching protocol is employed by the multi-antenna relay to receive
energy from the source and transmit information to the destination. The
instantaneous throughput is maximized by optimizing receive and transmit
beamformers at the relay and the time-split parameter. We study both optimum
and suboptimum schemes. The reformulated problem in the optimum scheme achieves
closed-form solutions in terms of transmit beamformer for some scenarios. In
other scenarios, the optimization problem is formulated as a semi-definite
relaxation problem and a rank-one optimum solution is always guaranteed. In the
suboptimum schemes, the beamformers are obtained using maximum ratio combining,
zero-forcing, and maximum ratio transmission. When beamformers have closed-form
solutions, the achievable instantaneous and delay-constrained throughput are
analytically characterized. Our results reveal that, beamforming increases both
the energy harvesting and loop interference suppression capabilities at the FD
relay. Moreover, simulation results demonstrate that the choice of the linear
processing scheme as well as the time-split plays a critical role in
determining the FD gains.
</dc:description>
 <dc:description>Comment: Accepted for publication in IEEE Transactions on Communications</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00145</dc:identifier>
 <dc:identifier>doi:10.1109/TCOMM.2016.2527785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00148</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Synthesis from Assume-Guarantee Contracts involving Infinite
  Theories: A Preliminary Report</dc:title>
 <dc:creator>Katis, Andreas</dc:creator>
 <dc:creator>Whalen, Michael W.</dc:creator>
 <dc:creator>Gacek, Andrew</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  In previous work, we have introduced a contract-based real- izability
checking algorithm for assume-guarantee contracts involving infinite theories,
such as linear integer/real arith- metic and uninterpreted functions over
infinite domains. This algorithm can determine whether or not it is possible to
con- struct a realization (i.e. an implementation) of an assume- guarantee
contract. The algorithm is similar to k-induction model checking, but involves
the use of quantifiers to deter- mine implementability. While our work on
realizability is inherently useful for vir- tual integration in determining
whether it is possible for sup- pliers to build software that meets a contract,
it also provides the foundations to solving the more challenging problem of
component synthesis. In this paper, we provide an initial synthesis algorithm
for assume-guarantee contracts involv- ing infinite theories. To do so, we take
advantage of our realizability checking procedure and a skolemization solver
for forall-exists formulas, called AE-VAL. We show that it is possible to
immediately adapt our existing algorithm towards syn- thesis by using this
solver, using a demonstration example. We then discuss challenges towards
creating a more robust synthesis algorithm.
</dc:description>
 <dc:description>Comment: 6 pages, 1 figure</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00162</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A remark on incoherent feedforward circuits as change detectors and
  feedback controllers</dc:title>
 <dc:creator>Sontag, Eduardo D.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This note analyzes incoherent feedforward loops in signal processing and
control. It studies the response properties of IFFL's to exponentially growing
inputs, both for a standard version of the IFFL and for a variation in which
the output variable has a positive self-feedback term. It also considers a
negative feedback configuration, using such a device as a controller. It
uncovers a somewhat surprising phenomenon in which stabilization is only
possible in disconnected regions of parameter space, as the controlled system's
growth rate is varied.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00162</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00163</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multiple instance learning approach for sequence data with across bag
  dependencies</dc:title>
 <dc:creator>Zoghlami, Manel</dc:creator>
 <dc:creator>Aridhi, Sabeur</dc:creator>
 <dc:creator>Sghaier, Haitham</dc:creator>
 <dc:creator>Maddouri, Mondher</dc:creator>
 <dc:creator>Nguifo, Engelbert Mephu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In Multiple Instance Learning (MIL) problem for sequence data, the learning
data consist of a set of bags where each bag contains a set of
instances/sequences. In many real world applications such as bioinformatics,
web mining, and text mining, comparing a random couple of sequences makes no
sense. In fact, each instance of each bag may have structural and/or temporal
relation with other instances in other bags. Thus, the classification task
should take into account the relation between semantically related instances
across bags. In this paper, we present two novel MIL approaches for sequence
data classification: (1) ABClass and (2) ABSim. In ABClass, each sequence is
represented by one vector of attributes. For each sequence of the unknown bag,
a discriminative classifier is applied in order to compute a partial
classification result. Then, an aggregation method is applied to these partial
results in order to generate the final result. In ABSim, we use a similarity
measure between each sequence of the unknown bag and the corresponding
sequences in the learning bags. An unknown bag is labeled with the bag that
presents more similar sequences. We applied both approaches to the problem of
bacterial Ionizing Radiation Resistance (IRR) prediction. We evaluated and
discussed the proposed approaches on well known Ionizing Radiation Resistance
Bacteria (IRRB) and Ionizing Radiation Sensitive Bacteria (IRSB) represented by
primary structure of basal DNA repair proteins. The experimental results show
that both ABClass and ABSim approaches are efficient.
</dc:description>
 <dc:description>Comment: Submitted to Data Mining and Knowledge Discovery Journal</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00163</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00165</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Social Networks to Aid Homeless Shelters: Dynamic Influence
  Maximization under Uncertainty - An Extended Version</dc:title>
 <dc:creator>Yadav, Amulya</dc:creator>
 <dc:creator>Chan, Hau</dc:creator>
 <dc:creator>Jiang, Albert</dc:creator>
 <dc:creator>Xu, Haifeng</dc:creator>
 <dc:creator>Rice, Eric</dc:creator>
 <dc:creator>Tambe, Milind</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This paper presents HEALER, a software agent that recommends sequential
intervention plans for use by homeless shelters, who organize these
interventions to raise awareness about HIV among homeless youth. HEALER's
sequential plans (built using knowledge of social networks of homeless youth)
choose intervention participants strategically to maximize influence spread,
while reasoning about uncertainties in the network. While previous work
presents influence maximizing techniques to choose intervention participants,
they do not address three real-world issues: (i) they completely fail to scale
up to real-world sizes; (ii) they do not handle deviations in execution of
intervention plans; (iii) constructing real-world social networks is an
expensive process. HEALER handles these issues via four major contributions:
(i) HEALER casts this influence maximization problem as a POMDP and solves it
using a novel planner which scales up to previously unsolvable real-world
sizes; (ii) HEALER allows shelter officials to modify its recommendations, and
updates its future plans in a deviation-tolerant manner; (iii) HEALER
constructs social networks of homeless youth at low cost, using a Facebook
application. Finally, (iv) we show hardness results for the problem that HEALER
solves. HEALER will be deployed in the real world in early Spring 2016 and is
currently undergoing testing at a homeless shelter.
</dc:description>
 <dc:description>Comment: This is an extended version of our AAMAS 2016 paper (with the same
  name) with full proofs of all our theorems included</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00165</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00169</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Linearithmic Time Algorithm for a Shortest Vector Problem in
  Compute-and-Forward Design</dc:title>
 <dc:creator>Wen, Jinming</dc:creator>
 <dc:creator>Chang, Xiao-Wen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose an algorithm with expected complexity of $\bigO(n\log n)$
arithmetic operations to solve a special shortest vector problem arising in
computer-and-forward design, where $n$ is the dimension of the channel vector.
This algorithm is more efficient than the best known algorithms with proved
complexity.
</dc:description>
 <dc:description>Comment: It has been submitted to ISIT 2016</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00172</identifier>
 <datestamp>2017-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Learning For Smile Recognition</dc:title>
 <dc:creator>Glauner, Patrick O.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Inspired by recent successes of deep learning in computer vision, we propose
a novel application of deep convolutional neural networks to facial expression
recognition, in particular smile recognition. A smile recognition test accuracy
of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action
(DISFA) database, significantly outperforming existing approaches based on
hand-crafted features with accuracies ranging from 65.55% to 79.67%. The
novelty of this approach includes a comprehensive model selection of the
architecture parameters, allowing to find an appropriate architecture for each
expression such as smile. This is feasible because all experiments were run on
a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations
on a CPU.
</dc:description>
 <dc:description>Comment: Proceedings of the 12th Conference on Uncertainty Modelling in
  Knowledge Engineering and Decision Making (FLINS 2016)</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2017-07-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00173</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Caching: Technical Misconceptions and Business Barriers</dc:title>
 <dc:creator>Paschos, Georgios</dc:creator>
 <dc:creator>Ba&#x15f;tu&#x11f;, Ejder</dc:creator>
 <dc:creator>Land, Ingmar</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:creator>Debbah, M&#xe9;rouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Caching is a hot research topic and poised to develop into a key technology
for the upcoming 5G wireless networks. The successful implementation of caching
techniques however, crucially depends on joint research developments in
different scientific domains such as networking, information theory, machine
learning, and wireless communications. Moreover, there exist business barriers
related to the complex interactions between the involved stakeholders, the
users, the cellular operators, and the Internet content providers. In this
article we discuss several technical misconceptions with the aim to uncover
enabling research directions for caching in wireless systems. Ultimately we
make a speculative stakeholder analysis for wireless caching in 5G.
</dc:description>
 <dc:description>Comment: a version of this paper has been accepted to IEEE Communications
  Magazine, Special Issue on Communications, Caching, and Computing for
  Content-Centric Mobile Networks</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00173</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2016.7537172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00174</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Experimental Evaluation of Multihop Cellular Networks using Mobile
  Relays</dc:title>
 <dc:creator>Gozalvez, J.</dc:creator>
 <dc:creator>Coll-Perales, B.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Future wireless networks are expected to provide high bandwidth multimedia
services in extended areas with homogeneous Quality of Service (QoS) levels.
Conventional cellular architectures might not be able to satisfy these
requirements due to the effect of surrounding obstacles and the signal
attenuation with distance, in particular under Non Line of Sight (NLOS)
propagation conditions. Recent studies have investigated the potential of
Multi-hop Cellular Networks (MCNs) to overcome the traditional cellular
architecture limitations through the integration of cellular and ad-hoc
networking technologies. However, these studies are generally analytical or
simulation-based. On the other hand, this paper reports the first experimental
field tests that validate and quantify the benefits that MCNs using mobile
relays can provide over traditional cellular systems.
</dc:description>
 <dc:description>Comment: 15 pages, 7 figures</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00174</dc:identifier>
 <dc:identifier>IEEE Communications Magazine, vol. 51, no. 7, pp. 122-129, July
  2013</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2013.6553688</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00177</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tracing liquid level and material boundaries in transparent vessels
  using the graph cut computer vision approach</dc:title>
 <dc:creator>Eppel, Sagi</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Detection of boundaries of materials stored in transparent vessels is
essential for identifying properties such as liquid level and phase boundaries,
which are vital for controlling numerous processes in the industry and
chemistry laboratory. This work presents a computer vision method for
identifying the boundary of materials in transparent vessels using the
graph-cut algorithm. The method receives an image of a transparent vessel
containing a material and the contour of the vessel in the image. The boundary
of the material in the vessel is found by the graph cut method. In general the
method uses the vessel region of the image to create a graph, where pixels are
vertices, and the cost of an edge between two pixels is inversely correlated
with their intensity difference. The bottom 10% of the vessel region in the
image is assumed to correspond to the material phase and defined as the graph
and source. The top 10% of the pixels in the vessels are assumed to correspond
to the air phase and defined as the graph sink. The minimal cut that splits the
resulting graph between the source and sink (hence, material and air) is traced
using the max-flow/min-cut approach. This cut corresponds to the boundary of
the material in the image. The method gave high accuracy in boundary
recognition for a wide range of liquid, solid, granular and powder materials in
various glass vessels from everyday life and the chemistry laboratory, such as
bottles, jars, Glasses, Chromotography colums and separatory funnels.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00177</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00180</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Geometry and Extremal Properties of the Edge-Degeneracy Model</dc:title>
 <dc:creator>Kim, Nicolas</dc:creator>
 <dc:creator>Wilburne, Dane</dc:creator>
 <dc:creator>Petrovi&#x107;, Sonja</dc:creator>
 <dc:creator>Rinaldo, Alessandro</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The edge-degeneracy model is an exponential random graph model that uses the
graph degeneracy, a measure of the graph's connection density, and number of
edges in a graph as its sufficient statistics. We show this model is relatively
well-behaved by studying the statistical degeneracy of this model through the
geometry of the associated polytope.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures. This version differs ever so slightly from the
  published one; several typos have been fixed and clarifying comments by J.
  Rauh incorporated in the update</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00192</identifier>
 <datestamp>2016-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Factor Revealing LP Approach for Facility Location with Penalties</dc:title>
 <dc:creator>Qiu, Xian</dc:creator>
 <dc:creator>Kern, Walter</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider the uncapacitated facility location problem with (linear) penalty
function and show that a modified JMS algorithm, combined with a randomized LP
rounding technique due to Byrka-Aardal[1], Li[14] and Li et al.[16] yields
1.488 approximation, improving the factor 1.5148 due to Li et al.[16]. This
closes the current gap between the classical facility location problem and this
penalized variant. Main ingredient is a straightforward adaptation of the JMS
algorithm to the penalty setting plus a consistent use of the upper bounding
technique for factor revealing LPs due to Fernandes et al.[7]. In contrast to
the bounds in [12], our factor revealing LP is monotone.
</dc:description>
 <dc:description>Comment: This paper has been withdrawn by the author due to a crucial sign
  error in the opening cost constraint</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00192</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00193</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Diffusion-restricted Social Network: A Measurement Study of WeChat
  Moments</dc:title>
 <dc:creator>Li, Zhuqi</dc:creator>
 <dc:creator>Chen, Lin</dc:creator>
 <dc:creator>Bai, Yichong</dc:creator>
 <dc:creator>Bian, Kaigui</dc:creator>
 <dc:creator>Zhou, Pan</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  WeChat is a mobile messaging application that has 549 million active users as
of Q1 2015, and &quot;WeChat Moments&quot; (WM) serves its social-networking function
that allows users to post/share links of web pages. WM differs from the other
social networks as it imposes many restrictions on the information diffusion
process to mitigate the information overload. In this paper, we conduct a
measurement study on information diffusion in the WM network by crawling and
analyzing the spreading statistics of more than 160,000 pages that involve
approximately 40 million users. Specifically, we identify the relationship of
the number of posted pages and the number of views, the diffusion path length,
the similarity and distribution of users' locations as well as their
connections with the GDP of the users' province. For each individual WM page,
we measure its temporal characteristics (e.g., the life time, the popularity
within a time period); for each individual user, we evaluate how many of, or
how likely, one's friends will view his posted pages. Our results will help the
business to decide when and how to release the marketing pages over WM for
better publicity.
</dc:description>
 <dc:description>Comment: Accepted by IEEE International Conference on Communications (IEEE ICC
  2016)</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:date>2016-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00193</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7511394</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00198</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discussion on Mechanical Learning and Learning Machine</dc:title>
 <dc:creator>Xiong, Chuyu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Mechanical learning is a computing system that is based on a set of simple
and fixed rules, and can learn from incoming data. A learning machine is a
system that realizes mechanical learning. Importantly, we emphasis that it is
based on a set of simple and fixed rules, contrasting to often called machine
learning that is sophisticated software based on very complicated mathematical
theory, and often needs human intervene for software fine tune and manual
adjustments. Here, we discuss some basic facts and principles of such system,
and try to lay down a framework for further study. We propose 2 directions to
approach mechanical learning, just like Church-Turing pair: one is trying to
realize a learning machine, another is trying to well describe the mechanical
learning.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00203</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Greedy Deep Dictionary Learning</dc:title>
 <dc:creator>Tariyal, Snigdha</dc:creator>
 <dc:creator>Majumdar, Angshul</dc:creator>
 <dc:creator>Singh, Richa</dc:creator>
 <dc:creator>Vatsa, Mayank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this work we propose a new deep learning tool called deep dictionary
learning. Multi-level dictionaries are learnt in a greedy fashion, one layer at
a time. This requires solving a simple (shallow) dictionary learning problem,
the solution to this is well known. We apply the proposed technique on some
benchmark deep learning datasets. We compare our results with other deep
learning tools like stacked autoencoder and deep belief network; and state of
the art supervised dictionary learning tools like discriminative KSVD and label
consistent KSVD. Our method yields better results than all.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00206</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Deep Hashing for Large-scale Visual Search</dc:title>
 <dc:creator>Xia, Zhaoqiang</dc:creator>
 <dc:creator>Feng, Xiaoyi</dc:creator>
 <dc:creator>Peng, Jinye</dc:creator>
 <dc:creator>Hadid, Abdenour</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning based hashing plays a pivotal role in large-scale visual search.
However, most existing hashing algorithms tend to learn shallow models that do
not seek representative binary codes. In this paper, we propose a novel hashing
approach based on unsupervised deep learning to hierarchically transform
features into hash codes. Within the heterogeneous deep hashing framework, the
autoencoder layers with specific constraints are considered to model the
nonlinear mapping between features and binary codes. Then, a Restricted
Boltzmann Machine (RBM) layer with constraints is utilized to reduce the
dimension in the hamming space. Extensive experiments on the problem of visual
search demonstrate the competitiveness of our proposed approach compared to
state-of-the-art.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00212</identifier>
 <datestamp>2016-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trainlets: Dictionary Learning in High Dimensions</dc:title>
 <dc:creator>Sulam, Jeremias</dc:creator>
 <dc:creator>Ophir, Boaz</dc:creator>
 <dc:creator>Zibulevsky, Michael</dc:creator>
 <dc:creator>Elad, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse representations has shown to be a very powerful model for real world
signals, and has enabled the development of applications with notable
performance. Combined with the ability to learn a dictionary from signal
examples, sparsity-inspired algorithms are often achieving state-of-the-art
results in a wide variety of tasks. Yet, these methods have traditionally been
restricted to small dimensions mainly due to the computational constraints that
the dictionary learning problem entails. In the context of image processing,
this implies handling small image patches. In this work we show how to
efficiently handle bigger dimensions and go beyond the small patches in
sparsity-based signal and image processing methods. We build our approach based
on a new cropped wavelet decomposition, which enables a multi-scale analysis
with virtually no border effects. We then employ this as the base dictionary
within a double sparsity model to enable the training of adaptive dictionaries.
To cope with the increase of training data, while at the same time improving
the training performance, we present an Online Sparse Dictionary Learning
(OSDL) algorithm to train this model effectively, enabling it to handle
millions of examples. This work shows that dictionary learning can be up-scaled
to tackle a new level of signal dimensions, obtaining large adaptable atoms
that we call trainlets.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00212</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2540599</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00214</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dimensionality Reduction via Regression in Hyperspectral Imagery</dc:title>
 <dc:creator>Laparra, Valero</dc:creator>
 <dc:creator>Malo, Jesus</dc:creator>
 <dc:creator>Camps-Valls, Gustau</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper introduces a new unsupervised method for dimensionality reduction
via regression (DRR). The algorithm belongs to the family of invertible
transforms that generalize Principal Component Analysis (PCA) by using
curvilinear instead of linear features. DRR identifies the nonlinear features
through multivariate regression to ensure the reduction in redundancy between
he PCA coefficients, the reduction of the variance of the scores, and the
reduction in the reconstruction error. More importantly, unlike other nonlinear
dimensionality reduction methods, the invertibility, volume-preservation, and
straightforward out-of-sample extension, makes DRR interpretable and easy to
apply. The properties of DRR enable learning a more broader class of data
manifolds than the recently proposed Non-linear Principal Components Analysis
(NLPCA) and Principal Polynomial Analysis (PPA). We illustrate the performance
of the representation in reducing the dimensionality of remote sensing data. In
particular, we tackle two common problems: processing very high dimensional
spectral information such as in hyperspectral image sounding data, and dealing
with spatial-spectral image patches of multispectral images. Both settings pose
collinearity and ill-determination problems. Evaluation of the expressive power
of the features is assessed in terms of truncation error, estimating
atmospheric variables, and surface land cover classification error. Results
show that DRR outperforms linear PCA and recently proposed invertible
extensions based on neural networks (NLPCA) and univariate regressions (PPA).
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, 62 references</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00214</dc:identifier>
 <dc:identifier>J. Sel. Topics Signal Processing 9(6): 1026-1036 (2015)</dc:identifier>
 <dc:identifier>doi:10.1109/JSTSP.2015.2417833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00216</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Selection for Regression Problems Based on the Morisita
  Estimator of Intrinsic Dimension</dc:title>
 <dc:creator>Golay, Jean</dc:creator>
 <dc:creator>Leuenberger, Michael</dc:creator>
 <dc:creator>Kanevski, Mikhail</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Data acquisition, storage and management have been improved, while the key
factors of many phenomena are not well known. Consequently, irrelevant and
redundant features artificially increase the size of datasets, which
complicates learning tasks, such as regression. To address this problem,
feature selection methods have been proposed. This paper introduces a new
supervised filter based on the Morisita estimator of intrinsic dimension. It
can identify relevant features and distinguish between redundant and irrelevant
information. Besides, it offers a clear graphical representation of the
results, and it can be easily implemented in different programming languages.
Comprehensive numerical experiments are conducted using simulated datasets
characterized by different levels of complexity, sample size and noise. The
suggested algorithm is also successfully tested on a selection of real world
applications and compared with RReliefF using extreme learning machine. In
addition, a new measure of feature relevance is presented and discussed.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00217</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image Denoising with Kernels based on Natural Image Relations</dc:title>
 <dc:creator>Laparra, Valero</dc:creator>
 <dc:creator>Guti&#xe9;rrez, Juan</dc:creator>
 <dc:creator>Camps-Valls, Gustavo</dc:creator>
 <dc:creator>Malo, Jes&#xfa;s</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A successful class of image denoising methods is based on Bayesian approaches
working in wavelet representations. However, analytical estimates can be
obtained only for particular combinations of analytical models of signal and
noise, thus precluding its straightforward extension to deal with other
arbitrary noise sources. In this paper, we propose an alternative non-explicit
way to take into account the relations among natural image wavelet coefficients
for denoising: we use support vector regression (SVR) in the wavelet domain to
enforce these relations in the estimated signal. Since relations among the
coefficients are specific to the signal, the regularization property of SVR is
exploited to remove the noise, which does not share this feature. The specific
signal relations are encoded in an anisotropic kernel obtained from mutual
information measures computed on a representative image database. Training
considers minimizing the Kullback-Leibler divergence (KLD) between the
estimated and actual probability functions of signal and noise in order to
enforce similarity. Due to its non-parametric nature, the method can eventually
cope with different noise sources without the need of an explicit
re-formulation, as it is strictly necessary under parametric Bayesian
formalisms. Results under several noise levels and noise sources show that: (1)
the proposed method outperforms conventional wavelet methods that assume
coefficient independence, (2) it is similar to state-of-the-art methods that do
explicitly include these relations when the noise source is Gaussian, and (3)
it gives better numerical and visual performance when more complex, realistic
noise sources are considered. Therefore, the proposed machine learning approach
can be seen as a more flexible (model-free) alternative to the explicit
description of wavelet coefficient relations for image denoising.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00217</dc:identifier>
 <dc:identifier>Journal of Machine Learning Research 11: 873-903 (2010)</dc:identifier>
 <dc:identifier>doi:10.1145/1756006.1756035</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00223</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Proximal Stochastic Quasi-Newton Algorithm</dc:title>
 <dc:creator>Luo, Luo</dc:creator>
 <dc:creator>Chen, Zihao</dc:creator>
 <dc:creator>Zhang, Zhihua</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we discuss the problem of minimizing the sum of two convex
functions: a smooth function plus a non-smooth function. Further, the smooth
part can be expressed by the average of a large number of smooth component
functions, and the non-smooth part is equipped with a simple proximal mapping.
We propose a proximal stochastic second-order method, which is efficient and
scalable. It incorporates the Hessian in the smooth part of the function and
exploits multistage scheme to reduce the variance of the stochastic gradient.
We prove that our method can achieve linear rate of convergence.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00223</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00224</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Order-aware Convolutional Pooling for Video Based Action Recognition</dc:title>
 <dc:creator>Wang, Peng</dc:creator>
 <dc:creator>Liu, Lingqiao</dc:creator>
 <dc:creator>Shen, Chunhua</dc:creator>
 <dc:creator>Shen, Heng Tao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Most video based action recognition approaches create the video-level
representation by temporally pooling the features extracted at each frame. The
pooling methods that they adopt, however, usually completely or partially
neglect the dynamic information contained in the temporal domain, which may
undermine the discriminative power of the resulting video representation since
the video sequence order could unveil the evolution of a specific event or
action. To overcome this drawback and explore the importance of incorporating
the temporal order information, in this paper we propose a novel temporal
pooling approach to aggregate the frame-level features. Inspired by the
capacity of Convolutional Neural Networks (CNN) in making use of the internal
structure of images for information abstraction, we propose to apply the
temporal convolution operation to the frame-level representations to extract
the dynamic information. However, directly implementing this idea on the
original high-dimensional feature would inevitably result in parameter
explosion.
  To tackle this problem, we view the temporal evolution of the feature value
at each feature dimension as a 1D signal and learn a unique convolutional
filter bank for each of these 1D signals. We conduct experiments on two
challenging video-based action recognition datasets, HMDB51 and UCF101; and
demonstrate that the proposed method is superior to the conventional pooling
methods.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00225</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transmitter Optimization in Slow Fading MISO Wiretap Channel</dc:title>
 <dc:creator>Vishwakarma, Sanjay</dc:creator>
 <dc:creator>Chockalingam, A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the transmitter optimization problem in slow
fading multiple-input-single-output (MISO) wiretap channel. The source
transmits a secret message intended for $K$ users in the presence of $J$
non-colluding eavesdroppers, and operates under a total power constraint. The
channels between the source and all users and eavesdroppers are assumed to be
slow fading, and only statistical channel state information (CSI) is known at
the source. For a given code rate and secrecy rate pair of the wiretap code,
denoted by $(R_{D}, R_{s})$, we define the non-outage event as the joint event
of the link information rates to $K$ users be greater than or equal to $R_{D}$
and the link information rates to $J$ eavesdroppers be less than or equal to
$(R_{D} - R_{s})$. We minimize the transmit power subject to the total power
constraint and satisfying the probability of the non-outage event to be greater
than or equal to a desired threshold $(1-\epsilon)$.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00233</identifier>
 <datestamp>2016-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterisations of Matrix and Operator-Valued $\Phi$-Entropies, and
  Operator Efron-Stein Inequalities</dc:title>
 <dc:creator>Cheng, Hao-Chung</dc:creator>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We derive new characterisations of the matrix $\mathrm{\Phi}$-entropy
functionals introduced in [Electron.~J.~Probab., 19(20): 1--30, 2014]. Notably,
all known equivalent characterisations of the classical $\Phi$-entropies have
their matrix correspondences. Next, we propose an operator-valued
generalisation of the matrix $\Phi$-entropy functionals, and prove their
subadditivity under L\&quot;owner partial ordering. Our results demonstrate that the
subadditivity of operator-valued $\Phi$-entropies is equivalent to the
convexity of various related functions. This result can be used to demonstrate
an interesting result in quantum information theory: the matrix $\Phi$-entropy
of a quantum ensemble is monotone under unital quantum channels. Finally, we
derive the operator Efron-Stein inequality to bound the operator-valued
variance of a random matrix.
</dc:description>
 <dc:description>Comment: 21 pages. Text partially overlaps with arXiv:1506.06801. Accepted in
  Proceedings of the Royal Society A: Mathematical, Physical &amp; Engineering
  Sciences</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00233</dc:identifier>
 <dc:identifier>Proc. R. Soc. A, Vol. 472, No. 2187, 20150563 (2016)</dc:identifier>
 <dc:identifier>doi:10.1098/rspa.2015.0563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00234</identifier>
 <datestamp>2017-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computer-Assisted Processing of Intertextuality in Ancient Languages</dc:title>
 <dc:creator>Hedges, Mark</dc:creator>
 <dc:creator>Jordanous, Anna</dc:creator>
 <dc:creator>Lawrence, K. Faith</dc:creator>
 <dc:creator>Rouech&#xe9;, Charlotte</dc:creator>
 <dc:creator>Tupman, Charlotte</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The production of digital critical editions of texts using TEI is now a
widely-adopted procedure within digital humanities. The work described in this
paper extends this approach to the publication of gnomologia (anthologies of
wise sayings), which formed a widespread literary genre in many cultures of the
medieval Mediterranean. These texts are challenging because they were rarely
copied straightforwardly; rather, sayings were selected, reorganised, modified
or re-attributed between manuscripts, resulting in a highly interconnected
corpus for which a standard approach to digital publication is insufficient.
Focusing on Greek and Arabic collections, we address this challenge using
semantic web techniques to create an ecosystem of texts, relationships and
annotations, and consider a new model - organic, collaborative, interconnected,
and open-ended - of what constitutes an edition. This semantic web-based
approach allows scholars to add their own materials and annotations to the
network of information and to explore the conceptual networks that arise from
these interconnected sayings.
</dc:description>
 <dc:description>Comment: 23 pages, 4 figures, submission to overlay journal Journal of Data
  Mining and Digital Humanities (jdmdh.episciences.org)</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-01-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00234</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00238</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Assessing 3D scan quality in Virtual Reality through paired-comparisons
  psychophysics test</dc:title>
 <dc:creator>Thorn, Jacob</dc:creator>
 <dc:creator>Pizarro, Rodrigo</dc:creator>
 <dc:creator>Spanlang, Bernhard</dc:creator>
 <dc:creator>Bermell-Garcia, Pablo</dc:creator>
 <dc:creator>Gonzalez-Franco, Mar</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Consumer 3D scanners and depth cameras are increasingly being used to
generate content and avatars for Virtual Reality (VR) environments and avoid
the inconveniences of hand modeling; however, it is sometimes difficult to
evaluate quantitatively the mesh quality at which 3D scans should be exported,
and whether the object perception might be affected by its shading. We propose
using a paired-comparisons test based on psychophysics of perception to do that
evaluation. As psychophysics is not subject to opinion, skill level, mental
state, or economic situation it can be considered a quantitative way to measure
how people perceive the mesh quality. In particular, we propose using the
psychophysical measure for the comparison of four different levels of mesh
quality (1K, 5K, 10K and 20K triangles). We present two studies within
subjects: in one we investigate the quality perception variations of seeing an
object in a regular screen monitor against an stereoscopic Head Mounted Display
(HMD); while in the second experiment we aim at detecting the effects of
shading into quality perception. At each iteration of the pair-test comparisons
participants pick the mesh that they think had higher quality; by the end of
the experiment we compile a preference matrix. The matrix evidences the
correlation between real quality and assessed quality. Regarding the shading
mode, we find an interaction with quality and shading when the model has high
definition. Furthermore, we assess the subjective realism of the most/least
preferred scans using an Immersive Augmented Reality (IAR) video-see-through
setup. Results show higher levels of realism were perceived through the HMD
than when using a monitor, although the quality was similarly perceived in both
systems.
</dc:description>
 <dc:description>Comment: 9 pages, 10 figures, video: https://youtu.be/vC3Tx07szXU</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00238</dc:identifier>
 <dc:identifier>Proceedings of the 2016 ACM on Multimedia Conference (MM '16).
  ACM, New York, NY, USA, 147-151</dc:identifier>
 <dc:identifier>doi:10.1145/2964284.2967200</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00242</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Technical Report: Representing SES Cases Using Ontology</dc:title>
 <dc:creator>Chen, Miao</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Socio-ecological System (SES) research studies the interaction between
environment, users, and governance of environment resources. Data produced
during the research cycle can be both long-tail (e.g. heterogeneous) and
longitudinal data. For example, the IFRI (International Forestry Resources and
Institutions) data set contains studies carried out over a period of 20 years.
Given the complexity of a SES system, case studies that are accumulated over
time and from different sites (e.g. site visit cases) are highly valuable in
the understanding of new SES system behavior for instance. We, as a group of
informatics researchers collaborating with personnel from the Workshop in
Political Theory and Policy Analysis at Indiana University, are developing
informatics approaches to facilitating SES scholars' research.
  Here we focus on presenting our work on representing SES cases using
ontology. An ontology for the SES field can help organize concepts in the
field, describe resources such as data and publications using a shared
vocabulary, and also facilitate data use and query for researchers. We develop
a core SES ontology, which contains core concepts and resources in the field
and can be used to describe actual concept and resource instances, and also a
tool for contributing instances by drawing graphs, called Cmap2SES.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00243</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reliability of Checking an Answer Given by a Mathematical Expression in
  Interactive Learning Systems</dc:title>
 <dc:creator>Danilov, Vladimir G.</dc:creator>
 <dc:creator>Turuntaev, Ilya S.</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  In this article we address the problem of automatic answer checking in
interactive learning systems that support mathematical notation. This problem
consists of the problem of establishing identities in formal mathematical
systems and hence is formally unsolvable. However, there is a way to cope with
the issue. We suggest to reinforce the standard algorithm for function
comparison with an additional pointwise checking procedure. An error might
appear in this case. The article provides a detailed analysis of the
probability of this error. It appears that the error probability is extremely
low in most common cases. Generally speaking, this means that such an
additional checking procedure can be quite successfully used in order to
support standard algorithms for functions comparison. The results, obtained in
this article, help avoiding some sudden effects of the identity problem, and
provide a way to estimate the reliability of answer checking procedure in
interactive learning systems.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00243</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00244</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On p-adic differential equations with separation of variables</dc:title>
 <dc:creator>Lairez, Pierre</dc:creator>
 <dc:creator>Vaccon, Tristan</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Several algorithms in computer algebra involve the computation of a power
series solution of a given ordinary differential equation. Over finite fields,
the problem is often lifted in an approximate $p$-adic setting to be
well-posed. This raises precision concerns: how much precision do we need on
the input to compute the output accurately? In the case of ordinary
differential equations with separation of variables, we make use of the recent
technique of differential precision to obtain optimal bounds on the stability
of the Newton iteration. The results apply, for example, to algorithms for
manipulating algebraic numbers over finite fields, for computing isogenies
between elliptic curves or for deterministically finding roots of polynomials
in finite fields. The new bounds lead to significant speedups in practice.
</dc:description>
 <dc:description>Comment: ISSAC '16, July 19-22, 2016, Waterloo, ON, Canada</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00244</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00248</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling the transmission dynamics of online social contagion</dc:title>
 <dc:creator>Kucharski, Adam J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  During 2014-15, there were several outbreaks of nominated-based online social
contagion. These infections, which were transmitted from one individual to
another via posts on social media, included games such as 'neknomination', 'ice
bucket challenge', 'no make up selfies', and Facebook users re-posting their
first profile pictures. Fitting a mathematical model of infectious disease
transmission to outbreaks of these four games in the United Kingdom, I
estimated the basic reproduction number, $R_0$, and generation time of each
infection. Median estimates for $R_0$ ranged from 1.9-2.5 across the four
outbreaks, and the estimated generation times were between 1.0 and 2.0 days.
Tests using out-of-sample data from Australia suggested that the model had
reasonable predictive power, with $R^2$ values between 0.52-0.70 across the
four Australian datasets. Further, the relatively low basic reproduction
numbers for the infections suggests that only 48-60% of index cases in
nomination-based games may subsequently generate major outbreaks.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00251</identifier>
 <datestamp>2017-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do we have privacy in the digital world?</dc:title>
 <dc:creator>Bakhtiyari, Kaveh</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Not really.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-01-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00251</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.2492.5203/2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00252</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comment Diffusons-nous sur les R\'eseaux Sociaux ?</dc:title>
 <dc:creator>Stattner, Erick</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The emergence of new communication media such as blogs, online newspapers and
social networks allow us to go further in the understanding of human behavior.
Indeed, these public exchange spaces are now firmly planted in our modern
society and appear to be powerful sensors of social behavior and opinion
movements. In this paper, we focus on information spreading and attempt to
understand what are the conditions in which a person decides to speak on a
subject. For this purpose, we propose a set of measures that aim to
characterize the diffusion behavior. Our measures have been used on messages
related to two events that took place in January 2015: presentation by
Microsoft of a new virtual reality headset and the election of a political
party of radical left in Greece.
</dc:description>
 <dc:description>Comment: 12 pages, in French. Colloque international et interdisciplinaire
  pour les enjeux et usages des technologies de l'information et de la
  communication, 2015 (EUTIC 2015)</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00252</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00269</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Atrribute Extraction from Clinical Texts</dc:title>
 <dc:creator>R, Sarath P</dc:creator>
 <dc:creator>Mandhan, Sunil</dc:creator>
 <dc:creator>Niwa, Yoshiki</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>68T50</dc:subject>
 <dc:description>  This paper describes about information extraction system, which is an
extension of the system developed by team Hitachi for &quot;Disease/Disorder
Template filling&quot; task organized by ShARe/CLEF eHealth Evolution Lab 2014. In
this extension module we focus on extraction of numerical attributes and values
from discharge summary records and associating correct relation between
attributes and values. We solve the problem in two steps. First step is
extraction of numerical attributes and values, which is developed as a Named
Entity Recognition (NER) model using Stanford NLP libraries. Second step is
correctly associating the attributes to values, which is developed as a
relation extraction module in Apache cTAKES framework. We integrated Stanford
NER model as cTAKES pipeline component and used in relation extraction module.
Conditional Random Field (CRF) algorithm is used for NER and Support Vector
Machines (SVM) for relation extraction. For attribute value relation
extraction, we observe 95% accuracy using NER alone and combined accuracy of
87% with NER and SVM.
</dc:description>
 <dc:description>Comment: 6 Pages</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00269</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.4763.3365</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00276</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Capacity of Online (Causal) $q$-ary Error-Erasure Channels</dc:title>
 <dc:creator>Chen, Zitan</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:creator>Langberg, Michael</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In the $q$-ary online (or &quot;causal&quot;) channel coding model, a sender wishes to
communicate a message to a receiver by transmitting a codeword $\mathbf{x}
=(x_1,\ldots,x_n) \in \{0,1,\ldots,q-1\}^n$ symbol by symbol via a channel
limited to at most $pn$ errors and/or $p^{*} n$ erasures. The channel is
&quot;online&quot; in the sense that at the $i$th step of communication the channel
decides whether to corrupt the $i$th symbol or not based on its view so far,
i.e., its decision depends only on the transmitted symbols $(x_1,\ldots,x_i)$.
This is in contrast to the classical adversarial channel in which the
corruption is chosen by a channel that has a full knowledge on the sent
codeword $\mathbf{x}$.
  In this work we study the capacity of $q$-ary online channels for a combined
corruption model, in which the channel may impose at most $pn$ {\em errors} and
at most $p^{*} n$ {\em erasures} on the transmitted codeword. The online
channel (in both the error and erasure case) has seen a number of recent
studies which present both upper and lower bounds on its capacity. In this
work, we give a full characterization of the capacity as a function of $q,p$,
and $p^{*}$.
</dc:description>
 <dc:description>Comment: This is a new version of the binary case, which can be found at
  arXiv:1412.6376</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00276</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00287</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Additive Approximations in High Dimensional Nonparametric Regression via
  the SALSA</dc:title>
 <dc:creator>Kandasamy, Kirthevasan</dc:creator>
 <dc:creator>Yu, Yaoliang</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  High dimensional nonparametric regression is an inherently difficult problem
with known lower bounds depending exponentially in dimension. A popular
strategy to alleviate this curse of dimensionality has been to use additive
models of \emph{first order}, which model the regression function as a sum of
independent functions on each dimension. Though useful in controlling the
variance of the estimate, such models are often too restrictive in practical
settings. Between non-additive models which often have large variance and first
order additive models which have large bias, there has been little work to
exploit the trade-off in the middle via additive models of intermediate order.
In this work, we propose SALSA, which bridges this gap by allowing interactions
between variables, but controls model capacity by limiting the order of
interactions. SALSA minimises the residual sum of squares with squared RKHS
norm penalties. Algorithmically, it can be viewed as Kernel Ridge Regression
with an additive kernel. When the regression function is additive, the excess
risk is only polynomial in dimension. Using the Girard-Newton formulae, we
efficiently sum over a combinatorial number of terms in the additive expansion.
Via a comparison on $15$ real datasets, we show that our method is competitive
against $21$ other alternatives.
</dc:description>
 <dc:description>Comment: International Conference on Machine Learning (ICML) 2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00287</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00293</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>WASSUP? LOL : Characterizing Out-of-Vocabulary Words in Twitter</dc:title>
 <dc:creator>Maity, Suman Kalyan</dc:creator>
 <dc:creator>Sarda, Chaitanya</dc:creator>
 <dc:creator>Chaudhary, Anshit</dc:creator>
 <dc:creator>Patil, Abhijeet</dc:creator>
 <dc:creator>Kumar, Shraman</dc:creator>
 <dc:creator>Mondal, Akash</dc:creator>
 <dc:creator>Mukherjee, Animesh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Language in social media is mostly driven by new words and spellings that are
constantly entering the lexicon thereby polluting it and resulting in high
deviation from the formal written version. The primary entities of such
language are the out-of-vocabulary (OOV) words. In this paper, we study various
sociolinguistic properties of the OOV words and propose a classification model
to categorize them into at least six categories. We achieve 81.26% accuracy
with high precision and recall. We observe that the content features are the
most discriminative ones followed by lexical and context features.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure, CSCW '16</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00296</identifier>
 <datestamp>2017-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Factorization Algorithm for G-Algebras and Applications</dc:title>
 <dc:creator>Heinle, Albert</dc:creator>
 <dc:creator>Levandovskyy, Viktor</dc:creator>
 <dc:subject>Mathematics - Rings and Algebras</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Operator Algebras</dc:subject>
 <dc:description>  It has been recently discovered by Bell, Heinle and Levandovskyy that a large
class of algebras, including the ubiquitous $G$-algebras, are finite
factorization domains (FFD for short).
  Utilizing this result, we contribute an algorithm to find all distinct
factorizations of a given element $f \in \mathcal{G}$, where $\mathcal{G}$ is
any $G$-algebra, with minor assumptions on the underlying field.
  Moreover, the property of being an FFD, in combination with the factorization
algorithm, enables us to propose an analogous description of the factorized
Gr\&quot;obner basis algorithm for $G$-algebras. This algorithm is useful for
various applications, e.g. in analysis of solution spaces of systems of linear
partial functional equations with polynomial coefficients, coming from
$\mathcal{G}$. Additionally, it is possible to include inequality constraints
for ideals in the input.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00296</dc:identifier>
 <dc:identifier>doi:10.1016/j.jsc.2017.06.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00307</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bit-Planes: Dense Subpixel Alignment of Binary Descriptors</dc:title>
 <dc:creator>Alismail, Hatem</dc:creator>
 <dc:creator>Browning, Brett</dc:creator>
 <dc:creator>Lucey, Simon</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Binary descriptors have been instrumental in the recent evolution of
computationally efficient sparse image alignment algorithms. Increasingly,
however, the vision community is interested in dense image alignment methods,
which are more suitable for estimating correspondences from high frame rate
cameras as they do not rely on exhaustive search. However, classic dense
alignment approaches are sensitive to illumination change. In this paper, we
propose an easy to implement and low complexity dense binary descriptor, which
we refer to as bit-planes, that can be seamlessly integrated within a
multi-channel Lucas &amp; Kanade framework. This novel approach combines the
robustness of binary descriptors with the speed and accuracy of dense alignment
methods. The approach is demonstrated on a template tracking problem achieving
state-of-the-art robustness and faster than real-time performance on consumer
laptops (400+ fps on a single core Intel i7) and hand-held mobile devices (100+
fps on an iPad Air 2).
</dc:description>
 <dc:description>Comment: 10 pages. In submission</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00307</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00309</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bandits meet Computer Architecture: Designing a Smartly-allocated Cache</dc:title>
 <dc:creator>Glassner, Yonatan</dc:creator>
 <dc:creator>Crammer, Koby</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In many embedded systems, such as imaging sys- tems, the system has a single
designated purpose, and same threads are executed repeatedly. Profiling thread
behavior, allows the system to allocate each thread its resources in a way that
improves overall system performance. We study an online resource al-
locationproblem,wherearesourcemanagersimulta- neously allocates resources
(exploration), learns the impact on the different consumers (learning) and im-
proves allocation towards optimal performance (ex- ploitation). We build on the
rich framework of multi- armed bandits and present online and offline algo-
rithms. Through extensive experiments with both synthetic data and real-world
cache allocation to threads we show the merits and properties of our al-
gorithms
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00309</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00310</identifier>
 <datestamp>2016-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a low-rank shared dictionary for object classification</dc:title>
 <dc:creator>Vu, Tiep H.</dc:creator>
 <dc:creator>Monga, Vishal</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Despite the fact that different objects possess distinct class-specific
features, they also usually share common patterns. Inspired by this
observation, we propose a novel method to explicitly and simultaneously learn a
set of common patterns as well as class-specific features for classification.
Our dictionary learning framework is hence characterized by both a shared
dictionary and particular (class-specific) dictionaries. For the shared
dictionary, we enforce a low-rank constraint, i.e. claim that its spanning
subspace should have low dimension and the coefficients corresponding to this
dictionary should be similar. For the particular dictionaries, we impose on
them the well-known constraints stated in the Fisher discrimination dictionary
learning (FDDL). Further, we propose a new fast and accurate algorithm to solve
the sparse coding problems in the learning step, accelerating its convergence.
The said algorithm could also be applied to FDDL and its extensions.
Experimental results on widely used image databases establish the advantages of
our method over state-of-the-art dictionary learning methods.
</dc:description>
 <dc:description>Comment: 4 page + 1 reference page</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00310</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00328</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Novel Views of Objects from a Single Image</dc:title>
 <dc:creator>Rematas, Konstantinos</dc:creator>
 <dc:creator>Nguyen, Chuong</dc:creator>
 <dc:creator>Ritschel, Tobias</dc:creator>
 <dc:creator>Fritz, Mario</dc:creator>
 <dc:creator>Tuytelaars, Tinne</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Taking an image of an object is at its core a lossy process. The rich
information about the three-dimensional structure of the world is flattened to
an image plane and decisions such as viewpoint and camera parameters are final
and not easily revertible. As a consequence, possibilities of changing
viewpoint are limited. Given a single image depicting an object, novel-view
synthesis is the task of generating new images that render the object from a
different viewpoint than the one given. The main difficulty is to synthesize
the parts that are disoccluded; disocclusion occurs when parts of an object are
hidden by the object itself under a specific viewpoint. In this work, we show
how to improve novel-view synthesis by making use of the correlations observed
in 3D models and applying them to new image instances. We propose a technique
to use the structural information extracted from a 3D model that matches the
image object in terms of viewpoint and shape. For the latter part, we propose
an efficient 2D-to-3D alignment method that associates precisely the image
appearance with the 3D model geometry with minimal user interaction. Our
technique is able to simulate plausible viewpoint changes for a variety of
object classes within seconds. Additionally, we show that our synthesized
images can be used as additional training data that improves the performance of
standard object detectors.
</dc:description>
 <dc:description>Comment: to appear in PAMI 2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-08-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00329</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lempel-Ziv Decoding in External Memory</dc:title>
 <dc:creator>Belazzougui, Djamal</dc:creator>
 <dc:creator>K&#xe4;rkk&#xe4;inen, Juha</dc:creator>
 <dc:creator>Kempa, Dominik</dc:creator>
 <dc:creator>Puglisi, Simon J.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simple and fast decoding is one of the main advantages of LZ77-type text
encoding used in many popular file compressors such as gzip and 7zip. With the
recent introduction of external memory algorithms for Lempel-Ziv factorization
there is a need for external memory LZ77 decoding but the standard algorithm
makes random accesses to the text and cannot be trivially modified for external
memory computation. We describe the first external memory algorithms for LZ77
decoding, prove that their I/O complexity is optimal, and demonstrate that they
are very fast in practice, only about three times slower than in-memory
decoding (when reading input and writing output is included in the time).
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00339</identifier>
 <datestamp>2017-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Multi-Relay Selection in Accumulate-then-Forward Energy
  Harvesting Relay Networks</dc:title>
 <dc:creator>Gu, Yifan</dc:creator>
 <dc:creator>Chen, He</dc:creator>
 <dc:creator>Li, Yonghui</dc:creator>
 <dc:creator>Vucetic, Branka</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates a wireless-powered cooperative network (WPCN)
consisting of one source-destination pair and multiple decode-and-forward (DF)
relays. We develop an energy threshold based multi-relay selection (ETMRS)
scheme for the considered WPCN. The proposed ETMRS scheme can be implemented in
a fully distributed manner as the relays only need local information to switch
between energy harvesting and information forwarding modes. By modeling the
charging/discharging behaviours of the finite-capacity battery at each relay as
a finite-state Markov Chain (MC), we derive an analytical expression for the
system outage probability of the proposed ETMRS scheme over mixed Nakagami-$m$
and Rayleigh fading channels. Based on the derived expression, the optimal
energy thresholds for all the relays corresponding to the minimum system outage
probability can be obtained via an exhaustive search. However, this approach
becomes computationally prohibitive when the number of relays and the
associated number of battery energy levels is large. To resolve this issue, we
propose a heuristic approach to optimize the energy threshold for each relay.
To gain some useful insights for practical relay design, we also derive the
upper bound for system outage probability corresponding to the case that all
relays are equipped with infinite-capacity batteries. Numerical results
validate our theoretical analysis. It is shown that the proposed heuristic
approach can achieve a near-optimal system performance and our ETMRS scheme
outperforms the existing single-relay selection scheme and common energy
threshold scheme.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Transactions on Green Communications and
  Networking</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-10-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00345</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hadoop on HPC: Integrating Hadoop and Pilot-based Dynamic Resource
  Management</dc:title>
 <dc:creator>Luckow, Andre</dc:creator>
 <dc:creator>Paraskevakos, Ioannis</dc:creator>
 <dc:creator>Chantzialexiou, George</dc:creator>
 <dc:creator>Jha, Shantenu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  High-performance computing platforms such as supercomputers have
traditionally been designed to meet the compute demands of scientific
applications. Consequently, they have been architected as producers and not
consumers of data. The Apache Hadoop ecosystem has evolved to meet the
requirements of data processing applications and has addressed many of the
limitations of HPC platforms. There exist a class of scientific applications
however, that need the collective capabilities of traditional high-performance
computing environments and the Apache Hadoop ecosystem. For example, the
scientific domains of bio-molecular dynamics, genomics and network science need
to couple traditional computing with Hadoop/Spark based analysis. We
investigate the critical question of how to present the capabilities of both
computing environments to such scientific applications. Whereas this questions
needs answers at multiple levels, we focus on the design of resource management
middleware that might support the needs of both. We propose extensions to the
Pilot-Abstraction to provide a unifying resource management layer. This is an
important step that allows applications to integrate HPC stages (e.g.
simulations) to data analytics. Many supercomputing centers have started to
officially support Hadoop environments, either in a dedicated environment or in
hybrid deployments using tools such as myHadoop. This typically involves many
intrinsic, environment-specific details that need to be mastered, and often
swamp conceptual issues like: How best to couple HPC and Hadoop application
stages? How to explore runtime trade-offs (data localities vs. data movement)?
This paper provides both conceptual understanding and practical solutions to
the integrated use of HPC and Hadoop environments.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00345</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00349</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interval Linear Algebra and Computational Complexity</dc:title>
 <dc:creator>Hor&#xe1;&#x10d;ek, Jaroslav</dc:creator>
 <dc:creator>Hlad&#xed;k, Milan</dc:creator>
 <dc:creator>&#x10c;ern&#xfd;, Michal</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This work connects two mathematical fields - computational complexity and
interval linear algebra. It introduces the basic topics of interval linear
algebra - regularity and singularity, full column rank, solving a linear
system, deciding solvability of a linear system, computing inverse matrix,
eigenvalues, checking positive (semi)definiteness or stability. We discuss
these problems and relations between them from the view of computational
complexity. Many problems in interval linear algebra are intractable, hence we
emphasize subclasses of these problems that are easily solvable or decidable.
The aim of this work is to provide a basic insight into this field and to
provide materials for further reading and research.
</dc:description>
 <dc:description>Comment: Submitted to Mat Triad 2015</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00349</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00351</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Subgradient Methods for Online AUC Maximization</dc:title>
 <dc:creator>Ding, Yi</dc:creator>
 <dc:creator>Zhao, Peilin</dc:creator>
 <dc:creator>Hoi, Steven C. H.</dc:creator>
 <dc:creator>Ong, Yew-Soon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Learning for maximizing AUC performance is an important research problem in
Machine Learning and Artificial Intelligence. Unlike traditional batch learning
methods for maximizing AUC which often suffer from poor scalability, recent
years have witnessed some emerging studies that attempt to maximize AUC by
single-pass online learning approaches. Despite their encouraging results
reported, the existing online AUC maximization algorithms often adopt simple
online gradient descent approaches that fail to exploit the geometrical
knowledge of the data observed during the online learning process, and thus
could suffer from relatively larger regret. To address the above limitation, in
this work, we explore a novel algorithm of Adaptive Online AUC Maximization
(AdaOAM) which employs an adaptive gradient method that exploits the knowledge
of historical gradients to perform more informative online learning. The new
adaptive updating strategy of the AdaOAM is less sensitive to the parameter
settings and maintains the same time complexity as previous non-adaptive
counterparts. Additionally, we extend the algorithm to handle high-dimensional
sparse data (SAdaOAM) and address sparsity in the solution by performing lazy
gradient updating. We analyze the theoretical bounds and evaluate their
empirical performance on various types of data sets. The encouraging empirical
results obtained clearly highlighted the effectiveness and efficiency of the
proposed algorithms.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00354</identifier>
 <datestamp>2016-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Learning Algorithms for Graphical Model Selection</dc:title>
 <dc:creator>Dasarathy, Gautam</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:creator>Balcan, Maria-Florina</dc:creator>
 <dc:creator>Park, Jong Hyuk</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  The problem of learning the structure of a high dimensional graphical model
from data has received considerable attention in recent years. In many
applications such as sensor networks and proteomics it is often expensive to
obtain samples from all the variables involved simultaneously. For instance,
this might involve the synchronization of a large number of sensors or the
tagging of a large number of proteins. To address this important issue, we
initiate the study of a novel graphical model selection problem, where the goal
is to optimize the total number of scalar samples obtained by allowing the
collection of samples from only subsets of the variables. We propose a general
paradigm for graphical model selection where feedback is used to guide the
sampling to high degree vertices, while obtaining only few samples from the
ones with the low degrees. We instantiate this framework with two specific
active learning algorithms, one of which makes mild assumptions but is
computationally expensive, while the other is more computationally efficient
but requires stronger (nevertheless standard) assumptions. Whereas the sample
complexity of passive algorithms is typically a function of the maximum degree
of the graph, we show that the sample complexity of our algorithms is provable
smaller and that it depends on a novel local complexity measure that is akin to
the average degree of the graph. We finally demonstrate the efficacy of our
framework via simulations.
</dc:description>
 <dc:description>Comment: 26 pages, 3 figures. Preliminary version to appear in AI &amp; Statistics
  2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00354</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00357</identifier>
 <datestamp>2017-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DeepCare: A Deep Dynamic Memory Model for Predictive Medicine</dc:title>
 <dc:creator>Pham, Trang</dc:creator>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Personalized predictive medicine necessitates the modeling of patient illness
and care processes, which inherently have long-term temporal dependencies.
Healthcare observations, recorded in electronic medical records, are episodic
and irregular in time. We introduce DeepCare, an end-to-end deep dynamic neural
network that reads medical records, stores previous illness history, infers
current illness states and predicts future medical outcomes. At the data level,
DeepCare represents care episodes as vectors in space, models patient health
state trajectories through explicit memory of historical records. Built on Long
Short-Term Memory (LSTM), DeepCare introduces time parameterizations to handle
irregular timed events by moderating the forgetting and consolidation of memory
cells. DeepCare also incorporates medical interventions that change the course
of illness and shape future medical risk. Moving up to the health state level,
historical and present health states are then aggregated through multiscale
temporal pooling, before passing through a neural network that estimates future
outcomes. We demonstrate the efficacy of DeepCare for disease progression
modeling, intervention recommendation, and future risk prediction. On two
important cohorts with heavy social and economic burden -- diabetes and mental
health -- the results show improved modeling and risk prediction accuracy.
</dc:description>
 <dc:description>Comment: Accepted at JBI under the new name: &quot;Predicting healthcare
  trajectories from medical records: A deep learning approach&quot;</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2017-04-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00357</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00363</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>INSQ: An Influential Neighbor Set Based Moving kNN Query Processing
  System</dc:title>
 <dc:creator>Li, Chuanwen</dc:creator>
 <dc:creator>Gu, Yu</dc:creator>
 <dc:creator>Qi, Jianzhong</dc:creator>
 <dc:creator>Yu, Ge</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Deng, Qingxu</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We revisit the moving k nearest neighbor (MkNN) query, which computes one's k
nearest neighbor set and maintains it while at move. Existing MkNN algorithms
are mostly safe region based, which lack efficiency due to either computing
small safe regions with a high recomputation frequency or computing larger safe
regions but with a high cost for each computation. In this demonstration, we
showcase a system named INSQ that adopts a novel algorithm called the
Influential Neighbor Set (INS) algorithm to process the MkNN query in both
two-dimensional Euclidean space and road networks. This algorithm uses a small
set of safe guarding objects instead of safe regions. As long as the the
current k nearest neighbors are closer to the query object than the safe
guarding objects are, the current k nearest neighbors stay valid and no
recomputation is required. Meanwhile, the region defined by the safe guarding
objects is the largest possible safe region. This means that the recomputation
frequency is also minimized and hence, the INS algorithm achieves high overall
query processing efficiency.
</dc:description>
 <dc:description>Comment: Accepted to appear in ICDE 2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00366</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Channel MAC Protocol for Full-Duplex Cognitive Radio Networks with
  Optimized Access Control and Load Balancing</dc:title>
 <dc:creator>Thanh, Tan Le</dc:creator>
 <dc:creator>Le, Long Bao</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  In this paper, we propose a multi-channel full-duplex Medium Access Control
(MAC) protocol for cognitive radio networks (MFDC-MAC). Our design exploits the
fact that full-duplex (FD) secondary users (SUs) can perform spectrum sensing
and access simultaneously, and we employ the randomized dynamic channel
selection for load balancing among channels and the standard backoff mechanism
for contention resolution on each available channel. Then, we develop a
mathematical model to analyze the throughput performance of the proposed
MFDC-MAC protocol. Furthermore, we study the protocol configuration
optimization to maximize the network throughput where we show that this
optimization can be performed in two steps, namely optimization of access and
transmission parameters on each channel and optimization of channel selection
probabilities of the users. Such optimization aims at achieving efficient
self-interference management for FD transceivers, sensing overhead control, and
load balancing among the channels. Numerical results demonstrate the impacts of
different protocol parameters and the importance of parameter optimization on
the throughput performance as well as the significant performance gain of the
proposed design compared to traditional design.
</dc:description>
 <dc:description>Comment: To appear in 2016 IEEE International Conference on Communications
  (IEEE ICC 2016). arXiv admin note: text overlap with arXiv:1512.03839</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00367</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Character-level Document Classification by Combining
  Convolution and Recurrent Layers</dc:title>
 <dc:creator>Xiao, Yijun</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Document classification tasks were primarily tackled at word level. Recent
research that works with character-level inputs shows several benefits over
word-level approaches such as natural incorporation of morphemes and better
handling of rare words. We propose a neural network architecture that utilizes
both convolution and recurrent layers to efficiently encode character inputs.
We validate the proposed model on eight large scale document classification
tasks and compare with character-level convolution-only models. It achieves
comparable performances with much less parameters.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00370</identifier>
 <datestamp>2016-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visualizing Large-scale and High-dimensional Data</dc:title>
 <dc:creator>Tang, Jian</dc:creator>
 <dc:creator>Liu, Jingzhou</dc:creator>
 <dc:creator>Zhang, Ming</dc:creator>
 <dc:creator>Mei, Qiaozhu</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  We study the problem of visualizing large-scale and high-dimensional data in
a low-dimensional (typically 2D or 3D) space. Much success has been reported
recently by techniques that first compute a similarity structure of the data
points and then project them into a low-dimensional space with the structure
preserved. These two steps suffer from considerable computational costs,
preventing the state-of-the-art methods such as the t-SNE from scaling to
large-scale and high-dimensional data (e.g., millions of data points and
hundreds of dimensions). We propose the LargeVis, a technique that first
constructs an accurately approximated K-nearest neighbor graph from the data
and then layouts the graph in the low-dimensional space. Comparing to t-SNE,
LargeVis significantly reduces the computational cost of the graph construction
step and employs a principled probabilistic model for the visualization step,
the objective of which can be effectively optimized through asynchronous
stochastic gradient descent with a linear time complexity. The whole procedure
thus easily scales to millions of high-dimensional data points. Experimental
results on real-world data sets demonstrate that the LargeVis outperforms the
state-of-the-art methods in both efficiency and effectiveness. The
hyper-parameters of LargeVis are also much more stable over different data
sets.
</dc:description>
 <dc:description>Comment: WWW 2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00370</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2883041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00374</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ConfidentCare: A Clinical Decision Support System for Personalized
  Breast Cancer Screening</dc:title>
 <dc:creator>Alaa, Ahmed M.</dc:creator>
 <dc:creator>Moon, Kyeong H.</dc:creator>
 <dc:creator>Hsu, William</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Breast cancer screening policies attempt to achieve timely diagnosis by the
regular screening of apparently healthy women. Various clinical decisions are
needed to manage the screening process; those include: selecting the screening
tests for a woman to take, interpreting the test outcomes, and deciding whether
or not a woman should be referred to a diagnostic test. Such decisions are
currently guided by clinical practice guidelines (CPGs), which represent a
one-size-fits-all approach that are designed to work well on average for a
population, without guaranteeing that it will work well uniformly over that
population. Since the risks and benefits of screening are functions of each
patients features, personalized screening policies that are tailored to the
features of individuals are needed in order to ensure that the right tests are
recommended to the right woman. In order to address this issue, we present
ConfidentCare: a computer-aided clinical decision support system that learns a
personalized screening policy from the electronic health record (EHR) data.
ConfidentCare operates by recognizing clusters of similar patients, and
learning the best screening policy to adopt for each cluster. A cluster of
patients is a set of patients with similar features (e.g. age, breast density,
family history, etc.), and the screening policy is a set of guidelines on what
actions to recommend for a woman given her features and screening test scores.
ConfidentCare algorithm ensures that the policy adopted for every cluster of
patients satisfies a predefined accuracy requirement with a high level of
confidence. We show that our algorithm outperforms the current CPGs in terms of
cost-efficiency and false positive rates.
</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00374</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00376</identifier>
 <datestamp>2016-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Beyond Countable Alphabets: An Extension of the Information-Spectrum
  Approach</dc:title>
 <dc:creator>Yang, Shengtian</dc:creator>
 <dc:creator>Honold, Thomas</dc:creator>
 <dc:creator>Zhang, Zhaoyang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A general approach is established for deriving one-shot performance bounds
for information-theoretic problems on general alphabets beyond countable
alphabets. It is mainly based on the quantization idea and a novel form of
&quot;likelihood ratio&quot;. As an example, one-shot lower and upper bounds for random
number generation from correlated sources on general alphabets are derived.
</dc:description>
 <dc:description>Comment: v0.5.1.20be8d, 7 pages</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-07-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00377</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cellular Underwater Wireless Optical CDMA Network: Potentials and
  Challenges</dc:title>
 <dc:creator>Akhoundi, Farhad</dc:creator>
 <dc:creator>Jamali, Mohammad Vahid</dc:creator>
 <dc:creator>Banihassan, Navid</dc:creator>
 <dc:creator>Beyranvand, Hamzeh</dc:creator>
 <dc:creator>Minoofar, Amir</dc:creator>
 <dc:creator>Salehi, Jawad A.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Underwater wireless optical communications is an emerging solution to the
expanding demand for broadband links in oceans and seas. In this paper, a
cellular underwater wireless optical code division multiple-access (UW-OCDMA)
network is proposed to provide broadband links for commercial and military
applications. The optical orthogonal codes (OOC) are employed as signature
codes of underwater mobile users. Fundamental key aspects of the network such
as its backhaul architecture, its potential applications and its design
challenges are presented. In particular, the proposed network is used as
infrastructure of centralized, decentralized and relay-assisted underwater
sensor networks for high-speed real-time monitoring. Furthermore, a promising
underwater localization and positioning scheme based on this cellular network
is presented. Finally, probable design challenges such as cell edge coverage,
blockage avoidance, power control and increasing the network capacity are
addressed.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00382</identifier>
 <datestamp>2016-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Constrained Recursive Nonlinear Least-Squares Estimation:
  Algorithms and Asymptotics</dc:title>
 <dc:creator>Sahu, Anit Kumar</dc:creator>
 <dc:creator>Kar, Soummya</dc:creator>
 <dc:creator>Moura, Jose' M. F.</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  This paper focuses on the problem of recursive nonlinear least squares
parameter estimation in multi-agent networks, in which the individual agents
observe sequentially over time an independent and identically distributed
(i.i.d.) time-series consisting of a nonlinear function of the true but unknown
parameter corrupted by noise. A distributed recursive estimator of the
\emph{consensus} + \emph{innovations} type, namely $\mathcal{CIWNLS}$, is
proposed, in which the agents update their parameter estimates at each
observation sampling epoch in a collaborative way by simultaneously processing
the latest locally sensed information~(\emph{innovations}) and the parameter
estimates from other agents~(\emph{consensus}) in the local neighborhood
conforming to a pre-specified inter-agent communication topology. Under rather
weak conditions on the connectivity of the inter-agent communication and a
\emph{global observability} criterion, it is shown that at every network agent,
the proposed algorithm leads to consistent parameter estimates. Furthermore,
under standard smoothness assumptions on the local observation functions, the
distributed estimator is shown to yield order-optimal convergence rates, i.e.,
as far as the order of pathwise convergence is concerned, the local parameter
estimates at each agent are as good as the optimal centralized nonlinear least
squares estimator which would require access to all the observations across all
the agents at all times. In order to benchmark the performance of the proposed
distributed $\mathcal{CIWNLS}$ estimator with that of the centralized nonlinear
least squares estimator, the asymptotic normality of the estimate sequence is
established and the asymptotic covariance of the distributed estimator is
evaluated. Finally, simulation results are presented which illustrate and
verify the analytical findings.
</dc:description>
 <dc:description>Comment: 28 pages. Initial Submission: Feb. 2016, Revised: July 2016,
  Accepted: September 2016, To appear in IEEE Transactions on Signal and
  Information Processing over Networks: Special Issue on Inference and Learning
  over Networks</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00382</dc:identifier>
 <dc:identifier>doi:10.1109/TSIPN.2016.2618318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00386</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scene Invariant Crowd Segmentation and Counting Using Scale-Normalized
  Histogram of Moving Gradients (HoMG)</dc:title>
 <dc:creator>Siva, Parthipan</dc:creator>
 <dc:creator>Shafiee, Mohammad Javad</dc:creator>
 <dc:creator>Jamieson, Mike</dc:creator>
 <dc:creator>Wong, Alexander</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The problem of automated crowd segmentation and counting has garnered
significant interest in the field of video surveillance. This paper proposes a
novel scene invariant crowd segmentation and counting algorithm designed with
high accuracy yet low computational complexity in mind, which is key for
widespread industrial adoption. A novel low-complexity, scale-normalized
feature called Histogram of Moving Gradients (HoMG) is introduced for highly
effective spatiotemporal representation of individuals and crowds within a
video. Real-time crowd segmentation is achieved via boosted cascade of weak
classifiers based on sliding-window HoMG features, while linear SVM regression
of crowd-region HoMG features is employed for real-time crowd counting.
Experimental results using multi-camera crowd datasets show that the proposed
algorithm significantly outperform state-of-the-art crowd counting algorithms,
as well as achieve very promising crowd segmentation results, thus
demonstrating the efficacy of the proposed method for highly-accurate,
real-time video-driven crowd analysis.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00389</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reverse Nearest Neighbor Heat Maps: A Tool for Influence Exploration</dc:title>
 <dc:creator>Sun, Yu</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Xue, Andy Yuan</dc:creator>
 <dc:creator>Qi, Jianzhong</dc:creator>
 <dc:creator>Du, Xiaoyong</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We study the problem of constructing a reverse nearest neighbor (RNN) heat
map by finding the RNN set of every point in a two-dimensional space. Based on
the RNN set of a point, we obtain a quantitative influence (i.e., heat) for the
point. The heat map provides a global view on the influence distribution in the
space, and hence supports exploratory analyses in many applications such as
marketing and resource management. To construct such a heat map, we first
reduce it to a problem called Region Coloring (RC), which divides the space
into disjoint regions within which all the points have the same RNN set. We
then propose a novel algorithm named CREST that efficiently solves the RC
problem by labeling each region with the heat value of its containing points.
In CREST, we propose innovative techniques to avoid processing expensive RNN
queries and greatly reduce the number of region labeling operations. We perform
detailed analyses on the complexity of CREST and lower bounds of the RC
problem, and prove that CREST is asymptotically optimal in the worst case.
Extensive experiments with both real and synthetic data sets demonstrate that
CREST outperforms alternative algorithms by several orders of magnitude.
</dc:description>
 <dc:description>Comment: Accepted to appear in ICDE 2016</dc:description>
 <dc:date>2016-01-31</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00398</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Short Note on Improved Logic Circuits in a Hexagonal Minesweeper</dc:title>
 <dc:creator>Lee, Seunghoon</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  This paper aims to present an advanced version of PP-hardness proof of
Minesweeper by Bondt. The advancement includes improved Minesweeper
configurations for 'logic circuits' in a hexagonal Minesweeper. To do so, I
demonstrate logical uncertainty in Minesweeper, which ironically allows a
possibility to make some Boolean operators.
  The fact that existing hexagonal logic circuits did not clearly distinguish
the true and false signal needs an improved form of a hexagonal wire. I
introduce new forms of logic circuits such as NOT, AND, OR gates, a curve and a
splitter of wires. Moreover, these new logic circuits complement Bondt's proof
for PP-hardness of Minesweeper by giving a new figure.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00399</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Price of Order</dc:title>
 <dc:creator>Bose, Prosenjit</dc:creator>
 <dc:creator>Morin, Pat</dc:creator>
 <dc:creator>van Renssen, Andr&#xe9;</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We present tight bounds on the spanning ratio of a large family of ordered
$\theta$-graphs. A $\theta$-graph partitions the plane around each vertex into
$m$ disjoint cones, each having aperture $\theta = 2 \pi/m$. An ordered
$\theta$-graph is constructed by inserting the vertices one by one and
connecting each vertex to the closest previously-inserted vertex in each cone.
We show that for any integer $k \geq 1$, ordered $\theta$-graphs with $4k + 4$
cones have a tight spanning ratio of $1 + 2 \sin(\theta/2) / (\cos(\theta/2) -
\sin(\theta/2))$. We also show that for any integer $k \geq 2$, ordered
$\theta$-graphs with $4k + 2$ cones have a tight spanning ratio of $1 / (1 - 2
\sin(\theta/2))$. We provide lower bounds for ordered $\theta$-graphs with $4k
+ 3$ and $4k + 5$ cones. For ordered $\theta$-graphs with $4k + 2$ and $4k + 5$
cones these lower bounds are strictly greater than the worst case spanning
ratios of their unordered counterparts. These are the first results showing
that ordered $\theta$-graphs have worse spanning ratios than unordered
$\theta$-graphs. Finally, we show that, unlike their unordered counterparts,
the ordered $\theta$-graphs with 4, 5, and 6 cones are not spanners.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00399</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00401</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum Capacities for Entanglement Networks</dc:title>
 <dc:creator>Cui, Shawn X</dc:creator>
 <dc:creator>Ji, Zhengfeng</dc:creator>
 <dc:creator>Yu, Nengkun</dc:creator>
 <dc:creator>Zeng, Bei</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We discuss quantum capacities for two types of entanglement networks:
$\mathcal{Q}$ for the quantum repeater network with free classical
communication, and $\mathcal{R}$ for the tensor network as the rank of the
linear operation represented by the tensor network. We find that $\mathcal{Q}$
always equals $\mathcal{R}$ in the regularized case for the samenetwork graph.
However, the relationships between the corresponding one-shot capacities
$\mathcal{Q}_1$ and $\mathcal{R}_1$ are more complicated, and the min-cut upper
bound is in general not achievable. We show that the tensor network can be
viewed as a stochastic protocol with the quantum repeater network, such that
$\mathcal{R}_1$ is a natural upper bound of $\mathcal{Q}_1$. We analyze the
possible gap between $\mathcal{R}_1$ and $\mathcal{Q}_1$ for certain networks,
and compare them with the one-shot classical capacity of the corresponding
classical network.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00412</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Frequent Directions Algorithm for Sparse Matrices</dc:title>
 <dc:creator>Ghashami, Mina</dc:creator>
 <dc:creator>Liberty, Edo</dc:creator>
 <dc:creator>Phillips, Jeff M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  This paper describes Sparse Frequent Directions, a variant of Frequent
Directions for sketching sparse matrices. It resembles the original algorithm
in many ways: both receive the rows of an input matrix $A^{n \times d}$ one by
one in the streaming setting and compute a small sketch $B \in R^{\ell \times
d}$. Both share the same strong (provably optimal) asymptotic guarantees with
respect to the space-accuracy tradeoff in the streaming setting. However,
unlike Frequent Directions which runs in $O(nd\ell)$ time regardless of the
sparsity of the input matrix $A$, Sparse Frequent Directions runs in $\tilde{O}
(nnz(A)\ell + n\ell^2)$ time. Our analysis loosens the dependence on computing
the Singular Value Decomposition (SVD) as a black box within the Frequent
Directions algorithm. Our bounds require recent results on the properties of
fast approximate SVD computations. Finally, we empirically demonstrate that
these asymptotic improvements are practical and significant on real and
synthetic data.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00413</identifier>
 <datestamp>2018-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Programming Bounds for Entanglement-Assisted Quantum
  Error-Correcting Codes by Split Weight Enumerators</dc:title>
 <dc:creator>Lai, Ching-Yi</dc:creator>
 <dc:creator>Ashikhmin, Alexei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Linear programming approaches have been applied to derive upper bounds on the
size of classical codes and quantum codes. In this paper, we derive similar
results for general quantum codes with entanglement assistance, including
nonadditive codes, by considering a type of split weight enumerators. After
deriving the MacWilliams identities for these split weight enumerators, we are
able to prove algebraic linear programming bounds, such as the Singleton bound,
the Hamming bound, and the first linear programming bound. In particular, we
show that the first linear programming bound improves the Hamming bound when
the relative distance is sufficiently large.
  On the other hand, we obtain additional constraints on the size of Pauli
subgroups for quantum codes, which allow us to improve the linear programming
bounds on the minimum distance of small quantum codes. In particular, we show
that there is no [[27,15,5]] or [[28,14,6]] quantum stabilizer code. We also
discuss the existence of some entanglement-assisted quantum stabilizer codes
with maximal entanglement. As a result, the upper and lower bounds on the
minimum distance of maximal-entanglement quantum stabilizer codes with length
up to 20 are significantly improved.
</dc:description>
 <dc:description>Comment: 23 pages, 5 figures, 2 tables. A refined Singleton bound for the
  general case is provided in this version. The code table is updated</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-05-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00413</dc:identifier>
 <dc:identifier>IEEE Trans. Inf. Theory, vol. 64, no. 1, pp. 622-639, Jan. 2018</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2711601</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00417</identifier>
 <datestamp>2016-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Transfer Learning Based on AdaBoost for Feature Selection from Multiple
  ConvNet Layer Features</dc:title>
 <dc:creator>Alikhanov, Jumabek</dc:creator>
 <dc:creator>Ga, Myeong Hyeon</dc:creator>
 <dc:creator>Ko, Seunghyun</dc:creator>
 <dc:creator>Jo, Geun-Sik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Networks (ConvNets) are powerful models that learn hierarchies
of visual features, which could also be used to obtain image representations
for transfer learning. The basic pipeline for transfer learning is to first
train a ConvNet on a large dataset (source task) and then use feed-forward
units activation of the trained ConvNet as image representation for smaller
datasets (target task). Our key contribution is to demonstrate superior
performance of multiple ConvNet layer features over single ConvNet layer
features. Combining multiple ConvNet layer features will result in more complex
feature space with some features being repetitive. This requires some form of
feature selection. We use AdaBoost with single stumps to implicitly select only
distinct features that are useful towards classification from concatenated
ConvNet features. Experimental results show that using multiple ConvNet layer
activation features instead of single ConvNet layer features consistently will
produce superior performance. Improvements becomes significant as we increase
the distance between source task and the target task.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00417</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00419</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Is collaboration among scientists related to the citation impact of
  papers because their quality increases with collaboration? An analysis based
  on data from F1000Prime and normalized citation scores</dc:title>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  In recent years, the relationship of collaboration among scientists and the
citation impact of papers have been frequently investigated. Most of the
studies show that the two variables are closely related: an increasing
collaboration activity (measured in terms of number of authors, number of
affiliations, and number of countries) is associated with an increased citation
impact. However, it is not clear whether the increased citation impact is based
on the higher quality of papers which profit from more than one scientist
giving expert input or other (citation-specific) factors. Thus, the current
study addresses this question by using two comprehensive datasets with
publications (in the biomedical area) including quality assessments by experts
(F1000Prime member scores) and citation data for the publications. The study is
based on nearly 10,000 papers. Robust regression models are used to investigate
the relationship between number of authors, number of affiliations, and number
of countries, respectively, and citation impact - controlling for the papers'
quality (measured by F1000Prime expert ratings). The results point out that the
effect of collaboration activities on impact is largely independent of the
papers' quality. The citation advantage is apparently not quality-related;
citation specific factors (e.g. self-citations) seem to be important here.
</dc:description>
 <dc:description>Comment: Accepted for publication in the Journal of the Association for
  Information Science and Technology</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00422</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Packed Compact Tries: A Fast and Efficient Data Structure for Online
  String Processing</dc:title>
 <dc:creator>Takagi, Takuya</dc:creator>
 <dc:creator>Inenaga, Shunsuke</dc:creator>
 <dc:creator>Sadakane, Kunihiko</dc:creator>
 <dc:creator>Arimura, Hiroki</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we present a new data structure called the packed compact trie
(packed c-trie) which stores a set $S$ of $k$ strings of total length $n$ in $n
\log\sigma + O(k \log n)$ bits of space and supports fast pattern matching
queries and updates, where $\sigma$ is the size of an alphabet. Assume that
$\alpha = \log_\sigma n$ letters are packed in a single machine word on the
standard word RAM model, and let $f(k,n)$ denote the query and update times of
the dynamic predecessor/successor data structure of our choice which stores $k$
integers from universe $[1,n]$ in $O(k \log n)$ bits of space. Then, given a
string of length $m$, our packed c-tries support pattern matching queries and
insert/delete operations in $O(\frac{m}{\alpha} f(k,n))$ worst-case time and in
$O(\frac{m}{\alpha} + f(k,n))$ expected time. Our experiments show that our
packed c-tries are faster than the standard compact tries (a.k.a. Patricia
trees) on real data sets. As an application of our packed c-trie, we show that
the sparse suffix tree for a string of length $n$ over prefix codes with $k$
sampled positions, such as evenly-spaced and word delimited sparse suffix
trees, can be constructed online in $O((\frac{n}{\alpha} + k) f(k,n))$
worst-case time and $O(\frac{n}{\alpha} + k f(k,n))$ expected time with $n \log
\sigma + O(k \log n)$ bits of space. When $k = O(\frac{n}{\alpha})$, by using
the state-of-the-art dynamic predecessor/successor data structures, we obtain
sub-linear time construction algorithms using only $O(\frac{n}{\alpha})$ bits
of space in both cases. We also discuss an application of our packed c-tries to
online LZD factorization.
</dc:description>
 <dc:description>Comment: 10 pages, 2 figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00422</dc:identifier>
 <dc:identifier>doi:10.1587/transfun.E100.A.1785</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00424</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reduction-Based Creative Telescoping for Algebraic Functions</dc:title>
 <dc:creator>Chen, Shaoshi</dc:creator>
 <dc:creator>Kauers, Manuel</dc:creator>
 <dc:creator>Koutschan, Christoph</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  Continuing a series of articles in the past few years on creative telescoping
using reductions, we develop a new algorithm to construct minimal telescopers
for algebraic functions. This algorithm is based on Trager's Hermite reduction
and on polynomial reduction, which was originally designed for hyperexponential
functions and extended to the algebraic case in this paper.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00424</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00426</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Iterative Deep Learning Framework for Unsupervised Discovery of
  Speech Features and Linguistic Units with Applications on Spoken Term
  Detection</dc:title>
 <dc:creator>Chung, Cheng-Tao</dc:creator>
 <dc:creator>Tsai, Cheng-Yu</dc:creator>
 <dc:creator>Lu, Hsiang-Hung</dc:creator>
 <dc:creator>Liu, Chia-Hsiang</dc:creator>
 <dc:creator>Lee, Hung-yi</dc:creator>
 <dc:creator>Lee, Lin-shan</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work we aim to discover high quality speech features and linguistic
units directly from unlabeled speech data in a zero resource scenario. The
results are evaluated using the metrics and corpora proposed in the Zero
Resource Speech Challenge organized at Interspeech 2015. A Multi-layered
Acoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets
of acoustic tokens from the given corpus. Each acoustic token set is specified
by a set of hyperparameters that describe the model configuration. These sets
of acoustic tokens carry different characteristics fof the given corpus and the
language behind, thus can be mutually reinforced. The multiple sets of token
labels are then used as the targets of a Multi-target Deep Neural Network
(MDNN) trained on low-level acoustic features. Bottleneck features extracted
from the MDNN are then used as the feedback input to the MAT and the MDNN
itself in the next iteration. We call this iterative deep learning framework
the Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN), which
generates both high quality speech features for the Track 1 of the Challenge
and acoustic tokens for the Track 2 of the Challenge. In addition, we performed
extra experiments on the same corpora on the application of query-by-example
spoken term detection. The experimental results showed the iterative deep
learning framework of MAT-DNN improved the detection performance due to better
underlying speech features and acoustic tokens.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1506.02327</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00430</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Sensing for Implantable Neural Recordings Using Co-sparse
  Analysis Model and Weighted $\ell_1$-Optimization</dc:title>
 <dc:creator>Sun, Biao</dc:creator>
 <dc:creator>Zhao, Wenfeng</dc:creator>
 <dc:creator>Zhu, Xinshan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Reliable and energy-efficient wireless data transmission remains a major
challenge in resource-constrained wireless neural recording tasks, where data
compression is generally adopted to relax the burdens on the wireless data
link. Recently, Compressed Sensing (CS) theory has successfully demonstrated
its potential in neural recording application. The main limitation of CS,
however, is that the neural signals have no good sparse representation with
commonly used dictionaries and learning a reliable dictionary is often data
dependent and computationally demanding. In this paper, a novel CS approach for
implantable neural recording is proposed. The main contributions are: 1) The
co-sparse analysis model is adopted to enforce co-sparsity of the neural
signals, therefore overcoming the drawbacks of conventional synthesis model and
enhancing the reconstruction performance. 2) A multi-fractional-order
difference matrix is constructed as the analysis dictionary, thus avoiding the
dictionary learning procedure and reducing the need for previously acquired
data and computational resources. 3) By exploiting the statistical priors of
the analysis coefficients, a weighted analysis $\ell_1$-minimization (WALM)
algorithm is proposed to reconstruct the neural signals. Experimental results
on Leicester neural signal database reveal that the proposed approach
outperforms the state-of-the-art CS-based methods. On the challenging high
compression ratio task, the proposed approach still achieves high
reconstruction performance and spike classification accuracy.
</dc:description>
 <dc:description>Comment: 22 pages, 11 figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00430</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00431</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving rank-constrained semidefinite programs in exact arithmetic</dc:title>
 <dc:creator>Naldi, Simone</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>14Q20, 52B55</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:description>  We consider the problem of minimizing a linear function over an affine
section of the cone of positive semidefinite matrices, with the additional
constraint that the feasible matrix has prescribed rank. When the rank
constraint is active, this is a non-convex optimization problem, otherwise it
is a semidefinite program. Both find numerous applications especially in
systems control theory and combinatorial optimization, but even in more general
contexts such as polynomial optimization or real algebra. While numerical
algorithms exist for solving this problem, such as interior-point or
Newton-like algorithms, in this paper we propose an approach based on symbolic
computation. We design an exact algorithm for solving rank-constrained
semidefinite programs, whose complexity is essentially quadratic on natural
degree bounds associated to the given optimization problem: for subfamilies of
the problem where the size of the feasible matrix is fixed, the complexity is
polynomial in the number of variables. The algorithm works under assumptions on
the input data: we prove that these assumptions are generically satisfied. We
also implement it in Maple and discuss practical experiments.
</dc:description>
 <dc:description>Comment: Published at ISSAC 2016. Extended version submitted to the Journal of
  Symbolic Computation</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-11-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00431</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00435</identifier>
 <datestamp>2016-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiently Correcting Matrix Products</dc:title>
 <dc:creator>Gasieniec, Leszek</dc:creator>
 <dc:creator>Levcopoulos, Christos</dc:creator>
 <dc:creator>Lingas, Andrzej</dc:creator>
 <dc:creator>Pagh, Rasmus</dc:creator>
 <dc:creator>Tokuyama, Takeshi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We study the problem of efficiently correcting an erroneous product of two
$n\times n$ matrices over a ring. Among other things, we provide a randomized
algorithm for correcting a matrix product with at most $k$ erroneous entries
running in $\tilde{O}(n^2+kn)$ time and a deterministic $\tilde{O}(kn^2)$-time
algorithm for this problem (where the notation $\tilde{O}$ suppresses
polylogarithmic terms in $n$ and $k$).
</dc:description>
 <dc:description>Comment: Fixed invalid reference to figure in v1</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-08-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00435</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00446</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph Representation for Two-Dimensional Finite Type Constrained
  Systems</dc:title>
 <dc:creator>Ota, Takahiro</dc:creator>
 <dc:creator>Manada, Akiko</dc:creator>
 <dc:creator>Morita, Hiroyoshi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The demand of two-dimensional source coding and constrained coding has been
getting higher these days, but compared to the one-dimensional case, many
problems have remained open as the analysis is cumbersome. A main reason for
that would be because there are no graph representations discovered so far. In
this paper, we focus on a two-dimensional finite type constrained system, a set
of two-dimensional blocks characterized by a finite number of two-dimensional
constraints, and propose its graph representation. We then show how to generate
an element of the two-dimensional finite type constrained system from the graph
representation.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00446</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00447</identifier>
 <datestamp>2016-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Faster Longest Common Extension Queries in Strings over General
  Alphabets</dc:title>
 <dc:creator>Gawrychowski, Pawe&#x142;</dc:creator>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:creator>Rytter, Wojciech</dc:creator>
 <dc:creator>Wale&#x144;, Tomasz</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:description>  Longest common extension queries (often called longest common prefix queries)
constitute a fundamental building block in multiple string algorithms, for
example computing runs and approximate pattern matching. We show that a
sequence of $q$ LCE queries for a string of size $n$ over a general ordered
alphabet can be realized in $O(q \log \log n+n\log^*n)$ time making only
$O(q+n)$ symbol comparisons. Consequently, all runs in a string over a general
ordered alphabet can be computed in $O(n \log \log n)$ time making $O(n)$
symbol comparisons. Our results improve upon a solution by Kosolobov
(Information Processing Letters, 2016), who gave an algorithm with $O(n
\log^{2/3} n)$ running time and conjectured that $O(n)$ time is possible. We
make a significant progress towards resolving this conjecture. Our techniques
extend to the case of general unordered alphabets, when the time increases to
$O(q\log n + n\log^*n)$. The main tools are difference covers and the
disjoint-sets data structure.
</dc:description>
 <dc:description>Comment: Accepted to CPM 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00447</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00448</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network planning tool based on network classification and load
  prediction</dc:title>
 <dc:creator>Hammami, Seif eddine</dc:creator>
 <dc:creator>Afifi, Hossam</dc:creator>
 <dc:creator>Marot, Michel</dc:creator>
 <dc:creator>Gauthier, Vincent</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Real Call Detail Records (CDR) are analyzed and classified based on Support
Vector Machine (SVM) algorithm. The daily classification results in three
traffic classes. We use two different algorithms, K-means and SVM to check the
classification efficiency. A second support vector regression (SVR) based
algorithm is built to make an online prediction of traffic load using the
history of CDRs. Then, these algorithms will be integrated to a network
planning tool which will help cellular operators on planning optimally their
access network.
</dc:description>
 <dc:description>Comment: The article has 6 pages, 8 figures and is accepted to be presented at
  WCNC'16</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00448</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00453</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Power Allocation and Scheduling for SWIPT Systems with Non-linear Energy
  Harvesting Model</dc:title>
 <dc:creator>Boshkovska, Elena</dc:creator>
 <dc:creator>Morsi, Rania</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we design a resource allocation algorithm for multiuser
simultaneous wireless information and power transfer systems for a realistic
non-linear energy harvesting (EH) model. In particular, the algorithm design is
formulated as a non-convex optimization problem for the maximization of the
long-term average total harvested power at EH receivers subject to quality of
service requirements for information decoding receivers. To obtain a tractable
solution, we transform the corresponding non-convex sum-of-ratios objective
function into an equivalent objective function in parametric subtractive form.
This leads to a computationally efficient iterative resource allocation
algorithm. Numerical results reveal a significant performance gain that can be
achieved if the resource allocation algorithm design is based on the non-linear
EH model instead of the traditional linear model.
</dc:description>
 <dc:description>Comment: Accepted for presentation at the IEEE ICC 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00453</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7511403</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00454</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Holonomic Tools for Basic Hypergeometric Functions</dc:title>
 <dc:creator>Koutschan, Christoph</dc:creator>
 <dc:creator>Paule, Peter</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  With the exception of q-hypergeometric summation, the use of computer algebra
packages implementing Zeilberger's &quot;holonomic systems approach&quot; in a broader
mathematical sense is less common in the field of q-series and basic
hypergeometric functions. A major objective of this article is to popularize
the usage of such tools also in these domains. Concrete case studies showing
software in action introduce to the basic techniques. An application highlight
is a new computer-assisted proof of the celebrated Ismail-Zhang formula, an
important q-analog of a classical expansion formula of plane waves in terms of
Gegenbauer polynomials.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00458</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Counting Constraints in Flat Array Fragments</dc:title>
 <dc:creator>Alberti, Francesco</dc:creator>
 <dc:creator>Ghilardi, Silvio</dc:creator>
 <dc:creator>Pagani, Elena</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We identify a fragment of Presburger arithmetic enriched with free function
symbols and cardinality constraints for interpreted sets, which is amenable to
automated analysis. We establish decidability and complexity results for such a
fragment and we implement our algorithms. The experiments run in discharging
proof obligations coming from invariant checking and bounded model-checking
benchmarks show the practical feasibility of our decision procedure.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00462</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed control and navigation system for quadrotor UAVs in
  GPS-denied environments</dc:title>
 <dc:creator>Yakovlev, Konstantin</dc:creator>
 <dc:creator>Khithov, Vsevolod</dc:creator>
 <dc:creator>Loginov, Maxim</dc:creator>
 <dc:creator>Petrov, Alexander</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  The problem of developing distributed control and navigation system for
quadrotor UAVs operating in GPS-denied environments is addressed in the paper.
Cooperative navigation, marker detection and mapping task solved by a team of
multiple unmanned aerial vehicles is chosen as demo example. Developed
intelligent control system complies with on 4D\RCS reference model and its
implementation is based on ROS framework. Custom implementation of EKF-based
map building algorithm is used to solve marker detection and map building task.
</dc:description>
 <dc:description>Comment: Camera-ready as submitted (and accepted) to the 7th IEEE
  International Conference Intelligent Systems IS'2014, September 24-26, 2014,
  Warsaw, Poland</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00462</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-11310-4_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00476</identifier>
 <datestamp>2017-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation Problems Over One-Counter Nets</dc:title>
 <dc:creator>Hofman, Piotr</dc:creator>
 <dc:creator>Lasota, Slawomir</dc:creator>
 <dc:creator>Mayr, Richard</dc:creator>
 <dc:creator>Totzke, Patrick</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  One-counter nets (OCN) are finite automata equipped with a counter that can
store non-negative integer values, and that cannot be tested for zero.
Equivalently, these are exactly 1-dimensional vector addition systems with
states. We show that both strong and weak simulation preorder on OCN are
PSPACE-complete.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00476</dc:identifier>
 <dc:identifier>Logical Methods in Computer Science, Volume 12, Issue 1 (March 14,
  2016) lmcs:1629</dc:identifier>
 <dc:identifier>doi:10.2168/LMCS-12(1:6)2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00477</identifier>
 <datestamp>2016-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reachability in Two-Dimensional Unary Vector Addition Systems with
  States is NL-Complete</dc:title>
 <dc:creator>Englert, Matthias</dc:creator>
 <dc:creator>Lazi&#x107;, Ranko</dc:creator>
 <dc:creator>Totzke, Patrick</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:description>  Blondin et al. showed at LICS 2015 that two-dimensional vector addition
systems with states have reachability witnesses of length exponential in the
number of states and polynomial in the norm of vectors. The resulting
guess-and-verify algorithm is optimal (PSPACE), but only if the input vectors
are given in binary. We answer positively the main question left open by their
work, namely establish that reachability witnesses of pseudo-polynomial length
always exist. Hence, when the input vectors are given in unary, the improved
guess-and-verify algorithm requires only logarithmic space.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-05-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00477</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00479</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Multi-User Perspective for Personalized Email Communities</dc:title>
 <dc:creator>Nawaz, Waqas</dc:creator>
 <dc:creator>Khan, Kifayat-Ullah</dc:creator>
 <dc:creator>Lee, Young-Koo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Email classification and prioritization expert systems have the potential to
automatically group emails and users as communities based on their
communication patterns, which is one of the most tedious tasks. The exchange of
emails among users along with the time and content information determine the
pattern of communication. The intelligent systems extract these patterns from
an email corpus of single or all users and are limited to statistical analysis.
However, the email information revealed in those methods is either constricted
or widespread, i.e. single or all users respectively, which limits the
usability of the resultant communities. In contrast to extreme views of the
email information, we relax the aforementioned restrictions by considering a
subset of all users as multi-user information in an incremental way to extend
the personalization concept. Accordingly, we propose a multi-user personalized
email community detection method to discover the groupings of email users based
on their structural and semantic intimacy. We construct a social graph using
multi-user personalized emails. Subsequently, the social graph is uniquely
leveraged with expedient attributes, such as semantics, to identify user
communities through collaborative similarity measure. The multi-user
personalized communities, which are evaluated through different quality
measures, enable the email systems to filter spam or malicious emails and
suggest contacts while composing emails. The experimental results over two
randomly selected users from email network, as constrained information, unveil
partial interaction among 80% email users with 14% search space reduction where
we notice 25% improvement in the clustering coefficient.
</dc:description>
 <dc:description>Comment: 46 pages, 14 images, Accepted in Expert Systems with Applications
  Journal</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00479</dc:identifier>
 <dc:identifier>doi:10.1016/j.eswa.2016.01.046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00481</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Symbolic Optimal Reachability in Weighted Timed Automata</dc:title>
 <dc:creator>Bouyer, Patricia</dc:creator>
 <dc:creator>Colange, Maximilien</dc:creator>
 <dc:creator>Markey, Nicolas</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Weighted timed automata have been defined in the early 2000's for modelling
resource-consumption or -allocation problems in real-time systems. Optimal
reachability is decidable in weighted timed automata, and a symbolic forward
algorithm has been developed to solve that problem. This algorithm uses
so-called priced zones, an extension of standard zones with cost functions. In
order to ensure termination, the algorithm requires clocks to be bounded. For
unpriced timed automata, much work has been done to develop sound abstractions
adapted to the forward exploration of timed automata, ensuring termination of
the model-checking algorithm without bounding the clocks. In this paper, we
take advantage of recent developments on abstractions for timed automata, and
propose an algorithm allowing for symbolic analysis of all weighted timed
automata, without requiring bounded clocks.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00482</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Memory-Based Data-Driven MRAC Architecture Ensuring Parameter
  Convergence</dc:title>
 <dc:creator>Roy, Sayan Basu</dc:creator>
 <dc:creator>Bhasin, Shubhendu</dc:creator>
 <dc:creator>Kar, Indra Narayan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Convergence of controller parameters in standard model reference adaptive
control (MRAC) requires the system states to be persistently exciting (PE), a
restrictive condition to be verified online. A recent data-driven approach,
concurrent learning, uses information-rich past data concurrently with the
standard parameter update laws to guarantee parameter convergence without the
need of the PE condition. This method guarantees exponential convergence of
both the tracking and the controller parameter estimation errors to zero,
whereas, the classical MRAC merely ensures asymptotic convergence of tracking
error to zero. However, the method requires knowledge of the state derivative,
at least at the time instances when the state values are stored in memory. The
method further assumes knowledge of the control allocation matrix. This paper
addresses these limitations by using a memory-based finite-time system
identifier in conjunction with a data-driven approach, leading to convergence
of both the tracking and the controller parameter estimation errors without the
PE condition and knowledge of the system matrices and the state derivative. A
Lyapunov based stability proof is included to justify the validity of the
proposed data-driven approach. Simulation results demonstrate the efficacy of
the suggested method.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00482</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00484</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mobile Edge Computing, Fog et al.: A Survey and Analysis of Security
  Threats and Challenges</dc:title>
 <dc:creator>Roman, Rodrigo</dc:creator>
 <dc:creator>Lopez, Javier</dc:creator>
 <dc:creator>Mambo, Masahiro</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>A.1</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:description>  For various reasons, the cloud computing paradigm is unable to meet certain
requirements (e.g. low latency and jitter, context awareness, mobility support)
that are crucial for several applications (e.g. vehicular networks, augmented
reality). To fulfil these requirements, various paradigms, such as fog
computing, mobile edge computing, and mobile cloud computing, have emerged in
recent years. While these edge paradigms share several features, most of the
existing research is compartmentalised; no synergies have been explored. This
is especially true in the field of security, where most analyses focus only on
one edge paradigm, while ignoring the others. The main goal of this study is to
holistically analyse the security threats, challenges, and mechanisms inherent
in all edge paradigms, while highlighting potential synergies and venues of
collaboration. In our results, we will show that all edge paradigms should
consider the advances in other paradigms.
</dc:description>
 <dc:description>Comment: In press, accepted manuscript: Future Generation Computer Systems</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-11-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00484</dc:identifier>
 <dc:identifier>doi:10.1016/j.future.2016.11.009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00487</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a Cognitive Routing Engine for Software Defined Networks</dc:title>
 <dc:creator>Francois, Frederic</dc:creator>
 <dc:creator>Gelenbe, Erol</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Most Software Defined Networks (SDN) traffic engineering applications use
excessive and frequent global monitoring in order to find the optimal
Quality-of-Service (QoS) paths for the current state of the network. In this
work, we present the motivations, architecture and initial evaluation of a SDN
application called Cognitive Routing Engine (CRE) which is able to find
near-optimal paths for a user-specified QoS while using a very small monitoring
overhead compared to global monitoring which is required to guarantee that
optimal paths are found. Smaller monitoring overheads bring the advantage of
smaller response time for the SDN controllers and switches. The initial
evaluation of CRE on a SDN representation of the GEANT academic network shows
that it is possible to find near-optimal paths with a small optimality gap of
1.65% while using 9.5 times less monitoring.
</dc:description>
 <dc:description>Comment: This is a non-final version of the paper submitted to IEEE ICC 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00487</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00489</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real Time Video Quality Representation Classification of Encrypted HTTP
  Adaptive Video Streaming - the Case of Safari</dc:title>
 <dc:creator>Dubin, Ran</dc:creator>
 <dc:creator>Dvir, Amit</dc:creator>
 <dc:creator>Pele, Ofir</dc:creator>
 <dc:creator>Hadar, Ofer</dc:creator>
 <dc:creator>Richman, Itay</dc:creator>
 <dc:creator>Trabelsi, Ofir</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The increasing popularity of HTTP adaptive video streaming services has
dramatically increased bandwidth requirements on operator networks, which
attempt to shape their traffic through Deep Packet Inspection (DPI). However,
Google and certain content providers have started to encrypt their video
services. As a result, operators often encounter difficulties in shaping their
encrypted video traffic via DPI. This highlights the need for new traffic
classification methods for encrypted HTTP adaptive video streaming to enable
smart traffic shaping. These new methods will have to effectively estimate the
quality representation layer and playout buffer. We present a new method and
show for the first time that video quality representation classification for
(YouTube) encrypted HTTP adaptive streaming is possible. We analyze the
performance of this classification method with Safari over HTTPS. Based on a
large number of offline and online traffic classification experiments, we
demonstrate that it can independently classify, in real time, every video
segment into one of the quality representation layers with 97.18% average
accuracy.
</dc:description>
 <dc:description>Comment: 9 pages</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00489</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00490</identifier>
 <datestamp>2017-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>I Know What You Saw Last Minute - Encrypted HTTP Adaptive Video
  Streaming Title Classification</dc:title>
 <dc:creator>Dubin, Ran</dc:creator>
 <dc:creator>Dvir, Amit</dc:creator>
 <dc:creator>Pele, Ofir</dc:creator>
 <dc:creator>Hadar, Ofer</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Desktops and laptops can be maliciously exploited to violate privacy. There
are two main types of attack scenarios: active and passive. In this paper, we
consider the passive scenario where the adversary does not interact actively
with the device, but he is able to eavesdrop on the network traffic of the
device from the network side. Most of the Internet traffic is encrypted and
thus passive attacks are challenging. Previous research has shown that
information can be extracted from encrypted multimedia streams. This includes
video title classification of non HTTP adaptive streams (non-HAS). This paper
presents an algorithm for encrypted HTTP adaptive video streaming title
classification. We show that an external attacker can identify the video title
from video HTTP adaptive streams (HAS) sites such as YouTube. To the best of
our knowledge, this is the first work that shows this. We provide a large data
set of 10000 YouTube video streams of 100 popular video titles (each title
downloaded 100 times) as examples for this task. The dataset was collected
under real-world network conditions. We present several machine algorithms for
the task and run a through set of experiments, which shows that our
classification accuracy is more than 95%. We also show that our algorithms are
able to classify video titles that are not in the training set as unknown and
some of the algorithms are also able to eliminate false prediction of video
titles and instead report unknown. Finally, we evaluate our algorithms
robustness to delays and packet losses at test time and show that a solution
that uses SVM is the most robust against these changes given enough training
data. We provide the dataset and the crawler for future research.
</dc:description>
 <dc:description>Comment: 9 pages. arXiv admin note: text overlap with arXiv:1602.00489</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-07-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00490</dc:identifier>
 <dc:identifier>IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 12,
  NO. 12, DECEMBER 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TIFS.2017.2730819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00503</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GRAD: On Graph Database Modeling</dc:title>
 <dc:creator>Ghrab, Amine</dc:creator>
 <dc:creator>Romero, Oscar</dc:creator>
 <dc:creator>Skhiri, Sabri</dc:creator>
 <dc:creator>Vaisman, Alejandro</dc:creator>
 <dc:creator>Zim&#xe1;nyi, Esteban</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Graph databases have emerged as the fundamental technology underpinning
trendy application domains where traditional databases are not well-equipped to
handle complex graph data. However, current graph databases support basic graph
structures and integrity constraints with no standard algebra. In this paper,
we introduce GRAD, a native and generic graph database model. GRAD goes beyond
traditional graph database models, which support simple graph structures and
constraints. Instead, GRAD presents a complete graph database model supporting
advanced graph structures, a set of well-defined constraints over these
structures and a powerful graph analysis-oriented algebra.
</dc:description>
 <dc:description>Comment: 28 pages, 13 figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00503</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00508</identifier>
 <datestamp>2017-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Bayesian view of Single-Qubit Clocks, and an Energy versus Accuracy
  tradeoff</dc:title>
 <dc:creator>Gopalkrishnan, Manoj</dc:creator>
 <dc:creator>Kandula, Varshith</dc:creator>
 <dc:creator>Sriram, Praveen</dc:creator>
 <dc:creator>Deshpande, Abhishek</dc:creator>
 <dc:creator>Muralidharan, Bhaskaran</dc:creator>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Condensed Matter - Mesoscale and Nanoscale Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Physics - Instrumentation and Detectors</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  We bring a Bayesian approach to the analysis of clocks. Using exponential
distributions as priors for clocks, we analyze how well one can keep time with
a single qubit freely precessing under a magnetic field. We find that, at least
with a single qubit, quantum mechanics does not allow exact timekeeping, in
contrast to classical mechanics which does. We find the design of the
single-qubit clock that leads to maximum accuracy. Further, we find an energy
versus accuracy tradeoff --- the energy cost is at least $k_BT$ times the
improvement in accuracy as measured by the entropy reduction in going from the
prior distribution to the posterior distribution. We propose a physical
realization of the single qubit clock using charge transport across a
capacitively-coupled quantum dot.
</dc:description>
 <dc:description>Comment: v2: 9 pages, 5 figures. v1:6 pages, figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00508</dc:identifier>
 <dc:identifier>Phys. Rev. A 96, 032339 (2017)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevA.96.032339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00515</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Marvin: Semantic annotation using multiple knowledge sources</dc:title>
 <dc:creator>Milosevic, Nikola</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>K.2</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  People are producing more written material then anytime in the history. The
increase is so high that professionals from the various fields are no more able
to cope with this amount of publications. Text mining tools can offer tools to
help them and one of the tools that can aid information retrieval and
information extraction is semantic text annotation. In this report we present
Marvin, a text annotator written in Java, which can be used as a command line
tool and as a Java library. Marvin is able to annotate text using multiple
sources, including WordNet, MetaMap, DBPedia and thesauri represented as SKOS.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures, keywords: Semantic annotation, text
  normalization, semantic web, linked data, information management, text
  mining, information extraction, data curation</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00515</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00542</identifier>
 <datestamp>2017-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cluster-Seeking James-Stein Estimators</dc:title>
 <dc:creator>Srinath, K. Pavan</dc:creator>
 <dc:creator>Venkataramanan, Ramji</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper considers the problem of estimating a high-dimensional vector of
parameters $\boldsymbol{\theta} \in \mathbb{R}^n$ from a noisy observation. The
noise vector is i.i.d. Gaussian with known variance. For a squared-error loss
function, the James-Stein (JS) estimator is known to dominate the simple
maximum-likelihood (ML) estimator when the dimension $n$ exceeds two. The
JS-estimator shrinks the observed vector towards the origin, and the risk
reduction over the ML-estimator is greatest for $\boldsymbol{\theta}$ that lie
close to the origin. JS-estimators can be generalized to shrink the data
towards any target subspace. Such estimators also dominate the ML-estimator,
but the risk reduction is significant only when $\boldsymbol{\theta}$ lies
close to the subspace. This leads to the question: in the absence of prior
information about $\boldsymbol{\theta}$, how do we design estimators that give
significant risk reduction over the ML-estimator for a wide range of
$\boldsymbol{\theta}$?
  In this paper, we propose shrinkage estimators that attempt to infer the
structure of $\boldsymbol{\theta}$ from the observed data in order to construct
a good attracting subspace. In particular, the components of the observed
vector are separated into clusters, and the elements in each cluster shrunk
towards a common attractor. The number of clusters and the attractor for each
cluster are determined from the observed vector. We provide concentration
results for the squared-error loss and convergence results for the risk of the
proposed estimators. The results show that the estimators give significant risk
reduction over the ML-estimator for a wide range of $\boldsymbol{\theta}$,
particularly for large $n$. Simulation results are provided to support the
theoretical claims.
</dc:description>
 <dc:description>Comment: 40 Pages, 7 figures. A shorter version of this paper appeared in the
  proceedings of ISIT 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-07-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00544</identifier>
 <datestamp>2016-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Observer-Based Feedback Stabilization of Linear Systems with
  Event-triggered Sampling and Dynamic Quantization</dc:title>
 <dc:creator>Tanwani, Aneel</dc:creator>
 <dc:creator>Prieur, Christophe</dc:creator>
 <dc:creator>Fiacchini, Mirko</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the problem of output feedback stabilization in linear systems
when the measured outputs and control inputs are subject to event-triggered
sampling and dynamic quantization. A new sampling algorithm is proposed for
outputs which does not lead to accumulation of sampling times and results in
asymptotic stabilization of the system. The approach for output sampling is
based on defining an event function that compares the difference between the
current output and the most recently transmitted output sample not only with
the current value of the output, but also takes into account a certain number
of previously transmitted output samples. This allows us to reconstruct the
state using an observer with sample-and-hold measurements. The estimated states
are used to generate a control input, which is subjected to a different
event-triggered sampling routine; hence the sampling times of inputs and
outputs are asynchronous. Using Lyapunov-based approach, we prove the
asymptotic stabilization of the closed-loop system and show that there exists a
minimum inter-sampling time for control inputs and for outputs. To show that
these sampling routines are robust with respect to transmission errors, only
the quantized (in space) values of outputs and inputs are transmitted to the
controller and the plant, respectively. A dynamic quantizer is adopted for this
purpose, and an algorithm is proposed to update the range and the centre of the
quantizer that results in an asymptotically stable closed-loop system.
</dc:description>
 <dc:date>2016-01-22</dc:date>
 <dc:date>2016-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00544</dc:identifier>
 <dc:identifier>doi:10.1016/j.sysconle.2016.05.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00545</identifier>
 <datestamp>2016-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Computation of the Nth Term of an Algebraic Series over a Finite
  Prime Field</dc:title>
 <dc:creator>Bostan, Alin</dc:creator>
 <dc:creator>Christol, Gilles</dc:creator>
 <dc:creator>Dumas, Philippe</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>11Y16, 68W30, 13F25, 11B85</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  We address the question of computing one selected term of an algebraic power
series. In characteristic zero, the best algorithm currently known for
computing the $N$th coefficient of an algebraic series uses differential
equations and has arithmetic complexity quasi-linear in $\sqrt{N}$. We show
that over a prime field of positive characteristic $p$, the complexity can be
lowered to $O(\log N)$. The mathematical basis for this dramatic improvement is
a classical theorem stating that a formal power series with coefficients in a
finite field is algebraic if and only if the sequence of its coefficients can
be generated by an automaton. We revisit and enhance two constructive proofs of
this result for finite prime fields. The first proof uses Mahler equations,
whose sizes appear to be prohibitively large. The second proof relies on
diagonals of rational functions; we turn it into an efficient algorithm, of
complexity linear in $\log N$ and quasi-linear in $p$.
</dc:description>
 <dc:description>Comment: Proceedings of ISSAC 2016, to appear</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-05-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00545</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00546</identifier>
 <datestamp>2018-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Functions Generated by the General Purpose Analog Computer</dc:title>
 <dc:creator>Bournez, Olivier</dc:creator>
 <dc:creator>Gra&#xe7;a, Daniel</dc:creator>
 <dc:creator>Pouly, Amaury</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  We consider the General Purpose Analog Computer (GPAC), introduced by Claude
Shannon in 1941 as a mathematical model of Differential Analysers, that is to
say as a model of continuous-time analog (mechanical, and later one electronic)
machines of that time. We extend the model properly to a model of computation
not restricted to univariate functions (i.e. functions $f: \mathbb{R} \to
\mathbb{R}$) but also to the multivariate case of (i.e. functions $f:
\mathbb{R}^n \to \mathbb{R}^m$), and establish some basic properties. In
particular, we prove that a very wide class of (continuous and discontinuous)
functions can be uniformly approximated over their full domain. Technically: we
generalize some known results about the GPAC to the multidimensional case: we
extend naturally the notion of \emph{generable} function, from the
unidimensional to the multidimensional case. We prove a few stability
properties of this class, mostly stability by arithmetic operations,
composition and ODE solving. We establish that generable functions are always
analytic. We prove that generable functions include some basic (useful)
generable functions, and that we can (uniformly) approximate a wide range of
functions this way. This extends some of the results from \cite{Sha41} to the
multidimensional case, and this also strengths the approximation result from
\cite{Sha41} over a compact domain to a uniform approximation result over
unbounded domains. We also discuss the issue of constants, and we prove that
involved constants can basically assumed to always be polynomial time
computable numbers.
</dc:description>
 <dc:date>2016-01-21</dc:date>
 <dc:date>2018-01-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00546</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00547</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Contraction-Based NMPC Formulation Without Stability-Related
  terminal Constraints</dc:title>
 <dc:creator>Alamir, Mazen</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Contraction-Based Nonlinear Model Predictive Control (NMPC) formulations are
attractive because of the generally short prediction horizons they require and
the needless use of terminal set computation that are commonly necessary to
guarantee stability. However, the inclusion of the contraction constraint in
the definition of the underlying optimization problem often leads to non
standard features such as the need for multi-step open-loop application of
control sequences or the use of multi-step memorization of the contraction
level that may induce unfeasibility in presence of unexpected disturbance. This
paper proposes a new formulation of contraction-based NMPC in which no
contraction constraint is explicitly involved. Convergence of the resulting
closed-loop behavior is proved under mild assumptions.
</dc:description>
 <dc:description>Comment: accepted in short version IFAC Nolcos 2016. submitted to Automatica
  as a technical communique</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00547</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00554</identifier>
 <datestamp>2017-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph-based Predictable Feature Analysis</dc:title>
 <dc:creator>Weghenkel, Bj&#xf6;rn</dc:creator>
 <dc:creator>Fischer, Asja</dc:creator>
 <dc:creator>Wiskott, Laurenz</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose graph-based predictable feature analysis (GPFA), a new method for
unsupervised learning of predictable features from high-dimensional time
series, where high predictability is understood very generically as low
variance in the distribution of the next data point given the previous ones. We
show how this measure of predictability can be understood in terms of graph
embedding as well as how it relates to the information-theoretic measure of
predictive information in special cases. We confirm the effectiveness of GPFA
on different datasets, comparing it to three existing algorithms with similar
objectives---namely slow feature analysis, forecastable component analysis, and
predictable feature analysis---to which GPFA shows very competitive results.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00554</dc:identifier>
 <dc:identifier>doi:10.1007/s10994-017-5632-x</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00557</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A SHM method for detecting damage with incomplete observations based on
  VARX modelling and Granger causality</dc:title>
 <dc:creator>Ugalde, Unai</dc:creator>
 <dc:creator>Anduaga, Javier</dc:creator>
 <dc:creator>Martinez, Fernando</dc:creator>
 <dc:creator>Iturrospe, Aitzol</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A SHM method is proposed that minimises the required number of sensors for
detecting damage. The damage detection method consists of two steps. In an
initial characterization step, substructuring approach is applied to the
healthy structure in order to isolate the substructures of interest and later,
each substructure is identified by a Vector Auto Regressive with eXogenous
inputs (VARX) model measuring all DOFs. Then, pairwise conditional Granger
causality analysis is carried out with data measured from substructural DOFs to
evaluate the information loss when measurements from all DOFs are not
available. This analysis allows selecting those accelerometers that can be
suppressed minimising the information loss. In the evaluation phase, vibration
data from the reduced set of sensors is compared to the estimated data obtained
from the healthy substructure's VARX model, and as a result a damage indicator
is computed. The proposed detection method is validated by finite element
simulations in a lattice structure model.
</dc:description>
 <dc:description>Comment: 9 pages, 3 figures, 2 tables</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00563</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Functional Dependencies Unleashed for Scalable Data Exchange</dc:title>
 <dc:creator>Bonifati, Angela</dc:creator>
 <dc:creator>Ileana, Ioana</dc:creator>
 <dc:creator>Linardi, Michele</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  We address the problem of efficiently evaluating target functional
dependencies (fds) in the Data Exchange (DE) process. Target fds naturally
occur in many DE scenarios, including the ones in Life Sciences in which
multiple source relations need to be structured under a constrained target
schema. However, despite their wide use, target fds' evaluation is still a
bottleneck in the state-of-the-art DE engines. Systems relying on an all-SQL
approach typically do not support target fds unless additional information is
provided. Alternatively, DE engines that do include these dependencies
typically pay the price of a significant drop in performance and scalability.
In this paper, we present a novel chase-based algorithm that can efficiently
handle arbitrary fds on the target. Our approach essentially relies on
exploiting the interactions between source-to-target (s-t) tuple-generating
dependencies (tgds) and target fds. This allows us to tame the size of the
intermediate chase results, by playing on a careful ordering of chase steps
interleaving fds and (chosen) tgds. As a direct consequence, we importantly
diminish the fd application scope, often a central cause of the dramatic
overhead induced by target fds. Moreover, reasoning on dependency interaction
further leads us to interesting parallelization opportunities, yielding
additional scalability gains. We provide a proof-of-concept implementation of
our chase-based algorithm and an experimental study aiming at gauging its
scalability with respect to a number of parameters, among which the size of
source instances and the number of dependencies of each tested scenario.
Finally, we empirically compare with the latest DE engines, and show that our
algorithm outperforms them.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00563</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00566</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Information-Centric Connectivity</dc:title>
 <dc:creator>Katsaros, Konstantinos V.</dc:creator>
 <dc:creator>Sourlas, Vasilis</dc:creator>
 <dc:creator>Psaras, Ioannis</dc:creator>
 <dc:creator>Rene, Sergi</dc:creator>
 <dc:creator>Pavlou, George</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Mobile devices are often presented with multiple connectivity options usually
making a selection either randomly or based on load/wireless conditions
metrics, as is the case of current offloading schemes. In this paper we claim
that link-layer connectivity can be associated with information-availability
and in this respect connectivity decisions should be information-aware. This
constitutes a next step for the Information-Centric Networking paradigm,
realizing the concept of Information-Centric Connectivity (ICCON). We elaborate
on different types of information availability and connectivity decisions in
the context of ICCON, present specific use cases and discuss emerging
opportunities, challenges and technical approaches. We illustrate the potential
benefits of ICCON through preliminary simulation and numerical results in an
example use case.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00566</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00569</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving PIE's performance over high-delay paths</dc:title>
 <dc:creator>Kuhn, Nicolas</dc:creator>
 <dc:creator>Ros, David</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Bufferbloat is excessive latency due to over- provisioned network buffers.
PIE and CoDel are two recently proposed Active Queue Management (AQM)
algorithms, designed to tackle bufferbloat by lowering the queuing delay
without degrading the bottleneck utilization. PIE uses a proportional integral
controller to maintain the average queuing delay at a desired level; however,
large Round Trip Times (RTT) result in large spikes in queuing delays, which
induce high dropping probability and low utilization. To deal with this
problem, we propose Maximum and Average queuing Delay with PIE (MADPIE).
Loosely based on the drop policy used by CoDel to keep queuing delay bounded,
MADPIE is a simple extension to PIE that adds deterministic packet drops at
controlled intervals. By means of simulations, we observe that our proposed
change does not affect PIE's performance when RTT &lt; 100 ms. The deterministic
drops are more dominant when the RTT increases, which results in lower maximum
queuing delays and better performance for VoIP traffic and small file
downloads, with no major impact on bulk transfers.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00569</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00572</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Social Networks Under Stress</dc:title>
 <dc:creator>Romero, Daniel M.</dc:creator>
 <dc:creator>Uzzi, Brian</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Social network research has begun to take advantage of fine-grained
communications regarding coordination, decision-making, and knowledge sharing.
These studies, however, have not generally analyzed how external events are
associated with a social network's structure and communicative properties.
Here, we study how external events are associated with a network's change in
structure and communications. Analyzing a complete dataset of millions of
instant messages among the decision-makers in a large hedge fund and their
network of outside contacts, we investigate the link between price shocks,
network structure, and change in the affect and cognition of decision-makers
embedded in the network. When price shocks occur the communication network
tends not to display structural changes associated with adaptiveness. Rather,
the network &quot;turtles up&quot;. It displays a propensity for higher clustering,
strong tie interaction, and an intensification of insider vs. outsider
communication. Further, we find changes in network structure predict shifts in
cognitive and affective processes, execution of new transactions, and local
optimality of transactions better than prices, revealing the important
predictive relationship between network structure and collective behavior
within a social network.
</dc:description>
 <dc:description>Comment: 12 pages, 8 figures, Proceedings of the 25th ACM International World
  Wide Web Conference (WWW) 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00572</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2883063l</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00575</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-object Classification via Crowdsourcing with a Reject Option</dc:title>
 <dc:creator>Li, Qunwei</dc:creator>
 <dc:creator>Vempaty, Aditya</dc:creator>
 <dc:creator>Varshney, Lav R.</dc:creator>
 <dc:creator>Varshney, Pramod K.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Consider designing an effective crowdsourcing system for an $M$-ary
classification task. Crowd workers complete simple binary microtasks whose
results are aggregated to give the final result. We consider the novel scenario
where workers have a reject option so they may skip microtasks when they are
unable or choose not to respond. For example, in mismatched speech
transcription, workers who do not know the language may not be able to respond
to microtasks focused on phonological dimensions outside their categorical
perception. We present an aggregation approach using a weighted majority voting
rule, where each worker's response is assigned an optimized weight to maximize
the crowd's classification performance. We evaluate system performance in both
exact and asymptotic forms. Further, we consider the setting where there may be
a set of greedy workers that complete microtasks even when they are unable to
perform it reliably. We consider an oblivious and an expurgation strategy to
deal with greedy workers, developing an algorithm to adaptively switch between
the two based on the estimated fraction of greedy workers in the anonymous
crowd. Simulation results show improved performance compared with conventional
majority voting.
</dc:description>
 <dc:description>Comment: two column, 15 pages, 8 figures, submitted to IEEE Trans. Signal
  Process</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00575</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2630038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00577</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Based Fast Image Saliency Detection Algorithm</dc:title>
 <dc:creator>Pan, Hengyue</dc:creator>
 <dc:creator>Jiang, Hui</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a fast deep learning method for object saliency
detection using convolutional neural networks. In our approach, we use a
gradient descent method to iteratively modify the input images based on the
pixel-wise gradients to reduce a pre-defined cost function, which is defined to
measure the class-specific objectness and clamp the class-irrelevant outputs to
maintain image background. The pixel-wise gradients can be efficiently computed
using the back-propagation algorithm. We further apply SLIC superpixels and LAB
color based low level saliency features to smooth and refine the gradients. Our
methods are quite computationally efficient, much faster than other deep
learning based saliency methods. Experimental results on two benchmark tasks,
namely Pascal VOC 2012 and MSRA10k, have shown that our proposed methods can
generate high-quality salience maps, at least comparable with many slow and
complicated deep learning methods. Comparing with the pure low-level methods,
our approach excels in handling many difficult images, which contain complex
background, highly-variable salient objects, multiple objects, and/or very
small salient objects.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1505.01173</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00585</identifier>
 <datestamp>2016-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Vertebra Segmentation through Joint Vertebra-Rib Atlases</dc:title>
 <dc:creator>Wang, Yinong</dc:creator>
 <dc:creator>Yao, Jianhua</dc:creator>
 <dc:creator>Roth, Holger R.</dc:creator>
 <dc:creator>Burns, Joseph E.</dc:creator>
 <dc:creator>Summers, Ronald M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Accurate spine segmentation allows for improved identification and
quantitative characterization of abnormalities of the vertebra, such as
vertebral fractures. However, in existing automated vertebra segmentation
methods on computed tomography (CT) images, leakage into nearby bones such as
ribs occurs due to the close proximity of these visibly intense structures in a
3D CT volume. To reduce this error, we propose the use of joint vertebra-rib
atlases to improve the segmentation of vertebrae via multi-atlas joint label
fusion. Segmentation was performed and evaluated on CTs containing 106 thoracic
and lumbar vertebrae from 10 pathological and traumatic spine patients on an
individual vertebra level basis. Vertebra atlases produced errors where the
segmentation leaked into the ribs. The use of joint vertebra-rib atlases
produced a statistically significant increase in the Dice coefficient from 92.5
$\pm$ 3.1% to 93.8 $\pm$ 2.1% for the left and right transverse processes and a
decrease in the mean and max surface distance from 0.75 $\pm$ 0.60mm and 8.63
$\pm$ 4.44mm to 0.30 $\pm$ 0.27mm and 3.65 $\pm$ 2.87mm, respectively.
</dc:description>
 <dc:description>Comment: Manuscript to be presented at SPIE Medical Imaging 2016, 27 February
  - 3 March, 2016, San Diego, California, USA</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00585</dc:identifier>
 <dc:identifier>doi:10.1117/12.2217118</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00586</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Gain Function for Architectural Decision-Making in Scientific
  Computing</dc:title>
 <dc:creator>Ferro, Mariza</dc:creator>
 <dc:creator>Mury, Antonio R.</dc:creator>
 <dc:creator>Schulze, Bruno</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Scientific Computing typically requires large computational needs which have
been addressed with High Performance Distributed Computing. It is essential to
efficiently deploy a number of complex scientific applications, which have
different characteristics, and so require distinct computational resources too.
However, in many research laboratories, this high performance architecture is
not dedicated. So, the architecture must be shared to execute a set of
scientific applications, with so many different execution times and relative
importance to research. Also, the high performance architectures have different
characteristics and costs. When a new infrastructure has to be acquired to meet
the needs of this scenario, the decision-making is hard and complex. In this
work, we present a Gain Function as a model of an utility function, with which
it is possible a decision-making with confidence. With the function is possible
to evaluate the best architectural option taking into account aspects of
applications and architectures, including the executions time, cost of
architecture, the relative importance of each application and also the relative
importance of performance and cost on the final evaluation. This paper presents
the Gain Function, examples, and a real case showing their applicabilities.
</dc:description>
 <dc:description>Comment: 25 pages, 1 figure, 7 tables</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00591</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NEXT: In-Network Nonconvex Optimization</dc:title>
 <dc:creator>Di Lorenzo, Paolo</dc:creator>
 <dc:creator>Scutari, Gesualdo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We study nonconvex distributed optimization in multi-agent networks with
time-varying (nonsymmetric) connectivity. We introduce the first algorithmic
framework for the distributed minimization of the sum of a smooth (possibly
nonconvex and nonseparable) function - the agents' sum-utility - plus a convex
(possibly nonsmooth and nonseparable) regularizer. The latter is usually
employed to enforce some structure in the solution, typically sparsity. The
proposed method hinges on successive convex approximation techniques while
leveraging dynamic consensus as a mechanism to distribute the computation among
the agents: each agent first solves (possibly inexactly) a local convex
approximation of the nonconvex original problem, and then performs local
averaging operations. Asymptotic convergence to (stationary) solutions of the
nonconvex problem is established. Our algorithmic framework is then customized
to a variety of convex and nonconvex problems in several fields, including
signal processing, communications, networking, and machine learning. Numerical
results show that the new method compares favorably to existing distributed
algorithms on both convex and nonconvex problems.
</dc:description>
 <dc:description>Comment: To appear on IEEE Transactions on Signal and Information Processing
  over Networks</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00591</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00596</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Decentralized Second-Order Method with Exact Linear Convergence Rate
  for Consensus Optimization</dc:title>
 <dc:creator>Mokhtari, Aryan</dc:creator>
 <dc:creator>Shi, Wei</dc:creator>
 <dc:creator>Ling, Qing</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  This paper considers decentralized consensus optimization problems where
different summands of a global objective function are available at nodes of a
network that can communicate with neighbors only. The proximal method of
multipliers is considered as a powerful tool that relies on proximal primal
descent and dual ascent updates on a suitably defined augmented Lagrangian. The
structure of the augmented Lagrangian makes this problem non-decomposable,
which precludes distributed implementations. This problem is regularly
addressed by the use of the alternating direction method of multipliers. The
exact second order method (ESOM) is introduced here as an alternative that
relies on: (i) The use of a separable quadratic approximation of the augmented
Lagrangian. (ii) A truncated Taylor's series to estimate the solution of the
first order condition imposed on the minimization of the quadratic
approximation of the augmented Lagrangian. The sequences of primal and dual
variables generated by ESOM are shown to converge linearly to their optimal
arguments when the aggregate cost function is strongly convex and its gradients
are Lipschitz continuous. Numerical results demonstrate advantages of ESOM
relative to decentralized alternatives in solving least squares and logistic
regression problems.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00596</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00602</identifier>
 <datestamp>2017-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Virtual Machine Warmup Blows Hot and Cold</dc:title>
 <dc:creator>Barrett, Edd</dc:creator>
 <dc:creator>Bolz-Tereick, Carl Friedrich</dc:creator>
 <dc:creator>Killick, Rebecca</dc:creator>
 <dc:creator>Mount, Sarah</dc:creator>
 <dc:creator>Tratt, Laurence</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3</dc:subject>
 <dc:description>  Virtual Machines (VMs) with Just-In-Time (JIT) compilers are traditionally
thought to execute programs in two phases: the initial warmup phase determines
which parts of a program would most benefit from dynamic compilation, before
JIT compiling those parts into machine code; subsequently the program is said
to be at a steady state of peak performance. Measurement methodologies almost
always discard data collected during the warmup phase such that reported
measurements focus entirely on peak performance. We introduce a fully automated
statistical approach, based on changepoint analysis, which allows us to
determine if a program has reached a steady state and, if so, whether that
represents peak performance or not. Using this, we show that even when run in
the most controlled of circumstances, small, deterministic, widely studied
microbenchmarks often fail to reach a steady state of peak performance on a
variety of common VMs. Repeating our experiment on 3 different machines, we
found that at most 43.5% of &lt;VM, benchmark&gt; pairs consistently reach a steady
state of peak performance.
</dc:description>
 <dc:description>Comment: 40 pages, 11 figures, 9 tables, 3 listings</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-10-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00602</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00615</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EMFS: Repurposing SMTP and IMAP for Data Storage and Synchronization</dc:title>
 <dc:creator>Woodruff, William</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Cloud storage has become a massive and lucrative business, with companies
like Apple, Microsoft, Google, and Dropbox providing hundreds of millions of
clients with synchronized and redundant storage. These services often command
price-to-storage ratios significantly higher than the market rate for physical
storage, as well as increase the surface area for data leakage. In place of
this consumer-unfriendly status quo, I propose using widely available, well
standardized email protocols like SMTP and IMAP in conjunction with free email
service providers to store, synchronize, and share files across discrete
systems.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00615</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00621</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On pattern matching with k mismatches and few don't cares</dc:title>
 <dc:creator>Nicolae, Marius</dc:creator>
 <dc:creator>Rajasekaran, Sanguthevar</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>68W32</dc:subject>
 <dc:subject>I.5.0</dc:subject>
 <dc:description>  We consider the problem of pattern matching with $k$ mismatches, where there
can be don't care or wild card characters in the pattern. Specifically, given a
pattern $P$ of length $m$ and a text $T$ of length $n$, we want to find all
occurrences of $P$ in $T$ that have no more than $k$ mismatches. The pattern
can have don't care characters, which match any character. Without don't cares,
the best known algorithm for pattern matching with $k$ mismatches has a runtime
of $O(n\sqrt{k \log k})$. With don't cares in the pattern, the best
deterministic algorithm has a runtime of $O(nk polylog m)$. Therefore, there is
an important gap between the versions with and without don't cares.
  In this paper we give an algorithm whose runtime increases with the number of
don't cares. We define an {\em island} to be a maximal length substring of $P$
that does not contain don't cares. Let $q$ be the number of islands in $P$. We
present an algorithm that runs in $O(n\sqrt{k\log m}+n\min\{\sqrt[3]{qk\log^2
m},\sqrt{q\log m}\})$ time. If the number of islands $q$ is $O(k)$ this runtime
becomes $O(n\sqrt{k\log m})$, which essentially matches the best known runtime
for pattern matching with $k$ mismatches without don't cares. If the number of
islands $q$ is $O(k^2)$, this algorithm is asymptotically faster than the
previous best algorithm for pattern matching with $k$ mismatches with don't
cares in the pattern.
</dc:description>
 <dc:description>Comment: Information Processing Letters, Available online 27 October 2016,
  ISSN 0020-0190</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00621</dc:identifier>
 <dc:identifier>doi:10.1016/j.ipl.2016.10.003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00639</identifier>
 <datestamp>2017-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Ski Rental for ON/OFF Scheduling of Energy Harvesting Base
  Stations</dc:title>
 <dc:creator>Lee, Gilsoo</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Mehbodniya, Abolfazl</dc:creator>
 <dc:creator>Adachi, Fumiyuki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The co-existence of small cell base stations (SBSs) with conventional
macrocell base station is a promising approach to boost the capacity and
coverage of cellular networks. However, densifying the network with a viral
deployment of SBSs can significantly increase energy consumption. To reduce the
reliance on unsustainable energy sources, one can adopt self-powered SBSs that
rely solely on energy harvesting. Due to the uncertainty of energy arrival and
the finite capacity of energy storage systems, self-powered SBSs must smartly
optimize their ON and OFF schedule. In this paper, the problem of ON/OFF
scheduling of self-powered SBSs is studied, in the presence of energy
harvesting uncertainty with the goal of minimizing the operational costs
consisted of energy consumption and transmission delay of a network. For the
original problem, we show an algorithm can solve the problem in the
illustrative case. To reduce the complexity of the original problem, an
approximation is proposed. To solve the approximated problem, a novel approach
based on the ski rental framework, a powerful online optimization tool, is
proposed. Using this approach, each SBS can effectively decide on its ON/OFF
schedule autonomously, without any prior information on future energy arrivals.
By using competitive analysis, a deterministic online algorithm (DOA) and a
randomized online algorithm (ROA) are developed. ROA is shown to achieve the
optimal competitive ratio in the approximation problem. Simulation results show
that, compared to a baseline approach, the ROA can yield performance gains
reaching up to 15.6% in terms of reduced total energy consumption of SBSs and
up to 20.6% in terms of per-SBS network delay reduction. The results shed light
on the fundamental aspects that impact the ON time of SBSs while demonstrating
that the proposed ROA can reduce up to 69.9% the total cost compared to a
baseline approach.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00639</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00646</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Autonomous Agent Behaviour Modelled in PRISM -- A Case Study</dc:title>
 <dc:creator>Hoffmann, Ruth</dc:creator>
 <dc:creator>Ireland, Murray</dc:creator>
 <dc:creator>Miller, Alice</dc:creator>
 <dc:creator>Norman, Gethin</dc:creator>
 <dc:creator>Veres, Sandor</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Formal verification of agents representing robot behaviour is a growing area
due to the demand that autonomous systems have to be proven safe. In this paper
we present an abstract definition of autonomy which can be used to model
autonomous scenarios and propose the use of small-scale simulation models
representing abstract actions to infer quantitative data. To demonstrate the
applicability of the approach we build and verify a model of an unmanned aerial
vehicle (UAV) in an exemplary autonomous scenario, utilising this approach.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00646</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00648</identifier>
 <datestamp>2016-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hybrid Beamforming for Massive MIMO Backhaul (Working Title)</dc:title>
 <dc:creator>Rajatheva, Namal</dc:creator>
 <dc:creator>Sousa, Elvino</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The uplink where both the transmitter and receiver can use a large antenna
array is considered. This is proposed as a method of antenna offloading and
connecting small cell access points (SCAP) in a Two-Tier cellular network. Due
to having a limited number of RF-chains, hybrid beamformers are designed where
phase-only processing is done at the RF-band, followed by digital processing at
the baseband. The proposed receiver is a row combiner that clusters
sufficiently correlated antenna elements, and its' performance is compared
against random projection via a Discrete Fourier Transform (DFT) matrix. The
analogue to the row combiner is a column spreader, which is dependent on the
transmit correlation, and repeats the transmitted signal over antenna elements
that are correlated. A key benefit of this approach is to reduce the number of
phase shifters used, while outperforming the DFT scheme. When only the
transmitter has correlation and is RF-chain limited, the baseband precoding
vectors are shown to be the eigenvectors of the effective transmit correlation
matrix. Depending on the channel correlation, this matrix can be approximated
to have a tridiagonal Toeplitz structure with the proposed column spreader
(CS). The resulting eigenvalues have a closed form solution which allows us to
characterize the sum rate of the system. Most interestingly, the associated
eigenvectors do not require knowledge of the effective transmit correlation
matrix to be calculated using an Eigenvalue Decomposition (EVD) method.
</dc:description>
 <dc:description>Comment: In process of submission for Globecomm, prior work done on thesis at
  https://tspace.library.utoronto.ca/handle/1807/70521. Revised March 27th</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00651</identifier>
 <datestamp>2016-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Computation of Minimal Interpolation Bases in Popov Form for
  Arbitrary Shifts</dc:title>
 <dc:creator>Jeannerod, Claude-Pierre</dc:creator>
 <dc:creator>Neiger, Vincent</dc:creator>
 <dc:creator>Schost, Eric</dc:creator>
 <dc:creator>Villard, Gilles</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We compute minimal bases of solutions for a general interpolation problem,
which encompasses Hermite-Pad\'e approximation and constrained multivariate
interpolation, and has applications in coding theory and security.
  This problem asks to find univariate polynomial relations between $m$ vectors
of size $\sigma$; these relations should have small degree with respect to an
input degree shift. For an arbitrary shift, we propose an algorithm for the
computation of an interpolation basis in shifted Popov normal form with a cost
of $\mathcal{O}\tilde{~}(m^{\omega-1} \sigma)$ field operations, where $\omega$
is the exponent of matrix multiplication and the notation
$\mathcal{O}\tilde{~}(\cdot)$ indicates that logarithmic terms are omitted.
  Earlier works, in the case of Hermite-Pad\'e approximation and in the general
interpolation case, compute non-normalized bases. Since for arbitrary shifts
such bases may have size $\Theta(m^2 \sigma)$, the cost bound
$\mathcal{O}\tilde{~}(m^{\omega-1} \sigma)$ was feasible only with restrictive
assumptions on the shift that ensure small output sizes. The question of
handling arbitrary shifts with the same complexity bound was left open.
  To obtain the target cost for any shift, we strengthen the properties of the
output bases, and of those obtained during the course of the algorithm: all the
bases are computed in shifted Popov form, whose size is always $\mathcal{O}(m
\sigma)$. Then, we design a divide-and-conquer scheme. We recursively reduce
the initial interpolation problem to sub-problems with more convenient shifts
by first computing information on the degrees of the intermediate bases.
</dc:description>
 <dc:description>Comment: 8 pages, sig-alternate class, 4 figures (problems and algorithms)</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00651</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00661</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and localization of change points in temporal networks with
  the aid of stochastic block models</dc:title>
 <dc:creator>De Ridder, Simon</dc:creator>
 <dc:creator>Vandermarliere, Benjamin</dc:creator>
 <dc:creator>Ryckebusch, Jan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  A framework based on generalized hierarchical random graphs (GHRGs) for the
detection of change points in the structure of temporal networks has recently
been developed by Peel and Clauset [1]. We build on this methodology and extend
it to also include the versatile stochastic block models (SBMs) as a parametric
family for reconstructing the empirical networks. We use five different
techniques for change point detection on prototypical temporal networks,
including empirical and synthetic ones. We find that none of the considered
methods can consistently outperform the others when it comes to detecting and
locating the expected change points in empirical temporal networks. With
respect to the precision and the recall of the results of the change points, we
find that the method based on a degree-corrected SBM has better recall
properties than other dedicated methods, especially for sparse networks and
smaller sliding time window widths.
</dc:description>
 <dc:description>Comment: This is an author-created, un-copyedited version of an article
  accepted for publication/published in Journal of Statistical Mechanics:
  Theory and Experiment. IOP Publishing Ltd is not responsible for any errors
  or omissions in this version of the manuscript or any version derived from
  it. The Version of Record is available online at
  http://dx.doi.org/10.1088/1742-5468/2016/11/113302</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00661</dc:identifier>
 <dc:identifier>J. Stat. Mech.(2016) 113302</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2016/11/113302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00678</identifier>
 <datestamp>2016-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Toolkit: Scalable and Flexible Execution of Ensembles of Tasks</dc:title>
 <dc:creator>Balasubramanian, Vivekanandan</dc:creator>
 <dc:creator>Treikalis, Antons</dc:creator>
 <dc:creator>Weidner, Ole</dc:creator>
 <dc:creator>Jha, Shantenu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  There are many science applications that require scalable task-level
parallelism and support for flexible execution and coupling of ensembles of
simulations. Most high-performance system software and middleware, however, are
designed to support the execution and optimization of single tasks. Motivated
by the missing capabilities of these computing systems and the increasing
importance of task-level parallelism, we introduce the Ensemble toolkit which
has the following application development features: (i) abstractions that
enable the expression of ensembles as primary entities, and (ii) support for
ensemble-based execution patterns that capture the majority of application
scenarios. Ensemble toolkit uses a scalable pilot-based runtime system that
decouples workload execution and resource management details from the
expression of the application, and enables the efficient and dynamic execution
of ensembles on heterogeneous computing resources. We investigate three
execution patterns and characterize the scalability and overhead of Ensemble
toolkit for these patterns. We investigate scaling properties for up to O(1000)
concurrent ensembles and O(1000) cores and find linear weak and strong scaling
behaviour.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00678</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00700</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerically validating the completeness of the real solution set of a
  system of polynomial equations</dc:title>
 <dc:creator>Brake, Daniel A.</dc:creator>
 <dc:creator>Hauenstein, Jonathan D.</dc:creator>
 <dc:creator>Liddell, Alan C.</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Computing the real solutions to a system of polynomial equations is a
challenging problem, particularly verifying that all solutions have been
computed. We describe an approach that combines numerical algebraic geometry
and sums of squares programming to test whether a given set is &quot;complete&quot; with
respect to the real solution set. Specifically, we test whether the Zariski
closure of that given set is indeed equal to the solution set of the real
radical of the ideal generated by the given polynomials. Examples with finitely
and infinitely many real solutions are provided, along with an example having
polynomial inequalities.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00700</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00709</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum perceptron over a field and neural network architecture
  selection in a quantum computer</dc:title>
 <dc:creator>da Silva, Adenilton J.</dc:creator>
 <dc:creator>Ludermir, Teresa B.</dc:creator>
 <dc:creator>de Oliveira, Wilson R.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In this work, we propose a quantum neural network named quantum perceptron
over a field (QPF). Quantum computers are not yet a reality and the models and
algorithms proposed in this work cannot be simulated in actual (or classical)
computers. QPF is a direct generalization of a classical perceptron and solves
some drawbacks found in previous models of quantum perceptrons. We also present
a learning algorithm named Superposition based Architecture Learning algorithm
(SAL) that optimizes the neural network weights and architectures. SAL searches
for the best architecture in a finite set of neural network architectures with
linear time over the number of patterns in the training set. SAL is the first
learning algorithm to determine neural network architectures in polynomial
time. This speedup is obtained by the use of quantum parallelism and a
non-linear quantum operator.
</dc:description>
 <dc:date>2016-01-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00709</dc:identifier>
 <dc:identifier>Neural Networks, Volume 76, April 2016, Pages 55-64</dc:identifier>
 <dc:identifier>doi:10.1016/j.neunet.2016.01.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00710</identifier>
 <datestamp>2016-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Computation of Shifted Popov Forms of Polynomial Matrices via
  Systems of Modular Polynomial Equations</dc:title>
 <dc:creator>Neiger, Vincent</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We give a Las Vegas algorithm which computes the shifted Popov form of an $m
\times m$ nonsingular polynomial matrix of degree $d$ in expected
$\widetilde{\mathcal{O}}(m^\omega d)$ field operations, where $\omega$ is the
exponent of matrix multiplication and $\widetilde{\mathcal{O}}(\cdot)$
indicates that logarithmic factors are omitted. This is the first algorithm in
$\widetilde{\mathcal{O}}(m^\omega d)$ for shifted row reduction with arbitrary
shifts.
  Using partial linearization, we reduce the problem to the case $d \le \lceil
\sigma/m \rceil$ where $\sigma$ is the generic determinant bound, with $\sigma
/ m$ bounded from above by both the average row degree and the average column
degree of the matrix. The cost above becomes $\widetilde{\mathcal{O}}(m^\omega
\lceil \sigma/m \rceil)$, improving upon the cost of the fastest previously
known algorithm for row reduction, which is deterministic.
  Our algorithm first builds a system of modular equations whose solution set
is the row space of the input matrix, and then finds the basis in shifted Popov
form of this set. We give a deterministic algorithm for this second step
supporting arbitrary moduli in $\widetilde{\mathcal{O}}(m^{\omega-1} \sigma)$
field operations, where $m$ is the number of unknowns and $\sigma$ is the sum
of the degrees of the moduli. This extends previous results with the same cost
bound in the specific cases of order basis computation and M-Pad\'e
approximation, in which the moduli are products of known linear factors.
</dc:description>
 <dc:description>Comment: 8 pages, sig-alternate class, 5 figures (problems and algorithms)</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00710</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00715</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithm-Induced Prior for Image Restoration</dc:title>
 <dc:creator>Chan, Stanley H.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper studies a type of image priors that are constructed implicitly
through the alternating direction method of multiplier (ADMM) algorithm, called
the algorithm-induced prior. Different from classical image priors which are
defined before running the reconstruction algorithm, algorithm-induced priors
are defined by the denoising procedure used to replace one of the two modules
in the ADMM algorithm. Since such prior is not explicitly defined, analyzing
the performance has been difficult in the past.
  Focusing on the class of symmetric smoothing filters, this paper presents an
explicit expression of the prior induced by the ADMM algorithm. The new prior
is reminiscent to the conventional graph Laplacian but with stronger
reconstruction performance. It can also be shown that the overall
reconstruction has an efficient closed-form implementation if the associated
symmetric smoothing filter is low rank. The results are validated with
experiments on image inpainting.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00721</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Concentration of measure without independence: a unified approach via
  the martingale method</dc:title>
 <dc:creator>Kontorovich, Aryeh</dc:creator>
 <dc:creator>Raginsky, Maxim</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The concentration of measure phenomenon may be summarized as follows: a
function of many weakly dependent random variables that is not too sensitive to
any of its individual arguments will tend to take values very close to its
expectation. This phenomenon is most completely understood when the arguments
are mutually independent random variables, and there exist several powerful
complementary methods for proving concentration inequalities, such as the
martingale method, the entropy method, and the method of transportation
inequalities. The setting of dependent arguments is much less well understood.
This chapter focuses on the martingale method for deriving concentration
inequalities without independence assumptions. In particular, we use the
machinery of so-called Wasserstein matrices to show that the Azuma-Hoeffding
concentration inequality for martingales with almost surely bounded
differences, when applied in a sufficiently abstract setting, is powerful
enough to recover and sharpen several known concentration results for
nonproduct measures. Wasserstein matrices provide a natural formalism for
capturing the interplay between the metric and the probabilistic structures,
which is fundamental to the concentration phenomenon.
</dc:description>
 <dc:description>Comment: Final version to appear in IMA Volume &quot;Concentration, Convexity, and
  Discrete Structures&quot; (Springer)</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00721</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00722</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Efficient Dynamic Resizing of Large DRAM Caches via A Hardware
  Consistent Hashing Mechanism</dc:title>
 <dc:creator>Chang, Kevin K.</dc:creator>
 <dc:creator>Loh, Gabriel H.</dc:creator>
 <dc:creator>Thottethodi, Mithuna</dc:creator>
 <dc:creator>Eckert, Yasuko</dc:creator>
 <dc:creator>O'Connor, Mike</dc:creator>
 <dc:creator>Manne, Srilatha</dc:creator>
 <dc:creator>Hsu, Lisa</dc:creator>
 <dc:creator>Subramanian, Lavanya</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Die-stacked DRAM has been proposed for use as a large, high-bandwidth,
last-level cache with hundreds or thousands of megabytes of capacity. Not all
workloads (or phases) can productively utilize this much cache space, however.
Unfortunately, the unused (or under-used) cache continues to consume power due
to leakage in the peripheral circuitry and periodic DRAM refresh. Dynamically
adjusting the available DRAM cache capacity could largely eliminate this energy
overhead. However, the current proposed DRAM cache organization introduces new
challenges for dynamic cache resizing. The organization differs from a
conventional SRAM cache organization because it places entire cache sets and
their tags within a single bank to reduce on-chip area and power overhead.
Hence, resizing a DRAM cache requires remapping sets from the powered-down
banks to active banks.
  In this paper, we propose CRUNCH (Cache Resizing Using Native Consistent
Hashing), a hardware data remapping scheme inspired by consistent hashing, an
algorithm originally proposed to uniformly and dynamically distribute Internet
traffic across a changing population of web servers. CRUNCH provides a
load-balanced remapping of data from the powered-down banks alone to the active
banks, without requiring sets from all banks to be remapped, unlike naive
schemes to achieve load balancing. CRUNCH remaps only sets from the
powered-down banks, so it achieves this load balancing with low bank
power-up/down transition latencies. CRUNCH's combination of good load balancing
and low transition latencies provides a substrate to enable efficient DRAM
cache resizing.
</dc:description>
 <dc:description>Comment: 13 pages</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00729</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Heterogeneous-Reliability Memory: Exploiting Application-Level Memory
  Error Tolerance</dc:title>
 <dc:creator>Luo, Yixin</dc:creator>
 <dc:creator>Govindan, Sriram</dc:creator>
 <dc:creator>Sharma, Bikash</dc:creator>
 <dc:creator>Santaniello, Mark</dc:creator>
 <dc:creator>Meza, Justin</dc:creator>
 <dc:creator>Kansal, Aman</dc:creator>
 <dc:creator>Liu, Jie</dc:creator>
 <dc:creator>Khessib, Badriddine</dc:creator>
 <dc:creator>Vaid, Kushagra</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Memory devices represent a key component of datacenter total cost of
ownership (TCO), and techniques used to reduce errors that occur on these
devices increase this cost. Existing approaches to providing reliability for
memory devices pessimistically treat all data as equally vulnerable to memory
errors. Our key insight is that there exists a diverse spectrum of tolerance to
memory errors in new data-intensive applications, and that traditional
one-size-fits-all memory reliability techniques are inefficient in terms of
cost. For example, we found that while traditional error protection increases
memory system cost by 12.5%, some applications can achieve 99.00% availability
on a single server with a large number of memory errors without any error
protection. This presents an opportunity to greatly reduce server hardware cost
by provisioning the right amount of memory reliability for different
applications.
  Toward this end, in this paper, we make three main contributions to enable
highly-reliable servers at low datacenter cost. First, we develop a new
methodology to quantify the tolerance of applications to memory errors. Second,
using our methodology, we perform a case study of three new data-intensive
workloads (an interactive web search application, an in-memory key-value store,
and a graph mining framework) to identify new insights into the nature of
application memory error vulnerability. Third, based on our insights, we
propose several new hardware/software heterogeneous-reliability memory system
designs to lower datacenter cost while achieving high reliability and discuss
their trade-offs. We show that our new techniques can reduce server hardware
cost by 4.7% while achieving 99.90% single server availability.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures, summary report for DSN 2014 paper:
  &quot;Characterizing Application Memory Error Vulnerability to Optimize Datacenter
  Cost via Heterogeneous-Reliability Memory&quot;</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00729</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00733</identifier>
 <datestamp>2016-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Well-quasi-ordering H-contraction-free graphs</dc:title>
 <dc:creator>Kami&#x144;ski, Marcin</dc:creator>
 <dc:creator>Raymond, Jean-Florent</dc:creator>
 <dc:creator>Trunck, Th&#xe9;ophile</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>06A07</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  A well-quasi-order is an order which contains no infinite decreasing sequence
and no infinite collection of incomparable elements. In this paper, we consider
graph classes defined by excluding one graph as contraction. More precisely, we
give a complete characterization of graphs H such that the class of
H-contraction-free graphs is well-quasi-ordered by the contraction relation.
This result is the contraction analogue on the previous dichotomy theorems of
Damsaschke [Induced subgraphs and well-quasi-ordering, Journal of Graph Theory,
14(4):427-435, 1990] on the induced subgraph relation, Ding [Subgraphs and
well-quasi-ordering, Journal of Graph Theory, 16(5):489-502, 1992] on the
subgraph relation, and B{\l}asiok et al. [Induced minors and
well-quasi-ordering, ArXiv e-prints, 1510.07135, 2015] on the induced minor
relation.
</dc:description>
 <dc:description>Comment: 18 pages</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-12-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00733</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00734</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Data Triage: Linear Decoding Works for Compressive MRI</dc:title>
 <dc:creator>Li, Yen-Huan</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The standard approach to compressive sampling considers recovering an unknown
deterministic signal with certain known structure, and designing the
sub-sampling pattern and recovery algorithm based on the known structure. This
approach requires looking for a good representation that reveals the signal
structure, and solving a non-smooth convex minimization problem (e.g., basis
pursuit). In this paper, another approach is considered: We learn a good
sub-sampling pattern based on available training signals, without knowing the
signal structure in advance, and reconstruct an accordingly sub-sampled signal
by computationally much cheaper linear reconstruction. We provide a theoretical
guarantee on the recovery error, and show via experiments on real-world MRI
data the effectiveness of the proposed compressive MRI scheme.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00734</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00739</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards a topological fingerprint of music</dc:title>
 <dc:creator>Bergomi, Mattia G.</dc:creator>
 <dc:creator>Barat&#xe9;, Adriano</dc:creator>
 <dc:creator>Di Fabio, Barbara</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:description>  Can music be represented as a meaningful geometric and topological object? In
this paper, we propose a strategy to describe some music features as a
polyhedral surface obtained by a simplicial interpretation of the
\textit{Tonnetz}. The \textit{Tonnetz} is a graph largely used in computational
musicology to describe the harmonic relationships of notes in equal tuning. In
particular, we use persistent homology in order to describe the
\textit{persistent} properties of music encoded in the aforementioned model.
Both the relevance and the characteristics of this approach are discussed by
analyzing some paradigmatic compositional styles. Eventually, the task of
automatic music style classification is addressed by computing the hierarchical
clustering of the topological fingerprints associated with some collections of
compositions.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00749</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combining ConvNets with Hand-Crafted Features for Action Recognition
  Based on an HMM-SVM Classifier</dc:title>
 <dc:creator>Wang, Pichao</dc:creator>
 <dc:creator>Li, Zhaoyang</dc:creator>
 <dc:creator>Hou, Yonghong</dc:creator>
 <dc:creator>Li, Wanqing</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper proposes a new framework for RGB-D-based action recognition that
takes advantages of hand-designed features from skeleton data and deeply
learned features from depth maps, and exploits effectively both the local and
global temporal information. Specifically, depth and skeleton data are firstly
augmented for deep learning and making the recognition insensitive to view
variance. Secondly, depth sequences are segmented using the hand-crafted
features based on skeleton joints motion histogram to exploit the local
temporal information. All training se gments are clustered using an Infinite
Gaussian Mixture Model (IGMM) through Bayesian estimation and labelled for
training Convolutional Neural Networks (ConvNets) on the depth maps. Thus, a
depth sequence can be reliably encoded into a sequence of segment labels.
Finally, the sequence of labels is fed into a joint Hidden Markov Model and
Support Vector Machine (HMM-SVM) classifier to explore the global temporal
information for final recognition.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00749</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00753</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects</dc:title>
 <dc:creator>Bagherinezhad, Hessam</dc:creator>
 <dc:creator>Hajishirzi, Hannaneh</dc:creator>
 <dc:creator>Choi, Yejin</dc:creator>
 <dc:creator>Farhadi, Ali</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Human vision greatly benefits from the information about sizes of objects.
The role of size in several visual reasoning tasks has been thoroughly explored
in human perception and cognition. However, the impact of the information about
sizes of objects is yet to be determined in AI. We postulate that this is
mainly attributed to the lack of a comprehensive repository of size
information. In this paper, we introduce a method to automatically infer object
sizes, leveraging visual and textual information from web. By maximizing the
joint likelihood of textual and visual observations, our method learns reliable
relative size estimates, with no explicit human supervision. We introduce the
relative size dataset and show that our method outperforms competitive textual
and visual baselines in reasoning about size comparisons.
</dc:description>
 <dc:description>Comment: To appear in AAAI 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00753</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00761</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimality and Rate-Compatibility for Erasure-Coded Packet Transmissions
  when Fading Channel Diversity Increases with Packet Length</dc:title>
 <dc:creator>Ranganathan, Sudarsan V. S.</dc:creator>
 <dc:creator>Mu, Tong</dc:creator>
 <dc:creator>Wesel, Richard D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A message composed of packets is transmitted using erasure and channel coding
over a fading channel with no feedback. For this scenario, the paper explores
the trade-off between the redundancies allocated to the packet-level erasure
code and the channel code, along with an objective of a low probability of
failure to recover the message.
  To this end, we consider a fading model that we term proportional-diversity
block fading (PD block fading). For a fixed overall code rate and transmit
power, we formulate an optimization problem to numerically find the optimal
channel-coding rate (and thus the optimal erasure-coding rate) that minimizes
the probability of failure for various approximations of the problem.
  Furthermore, an interpretation of the results from an incremental redundancy
point of view shows how rate-compatibility affects the possible trajectories of
the failure probability as a function of the overall code rate. Our numerical
results suggest that an optimal, rateless, hybrid coding scheme for a
single-user wireless system over the PD block-fading channel should have the
rate of the erasure code approach one.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00761</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00763</identifier>
 <datestamp>2017-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Online and Realtime Tracking</dc:title>
 <dc:creator>Bewley, Alex</dc:creator>
 <dc:creator>Ge, Zongyuan</dc:creator>
 <dc:creator>Ott, Lionel</dc:creator>
 <dc:creator>Ramos, Fabio</dc:creator>
 <dc:creator>Upcroft, Ben</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper explores a pragmatic approach to multiple object tracking where
the main focus is to associate objects efficiently for online and realtime
applications. To this end, detection quality is identified as a key factor
influencing tracking performance, where changing the detector can improve
tracking by up to 18.9%. Despite only using a rudimentary combination of
familiar techniques such as the Kalman Filter and Hungarian algorithm for the
tracking components, this approach achieves an accuracy comparable to
state-of-the-art online trackers. Furthermore, due to the simplicity of our
tracking method, the tracker updates at a rate of 260 Hz which is over 20x
faster than other state-of-the-art trackers.
</dc:description>
 <dc:description>Comment: Presented at ICIP 2016, code is available at
  https://github.com/abewley/sort</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2017-07-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00763</dc:identifier>
 <dc:identifier>doi:10.1109/ICIP.2016.7533003</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00766</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Access Mode Selection in Fog Computing Based Radio Access Networks</dc:title>
 <dc:creator>Yan, Shi</dc:creator>
 <dc:creator>Peng, Mugen</dc:creator>
 <dc:creator>Wang, Wenbo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Fog computing based radio access network is a promising paradigm for the
fifth generation wireless communication system to provide high spectral and
energy efficiency. With the help of the new designed fog computing based access
points (F-APs), the user-centric objectives can be achieved through the
adaptive technique and will relieve the load of fronthaul and alleviate the
burden of base band unit pool. In this paper, we derive the coverage
probability and ergodic rate for both F-AP users and device-to-device users by
taking into account the different nodes locations, cache sizes as well as user
access modes. Particularly, the stochastic geometry tool is used to derive
expressions for above performance metrics. Simulation results validate the
accuracy of our analysis and we obtain interesting trade-offs that depend on
the effect of the cache size, user node density, and the quality of service
constrains on the different performance metrics.
</dc:description>
 <dc:description>Comment: 6 pages, 3 figures, ICC 2016</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00766</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00767</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distance-Sensitive Planar Point Location</dc:title>
 <dc:creator>Aronov, Boris</dc:creator>
 <dc:creator>de Berg, Mark</dc:creator>
 <dc:creator>Eppstein, David</dc:creator>
 <dc:creator>Roeloffzen, Marcel</dc:creator>
 <dc:creator>Speckmann, Bettina</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  Let $\mathcal{S}$ be a connected planar polygonal subdivision with $n$ edges
that we want to preprocess for point-location queries, and where we are given
the probability $\gamma_i$ that the query point lies in a polygon $P_i$ of
$\mathcal{S}$. We show how to preprocess $\mathcal{S}$ such that the query time
for a point~$p\in P_i$ depends on~$\gamma_i$ and, in addition, on the distance
from $p$ to the boundary of~$P_i$---the further away from the boundary, the
faster the query. More precisely, we show that a point-location query can be
answered in time $O\left(\min \left(\log n, 1 + \log
\frac{\mathrm{area}(P_i)}{\gamma_i \Delta_{p}^2}\right)\right)$, where
$\Delta_{p}$ is the shortest Euclidean distance of the query point~$p$ to the
boundary of $P_i$. Our structure uses $O(n)$ space and $O(n \log n)$
preprocessing time. It is based on a decomposition of the regions of
$\mathcal{S}$ into convex quadrilaterals and triangles with the following
property: for any point $p\in P_i$, the quadrilateral or triangle
containing~$p$ has area $\Omega(\Delta_{p}^2)$. For the special case where
$\mathcal{S}$ is a subdivision of the unit square and
$\gamma_i=\mathrm{area}(P_i)$, we present a simpler solution that achieves a
query time of $O\left(\min \left(\log n, \log
\frac{1}{\Delta_{p}^2}\right)\right)$. The latter solution can be extended to
convex subdivisions in three dimensions.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00767</dc:identifier>
 <dc:identifier>Comp. Geom. Theory &amp; Applications 54: 17-31, 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.comgeo.2016.02.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00773</identifier>
 <datestamp>2016-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Querying Evolving Graphs with Portal</dc:title>
 <dc:creator>Moffitt, Vera Zaychik</dc:creator>
 <dc:creator>Stoyanovich, Julia</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Graphs are used to represent a plethora of phenomena, from the Web and social
networks, to biological pathways, to semantic knowledge bases. Arguably the
most interesting and important questions one can ask about graphs have to do
with their evolution. Which Web pages are showing an increasing popularity
trend? How does influence propagate in social networks? How does knowledge
evolve?
  This paper proposes a logical model of an evolving graph called a TGraph,
which captures evolution of graph topology and of its vertex and edge
attributes. We present a compositional temporal graph algebra TGA, and show a
reduction of TGA to temporal relational algebra with graph-specific primitives.
We formally study the properties of TGA, and also show that it is sufficient to
concisely express a wide range of common use cases. We describe an
implementation of our model and algebra in Portal, built on top of Apache Spark
/ GraphX. We conduct extensive experiments on real datasets, and show that
Portal scales.
</dc:description>
 <dc:description>Comment: 12 pages plus appendix. Submitted to SIGMOD 2017</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:date>2016-12-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00773</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00786</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Fourth Workshop on Synthesis</dc:title>
 <dc:creator>&#x10c;ern&#xfd;, Pavol</dc:creator>
 <dc:creator>Kuncak, Viktor</dc:creator>
 <dc:creator>Parthasarathy, Madhusudan</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The SYNT workshop aims to bring together researchers interested in the broad
area of synthesis of computing systems. The goal is to foster the development
of frontier techniques in automating the development of computing system.
Contributions of interest include algorithms, complexity and decidability
analysis, as well as reproducible heuristics, implemented tools, and
experimental evaluation. Application domains include software, hardware,
embedded, and cyberphysical systems. Computation models include functional,
reactive, hybrid and timed systems. Identifying, formalizing, and evaluating
synthesis in particular application domains is encouraged.
  The fourth iteration of the workshop took place in San Francisco, CA, USA. It
was co-located with the 27th International Conference on Computer Aided
Verification. The workshop included five contributed talks and two invited
talks. In addition, it featured a special session about the Syntax-Guided
Synthesis Competition (SyGuS) and the SyntComp Synthesis competition.
</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00786</dc:identifier>
 <dc:identifier>EPTCS 202, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00795</identifier>
 <datestamp>2016-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gender, Productivity, and Prestige in Computer Science Faculty Hiring
  Networks</dc:title>
 <dc:creator>Way, Samuel F.</dc:creator>
 <dc:creator>Larremore, Daniel B.</dc:creator>
 <dc:creator>Clauset, Aaron</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Women are dramatically underrepresented in computer science at all levels in
academia and account for just 15% of tenure-track faculty. Understanding the
causes of this gender imbalance would inform both policies intended to rectify
it and employment decisions by departments and individuals. Progress in this
direction, however, is complicated by the complexity and decentralized nature
of faculty hiring and the non-independence of hires. Using comprehensive data
on both hiring outcomes and scholarly productivity for 2659 tenure-track
faculty across 205 Ph.D.-granting departments in North America, we investigate
the multi-dimensional nature of gender inequality in computer science faculty
hiring through a network model of the hiring process. Overall, we find that
hiring outcomes are most directly affected by (i) the relative prestige between
hiring and placing institutions and (ii) the scholarly productivity of the
candidates. After including these, and other features, the addition of gender
did not significantly reduce modeling error. However, gender differences do
exist, e.g., in scholarly productivity, postdoctoral training rates, and in
career movements up the rankings of universities, suggesting that the effects
of gender are indirectly incorporated into hiring decisions through gender's
covariates. Furthermore, we find evidence that more highly ranked departments
recruit female faculty at higher than expected rates, which appears to inhibit
similar efforts by lower ranked departments. These findings illustrate the
subtle nature of gender inequality in faculty hiring networks and provide new
insights to the underrepresentation of women in computer science.
</dc:description>
 <dc:description>Comment: 11 pages, 7 figures, 5 tables</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00795</dc:identifier>
 <dc:identifier>Proc. 2016 World Wide Web Conference (WWW), 1169-1179 (2016)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00798</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Unified Framework for Information Consumption Based on Markov Chains</dc:title>
 <dc:creator>Hui, David Shui Wing</dc:creator>
 <dc:creator>Chen, Yi-Chao</dc:creator>
 <dc:creator>Zhang, Gong</dc:creator>
 <dc:creator>Wu, Weijie</dc:creator>
 <dc:creator>Chen, Guanrong</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:creator>Li, Yingtao</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  This paper establishes a Markov chain model as a unified framework for
understanding information consumption processes in complex networks, with clear
implications to the Internet and big-data technologies. In particular, the
proposed model is the first one to address the formation mechanism of the
&quot;trichotomy&quot; in observed probability density functions from empirical data of
various social and technical networks. Both simulation and experimental results
demonstrate a good match of the proposed model with real datasets, showing its
superiority over the classical power-law models.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00798</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00801</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Novel Human Computer Interaction Platform based College Mathematical
  Education Methodology</dc:title>
 <dc:creator>Li, Zhiyan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  This article proposes the analysis on novel human computer interaction (HCI)
platform based college mathematical education methodology. Above for the
application of virtual reality technology in teaching the problems in the
study, only through the organization focus on the professional and technical
personnel, and constantly improve researchers in development process of
professional knowledge, close to the actual needs of the teaching can we
achieve the satisfactory result. To obtain better education output, we combine
the Kinect to form the HCI based teaching environment. We firstly review the
latest HCI technique and principles of college math courses, then we introduce
basic components of the Kinect including the gesture segmentation, systematic
implementation and the primary characteristics of the platform. As the further
step, we implement the system with the re-write of script code to build up the
personalized HCI assisted education scenario. The verification and simulation
proves the feasibility of our method.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00801</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00802</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectrum Sharing Between A Surveillance Radar and Secondary Wi-Fi
  Networks</dc:title>
 <dc:creator>Hessar, Farzad</dc:creator>
 <dc:creator>Roy, Sumit</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Co-existence between unlicensed networks that share spectrum
spatio-temporally with terrestrial (e.g. Air Traffic Control) and shipborne
radars in 3-GHz band is attracting significant interest. Similar to every
primary-secondary coexistence scenario, interference from unlicensed devices to
a primary receiver must be within acceptable bounds. In this work, we formulate
the spectrum sharing problem between a pulsed, search radar (primary) and
802.11 WLAN as the secondary. We compute the protection region for such a
search radar for a) a single secondary user (initially) as well as b) a random
spatial distribution of multiple secondary users. Furthermore, we also analyze
the interference to the WiFi devices from the radar's transmissions to estimate
the impact on achievable WLAN throughput as a function of distance to the
primary radar.
</dc:description>
 <dc:description>Comment: IEEE Transactions on Aerospace and Electronic Systems, 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00802</dc:identifier>
 <dc:identifier>doi:10.1109/TAES.2016.150114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00804</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research on Information Security Enhancement Approaches and the
  Applications on HCI Systems</dc:title>
 <dc:creator>Yang, Yang</dc:creator>
 <dc:creator>Li, Zhiyan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  With rapid development of computer techniques, the human computer interaction
scenarios are becoming more and more frequent. The development history of the
human-computer interaction is from a person to adapt to the computer to the
computer and continually adapt to the rapid development. Facing the process of
human-computer interaction, information system daily operation to produce huge
amounts of data, how to ensure human-computer interaction interface clear,
generated data safe and reliable, has become a problem to be solved in the
world of information. To deal with the challenging, we propose the information
security enhancement approaches and the core applications on HCI systems.
Through reviewing the other state-of-the-art methods, we propose the data
encryption system to deal with the issues that uses mixed encryption system to
make full use of the symmetric cipher algorithm encryption speed and encryption
intensity is high while the encryption of large amounts of data efficiently.
Our method could enhance the general safety of the HCI system, the experimental
result verities the feasibility and general robustness of our approach.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00805</identifier>
 <datestamp>2016-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling social identification and helping in evacuation simulation</dc:title>
 <dc:creator>von Sivers, I.</dc:creator>
 <dc:creator>Templeton, A.</dc:creator>
 <dc:creator>K&#xfc;nzner, F.</dc:creator>
 <dc:creator>K&#xf6;ster, G.</dc:creator>
 <dc:creator>Drury, J.</dc:creator>
 <dc:creator>Philippides, A.</dc:creator>
 <dc:creator>Neckel, T.</dc:creator>
 <dc:creator>Bungartz, H. -J.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:description>  Social scientists have criticised computer models of pedestrian streams for
their treatment of psychological crowds as mere aggregations of individuals.
Indeed most models for evacuation dynamics use analogies from physics where
pedestrians are considered as particles. Although this ensures that the results
of the simulation match important physical phenomena, such as the deceleration
of the crowd with increasing density, social phenomena such as group processes
are ignored. In particular, people in a crowd have social identities and share
those social identities with the others in the crowd. The process of self
categorisation determines norms within the crowd and influences how people will
behave in evacuation situations. We formulate the application of social
identity in pedestrian simulation algorithmically. The goal is to examine
whether it is possible to carry over the psychological model to computer models
of pedestrian motion so that simulation results correspond to observations from
crowd psychology. That is, we quantify and formalise empirical research on and
verbal descriptions of the effect of group identity on behaviour. We use
uncertainty quantification to analyse the model's behaviour when we vary
crucial model parameters. In this first approach we restrict ourselves to a
specific scenario that was thoroughly investigated by crowd psychologists and
where some quantitative data is available: the bombing and subsequent
evacuation of a London underground tube carriage on July 7th 2005.
</dc:description>
 <dc:description>Comment: accepted by Safety Science, 34 pages (incl. bibliography)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-07-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00805</dc:identifier>
 <dc:identifier>doi:10.1016/j.ssci.2016.07.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00810</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Time Interactive Certificates for the Minimal Polynomial and the
  Determinant of a Sparse Matrix</dc:title>
 <dc:creator>Dumas, Jean-Guillaume</dc:creator>
 <dc:creator>Kaltofen, Erich</dc:creator>
 <dc:creator>Thom&#xe9;, Emmanuel</dc:creator>
 <dc:creator>Villard, Gilles</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Certificates to a linear algebra computation are additional data structures
for each output, which can be used by a-possibly randomized- verification
algorithm that proves the correctness of each output. In this paper, we give an
algorithm that compute a certificate for the minimal polynomial of sparse or
structured n x n matrices over an abstract field, of sufficiently large
cardinality, whose Monte Carlo verification complexity requires a single
matrix-vector multiplication and a linear number of extra field operations. We
also propose a novel preconditioner that ensures irreducibility of the
characteristic polynomial of the preconditioned matrix. This preconditioner
takes linear time to be applied and uses only two random entries. We then
combine these two techniques to give algorithms that compute certificates for
the determinant, and thus for the characteristic polynomial, whose Monte Carlo
verification complexity is therefore also linear.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00810</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00812</identifier>
 <datestamp>2016-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Grail theorem prover: Type theory for syntax and semantics</dc:title>
 <dc:creator>Moot, Richard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  As the name suggests, type-logical grammars are a grammar formalism based on
logic and type theory. From the prespective of grammar design, type-logical
grammars develop the syntactic and semantic aspects of linguistic phenomena
hand-in-hand, letting the desired semantics of an expression inform the
syntactic type and vice versa. Prototypical examples of the successful
application of type-logical grammars to the syntax-semantics interface include
coordination, quantifier scope and extraction.This chapter describes the Grail
theorem prover, a series of tools for designing and testing grammars in various
modern type-logical grammars which functions as a tool . All tools described in
this chapter are freely available.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00812</dc:identifier>
 <dc:identifier>Modern Perspectives in Type Theoretical Semantics, Springer, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00828</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning a Deep Model for Human Action Recognition from Novel Viewpoints</dc:title>
 <dc:creator>Rahmani, Hossein</dc:creator>
 <dc:creator>Mian, Ajmal</dc:creator>
 <dc:creator>Shah, Mubarak</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recognizing human actions from unknown and unseen (novel) views is a
challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model
(R-NKTM) for human action recognition from novel views. The proposed R-NKTM is
a deep fully-connected neural network that transfers knowledge of human actions
from any unknown view to a shared high-level virtual view by finding a
non-linear virtual path that connects the views. The R-NKTM is learned from
dense trajectories of synthetic 3D human models fitted to real motion capture
data and generalizes to real videos of human actions. The strength of our
technique is that we learn a single R-NKTM for all actions and all viewpoints
for knowledge transfer of any real human action video without the need for
re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to
incorporate new action classes. R-NKTM is learned with dummy labels and does
not require knowledge of the camera viewpoint at any stage. Experiments on
three benchmark cross-view human action datasets show that our method
outperforms existing state-of-the-art.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00828</dc:identifier>
 <dc:identifier>Phys. Rev. D 94, 065007 (2016)</dc:identifier>
 <dc:identifier>doi:10.1103/PhysRevD.94.065007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00831</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Perceiving Mass in Mixed Reality through Pseudo-Haptic Rendering of
  Newton's Third Law</dc:title>
 <dc:creator>Issartel, Paul</dc:creator>
 <dc:creator>Gu&#xe9;niat, Florimond</dc:creator>
 <dc:creator>Coquillart, Sabine</dc:creator>
 <dc:creator>Ammi, Mehdi</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In mixed reality, real objects can be used to interact with virtual objects.
However, unlike in the real world, real objects do not encounter any opposite
reaction force when pushing against virtual objects. The lack of reaction force
during manipulation prevents users from perceiving the mass of virtual objects.
Although this could be addressed by equipping real objects with force-feedback
devices, such a solution remains complex and impractical.In this work, we
present a technique to produce an illusion of mass without any active
force-feedback mechanism. This is achieved by simulating the effects of this
reaction force in a purely visual way. A first study demonstrates that our
technique indeed allows users to differentiate light virtual objects from heavy
virtual objects. In addition, it shows that the illusion is immediately
effective, with no prior training. In a second study, we measure the lowest
mass difference (JND) that can be perceived with this technique. The
effectiveness and ease of implementation of our solution provides an
opportunity to enhance mixed reality interaction at no additional cost.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00831</dc:identifier>
 <dc:identifier>doi:10.1109/VR.2015.7223322</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00833</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Non-Linear Energy Harvesting Model and Resource Allocation in
  SWIPT Systems</dc:title>
 <dc:creator>Boshkovska, Elena</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Simultaneous wireless information and power transfer (SWIPT) is a promising
solution for enabling long-life, and self-sustainable wireless networks. In
this thesis, we propose a practical non-linear energy harvesting (EH) model and
design a resource allocation algorithm for SWIPT systems. In particular, the
algorithm design is formulated as a non-convex optimization problem for the
maximization of the total harvested power at the EH receivers subject to
quality of service (QoS) constraints for the information decoding (ID)
receivers. To circumvent the non-convexity of the problem, we transform the
corresponding non-convex sum-of-ratios objective function into an equivalent
objective function in parametric subtractive form. Furthermore, we design a
computationally efficient iterative resource allocation algorithm to obtain the
globally optimal solution. Numerical results illustrate significant performance
gain in terms of average total harvested power for the proposed non-linear EH
receiver model, when compared to the traditional linear model.\
</dc:description>
 <dc:description>Comment: Master thesis, Institute for Digital Communications, University of
  Erlangen-Nuremberg, Germany</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00833</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00836</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms for Simultaneous Pad\'e Approximations</dc:title>
 <dc:creator>Nielsen, Johan S. R.</dc:creator>
 <dc:creator>Storjohann, Arne</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We describe how to solve simultaneous Pad\'e approximations over a power
series ring $K[[x]]$ for a field $K$ using $O~(n^{\omega - 1} d)$ operations in
$K$, where $d$ is the sought precision and $n$ is the number of power series to
approximate. We develop two algorithms using different approaches. Both
algorithms return a reduced sub-bases that generates the complete set of
solutions to the input approximations problem that satisfy the given degree
constraints. Our results are made possible by recent breakthroughs in fast
computations of minimal approximant bases and Hermite Pad\'e approximations.
</dc:description>
 <dc:description>Comment: ISSAC 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00836</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00841</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Physical Web models</dc:title>
 <dc:creator>Sneps-Sneppe, Manfred</dc:creator>
 <dc:creator>Namiot, Dmitry</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Physical Web is a generic term describes interconnection of physical
objects and web. The Physical Web lets present physical objects in a web. There
are different ways to do that and we will discuss them in our paper. Usually,
the web presentation for a physical object could be implemented with the help
of mobile devices. The basic idea behind the Physical Web is to navigate and
control physical objects in the world surrounding mobile devices with the help
of web technologies. Of course, there are different ways to identify and
enumerate physical objects. In this paper, we describe the existing models as
well as related challenges. In our analysis, we will target objects enumeration
and navigation as well as data retrieving and programming for the Physical Web.
</dc:description>
 <dc:description>Comment: a paper for Sibcon 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00841</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00844</identifier>
 <datestamp>2016-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A sufficient condition for tail asymptotics of SIR distribution in
  downlink cellular networks</dc:title>
 <dc:creator>Miyoshi, Naoto</dc:creator>
 <dc:creator>Shirai, Tomoyuki</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60G55</dc:subject>
 <dc:description>  We consider the spatial stochastic model of single-tier downlink cellular
networks, where the wireless base stations are deployed according to a general
stationary point process on the Euclidean plane with general i.i.d. propagation
effects. Recently, Ganti &amp; Haenggi (2016) consider the same general cellular
network model and, as one of many significant results, derive the tail
asymptotics of the signal-to-interference ratio (SIR) distribution. However,
they do not mention any conditions under which the result holds. In this paper,
we compensate their result for the lack of the condition and expose a
sufficient condition for the asymptotic result to be valid. We further
illustrate some examples satisfying such a sufficient condition and indicate
the corresponding asymptotic results for the example models. We give also a
simple counterexample violating the sufficient condition.
</dc:description>
 <dc:description>Comment: 7 pages, 1 figure, SpaSWin 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00844</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00848</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the p-adic stability of the FGLM algorithm</dc:title>
 <dc:creator>Renault, Gu&#xe9;na&#xeb;l</dc:creator>
 <dc:creator>Vaccon, Tristan</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  Nowadays, many strategies to solve polynomial systems use the computation of
a Gr{\&quot;o}bner basis for the graded reverse lexicographical ordering, followed
by a change of ordering algorithm to obtain a Gr{\&quot;o}bner basis for the
lexicographical ordering. The change of ordering algorithm is crucial for these
strategies. We study the p-adic stability of the main change of ordering
algorithm, FGLM. We show that FGLM is stable and give explicit upper bound on
the loss of precision occuring in its execution. The variant of FGLM designed
to pass from the grevlex ordering to a Gr{\&quot;o}bner basis in shape position is
also stable. Our study relies on the application of Smith Normal Form
computations for linear algebra.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00848</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00849</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GTOC8: Results and Methods of ESA Advanced Concepts Team and JAXA-ISAS</dc:title>
 <dc:creator>Izzo, Dario</dc:creator>
 <dc:creator>Hennes, Daniel</dc:creator>
 <dc:creator>M&#xe4;rtens, Marcus</dc:creator>
 <dc:creator>Getzner, Ingmar</dc:creator>
 <dc:creator>Nowak, Krzysztof</dc:creator>
 <dc:creator>Heffernan, Anna</dc:creator>
 <dc:creator>Campagnola, Stefano</dc:creator>
 <dc:creator>Yam, Chit Hong</dc:creator>
 <dc:creator>Ozaki, Naoya</dc:creator>
 <dc:creator>Sugimoto, Yoshihide</dc:creator>
 <dc:subject>Physics - Space Physics</dc:subject>
 <dc:subject>Astrophysics - Instrumentation and Methods for Astrophysics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We consider the interplanetary trajectory design problem posed by the 8th
edition of the Global Trajectory Optimization Competition and present the
end-to-end strategy developed by the team ACT-ISAS (a collaboration between the
European Space Agency's Advanced Concepts Team and JAXA's Institute of Space
and Astronautical Science). The resulting interplanetary trajectory won 1st
place in the competition, achieving a final mission value of $J=146.33$ [Mkm].
Several new algorithms were developed in this context but have an interest that
go beyond the particular problem considered, thus, they are discussed in some
detail. These include the Moon-targeting technique, allowing one to target a
Moon encounter from a low Earth orbit; the 1-$k$ and 2-$k$ fly-by targeting
techniques, enabling one to design resonant fly-bys while ensuring a targeted
future formation plane% is acquired at some point after the manoeuvre ; the
distributed low-thrust targeting technique, admitting one to control the
spacecraft formation plane at 1,000,000 [km]; and the low-thrust optimization
technique, permitting one to enforce the formation plane's orientations as path
constraints.
</dc:description>
 <dc:description>Comment: Presented at the 26th AAS/AIAA Space Flight Mechanics Meeting, Napa,
  CA. Paper AAS 16-275</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00849</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00860</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the security of the Algebraic Eraser tag authentication protocol</dc:title>
 <dc:creator>Blackburn, Simon R.</dc:creator>
 <dc:creator>Robshaw, M. J. B.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:description>  The Algebraic Eraser has been gaining prominence as SecureRF, the company
commercializing the algorithm, increases its marketing reach. The scheme is
claimed to be well-suited to IoT applications but a lack of detail in available
documentation has hampered peer-review. Recently more details of the system
have emerged after a tag authentication protocol built using the Algebraic
Eraser was proposed for standardization in ISO/IEC SC31 and SecureRF provided
an open public description of the protocol. In this paper we describe a range
of attacks on this protocol that include very efficient and practical tag
impersonation as well as partial, and total, tag secret key recovery. Most of
these results have been practically verified, they contrast with the 80-bit
security that is claimed for the protocol, and they emphasize the importance of
independent public review for any cryptographic proposal.
</dc:description>
 <dc:description>Comment: 21 pages. Minor changes. Final version accepted for ACNS 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00875</identifier>
 <datestamp>2016-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Converse Bounds for Noisy Group Testing with Arbitrary Measurement
  Matrices</dc:title>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the group testing problem, in which one seeks to identify a
subset of defective items within a larger set of items based on a number of
noisy tests. While matching achievability and converse bounds are known in
several cases of interest for i.i.d.~measurement matrices, less is known
regarding converse bounds for arbitrary measurement matrices. We address this
by presenting two converse bounds for arbitrary matrices and general noise
models. First, we provide a strong converse bound ($\mathbb{P}[\mathrm{error}]
\to 1$) that matches existing achievability bounds in several cases of
interest. Second, we provide a weak converse bound ($\mathbb{P}[\mathrm{error}]
\not\to 0$) that matches existing achievability bounds in greater generality.
</dc:description>
 <dc:description>Comment: Accepted to ISIT 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00875</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00877</identifier>
 <datestamp>2016-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Partial Recovery Bounds for the Sparse Stochastic Block Model</dc:title>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we study the information-theoretic limits of community
detection in the symmetric two-community stochastic block model, with
intra-community and inter-community edge probabilities $\frac{a}{n}$ and
$\frac{b}{n}$ respectively. We consider the sparse setting, in which $a$ and
$b$ do not scale with $n$, and provide upper and lower bounds on the proportion
of community labels recovered on average. We provide a numerical example for
which the bounds are near-matching for moderate values of $a - b$, and matching
in the limit as $a-b$ grows large.
</dc:description>
 <dc:description>Comment: Accepted to ISIT 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-04-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00877</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00878</identifier>
 <datestamp>2017-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Properties of the Support of Capacity-Achieving Distributions for
  Additive Noise Channel Models with Input Cost Constraints</dc:title>
 <dc:creator>Fahs, Jihad</dc:creator>
 <dc:creator>Abou-Faycal, Ibrahim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the classical problem of characterizing the channel capacity and its
achieving distribution in a generic fashion. We derive a simple relation
between three parameters: the input-output function, the input cost function
and the noise probability density function, one which dictates the type of the
optimal input. In Layman terms we prove that the support of the optimal input
is bounded whenever the cost grows faster than a cut-off rate equal to the
logarithm of the noise PDF evaluated at the input-output function. Furthermore,
we prove a converse statement that says whenever the cost grows slower than the
cut-off rate, the optimal input has necessarily an unbounded support. In
addition, we show how the discreteness of the optimal input is guaranteed
whenever the triplet satisfy some analyticity properties. We argue that a
suitable cost function to be imposed on the channel input is one that grows
similarly to the cut-off rate. Our results are valid for any cost function that
is super-logarithmic. They summarize a large number of previous channel
capacity results and give new ones for a wide range of communication channel
models, such as Gaussian mixtures, generalized-Gaussians and heavy-tailed noise
models, that we state along with numerical computations.
</dc:description>
 <dc:description>Comment: Accepted for publication in the IEEE Transactions on Information
  Theory with minor modifications on the current version</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2017-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00878</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2017.2771815</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00883</identifier>
 <datestamp>2016-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Scheduling in Multiple Access with Bursty Arrivals and Delay
  Constraints</dc:title>
 <dc:creator>Kapoor, Sakshi</dc:creator>
 <dc:creator>Sreekumar, Sreejith</dc:creator>
 <dc:creator>Pillai, Sibi Raj B</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A multiple access system with bursty data arrivals to the terminals is
considered. The users are frame-synchronized, with variable sized packets
independently arriving in each slot at every transmitter. Each packet needs to
be delivered to a common receiver within a certain number of slots specified by
a maximum delay constraint. The key assumption is that the terminals know only
their own packet arrival process, i.e. the arrivals at the rest of the
terminals are unknown to each transmitter, except for their statistics. For
this interesting distributed multiple access model, we design novel online
communication schemes which transport the arriving data without any outage,
while ensuring the delay constraint. In particular, the transmit powers in each
slot are chosen in a distributed manner, ensuring at the same time that the
joint power vector is sufficient to support the distributed choice of
data-rates employed in that slot. The proposed schemes not only are optimal for
minimizing the average transmit sum-power, but they also considerably
outperform conventional orthogonal multiple access techniques like TDMA.
</dc:description>
 <dc:description>Comment: 39 pages, 16 figures, presented in part at ISIT 2014</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-11-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00895</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BANZKP: a Secure Authentication Scheme Using Zero Knowledge Proof for
  WBANs</dc:title>
 <dc:creator>Khernane, Nesrine</dc:creator>
 <dc:creator>Potop-Butucaru, Maria</dc:creator>
 <dc:creator>Chaudet, Claude</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  -Wireless body area network(WBAN) has shown great potential in improving
healthcare quality not only for patients but also for medical staff. However,
security and privacy are still an important issue in WBANs especially in
multi-hop architectures. In this paper, we propose and present the design and
the evaluation of a secure lightweight and energy efficient authentication
scheme BANZKP based on an efficient cryptographic protocol, Zero Knowledge
Proof (ZKP) and a commitment scheme. ZKP is used to confirm the identify of the
sensor nodes, with small computational requirement, which is favorable for body
sensors given their limited resources, while the commitment scheme is used to
deal with replay attacks and hence the injection attacks by committing a
message and revealing the key later. Our scheme reduces the memory requirement
by 56.13 % compared to TinyZKP [13], the comparable alternative so far for Body
Area Networks, and uses 10 % less energy.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00904</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative evaluation of state-of-the-art algorithms for SSVEP-based
  BCIs</dc:title>
 <dc:creator>Oikonomou, Vangelis P.</dc:creator>
 <dc:creator>Liaros, Georgios</dc:creator>
 <dc:creator>Georgiadis, Kostantinos</dc:creator>
 <dc:creator>Chatzilari, Elisavet</dc:creator>
 <dc:creator>Adam, Katerina</dc:creator>
 <dc:creator>Nikolopoulos, Spiros</dc:creator>
 <dc:creator>Kompatsiaris, Ioannis</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Brain-computer interfaces (BCIs) have been gaining momentum in making
human-computer interaction more natural, especially for people with
neuro-muscular disabilities. Among the existing solutions the systems relying
on electroencephalograms (EEG) occupy the most prominent place due to their
non-invasiveness. However, the process of translating EEG signals into computer
commands is far from trivial, since it requires the optimization of many
different parameters that need to be tuned jointly. In this report, we focus on
the category of EEG-based BCIs that rely on Steady-State-Visual-Evoked
Potentials (SSVEPs) and perform a comparative evaluation of the most promising
algorithms existing in the literature. More specifically, we define a set of
algorithms for each of the various different parameters composing a BCI system
(i.e. filtering, artifact removal, feature extraction, feature selection and
classification) and study each parameter independently by keeping all other
parameters fixed. The results obtained from this evaluation process are
provided together with a dataset consisting of the 256-channel, EEG signals of
11 subjects, as well as a processing toolbox for reproducing the results and
supporting further experimentation. In this way, we manage to make available
for the community a state-of-the-art baseline for SSVEP-based BCIs that can be
used as a basis for introducing novel methods and approaches.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00910</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>5G Waveforms for Overlay D2D Communications: Effects of Time-Frequency
  Misalignment</dc:title>
 <dc:creator>Bodinier, Quentin</dc:creator>
 <dc:creator>Farhang, Arman</dc:creator>
 <dc:creator>Bader, Faouzi</dc:creator>
 <dc:creator>Ahmadi, Hamed</dc:creator>
 <dc:creator>Palicot, Jacques</dc:creator>
 <dc:creator>DaSilva, Luiz A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper analyses a scenario where a Device-To-Device (D2D) pair coexists
with an Orthogonal Frequency Division Multiplexing (OFDM) based incumbent
network. D2D transmitter communicates in parts of spectrum left free by
cellular users, while respecting a given spectral mask. The D2D pair is
misaligned in time and frequency with the cellular users. Furthermore, the D2D
pair utilizes alternative waveforms to OFDM proposed for 5G. In this study, we
show that it is not worth synchronising the D2D pair in time with respect to
the cellular users. Indeed, the interference injected into the incumbent
network has small variations with respect to time misalignment. We provide
interference tables that encompass both time and frequency misalignment. We use
them to analyse the maximum rate achievable by the D2D pair when it uses
different waveforms. Then, we present numerical results showing what waveform
should be utilized by the D2D pair according to the time-frequency resources
that are not used by the incumbent network. Our results show that the delay
induced by linearly convolved waveforms make them hardly applicable to short
time windows, but that they dominate OFDM for long transmissions, mainly in the
case where cellular users are very sensitive to interference.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, Accepted at IEEE ICC 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00910</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7511285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00912</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From $\mu$-Calculus to Alternating Tree Automata using Parity Games</dc:title>
 <dc:creator>Arif, M. Fareed</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  $\mu$-Calculus and automata on infinite trees are complementary ways of
describing infinite tree languages. The correspondence between $\mu$-Calculus
and alternating tree automaton is used to solve the satisfiability and model
checking problems by compiling the modal $\mu$-Calculus formula into an
alternating tree automata. Thus advocating an automaton model specially
tailored for working with modal $\mu$-Calculus. The advantage of the automaton
model is its ability to deal with arbitrary branching in a much simpler way as
compare to the one proposed by Janin and Walukiewicz. Both problems (i.e.,
model checking and satisfiability) are solved by reduction to the corresponding
problems of alternating tree automata, namely to the acceptance and the
non-emptiness problems, respectively. These problems, in turn, are solved using
parity games where semantics of alternating tree automata is translated to a
winning strategy in an appropriate parity game.
</dc:description>
 <dc:description>Comment: 17 pages, 1 figure</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00914</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binary linear codes with at most 4 weights</dc:title>
 <dc:creator>Li, Fei</dc:creator>
 <dc:creator>Yan, Yang</dc:creator>
 <dc:creator>Wang, Qiuyan</dc:creator>
 <dc:creator>Yan, Tongjiang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For the past decades, linear codes with few weights have been widely studied,
since they have applications in space communications, data storage and
cryptography. In this paper, a class of binary linear codes is constructed and
their weight distribution is determined. Results show that they are at most
4-weight linear codes. Additionally, these codes can be used in secret sharing
schemes.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00914</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00917</identifier>
 <datestamp>2016-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HYPERgeometric functions DIfferential REduction: Mathematica-based
  packages for the differential reduction of generalizedhypergeometric
  functions: Fc hypergeometric function of three variables</dc:title>
 <dc:creator>Bytev, V.</dc:creator>
 <dc:creator>Kniehl, B.</dc:creator>
 <dc:subject>Mathematical Physics</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>High Energy Physics - Phenomenology</dc:subject>
 <dc:subject>High Energy Physics - Theory</dc:subject>
 <dc:description>  We present a further extension of the HYPERDIRE project, which is devoted to
the creation of a set of Mathematica-based program packages for manipulations
with Horn-type hypergeometric functions on the basis of differential equations.
Specifically, we present the implementation of the differential reduction for
the Lauricella function $F_C$ of three variables.
</dc:description>
 <dc:description>Comment: 15 pages, minor changes, accepted for publication in Computer Physics
  Communications</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00917</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2016.04.016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00928</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Continuum Extensions of Asymmetric Gaussian Channels (Multiple
  Access and Broadcast)</dc:title>
 <dc:creator>Gorce, Jean-Marie</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:creator>Kelif, Jean-Marc</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper proposes a new model called \emph{spatial continuum asymmetric
channels} to study the channel capacity region of asymmetric scenarios in which
either one source transmits to a spatial density of receivers or a density of
transmitters transmit to a unique receiver.This approach is built upon the
classical broadcast channel (BC) and multiple access channel (MAC). For the
sake of consistency, the study is limited to Gaussian channels with power
constraints and is restricted to the asymptotic regime (zero-error
capacity).The reference scenario comprises one base station (BS) in Tx or Rx
mode, a spatial random distribution of nodes (resp. in Rx or Tx mode)
characterized by a probability spatial density $u(x)$ and a request for a
quantity of information with no delay constraint. This system is modeled as an
$\infty-$user asymmetric channel (BC or MAC). To derive the properties of this
model, a spatial discretization is performed and the equivalence with either a
BC or MAC is established. A discretization sequence is then defined to refine
infinitely the approximation. Achievability and capacity results are obtained
in the limit of this sequence. The uniform capacity is then defined as the
maximal symmetric achievable rate at which the distributed users can
transmit/receive with no delay constraint.The capacity region is also
established as the set of information distributions that are achievable. The
tightness of these limits and their practical interest are briefly illustrated
and discussed.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00928</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00932</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Addendum to Pentapods with Mobility 2</dc:title>
 <dc:creator>Nawratil, Georg</dc:creator>
 <dc:creator>Schicho, Josef</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:description>  In a foregoing publication the authors studied pentapods with mobility 2,
where neither all platform anchor points nor all base anchor points are located
on a line. It turned out that the given classification is incomplete. This
addendum is devoted to the discussion of the missing cases resulting in
additional solutions already known to Duporcq.
</dc:description>
 <dc:description>Comment: 9 pages, 6 figures</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00932</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00955</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised High-level Feature Learning by Ensemble Projection for
  Semi-supervised Image Classification and Image Clustering</dc:title>
 <dc:creator>Dai, Dengxin</dc:creator>
 <dc:creator>Van Gool, Luc</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper investigates the problem of image classification with limited or
no annotations, but abundant unlabeled data. The setting exists in many tasks
such as semi-supervised image classification, image clustering, and image
retrieval. Unlike previous methods, which develop or learn sophisticated
regularizers for classifiers, our method learns a new image representation by
exploiting the distribution patterns of all available data for the task at
hand. Particularly, a rich set of visual prototypes are sampled from all
available data, and are taken as surrogate classes to train discriminative
classifiers; images are projected via the classifiers; the projected values,
similarities to the prototypes, are stacked to build the new feature vector.
The training set is noisy. Hence, in the spirit of ensemble learning we create
a set of such training sets which are all diverse, leading to diverse
classifiers. The method is dubbed Ensemble Projection (EP). EP captures not
only the characteristics of individual images, but also the relationships among
images. It is conceptually simple and computationally efficient, yet effective
and flexible. Experiments on eight standard datasets show that: (1) EP
outperforms previous methods for semi-supervised image classification; (2) EP
produces promising results for self-taught image classification, where
unlabeled samples are a random collection of images rather than being from the
same distribution as the labeled ones; and (3) EP improves over the original
features for image clustering. The code of the method is available on the
project page.
</dc:description>
 <dc:description>Comment: 22 pages, 8 figures</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00955</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00963</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algorithms and Heuristics for Scalable Betweenness Centrality
  Computation on Multi-GPU Systems</dc:title>
 <dc:creator>Vella, Flavio</dc:creator>
 <dc:creator>Carbone, Giancarlo</dc:creator>
 <dc:creator>Bernaschi, Massimo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Betweenness Centrality (BC) is steadily growing in popularity as a metrics of
the influence of a vertex in a graph. The BC score of a vertex is proportional
to the number of all-pairs-shortest-paths passing through it. However, complete
and exact BC computation for a large-scale graph is an extraordinary challenge
that requires high performance computing techniques to provide results in a
reasonable amount of time. Our approach combines bi-dimensional (2-D)
decomposition of the graph and multi-level parallelism together with a suitable
data-thread mapping that overcomes most of the difficulties caused by the
irregularity of the computation on GPUs. Furthermore, we propose novel
heuristics which exploit the topology information of the graph in order to
reduce time and space requirements of BC computation. Experimental results on
synthetic and real-world graphs show that the proposed techniques allow the BC
computation of graphs which are too large to fit in the memory of a single
computational node along with a significant reduction of the computing time.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00970</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual descriptors for content-based retrieval of remote sensing images</dc:title>
 <dc:creator>Napoletano, Paolo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present an extensive evaluation of visual descriptors for
the content-based retrieval of remote sensing (RS) images. The evaluation
includes global hand-crafted, local hand-crafted, and Convolutional Neural
Network (CNNs) features coupled with four different Content-Based Image
Retrieval schemes. We conducted all the experiments on two publicly available
datasets: the 21-class UC Merced Land Use/Land Cover (LandUse) dataset and
19-class High-resolution Satellite Scene dataset (SceneSat). The content of RS
images might be quite heterogeneous, ranging from images containing fine
grained textures, to coarse grained ones or to images containing objects. It is
therefore not obvious in this domain, which descriptor should be employed to
describe images having such a variability. Results demonstrate that CNN-based
features perform better than both global and and local hand-crafted features
whatever is the retrieval scheme adopted. Features extracted from SatResNet-50,
a residual CNN suitable fine-tuned on the RS domain, shows much better
performance than a residual CNN pre-trained on multimedia scene and object
images. Features extracted from NetVLAD, a CNN that considers both CNN and
local features, works better than others CNN solutions on those images that
contain fine-grained textures and objects.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2017-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00970</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00975</identifier>
 <datestamp>2017-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BotOrNot: A System to Evaluate Social Bots</dc:title>
 <dc:creator>Davis, Clayton A.</dc:creator>
 <dc:creator>Varol, Onur</dc:creator>
 <dc:creator>Ferrara, Emilio</dc:creator>
 <dc:creator>Flammini, Alessandro</dc:creator>
 <dc:creator>Menczer, Filippo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  While most online social media accounts are controlled by humans, these
platforms also host automated agents called social bots or sybil accounts.
Recent literature reported on cases of social bots imitating humans to
manipulate discussions, alter the popularity of users, pollute content and
spread misinformation, and even perform terrorist propaganda and recruitment
actions. Here we present BotOrNot, a publicly-available service that leverages
more than one thousand features to evaluate the extent to which a Twitter
account exhibits similarity to the known characteristics of social bots. Since
its release in May 2014, BotOrNot has served over one million requests via our
website and APIs.
</dc:description>
 <dc:description>Comment: 2 pages, 2 figures, WWW Developers Day</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00975</dc:identifier>
 <dc:identifier>Proceedings of the 25th International Conference Companion on
  World Wide Web (pp. 273-274). 2016</dc:identifier>
 <dc:identifier>doi:10.1145/2872518.2889302</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00981</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>CPL: A Core Language for Cloud Computing -- Technical Report</dc:title>
 <dc:creator>Bra&#x10d;evac, Oliver</dc:creator>
 <dc:creator>Erdweg, Sebastian</dc:creator>
 <dc:creator>Salvaneschi, Guido</dc:creator>
 <dc:creator>Mezini, Mira</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Running distributed applications in the cloud involves deployment. That is,
distribution and configuration of application services and middleware
infrastructure. The considerable complexity of these tasks resulted in the
emergence of declarative JSON-based domain-specific deployment languages to
develop deployment programs. However, existing deployment programs unsafely
compose artifacts written in different languages, leading to bugs that are hard
to detect before run time. Furthermore, deployment languages do not provide
extension points for custom implementations of existing cloud services such as
application-specific load balancing policies.
  To address these shortcomings, we propose CPL (Cloud Platform Language), a
statically-typed core language for programming both distributed applications as
well as their deployment on a cloud platform. In CPL, application services and
deployment programs interact through statically typed, extensible interfaces,
and an application can trigger further deployment at run time. We provide a
formal semantics of CPL and demonstrate that it enables type-safe, composable
and extensible libraries of service combinators, such as load balancing and
fault tolerance.
</dc:description>
 <dc:description>Comment: Technical report accompanying the MODULARITY '16 submission</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00981</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00984</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Influence of the Java Collection Framework on Overall Energy
  Consumption</dc:title>
 <dc:creator>Pereira, Rui</dc:creator>
 <dc:creator>Couto, Marco</dc:creator>
 <dc:creator>Cunha, J&#xe1;come</dc:creator>
 <dc:creator>Fernandes, Jo&#xe3;o Paulo</dc:creator>
 <dc:creator>Saraiva, Jo&#xe3;o</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This paper presents a detailed study of the energy consumption of the
different Java Collection Framework (JFC) implementations. For each method of
an implementation in this framework, we present its energy consumption when
handling different amounts of data. Knowing the greenest methods for each
implementation, we present an energy optimization approach for Java programs:
based on calls to JFC methods in the source code of a program, we select the
greenest implementation. Finally, we present preliminary results of optimizing
a set of Java programs where we obtained 6.2% energy savings.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00984</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00985</identifier>
 <datestamp>2016-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mental State Recognition via Wearable EEG</dc:title>
 <dc:creator>Bashivan, Pouya</dc:creator>
 <dc:creator>Rish, Irina</dc:creator>
 <dc:creator>Heisig, Steve</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  The increasing quality and affordability of consumer electroencephalogram
(EEG) headsets make them attractive for situations where medical grade devices
are impractical. Predicting and tracking cognitive states is possible for tasks
that were previously not conducive to EEG monitoring. For instance, monitoring
operators for states inappropriate to the task (e.g. drowsy drivers), tracking
mental health (e.g. anxiety) and productivity (e.g. tiredness) are among
possible applications for the technology. Consumer grade EEG headsets are
affordable and relatively easy to use, but they lack the resolution and quality
of signal that can be achieved using medical grade EEG devices. Thus, the key
questions remain: to what extent are wearable EEG devices capable of mental
state recognition, and what kind of mental states can be accurately recognized
with these devices? In this work, we examined responses to two different types
of input: instructional (logical) versus recreational (emotional) videos, using
a range of machine-learning methods. We tried SVMs, sparse logistic regression,
and Deep Belief Networks, to discriminate between the states of mind induced by
different types of video input, that can be roughly labeled as logical vs.
emotional. Our results demonstrate a significant potential of wearable EEG
devices in differentiating cognitive states between situations with large
contextual but subtle apparent differences.
</dc:description>
 <dc:description>Comment: Presented at MLINI-2015 workshop, 2015 (arXiv:cs/0101200)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-06-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00985</dc:identifier>
 <dc:identifier>Proceedings of 5th NIPS workshop on Machine Learning and
  Interpretation in Neuroimaging (MLINI15) (2015) 5-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00991</identifier>
 <datestamp>2016-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks</dc:title>
 <dc:creator>Ondruska, Peter</dc:creator>
 <dc:creator>Posner, Ingmar</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:description>  This paper presents to the best of our knowledge the first end-to-end object
tracking approach which directly maps from raw sensor input to object tracks in
sensor space without requiring any feature engineering or system identification
in the form of plant or sensor models. Specifically, our system accepts a
stream of raw sensor data at one end and, in real-time, produces an estimate of
the entire environment state at the output including even occluded objects. We
achieve this by framing the problem as a deep learning task and exploit
sequence models in the form of recurrent neural networks to learn a mapping
from sensor measurements to object tracks. In particular, we propose a learning
method based on a form of input dropout which allows learning in an
unsupervised manner, only based on raw, occluded sensor data without access to
ground-truth annotations. We demonstrate our approach using a synthetic dataset
designed to mimic the task of tracking objects in 2D laser data -- as commonly
encountered in robotics applications -- and show that it learns to track many
dynamic objects despite occlusions and the presence of sensor noise.
</dc:description>
 <dc:description>Comment: Published in The Thirtieth AAAI Conference on Artificial Intelligence
  (AAAI-16), Video: https://youtu.be/cdeWCpfUGWc, Code:
  http://mrg.robots.ox.ac.uk/mrg_people/peter-ondruska/</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-03-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00994</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic City Region Analysis for Urban Routing</dc:title>
 <dc:creator>Zhao, Kai</dc:creator>
 <dc:creator>Prasath, C Mohan</dc:creator>
 <dc:creator>Tarkoma, Sasu</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  There are different functional regions in cities such as tourist attractions,
shopping centers, workplaces and residential places. The human mobility
patterns for different functional regions are different, e.g., people usually
go to work during daytime on weekdays, and visit shopping centers after work.
In this paper, we analyse urban human mobility patterns and infer the functions
of the regions in three cities. The analysis is based on three large taxi GPS
datasets in Rome, San Francisco and Beijing containing 21 million, 11 million
and 17 million GPS points respectively. We categorized the city regions into
four kinds of places, workplaces, entertainment places, residential places and
other places. First, we provide a new quad-tree region division method based on
the taxi visits. Second, we use the association rule to infer the functional
regions in these three cities according to temporal human mobility patterns.
Third, we show that these identified functional regions can help us deliver
data in network applications, such as urban Delay Tolerant Networks (DTNs),
more efficiently. The new functional-regions-based DTNs algorithm achieves up
to 183% improvement in terms of delivery ratio.
</dc:description>
 <dc:description>Comment: In proceedings of the IEEE International Conference on Data Mining
  (ICDM) workshop 2015</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00994</dc:identifier>
 <dc:identifier>doi:10.1109/ICDMW.2015.176</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00997</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Head Pose Estimation of Occluded Faces using Regularized Regression</dc:title>
 <dc:creator>Kumar, Amit</dc:creator>
 <dc:creator>Bindal, Rishabh</dc:creator>
 <dc:creator>Indela, Soumya</dc:creator>
 <dc:creator>Rotkowitz, Michael</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents regression methods for estimation of head pose from
occluded 2-D face images. The process primarily involves reconstructing a face
from its occluded image, followed by classification. Typical methods for
reconstruction assume that the pixel errors of the occluded regions are
independent. However, such an assumption is not true in the case of occlusion,
because of its inherent contiguous nature. Hence, we use nuclear norm as a
metric that can describe well the structure of the error. We also use LASSO
Regression based l1 - regularization to improve reconstruction. Next, we
implement Nuclear Norm Regularized Regression (NR), and also our proposed
method, for reconstruction and subsequent classification. Finally, we compare
the performance of the methods in terms of accuracy of head pose estimation of
occluded faces.
</dc:description>
 <dc:description>Comment: Submitted to ICIP'16</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00997</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.00998</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A combinatorial approach to certain topological spaces based on minimum
  complement S-approximation spaces</dc:title>
 <dc:creator>Hooshmandasl, M. R.</dc:creator>
 <dc:creator>Meybodi, M. Alambardar</dc:creator>
 <dc:creator>Goharshady, A. K.</dc:creator>
 <dc:creator>Shakiba, A.</dc:creator>
 <dc:subject>Mathematics - Algebraic Topology</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>54F99, 68P01</dc:subject>
 <dc:description>  An S-approximation space is a novel approach to study systems with
uncertainty that are not expressible in terms of inclusion relations. In this
work, we further examined these spaces, mostly from a topological point of view
by a combinatorial approach. This work also identifies a subclass of these
approximation spaces, called $S_\mathcal{MC}$-approximations. Topological
properties of this subclass are investigated and finally, the topologies formed
by $S_\mathcal{MC}$-approximations are enumerated up to homeomorphism.
</dc:description>
 <dc:description>Comment: This paper is presented in 8th International Seminar on Geometry and
  Topology at Amirkabir University of Technology (Iran)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.00998</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01003</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Node Centrality and Optimal Control to Maximize Information
  Diffusion in Social Networks</dc:title>
 <dc:creator>Kandhway, Kundan</dc:creator>
 <dc:creator>Kuri, Joy</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We model information dissemination as a susceptible-infected epidemic process
and formulate a problem to jointly optimize seeds for the epidemic and time
varying resource allocation over the period of a fixed duration campaign
running on a social network with a given adjacency matrix. Individuals in the
network are grouped according to their centrality measure and each group is
influenced by an external control function---implemented through
advertisements---during the campaign duration. The aim is to maximize an
objective function which is a linear combination of the reward due to the
fraction of informed individuals at the deadline, and the aggregated cost of
applying controls (advertising) over the campaign duration. We also study a
problem variant with a fixed budget constraint. We set up the optimality system
using Pontryagin's Maximum Principle from optimal control theory and solve it
numerically using the forward-backward sweep technique. Our formulation allows
us to compare the performance of various centrality measures (pagerank, degree,
closeness and betweenness) in maximizing the spread of a message in the optimal
control framework. We find that degree---a simple and local measure---performs
well on the three social networks used to demonstrate results: scientific
collaboration, Slashdot and Facebook. The optimal strategy targets central
nodes when the resource is scarce, but non-central nodes are targeted when the
resource is in abundance. Our framework is general and can be used in similar
studies for other disease or information spread models---that can be modeled
using a system of ordinary differential equations---for a network with a known
adjacency matrix.
</dc:description>
 <dc:description>Comment: 12 pages, 11 figures. Author's version of an article published in
  IEEE Transactions on Systems, Man, and Cybernetics: Systems. Minor typos were
  fixed in v2. The published version can be accessed at
  http://dx.doi.org/10.1109/TSMC.2016.2531690</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-03-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01003</dc:identifier>
 <dc:identifier>IEEE Transactions on Systems, Man, and Cybernetics: Systems,
  Volume: 47, Issue: 7, Pages 1099-1110, July 2017</dc:identifier>
 <dc:identifier>doi:10.1109/TSMC.2016.2531690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01006</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A-expansion for multiple &quot;hedgehog&quot; shapes</dc:title>
 <dc:creator>Isack, Hossam</dc:creator>
 <dc:creator>Boykov, Yuri</dc:creator>
 <dc:creator>Veksler, Olga</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Overlapping colors and cluttered or weak edges are common segmentation
problems requiring additional regularization. For example, star-convexity is
popular for interactive single object segmentation due to simplicity and
amenability to exact graph cut optimization. This paper proposes an approach to
multiobject segmentation where objects could be restricted to separate
&quot;hedgehog&quot; shapes. We show that a-expansion moves are submodular for our
multi-shape constraints. Each &quot;hedgehog&quot; shape has its surface normals
constrained by some vector field, e.g. gradients of a distance transform for
user scribbles. Tight constraint give an extreme case of a shape prior
enforcing skeleton consistency with the scribbles. Wider cones of allowed
normals gives more relaxed hedgehog shapes. A single click and +/-90 degrees
normal orientation constraints reduce our hedgehog prior to star-convexity. If
all hedgehogs come from single clicks then our approach defines multi-star
prior. Our general method has significantly more applications than standard
one-star segmentation. For example, in medical data we can separate multiple
non-star organs with similar appearances and weak or noisy edges.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01006</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01007</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Real-Time Bidding Frameworks Discussion</dc:title>
 <dc:creator>Zhang, Weinan</dc:creator>
 <dc:creator>Ren, Kan</dc:creator>
 <dc:creator>Wang, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  This note is a complementary material for the solution of optimal real-time
bidding function in paper &quot;Optimal Real-Time Bidding for Display Advertising,
KDD 2014&quot;, where the estimated cost is taken as the bid price, i.e., the upper
bound of the true cost. Here we discuss a more general bid optimisation
framework with various utility and cost functions.
</dc:description>
 <dc:description>Comment: 4 pages</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01013</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring limits to prediction in complex social systems</dc:title>
 <dc:creator>Martin, Travis</dc:creator>
 <dc:creator>Hofman, Jake M.</dc:creator>
 <dc:creator>Sharma, Amit</dc:creator>
 <dc:creator>Anderson, Ashton</dc:creator>
 <dc:creator>Watts, Duncan J.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  How predictable is success in complex social systems? In spite of a recent
profusion of prediction studies that exploit online social and information
network data, this question remains unanswered, in part because it has not been
adequately specified. In this paper we attempt to clarify the question by
presenting a simple stylized model of success that attributes prediction error
to one of two generic sources: insufficiency of available data and/or models on
the one hand; and inherent unpredictability of complex social systems on the
other. We then use this model to motivate an illustrative empirical study of
information cascade size prediction on Twitter. Despite an unprecedented volume
of information about users, content, and past performance, our best performing
models can explain less than half of the variance in cascade sizes. In turn,
this result suggests that even with unlimited data predictive performance would
be bounded well below deterministic accuracy. Finally, we explore this
potential bound theoretically using simulations of a diffusion process on a
random scale free network similar to Twitter. We show that although higher
predictive power is possible in theory, such performance requires a homogeneous
system and perfect ex-ante knowledge of it: even a small degree of uncertainty
in estimating product quality or slight variation in quality across products
leads to substantially more restrictive bounds on predictability. We conclude
that realistic bounds on predictive accuracy are not dissimilar from those we
have obtained empirically, and that such bounds for other complex social
systems for which data is more difficult to obtain are likely even lower.
</dc:description>
 <dc:description>Comment: 12 pages, 6 figures, Proceedings of the 25th ACM International World
  Wide Web Conference (WWW) 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01013</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2883001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01016</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Clustering via Maximizing Modularity: Approximation Algorithms
  and Theoretical Limits</dc:title>
 <dc:creator>Dinh, Thang N.</dc:creator>
 <dc:creator>Li, Xiang</dc:creator>
 <dc:creator>Thai, My T.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Many social networks and complex systems are found to be naturally divided
into clusters of densely connected nodes, known as community structure (CS).
Finding CS is one of fundamental yet challenging topics in network science. One
of the most popular classes of methods for this problem is to maximize Newman's
modularity. However, there is a little understood on how well we can
approximate the maximum modularity as well as the implications of finding
community structure with provable guarantees. In this paper, we settle
definitely the approximability of modularity clustering, proving that
approximating the problem within any (multiplicative) positive factor is
intractable, unless P = NP. Yet we propose the first additive approximation
algorithm for modularity clustering with a constant factor. Moreover, we
provide a rigorous proof that a CS with modularity arbitrary close to maximum
modularity QOPT might bear no similarity to the optimal CS of maximum
modularity. Thus even when CS with near-optimal modularity are found, other
verification methods are needed to confirm the significance of the structure.
</dc:description>
 <dc:description>Comment: Appeared in IEEE ICDM 2015</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01016</dc:identifier>
 <dc:identifier>doi:10.1109/ICDM.2015.139</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01024</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Deep Multi-View Representation Learning: Objectives and Optimization</dc:title>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Arora, Raman</dc:creator>
 <dc:creator>Livescu, Karen</dc:creator>
 <dc:creator>Bilmes, Jeff</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider learning representations (features) in the setting in which we
have access to multiple unlabeled views of the data for learning while only one
view is available for downstream tasks. Previous work on this problem has
proposed several techniques based on deep neural networks, typically involving
either autoencoder-like networks with a reconstruction objective or paired
feedforward networks with a batch-style correlation-based objective. We analyze
several techniques based on prior work, as well as new variants, and compare
them empirically on image, speech, and text tasks. We find an advantage for
correlation-based representation learning, while the best results on most tasks
are obtained with our new variant, deep canonically correlated autoencoders
(DCCAE). We also explore a stochastic optimization procedure for minibatch
correlation-based objectives and discuss the time/performance trade-offs for
kernel-based and neural network-based implementations.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01024</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01028</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Provably Correct MPC Approach to Safety Control of Urban Traffic
  Networks</dc:title>
 <dc:creator>Sadraddini, Sadra</dc:creator>
 <dc:creator>Belta, Calin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Model predictive control (MPC) is a popular strategy for urban traffic
management that is able to incorporate physical and user defined constraints.
However, the current MPC methods rely on finite horizon predictions that are
unable to guarantee desirable behaviors over long periods of time. In this
paper we design an MPC strategy that is guaranteed to keep the evolution of a
network in a desirable yet arbitrary -safe- set, while optimizing a finite
horizon cost function. Our approach relies on finding a robust controlled
invariant set inside the safe set that provides an appropriate terminal
constraint for the MPC optimization problem. An illustrative example is
included.
</dc:description>
 <dc:description>Comment: 16 Pages, single column, shorter version to appear in the proceedings
  of 2016 American Control Conference (ACC), Boston, MA</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01038</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive Multiple Model Estimation of Doubly-Selective Channels for
  OFDM systems</dc:title>
 <dc:creator>Ashour, Mahmoud</dc:creator>
 <dc:creator>El-Keyi, Amr</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose an algorithm for channel estimation, acquisition
and tracking, for orthogonal frequency division multiplexing (OFDM) systems.
The proposed algorithm is suitable for vehicular communications that encounter
very high mobility. A preamble sequence is used to derive an initial estimate
of the channel using least squares (LS). The temporal variation of the channel
within one OFDM symbol is approximated by two complex exponential basis
expansion models (CE-BEM). One of the Fourier-based BEMs is intended to capture
the low frequencies in the channel (slow variations corresponding to low
Doppler), while the other is destined to capture high frequencies (fast
variations corresponding to high Doppler). Kalman filtering is employed to
track the BEM coefficients iteratively on an OFDM symbol-by-symbol basis. An
interactive multiple model (IMM) estimator is implemented to dynamically mix
the estimates obtained by the two Kalman filters, each of which matched to one
of the BEMs. Extensive numerical simulations are conducted to signify the gain
obtained by the proposed combining technique.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01038</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01040</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Ontological Query Processing over Semantically Integrated Life
  Science Datasets using MapReduce</dc:title>
 <dc:creator>Kim, HyeongSik</dc:creator>
 <dc:creator>Anyanwu, Kemafor</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  To address the requirement of enabling a comprehensive perspective of
life-sciences data, Semantic Web technologies have been adopted for
standardized representations of data and linkages between data. This has
resulted in data warehouses such as UniProt, Bio2RDF, and Chem2Bio2RDF, that
integrate different kinds of biological and chemical data using ontologies.
Unfortunately, the ability to process queries over ontologically-integrated
collections remains a challenge, particularly when data is large. The reason is
that besides the traditional challenges of processing graph-structured data,
complete query answering requires inferencing to explicate implicitly
represented facts. Since traditional inferencing techniques like forward
chaining are difficult to scale up, and need to be repeated each time data is
updated, recent focus has been on inferencing that can be supported using
database technologies via query rewriting. However, due to the richness of most
biomedical ontologies relative to other domain ontologies, the queries
resulting from the query rewriting technique are often more complex than
existing query optimization techniques can cope with. This is particularly so
when using the emerging class of cloud data processing platforms for big data
processing due to some additional overhead which they introduce. In this paper,
we present an approach for dealing such complex queries on big data using
MapReduce, along with an evaluation on existing real-world datasets and
benchmark queries.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01042</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Achievability and Converse Bounds for Erd\H{o}s-R\'enyi Graph
  Matching</dc:title>
 <dc:creator>Cullina, Daniel</dc:creator>
 <dc:creator>Kiyavash, Negar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of perfectly recovering the vertex correspondence
between two correlated Erd\H{o}s-R\'enyi (ER) graphs. For a pair of correlated
graphs on the same vertex set, the correspondence between the vertices can be
obscured by randomly permuting the vertex labels of one of the graphs. In some
cases, the structural information in the graphs allow this correspondence to be
recovered. We investigate the information-theoretic threshold for exact
recovery, i.e. the conditions under which the entire vertex correspondence can
be correctly recovered given unbounded computational resources.
  Pedarsani and Grossglauser provided an achievability result of this type.
Their result establishes the scaling dependence of the threshold on the number
of vertices. We improve on their achievability bound. We also provide a
converse bound, establishing conditions under which exact recovery is
impossible. Together, these establish the scaling dependence of the threshold
on the level of correlation between the two graphs. The converse and
achievability bounds differ by a factor of two for sparse, significantly
correlated graphs.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01042</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01052</identifier>
 <datestamp>2016-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Better safe than sorry: Risky function exploitation through safe
  optimization</dc:title>
 <dc:creator>Schulz, Eric</dc:creator>
 <dc:creator>Huys, Quentin J. M.</dc:creator>
 <dc:creator>Bach, Dominik R.</dc:creator>
 <dc:creator>Speekenbrink, Maarten</dc:creator>
 <dc:creator>Krause, Andreas</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Exploration-exploitation of functions, that is learning and optimizing a
mapping between inputs and expected outputs, is ubiquitous to many real world
situations. These situations sometimes require us to avoid certain outcomes at
all cost, for example because they are poisonous, harmful, or otherwise
dangerous. We test participants' behavior in scenarios in which they have to
find the optimum of a function while at the same time avoid outputs below a
certain threshold. In two experiments, we find that Safe-Optimization, a
Gaussian Process-based exploration-exploitation algorithm, describes
participants' behavior well and that participants seem to care firstly whether
a point is safe and then try to pick the optimal point from all such safe
points. This means that their trade-off between exploration and exploitation
can be seen as an intelligent, approximate, and homeostasis-driven strategy.
</dc:description>
 <dc:description>Comment: 6 pages, submitted to Cognitive Science Conference</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-05-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01059</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparative Study of Ranking-based Semantics for Abstract
  Argumentation</dc:title>
 <dc:creator>Bonzon, Elise</dc:creator>
 <dc:creator>Delobelle, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Konieczny, S&#xe9;bastien</dc:creator>
 <dc:creator>Maudet, Nicolas</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Argumentation is a process of evaluating and comparing a set of arguments. A
way to compare them consists in using a ranking-based semantics which
rank-order arguments from the most to the least acceptable ones. Recently, a
number of such semantics have been proposed independently, often associated
with some desirable properties. However, there is no comparative study which
takes a broader perspective. This is what we propose in this work. We provide a
general comparison of all these semantics with respect to the proposed
properties. That allows to underline the differences of behavior between the
existing semantics.
</dc:description>
 <dc:description>Comment: Proceedings of the 30th AAAI Conference on Artificial Intelligence
  (AAAI-2016), Feb 2016, Phoenix, United States</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01059</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01061</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Waveform Optimization for SWIPT with Nonlinear Energy Harvester Modeling</dc:title>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Simultaneous Wireless Information and Power Transfer (SWIPT) has attracted
significant attention in the communication community. The problem of waveform
design for SWIPT has however never been addressed so far. In this paper, a
novel SWIPT transceiver architecture is introduced relying on the superposition
of multisine and OFDM waveforms at the transmitter and a power-splitter
receiver equipped with an energy harvester and an information decoder capable
of cancelling the multisine waveforms. The SWIPT multisine/OFDM waveforms are
optimized so as to maximize the rate-energy region of the whole system. They
are adaptive to the channel state information and result from a posynomial
maximization problem that originates from the non-linearity of the energy
harvester. Numerical results illustrate the performance of the derived
waveforms and SWIPT architecture.
</dc:description>
 <dc:description>Comment: to be presented at 20th International ITG Workshop on Smart Antennas
  (WSA 2016)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01064</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Regret Search for Single- and Multi-Task Optimization</dc:title>
 <dc:creator>Metzen, Jan Hendrik</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We propose minimum regret search (MRS), a novel acquisition function for
Bayesian optimization. MRS bears similarities with information-theoretic
approaches such as entropy search (ES). However, while ES aims in each query at
maximizing the information gain with respect to the global maximum, MRS aims at
minimizing the expected simple regret of its ultimate recommendation for the
optimum. While empirically ES and MRS perform similar in most of the cases, MRS
produces fewer outliers with high simple regret than ES. We provide empirical
results both for a synthetic single-task optimization problem as well as for a
simulated multi-task robotic control problem.
</dc:description>
 <dc:description>Comment: Final version for ICML 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01064</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01065</identifier>
 <datestamp>2016-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Online Data Aggregation in Dynamic Graphs</dc:title>
 <dc:creator>Bramas, Quentin</dc:creator>
 <dc:creator>Masuzawa, Toshimitsu</dc:creator>
 <dc:creator>Tixeuil, S&#xe9;bastien</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We consider the problem of aggregating data in a dynamic graph, that is,
aggregating the data that originates from all nodes in the graph to a specific
node, the sink. We are interested in giving lower bounds for this problem,
under different kinds of adversaries. In our model, nodes are endowed with
unlimited memory and unlimited computational power. Yet, we assume that
communications between nodes are carried out with pairwise interactions, where
nodes can exchange control information before deciding whether they transmit
their data or not, given that each node is allowed to transmit its data at most
once. When a node receives a data from a neighbor, the node may aggregate it
with its own data. We consider three possible adversaries: the online adaptive
adversary, the oblivious adversary , and the randomized adversary that chooses
the pairwise interactions uniformly at random. For the online adaptive and the
oblivious adversary, we give impossibility results when nodes have no knowledge
about the graph and are not aware of the future. Also, we give several tight
bounds depending on the knowledge (be it topology related or time related) of
the nodes. For the randomized adversary, we show that the Gathering algorithm,
which always commands a node to transmit, is optimal if nodes have no knowledge
at all. Also, we propose an algorithm called Waiting Greedy, where a node
either waits or transmits depending on some parameter, that is optimal when
each node knows its future pairwise interactions with the sink.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-10-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01065</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01066</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Beamforming for SWIPT Systems with Non-linear Energy Harvesting
  Model</dc:title>
 <dc:creator>Boshkovska, Elena</dc:creator>
 <dc:creator>Koelpin, Alexander</dc:creator>
 <dc:creator>Ng, Derrick Wing Kwan</dc:creator>
 <dc:creator>Zlatanov, Nikola</dc:creator>
 <dc:creator>Schober, Robert</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper investigates resource allocation for simultaneous wireless
information and power transfer (SWIPT) downlink systems based on a non-linear
energy harvesting model. The resource allocation algorithm design is formulated
as a non-convex optimization problem for the maximization of the total
harvested power. The proposed problem formulation not only takes into account
imperfect channel state information (CSI) but also guarantees the
quality-of-service (QoS) of information transfer. A novel iterative algorithm
is proposed to obtain the globally optimal solution of the considered
non-convex optimization problem. In each iteration, a rank-constrained
semidefinite program (SDP) is solved optimally by SDP relaxation. Simulation
results demonstrate the significant gains in harvested power and the robustness
against CSI imperfection for the proposed optimal resource allocation, compared
to a baseline scheme designed for perfect CSI and the conventional linear
energy harvesting model.
</dc:description>
 <dc:description>Comment: Invited paper, accepted for presentation, IEEE SPAWC 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01066</dc:identifier>
 <dc:identifier>doi:10.1109/SPAWC.2016.7536860</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01075</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Rapid Transformation of Ideas into Software</dc:title>
 <dc:creator>Afshari, Mehrdad</dc:creator>
 <dc:creator>Su, Zhendong</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A key mission of computer science is to enable people realize their creative
ideas as naturally and painlessly as possible. Software engineering is at the
center of this mission -- software technologies enable reification of ideas
into working systems. As computers become ubiquitous, both in availability and
the aspects of human lives they touch, the quantity and diversity of ideas also
rapidly grow. Our programming systems and technologies need to evolve to make
this reification process -- transforming ideas to software -- as quick and
accessible as possible.
  The goal of this paper is twofold. First, it advocates and highlights the
&quot;transforming ideas to software&quot; mission as a moonshot for software engineering
research. This is a long-term direction for the community, and there is no
silver bullet that can get us there. To make this mission a reality, as a
community, we need to improve the status quo across many dimensions. Thus, the
second goal is to outline a number of directions to modernize our contemporary
programming technologies for decades to come, describe work that has been
undertaken along those vectors, and pinpoint critical challenges.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01075</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01084</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple fluidic digital half-adder</dc:title>
 <dc:creator>Morgan, Alex J. L.</dc:creator>
 <dc:creator>Barrow, David A.</dc:creator>
 <dc:creator>Adamatzky, Andrew</dc:creator>
 <dc:creator>Hanczyc, Martin M.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  A fluidic one-bit half-adder is made of five channels which intersect at a
junction. Two channels are inputs, two channels are outputs and one channel is
the drain. The channels direct fluid from input fragments to output fragments
and the streams of fluid interact at the junctions. Binary signals are
represented by water droplets introduced in the input channels: presence of a
droplet in an input or output segments symbolises logical {\sc True}, absence
--- {\sc False}. The droplets travel along channels by following a path of
least resistance unless deflected at the junction. We demonstrate the function
of the half-adder in both computer modelling and laboratory experiments, and
propose a design of a one-bit full adder based on simulation.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01103</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Winning Arguments: Interaction Dynamics and Persuasion Strategies in
  Good-faith Online Discussions</dc:title>
 <dc:creator>Tan, Chenhao</dc:creator>
 <dc:creator>Niculae, Vlad</dc:creator>
 <dc:creator>Danescu-Niculescu-Mizil, Cristian</dc:creator>
 <dc:creator>Lee, Lillian</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Changing someone's opinion is arguably one of the most important challenges
of social interaction. The underlying process proves difficult to study: it is
hard to know how someone's opinions are formed and whether and how someone's
views shift. Fortunately, ChangeMyView, an active community on Reddit, provides
a platform where users present their own opinions and reasoning, invite others
to contest them, and acknowledge when the ensuing discussions change their
original views. In this work, we study these interactions to understand the
mechanisms behind persuasion.
  We find that persuasive arguments are characterized by interesting patterns
of interaction dynamics, such as participant entry-order and degree of
back-and-forth exchange. Furthermore, by comparing similar counterarguments to
the same opinion, we show that language factors play an essential role. In
particular, the interplay between the language of the opinion holder and that
of the counterargument provides highly predictive cues of persuasiveness.
Finally, since even in this favorable setting people may not be persuaded, we
investigate the problem of determining whether someone's opinion is susceptible
to being changed at all. For this more difficult task, we show that stylistic
choices in how the opinion is expressed carry predictive power.
</dc:description>
 <dc:description>Comment: 12 pages, 10 figures, to appear in Proceedings of WWW 2016, data and
  more at https://chenhaot.com/pages/changemyview.html (v2 made a minor
  correction on submission rules in ChangeMyView.)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01103</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2883081</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01107</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Do Cascades Recur?</dc:title>
 <dc:creator>Cheng, Justin</dc:creator>
 <dc:creator>Adamic, Lada A</dc:creator>
 <dc:creator>Kleinberg, Jon</dc:creator>
 <dc:creator>Leskovec, Jure</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  Cascades of information-sharing are a primary mechanism by which content
reaches its audience on social media, and an active line of research has
studied how such cascades, which form as content is reshared from person to
person, develop and subside. In this paper, we perform a large-scale analysis
of cascades on Facebook over significantly longer time scales, and find that a
more complex picture emerges, in which many large cascades recur, exhibiting
multiple bursts of popularity with periods of quiescence in between. We
characterize recurrence by measuring the time elapsed between bursts, their
overlap and proximity in the social network, and the diversity in the
demographics of individuals participating in each peak. We discover that
content virality, as revealed by its initial popularity, is a main driver of
recurrence, with the availability of multiple copies of that content helping to
spark new bursts. Still, beyond a certain popularity of content, the rate of
recurrence drops as cascades start exhausting the population of interested
individuals. We reproduce these observed patterns in a simple model of content
recurrence simulated on a real social network. Using only characteristics of a
cascade's initial burst, we demonstrate strong performance in predicting
whether it will recur in the future.
</dc:description>
 <dc:description>Comment: WWW 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01107</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01116</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Index for Weighted Sequences</dc:title>
 <dc:creator>Barton, Carl</dc:creator>
 <dc:creator>Kociumaka, Tomasz</dc:creator>
 <dc:creator>Pissis, Solon P.</dc:creator>
 <dc:creator>Radoszewski, Jakub</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The problem of finding factors of a text string which are identical or
similar to a given pattern string is a central problem in computer science. A
generalised version of this problem consists in implementing an index over the
text to support efficient on-line pattern queries. We study this problem in the
case where the text is weighted: for every position of the text and every
letter of the alphabet a probability of occurrence of this letter at this
position is given. Sequences of this type, also called position weight
matrices, are commonly used to represent imprecise or uncertain data. A
weighted sequence may represent many different strings, each with probability
of occurrence equal to the product of probabilities of its letters at
subsequent positions. Given a probability threshold $1/z$, we say that a
pattern string $P$ matches a weighted text at position $i$ if the product of
probabilities of the letters of $P$ at positions $i,\ldots,i+|P|-1$ in the text
is at least $1/z$. In this article, we present an $O(nz)$-time construction of
an $O(nz)$-sized index that can answer pattern matching queries in a weighted
text in optimal time improving upon the state of the art by a factor of $z \log
z$. Other applications of this data structure include an $O(nz)$-time
construction of the weighted prefix table and an $O(nz)$-time computation of
all covers of a weighted sequence, which improve upon the state of the art by
the same factor.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01116</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01125</identifier>
 <datestamp>2017-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fitting a 3D Morphable Model to Edges: A Comparison Between Hard and
  Soft Correspondences</dc:title>
 <dc:creator>Bas, Anil</dc:creator>
 <dc:creator>Smith, William A. P.</dc:creator>
 <dc:creator>Bolkart, Timo</dc:creator>
 <dc:creator>Wuhrer, Stefanie</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We propose a fully automatic method for fitting a 3D morphable model to
single face images in arbitrary pose and lighting. Our approach relies on
geometric features (edges and landmarks) and, inspired by the iterated closest
point algorithm, is based on computing hard correspondences between model
vertices and edge pixels. We demonstrate that this is superior to previous work
that uses soft correspondences to form an edge-derived cost surface that is
minimised by nonlinear optimisation.
</dc:description>
 <dc:description>Comment: To appear in ACCV 2016 Workshop on Facial Informatics</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-10-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01125</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-54427-4_28</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01128</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Max Consensus in Sensor Networks: Non-linear Bounded Transmission and
  Additive Noise</dc:title>
 <dc:creator>Zhang, Sai</dc:creator>
 <dc:creator>Tepedelenlioglu, Cihan</dc:creator>
 <dc:creator>Banavar, Mahesh K.</dc:creator>
 <dc:creator>Spanias, Andreas</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A distributed consensus algorithm for estimating the maximum value of the
initial measurements in a sensor network with communication noise is proposed.
In the absence of communication noise, max estimation can be done by updating
the state value with the largest received measurements in every iteration at
each sensor. In the presence of communication noise, however, the maximum
estimate will incorrectly drift and the estimate at each sensor will diverge.
As a result, a soft-max approximation together with a non-linear consensus
algorithm is introduced herein. A design parameter controls the trade-off
between the soft-max error and convergence speed. An analysis of this trade-off
gives a guideline towards how to choose the design parameter for the max
estimate. We also show that if some prior knowledge of the initial measurements
is available, the consensus process can converge faster by using an optimal
step size in the iterative algorithm. A shifted non-linear bounded transmit
function is also introduced for faster convergence when sensor nodes have some
prior knowledge of the initial measurements. Simulation results corroborating
the theory are also provided.
</dc:description>
 <dc:description>Comment: 8 pages, 8 figures</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01128</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01130</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GraphPrints: Towards a Graph Analytic Method for Network Anomaly
  Detection</dc:title>
 <dc:creator>Harshaw, Christopher R.</dc:creator>
 <dc:creator>Bridges, Robert A.</dc:creator>
 <dc:creator>Iannacone, Michael D.</dc:creator>
 <dc:creator>Reed, Joel W.</dc:creator>
 <dc:creator>Goodall, John R.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper introduces a novel graph-analytic approach for detecting anomalies
in network flow data called GraphPrints. Building on foundational
network-mining techniques, our method represents time slices of traffic as a
graph, then counts graphlets -- small induced subgraphs that describe local
topology. By performing outlier detection on the sequence of graphlet counts,
anomalous intervals of traffic are identified, and furthermore, individual IPs
experiencing abnormal behavior are singled-out. Initial testing of GraphPrints
is performed on real network data with an implanted anomaly. Evaluation shows
false positive rates bounded by 2.84% at the time-interval level, and 0.05% at
the IP-level with 100% true positive rates at both.
</dc:description>
 <dc:description>Comment: 4 pages submitted to Cyber &amp; Information Security Research Conference
  2016, ACM</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01130</dc:identifier>
 <dc:identifier>doi:10.1145/1235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01132</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive algorithms: from pool to stream</dc:title>
 <dc:creator>Sabato, Sivan</dc:creator>
 <dc:creator>Hess, Tom</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider interactive algorithms in the pool-based setting, and in the
stream-based setting. Interactive algorithms observe suggested elements
(representing actions or queries), and interactively select some of them and
receive responses. Pool-based algorithms can select elements at any order,
while stream-based algorithms observe elements in sequence, and can only select
elements immediately after observing them. We assume that the suggested
elements are generated independently from some source distribution, and ask
what is the stream size required for emulating a pool algorithm with a given
pool size. We provide algorithms and matching lower bounds for general pool
algorithms, and for utility-based pool algorithms. We further show that a
maximal gap between the two settings exists also in the special case of active
learning for binary classification.
</dc:description>
 <dc:description>Comment: Appearing in COLT 2016</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01132</dc:identifier>
 <dc:identifier>Proceedings of the 29th Annual Conference on Learning Theory
  (COLT), JMLR Workshop and Conference Proceedings 49:1419-1439, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01137</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Dual Embedding Space Model for Document Ranking</dc:title>
 <dc:creator>Mitra, Bhaskar</dc:creator>
 <dc:creator>Nalisnick, Eric</dc:creator>
 <dc:creator>Craswell, Nick</dc:creator>
 <dc:creator>Caruana, Rich</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  A fundamental goal of search engines is to identify, given a query, documents
that have relevant text. This is intrinsically difficult because the query and
the document may use different vocabulary, or the document may contain query
words without being relevant. We investigate neural word embeddings as a source
of evidence in document ranking. We train a word2vec embedding model on a large
unlabelled query corpus, but in contrast to how the model is commonly used, we
retain both the input and the output projections, allowing us to leverage both
the embedding spaces to derive richer distributional relationships. During
ranking we map the query words into the input space and the document words into
the output space, and compute a query-document relevance score by aggregating
the cosine similarities across all the query-document word pairs.
  We postulate that the proposed Dual Embedding Space Model (DESM) captures
evidence on whether a document is about a query term in addition to what is
modelled by traditional term-frequency based approaches. Our experiments show
that the DESM can re-rank top documents returned by a commercial Web search
engine, like Bing, better than a term-matching based signal like TF-IDF.
However, when ranking a larger set of candidate documents, we find the
embeddings-based approach is prone to false positives, retrieving documents
that are only loosely related to the query. We demonstrate that this problem
can be solved effectively by ranking based on a linear mixture of the DESM and
the word counting features.
</dc:description>
 <dc:description>Comment: This paper is an extended evaluation and analysis of the model
  proposed in a poster to appear in WWW'16, April 11 - 15, 2016, Montreal,
  Canada</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01137</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01139</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Throughput Analysis of Massive MIMO Uplink with Low-Resolution ADCs</dc:title>
 <dc:creator>Jacobsson, Sven</dc:creator>
 <dc:creator>Durisi, Giuseppe</dc:creator>
 <dc:creator>Coldrey, Mikael</dc:creator>
 <dc:creator>Gustavsson, Ulf</dc:creator>
 <dc:creator>Studer, Christoph</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the uplink throughput achievable by a multiple-user (MU)
massive multiple-input multiple-output (MIMO) system in which the base station
is equipped with a large number of low-resolution analog-to-digital converters
(ADCs). Our focus is on the case where neither the transmitter nor the receiver
have any a priori channel state information. This implies that the fading
realizations have to be learned through pilot transmission followed by channel
estimation at the receiver, based on coarsely quantized observations. We
propose a novel channel estimator, based on Bussgang's decomposition, and a
novel approximation to the rate achievable with finite-resolution ADCs, both
for the case of finite-cardinality constellations and of Gaussian inputs, that
is accurate for a broad range of system parameters. Through numerical results,
we illustrate that, for the 1-bit quantized case, pilot-based channel
estimation together with maximal-ratio combing or zero-forcing detection
enables reliable multi-user communication with high-order constellations in
spite of the severe nonlinearity introduced by the ADCs. Furthermore, we show
that the rate achievable in the infinite-resolution (no quantization) case can
be approached using ADCs with only a few bits of resolution. We finally
investigate the robustness of low-ADC-resolution MU-MIMO uplink against receive
power imbalances between the different users, caused for example by imperfect
power control.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2017-04-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01139</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2017.2691318</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01149</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Index Coding: Existence and Construction</dc:title>
 <dc:creator>Ong, Lawrence</dc:creator>
 <dc:creator>Vellambi, Badri N.</dc:creator>
 <dc:creator>Yeoh, Phee Lep</dc:creator>
 <dc:creator>Kliewer, J&#xf6;rg</dc:creator>
 <dc:creator>Yuan, Jinhong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the construction of weakly-secure index codes for a sender to
send messages to multiple receivers with side information in the presence of an
eavesdropper. We derive a sufficient and necessary condition for the existence
of index codes that are secure against an eavesdropper with access to any
subset of messages of cardinality $t$, for any fixed $t$. In contrast to the
benefits of using random keys in secure network coding, we prove that random
keys do not promote security in three classes of index-coding instances.
</dc:description>
 <dc:description>Comment: Author final manuscript (to be presented at the 2016 IEEE
  International Symposium on Information Theory)</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01149</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541816</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01154</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The value of Side Information in Secondary Spectrum Markets</dc:title>
 <dc:creator>Ghosh, Arnob</dc:creator>
 <dc:creator>Sarkar, Saswati</dc:creator>
 <dc:creator>Berry, Randall</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In a secondary spectrum market primaries set prices for their unused channels
to the secondaries. The payoff of a primary depends on the availability of
unused channels of its competitors. We consider a model were a primary can
acquire its competitor's channel state information (C-CSI) at a cost. We
formulate a game between two primaries where each primary decides whether to
acquire C-CSI or not and then selects its price based on that. We first
characterize the Nash Equilibrium (NE) of this game for a symmetric model where
the C-CSI is perfect. We show that the payoff of a primary is independent of
the C-CSI acquisition cost. We then generalize our analysis to allow for
imperfect estimation and cases where the two primaries have different C-CSI
costs or different channel availabilities. Our results show interestingly that
the payoff of a primary increases when there is estimation error. We also show
that surprisingly, the expected payoff of a primary may decrease when the C-CSI
acquisition cost decreases when primaries have different availabilities.
</dc:description>
 <dc:description>Comment: Shorter version will be presented in ISIT'16. Submitted to JSAC
  Special Issue on Spectrum Sharing, 2016. Impacts of Estimation errors,
  different C-CSI acquisition costs and different availabilities are now
  considered</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-10-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01154</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01161</identifier>
 <datestamp>2016-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Scheduling and Groupping for Machine-TYpe
  Communications over Cellular Networks</dc:title>
 <dc:creator>Azari, Amin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, energy-efficient scheduling for grouped machine-type devices
deployed in cellular networks is investigated. We introduce a scheduling-based
cooperation incentive scheme which enables machine nodes to organize themselves
locally, create machine groups, and communicate through group representatives
to the base station. This scheme benefits from a novel scheduler design which
takes into account the cooperation level of each node, reimburses the extra
energy consumptions of group representatives, and maximizes the network
lifetime. As reusing cellular uplink resources for communications inside the
groups degrades the Quality of Service (QoS) of the primary users, analytical
results are provided which present a tradeoff between maximum allowable number
of simultaneously active machine groups in a given cell and QoS of the primary
users. Furthermore, we extend our derived solutions for the existing cellular
networks, propose a cooperation-incentive LTE scheduler, and present our
simulation results in the context of LTE. The simulation results show that the
proposed solutions significantly prolong the network lifetime. Also, it is
shown that under certain circumstances, reusing uplink resource by machine
devices can degrade the outage performance of the primary users significantly,
and hence, coexistence management of machine devices and cellular users is of
paramount importance for next generations of cellular networks in order to
enable group-based machine-type communications while guaranteeing QoS for the
primary users.
</dc:description>
 <dc:description>Comment: Accepted in Elsevier Ad Hoc Journal</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01161</dc:identifier>
 <dc:identifier>doi:10.1016/j.adhoc.2016.02.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01164</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Single-Solution Hypervolume Maximization and its use for Improving
  Generalization of Neural Networks</dc:title>
 <dc:creator>Miranda, Conrado S.</dc:creator>
 <dc:creator>Von Zuben, Fernando J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper introduces the hypervolume maximization with a single solution as
an alternative to the mean loss minimization. The relationship between the two
problems is proved through bounds on the cost function when an optimal solution
to one of the problems is evaluated on the other, with a hyperparameter to
control the similarity between the two problems. This same hyperparameter
allows higher weight to be placed on samples with higher loss when computing
the hypervolume's gradient, whose normalized version can range from the mean
loss to the max loss. An experiment on MNIST with a neural network is used to
validate the theory developed, showing that the hypervolume maximization can
behave similarly to the mean loss minimization and can also provide better
performance, resulting on a 20% reduction of the classification error on the
test set.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01164</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01168</identifier>
 <datestamp>2016-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Discriminative Features via Label Consistent Neural Network</dc:title>
 <dc:creator>Jiang, Zhuolin</dc:creator>
 <dc:creator>Wang, Yaming</dc:creator>
 <dc:creator>Davis, Larry</dc:creator>
 <dc:creator>Andrews, Walt</dc:creator>
 <dc:creator>Rozgic, Viktor</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Deep Convolutional Neural Networks (CNN) enforces supervised information only
at the output layer, and hidden layers are trained by back propagating the
prediction error from the output layer without explicit supervision. We propose
a supervised feature learning approach, Label Consistent Neural Network, which
enforces direct supervision in late hidden layers. We associate each neuron in
a hidden layer with a particular class label and encourage it to be activated
for input signals from the same class. More specifically, we introduce a label
consistency regularization called &quot;discriminative representation error&quot; loss
for late hidden layers and combine it with classification error loss to build
our overall objective function. This label consistency constraint alleviates
the common problem of gradient vanishing and tends to faster convergence; it
also makes the features derived from late hidden layers discriminative enough
for classification even using a simple $k$-NN classifier, since input signals
from the same class will have very similar representations. Experimental
results demonstrate that our approach achieves state-of-the-art performances on
several public benchmarks for action and object category recognition.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:date>2016-06-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01168</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01170</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Results and Analysis of SyGuS-Comp'15</dc:title>
 <dc:creator>Alur, Rajeev</dc:creator>
 <dc:creator>Fisman, Dana</dc:creator>
 <dc:creator>Singh, Rishabh</dc:creator>
 <dc:creator>Solar-Lezama, Armando</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>I.2.2, D.2.4, F.3.1</dc:subject>
 <dc:description>  Syntax-Guided Synthesis (SyGuS) is the computational problem of finding an
implementation f that meets both a semantic constraint given by a logical
formula $\varphi$ in a background theory T, and a syntactic constraint given by
a grammar G, which specifies the allowed set of candidate implementations. Such
a synthesis problem can be formally defined in SyGuS-IF, a language that is
built on top of SMT-LIB.
  The Syntax-Guided Synthesis Competition (SyGuS-comp) is an effort to
facilitate, bring together and accelerate research and development of efficient
solvers for SyGuS by providing a platform for evaluating different synthesis
techniques on a comprehensive set of benchmarks. In this year's competition we
added two specialized tracks: a track for conditional linear arithmetic, where
the grammar need not be specified and is implicitly assumed to be that of the
LIA logic of SMT-LIB, and a track for invariant synthesis problems, with
special constructs conforming to the structure of an invariant synthesis
problem. This paper presents and analyzes the results of SyGuS-comp'15.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01170</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 3-26</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01171</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Second Reactive Synthesis Competition (SYNTCOMP 2015)</dc:title>
 <dc:creator>Jacobs, Swen</dc:creator>
 <dc:creator>Bloem, Roderick</dc:creator>
 <dc:creator>Brenguier, Romain</dc:creator>
 <dc:creator>K&#xf6;nighofer, Robert</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Ryzhyk, Leonid</dc:creator>
 <dc:creator>Sankur, Ocan</dc:creator>
 <dc:creator>Seidl, Martina</dc:creator>
 <dc:creator>Tentrup, Leander</dc:creator>
 <dc:creator>Walker, Adam</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We report on the design and results of the second reactive synthesis
competition (SYNTCOMP 2015). We describe our extended benchmark library, with 6
completely new sets of benchmarks, and additional challenging instances for 4
of the benchmark sets that were already used in SYNTCOMP 2014. To enhance the
analysis of experimental results, we introduce an extension of our benchmark
format with meta-information, including a difficulty rating and a reference
size for solutions. Tools are evaluated on a set of 250 benchmarks, selected to
provide a good coverage of benchmarks from all classes and difficulties. We
report on changes of the evaluation scheme and the experimental setup. Finally,
we describe the entrants into SYNTCOMP 2015, as well as the results of our
experimental evaluation. In our analysis, we emphasize progress over the tools
that participated last year.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01171</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 27-57</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01172</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Synthesizing a Lego Forklift Controller in GR(1): A Case Study</dc:title>
 <dc:creator>Maoz, Shahar</dc:creator>
 <dc:creator>Ringert, Jan Oliver</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Reactive synthesis is an automated procedure to obtain a
correct-by-construction reactive system from a given specification. GR(1) is a
well-known fragment of linear temporal logic (LTL) where synthesis is possible
using a polynomial symbolic algorithm. We conducted a case study to learn about
the challenges that software engineers may face when using GR(1) synthesis for
the development of a reactive robotic system. In the case study we developed
two variants of a forklift controller, deployed on a Lego robot. The case study
employs LTL specification patterns as an extension of the GR(1) specification
language, an examination of two specification variants for execution
scheduling, traceability from the synthesized controller to constraints in the
specification, and generated counter strategies to support understanding
reasons for unrealizability. We present the specifications we developed, our
observations, and challenges faced during the case study.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01172</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 58-72</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01173</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A multi-paradigm language for reactive synthesis</dc:title>
 <dc:creator>Filippidis, Ioannis</dc:creator>
 <dc:creator>Murray, Richard M.</dc:creator>
 <dc:creator>Holzmann, Gerard J.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes a language for describing reactive synthesis problems
that integrates imperative and declarative elements. The semantics is defined
in terms of two-player turn-based infinite games with full information.
Currently, synthesis tools accept linear temporal logic (LTL) as input, but
this description is less structured and does not facilitate the expression of
sequential constraints. This motivates the use of a structured programming
language to specify synthesis problems. Transition systems and guarded commands
serve as imperative constructs, expressed in a syntax based on that of the
modeling language Promela. The syntax allows defining which player controls
data and control flow, and separating a program into assumptions and
guarantees. These notions are necessary for input to game solvers. The
integration of imperative and declarative paradigms allows using the paradigm
that is most appropriate for expressing each requirement. The declarative part
is expressed in the LTL fragment of generalized reactivity(1), which admits
efficient synthesis algorithms, extended with past LTL. The implementation
translates Promela to input for the Slugs synthesizer and is written in Python.
The AMBA AHB bus case study is revisited and synthesized efficiently,
identifying the need to reorder binary decision diagrams during strategy
construction, in order to prevent the exponential blowup observed in previous
work.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01173</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 73-97</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01174</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compositional Algorithms for Succinct Safety Games</dc:title>
 <dc:creator>Brenguier, Romain</dc:creator>
 <dc:creator>P&#xe9;rez, Guillermo A.</dc:creator>
 <dc:creator>Raskin, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Sankur, Ocan</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.3.1,B.1.2,B.6.3</dc:subject>
 <dc:description>  We study the synthesis of circuits for succinct safety specifications given
in the AIG format. We show how AIG safety specifications can be decomposed
automatically into sub specifications. Then we propose symbolic compositional
algorithms to solve the synthesis problem compositionally starting for the
sub-specifications. We have evaluated the compositional algorithms on a set of
benchmarks including those proposed for the first synthesis competition
organised in 2014 by the Synthesis Workshop affiliated to the CAV conference.
We show that a large number of benchmarks can be decomposed automatically and
solved more efficiently with the compositional algorithms that we propose in
this paper.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01174</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 98-111</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01175</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Specification Format for Reactive Synthesis Problems</dc:title>
 <dc:creator>Khalimov, Ayrat</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Automatic synthesis from a given specification automatically constructs
correct implementation. This frees the user from the mundane implementation
work, but still requires the specification. But is specifying easier than
implementing? In this paper, we propose a user-friendly format to ease the
specification work, in particularly, that of specifying partial
implementations. Also, we provide scripts to convert specifications in the new
format into the SYNTCOMP format, thus benefiting from state of the art
synthesizers.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01175</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 112-119</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01176</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The complexity of approximations for epistemic synthesis (extended
  abstract)</dc:title>
 <dc:creator>Huang, Xiaowei</dc:creator>
 <dc:creator>van der Meyden, Ron</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  Epistemic protocol specifications allow programs, for settings in which
multiple agents act with incomplete information, to be described in terms of
how actions are related to what the agents know. They are a variant of the
knowledge-based programs of Fagin et al [Distributed Computing, 1997],
motivated by the complexity of synthesizing implementations in that framework.
The paper proposes an approach to the synthesis of implementations of epistemic
protocol specifications, that reduces the problem of finding an implementation
to a sequence of model checking problems in approximations of the ultimate
system being synthesized. A number of ways to construct such approximations is
considered, and these are studied for the complexity of the associated model
checking problems. The outcome of the study is the identification of the best
approximations with the property of being PTIME implementable.
</dc:description>
 <dc:description>Comment: In Proceedings SYNT 2015, arXiv:1602.00786</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01176</dc:identifier>
 <dc:identifier>EPTCS 202, 2016, pp. 120-137</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.202.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01178</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GECKA3D: A 3D Game Engine for Commonsense Knowledge Acquisition</dc:title>
 <dc:creator>Cambria, Erik</dc:creator>
 <dc:creator>Nguyen, Tam V.</dc:creator>
 <dc:creator>Cheng, Brian</dc:creator>
 <dc:creator>Kwok, Kenneth</dc:creator>
 <dc:creator>Sepulveda, Jose</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Commonsense knowledge representation and reasoning is key for tasks such as
artificial intelligence and natural language understanding. Since commonsense
consists of information that humans take for granted, gathering it is an
extremely difficult task. In this paper, we introduce a novel 3D game engine
for commonsense knowledge acquisition (GECKA3D) which aims to collect
commonsense from game designers through the development of serious games.
GECKA3D integrates the potential of serious games and games with a purpose.
This provides a platform for the acquisition of re-usable and multi-purpose
knowledge, and also enables the development of games that can provide
entertainment value and teach players something meaningful about the actual
world they live in.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01197</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Sparse Neighbor Approximation for Imbalanced Learning</dc:title>
 <dc:creator>Huang, Chen</dc:creator>
 <dc:creator>Loy, Chen Change</dc:creator>
 <dc:creator>Tang, Xiaoou</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Data imbalance is common in many vision tasks where one or more classes are
rare. Without addressing this issue conventional methods tend to be biased
toward the majority class with poor predictive accuracy for the minority class.
These methods further deteriorate on small, imbalanced data that has a large
degree of class overlap. In this study, we propose a novel discriminative
sparse neighbor approximation (DSNA) method to ameliorate the effect of
class-imbalance during prediction. Specifically, given a test sample, we first
traverse it through a cost-sensitive decision forest to collect a good subset
of training examples in its local neighborhood. Then we generate from this
subset several class-discriminating but overlapping clusters and model each as
an affine subspace. From these subspaces, the proposed DSNA iteratively seeks
an optimal approximation of the test sample and outputs an unbiased prediction.
We show that our method not only effectively mitigates the imbalance issue, but
also allows the prediction to extrapolate to unseen data. The latter capability
is crucial for achieving accurate prediction on small dataset with limited
samples. The proposed imbalanced learning method can be applied to both
classification and regression tasks at a wide range of imbalance levels. It
significantly outperforms the state-of-the-art methods that do not possess an
imbalance handling mechanism, and is found to perform comparably or even better
than recent deep learning methods by using hand-crafted features only.
</dc:description>
 <dc:description>Comment: 11 pages, 10 figures, In submission</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01198</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>k-variates++: more pluses in the k-means++</dc:title>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:creator>Canyasse, Rapha&#xeb;l</dc:creator>
 <dc:creator>Boreli, Roksana</dc:creator>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:subject>I.5.3</dc:subject>
 <dc:description>  k-means++ seeding has become a de facto standard for hard clustering
algorithms. In this paper, our first contribution is a two-way generalisation
of this seeding, k-variates++, that includes the sampling of general densities
rather than just a discrete set of Dirac densities anchored at the point
locations, and a generalisation of the well known Arthur-Vassilvitskii (AV)
approximation guarantee, in the form of a bias+variance approximation bound of
the global optimum. This approximation exhibits a reduced dependency on the
&quot;noise&quot; component with respect to the optimal potential --- actually
approaching the statistical lower bound. We show that k-variates++ reduces to
efficient (biased seeding) clustering algorithms tailored to specific
frameworks; these include distributed, streaming and on-line clustering, with
direct approximation results for these algorithms. Finally, we present a novel
application of k-variates++ to differential privacy. For either the specific
frameworks considered here, or for the differential privacy setting, there is
little to no prior results on the direct application of k-means++ and its
approximation bounds --- state of the art contenders appear to be significantly
more complex and / or display less favorable (approximation) properties. We
stress that our algorithms can still be run in cases where there is \textit{no}
closed form solution for the population minimizer. We demonstrate the
applicability of our analysis via experimental evaluation on several domains
and settings, displaying competitive performances vs state of the art.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01198</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01202</identifier>
 <datestamp>2016-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Locally rewritable codes for resistive memories</dc:title>
 <dc:creator>Kim, Yongjune</dc:creator>
 <dc:creator>Sharma, Abhishek A.</dc:creator>
 <dc:creator>Mateescu, Robert</dc:creator>
 <dc:creator>Song, Seung-Hwan</dc:creator>
 <dc:creator>Bandic, Zvonimir Z.</dc:creator>
 <dc:creator>Bain, James A.</dc:creator>
 <dc:creator>Kumar, B. V. K. Vijaya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We propose locally rewritable codes (LWC) for resistive memories inspired by
locally repairable codes (LRC) for distributed storage systems. Small values of
repair locality of LRC enable fast repair of a single failed node since the
lost data in the failed node can be recovered by accessing only a small
fraction of other nodes. By using rewriting locality, LWC can improve endurance
limit and power consumption which are major challenges for resistive memories.
We point out the duality between LRC and LWC, which indicates that existing
construction methods of LRC can be applied to construct LWC.
</dc:description>
 <dc:description>Comment: accepted by IEEE International Conference on Communications (ICC)
  2016</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01202</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7510727</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01205</identifier>
 <datestamp>2016-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Citations to articles citing Benford's law: a Benford analysis</dc:title>
 <dc:creator>Mir, Tariq Ahmad</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The occurrence of first significant digits of numbers in large data is often
governed by a logarithmically decreasing distribution called Benford's law
(BL), reported first by S. Newcomb (SN) and many decades later independently by
F. Benford (FB). Due to its counter-intuitiveness the law was ignored for
decades as a mere curious observation. However, an indication of its remarkable
resurgence is the huge swell in the number of citations received by the papers
of SN/FB. The law has come a long way, from obscurity to now being a regular
subject of books, peer reviewed papers, patents, blogs and news. Here, we use
Google Scholar (GS) to collect the data on the number of citations received by
the articles citing the original paper of SN/FB and then investigate whether
the leading digits of this citations data are distributed according to the law
they discovered. We find that the citations data of literature on BL is in
remarkable agreement with the predictions of the law.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figure, 7 tables, 37 references</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01208</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spatial Concept Acquisition for a Mobile Robot that Integrates
  Self-Localization and Unsupervised Word Discovery from Spoken Sentences</dc:title>
 <dc:creator>Taniguchi, Akira</dc:creator>
 <dc:creator>Taniguchi, Tadahiro</dc:creator>
 <dc:creator>Inamura, Tetsunari</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  In this paper, we propose a novel unsupervised learning method for the
lexical acquisition of words related to places visited by robots, from human
continuous speech signals. We address the problem of learning novel words by a
robot that has no prior knowledge of these words except for a primitive
acoustic model. Further, we propose a method that allows a robot to effectively
use the learned words and their meanings for self-localization tasks. The
proposed method is nonparametric Bayesian spatial concept acquisition method
(SpCoA) that integrates the generative model for self-localization and the
unsupervised word segmentation in uttered sentences via latent variables
related to the spatial concept. We implemented the proposed method SpCoA on
SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile
robot in a real environment. Further, we conducted experiments for evaluating
the performance of SpCoA. The experimental results showed that SpCoA enabled
the robot to acquire the names of places from speech sentences. They also
revealed that the robot could effectively utilize the acquired spatial concepts
and reduce the uncertainty in self-localization.
</dc:description>
 <dc:description>Comment: This paper was accepted in the IEEE Transactions on Cognitive and
  Developmental Systems. (04-May-2016)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01208</dc:identifier>
 <dc:identifier>doi:10.1109/TCDS.2016.2565542</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01218</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Accuracy of Interference Models in Wireless Communications</dc:title>
 <dc:creator>Shokri-Ghadikolaei, Hossein</dc:creator>
 <dc:creator>Fischione, Carlo</dc:creator>
 <dc:creator>Modiano, Eytan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We develop a new framework for measuring and comparing the accuracy of any
wireless interference models used in the analysis and design of wireless
networks. Our approach is based on a new index that assesses the ability of the
interference model to correctly predict harmful interference events, i.e., link
outages. We use this new index to quantify the accuracy of various interference
models used in the literature, under various scenarios such as Rayleigh fading
wireless channels, directional antennas, and blockage (impenetrable obstacles)
in the network. Our analysis reveals that in highly directional antenna
settings with obstructions, even simple interference models (e.g., the
classical protocol model) are accurate, while with omnidirectional antennas,
more sophisticated and complex interference models (e.g., the classical
physical model) are necessary. Our new approach makes it possible to adopt the
appropriate interference model of adequate accuracy and simplicity in different
settings.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures, accepted in IEEE ICC 2016</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01224</identifier>
 <datestamp>2016-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smooth surface interpolation using patches with rational offsets</dc:title>
 <dc:creator>L&#xe1;vi&#x10d;ka, Miroslav</dc:creator>
 <dc:creator>&#x160;&#xed;r, Zbyn&#x11b;k</dc:creator>
 <dc:creator>Vr&#x161;ek, Jan</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a new method for the interpolation of given data points and
associated normals with surface parametric patches with rational normal fields.
We give some arguments why a dual approach is the most convenient for these
surfaces, which are traditionally called Pythagorean normal vector (PN)
surfaces. Our construction is based on the isotropic model of the dual space to
which the original data are pushed. Then the bicubic Coons patches are
constructed in the isotropic space and then pulled back to the standard three
dimensional space. As a result we obtain the patch construction which is
completely local and produces surfaces with the global G1~continuity.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-09-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01224</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01225</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Non-ideal torque control of wind turbine systems: Impacts on annual
  energy production</dc:title>
 <dc:creator>Hackl, Christoph M.</dc:creator>
 <dc:creator>Schechner, Korbinian</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We discuss non-ideal torque control in wind turbine systems (WTS). Most
high-level controllers generate a reference torque which is then send to the
underlying electrical drive system (generator+inverter) of the WTS to steer the
turbine/generator to its optimal operation point (depending on the wind speed).
The energy production heavily depends on the mechanical power (i.e. the product
of rotational speed and generator torque). However, since torque sensors in the
MW range are not available or extremely expensive, the torque controllers are
implemented as feedforward controllers and, therefore, are inherently sensitive
to parameter variations/uncertainties. Based on real wind data and a dynamical
WTS model, we discuss causes and impacts of non-ideal (feedforward) torque
control on the energy production and the gross earnings.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01225</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01226</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Maintenance of Automated Test Suites in Industry: An Empirical study on
  Visual GUI Testing</dc:title>
 <dc:creator>Al&#xe9;groth, Emil</dc:creator>
 <dc:creator>Feldt, Robert</dc:creator>
 <dc:creator>Kolstr&#xf6;m, Pirjo</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Context: Verification and validation (V&amp;V) activities make up 20 to 50
percent of the total development costs of a software system in practice. Test
automation is proposed to lower these V&amp;V costs but available research only
provides limited empirical data from industrial practice about the maintenance
costs of automated tests and what factors affect these costs. In particular,
these costs and factors are unknown for automated GUI-based testing.
  Objective: This paper addresses this lack of knowledge through analysis of
the costs and factors associated with the maintenance of automated GUI-based
tests in industrial practice.
  Method: An empirical study at two companies, Siemens and Saab, is reported
where interviews about, and empirical work with, Visual GUI Testing is
performed to acquire data about the technique's maintenance costs and
feasibility.
  Results: 13 factors are observed that affect maintenance, e.g. tester
knowledge/experience and test case complexity. Further, statistical analysis
shows that developing new test scripts is costlier than maintenance but also
that frequent maintenance is less costly than infrequent, big bang maintenance.
In addition a cost model, based on previous work, is presented that estimates
the time to positive return on investment (ROI) of test automation compared to
manual testing.
  Conclusions: It is concluded that test automation can lower overall software
development costs of a project whilst also having positive effects on software
quality. However, maintenance costs can still be considerable and the less time
a company currently spends on manual testing, the more time is required before
positive, economic, ROI is reached after automation.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01226</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01228</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image and Information</dc:title>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A well-known old adage says that {\em &quot;A picture is worth a thousand words!&quot;}
(attributed to the Chinese philosopher Confucius ca 500 years BC). But more
precisely, what do we mean by information in images? And how can it be
retrieved effectively by machines? We briefly highlight these puzzling
questions in this column. But first of all, let us start by defining more
precisely what is meant by an &quot;Image.&quot;
</dc:description>
 <dc:description>Comment: 9 pages, 7 figures. to be published in french by Belin publisher for
  a collaborative book project on &quot;Image and Communication&quot;</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01228</dc:identifier>
 <dc:language>fr</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01237</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How Far are We from Solving Pedestrian Detection?</dc:title>
 <dc:creator>Zhang, Shanshan</dc:creator>
 <dc:creator>Benenson, Rodrigo</dc:creator>
 <dc:creator>Omran, Mohamed</dc:creator>
 <dc:creator>Hosang, Jan</dc:creator>
 <dc:creator>Schiele, Bernt</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Encouraged by the recent progress in pedestrian detection, we investigate the
gap between current state-of-the-art methods and the &quot;perfect single frame
detector&quot;. We enable our analysis by creating a human baseline for pedestrian
detection (over the Caltech dataset), and by manually clustering the recurrent
errors of a top detector. Our results characterize both localization and
background-versus-foreground errors. To address localization errors we study
the impact of training annotation noise on the detector performance, and show
that we can improve even with a small portion of sanitized training data. To
address background/foreground discrimination, we study convnets for pedestrian
detection, and discuss which factors affect their performance. Other than our
in-depth analysis, we report top performance on the Caltech dataset, and
provide a new sanitized set of training and test annotations.
</dc:description>
 <dc:description>Comment: CVPR16 camera ready</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01242</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Galois Correspondence on Linear Codes over Finite Chain Rings</dc:title>
 <dc:creator>Tabue, A. Fotue</dc:creator>
 <dc:creator>Mart&#xed;nez-Moro, E.</dc:creator>
 <dc:creator>Mouaha, C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>51E22, 94B05</dc:subject>
 <dc:description>  Given $\texttt{S}|\texttt{R}$ a finite Galois extension of finite chain rings
and $\mathcal{B}$ an $\texttt{S}$-linear code we define two Galois operators,
the closure operator and the interior operator. We proof that a linear code is
Galois invariant if and only if the row standard form of its generator matrix
has all entries in the fixed ring by the Galois group and show a Galois
correspondence in the class of $\texttt{S}$-linear codes. As applications some
improvements of upper and lower bounds for the rank of the restriction and
trace code are given and some applications to $\texttt{S}$-linear cyclic codes
are shown.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01242</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01246</identifier>
 <datestamp>2016-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing with quasiseparable matrices</dc:title>
 <dc:creator>Pernet, Clement</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  The class of quasiseparable matrices is defined by a pair of bounds, called
the quasiseparable orders, on the ranks of the maximal sub-matrices entirely
located in their strictly lower and upper triangular parts. These arise
naturally in applications, as e.g. the inverse of band matrices, and are widely
used for they admit structured representations allowing to compute with them in
time linear in the dimension and quadratic with the quasiseparable order. We
show, in this paper, the connection between the notion of quasisepa-rability
and the rank profile matrix invariant, presented in [Dumas \&amp; al. ISSAC'15].
This allows us to propose an algorithm computing the quasiseparable orders (rL,
rU) in time O(n^2 s^($\omega$--2)) where s = max(rL, rU) and $\omega$ the
exponent of matrix multiplication. We then present two new structured
representations, a binary tree of PLUQ decompositions, and the Bruhat
generator, using respectively O(ns log n/s) and O(ns) field elements instead of
O(ns^2) for the previously known generators. We present algorithms computing
these representations in time O(n^2 s^($\omega$--2)). These representations
allow a matrix-vector product in time linear in the size of their
representation. Lastly we show how to multiply two such structured matrices in
time O(n^2 s^($\omega$--2)).
</dc:description>
 <dc:description>Comment: International Symposium on Symbolic and Algebraic Computation
  (ISSAC'16), Jul 2016, Waterloo, France</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-09-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01246</dc:identifier>
 <dc:identifier>doi:10.1145/2930889.2930915</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01248</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using Hadoop for Large Scale Analysis on Twitter: A Technical Report</dc:title>
 <dc:creator>Nodarakis, Nikolaos</dc:creator>
 <dc:creator>Sioutas, Spyros</dc:creator>
 <dc:creator>Tsakalidis, Athanasios</dc:creator>
 <dc:creator>Tzimas, Giannis</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.2.4</dc:subject>
 <dc:description>  Sentiment analysis (or opinion mining) on Twitter data has attracted much
attention recently. One of the system's key features, is the immediacy in
communication with other users in an easy, user-friendly and fast way.
Consequently, people tend to express their feelings freely, which makes Twitter
an ideal source for accumulating a vast amount of opinions towards a wide
diversity of topics. This amount of information offers huge potential and can
be harnessed to receive the sentiment tendency towards these topics. However,
since none can invest an infinite amount of time to read through these tweets,
an automated decision making approach is necessary. Nevertheless, most existing
solutions are limited in centralized environments only. Thus, they can only
process at most a few thousand tweets. Such a sample, is not representative to
define the sentiment polarity towards a topic due to the massive number of
tweets published daily. In this paper, we go one step further and develop a
novel method for sentiment learning in the MapReduce framework. Our algorithm
exploits the hashtags and emoticons inside a tweet, as sentiment labels, and
proceeds to a classification procedure of diverse sentiment types in a parallel
and distributed manner. Moreover, we utilize Bloom filters to compact the
storage size of intermediate data and boost the performance of our algorithm.
Through an extensive experimental evaluation, we prove that our solution is
efficient, robust and scalable and confirm the quality of our sentiment
identification.
</dc:description>
 <dc:description>Comment: 8 pages, 3 tables, 3 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01248</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01255</identifier>
 <datestamp>2016-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning scale-variant and scale-invariant features for deep image
  classification</dc:title>
 <dc:creator>van Noord, Nanne</dc:creator>
 <dc:creator>Postma, Eric</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Convolutional Neural Networks (CNNs) require large image corpora to be
trained on classification tasks. The variation in image resolutions, sizes of
objects and patterns depicted, and image scales, hampers CNN training and
performance, because the task-relevant information varies over spatial scales.
Previous work attempting to deal with such scale variations focused on
encouraging scale-invariant CNN representations. However, scale-invariant
representations are incomplete representations of images, because images
contain scale-variant information as well. This paper addresses the combined
development of scale-invariant and scale-variant representations. We propose a
multi- scale CNN method to encourage the recognition of both types of features
and evaluate it on a challenging image classification task involving
task-relevant characteristics at multiple scales. The results show that our
multi-scale CNN outperforms single-scale CNN. This leads to the conclusion that
encouraging the combined development of a scale-invariant and scale-variant
representation in CNNs is beneficial to image recognition performance.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01258</identifier>
 <datestamp>2016-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A network-based rating system and its resistance to bribery</dc:title>
 <dc:creator>Grandi, Umberto</dc:creator>
 <dc:creator>Turrini, Paolo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We study a rating system in which a set of individuals (e.g., the customers
of a restaurant) evaluate a given service (e.g, the restaurant), with their
aggregated opinion determining the probability of all individuals to use the
service and thus its generated revenue. We explicitly model the influence
relation by a social network, with individuals being influenced by the
evaluation of their trusted peers. On top of that we allow a malicious service
provider (e.g., the restaurant owner) to bribe some individuals, i.e., to
invest a part of his or her expected income to modify their opinion, therefore
influencing his or her final gain. We analyse the effect of bribing strategies
under various constraints, and we show under what conditions the system is
bribery-proof, i.e., no bribing strategy yields a strictly positive expected
gain to the service provider.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01261</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>User Collusion Avoidance Scheme for Privacy-Preserving Decentralized
  Key-Policy Attribute-Based Encryption -- Full Version</dc:title>
 <dc:creator>Rahulamathavan, Yogachandran</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Recent trend towards cloud computing paradigm, smart devices and 4G wireless
technologies has enabled seamless data sharing among users. Cloud computing
environment is distributed and untrusted, hence data owners have to encrypt
their data to enforce data confidentiality. The data confidentiality in a
distributed environment can be achieved by using attribute-based encryption
technique. Decentralized attribute-based encryption technique is a variant of
multiple authority based attribute-based encryption whereby any attribute
authority can independently join and leave the system without collaborating
with the existing attribute authorities. In this paper, we propose a
privacy-preserving decentralized key-policy attribute-based encryption scheme.
The scheme preserves the user privacy when users interact with multiple
authorities to obtain decryption keys while mitigating the well-known user
collusion security vulnerability. We showed that our scheme relies on
decisional bilinear Diffie-Hellman standard complexity assumption in contrast
to the previous nonstandard complexity assumptions such as $q-$decisional
Diffie-Hellman inversion.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01265</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantifying synergistic information using intermediate stochastic
  variables</dc:title>
 <dc:creator>Quax, Rick</dc:creator>
 <dc:creator>Har-Shemesh, Omri</dc:creator>
 <dc:creator>Sloot, Peter M. A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>H.1.1</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:description>  Quantifying synergy among stochastic variables is an important open problem
in information theory. Information synergy occurs when multiple sources
together predict an outcome variable better than the sum of single-source
predictions. It is an essential phenomenon in biology such as in neuronal
networks and cellular regulatory processes, where different information flows
integrate to produce a single response, but also in social cooperation
processes as well as in statistical inference tasks in machine learning. Here
we propose a metric of synergistic entropy and synergistic information from
first principles. The proposed measure relies on so-called synergistic random
variables (SRVs) which are constructed to have zero mutual information about
individual source variables but non-zero mutual information about the complete
set of source variables. We prove several basic and desired properties of our
measure, including bounds and additivity properties. In addition, we prove
several important consequences of our measure, including the fact that
different types of synergistic information may co-exist between the same sets
of variables. A numerical implementation is provided, which we use to
demonstrate that synergy is associated with resilience to noise. Our measure
may be a marked step forward in the study of multivariate information theory
and its numerous applications.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-10-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01265</dc:identifier>
 <dc:identifier>doi:10.3390/e19020085</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01286</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructing Dominating Sets in Circulant Graphs</dc:title>
 <dc:creator>Shparlinski, Igor E.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  We give an efficient construction of a reasonably small dominating set in a
circulant graph on $n$ notes and $k$ distinct chord lengths. This result is
based on bounds on some double exponential sums. .
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01286</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01295</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How proofs are prepared at Camelot</dc:title>
 <dc:creator>Bj&#xf6;rklund, Andreas</dc:creator>
 <dc:creator>Kaski, Petteri</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>G.3</dc:subject>
 <dc:subject>I.1.2</dc:subject>
 <dc:description>  We study a design framework for robust, independently verifiable, and
workload-balanced distributed algorithms working on a common input. An
algorithm based on the framework is essentially a distributed encoding
procedure for a Reed--Solomon code, which enables (a) robustness against
byzantine failures with intrinsic error-correction and identification of failed
nodes, and (b) independent randomized verification to check the entire
computation for correctness, which takes essentially no more resources than
each node individually contributes to the computation. The framework builds on
recent Merlin--Arthur proofs of batch evaluation of Williams~[{\em Electron.\
Colloq.\ Comput.\ Complexity}, Report TR16-002, January 2016] with the
observation that {\em Merlin's magic is not needed} for batch evaluation---mere
Knights can prepare the proof, in parallel, and with intrinsic
error-correction.
  The contribution of this paper is to show that in many cases the verifiable
batch evaluation framework admits algorithms that match in total resource
consumption the best known sequential algorithm for solving the problem. As our
main result, we show that the $k$-cliques in an $n$-vertex graph can be counted
{\em and} verified in per-node $O(n^{(\omega+\epsilon)k/6})$ time and space on
$O(n^{(\omega+\epsilon)k/6})$ compute nodes, for any constant $\epsilon&gt;0$ and
positive integer $k$ divisible by $6$, where $2\leq\omega&lt;2.3728639$ is the
exponent of matrix multiplication. This matches in total running time the best
known sequential algorithm, due to Ne{\v{s}}et{\v{r}}il and Poljak [{\em
Comment.~Math.~Univ.~Carolin.}~26 (1985) 415--419], and considerably improves
its space usage and parallelizability. Further results include novel algorithms
for counting triangles in sparse graphs, computing the chromatic polynomial of
a graph, and computing the Tutte polynomial of a graph.
</dc:description>
 <dc:description>Comment: 42 pp</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01295</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01298</identifier>
 <datestamp>2016-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The b-continuity of graphs with large girth</dc:title>
 <dc:creator>Silva, Ana</dc:creator>
 <dc:creator>Linhares-Sales, Cl&#xe1;udia</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  A b-coloring of the vertices of a graph is a proper coloring where each color
class contains a vertex which is adjacent to each other color class. The
b-chromatic number of $G$ is the maximum integer $b(G)$ for which $G$ has a
b-coloring with $b(G)$ colors. A graph $G$ is b-continuous if $G$ has a
b-coloring with $k$ colors, for every integer $k$ in the interval
$[\chi(G),b(G)]$. It is known that not all graphs are b-continuous. In this
article, we show that if $G$ has girth at least 10, then $G$ is b-continuous.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01298</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01303</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Division and Slope Factorization of p-Adic Polynomials</dc:title>
 <dc:creator>Caruso, Xavier</dc:creator>
 <dc:creator>Roe, David</dc:creator>
 <dc:creator>Vaccon, Tristan</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  We study two important operations on polynomials defined over complete
discrete valuation fields: Euclidean division and factorization. In particular,
we design a simple and efficient algorithm for computing slope factorizations,
based on Newton iteration. One of its main features is that we avoid working
with fractional exponents. We pay particular attention to stability, and
analyze the behavior of the algorithm using several precision models.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01303</dc:identifier>
 <dc:identifier>doi:10.1145/1235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01304</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inverse Inequality Estimates with Symbolic Computation</dc:title>
 <dc:creator>Koutschan, Christoph</dc:creator>
 <dc:creator>Neum&#xfc;ller, Martin</dc:creator>
 <dc:creator>Radu, Cristian-Silviu</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>33F10, 65N12 (Primary) 65N30, 68W30, 65F15, 05A20, 15A15, 15A45
  (Secondary)</dc:subject>
 <dc:description>  In the convergence analysis of numerical methods for solving partial
differential equations (such as finite element methods) one arrives at certain
generalized eigenvalue problems, whose maximal eigenvalues need to be estimated
as accurately as possible. We apply symbolic computation methods to the
situation of square elements and are able to improve the previously known upper
bound, given in &quot;p- and hp-finite element methods&quot; (Schwab, 1998), by a factor
of 8. More precisely, we try to evaluate the corresponding determinant using
the holonomic ansatz, which is a powerful tool for dealing with determinants,
proposed by Zeilberger in 2007. However, it turns out that this method does not
succeed on the problem at hand. As a solution we present a variation of the
original holonomic ansatz that is applicable to a larger class of determinants,
including the one we are dealing with here. We obtain an explicit closed form
for the determinant, whose special form enables us to derive new and tight
upper resp. lower bounds on the maximal eigenvalue, as well as its asymptotic
behaviour.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01304</dc:identifier>
 <dc:identifier>Advances in Applied Mathematics 80:1-23, 2016</dc:identifier>
 <dc:identifier>doi:10.1016/j.aam.2016.04.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01321</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A continuum among logarithmic, linear, and exponential functions, and
  its potential to improve generalization in neural networks</dc:title>
 <dc:creator>Godfrey, Luke B.</dc:creator>
 <dc:creator>Gashler, Michael S.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present the soft exponential activation function for artificial neural
networks that continuously interpolates between logarithmic, linear, and
exponential functions. This activation function is simple, differentiable, and
parameterized so that it can be trained as the rest of the network is trained.
We hypothesize that soft exponential has the potential to improve neural
network learning, as it can exactly calculate many natural operations that
typical neural networks can only approximate, including addition,
multiplication, inner product, distance, polynomials, and sinusoids.
</dc:description>
 <dc:description>Comment: 6 pages, 8 figures, conference, In Proceedings of Knowledge Discovery
  and Information Retrieval (KDIR) 2015, Lisbon, Portugal, December 2015</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01323</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Biclustering Readings and Manuscripts via Non-negative Matrix
  Factorization, with Application to the Text of Jude</dc:title>
 <dc:creator>McCollum, Joey</dc:creator>
 <dc:creator>Brown, Stephen</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>6U815</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  The text-critical practice of grouping witnesses into families or texttypes
often faces two obstacles: Contamination in the manuscript tradition, and
co-dependence in identifying characteristic readings and manuscripts. We
introduce non-negative matrix factorization (NMF) as a simple, unsupervised,
and efficient way to cluster large numbers of manuscripts and readings
simultaneously while summarizing contamination using an easy-to-interpret
mixture model. We apply this method to an extensive collation of the New
Testament epistle of Jude and show that the resulting clusters correspond to
human-identified textual families from existing research.
</dc:description>
 <dc:description>Comment: 31 pages, 2 figures, 42 tables</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01323</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01327</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On The Construction of Capacity-Achieving Lattice Gaussian Codes</dc:title>
 <dc:creator>Alghamdi, Wael</dc:creator>
 <dc:creator>Abediseid, Walid</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose a new approach to proving results regarding channel
coding schemes based on construction-A lattices for the Additive White Gaussian
Noise (AWGN) channel that yields new characterizations of the code construction
parameters, i.e., the primes and dimensions of the codes, as functions of the
block-length. The approach we take introduces an averaging argument that
explicitly involves the considered parameters. This averaging argument is
applied to a generalized Loeliger ensemble to provide a more practical proof of
the existence of AWGN-good lattices, and to characterize suitable parameters
for the lattice Gaussian coding scheme proposed by Ling and Belfiore.
</dc:description>
 <dc:description>Comment: 9 pages, a short version of this paper has been submitted to the 2016
  IEEE International Symposium on Information Theory</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01327</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01329</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effect of Data Sharing on Private Cache Design in Chip Multiprocessors</dc:title>
 <dc:creator>Yavits, Leonid</dc:creator>
 <dc:creator>Morad, Amir</dc:creator>
 <dc:creator>Ginosar, Ran</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  In multithreaded applications with high degree of data sharing, the miss rate
of private cache is shown to exhibit a compulsory miss component. It manifests
because at least some of the shared data originates from other cores and can
only be accessed in a shared cache. The compulsory component does not change
with the private cache size, causing its miss rate to diminish slower as the
cache size grows. As a result, the peak performance of a Chip Multiprocessor
(CMP) for workloads with high degree of data sharing is achieved with a smaller
private cache, compared to workloads with no data sharing. The CMP performance
can be improved by reassigning some of the constrained area or power resource
from private cache to core. Alternatively, the area or power budget of a CMP
can be reduced without a performance hit.
</dc:description>
 <dc:description>Comment: 4 pages, 4 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01329</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01342</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Plurality Consensus via Shuffling: Lessons Learned from Load Balancing</dc:title>
 <dc:creator>Berenbrink, Petra</dc:creator>
 <dc:creator>Friedetzky, Tom</dc:creator>
 <dc:creator>Kling, Peter</dc:creator>
 <dc:creator>Mallmann-Trenn, Frederik</dc:creator>
 <dc:creator>Wastell, Chris</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We consider \emph{plurality consensus} in a network of $n$ nodes. Initially,
each node has one of $k$ opinions. The nodes execute a (randomized) distributed
protocol to agree on the plurality opinion (the opinion initially supported by
the most nodes). Nodes in such networks are often quite cheap and simple, and
hence one seeks protocols that are not only fast but also simple and space
efficient. Typically, protocols depend heavily on the employed communication
mechanism, which ranges from sequential (only one pair of nodes communicates at
any time) to fully parallel (all nodes communicate with all their neighbors at
once) communication and everything in-between.
  We propose a framework to design protocols for a multitude of communication
mechanisms. We introduce protocols that solve the plurality consensus problem
and are with probability 1-o(1) both time and space efficient. Our protocols
are based on an interesting relationship between plurality consensus and
distributed load balancing. This relationship allows us to design protocols
that generalize the state of the art for a large range of problem parameters.
In particular, we obtain the same bounds as the recent result of Alistarh et
al. (who consider only two opinions on a clique) using a much simpler protocol
that generalizes naturally to general graphs and multiple opinions.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01342</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01346</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>C-planarity of Embedded Cyclic c-Graphs</dc:title>
 <dc:creator>Fulek, Radoslav</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We show that c-planarity is solvable in quadratic time for flat clustered
graphs with three clusters if the combinatorial embedding of the underlying
graph is fixed. In simpler graph-theoretical terms our result can be viewed as
follows. Given a graph $G$ with the vertex set partitioned into three parts
embedded on a 2-sphere, our algorithm decides if we can augment $G$ by adding
edges without creating an edge-crossing so that in the resulting spherical
graph the vertices of each part induce a connected sub-graph. We proceed by a
reduction to the problem of testing the existence of a perfect matching in
planar bipartite graphs. We formulate our result in a slightly more general
setting of cyclic clustered graphs, i.e., the simple graph obtained by
contracting each cluster, where we disregard loops and multi-edges, is a cycle.
</dc:description>
 <dc:description>Comment: a revised version that appears in the Proceedings of the 24th
  International Symposium on Graph Drawing and Network Visualization (GD 2016)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01348</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Accelerating Bottlenecks in GPU Execution with Assist
  Warps</dc:title>
 <dc:creator>Vijaykumar, Nandita</dc:creator>
 <dc:creator>Pekhimenko, Gennady</dc:creator>
 <dc:creator>Jog, Adwait</dc:creator>
 <dc:creator>Ghose, Saugata</dc:creator>
 <dc:creator>Bhowmick, Abhishek</dc:creator>
 <dc:creator>Ausavarangnirun, Rachata</dc:creator>
 <dc:creator>Das, Chita</dc:creator>
 <dc:creator>Kandemir, Mahmut</dc:creator>
 <dc:creator>Mowry, Todd C.</dc:creator>
 <dc:creator>Mutlu, Onur</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Modern Graphics Processing Units (GPUs) are well provisioned to support the
concurrent execution of thousands of threads. Unfortunately, different
bottlenecks during execution and heterogeneous application requirements create
imbalances in utilization of resources in the cores. For example, when a GPU is
bottlenecked by the available off-chip memory bandwidth, its computational
resources are often overwhelmingly idle, waiting for data from memory to
arrive.
  This work describes the Core-Assisted Bottleneck Acceleration (CABA)
framework that employs idle on-chip resources to alleviate different
bottlenecks in GPU execution. CABA provides flexible mechanisms to
automatically generate &quot;assist warps&quot; that execute on GPU cores to perform
specific tasks that can improve GPU performance and efficiency.
  CABA enables the use of idle computational units and pipelines to alleviate
the memory bandwidth bottleneck, e.g., by using assist warps to perform data
compression to transfer less data from memory. Conversely, the same framework
can be employed to handle cases where the GPU is bottlenecked by the available
computational units, in which case the memory pipelines are idle and can be
used by CABA to speed up computation, e.g., by performing memoization using
assist warps.
  We provide a comprehensive design and evaluation of CABA to perform effective
and flexible data compression in the GPU memory hierarchy to alleviate the
memory bandwidth bottleneck. Our extensive evaluations show that CABA, when
used to implement data compression, provides an average performance improvement
of 41.7% (as high as 2.6X) across a variety of memory-bandwidth-sensitive GPGPU
applications.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01352</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Universality of causal graph dynamics</dc:title>
 <dc:creator>Martiel, Simon</dc:creator>
 <dc:creator>Martin, Bruno</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Causal Graph Dynamics generalize Cellular Automata, extending them to bounded
degree, time varying graphs. The dynamics rewrite the graph at each time step
with respect to two physics-like symmetries: causality (bounded speed of
information) and homogeneity (the rewriting acts the same everywhere on the
graph, at every time step). Universality is the ability simulating every other
instances of another (or the same) model of computation. In this work, we study
three different notions of simulation for Causal Graph Dynamics, each of them
leading to a definition of universality.
</dc:description>
 <dc:description>Comment: long version</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01352</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01358</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Scalable Synthesis of Stochastic Control Systems</dc:title>
 <dc:creator>Zamani, Majid</dc:creator>
 <dc:creator>Tkachev, Ilya</dc:creator>
 <dc:creator>Abate, Alessandro</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>93E03, 68Q60, 93C10</dc:subject>
 <dc:subject>D.2.4</dc:subject>
 <dc:subject>B.1.2</dc:subject>
 <dc:subject>B.5.2</dc:subject>
 <dc:subject>I.2.8</dc:subject>
 <dc:description>  Formal control synthesis approaches over stochastic systems have received
significant attention in the past few years, in view of their ability to
provide provably correct controllers for complex logical specifications in an
automated fashion. Examples of complex specifications of interest include
properties expressed as formulae in linear temporal logic (LTL) or as automata
on infinite strings. A general methodology to synthesize controllers for such
properties resorts to symbolic abstractions of the given stochastic systems.
Symbolic models are discrete abstractions of the given concrete systems with
the property that a controller designed on the abstraction can be refined (or
implemented) into a controller on the original system. Although the recent
development of techniques for the construction of symbolic models has been
quite encouraging, the general goal of formal synthesis over stochastic control
systems is by no means solved. A fundamental issue with the existing techniques
is the known &quot;curse of dimensionality,&quot; which is due to the need to discretize
state and input sets and that results in an exponential complexity over the
number of state and input variables in the concrete system. In this work we
propose a novel abstraction technique for incrementally stable stochastic
control systems, which does not require state-space discretization but only
input set discretization, and that can be potentially more efficient (and thus
scalable) than existing approaches. We elucidate the effectiveness of the
proposed approach by synthesizing a schedule for the coordination of two
traffic lights under some safety and fairness requirements for a road traffic
model. Further we argue that this 5-dimensional linear stochastic control
system cannot be studied with existing approaches based on state-space
discretization due to the very large number of generated discrete states.
</dc:description>
 <dc:description>Comment: 22 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1407.2730</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01365</identifier>
 <datestamp>2017-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Semantics of Intensionality</dc:title>
 <dc:creator>Kavvos, G. A.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  In this paper we propose a categorical theory of intensionality. We first
revisit the notion of intensionality, and discuss we its relevance to logic and
computer science. It turns out that 1-category theory is not the most
appropriate vehicle for studying the interplay of extension and intension. We
are thus led to consider the P-categories of \v{C}ubri\'{c}, Dybjer and Scott,
which are categories only up to a partial equivalence relation (PER). In this
setting, we introduce a new P-categorical construct, that of exposures.
Exposures are very nearly functors, except that they do not preserve the PERs
of the P-category. Inspired by the categorical semantics of modal logic, we
begin to develop their theory. Our leading examples demonstrate that an
exposure is an abstraction of well-behaved intensional devices, such as G\&quot;odel
numberings. The outcome is a unifying framework in which classic results of
Kleene, G\&quot;odel, Tarski and Rice find concise, clear formulations, and where
each logical device or assumption involved in their proofs can be expressed in
the same algebraic manner.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01365</dc:identifier>
 <dc:identifier>In: Esparza J., Murawski A. (eds) Foundations of Software Science
  and Computation Structures. FoSSaCS 2017. Lecture Notes in Computer Science,
  vol 10203. Springer, Berlin, Heidelberg</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-662-54458-7_32</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01366</identifier>
 <datestamp>2016-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semantic Acyclicity Under Constraints</dc:title>
 <dc:creator>Barcelo, Pablo</dc:creator>
 <dc:creator>Gottlob, Georg</dc:creator>
 <dc:creator>Pieris, Andreas</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  A conjunctive query (CQ) is semantically acyclic if it is equivalent to an
acyclic one. Semantic acyclicity has been studied in the constraint-free case,
and deciding whether a query enjoys this property is NP-complete. However, in
case the database is subject to constraints such as tuple-generating
dependencies (tgds) that can express, e.g., inclusion dependencies, or
equality-generating dependencies (egds) that capture, e.g., functional
dependencies, a CQ may turn out to be semantically acyclic under the
constraints while not semantically acyclic in general. This opens avenues to
new query optimization techniques. In this paper we initiate and develop the
theory of semantic acyclicity under constraints. More precisely, we study the
following natural problem: Given a CQ and a set of constraints, is the query
semantically acyclic under the constraints, or, in other words, is the query
equivalent to an acyclic one over all those databases that satisfy the set of
constraints? We show that, contrary to what one might expect, decidability of
CQ containment is a necessary but not sufficient condition for the decidability
of semantic acyclicity. In particular, we show that semantic acyclicity is
undecidable in the presence of full tgds (i.e., Datalog rules). In view of this
fact, we focus on the main classes of tgds for which CQ containment is
decidable, and do not capture the class of full tgds, namely guarded,
non-recursive and sticky tgds. For these classes we show that semantic
acyclicity is decidable, and its complexity coincides with the complexity of CQ
containment. In the case of egds, we show that for keys over unary and binary
predicates semantic acyclicity is decidable (NP-complete). We finally consider
the problem of evaluating a semantically acyclic query over a database that
satisfies a set of constraints; for guarded tgds and functional dependencies
this problem is tractable.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01366</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01376</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Inv-ASKIT: A Parallel Fast Diret Solver for Kernel Matrices</dc:title>
 <dc:creator>Yu, Chenhan D.</dc:creator>
 <dc:creator>March, William B.</dc:creator>
 <dc:creator>Xiao, Bo</dc:creator>
 <dc:creator>Biros, George</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  We present a parallel algorithm for computing the approximate factorization
of an $N$-by-$N$ kernel matrix. Once this factorization has been constructed
(with $N \log^2 N $ work), we can solve linear systems with this matrix with $N
\log N $ work. Kernel matrices represent pairwise interactions of points in
metric spaces. They appear in machine learning, approximation theory, and
computational physics. Kernel matrices are typically dense (matrix
multiplication scales quadratically with $N$) and ill-conditioned (solves can
require 100s of Krylov iterations). Thus, fast algorithms for matrix
multiplication and factorization are critical for scalability.
  Recently we introduced ASKIT, a new method for approximating a kernel matrix
that resembles N-body methods. Here we introduce INV-ASKIT, a factorization
scheme based on ASKIT. We describe the new method, derive complexity estimates,
and conduct an empirical study of its accuracy and scalability. We report
results on real-world datasets including &quot;COVTYPE&quot; ($0.5$M points in 54
dimensions), &quot;SUSY&quot; ($4.5$M points in 8 dimensions) and &quot;MNIST&quot; (2M points in
784 dimensions) using shared and distributed memory parallelism. In our largest
run we approximately factorize a dense matrix of size 32M $\times$ 32M
(generated from points in 64 dimensions) on 4,096 Sandy-Bridge cores. To our
knowledge these results improve the state of the art by several orders of
magnitude.
</dc:description>
 <dc:description>Comment: 11 pages, 2 figures, to appear in IPDPS 2016</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01376</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01385</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Minimum Shared Edges Problem on Planar Graphs</dc:title>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Sorge, Manuel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17, 68Q25, 68R10, 05C10</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study the Minimum Shared Edges problem introduced by Omran et al. [Journal
of Combinatorial Optimization, 2015] on planar graphs: Planar MSE asks, given a
planar graph G = (V,E), two distinct vertices s,t in V , and two integers p, k,
whether there are p s-t paths in G that share at most k edges, where an edges
is called shared if it appears in at least two of the p s-t paths. We show that
Planar MSE is NP-hard by reduction from Vertex Cover. We make use of a
grid-like structure, where the alignment (horizontal/vertical) of the edges in
the grid correspond to selection and validation gadgets respectively.
</dc:description>
 <dc:description>Comment: 7 pages, 3 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01385</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01387</identifier>
 <datestamp>2016-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unrestricted State Complexity of Binary Operations on Regular Languages</dc:title>
 <dc:creator>Brzozowski, Janusz</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  I study the state complexity of binary operations on regular languages over
different alphabets. It is well known that if $L'_m$ and $L_n$ are languages
restricted to be over the same alphabet, with $m$ and $n$ quotients,
respectively, the state complexity of any binary boolean operation on $L'_m$
and $L_n$ is $mn$, and that of the product (concatenation) is $(m-1)2^n
+2^{n-1}$. In contrast to this, I show that if $L'_m$ and $L_n$ are over their
own different alphabets, the state complexity of union and symmetric difference
is $mn+m+n+1$, that of intersection is $mn$, that of difference is $mn+m$, and
that of the product is $m2^n+2^{n-1}$.
</dc:description>
 <dc:description>Comment: 13 pages, 6 figures. An earlier version is to appear in the
  proceedings of DCFS 2016. Two errors are corrected in the present arXiv
  version</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01387</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-41114-9_5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01388</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analyses of a Virtual World</dc:title>
 <dc:creator>Holovatch, Yurij</dc:creator>
 <dc:creator>Mryglod, Olesya</dc:creator>
 <dc:creator>Szell, Michael</dc:creator>
 <dc:creator>Thurner, Stefan</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We present an overview of a series of results obtained from the analysis of
human behavior in a virtual environment. We focus on the massive multiplayer
online game (MMOG) Pardus which has a worldwide participant base of more than
400,000 registered players. We provide evidence for striking statistical
similarities between social structures and human-action dynamics in the real
and virtual worlds. In this sense MMOGs provide an extraordinary way for
accurate and falsifiable studies of social phenomena. We further discuss
possibilities to apply methods and concepts developed in the course of these
studies to analyse oral and written narratives.
</dc:description>
 <dc:description>Comment: 16 pages, 7 figures. To appear in: &quot;Maths Meets Myths:
  Complexity-science approaches to folktales, myths, sagas, and histories.&quot;
  Editors: R. Kenna, M. Mac Carron, P. Mac Carron. (Springer, 2016)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01388</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01396</identifier>
 <datestamp>2017-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Making Walks Count: From Silent Circles to Hamiltonian Cycles</dc:title>
 <dc:creator>Alekseyev, Max A.</dc:creator>
 <dc:creator>Michon, Gerard P.</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  We illustrate the application of the matrix-transfer method for a number of
enumeration problems concerning the party game Silent Circles, Hamiltonian
cycles in the antiprism graphs, and simple paths and cycles of a fixed length
in arbitrary graphs.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01396</dc:identifier>
 <dc:identifier>In: J. Beineke, J. Rosenhouse (eds.) The Mathematics of Various
  Entertaining Subjects: Research in Recreational Math, Volume 2, Princeton
  University Press, 2017, pp. 157-168. ISBN 978-0-691-17192-0</dc:identifier>
 <dc:identifier>doi:10.2307/j.ctt1s4773q.14</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01398</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding the different patterns in buildings data using bag of words
  representation with clustering</dc:title>
 <dc:creator>Habib, Usman</dc:creator>
 <dc:creator>Zucker, Gerhard</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The understanding of the buildings operation has become a challenging task
due to the large amount of data recorded in energy efficient buildings. Still,
today the experts use visual tools for analyzing the data. In order to make the
task realistic, a method has been proposed in this paper to automatically
detect the different patterns in buildings. The K Means clustering is used to
automatically identify the ON (operational) cycles of the chiller. In the next
step the ON cycles are transformed to symbolic representation by using Symbolic
Aggregate Approximation (SAX) method. Then the SAX symbols are converted to bag
of words representation for hierarchical clustering. Moreover, the proposed
technique is applied to real life data of adsorption chiller. Additionally, the
results from the proposed method and dynamic time warping (DTW) approach are
also discussed and compared.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01398</dc:identifier>
 <dc:identifier>doi:10.1109/FIT.2015.60</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01404</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Quantum walks public key cryptographic system</dc:title>
 <dc:creator>Vlachou, C.</dc:creator>
 <dc:creator>Rodrigues, J.</dc:creator>
 <dc:creator>Mateus, P.</dc:creator>
 <dc:creator>Paunkovi&#x107;, N.</dc:creator>
 <dc:creator>Souto, A.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum Cryptography is a rapidly developing field of research that benefits
from the properties of Quantum Mechanics in performing cryptographic tasks.
Quantum walks are a powerful model for quantum computation and very promising
for quantum information processing. In this paper, we present a quantum
public-key cryptographic system based on quantum walks. In particular, in the
proposed protocol the public key is given by a quantum state generated by
performing a quantum walk. We show that the protocol is secure and analyze the
complexity of public-key generation and encryption/decryption procedures.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01404</dc:identifier>
 <dc:identifier>International Journal of Quantum Information, Vol. 13, No. 6
  (2015) 1550050</dc:identifier>
 <dc:identifier>doi:10.1142/S0219749915500501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01407</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Kronecker-factored approximate Fisher matrix for convolution layers</dc:title>
 <dc:creator>Grosse, Roger</dc:creator>
 <dc:creator>Martens, James</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Second-order optimization methods such as natural gradient descent have the
potential to speed up training of neural networks by correcting for the
curvature of the loss function. Unfortunately, the exact natural gradient is
impractical to compute for large models, and most approximations either require
an expensive iterative procedure or make crude approximations to the curvature.
We present Kronecker Factors for Convolution (KFC), a tractable approximation
to the Fisher matrix for convolutional networks based on a structured
probabilistic model for the distribution over backpropagated derivatives.
Similarly to the recently proposed Kronecker-Factored Approximate Curvature
(K-FAC), each block of the approximate Fisher matrix decomposes as the
Kronecker product of small matrices, allowing for efficient inversion. KFC
captures important curvature information while still yielding comparably
efficient updates to stochastic gradient descent (SGD). We show that the
updates are invariant to commonly used reparameterizations, such as centering
of the activations. In our experiments, approximate natural gradient descent
with KFC was able to train convolutional networks several times faster than
carefully tuned SGD. Furthermore, it was able to train the networks in 10-20
times fewer iterations than SGD, suggesting its potential applicability in a
distributed setting.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01409</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal De-Anonymization in Random Graphs with Community Structure</dc:title>
 <dc:creator>Onaran, Efe</dc:creator>
 <dc:creator>Garg, Siddharth</dc:creator>
 <dc:creator>Erkip, Elza</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Anonymized social network graphs published for academic or advertisement
purposes are subject to de-anonymization attacks by leveraging side information
in the form of a second, public social network graph correlated with the
anonymized graph. This is because the two are from the same underlying graph of
true social relationships. In this paper, we (i) characterize the maximum a
posteriori (MAP) estimates of user identities for the anonymized graph and (ii)
provide sufficient conditions for successful de-anonymization for underlying
graphs with community structure. Our results generalize prior work that assumed
underlying graphs of Erd\H{o}s-R\'enyi type, in addition to proving the
optimality of the attack strategy adopted in the prior work.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01410</identifier>
 <datestamp>2016-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Framework for Fast Image Deconvolution with Incomplete Observations</dc:title>
 <dc:creator>Sim&#xf5;es, Miguel</dc:creator>
 <dc:creator>Almeida, Luis B.</dc:creator>
 <dc:creator>Bioucas-Dias, Jos&#xe9;</dc:creator>
 <dc:creator>Chanussot, Jocelyn</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In image deconvolution problems, the diagonalization of the underlying
operators by means of the FFT usually yields very large speedups. When there
are incomplete observations (e.g., in the case of unknown boundaries), standard
deconvolution techniques normally involve non-diagonalizable operators,
resulting in rather slow methods, or, otherwise, use inexact convolution
models, resulting in the occurrence of artifacts in the enhanced images. In
this paper, we propose a new deconvolution framework for images with incomplete
observations that allows us to work with diagonalized convolution operators,
and therefore is very fast. We iteratively alternate the estimation of the
unknown pixels and of the deconvolved image, using, e.g., an FFT-based
deconvolution method. This framework is an efficient, high-quality alternative
to existing methods of dealing with the image boundaries, such as edge
tapering. It can be used with any fast deconvolution method. We give an example
in which a state-of-the-art method that assumes periodic boundary conditions is
extended, through the use of this framework, to unknown boundary conditions.
Furthermore, we propose a specific implementation of this framework, based on
the alternating direction method of multipliers (ADMM). We provide a proof of
convergence for the resulting algorithm, which can be seen as a &quot;partial&quot; ADMM,
in which not all variables are dualized. We report experimental comparisons
with other primal-dual methods, where the proposed one performed at the level
of the state of the art. Four different kinds of applications were tested in
the experiments: deconvolution, deconvolution with inpainting, superresolution,
and demosaicing, all with unknown boundaries.
</dc:description>
 <dc:description>Comment: IEEE Trans. Image Process., to be published. 15 pages, 11 figures.
  MATLAB code available at
  https://github.com/alfaiate/DeconvolutionIncompleteObs</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01410</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2603920</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01412</identifier>
 <datestamp>2016-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Canary: A Scheduling Architecture for High Performance Cloud Computing</dc:title>
 <dc:creator>Qu, Hang</dc:creator>
 <dc:creator>Mashayekhi, Omid</dc:creator>
 <dc:creator>Terei, David</dc:creator>
 <dc:creator>Levis, Philip</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We present Canary, a scheduling architecture that allows high performance
analytics workloads to scale out to run on thousands of cores. Canary is
motivated by the observation that a central scheduler is a bottleneck for high
performance codes: a handful of multicore workers can execute tasks faster than
a controller can schedule them.
  The key insight in Canary is to reverse the responsibilities between
controllers and workers. Rather than dispatch tasks to workers, which then
fetch data as necessary, in Canary the controller assigns data partitions to
workers, which then spawn and schedule tasks locally.
  We evaluate three benchmark applications in Canary on up to 64 servers and
1,152 cores on Amazon EC2. Canary achieves up to 9-90X speedup over Spark and
up to 4X speedup over GraphX, a highly optimized graph analytics engine. While
current centralized schedulers can schedule 2,500 tasks/second, each Canary
worker can schedule 136,000 tasks/second per core and experiments show this
scales out linearly, with 64 workers scheduling over 120 million tasks per
second, allowing Canary to support optimized jobs running on thousands of
cores.
</dc:description>
 <dc:description>Comment: We have some presentation issues with the paper</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-04-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01416</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Relay-Fallback Tradeoff in Millimeter Wave Wireless System</dc:title>
 <dc:creator>Congiu, Roberto</dc:creator>
 <dc:creator>Shokri-Ghadikolaei, Hossein</dc:creator>
 <dc:creator>Fischione, Carlo</dc:creator>
 <dc:creator>Santucci, Fortunato</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Millimeter wave (mmWave) communications systems are promising candidate to
support extremely high data rate services in future wireless networks. MmWave
communications exhibit high penetration loss (blockage) and require directional
transmissions to compensate for severe channel attenuations and for high noise
powers. When blockage occurs, there are at least two simple prominent options:
1) switching to the conventional microwave frequencies (fallback option) and 2)
using an alternative non-blocked path (relay option). However, currently it is
not clear under which conditions and network parameters one option is better
than the other. To investigate the performance of the two options, this paper
proposes a novel blockage model that allows deriving maximum achievable
throughput and delay performance of both options. A simple criterion to decide
which option should be taken under which network condition is provided. By a
comprehensive performance analysis, it is shown that the right option depends
on the payload size, beam training overhead, and blockage probability. For a
network with light traffic and low probability of blockage in the direct link,
the fallback option is throughput- and delay-optimal. For a network with heavy
traffic demands and semi-static topology (low beam-training overhead), the
relay option is preferable.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, accepted in IEEE INFOCOM mmNet Workshop</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01416</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01421</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An SSD-based eigensolver for spectral analysis on billion-node graphs</dc:title>
 <dc:creator>Zheng, Da</dc:creator>
 <dc:creator>Burns, Randal</dc:creator>
 <dc:creator>Vogelstein, Joshua</dc:creator>
 <dc:creator>Priebe, Carey E.</dc:creator>
 <dc:creator>Szalay, Alexander S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Many eigensolvers such as ARPACK and Anasazi have been developed to compute
eigenvalues of a large sparse matrix. These eigensolvers are limited by the
capacity of RAM. They run in memory of a single machine for smaller eigenvalue
problems and require the distributed memory for larger problems.
  In contrast, we develop an SSD-based eigensolver framework called FlashEigen,
which extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph
with hundreds of millions or even billions of vertices in a single machine.
FlashEigen performs sparse matrix multiplication in a semi-external memory
fashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in
memory. We store the entire vector subspace on SSDs and reduce I/O to improve
performance through caching the most recent dense matrix. Our result shows that
FlashEigen is able to achieve 40%-60% performance of its in-memory
implementation and has performance comparable to the Anasazi eigensolvers on a
machine with 48 CPU cores. Furthermore, it is capable of scaling to a graph
with 3.4 billion vertices and 129 billion edges. It takes about four hours to
compute eight eigenvalues of the billion-node graph using 120 GB memory.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-02-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01421</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01425</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Geometric transformations of multidimensional color images based on NASS</dc:title>
 <dc:creator>Fan, Ping</dc:creator>
 <dc:creator>Zhou, Ri-Gui</dc:creator>
 <dc:creator>Jing, Naihuan</dc:creator>
 <dc:creator>Li, Hai-Sheng</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present quantum algorithms to realize geometric transformations (two-point
swappings, symmetric flips, local flips, orthogonal rotations, and
translations) based on an $n$-qubit normal arbitrary superposition state
(NASS). These transformations are implemented using quantum circuits consisting
of basic quantum gates, which are constructed with polynomial numbers of
single-qubit and two-qubit gates. Complexity analysis shows that the global
operators (symmetric flips, local flips, orthogonal rotations) can be
implemented with $O(n)$ gates. The proposed geometric transformations are used
to facilitate applications of quantum images with low complexity.
</dc:description>
 <dc:description>Comment: 32 pages</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01425</dc:identifier>
 <dc:identifier>Information Sciences 340-341 (2016), 191-208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01428</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Draw My Topics&quot;: Find Desired Topics fast from large scale of Corpus</dc:title>
 <dc:creator>Dou, Jason</dc:creator>
 <dc:creator>Sun, Ni</dc:creator>
 <dc:creator>Zou, Xiaojun</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  We develop the &quot;Draw My Topics&quot; toolkit, which provides a fast way to
incorporate social scientists' interest into standard topic modelling. Instead
of using raw corpus with primitive processing as input, an algorithm based on
Vector Space Model and Conditional Entropy are used to connect social
scientists' willingness and unsupervised topic models' output. Space for users'
adjustment on specific corpus of their interest is also accommodated. We
demonstrate the toolkit's use on the Diachronic People's Daily Corpus in
Chinese.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01428</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01441</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computational Security of Quantum Encryption</dc:title>
 <dc:creator>Alagic, Gorjan</dc:creator>
 <dc:creator>Broadbent, Anne</dc:creator>
 <dc:creator>Fefferman, Bill</dc:creator>
 <dc:creator>Gagliardoni, Tommaso</dc:creator>
 <dc:creator>Schaffner, Christian</dc:creator>
 <dc:creator>Jules, Michael St.</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Quantum-mechanical devices have the potential to transform cryptography. Most
research in this area has focused either on the information-theoretic
advantages of quantum protocols or on the security of classical cryptographic
schemes against quantum attacks. In this work, we initiate the study of another
relevant topic: the encryption of quantum data in the computational setting.
  In this direction, we establish quantum versions of several fundamental
classical results. First, we develop natural definitions for private-key and
public-key encryption schemes for quantum data. We then define notions of
semantic security and indistinguishability, and, in analogy with the classical
work of Goldwasser and Micali, show that these notions are equivalent. Finally,
we construct secure quantum encryption schemes from basic primitives. In
particular, we show that quantum-secure one-way functions imply IND-CCA1-secure
symmetric-key quantum encryption, and that quantum-secure trapdoor one-way
permutations imply semantically-secure public-key quantum encryption.
</dc:description>
 <dc:description>Comment: 31 pages, 3 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01441</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Information
  Theoretic Security (ICITS 2016) pp. 47-71</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-49175-2_3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01443</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Some Pairs Problems</dc:title>
 <dc:creator>Ullman, Jeffrey D.</dc:creator>
 <dc:creator>Ullman, Jonathan</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  A common form of MapReduce application involves discovering relationships
between certain pairs of inputs. Similarity joins serve as a good example of
this type of problem, which we call a &quot;some-pairs&quot; problem. In the framework of
Afrati et al. (VLDB 2013), algorithms are measured by the tradeoff between
reducer size (maximum number of inputs a reducer can handle) and the
replication rate (average number of reducers to which an input must be sent.
There are two obvious approaches to solving some-pairs problems in general. We
show that no general-purpose MapReduce algorithm can beat both of these two
algorithms in the worst case. We then explore a recursive algorithm for solving
some-pairs problems and heuristics for beating the lower bound on common
instances of the some-pairs class of problems.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01449</identifier>
 <datestamp>2016-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Development of an Ideal Observer that Incorporates Nuisance Parameters
  and Processes List-Mode Data</dc:title>
 <dc:creator>MacGahan, Christopher J.</dc:creator>
 <dc:creator>Kupinski, Matthew A.</dc:creator>
 <dc:creator>Hilton, Nathan R.</dc:creator>
 <dc:creator>Brubaker, Erik M.</dc:creator>
 <dc:creator>Johnson, William C.</dc:creator>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Observer models were developed to process data in list-mode format in order
to perform binary discrimination tasks for use in an arms-control-treaty
context. Data used in this study was generated using GEANT4 Monte Carlo
simulations for photons using custom models of plutonium inspection objects and
a radiation imaging system. Observer model performance was evaluated and
presented using the area under the receiver operating characteristic curve. The
ideal observer was studied under both signal-known-exactly conditions and in
the presence of unknowns such as object orientation and absolute count-rate
variability; when these additional sources of randomness were present, their
incorporation into the observer yielded superior performance.
</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01449</dc:identifier>
 <dc:identifier>doi:10.1364/JOSAA.33.000689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01458</identifier>
 <datestamp>2017-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Private Information Retrieval from MDS Coded Data in Distributed Storage
  Systems</dc:title>
 <dc:creator>Tajeddine, Razan</dc:creator>
 <dc:creator>Gnilke, Oliver W.</dc:creator>
 <dc:creator>Rouayheb, Salim El</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The problem of providing privacy, in the private information retrieval (PIR)
sense, to users requesting data from a distributed storage system (DSS), is
considered. The DSS is coded by an $(n,k,d)$ Maximum Distance Separable (MDS)
code to store the data reliably on unreliable storage nodes. Some of these
nodes can be spies which report to a third party, such as an oppressive regime,
which data is being requested by the user. An information theoretic PIR scheme
ensures that a user can satisfy its request while revealing, to the spy nodes,
no information on which data is being requested. A user can trivially achieve
PIR by downloading all the data in the DSS. However, this is not a feasible
solution due to its high communication cost. We construct PIR schemes with low
download communication cost. When there is $b=1$ spy node in the DSS, we
construct PIR schemes with download cost $\frac{1}{1-R}$ per unit of requested
data ($R=k/n$ is the code rate), achieving the information theoretic limit for
linear schemes. The proposed schemes are universal since they depend on the
code rate, but not on the generator matrix of the code. Also, when $b\leq
n-\delta k$, for some $\delta \in \mathbb{N^+}$, we construct linear PIR
schemes with $cPoP = \frac{b+\delta k}{\delta}$.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2017-08-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01464</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Latent-Class Hough Forests for 6 DoF Object Pose Estimation</dc:title>
 <dc:creator>Kouskouridas, Rigas</dc:creator>
 <dc:creator>Tejani, Alykhan</dc:creator>
 <dc:creator>Doumanoglou, Andreas</dc:creator>
 <dc:creator>Tang, Danhang</dc:creator>
 <dc:creator>Kim, Tae-Kyun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we present Latent-Class Hough Forests, a method for object
detection and 6 DoF pose estimation in heavily cluttered and occluded
scenarios. We adapt a state of the art template matching feature into a
scale-invariant patch descriptor and integrate it into a regression forest
using a novel template-based split function. We train with positive samples
only and we treat class distributions at the leaf nodes as latent variables.
During testing we infer by iteratively updating these distributions, providing
accurate estimation of background clutter and foreground occlusions and, thus,
better detection rate. Furthermore, as a by-product, our Latent-Class Hough
Forests can provide accurate occlusion aware segmentation masks, even in the
multi-instance scenario. In addition to an existing public dataset, which
contains only single-instance sequences with large amounts of clutter, we have
collected two, more challenging, datasets for multiple-instance detection
containing heavy 2D and 3D clutter as well as foreground occlusions. We provide
extensive experiments on the various parameters of the framework such as patch
size, number of trees and number of iterations to infer class distributions at
test time. We also evaluate the Latent-Class Hough Forests on all datasets
where we outperform state of the art methods.
</dc:description>
 <dc:description>Comment: PAMI submission, project page:
  http://www.iis.ee.ic.ac.uk/rkouskou/research/LCHF.html</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01464</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01483</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed Algorithm for Computing a Common Fixed Point of a Family
  of Paracontractions</dc:title>
 <dc:creator>Fullmer, Daniel</dc:creator>
 <dc:creator>Wang, Lili</dc:creator>
 <dc:creator>Morse, A. Stephen</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A distributed algorithm is described for finding a common fixed point of a
family of $m&gt;1$ nonlinear maps $M_i : \mathbb{R}^n \rightarrow \mathbb{R}^n$
assuming that each map is a paracontraction and that such a common fixed point
exists. The common fixed point is simultaneously computed by $m$ agents
assuming each agent $i$ knows only $M_i$, the current estimates of the fixed
point generated by its neighbors, and nothing more. Each agent recursively
updates its estimate of the fixed point by utilizing the current estimates
generated by each of its neighbors. Neighbor relations are characterized by a
time-dependent directed graph $\mathbb{N}(t)$ whose vertices correspond to
agents and whose arcs depict neighbor relations. It is shown that for any
family of paracontractions $M_i, i \in \{1,2,\ldots,m\}$ which has at least one
common fixed point, and any sequence of strongly connected neighbor graphs
$\mathbb{N}(t)$, $t=1,2,\ldots$, the algorithm causes all agent estimates to
converge to a common fixed point.
</dc:description>
 <dc:description>Comment: Accepted for the 10th IFAC Symposium on Nonlinear Control Systems
  (NOLCOS 2016)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01506</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Level-set methods for convex optimization</dc:title>
 <dc:creator>Aravkin, Aleksandr Y.</dc:creator>
 <dc:creator>Burke, James V.</dc:creator>
 <dc:creator>Drusvyatskiy, Dmitriy</dc:creator>
 <dc:creator>Friedlander, Michael P.</dc:creator>
 <dc:creator>Roy, Scott</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Convex optimization problems arising in applications often have favorable
objective functions and complicated constraints, thereby precluding first-order
methods from being immediately applicable. We describe an approach that
exchanges the roles of the objective and constraint functions, and instead
approximately solves a sequence of parametric level-set problems. A
zero-finding procedure, based on inexact function evaluations and possibly
inexact derivative information, leads to an efficient solution scheme for the
original problem. We describe the theoretical and practical properties of this
approach for a broad range of problems, including low-rank semidefinite
optimization, sparse optimization, and generalized linear models for inference.
</dc:description>
 <dc:description>Comment: 38 pages</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01509</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A View of Fog Computing from Networking Perspective</dc:title>
 <dc:creator>Luan, Tom H.</dc:creator>
 <dc:creator>Gao, Longxiang</dc:creator>
 <dc:creator>Li, Zhi</dc:creator>
 <dc:creator>Xiang, Yang</dc:creator>
 <dc:creator>We, Guiyi</dc:creator>
 <dc:creator>Sun, Limin</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  With smart devices, particular smartphones, becoming our everyday companions,
the ubiquitous mobile Internet and computing applications pervade people's
daily lives. With the surge demand on high-quality mobile services at anywhere,
how to address the ubiquitous user demand and accommodate the explosive growth
of mobile traffics is the key issue of the next generation mobile networks. The
Fog computing is a promising solution towards this goal. Fog computing extends
cloud computing by providing virtualized resources and engaged location-based
services to the edge of the mobile networks so as to better serve mobile
traffics. Therefore, Fog computing is a lubricant of the combination of cloud
computing and mobile applications. In this article, we outline the main
features of Fog computing and describe its concept, architecture and design
goals. Lastly, we discuss some of the future research issues from the
networking perspective.
</dc:description>
 <dc:description>Comment: The manuscript is an update version of arXiv:1502.01815 and has
  substantial text overlap with arXiv:1502.01815. It is therefore requested to
  be withdrawn to avoid duplication</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01510</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Regenerative Learning of Hierarchical Features in Spiking
  Deep Networks for Object Recognition</dc:title>
 <dc:creator>Panda, Priyadarshini</dc:creator>
 <dc:creator>Roy, Kaushik</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We present a spike-based unsupervised regenerative learning scheme to train
Spiking Deep Networks (SpikeCNN) for object recognition problems using
biologically realistic leaky integrate-and-fire neurons. The training
methodology is based on the Auto-Encoder learning model wherein the
hierarchical network is trained layer wise using the encoder-decoder principle.
Regenerative learning uses spike-timing information and inherent latencies to
update the weights and learn representative levels for each convolutional layer
in an unsupervised manner. The features learnt from the final layer in the
hierarchy are then fed to an output layer. The output layer is trained with
supervision by showing a fraction of the labeled training dataset and performs
the overall classification of the input. Our proposed methodology yields
0.92%/29.84% classification error on MNIST/CIFAR10 datasets which is comparable
with state-of-the-art results. The proposed methodology also introduces
sparsity in the hierarchical feature representations on account of event-based
coding resulting in computationally efficient learning.
</dc:description>
 <dc:description>Comment: 8 pages, 9 figures, &lt;Under review in IJCNN 2016&gt;</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01510</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01511</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear codes with a few weights from inhomogeneous quadratic functions</dc:title>
 <dc:creator>Tang, Chunming</dc:creator>
 <dc:creator>Xiang, Can</dc:creator>
 <dc:creator>Feng, Keqin</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Linear codes with few weights have been an interesting subject of study for
many years, as these codes have applications in secrete sharing, authentication
codes, association schemes, and strongly regular graphs. In this paper, linear
codes with a few weights are constructed from inhomogeneous quadratic functions
over the finite field $\gf(p)$, where $p$ is an odd prime. They include some
earlier linear codes as special cases. The weight distributions of these linear
codes are also determined.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01516</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Market-based Microgrid Optimal Scheduling</dc:title>
 <dc:creator>Parhizi, Sina</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents an optimal scheduling model for a microgrid participating
in the electricity distribution market in interaction with the Distribution
Market Operator (DMO). The DMO is a concept proposed here, which administers
the established electricity market in the distribution level, i.e., similar to
the role of Independent System Operator (ISO) in the wholesale electricity
market, sets electricity prices, determines the amounts of the power exchange
between market participators, and interacts with the ISO. Considering a
predetermined main grid power transfer to the microgrid, the microgrid
scheduling problem will aim at balancing the power supply and demand while
taking financial objectives into account. A stochastic programming method is
employed to model prevailing uncertainties in the microgrid grid-connected and
islanded operations. Numerical simulations exhibit the application and the
effectiveness of the proposed market-based microgrid scheduling model.
</dc:description>
 <dc:description>Comment: Appeared in 6th IEEE International Conference on Smart Grid
  Communications (SmartGridComm 2015)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01516</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01517</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Better Exploiting Convolutional Neural Networks for Remote
  Sensing Scene Classification</dc:title>
 <dc:creator>Nogueira, Keiller</dc:creator>
 <dc:creator>Penatti, Ot&#xe1;vio A. B.</dc:creator>
 <dc:creator>Santos, Jefersson A. dos</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We present an analysis of three possible strategies for exploiting the power
of existing convolutional neural networks (ConvNets) in different scenarios
from the ones they were trained: full training, fine tuning, and using ConvNets
as feature extractors. In many applications, especially including remote
sensing, it is not feasible to fully design and train a new ConvNet, as this
usually requires a considerable amount of labeled data and demands high
computational costs. Therefore, it is important to understand how to obtain the
best profit from existing ConvNets. We perform experiments with six popular
ConvNets using three remote sensing datasets. We also compare ConvNets in each
strategy with existing descriptors and with state-of-the-art baselines. Results
point that fine tuning tends to be the best performing strategy. In fact, using
the features from the fine-tuned ConvNet with linear SVM obtains the best
results. We also achieved state-of-the-art results for the three datasets used.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01517</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2016.07.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01520</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating the Necessity of Distribution Markets in Accomodating High
  Penetration Microgrids</dc:title>
 <dc:creator>Parhizi, Sina</dc:creator>
 <dc:creator>Khodaei, Amin</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The increased need for reliable, resilient, and high quality power combined
with a falling cost of distributed generation technologies has resulted in a
rapid growth of microgrid in power systems. Although providing multitude of
benefits, the microgrid power transfer with the main grid, which is commonly
obtained using economy and reliability consideration, may result in major
operational drawbacks, most notably, a large mismatch between actual and
forecasted system loads. This paper investigates the impact of high penetration
microgrids on the power system net load, and further proposes three paradigms
that can be adopted to address the emerging operational issues. The IEEE 6-bus
test system is used for numerical studies and to further support the
discussions.
</dc:description>
 <dc:description>Comment: To appear in &quot;IEEE PES Transmission and Distribution Conference,
  Dallas, TX, 2016.&quot;</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01520</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01528</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EIE: Efficient Inference Engine on Compressed Deep Neural Network</dc:title>
 <dc:creator>Han, Song</dc:creator>
 <dc:creator>Liu, Xingyu</dc:creator>
 <dc:creator>Mao, Huizi</dc:creator>
 <dc:creator>Pu, Jing</dc:creator>
 <dc:creator>Pedram, Ardavan</dc:creator>
 <dc:creator>Horowitz, Mark A.</dc:creator>
 <dc:creator>Dally, William J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  State-of-the-art deep neural networks (DNNs) have hundreds of millions of
connections and are both computationally and memory intensive, making them
difficult to deploy on embedded systems with limited hardware resources and
power budgets. While custom hardware helps the computation, fetching weights
from DRAM is two orders of magnitude more expensive than ALU operations, and
dominates the required power.
  Previously proposed 'Deep Compression' makes it possible to fit large DNNs
(AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by
pruning the redundant connections and having multiple connections share the
same weight. We propose an energy efficient inference engine (EIE) that
performs inference on this compressed network model and accelerates the
resulting sparse matrix-vector multiplication with weight sharing. Going from
DRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x;
Weight sharing gives 8x; Skipping zero activations from ReLU saves another 3x.
Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to
CPU and GPU implementations of the same DNN without compression. EIE has a
processing power of 102GOPS/s working directly on a compressed network,
corresponding to 3TOPS/s on an uncompressed network, and processes FC layers of
AlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is
24,000x and 3,400x more energy efficient than a CPU and GPU respectively.
Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy
efficiency and area efficiency.
</dc:description>
 <dc:description>Comment: External Links: TheNextPlatform: http://goo.gl/f7qX0L ; O'Reilly:
  https://goo.gl/Id1HNT ; Hacker News: https://goo.gl/KM72SV ; Embedded-vision:
  http://goo.gl/joQNg8 ; Talk at NVIDIA GTC'16: http://goo.gl/6wJYvn ; Talk at
  Embedded Vision Summit: https://goo.gl/7abFNe ; Talk at Stanford University:
  https://goo.gl/6lwuer. Published as a conference paper in ISCA 2016</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01528</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01530</identifier>
 <datestamp>2018-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomness Extraction in AC0 and with Small Locality</dc:title>
 <dc:creator>Cheng, Kuan</dc:creator>
 <dc:creator>Li, Xin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  Randomness extractors, which extract high quality (almost-uniform) random
bits from biased random sources, are important objects both in theory and in
practice. While there have been significant progress in obtaining near optimal
constructions of randomness extractors in various settings, the computational
complexity of randomness extractors is still much less studied. In particular,
it is not clear whether randomness extractors with good parameters can be
computed in several interesting complexity classes that are much weaker than P.
  In this paper we study randomness extractors in the following two models of
computation: (1) constant-depth circuits (AC0), and (2) the local computation
model. Previous work in these models, such as [Viola 2005 Complexity],
[Goldreich 2015 Randomness] and [Bogdanov 2013 Sparse], only achieve
constructions with weak parameters. In this work we give explicit constructions
of randomness extractors with much better parameters. As an application, we use
our AC0 extractors to study pseudorandom generators in AC0, and show that we
can construct both cryptographic pseudorandom generators (under reasonable
computational assumptions) and unconditional pseudorandom generators for space
bounded computation with very good parameters.
  Our constructions combine several previous techniques in randomness
extractors, as well as introduce new techniques to reduce or preserve the
complexity of extractors, which may be of independent interest. These include
(1) a general way to reduce the error of strong seeded extractors while
preserving the AC0 property and small locality, and (2) a seeded randomness
condenser with small locality.
</dc:description>
 <dc:description>Comment: 61 pages</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2018-01-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01530</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01532</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Transport Theory for Power-Efficient Deployment of Unmanned
  Aerial Vehicles</dc:title>
 <dc:creator>Mozaffari, Mohammad</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:creator>Debbah, Merouane</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the optimal deployment of multiple unmanned aerial vehicles
(UAVs) acting as flying base stations is investigated. Considering the downlink
scenario, the goal is to minimize the total required transmit power of UAVs
while satisfying the users' rate requirements. To this end, the optimal
locations of UAVs as well as the cell boundaries of their coverage areas are
determined. To find those optimal parameters, the problem is divided into two
sub-problems that are solved iteratively. In the first sub-problem, given the
cell boundaries corresponding to each UAV, the optimal locations of the UAVs
are derived using the facility location framework. In the second sub-problem,
the locations of UAVs are assumed to be fixed, and the optimal cell boundaries
are obtained using tools from optimal transport theory. The analytical results
show that the total required transmit power is significantly reduced by
determining the optimal coverage areas for UAVs. These results also show that,
moving the UAVs based on users' distribution, and adjusting their altitudes can
lead to a minimum power consumption. Finally, it is shown that the proposed
deployment approach, can improve the system's power efficiency by a factor of
20 compared to the classical Voronoi cell association technique with fixed UAVs
locations.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01532</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01537</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TopCom: Index for Shortest Distance Query in Directed Graph</dc:title>
 <dc:creator>Dave, Vachik S.</dc:creator>
 <dc:creator>Hasan, Mohammad Al</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Finding shortest distance between two vertices in a graph is an important
problem due to its numerous applications in diverse domains, including
geo-spatial databases, social network analysis, and information retrieval.
Classical algorithms (such as, Dijkstra) solve this problem in polynomial time,
but these algorithms cannot provide real-time response for a large number of
bursty queries on a large graph. So, indexing based solutions that pre-process
the graph for efficiently answering (exactly or approximately) a large number
of distance queries in real-time is becoming increasingly popular. Existing
solutions have varying performance in terms of index size, index building time,
query time, and accuracy. In this work, we propose T OP C OM , a novel
indexing-based solution for exactly answering distance queries. Our experiments
with two of the existing state-of-the-art methods (IS-Label and TreeMap) show
the superiority of T OP C OM over these two methods considering scalability and
query time. Besides, indexing of T OP C OM exploits the DAG (directed acyclic
graph) structure in the graph, which makes it significantly faster than the
existing methods if the SCCs (strongly connected component) of the input graph
are relatively small.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01541</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fundamental Limits in Multi-image Alignment</dc:title>
 <dc:creator>Aguerrebere, Cecilia</dc:creator>
 <dc:creator>Delbracio, Mauricio</dc:creator>
 <dc:creator>Bartesaghi, Alberto</dc:creator>
 <dc:creator>Sapiro, Guillermo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The performance of multi-image alignment, bringing different images into one
coordinate system, is critical in many applications with varied signal-to-noise
ratio (SNR) conditions. A great amount of effort is being invested into
developing methods to solve this problem. Several important questions thus
arise, including: Which are the fundamental limits in multi-image alignment
performance? Does having access to more images improve the alignment?
Theoretical bounds provide a fundamental benchmark to compare methods and can
help establish whether improvements can be made. In this work, we tackle the
problem of finding the performance limits in image registration when multiple
shifted and noisy observations are available. We derive and analyze the
Cram\'er-Rao and Ziv-Zakai lower bounds under different statistical models for
the underlying image. The accuracy of the derived bounds is experimentally
assessed through a comparison to the maximum likelihood estimator. We show the
existence of different behavior zones depending on the difficulty level of the
problem, given by the SNR conditions of the input images. We find that
increasing the number of images is only useful below a certain SNR threshold,
above which the pairwise MLE estimation proves to be optimal. The analysis we
present here brings further insight into the fundamental limitations of the
multi-image alignment problem.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01541</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2600517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01545</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correction of Data and Syndrome Errors by Stabilizer Codes</dc:title>
 <dc:creator>Ashikhmin, Alexei</dc:creator>
 <dc:creator>Lai, Ching-Yi</dc:creator>
 <dc:creator>Brun, Todd</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:description>  Performing active quantum error correction to protect fragile quantum states
highly depends on the correctness of error information--error syndromes. To
obtain reliable error syndromes using imperfect physical circuits, we propose
the idea of quantum data-syndrome (DS) codes that are capable of correcting
both data qubits and syndrome bits errors. We study fundamental properties of
quantum DS codes and provide several CSS-type code constructions of quantum DS
codes.
</dc:description>
 <dc:description>Comment: 2 figures. This is a short version of our full paper (in preparation)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01545</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01547</identifier>
 <datestamp>2016-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Under a cloud of uncertainty: Legal questions affecting Internet storage
  and transmission of copyright-protected video content</dc:title>
 <dc:creator>Fund, Fraida</dc:creator>
 <dc:creator>Hosseini, S. Amir</dc:creator>
 <dc:creator>Panwar, Shivendra S.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  The rapid growth of multimedia consumption has triggered technical, economic,
and business innovations that improve the quality and accessibility of content.
It has also opened new markets, promising large revenues for industry players.
However, new technologies also pose new questions regarding the legal aspects
of content delivery, which are often resolved through litigation between
copyright owners and content distributors. The precedents set by these cases
will act as a game changer in the content delivery industry and will shape the
existing offerings in the market in terms of how new technologies can be
deployed and what kind of pricing strategies can be associated with them. In
this paper, we offer a tutorial on key copyright and communications laws and
decisions related to storage and transmission of video content over the
Internet. We summarize legal limitations on the deployment of new technologies
and pricing mechanisms, and explain the implications of recent lawsuits.
Understanding these concerns is essential for engineers engaged in designing
the technical and economic aspects of video delivery systems.
</dc:description>
 <dc:description>Comment: Accepted in IEEE Network Special Issue on Smart Data Pricing</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01547</dc:identifier>
 <dc:identifier>IEEE Network, vol. 30, no. 2, pp. 32-38, March-April 2016</dc:identifier>
 <dc:identifier>doi:10.1109/MNET.2016.7437022</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01557</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An ensemble diversity approach to supervised binary hashing</dc:title>
 <dc:creator>Carreira-Perpi&#xf1;&#xe1;n, Miguel &#xc1;.</dc:creator>
 <dc:creator>Raziperchikolaei, Ramin</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Binary hashing is a well-known approach for fast approximate nearest-neighbor
search in information retrieval. Much work has focused on affinity-based
objective functions involving the hash functions or binary codes. These
objective functions encode neighborhood information between data points and are
often inspired by manifold learning algorithms. They ensure that the hash
functions differ from each other through constraints or penalty terms that
encourage codes to be orthogonal or dissimilar across bits, but this couples
the binary variables and complicates the already difficult optimization. We
propose a much simpler approach: we train each hash function (or bit)
independently from each other, but introduce diversity among them using
techniques from classifier ensembles. Surprisingly, we find that not only is
this faster and trivially parallelizable, but it also improves over the more
complex, coupled objective function, and achieves state-of-the-art precision
and recall in experiments with image retrieval.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01560</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online energy efficient packet scheduling for a common deadline with and
  without energy harvesting</dc:title>
 <dc:creator>Deshmukh, Aditya</dc:creator>
 <dc:creator>Vaze, Rahul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The problem of online packet scheduling to minimize the required conventional
grid energy for transmitting a fixed number of packets given a common deadline
is considered. The total number of packets arriving within the deadline is
known, but the packet arrival times are unknown, and can be arbitrary. The
proposed algorithm tries to finish the transmission of each packet assuming all
future packets are going to arrive at equal time intervals within the left-over
time. The proposed online algorithm is shown to have competitive ratio that is
logarithmic in the number of packet arrivals. The hybrid energy paradigm is
also considered, where in addition to grid energy, energy is also available via
extraction from renewable sources. The objective here is to minimize the grid
energy use. A suitably modified version of the previous algorithm is also shown
to have competitive ratio that is logarithmic in the number of packet arrivals.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01560</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01565</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Context-Aware Scheduling of Joint Millimeter Wave and Microwave
  Resources for Dual-Mode Base Stations</dc:title>
 <dc:creator>Semiari, Omid</dc:creator>
 <dc:creator>Saad, Walid</dc:creator>
 <dc:creator>Bennis, Mehdi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  One of the most promising approaches to overcome the drastic channel
variations of millimeter wave (mmW) communications is to deploy dual-mode base
stations that integrate both mmW and microwave (\muW) frequencies. Reaping the
benefits of a dual-mode operation requires scheduling mechanisms that can
allocate resources efficiently and jointly at both frequency bands. In this
paper, a novel resource allocation framework is proposed that exploits users'
context, in terms of user application (UA) delay requirements, to maximize the
quality-of-service (QoS) of a dual-mode base station. In particular, such a
context-aware approach enables the network to dynamically schedule UAs, instead
of users, thus providing more precise delay guarantees and a more efficient
exploitation of the mmW resources. The scheduling of UAs is formulated as a
one-to-many matching problem between UAs and resources and a novel algorithm is
proposed to solve it. The proposed algorithm is shown to converge to a
two-sided stable matching between UAs and network resources. Simulation results
show that the proposed approach outperforms classical CSI-based scheduling in
terms of the per UA QoS, yielding up to 36% improvement. The results also show
that exploiting mmW resources provides significant traffic offloads reaching up
to 43% from \muW band.
</dc:description>
 <dc:description>Comment: In Proc. of the IEEE International Conference on Communications
  (ICC), Mobile and Wireless Networks Symposium, Kualalumpur, Malaysia, May
  2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01565</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7510912</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01567</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Testing Wireless Sensor Networks with Hybrid Simulators</dc:title>
 <dc:creator>Saginbekov, Sain</dc:creator>
 <dc:creator>Shakenov, Chingiz</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Software development for Wireless Sensor Networks (WSNs) is challenging due
to characteristics of sensor nodes and the environment they are deployed in.
Testing software in a real WSN testbed allows users to get reliable test
results. However, real testbeds become more expensive as the number of sensor
nodes in the network grows. Simulation tools are alternatives to real testbeds.
They are cheaper, faster and repeatable. However, simulation results are not
reliable as that of testbeds. Therefore, there is a need for a testing tool
that can leverage the advantages of testbeds and simulation tools. These tools
are usually called hybrid simulators. In this survey, we discuss several hybrid
simulators that use real sensor motes integrated with a simulator to make
software development cheaper, repeatable and to make the results more reliable.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01567</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01569</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unraveling the Rank-One Solution Mystery of Robust MISO Downlink
  Transmit Optimization: A Verifiable Sufficient Condition via a New Duality
  Result</dc:title>
 <dc:creator>Ma, Wing-Kin</dc:creator>
 <dc:creator>Pan, Jiaxian</dc:creator>
 <dc:creator>So, Anthony Man-Cho</dc:creator>
 <dc:creator>Chang, Tsung-Hui</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper concentrates on a robust transmit optimization problem for the
multiuser multi-input single-output (MISO) downlink scenario and under
inaccurate channel state information (CSI). This robust problem deals with a
general-rank transmit covariance design, and it follows a safe rate-constrained
formulation under spherically bounded CSI uncertainties. Curiously, simulation
results in previous works suggested that the robust problem admits rank-one
optimal transmit covariances in most cases. Such a numerical finding is
appealing because transmission with rank-one covariances can be easily realized
by single-stream transmit beamforming. This gives rise to a fundamentally
important question, namely, whether we can theoretically identify conditions
under which the robust problem admits a rank-one solution. In this paper, we
identify one such condition. Simply speaking, we show that the robust problem
is guaranteed to admit a rank-one solution if the CSI uncertainties are not too
large and the multiuser channel is not too poorly conditioned. To establish the
aforementioned condition, we develop a novel duality framework, through which
an intimate relationship between the robust problem and a related maximin
problem is revealed. Our condition involves only a simple expression with
respect to the multiuser channel and other system parameters. In particular,
unlike other sufficient rank-one conditions that have appeared in the
literature, ours is verifiable. The application of our analysis framework to
several other CSI uncertainty models is also discussed.
</dc:description>
 <dc:description>Comment: To appear in IEEE Trans. Signal Process. This version combines the
  main manuscript and its accompanied supplementary report into one single
  article</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-12-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01569</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2649488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01576</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Factorized Recurrent Neural Network based architecture for medium to
  large vocabulary Language Modelling</dc:title>
 <dc:creator>Iyer, Anantharaman Palacode Narayana</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Statistical language models are central to many applications that use
semantics. Recurrent Neural Networks (RNN) are known to produce state of the
art results for language modelling, outperforming their traditional n-gram
counterparts in many cases. To generate a probability distribution across a
vocabulary, these models require a softmax output layer that linearly increases
in size with the size of the vocabulary. Large vocabularies need a
commensurately large softmax layer and training them on typical laptops/PCs
requires significant time and machine resources. In this paper we present a new
technique for implementing RNN based large vocabulary language models that
substantially speeds up computation while optimally using the limited memory
resources. Our technique, while building on the notion of factorizing the
output layer by having multiple output layers, improves on the earlier work by
substantially optimizing on the individual output layer size and also
eliminating the need for a multistep prediction process.
</dc:description>
 <dc:description>Comment: 8 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01576</dc:identifier>
 <dc:identifier>doi:10.1109/ICSC.2016.37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01577</identifier>
 <datestamp>2017-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>New Coupled Codes Constructed by Overlapping Circular SC-LDPC Codes</dc:title>
 <dc:creator>Kwak, Heeyoul</dc:creator>
 <dc:creator>Jun, Bohwan</dc:creator>
 <dc:creator>Yang, Pilwoong</dc:creator>
 <dc:creator>No, Jong-Seon</dc:creator>
 <dc:creator>Shin, Dong-Joon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we propose new coupled codes constructed by overlapping
circular spatially-coupled low-density parity-check (SC-LDPC) codes, which show
better asymptotic and finite-length decoding performance compared to the
conventional SC-LDPC codes. The performance improvement comes from the property
that the proposed codes effectively split into two separated SC-LDPC codes with
shorter chain length during the decoding process. We verify that the property
of the proposed codes is valid in asymptotic setting via analysis tools such as
the density evolution and the expected graph evolution. Experimental results
show that the proposed codes also outperform the conventional SC-LDPC codes in
terms of the finite-length performance under belief propagation decoding.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01577</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01580</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Long-term Planning by Short-term Prediction</dc:title>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:creator>Ben-Zrihem, Nir</dc:creator>
 <dc:creator>Cohen, Aviad</dc:creator>
 <dc:creator>Shashua, Amnon</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider planning problems, that often arise in autonomous driving
applications, in which an agent should decide on immediate actions so as to
optimize a long term objective. For example, when a car tries to merge in a
roundabout it should decide on an immediate acceleration/braking command, while
the long term effect of the command is the success/failure of the merge. Such
problems are characterized by continuous state and action spaces, and by
interaction with multiple agents, whose behavior can be adversarial. We argue
that dual versions of the MDP framework (that depend on the value function and
the $Q$ function) are problematic for autonomous driving applications due to
the non Markovian of the natural state space representation, and due to the
continuous state and action spaces. We propose to tackle the planning task by
decomposing the problem into two phases: First, we apply supervised learning
for predicting the near future based on the present. We require that the
predictor will be differentiable with respect to the representation of the
present. Second, we model a full trajectory of the agent using a recurrent
neural network, where unexplained factors are modeled as (additive) input
nodes. This allows us to solve the long-term planning problem using supervised
learning techniques and direct optimization over the recurrent neural network.
Our approach enables us to learn robust policies by incorporating adversarial
elements to the environment.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01580</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01581</identifier>
 <datestamp>2016-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Construction of High Dimensional Simple Games</dc:title>
 <dc:creator>Olsen, Martin</dc:creator>
 <dc:creator>Kurz, Sascha</dc:creator>
 <dc:creator>Molinero, Xavier</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>91B12, 91A12, 68P30</dc:subject>
 <dc:description>  Voting is a commonly applied method for the aggregation of the preferences of
multiple agents into a joint decision. If preferences are binary, i.e., &quot;yes&quot;
and &quot;no&quot;, every voting system can be described by a (monotone) Boolean function
$\chi\colon\{0,1\}^n\rightarrow \{0,1\}$. However, its naive encoding needs
$2^n$ bits. The subclass of threshold functions, which is sufficient for
homogeneous agents, allows a more succinct representation using $n$ weights and
one threshold. For heterogeneous agents, one can represent $\chi$ as an
intersection of $k$ threshold functions. Taylor and Zwicker have constructed a
sequence of examples requiring $k\ge 2^{\frac{n}{2}-1}$ and provided a
construction guaranteeing $k\le {n\choose {\lfloor n/2\rfloor}}\in 2^{n-o(n)}$.
The magnitude of the worst-case situation was thought to be determined by
Elkind et al.~in 2008, but the analysis unfortunately turned out to be wrong.
Here we uncover a relation to coding theory that allows the determination of
the minimum number $k$ for a subclass of voting systems. As an application, we
give a construction for $k\ge 2^{n-o(n)}$, i.e., there is no gain from a
representation complexity point of view.
</dc:description>
 <dc:description>Comment: 13 pages, 1 table</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-07-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01581</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01582</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDCA without Duality, Regularization, and Individual Convexity</dc:title>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic Dual Coordinate Ascent is a popular method for solving regularized
loss minimization for the case of convex losses. We describe variants of SDCA
that do not require explicit regularization and do not rely on duality. We
prove linear convergence rates even if individual loss functions are
non-convex, as long as the expected loss is strongly convex.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01582</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01585</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ups and Downs: Modeling the Visual Evolution of Fashion Trends with
  One-Class Collaborative Filtering</dc:title>
 <dc:creator>He, Ruining</dc:creator>
 <dc:creator>McAuley, Julian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Building a successful recommender system depends on understanding both the
dimensions of people's preferences as well as their dynamics. In certain
domains, such as fashion, modeling such preferences can be incredibly
difficult, due to the need to simultaneously model the visual appearance of
products as well as their evolution over time. The subtle semantics and
non-linear dynamics of fashion evolution raise unique challenges especially
considering the sparsity and large scale of the underlying datasets. In this
paper we build novel models for the One-Class Collaborative Filtering setting,
where our goal is to estimate users' fashion-aware personalized ranking
functions based on their past feedback. To uncover the complex and evolving
visual factors that people consider when evaluating products, our method
combines high-level visual features extracted from a deep convolutional neural
network, users' past feedback, as well as evolving trends within the community.
Experimentally we evaluate our method on two large real-world datasets from
Amazon.com, where we show it to outperform state-of-the-art personalized
ranking measures, and also use it to visualize the high-level fashion trends
across the 11-year span of our dataset.
</dc:description>
 <dc:description>Comment: 11 pages, 5 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01585</dc:identifier>
 <dc:identifier>doi:10.1145/2872427.2883037</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01595</identifier>
 <datestamp>2016-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Many Languages, One Parser</dc:title>
 <dc:creator>Ammar, Waleed</dc:creator>
 <dc:creator>Mulcaire, George</dc:creator>
 <dc:creator>Ballesteros, Miguel</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We train one multilingual model for dependency parsing and use it to parse
sentences in several languages. The parsing model uses (i) multilingual word
clusters and embeddings; (ii) token-level language information; and (iii)
language-specific features (fine-grained POS tags). This input representation
enables the parser not only to parse effectively in multiple languages, but
also to generalize across languages based on linguistic universals and
typological similarities, making it more effective to learn from limited
annotations. Our parser's performance compares favorably to strong baselines in
a range of data scenarios, including when the target language has a large
treebank, a small treebank, or no treebank for training.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01595</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01599</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparative Evaluation of Action Recognition Methods via Riemannian
  Manifolds, Fisher Vectors and GMMs: Ideal and Challenging Conditions</dc:title>
 <dc:creator>Carvajal, Johanna</dc:creator>
 <dc:creator>Wiliem, Arnold</dc:creator>
 <dc:creator>McCool, Chris</dc:creator>
 <dc:creator>Lovell, Brian</dc:creator>
 <dc:creator>Sanderson, Conrad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  We present a comparative evaluation of various techniques for action
recognition while keeping as many variables as possible controlled. We employ
two categories of Riemannian manifolds: symmetric positive definite matrices
and linear subspaces. For both categories we use their corresponding nearest
neighbour classifiers, kernels, and recent kernelised sparse representations.
We compare against traditional action recognition techniques based on Gaussian
mixture models and Fisher vectors (FVs). We evaluate these action recognition
techniques under ideal conditions, as well as their sensitivity in more
challenging conditions (variations in scale and translation). Despite recent
advancements for handling manifolds, manifold based techniques obtain the
lowest performance and their kernel representations are more unstable in the
presence of challenging conditions. The FV approach obtains the highest
accuracy under ideal conditions. Moreover, FV best deals with moderate scale
and translation changes.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01599</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science (LNCS), Vol. 9794, pp. 88-100,
  2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-42996-0_8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01600</identifier>
 <datestamp>2017-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of Geometric Molecular Bonds</dc:title>
 <dc:creator>Doty, David</dc:creator>
 <dc:creator>Winslow, Andrew</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  An example of a nonspecific molecular bond is the affinity of any positive
charge for any negative charge (like-unlike), or of nonpolar material for
itself when in aqueous solution (like-like). This contrasts specific bonds such
as the affinity of the DNA base A for T, but not for C, G, or another A. Recent
experimental breakthroughs in DNA nanotechnology demonstrate that a particular
nonspecific like-like bond (&quot;blunt-end DNA stacking&quot; that occurs between the
ends of any pair of DNA double-helices) can be used to create specific
&quot;macrobonds&quot; by careful geometric arrangement of many nonspecific blunt ends,
motivating the need for sets of macrobonds that are orthogonal: two macrobonds
not intended to bind should have relatively low binding strength, even when
misaligned.
  To address this need, we introduce geometric orthogonal codes that abstractly
model the engineered DNA macrobonds as two-dimensional binary codewords. While
motivated by completely different applications, geometric orthogonal codes
share similar features to the optical orthogonal codes studied by Chung,
Salehi, and Wei. The main technical difference is the importance of 2D geometry
in defining codeword orthogonality.
</dc:description>
 <dc:description>Comment: Accepted to appear in IEEE Transactions on Molecular, Biological, and
  Multi-Scale Communications</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01601</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Recognition and Segmentation of Actions via Probabilistic
  Integration of Spatio-Temporal Fisher Vectors</dc:title>
 <dc:creator>Carvajal, Johanna</dc:creator>
 <dc:creator>McCool, Chris</dc:creator>
 <dc:creator>Lovell, Brian</dc:creator>
 <dc:creator>Sanderson, Conrad</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>I.2.10</dc:subject>
 <dc:subject>I.4</dc:subject>
 <dc:subject>I.5</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  We propose a hierarchical approach to multi-action recognition that performs
joint classification and segmentation. A given video (containing several
consecutive actions) is processed via a sequence of overlapping temporal
windows. Each frame in a temporal window is represented through selective
low-level spatio-temporal features which efficiently capture relevant local
dynamics. Features from each window are represented as a Fisher vector, which
captures first and second order statistics. Instead of directly classifying
each Fisher vector, it is converted into a vector of class probabilities. The
final classification decision for each frame is then obtained by integrating
the class probabilities at the frame level, which exploits the overlapping of
the temporal windows. Experiments were performed on two datasets: s-KTH (a
stitched version of the KTH dataset to simulate multi-actions), and the
challenging CMU-MMAC dataset. On s-KTH, the proposed approach achieves an
accuracy of 85.0%, significantly outperforming two recent approaches based on
GMMs and HMMs which obtained 78.3% and 71.2%, respectively. On CMU-MMAC, the
proposed approach achieves an accuracy of 40.9%, outperforming the GMM and HMM
approaches which obtained 33.7% and 38.4%, respectively. Furthermore, the
proposed system is on average 40 times faster than the GMM based approach.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01601</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science (LNCS), Vol. 9794, pp. 115-127,
  2016</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-42996-0_10</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01608</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Appearance Based Robot and Human Activity Recognition System</dc:title>
 <dc:creator>Mandal, Bappaditya</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present an appearance based human activity recognition
system. It uses background modeling to segment the foreground object and
extracts useful discriminative features for representing activities performed
by humans and robots. Subspace based method like principal component analysis
is used to extract low dimensional features from large voluminous activity
images. These low dimensional features are then used to classify an activity.
An apparatus is designed using a webcam, which watches a robot replicating a
human fall under indoor environment. In this apparatus, a robot performs
various activities (like walking, bending, moving arms) replicating humans,
which also includes a sudden fall. Experimental results on robot performing
various activities and standard human activity recognition databases show the
efficacy of our proposed method.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01608</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01614</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectivity Scaling Laws in Wireless Networks</dc:title>
 <dc:creator>Coon, Justin P.</dc:creator>
 <dc:creator>Georgiou, Orestis</dc:creator>
 <dc:creator>Dettmann, Carl P.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present scaling laws that dictate both local and global connectivity
properties of bounded wireless networks. These laws are defined with respect to
the key system parameters of per-node transmit power and the number of antennas
exploited for diversity coding and/or beamforming at each node. We demonstrate
that the local probability of connectivity scales like $\mathcal{O}(z^\mathcal
C)$ in these parameters, where $\mathcal C$ is the ratio of the dimension of
the network domain to the path loss exponent, thus enabling efficient boundary
effect mitigation and network topology control.
</dc:description>
 <dc:description>Comment: 4 pages, 1 figure</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01614</dc:identifier>
 <dc:identifier>IEEE Wireless Communications Letters 4 (2015): 629-632</dc:identifier>
 <dc:identifier>doi:10.1109/LWC.2015.2476488</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01616</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Based Implementation of Deep Neural Networks Using On-chip Memory
  Only</dc:title>
 <dc:creator>Park, Jinhwan</dc:creator>
 <dc:creator>Sung, Wonyong</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep neural networks (DNNs) demand a very large amount of computation and
weight storage, and thus efficient implementation using special purpose
hardware is highly desired. In this work, we have developed an FPGA based
fixed-point DNN system using only on-chip memory not to access external DRAM.
The execution time and energy consumption of the developed system is compared
with a GPU based implementation. Since the capacity of memory in FPGA is
limited, only 3-bit weights are used for this implementation, and training
based fixed-point weight optimization is employed. The implementation using
Xilinx XC7Z045 is tested for the MNIST handwritten digit recognition benchmark
and a phoneme recognition task on TIMIT corpus. The obtained speed is about one
quarter of a GPU based implementation and much better than that of a PC based
one. The power consumption is less than 5 Watt at the full speed operation
resulting in much higher efficiency compared to GPU based systems.
</dc:description>
 <dc:description>Comment: Published in ICASSP 2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01619</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Power Allocation and Channel Access Probability Assignment
  for Cognitive Radio</dc:title>
 <dc:creator>Georgiou, Orestis</dc:creator>
 <dc:creator>Bocus, Mohammud Z.</dc:creator>
 <dc:creator>Wang, Shanshan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we present a framework for distributively optimizing the
transmission strategies of secondary users in an ad hoc cognitive radio
network. In particular, the proposed approach allows secondary users to set
their transmit powers and channel access probabilities such that, on average,
the quality of service of both the primary and secondary networks are
satisfied. The system under consideration assumes several primary and secondary
transceiver pairs and assumes no cooperation or information exchange between
neither primary and secondary users nor among secondary users. The outage
probability, and consequently the connection probability, is derived for the
system and is used in defining a new performance metric in the optimization
problem using tools from stochastic geometry. We refer to this metric as the
spatial density of successful transmission. We corroborate our derivations
through numerical evaluations. We further demonstrate that even in the absence
of any form of cooperation, an acceptable quality of service can be attained in
the cognitive radio environment.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, Published in Proceedings of IEEE Globecom 2015</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01620</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Green Enterprise Computing Architecture for Developing Countries</dc:title>
 <dc:creator>Akbar, Rabia</dc:creator>
 <dc:creator>Azim, Tahir</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Developing countries often have access to limited energy resources, which
frequently results in power cuts and failures. During these power cuts,
enterprises rely on backup sources for power such as uninterruptible power
supplies (UPS) and electric generators. This paper proposes AnywareDC, an
architecture that builds on the recent work on Anyware to reduce energy
utilization in the presence of such intermittent power supplies. Anyware
reduces energy usage by providing enterprise users laptops instead of desktops,
while maintaining performance using a central compute cluster. Our basic
insight is that in the presence of power cuts, only the routers and the cluster
needs to be provided power: the laptops can continue to run on their own
batteries. This reduces both energy usage and UPS load allowing it to supply
power for longer, thus also saving generator fuel costs. Simulations show that
this architecture reduces energy usage by up to 80% compared to one not using
Anyware, and by up to 20% compared to Anyware.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01623</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Connectivity of Cooperative Ad hoc Networks</dc:title>
 <dc:creator>Georgiou, Orestis</dc:creator>
 <dc:creator>Kalogridis, Georgios</dc:creator>
 <dc:creator>Yassine, Hachem</dc:creator>
 <dc:creator>Denic, Stojan</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The connectivity properties of ad hoc networks have been extensively studied
over the past few years, from local observables, to global network properties.
In this paper we introduce a novel layer of network dynamics which lives and
evolves on top of the ad hoc network. Nodes are assumed selfish and a
snow-drift type game is defined dictating the way nodes decide to allocate
their cooperative resource efforts towards other nodes in the network. The
dynamics are strongly coupled with the physical network causing the cooperation
network topology to converge towards a stable equilibrium state, a global
maximum of the total pay-off. We study this convergence from a connectivity
perspective and analyse the inherent parameter dependence. Moreover, we show
that direct reciprocity can be an efficient incentive to promote cooperation
within the network and discuss the analogies between our simple yet tractable
framework with D2D proximity based services such as LTE-Direct. We argue that
cooperative network dynamics have many application in ICT, not just ad hoc
networks, and similar models as the one described herein can be devised and
studied in their own right.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01625</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-Transfer Learning for Fully Weakly Supervised Object Localization</dc:title>
 <dc:creator>Hwang, Sangheum</dc:creator>
 <dc:creator>Kim, Hyo-Eun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent advances of deep learning have achieved remarkable performances in
various challenging computer vision tasks. Especially in object localization,
deep convolutional neural networks outperform traditional approaches based on
extraction of data/task-driven features instead of hand-crafted features.
Although location information of region-of-interests (ROIs) gives good prior
for object localization, it requires heavy annotation efforts from human
resources. Thus a weakly supervised framework for object localization is
introduced. The term &quot;weakly&quot; means that this framework only uses image-level
labeled datasets to train a network. With the help of transfer learning which
adopts weight parameters of a pre-trained network, the weakly supervised
learning framework for object localization performs well because the
pre-trained network already has well-trained class-specific features. However,
those approaches cannot be used for some applications which do not have
pre-trained networks or well-localized large scale images. Medical image
analysis is a representative among those applications because it is impossible
to obtain such pre-trained networks. In this work, we present a &quot;fully&quot; weakly
supervised framework for object localization (&quot;semi&quot;-weakly is the counterpart
which uses pre-trained filters for weakly supervised localization) named as
self-transfer learning (STL). It jointly optimizes both classification and
localization networks simultaneously. By controlling a supervision level of the
localization network, STL helps the localization network focus on correct ROIs
without any types of priors. We evaluate the proposed STL framework using two
medical image datasets, chest X-rays and mammograms, and achieve signiticantly
better localization performance compared to previous weakly supervised
approaches.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01625</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01626</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spectral deferred corrections with fast-wave slow-wave splitting</dc:title>
 <dc:creator>Ruprecht, Daniel</dc:creator>
 <dc:creator>Speck, Robert</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65M70, 65M20, 65L05, 65L04</dc:subject>
 <dc:description>  The paper investigates a variant of semi-implicit spectral deferred
corrections (SISDC) in which the stiff, fast dynamics correspond to fast
propagating waves (&quot;fast-wave slow-wave problem&quot;). We show that for a scalar
test problem with two imaginary eigenvalues $i \lambda_{fast}$, $i
\lambda_{slow}$, having $\Delta t \left(\left| \lambda_{fast} \right| + \left|
\lambda_{slow} \right| \right) &lt; 1$ is sufficient for the fast-wave slow-wave
SDC (FWSW-SDC) iteration to converge and that in the limit of infinitely fast
waves the convergence rate of the non-split version is retained. Stability
function and discrete dispersion relation are derived and show that the method
is stable for essentially arbitrary fast-wave CFL numbers as long as the slow
dynamics are resolved. The method causes little numerical diffusion and its
semi-discrete phase speed is accurate also for large wave number modes.
Performance is studied for an acoustic-advection problem and for the linearised
Boussinesq equations, describing compressible, stratified flow. FWSW-SDC is
compared to a diagonally implicit Runge-Kutta (DIRK) and IMEX Runge-Kutta
(IMEX) method and found to be competitive in terms of both accuracy and cost.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-06-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01626</dc:identifier>
 <dc:identifier>SIAM Journal on Scientific Computing 38(4), pp. A2535-A2557, 2016</dc:identifier>
 <dc:identifier>doi:10.1137/16M1060078</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01628</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Object-Oriented Dynamic Networks. II</dc:title>
 <dc:creator>Terletskyi, D. A.</dc:creator>
 <dc:creator>Provotar, A. I.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>I.2.4</dc:subject>
 <dc:subject>D.1.5</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>E.2</dc:subject>
 <dc:description>  This article generalizes object-oriented dynamic networks to the fuzzy case,
which allows one to represent knowledge on objects and classes of objects that
are fuzzy by nature and also to model their changes in time. Within the
framework of the approach described, a mechanism is proposed that makes it
possible to acquire new knowledge on the basis of basic knowledge and
considerably differs from well-known methods used in existing models of
knowledge representation. The approach is illustrated by an example of
construction of a concrete fuzzy object-oriented dynamic network.
</dc:description>
 <dc:description>Comment: 2 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01628</dc:identifier>
 <dc:identifier>Cybernetics and Systems Analysis, 2016, Volume 52, Issue 1, pp
  38-45</dc:identifier>
 <dc:identifier>doi:10.1007/s10559-016-9797-2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01629</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online and Global Network Optimization: Towards the Next-Generation of
  Routing Platforms</dc:title>
 <dc:creator>Leguay, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:creator>Draief, Moez</dc:creator>
 <dc:creator>Chouvardas, Symeon</dc:creator>
 <dc:creator>Paris, Stefano</dc:creator>
 <dc:creator>Paschos, Georgios S.</dc:creator>
 <dc:creator>Maggi, Lorenzo</dc:creator>
 <dc:creator>Qi, Meiyu</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The computation power of SDN controllers fosters the development of a new
generation of control plane that uses compute-intensive operations to automate
and optimize the network configuration across layers. From now on, cutting-edge
optimization and machine learning algorithms can be used to control networks in
real-time. This formidable opportunity transforms the way routing systems
should be conceived and designed. This paper presents a candidate architecture
for the next generation of routing platforms built on three main pillars for
admission control, re-routing and monitoring that would have not been possible
in legacy control planes.
</dc:description>
 <dc:description>Comment: 16 pages, 6 figures, Under submission</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01635</identifier>
 <datestamp>2017-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalised Quantifier Theory of Natural Language in Categorical
  Compositional Distributional Semantics with Bialgebras</dc:title>
 <dc:creator>Hedges, Jules</dc:creator>
 <dc:creator>Sadrzadeh, Mehrnoosh</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>cs.CL, cs.AI, math.CT</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  Categorical compositional distributional semantics is a model of natural
language; it combines the statistical vector space models of words with the
compositional models of grammar. We formalise in this model the generalised
quantifier theory of natural language, due to Barwise and Cooper. The
underlying setting is a compact closed category with bialgebras. We start from
a generative grammar formalisation and develop an abstract categorical
compositional semantics for it, then instantiate the abstract setting to sets
and relations and to finite dimensional vector spaces and linear maps. We prove
the equivalence of the relational instantiation to the truth theoretic
semantics of generalised quantifiers. The vector space instantiation formalises
the statistical usages of words and enables us to, for the first time, reason
about quantified phrases and sentences compositionally in distributional
semantics.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-09-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01641</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orientations of Simplices Determined by Orderings on the Coordinates of
  their Vertices</dc:title>
 <dc:creator>Gioan, Emeric</dc:creator>
 <dc:creator>Sol, Kevin</dc:creator>
 <dc:creator>Subsol, G&#xe9;rard</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Provided n points in an (n-1)-dimensional affine space, and one ordering of
the points for each coordinate, we address the problem of testing whether these
orderings determine if the points are the vertices of a simplex (i.e. are
affinely independent), regardless of the real values of the coordinates. We
also attempt to determine the orientation of this simplex. In other words,
given a matrix whose columns correspond to affine points, we want to know when
the sign (or the non-nullity) of its determinant is implied by orderings given
to each row for the values of the row. We completely solve the problem in
dimensions 2 and 3. We provide a direct combinatorial characterization, along
with a formal calculus method. It can also be viewed as a decision algorithm,
and is based on testing the existence of a suitable inductive cofactor
expansion of the determinant. We conjecture that our method generalizes in
higher dimensions. This work aims to be part of a study on how oriented
matroids encode shapes of 3-dimensional landmark-based objects. Specifically,
applications include the analysis of anatomical data for physical anthropology
and clinical research.
</dc:description>
 <dc:description>Comment: Full length paper submitted to a journal. A short conference version
  has been published [5]</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01644</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A semi-automatic computer-aided method for surgical template design</dc:title>
 <dc:creator>Chen, Xiaojun</dc:creator>
 <dc:creator>Xu, Lu</dc:creator>
 <dc:creator>Yang, Yue</dc:creator>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper presents a generalized integrated framework of semi-automatic
surgical template design. Several algorithms were implemented including the
mesh segmentation, offset surface generation, collision detection, ruled
surface generation, etc., and a special software named TemDesigner was
developed. With a simple user interface, a customized template can be semi-
automatically designed according to the preoperative plan. Firstly, mesh
segmentation with signed scalar of vertex is utilized to partition the inner
surface from the input surface mesh based on the indicated point loop. Then,
the offset surface of the inner surface is obtained through contouring the
distance field of the inner surface, and segmented to generate the outer
surface. Ruled surface is employed to connect inner and outer surfaces.
Finally, drilling tubes are generated according to the preoperative plan
through collision detection and merging. It has been applied to the template
design for various kinds of surgeries, including oral implantology, cervical
pedicle screw insertion, iliosacral screw insertion and osteotomy,
demonstrating the efficiency, functionality and generality of our method.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures, 2 tables, 36 references</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01644</dc:identifier>
 <dc:identifier>Scientific Reports 6, Article number: 20280, 2016</dc:identifier>
 <dc:identifier>doi:10.1038/srep20280</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01648</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Uniformity Properties of Construction C</dc:title>
 <dc:creator>Bollauf, Maiara F.</dc:creator>
 <dc:creator>Zamir, Ram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Construction C (also known as Forney's multi-level code formula) forms a
Euclidean code for the additive white Gaussian noise (AWGN) channel from $L$
binary code components. If the component codes are linear, then the minimum
distance is the same for all the points, although the kissing number may vary.
In fact, while in the single level ($L=1$) case it reduces to lattice
Construction A, a multi-level Construction C is in general not a lattice. We
show that the two-level ($L=2$) case is special: a two-level Construction C
satisfies Forney's definition for a geometrically uniform constellation.
Specifically, every point sees the same configuration of neighbors, up to a
reflection of the coordinates in which the lower level code is equal to 1. In
contrast, for three levels and up ($L\geq 3$), we construct examples where the
distance spectrum varies between the points, hence the constellation is not
geometrically uniform.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure, submitted to ISIT 2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-05-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01652</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamics of Disagreement: Large-Scale Temporal Network Analysis Reveals
  Negative Interactions in Online Collaboration</dc:title>
 <dc:creator>Tsvetkova, Milena</dc:creator>
 <dc:creator>Garc&#xed;a-Gavilanes, Ruth</dc:creator>
 <dc:creator>Yasseri, Taha</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Disagreement and conflict are a fact of social life and considerably affect
our well-being and productivity. Such negative interactions are rarely
explicitly declared and recorded and this makes them hard for scientists to
study. We overcome this challenge by investigating the patterns in the timing
and configuration of contributions to a large online collaboration community.
We analyze sequences of reverts of contributions to Wikipedia, the largest
online encyclopedia, and investigate how often and how fast they occur compared
to a null model that randomizes the order of actions to remove any systematic
clustering. We find evidence that individuals systematically attack the same
person and attack back their attacker; both of these interactions occur at a
faster response rate than expected. We also establish that individuals come to
defend an attack victim but we do not find evidence that attack victims &quot;pay it
forward&quot; or that attackers collude to attack the same individual. We further
find that high-status contributors are more likely to attack many others
serially, status equals are more likely to revenge attacks back, while attacks
by lower-status contributors trigger attacks forward; yet, it is the
lower-status contributors who also come forward to defend third parties. The
method we use can be applied to other large-scale temporal communication and
collaboration networks to identify the existence of negative social
interactions and other social processes.
</dc:description>
 <dc:description>Comment: Forthcoming in Scientific Reports</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-10-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01652</dc:identifier>
 <dc:identifier>Scientific Reports (2016) 6:36333</dc:identifier>
 <dc:identifier>doi:10.1038/srep36333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01659</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accelerating Local Search for the Maximum Independent Set Problem</dc:title>
 <dc:creator>Dahlum, Jakob</dc:creator>
 <dc:creator>Lamm, Sebastian</dc:creator>
 <dc:creator>Sanders, Peter</dc:creator>
 <dc:creator>Schulz, Christian</dc:creator>
 <dc:creator>Strash, Darren</dc:creator>
 <dc:creator>Werneck, Renato F.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  Computing high-quality independent sets quickly is an important problem in
combinatorial optimization. Several recent algorithms have shown that
kernelization techniques can be used to find exact maximum independent sets in
medium-sized sparse graphs, as well as high-quality independent sets in huge
sparse graphs that are intractable for exact (exponential-time) algorithms.
However, a major drawback of these algorithms is that they require significant
preprocessing overhead, and therefore cannot be used to find a high-quality
independent set quickly.
  In this paper, we show that performing simple kernelization techniques in an
online fashion significantly boosts the performance of local search, and is
much faster than pre-computing a kernel using advanced techniques. In addition,
we show that cutting high-degree vertices can boost local search performance
even further, especially on huge (sparse) complex networks. Our experiments
show that we can drastically speed up the computation of large independent sets
compared to other state-of-the-art algorithms, while also producing results
that are very close to the best known solutions.
</dc:description>
 <dc:description>Comment: 17 pages, 2 figures, 3 tables</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01659</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01665</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Query Topic Models via Pseudo-Relevant P\'olya Document Models</dc:title>
 <dc:creator>Cummins, Ronan</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Query-expansion via pseudo-relevance feedback is a popular method of
overcoming the problem of vocabulary mismatch and of increasing average
retrieval effectiveness. In this paper, we develop a new method that estimates
a query topic model from a set of pseudo-relevant documents using a new
language modelling framework.
  We assume that documents are generated via a mixture of multivariate Polya
distributions, and we show that by identifying the topical terms in each
document, we can appropriately select terms that are likely to belong to the
query topic model. The results of experiments on several TREC collections show
that the new approach compares favourably to current state-of-the-art expansion
methods.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01690</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimizing the Maximal Loss: How and Why?</dc:title>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:creator>Wexler, Yonatan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A commonly used learning rule is to approximately minimize the \emph{average}
loss over the training set. Other learning algorithms, such as AdaBoost and
hard-SVM, aim at minimizing the \emph{maximal} loss over the training set. The
average loss is more popular, particularly in deep learning, due to three main
reasons. First, it can be conveniently minimized using online algorithms, that
process few examples at each iteration. Second, it is often argued that there
is no sense to minimize the loss on the training set too much, as it will not
be reflected in the generalization loss. Last, the maximal loss is not robust
to outliers. In this paper we describe and analyze an algorithm that can
convert any online algorithm to a minimizer of the maximal loss. We prove that
in some situations better accuracy on the training set is crucial to obtain
good performance on unseen examples. Last, we propose robust versions of the
approach that can handle outliers.
</dc:description>
 <dc:description>Comment: ICML 2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01700</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The large deviations of the whitening process in random constraint
  satisfaction problems</dc:title>
 <dc:creator>Braunstein, Alfredo</dc:creator>
 <dc:creator>Dall'Asta, Luca</dc:creator>
 <dc:creator>Semerjian, Guilhem</dc:creator>
 <dc:creator>Zdeborova, Lenka</dc:creator>
 <dc:subject>Condensed Matter - Disordered Systems and Neural Networks</dc:subject>
 <dc:subject>Condensed Matter - Statistical Mechanics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Random constraint satisfaction problems undergo several phase transitions as
the ratio between the number of constraints and the number of variables is
varied. When this ratio exceeds the satisfiability threshold no more solutions
exist; the satisfiable phase, for less constrained problems, is itself divided
in an unclustered regime and a clustered one. In the latter solutions are
grouped in clusters of nearby solutions separated in configuration space from
solutions of other clusters. In addition the rigidity transition signals the
appearance of so-called frozen variables in typical solutions: beyond this
threshold most solutions belong to clusters with an extensive number of
variables taking the same values in all solutions of the cluster. In this paper
we refine the description of this phenomenon by estimating the location of the
freezing transition, corresponding to the disappearance of all unfrozen
solutions (not only typical ones). We also unveil phase transitions for the
existence and uniqueness of locked solutions, in which all variables are
frozen. From a technical point of view we characterize atypical solutions with
a number of frozen variables different from the typical value via a large
deviation study of the dynamics of a stripping process (whitening) that unveils
the frozen variables of a solution, building upon recent works on atypical
trajectories of the bootstrap percolation dynamics. Our results also bear some
relevance from an algorithmic perspective, previous numerical studies having
shown that heuristic algorithms of various kinds usually output unfrozen
solutions.
</dc:description>
 <dc:description>Comment: 55 pages, 32 figures. v2: additional discussion of locked solutions.
  v3: erroneous value l_c(k=4) was corrected from 19 to 17 in Table I</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01700</dc:identifier>
 <dc:identifier>J. Stat. Mech. 053401 (2016)</dc:identifier>
 <dc:identifier>doi:10.1088/1742-5468/2016/05/053401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01711</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Great Time Series Classification Bake Off: An Experimental
  Evaluation of Recently Proposed Algorithms. Extended Version</dc:title>
 <dc:creator>Bagnall, Anthony</dc:creator>
 <dc:creator>Bostrom, Aaron</dc:creator>
 <dc:creator>Large, James</dc:creator>
 <dc:creator>Lines, Jason</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In the last five years there have been a large number of new time series
classification algorithms proposed in the literature. These algorithms have
been evaluated on subsets of the 47 data sets in the University of California,
Riverside time series classification archive. The archive has recently been
expanded to 85 data sets, over half of which have been donated by researchers
at the University of East Anglia. Aspects of previous evaluations have made
comparisons between algorithms difficult. For example, several different
programming languages have been used, experiments involved a single train/test
split and some used normalised data whilst others did not. The relaunch of the
archive provides a timely opportunity to thoroughly evaluate algorithms on a
larger number of datasets. We have implemented 18 recently proposed algorithms
in a common Java framework and compared them against two standard benchmark
classifiers (and each other) by performing 100 resampling experiments on each
of the 85 datasets. We use these results to test several hypotheses relating to
whether the algorithms are significantly more accurate than the benchmarks and
each other. Our results indicate that only 9 of these algorithms are
significantly more accurate than both benchmarks and that one classifier, the
Collective of Transformation Ensembles, is significantly more accurate than all
of the others. All of our experiments and results are reproducible: we release
all of our code, results and experimental details and we hope these experiments
form the basis for more rigorous testing of new algorithms in the future.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01711</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01716</identifier>
 <datestamp>2016-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decentralized Prediction-Correction Methods for Networked Time-Varying
  Convex Optimization</dc:title>
 <dc:creator>Simonetto, Andrea</dc:creator>
 <dc:creator>Koppel, Alec</dc:creator>
 <dc:creator>Mokhtari, Aryan</dc:creator>
 <dc:creator>Leus, Geert</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We develop algorithms that find and track the optimal solution trajectory of
time-varying convex optimization problems which consist of local and
network-related objectives. The algorithms are derived from the
prediction-correction methodology, which corresponds to a strategy where the
time-varying problem is sampled at discrete time instances and then a sequence
is generated via alternatively executing predictions on how the optimizers at
the next time sample are changing and corrections on how they actually have
changed. Prediction is based on how the optimality conditions evolve in time,
while correction is based on a gradient or Newton method, leading to
Decentralized Prediction-Correction Gradient (DPC-G) and Decentralized
Prediction-Correction Newton (DPC-N). We extend these methods to cases where
the knowledge on how the optimization programs are changing in time is only
approximate and propose Decentralized Approximate Prediction-Correction
Gradient (DAPC-G) and Decentralized Approximate Prediction-Correction Newton
(DAPC-N). Convergence properties of all the proposed methods are studied and
empirical performance is shown on an application of a resource allocation
problem in a wireless network. We observe that the proposed methods outperform
existing running algorithms by orders of magnitude. The numerical results
showcase a trade-off between convergence accuracy, sampling period, and network
communications.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01716</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01718</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Formal Verification of Autonomous Vehicle Platooning</dc:title>
 <dc:creator>Kamali, Maryam</dc:creator>
 <dc:creator>Dennis, Louise A.</dc:creator>
 <dc:creator>McAree, Owen</dc:creator>
 <dc:creator>Fisher, Michael</dc:creator>
 <dc:creator>Veres, Sandor M.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  The coordination of multiple autonomous vehicles into convoys or platoons is
expected on our highways in the near future. However, before such platoons can
be deployed, the new autonomous behaviors of the vehicles in these platoons
must be certified. An appropriate representation for vehicle platooning is as a
multi-agent system in which each agent captures the &quot;autonomous decisions&quot;
carried out by each vehicle. In order to ensure that these autonomous
decision-making agents in vehicle platoons never violate safety requirements,
we use formal verification. However, as the formal verification technique used
to verify the agent code does not scale to the full system and as the global
verification technique does not capture the essential verification of
autonomous behavior, we use a combination of the two approaches. This mixed
strategy allows us to verify safety requirements not only of a model of the
system, but of the actual agent code used to program the autonomous vehicles.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01728</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NeRD: a Neural Response Divergence Approach to Visual Salience Detection</dc:title>
 <dc:creator>Shafiee, M. J.</dc:creator>
 <dc:creator>Siva, P.</dc:creator>
 <dc:creator>Scharfenberger, C.</dc:creator>
 <dc:creator>Fieguth, P.</dc:creator>
 <dc:creator>Wong, A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, a novel approach to visual salience detection via Neural
Response Divergence (NeRD) is proposed, where synaptic portions of deep neural
networks, previously trained for complex object recognition, are leveraged to
compute low level cues that can be used to compute image region
distinctiveness. Based on this concept , an efficient visual salience detection
framework is proposed using deep convolutional StochasticNets. Experimental
results using CSSD and MSRA10k natural image datasets show that the proposed
NeRD approach can achieve improved performance when compared to
state-of-the-art image saliency approaches, while the attaining low
computational complexity necessary for near-real-time computer vision
applications.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01728</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01729</identifier>
 <datestamp>2017-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Correntropy Maximization via ADMM - Application to Robust Hyperspectral
  Unmixing</dc:title>
 <dc:creator>Zhu, Fei</dc:creator>
 <dc:creator>Halimi, Abderrahim</dc:creator>
 <dc:creator>Honeine, Paul</dc:creator>
 <dc:creator>Chen, Badong</dc:creator>
 <dc:creator>Zheng, Nanning</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In hyperspectral images, some spectral bands suffer from low signal-to-noise
ratio due to noisy acquisition and atmospheric effects, thus requiring robust
techniques for the unmixing problem. This paper presents a robust supervised
spectral unmixing approach for hyperspectral images. The robustness is achieved
by writing the unmixing problem as the maximization of the correntropy
criterion subject to the most commonly used constraints. Two unmixing problems
are derived: the first problem considers the fully-constrained unmixing, with
both the non-negativity and sum-to-one constraints, while the second one deals
with the non-negativity and the sparsity-promoting of the abundances. The
corresponding optimization problems are solved efficiently using an alternating
direction method of multipliers (ADMM) approach. Experiments on synthetic and
real hyperspectral images validate the performance of the proposed algorithms
for different scenarios, demonstrating that the correntropy-based unmixing is
robust to outlier bands.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01729</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2017.2696262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01731</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Objective Framework for Dynamic Optimization of OFDMA Cellular
  Systems</dc:title>
 <dc:creator>Chandhar, Prabhu</dc:creator>
 <dc:creator>Das, Suvra Sekhar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Green cellular networking has become an important research area in recent
years due to environmental and economical concerns. Switching off
under-utilized BSs during off-peak traffic load conditions is a promising
approach to reduce energy consumption in cellular networks. In practice, during
initial cell planning, the BS locations and RAN parameters are optimized to
meet the basic system design requirements like coverage, capacity, overlap, QoS
etc. As these metrics are tightly coupled with each other due to co-channel
interference, switching off certain BSs may affect the system requirements.
Therefore, identifying a subset of large number of BSs which are to be put into
sleep mode, is a challenging dynamic optimization problem. In this work, we
develop a multiobjective framework for dynamic optimization framework for OFDMA
based cellular systems. The objective is to identify the appropriate set of
active sectors and RAN parameters that maximize coverage and area spectral
efficiency while minimizing overlap and area power consumption without
violating the QoS requirements for a given traffic demand density. The
objective functions and constraints are obtained using appropriate analytical
models which capture the traffic characteristics, propagation characteristics
(pathloss, shadowing, and small scale fading) as well as load condition in
neighbouring cells. A low complexity evolutionary algorithm is used for
identifying the global Pareto optimal solutions at a faster convergence rate.
The inter-relationships between the system objectives are studied and
guidelines are provided to find an appropriate network configuration that
provides the best achievable trade-offs. The results show that using the
proposed framework, significant amount of energy saving can be achieved and
with a low computational complexity while maintaining good trade-offs among the
other objectives.
</dc:description>
 <dc:description>Comment: To Appear (IEEE Access), 25 pages, 24 figures, 4 tables</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-04-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01731</dc:identifier>
 <dc:identifier>doi:10.1109/ACCESS.2016.2551640</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01732</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Buffer-aware Worst Case Timing Analysis of Wormhole Network On Chip</dc:title>
 <dc:creator>Mifdaoui, Ahlem</dc:creator>
 <dc:creator>Ayed, Hamdi</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  A buffer-aware worst-case timing analysis of wormhole NoC is proposed in this
paper to integrate the impact of buffer size on the different dependencies
relationship between flows, i.e. direct and indirect blocking flows, and
consequently the timing performance. First, more accurate definitions of direct
and indirect blocking flows sets have been introduced to take into account the
buffer size impact. Then, the modeling and worst-case timing analysis of
wormhole NoC have been detailed, based on Network Calculus formalism and the
newly defined blocking flows sets. This introduced approach has been
illustrated in the case of a realistic NoC case study to show the trade off
between latency and buffer size. The comparative analysis of our proposed
Buffer-aware timing analysis with conventional approaches is conducted and
noticeable enhancements in terms of maximum latency have been proved.
</dc:description>
 <dc:description>Comment: ISAE Technical report done during the master Thesis of Hamdi Ayed at
  ISAE at 2010</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01732</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01739</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Parameterized Complexity of the Minimum Shared Edges Problem</dc:title>
 <dc:creator>Fluschnik, Till</dc:creator>
 <dc:creator>Kratsch, Stefan</dc:creator>
 <dc:creator>Niedermeier, Rolf</dc:creator>
 <dc:creator>Sorge, Manuel</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q17, 68Q25, 68R10</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  We study the NP-complete Minimum Shared Edges (MSE) problem. Given an
undirected graph, a source and a sink vertex, and two integers p and k, the
question is whether there are p paths in the graph connecting the source with
the sink and sharing at most k edges. Herein, an edge is shared if it appears
in at least two paths. We show that MSE is W[1]-hard when parameterized by the
treewidth of the input graph and the number k of shared edges combined. We show
that MSE is fixed-parameter tractable with respect to p, but does not admit a
polynomial-size kernel (unless NP is contained in coNP/poly). In the proof of
the fixed-parameter tractability of MSE parameterized by p, we employ the
treewidth reduction technique due to Marx, O'Sullivan, and Razgon [ACM TALG
2013].
</dc:description>
 <dc:description>Comment: 35 pages, 16 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01764</identifier>
 <datestamp>2017-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A double oracle approach for minmax regret optimization problems with
  interval data</dc:title>
 <dc:creator>Gilbert, Hugo</dc:creator>
 <dc:creator>Spanjaard, Olivier</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>90C27</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:subject>G.1.6</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  In this paper, we provide a generic anytime lower bounding procedure for
minmax regret optimization problems. We show that the lower bound obtained is
always at least as accurate as the lower bound recently proposed by Chassein
and Goerigk (2015). This lower bound can be viewed as the optimal value of a
linear programming relaxation of a mixed integer programming formulation of
minmax regret optimization, but the contribution of the paper is to compute
this lower bound via a double oracle algorithm (McMahan et al., 2003) that we
specify. The double oracle algorithm is designed by relying on a game theoretic
view of robust optimization, similar to the one developed by Mastin et al.
(2015), and it can be efficiently implemented for any minmax regret
optimization problem whose standard version is &quot;easy&quot;. We describe how to
efficiently embed this lower bound in a branch and bound procedure. Finally, we
apply our approach to the robust shortest path problem. Our numerical results
show a significant gain in the computation times compared to previous
approaches in the literature.
</dc:description>
 <dc:description>Comment: 29 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-07-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01764</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01768</identifier>
 <datestamp>2016-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Randomized Quasi-Newton Updates are Linearly Convergent Matrix Inversion
  Algorithms</dc:title>
 <dc:creator>Gower, Robert M.</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>15A09, 15B52, 15A24, 65F10, 65F08, 68W20, 65Y20, 68Q25, 68W40,
  90C20,</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:description>  We develop and analyze a broad family of stochastic/randomized algorithms for
inverting a matrix. We also develop specialized variants maintaining symmetry
or positive definiteness of the iterates. All methods in the family converge
globally and linearly (i.e., the error decays exponentially), with explicit
rates. In special cases, we obtain stochastic block variants of several
quasi-Newton updates, including bad Broyden (BB), good Broyden (GB),
Powell-symmetric-Broyden (PSB), Davidon-Fletcher-Powell (DFP) and
Broyden-Fletcher-Goldfarb-Shanno (BFGS). Ours are the first stochastic versions
of these updates shown to converge to an inverse of a fixed matrix. Through a
dual viewpoint we uncover a fundamental link between quasi-Newton updates and
approximate inverse preconditioning. Further, we develop an adaptive variant of
randomized block BFGS, where we modify the distribution underlying the
stochasticity of the method throughout the iterative process to achieve faster
convergence. By inverting several matrices from varied applications, we
demonstrate that AdaRBFGS is highly competitive when compared to the well
established Newton-Schulz and minimal residual methods. In particular, on
large-scale problems our method outperforms the standard methods by orders of
magnitude. Development of efficient methods for estimating the inverse of very
large matrices is a much needed tool for preconditioning and variable metric
optimization methods in the advent of the big data era.
</dc:description>
 <dc:description>Comment: 42 pages, 6 figures, 2 tables</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-03-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01771</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Quantum Obfuscation</dc:title>
 <dc:creator>Alagic, Gorjan</dc:creator>
 <dc:creator>Fefferman, Bill</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Encryption of data is fundamental to secure communication in the modern
world. Beyond encryption of data lies obfuscation, i.e., encryption of
functionality. It is well-known that the most powerful means of obfuscating
classical programs, so-called ``black-box obfuscation',' is provably impossible
[Barak et al '12]. However, several recent results have yielded candidate
schemes that satisfy a definition weaker than black-box, and yet still have
numerous applications.
  In this work, we initialize the rigorous study of obfuscating programs via
quantum-mechanical means. We define notions of quantum obfuscation which
encompass several natural variants. The input to the obfuscator can describe
classical or quantum functionality, and the output can be a circuit description
or a quantum state. The obfuscator can also satisfy one of a number of
obfuscation conditions: black-box, information-theoretic black-box,
indistinguishability, and best possible; the last two conditions come in three
variants: perfect, statistical, and computational. We discuss many
applications, including CPA-secure quantum encryption, quantum
fully-homomorphic encryption, and public-key quantum money.
  We then prove several impossibility results, extending a number of
foundational papers on classical obfuscation to the quantum setting. We prove
that quantum black-box obfuscation is impossible in a setting where adversaries
can possess more than one output of the obfuscator. In particular, generic
transformation of quantum circuits into black-box-obfuscated quantum circuits
is impossible. We also show that statistical indistinguishability obfuscation
is impossible, up to an unlikely complexity-theoretic collapse. Our proofs
involve a new tool: chosen-ciphertext-secure encryption of quantum data, which
was recently shown to be possible assuming quantum-secure one-way functions
exist [Alagic et al '16].
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01771</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01777</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Isocontour Visualization in Road Networks via Minimum-Link
  Paths</dc:title>
 <dc:creator>Baum, Moritz</dc:creator>
 <dc:creator>Bl&#xe4;sius, Thomas</dc:creator>
 <dc:creator>Gemsa, Andreas</dc:creator>
 <dc:creator>Rutter, Ignaz</dc:creator>
 <dc:creator>Wegner, Franziska</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Isocontours in road networks represent the area that is reachable from a
source within a given resource limit. We study the problem of computing
accurate isocontours in realistic, large-scale networks. We propose polygons
with minimum number of segments that separate reachable and unreachable
components of the network. Since the resulting problem is not known to be
solvable in polynomial time, we introduce several heuristics that are simple
enough to be implemented in practice. A key ingredient is a new practical
linear-time algorithm for minimum-link paths in simple polygons. Experiments in
a challenging realistic setting show excellent performance of our algorithms in
practice, answering queries in a few milliseconds on average even for long
ranges.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01777</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01783</identifier>
 <datestamp>2016-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asynchronous Methods for Deep Reinforcement Learning</dc:title>
 <dc:creator>Mnih, Volodymyr</dc:creator>
 <dc:creator>Badia, Adri&#xe0; Puigdom&#xe8;nech</dc:creator>
 <dc:creator>Mirza, Mehdi</dc:creator>
 <dc:creator>Graves, Alex</dc:creator>
 <dc:creator>Lillicrap, Timothy P.</dc:creator>
 <dc:creator>Harley, Tim</dc:creator>
 <dc:creator>Silver, David</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a conceptually simple and lightweight framework for deep
reinforcement learning that uses asynchronous gradient descent for optimization
of deep neural network controllers. We present asynchronous variants of four
standard reinforcement learning algorithms and show that parallel
actor-learners have a stabilizing effect on training allowing all four methods
to successfully train neural network controllers. The best performing method,
an asynchronous variant of actor-critic, surpasses the current state-of-the-art
on the Atari domain while training for half the time on a single multi-core CPU
instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds
on a wide variety of continuous motor control problems as well as on a new task
of navigating random 3D mazes using a visual input.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-06-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01783</dc:identifier>
 <dc:identifier>ICML 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01792</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Forest DBSCAN for USPTO Inventor Name Disambiguation</dc:title>
 <dc:creator>Kim, Kunho</dc:creator>
 <dc:creator>Khabsa, Madian</dc:creator>
 <dc:creator>Giles, C. Lee</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Name disambiguation and the subsequent name conflation are essential for the
correct processing of person name queries in a digital library or other
database. It distinguishes each unique person from all other records in the
database. We study inventor name disambiguation for a patent database using
methods and features from earlier work on author name disambiguation and
propose a feature set appropriate for a patent database. A random forest was
selected for the pairwise linking classifier since they outperform Naive Bayes,
Logistic Regression, Support Vector Machines (SVM), Conditional Inference Tree,
and Decision Trees. Blocking size, very important for scaling, was selected
based on experiments that determined feature importance and accuracy. The
DBSCAN algorithm is used for clustering records, using a distance function
derived from random forest classifier. For additional scalability clustering
was parallelized. Tests on the USPTO patent database show that our method
successfully disambiguated 12 million inventor mentions within 6.5 hours.
Evaluation on datasets from USPTO PatentsView inventor name disambiguation
competition shows our algorithm outperforms all algorithms in the competition.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01792</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01804</identifier>
 <datestamp>2016-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Obtaining personal data and asking for erasure: Do app vendors and
  website owners honour your privacy rights?</dc:title>
 <dc:creator>Herrmann, Dominik</dc:creator>
 <dc:creator>Lindemann, Jens</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  EU Directive 95/46/EC and the upcoming EU General Data Protection Regulation
grant Europeans the right of access to data pertaining to them. Consumers can
approach their service providers to obtain all personal data stored and
processed there. Furthermore, they can demand erasure (or correction) of their
data. We conducted an undercover field study to determine whether these rights
can be exerted in practice. We assessed the behaviour of the vendors of 150
smartphone apps and 120 websites that are popular in Germany. Our deletion
requests were fulfilled in 52 to 57% of the cases and less than half of the
data provision requests were answered satisfactorily. Further, we observed
instances of carelessness: About 20% of website owners would have disclosed our
personal data to impostors. The results indicate that exerting privacy rights
that have been introduced two decades ago is still a frustrating endeavour most
of the time.
</dc:description>
 <dc:description>Comment: This paper has been accepted for publication at Sicherheit 2016. The
  preprint is a slightly extended version of the conference paper: The preprint
  contains the list of the selected apps and websites. Differences in Version
  v2: includes Acknowledgements, changed a typo in first paragraph of Sect. 3.1</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-04-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01804</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01818</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Feature Maps via a Layered Random Projection (LaRP) Framework for
  Object Classification</dc:title>
 <dc:creator>Chung, A. G.</dc:creator>
 <dc:creator>Shafiee, M. J.</dc:creator>
 <dc:creator>Wong, A.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The approximation of nonlinear kernels via linear feature maps has recently
gained interest due to their applications in reducing the training and testing
time of kernel-based learning algorithms. Current random projection methods
avoid the curse of dimensionality by embedding the nonlinear feature space into
a low dimensional Euclidean space to create nonlinear kernels. We introduce a
Layered Random Projection (LaRP) framework, where we model the linear kernels
and nonlinearity separately for increased training efficiency. The proposed
LaRP framework was assessed using the MNIST hand-written digits database and
the COIL-100 object database, and showed notable improvement in object
classification performance relative to other state-of-the-art random projection
methods.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01818</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01819</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A short note on Merlin-Arthur protocols for subset sum</dc:title>
 <dc:creator>Nederlof, Jesper</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the subset sum problem we are given n positive integers along with a
target integer t. A solution is a subset of these integers summing to t. In
this short note we show that for a given subset sum instance there is a proof
of size $O^*(\sqrt{t})$ of what the number of solutions is that can be
constructed in $O^*(t)$ time and can be probabilistically verified in time
$O^*(\sqrt{t})$ with at most constant error probability. Here, the $O^*()$
notation omits factors polynomial in the input size $n\log(t)$.
</dc:description>
 <dc:description>Comment: 2 pages</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01827</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Leveraging Mid-Level Deep Representations For Predicting Face Attributes
  in the Wild</dc:title>
 <dc:creator>Zhong, Yang</dc:creator>
 <dc:creator>Sullivan, Josephine</dc:creator>
 <dc:creator>Li, Haibo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Predicting facial attributes from faces in the wild is very challenging due
to pose and lighting variations in the real world. The key to this problem is
to build proper feature representations to cope with these unfavourable
conditions. Given the success of Convolutional Neural Network (CNN) in image
classification, the high-level CNN feature, as an intuitive and reasonable
choice, has been widely utilized for this problem. In this paper, however, we
consider the mid-level CNN features as an alternative to the high-level ones
for attribute prediction. This is based on the observation that face attributes
are different: some of them are locally oriented while others are globally
defined. Our investigations reveal that the mid-level deep representations
outperform the prediction accuracy achieved by the (fine-tuned) high-level
abstractions. We empirically demonstrate that the midlevel representations
achieve state-of-the-art prediction performance on CelebA and LFWA datasets.
Our investigations also show that by utilizing the mid-level representations
one can employ a single deep network to achieve both face recognition and
attribute prediction.
</dc:description>
 <dc:description>Comment: In proceedings of 2016 International Conference on Image Processing
  (ICIP)</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01827</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01867</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scheduling of unit-length jobs with bipartite incompatibility graphs on
  four uniform machines</dc:title>
 <dc:creator>Furmanczyk, H.</dc:creator>
 <dc:creator>Kubale, M.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In the paper we consider the problem of scheduling $n$ identical jobs on 4
uniform machines with speeds $s_1 \geq s_2 \geq s_3 \geq s_4,$ respectively.
Our aim is to find a schedule with a minimum possible length. We assume that
jobs are subject to some kind of mutual exclusion constraints modeled by a
bipartite incompatibility graph of degree $\Delta$, where two incompatible jobs
cannot be processed on the same machine. We show that the problem is NP-hard
even if $s_1=s_2=s_3$. If, however, $\Delta \leq 4$ and $s_1 \geq 12 s_2$,
$s_2=s_3=s_4$, then the problem can be solved to optimality in time
$O(n^{1.5})$. The same algorithm returns a solution of value at most 2 times
optimal provided that $s_1 \geq 2s_2$. Finally, we study the case $s_1 \geq s_2
\geq s_3=s_4$ and give an $O(n^{1.5})$-time $32/15$-approximation algorithm in
all such situations.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01867</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01868</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>2nd Workshop on Cognitive Architectures for Social Human-Robot
  Interaction 2016 (CogArch4sHRI 2016)</dc:title>
 <dc:creator>Baxter, Paul</dc:creator>
 <dc:creator>Trafton, J. Gregory</dc:creator>
 <dc:creator>Lemaignan, Severin</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This volume is the proceedings of the 2nd workshop on Cognitive Architectures
for Social Human-Robot Interaction, held at the ACM/IEEE HRI 2016 conference,
which took place on Monday 7th March 2016, in Christchurch, New Zealand.
  Organised by Paul Baxter (Plymouth University, U.K.), J. Gregory Trafton
(Naval Research Laboratory, USA), and Severin Lemaignan (Plymouth University,
U.K.).
</dc:description>
 <dc:description>Comment: Index for conference proceedings CogArch4sHRI 2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01868</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01870</identifier>
 <datestamp>2017-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polar Coding for Processes with Memory</dc:title>
 <dc:creator>Sasoglu, Eren</dc:creator>
 <dc:creator>Tal, Ido</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study polar coding over channels and sources with memory. We show that
$\psi$-mixing processes polarize under the standard transform, and that the
rate of polarization to deterministic distributions is roughly
$O(2^{-\sqrt{N}})$ as in the memoryless case, where $N$ is the blocklength.
This implies that the error probability guarantees of polar channel and source
codes extend to a large class of models with memory, including finite-order
Markov sources and finite-state channels.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Information Theory</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-01-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01870</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01871</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying the Major Sources of Variance in Transaction Latencies:
  Towards More Predictable Databases</dc:title>
 <dc:creator>Huang, Jiamin</dc:creator>
 <dc:creator>Mozafari, Barzan</dc:creator>
 <dc:creator>Schoenebeck, Grant</dc:creator>
 <dc:creator>Wenisch, Thomas</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Decades of research have sought to improve transaction processing performance
and scalability in database management systems (DBMSs). However, significantly
less attention has been dedicated to the predictability of performance: how
often individual transactions exhibit execution latency far from the mean?
Performance predictability is vital when transaction processing lies on the
critical path of a complex enterprise software or an interactive web service,
as well as in emerging database-as-a-service markets where customers contract
for guaranteed levels of performance. In this paper, we take several steps
towards achieving more predictable database systems. First, we propose a
profiling framework called VProfiler that, given the source code of a DBMS, is
able to identify the dominant sources of variance in transaction latency.
VProfiler automatically instruments the DBMS source code to deconstruct the
overall variance of transaction latencies into variances and covariances of the
execution time of individual functions, which in turn provide insight into the
root causes of variance. Second, we use VProfiler to analyze MySQL and Postgres
- two of the most popular and complex open-source database systems. Our case
studies reveal that the primary causes of variance in MySQL and Postgres are
lock scheduling and centralized logging, respectively. Finally, based on
VProfiler's findings, we further focus on remedying the performance variance of
MySQL by (1) proposing a new lock scheduling algorithm, called Variance-Aware
Transaction Scheduling (VATS), (2) enhancing the buffer pool replacement
policy, and (3) identifying tuning parameters that can reduce variance
significantly. Our experimental results show that our schemes reduce overall
transaction latency variance by 37% on average (and up to 64%) without
compromising throughput or mean latency.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01871</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01883</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Diagnosis and Repair for Synthesis from Signal Temporal Logic
  Specifications</dc:title>
 <dc:creator>Ghosh, Shromona</dc:creator>
 <dc:creator>Sadigh, Dorsa</dc:creator>
 <dc:creator>Nuzzo, Pierluigi</dc:creator>
 <dc:creator>Raman, Vasumathi</dc:creator>
 <dc:creator>Donze, Alexandre</dc:creator>
 <dc:creator>Sangiovanni-Vincentelli, Alberto</dc:creator>
 <dc:creator>Sastry, S. Shankar</dc:creator>
 <dc:creator>Seshia, Sanjit A.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We address the problem of diagnosing and repairing specifications for hybrid
systems formalized in signal temporal logic (STL). Our focus is on the setting
of automatic synthesis of controllers in a model predictive control (MPC)
framework. We build on recent approaches that reduce the controller synthesis
problem to solving one or more mixed integer linear programs (MILPs), where
infeasibility of a MILP usually indicates unrealizability of the controller
synthesis problem. Given an infeasible STL synthesis problem, we present
algorithms that provide feedback on the reasons for unrealizability, and
suggestions for making it realizable. Our algorithms are sound and complete,
i.e., they provide a correct diagnosis, and always terminate with a non-trivial
specification that is feasible using the chosen synthesis method, when such a
solution exists. We demonstrate the effectiveness of our approach on the
synthesis of controllers for various cyber-physical systems, including an
autonomous driving application and an aircraft electric power system.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01883</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01887</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Visual Tracking via Reliable Memories</dc:title>
 <dc:creator>Wang, Shu</dc:creator>
 <dc:creator>Zhang, Shaoting</dc:creator>
 <dc:creator>Liu, Wei</dc:creator>
 <dc:creator>Metaxas, Dimitris N.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we propose a novel visual tracking framework that
intelligently discovers reliable patterns from a wide range of video to resist
drift error for long-term tracking tasks. First, we design a Discrete Fourier
Transform (DFT) based tracker which is able to exploit a large number of
tracked samples while still ensures real-time performance. Second, we propose a
clustering method with temporal constraints to explore and memorize consistent
patterns from previous frames, named as reliable memories. By virtue of this
method, our tracker can utilize uncontaminated information to alleviate
drifting issues. Experimental results show that our tracker performs favorably
against other state of-the-art methods on benchmark datasets. Furthermore, it
is significantly competent in handling drifts and able to robustly track
challenging long videos over 4000 frames, while most of others lose track at
early frames.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01887</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01890</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Search Tracker: Human-derived object tracking in-the-wild through
  large-scale search and retrieval</dc:title>
 <dc:creator>Bency, Archith J.</dc:creator>
 <dc:creator>Karthikeyan, S.</dc:creator>
 <dc:creator>De Leo, Carter</dc:creator>
 <dc:creator>Sunderrajan, Santhoshkumar</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Humans use context and scene knowledge to easily localize moving objects in
conditions of complex illumination changes, scene clutter and occlusions. In
this paper, we present a method to leverage human knowledge in the form of
annotated video libraries in a novel search and retrieval based setting to
track objects in unseen video sequences. For every video sequence, a document
that represents motion information is generated. Documents of the unseen video
are queried against the library at multiple scales to find videos with similar
motion characteristics. This provides us with coarse localization of objects in
the unseen video. We further adapt these retrieved object locations to the new
video using an efficient warping scheme. The proposed method is validated on
in-the-wild video surveillance datasets where we outperform state-of-the-art
appearance-based trackers. We also introduce a new challenging dataset with
complex object appearance changes.
</dc:description>
 <dc:description>Comment: Under review with the IEEE Transactions on Circuits and Systems for
  Video Technology</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01890</dc:identifier>
 <dc:identifier>doi:10.1109/TCSVT.2016.2555718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01891</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Estimation for Cooperative Mobile Manipulation</dc:title>
 <dc:creator>Franchi, Antonio</dc:creator>
 <dc:creator>Petitti, Antonio</dc:creator>
 <dc:creator>Rizzo, Alessandro</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We present a distributed method for the estimation of the kinematic
parameters, the dynamic parameters, and the kinematic state of an unknown body
manipulated by a decentralized team of mobile ground (planar) robots. The
proposed approach relies on the geometry of the rigid body kinematics, the
rigid body dynamics, on nonlinear observation, and on consensus algorithms. The
only three requirements are that each robot is able to control the 2D wrench
exerted locally on the load, it can measure the velocity of its contact point,
and the communication graph is connected. The finite time convergence of the
strategy is proven and all the robots agree on the same estimated quantities at
the end of the procedure. We present also two basic distributed control
strategies that are proven to satisfy nonlinear observability conditions needed
for the estimation accomplishment. Finally, a numerical test that demonstrates
the evolution of the estimation algorithm is given.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01891</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01895</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generate Image Descriptions based on Deep RNN and Memory Cells for
  Images Features</dc:title>
 <dc:creator>Tang, Shijian</dc:creator>
 <dc:creator>Han, Song</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Generating natural language descriptions for images is a challenging task.
The traditional way is to use the convolutional neural network (CNN) to extract
image features, followed by recurrent neural network (RNN) to generate
sentences. In this paper, we present a new model that added memory cells to
gate the feeding of image features to the deep neural network. The intuition is
enabling our model to memorize how much information from images should be fed
at each stage of the RNN. Experiments on Flickr8K and Flickr30K datasets showed
that our model outperforms other state-of-the-art models with higher BLEU
scores.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01895</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01896</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Catcher-Evader Games</dc:title>
 <dc:creator>Li, Yuqian</dc:creator>
 <dc:creator>Conitzer, Vincent</dc:creator>
 <dc:creator>Korzhyk, Dmytro</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Algorithms for computing game-theoretic solutions have recently been applied
to a number of security domains. However, many of the techniques developed for
compact representations of security games do not extend to {\em Bayesian}
security games, which allow us to model uncertainty about the attacker's type.
In this paper, we introduce a general framework of {\em catcher-evader} games
that can capture Bayesian security games as well as other game families of
interest. We show that computing Stackelberg strategies is NP-hard, but give an
algorithm for computing a Nash equilibrium that performs well in experiments.
We also prove that the Nash equilibria of these games satisfy the {\em
interchangeability} property, so that equilibrium selection is not an issue.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-04-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01896</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01904</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Discovery of Success Trajectories of Authors</dc:title>
 <dc:creator>Pradhan, Dinesh</dc:creator>
 <dc:creator>Chakraborty, Tanmoy</dc:creator>
 <dc:creator>Pandit, Saswata</dc:creator>
 <dc:creator>Nandi, Subrata</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>H.3.7</dc:subject>
 <dc:subject>H.4.0</dc:subject>
 <dc:description>  Understanding the qualitative patterns of research endeavor of scientific
authors in terms of publication count and their impact (citation) is important
in order to quantify success trajectories. Here, we examine the career profile
of authors in computer science and physics domains and discover at least six
different success trajectories in terms of normalized citation count in
longitudinal scale. Initial observations of individual trajectories lead us to
characterize the authors in each category. We further leverage this trajectory
information to build a two-stage stratification model to predict future success
of an author at the early stage of her career. Our model outperforms the
baseline with an average improvement of 15.68% for both the datasets.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure in 25rd International World Wide Web Conference WWW
  2016</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01904</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01906</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Selecting wavelengths for least squares range estimation</dc:title>
 <dc:creator>Akhlaq, Assad</dc:creator>
 <dc:creator>McKilliam, Robby</dc:creator>
 <dc:creator>Subramanian, Ramanan</dc:creator>
 <dc:creator>Pollok, Andre</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of estimating the distance, or range, between two
locations by measuring the phase of multiple sinusoidal signals transmitted
between the locations. Traditional estimators developed for optical
interferometry include the beat wavelength and excess fractions methods. More
recently, estimators based on the Chinese remainder theorem (CRT) and least
squares have appeared. Recent research suggests the least squares estimator to
be most accurate in many cases. The accuracy of all of these range estimators
depends upon the wavelengths chosen. This leads to the problem of selecting
wavelengths that maximise accuracy. Procedures for selecting wavelengths for
the beat wavelength and excess fractions methods have previously been
described, but procedures for the CRT and least squares estimators are yet to
be developed. In this paper we develop an algorithm to automatically select
wavelengths for use with the least square range estimator. The algorithm
minimises an optimisation criterion connected with the mean square error.
Interesting properties of a particular class of lattices simplify the criterion
allowing minimisation by depth first search. Monte-Carlo simulations indicate
that wavelengths that minimise the criterion can result is considerably more
accurate range estimates than wavelengths selected by ad hoc means.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01906</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2595490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01910</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Multiplier Methods to Optimize Non-exhaustive, Overlapping
  Clustering</dc:title>
 <dc:creator>Hou, Yangyang</dc:creator>
 <dc:creator>Whang, Joyce Jiyoung</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:creator>Dhillon, Inderjit S.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clustering is one of the most fundamental and important tasks in data mining.
Traditional clustering algorithms, such as K-means, assign every data point to
exactly one cluster. However, in real-world datasets, the clusters may overlap
with each other. Furthermore, often, there are outliers that should not belong
to any cluster. We recently proposed the NEO-K-Means (Non-Exhaustive,
Overlapping K-Means) objective as a way to address both issues in an integrated
fashion. Optimizing this discrete objective is NP-hard, and even though there
is a convex relaxation of the objective, straightforward convex optimization
approaches are too expensive for large datasets. A practical alternative is to
use a low-rank factorization of the solution matrix in the convex formulation.
The resulting optimization problem is non-convex, and we can locally optimize
the objective function using an augmented Lagrangian method. In this paper, we
consider two fast multiplier methods to accelerate the convergence of an
augmented Lagrangian scheme: a proximal method of multipliers and an
alternating direction method of multipliers (ADMM). For the proximal augmented
Lagrangian or proximal method of multipliers, we show a convergence result for
the non-convex case with bound-constrained subproblems. These methods are up to
13 times faster---with no change in quality---compared with a standard
augmented Lagrangian method on problems with over 10,000 variables and bring
runtimes down from over an hour to around 5 minutes.
</dc:description>
 <dc:description>Comment: 9 pages. 2 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01910</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01911</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Achievable Rate-Distortion Region for Multiple Descriptions Source
  Coding Based on Coset Codes</dc:title>
 <dc:creator>Shirani, Farhad</dc:creator>
 <dc:creator>Pradhan, S. Sandeep</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider the problem of multiple descriptions (MD) source coding and
propose new coding strategies involving both unstructured and structured coding
layers. Previously, the most general achievable rate-distortion (RD) region for
the $l$-descriptions problem was the Combinatorial Message Sharing with Binning
(CMSB) region. The CMSB scheme utilizes unstructured quantizers and
unstructured binning. In the first part of the paper, we show that this
strategy can be improved upon using more general unstructured quantizers and a
more general unstructured binning method. In the second part, structured coding
strategies are considered. First, structured coding strategies are developed by
considering specific MD examples involving three or more descriptions. We show
that application of structured quantizers results in strict RD improvements
when there are more than two descriptions. Furthermore, we show that structured
binning also yields improvements. These improvements are in addition to the
ones derived in the first part of the paper. This suggests that structured
coding is essential when coding over more than two descriptions. Using the
ideas developed through these examples we provide a new unified coding strategy
by considering several structured coding layers. Finally, we characterize its
performance in the form of an inner bound to the optimal rate-distortion region
using computable single-letter information quantities. The new RD region
strictly contains all of the previous known achievable regions.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01913</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Effective Clipart Image Vectorization Through Direct Optimization of
  Bezigons</dc:title>
 <dc:creator>Yang, Ming</dc:creator>
 <dc:creator>Chao, Hongyang</dc:creator>
 <dc:creator>Zhang, Chi</dc:creator>
 <dc:creator>Guo, Jun</dc:creator>
 <dc:creator>Yuan, Lu</dc:creator>
 <dc:creator>Sun, Jian</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  Bezigons, i.e., closed paths composed of B\'ezier curves, have been widely
employed to describe shapes in image vectorization results. However, most
existing vectorization techniques infer the bezigons by simply approximating an
intermediate vector representation (such as polygons). Consequently, the
resultant bezigons are sometimes imperfect due to accumulated errors, fitting
ambiguities, and a lack of curve priors, especially for low-resolution images.
In this paper, we describe a novel method for vectorizing clipart images. In
contrast to previous methods, we directly optimize the bezigons rather than
using other intermediate representations; therefore, the resultant bezigons are
not only of higher fidelity compared with the original raster image but also
more reasonable because they were traced by a proficient expert. To enable such
optimization, we have overcome several challenges and have devised a
differentiable data energy as well as several curve-based prior terms. To
improve the efficiency of the optimization, we also take advantage of the local
control property of bezigons and adopt an overlapped piecewise optimization
strategy. The experimental results show that our method outperforms both the
current state-of-the-art method and commonly used commercial software in terms
of bezigon quality.
</dc:description>
 <dc:description>Comment: 18 pages, 16 figures</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01913</dc:identifier>
 <dc:identifier>IEEE Transactions on Visualization and Computer Graphics (TVCG),
  Volume 22 Issue 2, February 2016, Pages 1063-1075</dc:identifier>
 <dc:identifier>doi:10.1109/TVCG.2015.2440273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01921</identifier>
 <datestamp>2017-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recognition of Visually Perceived Compositional Human Actions by
  Multiple Spatio-Temporal Scales Recurrent Neural Networks</dc:title>
 <dc:creator>Lee, Haanvid</dc:creator>
 <dc:creator>Jung, Minju</dc:creator>
 <dc:creator>Tani, Jun</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The current paper proposes a novel neural network model for recognizing
visually perceived human actions. The proposed multiple spatio-temporal scales
recurrent neural network (MSTRNN) model is derived by introducing multiple
timescale recurrent dynamics to the conventional convolutional neural network
model. One of the essential characteristics of the MSTRNN is that its
architecture imposes both spatial and temporal constraints simultaneously on
the neural activity which vary in multiple scales among different layers. As
suggested by the principle of the upward and downward causation, it is assumed
that the network can develop meaningful structures such as functional hierarchy
by taking advantage of such constraints during the course of learning. To
evaluate the characteristics of the model, the current study uses three types
of human action video dataset consisting of different types of primitive
actions and different levels of compositionality on them. The performance of
the MSTRNN in testing with these dataset is compared with the ones by other
representative deep learning models used in the field. The analysis of the
internal representation obtained through the learning with the dataset
clarifies what sorts of functional hierarchy can be developed by extracting the
essential compositionality underlying the dataset.
</dc:description>
 <dc:description>Comment: 10 pages, 9 figures, 5 tables</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2017-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01921</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01925</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Massively Multilingual Word Embeddings</dc:title>
 <dc:creator>Ammar, Waleed</dc:creator>
 <dc:creator>Mulcaire, George</dc:creator>
 <dc:creator>Tsvetkov, Yulia</dc:creator>
 <dc:creator>Lample, Guillaume</dc:creator>
 <dc:creator>Dyer, Chris</dc:creator>
 <dc:creator>Smith, Noah A.</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We introduce new methods for estimating and evaluating embeddings of words in
more than fifty languages in a single shared embedding space. Our estimation
methods, multiCluster and multiCCA, use dictionaries and monolingual data; they
do not require parallel data. Our new evaluation method, multiQVEC-CCA, is
shown to correlate better than previous ones with two downstream tasks (text
categorization and parsing). We also describe a web portal for evaluation that
will facilitate further research in this area, along with open-source releases
of all our methods.
</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:date>2016-05-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01925</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01927</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Feature based Delaunay Triangulation for Palmprint Recognition</dc:title>
 <dc:creator>Khan, Zanobya N.</dc:creator>
 <dc:creator>Qureshi, Rashid Jalal</dc:creator>
 <dc:creator>Ahmad, Jamil</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Authentication of individuals via palmprint based biometric system is
becoming very popular due to its reliability as it contains unique and stable
features. In this paper, we present a novel approach for palmprint recognition
and its representation. To extract the palm lines, local thresholding technique
Niblack binarization algorithm is adopted. The endpoints of these lines are
determined and a connection is created among them using the Delaunay
triangulation thereby generating a distinct topological structure of each
palmprint. Next, we extract different geometric as well as quantitative
features from the triangles of the Delaunay triangulation that assist in
identifying different individuals. To ensure that the proposed approach is
invariant to rotation and scaling, features were made relative to topological
and geometrical structure of the palmprint. The similarity of the two
palmprints is computed using the weighted sum approach and compared with the
k-nearest neighbor. The experimental results obtained reflect the effectiveness
of the proposed approach to discriminate between different palmprint images and
thus achieved a recognition rate of 90% over large databases.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01927</dc:identifier>
 <dc:identifier>Journal of Platform Technology, 3(4), 9-18 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01929</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fantastic 4 system for NIST 2015 Language Recognition Evaluation</dc:title>
 <dc:creator>Lee, Kong Aik</dc:creator>
 <dc:creator>Hautam&#xe4;ki, Ville</dc:creator>
 <dc:creator>Larcher, Anthony</dc:creator>
 <dc:creator>Rao, Wei</dc:creator>
 <dc:creator>Sun, Hanwu</dc:creator>
 <dc:creator>Nguyen, Trung Hieu</dc:creator>
 <dc:creator>Wang, Guangsen</dc:creator>
 <dc:creator>Sizov, Aleksandr</dc:creator>
 <dc:creator>Kukanov, Ivan</dc:creator>
 <dc:creator>Poorjam, Amir</dc:creator>
 <dc:creator>Trong, Trung Ngo</dc:creator>
 <dc:creator>Xiao, Xiong</dc:creator>
 <dc:creator>Xu, Cheng-Lin</dc:creator>
 <dc:creator>Xu, Hai-Hua</dc:creator>
 <dc:creator>Ma, Bin</dc:creator>
 <dc:creator>Li, Haizhou</dc:creator>
 <dc:creator>Meignier, Sylvain</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This article describes the systems jointly submitted by Institute for
Infocomm (I$^2$R), the Laboratoire d'Informatique de l'Universit\'e du Maine
(LIUM), Nanyang Technology University (NTU) and the University of Eastern
Finland (UEF) for 2015 NIST Language Recognition Evaluation (LRE). The
submitted system is a fusion of nine sub-systems based on i-vectors extracted
from different types of features. Given the i-vectors, several classifiers are
adopted for the language detection task including support vector machines
(SVM), multi-class logistic regression (MCLR), Probabilistic Linear
Discriminant Analysis (PLDA) and Deep Neural Networks (DNN).
</dc:description>
 <dc:description>Comment: Technical report for NIST LRE 2015 Workshop</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01930</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficiency of Adversarial Timeline Competition in Online Social Networks</dc:title>
 <dc:creator>Xu, Yuedong</dc:creator>
 <dc:creator>Xiao, Zhujun</dc:creator>
 <dc:creator>Ni, Tianyu</dc:creator>
 <dc:creator>Wang, Xin</dc:creator>
 <dc:creator>Altman, Eitan</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Targeted online advertising elicits a potential threat. A commercial agent
has a chance to mitigate the visibility of his opponents because their sales or
services are of similar types. In this paper, we consider the competition for
attention in popular online social networks (OSNs) that usually employ a
timeline-based homepage to sort messages chronologically in a limited visible
region. A non-cooperative Tullock-like game model is formulated that consists
of a finite amount of \emph{benign} agents and one \emph{malicious} agent. By
paying to the OSN, each benign agent seeks to maximize his utility of
visibility, while the malicious one aims to reduce the utilities of benign
agents. Our primary purposes are to quantify how robust the overall performance
of benign agents is against the malicious action, and how the OSN's revenue is
influenced. We derive the upper and the lower bounds of six fundamental
measures with regard to the total utility and the total net utility of benign
agents and the OSN's revenue under three different scenarios: with and without
the malicious agent, and the maximum. They capture the worst and the best
performances of the benign agents as well as the OSN. Our study reveals two
important insights: i) the performance bounds are very sensitive to the
malicious agent's willingness to pay at certain ranges; ii) the OSN acquires
more revenues from this malicious action.
</dc:description>
 <dc:description>Comment: 21</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01937</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>YOURPRIVACYPROTECTOR, A recommender system for privacy settings in
  social networks</dc:title>
 <dc:creator>Ghazinour, Kambiz</dc:creator>
 <dc:creator>Matwin, Stan</dc:creator>
 <dc:creator>Sokolova, Marina</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Ensuring privacy of users of social networks is probably an unsolvable
conundrum. At the same time, an informed use of the existing privacy options by
the social network participants may alleviate - or even prevent - some of the
more drastic privacy-averse incidents. Unfortunately, recent surveys show that
an average user is either not aware of these options or does not use them,
probably due to their perceived complexity. It is therefore reasonable to
believe that tools assisting users with two tasks: 1) understanding their
social net behavior in terms of their privacy settings and broad privacy
categories, and 2)recommending reasonable privacy options, will be a valuable
tool for everyday privacy practice in a social network context. This paper
presents YourPrivacyProtector, a recommender system that shows how simple
machine learning techniques may provide useful assistance in these two tasks to
Facebook users. We support our claim with empirical results of application of
YourPrivacyProtector to two groups of Facebook users.
</dc:description>
 <dc:description>Comment: 15 pages, International journal of security, privacy and trust
  management. (IJSPTM) Volume 2, No 4, Aug. 2013</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01937</dc:identifier>
 <dc:identifier>International journal of security, privacy and trust management.
  (IJSPTM) Volume 2, No 4, Aug. 2013</dc:identifier>
 <dc:identifier>doi:10.5121/ijsptm.2013.2402</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01940</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic and Quantitative evaluation of attribute discovery methods</dc:title>
 <dc:creator>Liu, Liangchen</dc:creator>
 <dc:creator>Wiliem, Arnold</dc:creator>
 <dc:creator>Chen, Shaokang</dc:creator>
 <dc:creator>Lovell, Brian C.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Many automatic attribute discovery methods have been developed to extract a
set of visual attributes from images for various tasks. However, despite good
performance in some image classification tasks, it is difficult to evaluate
whether these methods discover meaningful attributes and which one is the best
to find the attributes for image descriptions. An intuitive way to evaluate
this is to manually verify whether consistent identifiable visual concepts
exist to distinguish between positive and negative images of an attribute. This
manual checking is tedious, labor intensive and expensive and it is very hard
to get quantitative comparisons between different methods. In this work, we
tackle this problem by proposing an attribute meaningfulness metric, that can
perform automatic evaluation on the meaningfulness of attribute sets as well as
achieving quantitative comparisons. We apply our proposed metric to recent
automatic attribute discovery methods and popular hashing methods on three
attribute datasets. A user study is also conducted to validate the
effectiveness of the metric. In our evaluation, we gleaned some insights that
could be beneficial in developing automatic attribute discovery methods to
generate meaningful attributes. To the best of our knowledge, this is the first
work to quantitatively measure the semantic content of automatically discovered
attributes.
</dc:description>
 <dc:description>Comment: 9 pages, WACV 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01940</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01944</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Immersive Augmented Reality Training for Complex Manufacturing Scenarios</dc:title>
 <dc:creator>Gonzalez-Franco, Mar</dc:creator>
 <dc:creator>Cermeron, Julio</dc:creator>
 <dc:creator>Li, Katie</dc:creator>
 <dc:creator>Pizarro, Rodrigo</dc:creator>
 <dc:creator>Thorn, Jacob</dc:creator>
 <dc:creator>Hutabarat, Windo</dc:creator>
 <dc:creator>Tiwari, Ashutosh</dc:creator>
 <dc:creator>Bermell-Garcia, Pablo</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In the complex manufacturing sector a considerable amount of resources are
focused on developing new skills and training workers. In that context,
increasing the effectiveness of those processes and reducing the investment
required is an outstanding issue. In this paper we present an experiment that
shows how modern Human Computer Interaction (HCI) metaphors such as
collaborative mixed-reality can be used to transmit procedural knowledge and
could eventually replace other forms of face-to-face training. We implement a
real-time Immersive Augmented Reality (IAR) setup with see-through cameras that
allows for collaborative interactions that can simulate conventional forms of
training. The obtained results indicate that people who took the IAR training
achieved the same performance than people in the conventional face-to-face
training condition. These results, their implications for future training and
the use of HCI paradigms in this context are discussed in this paper.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, Video: https://youtu.be/xCbvmGkL6Y4</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-11-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01944</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01947</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Investigating Reliability Aspects of Memristor based RRAM with Reference
  to Write Voltage and Frequency</dc:title>
 <dc:creator>Dongale, T. D.</dc:creator>
 <dc:creator>Khot, K. V.</dc:creator>
 <dc:creator>Mohite, S. V.</dc:creator>
 <dc:creator>Desai, N. K.</dc:creator>
 <dc:creator>Shinde, S. S.</dc:creator>
 <dc:creator>Moholkar, A. V.</dc:creator>
 <dc:creator>Rajpure, K. Y.</dc:creator>
 <dc:creator>Bhosale, P. N.</dc:creator>
 <dc:creator>Patil, P. S.</dc:creator>
 <dc:creator>Gaikwad, P. K.</dc:creator>
 <dc:creator>Kamat, R. K.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>00A72, 68M1</dc:subject>
 <dc:subject>B.3.4</dc:subject>
 <dc:description>  In this paper, we report the effect of write voltage and frequency on
memristor based Resistive Random Access Memory (RRAM). The above said
parameters have been investigated on the linear drift model of memristor. With
a variation of write voltage from 0.2V to 1.2V and a subsequent frequency
modulation from 1, 2, 4, 10, 100 and 200 Hz the corresponding effects on memory
window, Low Resistance State (LRS) and High Resistance State (HRS) have been
reported. Thus the lifetime ({\tau}) reliability analysis of memristor based
RRAM is carried out using above results. It is found that, the HRS is
independent of write voltage, whereas LRS shows dependency on write voltage and
frequency. The simulation results showcase that the memristor possess higher
memory window and lifetime ({\tau}) in the higher voltage with lower frequency
region, which has been attributed to the fewer data losses in the memory
architecture.
</dc:description>
 <dc:description>Comment: Pages-11, figures-6</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01947</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01949</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Trajectory Generation for Quadrotor Based Systems using Numerical
  Optimal Control</dc:title>
 <dc:creator>Geisert, Mathieu</dc:creator>
 <dc:creator>Mansard, Nicolas</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  The recent works on quadrotor have focused on more and more challenging tasks
on increasingly complex systems. Systems are often augmented with slung loads,
inverted pendulums or arms, and accomplish complex tasks such as going through
a window, grasping, throwing or catching. Usually, controllers are designed to
accomplish a specific task on a specific system using analytic solutions, so
each application needs long preparations. On the other hand, the direct
multiple shooting approach is able to solve complex problems without any
analytic development, by using on-the-shelf optimization solver. In this paper,
we show that this approach is able to solve a wide range of problems relevant
to quadrotor systems, from on-line trajectory generation for quadrotors, to
going through a window for a quadrotor-and-pendulum system, through
manipulation tasks for a aerial manipulator.
</dc:description>
 <dc:description>Comment: in ICRA, May 2016, Stockholm, Sweden. 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01950</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RPYS i/o: A web-based tool for the historiography and visualization of
  citation classics, sleeping beauties, and research fronts</dc:title>
 <dc:creator>Comins, Jordan A.</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Reference Publication Year Spectroscopy (RPYS) and Multi-RPYS provide
algorithmic approaches to reconstructing the intellectual histories of
scientific fields. With this brief communication, we describe a technical
advancement for developing research historiographies by introducing RPYS i/o,
an online tool for performing standard RPYS and Multi-RPYS analyses
interactively (at http://comins.leydesdorff.net/). The tool enables users to
explore seminal works underlying a research field and to plot the influence of
these seminal works over time. This suite of visualizations offers the
potential to analyze and visualize the myriad of temporal dynamics of
scientific influence, such as citation classics, sleeping beauties, and the
dynamics of research fronts. We demonstrate the features of the tool by
analyzing--as an example--the references in documents published in the journal
Philosophy of Science.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01956</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>&quot;Almost-stable&quot; matchings in the Hospitals / Residents problem with
  Couples</dc:title>
 <dc:creator>Manlove, David F.</dc:creator>
 <dc:creator>McBride, Iain</dc:creator>
 <dc:creator>Trimble, James</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Hospitals / Residents problem with Couples (HRC) models the allocation of
intending junior doctors to hospitals where couples are allowed to submit joint
preference lists over pairs of (typically geographically close) hospitals. It
is known that a stable matching need not exist, so we consider MIN BP HRC, the
problem of finding a matching that admits the minimum number of blocking pairs
(i.e., is &quot;as stable as possible&quot;). We show that this problem is NP-hard and
difficult to approximate even in the highly restricted case that each couple
finds only one hospital pair acceptable. However if we further assume that the
preference list of each single resident and hospital is of length at most 2, we
give a polynomial-time algorithm for this case. We then present the first
Integer Programming (IP) and Constraint Programming (CP) models for MIN BP HRC.
Finally, we discuss an empirical evaluation of these models applied to
randomly-generated instances of MIN BP HRC. We find that on average, the CP
model is about 1.15 times faster than the IP model, and when presolving is
applied to the CP model, it is on average 8.14 times faster. We further observe
that the number of blocking pairs admitted by a solution is very small, i.e.,
usually at most 1, and never more than 2, for the (28,000) instances
considered.
</dc:description>
 <dc:description>Comment: A shortened version of this paper will appear at CP 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-06-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01956</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01958</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Scenario-Based Optimization for Asset Management in a
  Hierarchical Decision Making Environment</dc:title>
 <dc:creator>Dalal, Gal</dc:creator>
 <dc:creator>Gilboa, Elad</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Asset management attempts to keep the power system in working conditions. It
requires much coordination between multiple entities and long term planning
often months in advance. In this work we introduce a mid-term asset management
formulation as a stochastic optimization problem, that includes three
hierarchical layers of decision making, namely the mid-term, short-term and
real-time. We devise a tractable scenario approximation technique for
efficiently assessing the complex implications a maintenance schedule inflicts
on a power system. This is done using efficient Monte-Carlo simulations that
trade-off between accuracy and tractability. We then present our implementation
of a distributed scenario-based optimization algorithm for solving our
formulation, and use an updated PJM 5-bus system to show a solution that is
cheaper than other maintenance heuristics that are likely to be considered by
TSOs.
</dc:description>
 <dc:description>Comment: Accepted to IEEE PES PSCC2016. Latest update: added acknowledgments</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01958</dc:identifier>
 <dc:identifier>doi:10.1109/PSCC.2016.7540962</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01959</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lifetime-Based Memory Management for Distributed Data Processing Systems</dc:title>
 <dc:creator>Lu, Lu</dc:creator>
 <dc:creator>Shi, Xuanhua</dc:creator>
 <dc:creator>Zhou, Yongluan</dc:creator>
 <dc:creator>Zhang, Xiong</dc:creator>
 <dc:creator>Jin, Hai</dc:creator>
 <dc:creator>Pei, Cheng</dc:creator>
 <dc:creator>He, Ligang</dc:creator>
 <dc:creator>Geng, Yuanzhen</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  In-memory caching of intermediate data and eager combining of data in shuffle
buffers have been shown to be very effective in minimizing the re-computation
and I/O cost in distributed data processing systems like Spark and Flink.
However, it has also been widely reported that these techniques would create a
large amount of long-living data objects in the heap, which may quickly
saturate the garbage collector, especially when handling a large dataset, and
hence would limit the scalability of the system. To eliminate this problem, we
propose a lifetime-based memory management framework, which, by automatically
analyzing the user-defined functions and data types, obtains the expected
lifetime of the data objects, and then allocates and releases memory space
accordingly to minimize the garbage collection overhead. In particular, we
present Deca, a concrete implementation of our proposal on top of Spark, which
transparently decomposes and groups objects with similar lifetimes into byte
arrays and releases their space altogether when their lifetimes come to an end.
An extensive experimental study using both synthetic and real datasets shows
that, in comparing to Spark, Deca is able to 1) reduce the garbage collection
time by up to 99.9%, 2) to achieve up to 22.7x speed up in terms of execution
time in cases without data spilling and 41.6x speedup in cases with data
spilling, and 3) to consume up to 46.6% less memory.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-05-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01959</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01963</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Winning Cores in Parity Games</dc:title>
 <dc:creator>Vester, Steen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We introduce the novel notion of winning cores in parity games and develop a
deterministic polynomial-time under-approximation algorithm for solving parity
games based on winning core approximation. Underlying this algorithm are a
number properties about winning cores which are interesting in their own right.
In particular, we show that the winning core and the winning region for a
player in a parity game are equivalently empty. Moreover, the winning core
contains all fatal attractors but is not necessarily a dominion itself.
Experimental results are very positive both with respect to quality of
approximation and running time. It outperforms existing state-of-the-art
algorithms significantly on most benchmarks.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01970</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Threshold games and cooperation on multiplayer graphs</dc:title>
 <dc:creator>Mikkelsen, Kaare B.</dc:creator>
 <dc:creator>Bach, Lars A.</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>91A06, 91A12, 91A15, 91A22, 91A43</dc:subject>
 <dc:description>  Objective: The study investigates the effect on cooperation in multiplayer
games, when the population from which all individuals are drawn is structured -
i.e. when a given individual is only competing with a small subset of the
entire population.
  Method: To optimize the focus on multiplayer effects, a class of games were
chosen for which the payoff depends nonlinearly on the number of cooperators -
this ensures that the game cannot be represented as a sum of pair-wise
interactions, and increases the likelihood of observing behaviour different
from that seen in two-player games. The chosen class of games are named
&quot;threshold games&quot;, and are defined by a threshold, $M &gt; 0$, which describes the
minimal number of cooperators in a given match required for all the
participants to receive a benefit. The model was studied primarily through
numerical simulations of large populations of individuals, each with
interaction neighbourhoods described by various classes of networks.
  Results: When comparing the level of cooperation in a structured population
to the mean-field model, we find that most types of structure lead to a
decrease in cooperation. This is both interesting and novel, simply due to the
generality and breadth of relevance of the model - it is likely that any model
with similar payoff structure exhibits related behaviour.
  More importantly, we find that the details of the behaviour depends to a
large extent on the size of the immediate neighbourhoods of the individuals, as
dictated by the network structure. In effect, the players behave as if they are
part of a much smaller, fully mixed, population, which we suggest an expression
for.
</dc:description>
 <dc:description>Comment: in PLOS ONE, 4th Feb 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01970</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0147207</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01971</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wayfinding and cognitive maps for pedestrian models</dc:title>
 <dc:creator>Andresen, Erik</dc:creator>
 <dc:creator>Haensel, David</dc:creator>
 <dc:creator>Chraibi, Mohcine</dc:creator>
 <dc:creator>Seyfried, Armin</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Usually, routing models in pedestrian dynamics assume that agents have
fulfilled and global knowledge about the building's structure. However, they
neglect the fact that pedestrians possess no or only parts of information about
their position relative to final exits and possible routes leading to them. To
get a more realistic description we introduce the systematics of gathering and
using spatial knowledge. A new wayfinding model for pedestrian dynamics is
proposed. The model defines for every pedestrian an individual knowledge
representation implying inaccuracies and uncertainties. In addition,
knowledge-driven search strategies are introduced. The presented concept is
tested on a fictive example scenario.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures, TGF'15 Conference, 2015</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01971</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01982</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of the Half-Duplex MIMO Gaussian Diamond Channel</dc:title>
 <dc:creator>Mampilly, Antony V.</dc:creator>
 <dc:creator>Bhashyam, Srikrishna</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>94A15</dc:subject>
 <dc:description>  In this paper, we analyze the 2-relay multiple-input multiple-output (MIMO)
Gaussian diamond channel. We show that a multihopping decode-and-forward with
multiple access (MDF-MAC) protocol achieves rates within a constant gap from
capacity when a channel parameter $\Delta$ is greater than zero. We also
identify the transmit covariance matrices to be used by each relay in the
multiple-access (MAC) state of the MDF-MAC protocol. As done for the
single-antenna 2-relay Gaussian diamond channel, the channel parameter $\Delta$
is defined to be the difference between the product of the capacities of the
links from the source to the two relays and the product of the capacities of
the links from the two relays to the destination.
</dc:description>
 <dc:description>Comment: Submitted to ISIT 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.01995</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient distribution and improved security for reliable cloud storage
  system</dc:title>
 <dc:creator>Marina, Ninoslav</dc:creator>
 <dc:creator>Velkoska, Aneta</dc:creator>
 <dc:creator>Paunkoska, Natasa</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The distributed data storage systems are constructed by large number of nodes
which are interconnected over a network. Each node in such peer-to-peer network
is vulnerable and at a potential risk for attack. The attackers can eavesdrop
the nodes and possibly modify their data. Hence distributed storage systems
should be secure apart from satisfying the reconstruction and repair
requirements. We constructed a distributed storage system, Twin MDS code
framework which is more efficient than the regenerating codes based storage
systems. We prove that this Twin MDS code framework gives better performance
than MBR codes and equal with MSR codes in the distribution process and
investigate its security performance comparing with the security of the MBR and
MSR codes. Such Twin MDS code framework is examined in an eavesdropper model
where passive attackers can access to the stored data or/and downloaded data
during the repair process. We demonstrate that the Twin MDS code framework
manages better results than MBR and MSR codes regarding the security in the
system.
</dc:description>
 <dc:description>Comment: 22 pages, 9 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.01995</dc:identifier>
 <dc:identifier>doi:10.1109/ICUMT.2015.7382437</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02004</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Code Generation for Event-B</dc:title>
 <dc:creator>Rivera, Victor</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Stepwise refinement and Design-by-Contract are two formal approaches for
modelling systems. These approaches are widely used in the development of
systems. Both approaches have (dis-)advantages. This thesis aims to answer, is
it possible to combine both approaches in the development of systems, providing
the user with the benefits of both? We answer this question by translating the
stepwise refinement method with Event-B to Design-by-Contract with Java and
JML, so users can take full advantage of both formal approaches without losing
their benefits. This thesis presents a set of syntactic rules that translates
Event-B to JML-annotated Java code. It also presents the implementation of the
syntactic rules as the EventB2Java tool. We used the tool to translate several
Event-B models. It generated JML-annotated Java code for all the considered
models that serve as initial implementation. We also used EventB2Java for the
development of two software applications. Additionally, we compared EventB2Java
against two other tools for Event-B code generation. EventB2Java enables users
to start the software development process in Event-B, where users can model the
system and prove its consistency, to then transition to JML-annotated Java
code, where users can continue the development process.
</dc:description>
 <dc:description>Comment: PhD thesis. Supervisor: Nestor Catano</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02004</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02009</identifier>
 <datestamp>2016-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing with hardware neurons: spiking or classical? Perspectives of
  applied Spiking Neural Networks from the hardware side</dc:title>
 <dc:creator>Dytckov, Sergei</dc:creator>
 <dc:creator>Daneshtalab, Masoud</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  While classical neural networks take a position of a leading method in the
machine learning community, spiking neuromorphic systems bring attention and
large projects in neuroscience. Spiking neural networks were shown to be able
to substitute networks of classical neurons in applied tasks. This work
explores recent hardware designs focusing on perspective applications (like
convolutional neural networks) for both neuron types from the energy efficiency
side to analyse whether there is a possibility for spiking neuromorphic
hardware to grow up for a wider use. Our comparison shows that spiking hardware
is at least on the same level of energy efficiency or even higher than
non-spiking on a level of basic operations. However, on a system level, spiking
systems are outmatched and consume much more energy due to inefficient data
representation with a long series of spikes. If spike-driven applications,
minimizing an amount of spikes, are developed, spiking neural systems may reach
the energy efficiency level of classical neural systems. However, in the near
future, both type of neuromorphic systems may benefit from emerging memory
technologies, minimizing the energy consumption of computation and memory for
both neuron types. That would make infrastructure and data transfer energy
dominant on the system level. We expect that spiking neurons have some
benefits, which would allow achieving better energy results. Still the problem
of an amount of spikes will still be the major bottleneck for spiking hardware
systems.
</dc:description>
 <dc:description>Comment: Withdrawn by the author as the paper is rejected from the target
  conference</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-04-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02009</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02018</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive Spectral Clustering</dc:title>
 <dc:creator>Tremblay, Nicolas</dc:creator>
 <dc:creator>Puy, Gilles</dc:creator>
 <dc:creator>Gribonval, Remi</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Spectral clustering has become a popular technique due to its high
performance in many contexts. It comprises three main steps: create a
similarity graph between N objects to cluster, compute the first k eigenvectors
of its Laplacian matrix to define a feature vector for each object, and run
k-means on these features to separate objects into k classes. Each of these
three steps becomes computationally intensive for large N and/or k. We propose
to speed up the last two steps based on recent results in the emerging field of
graph signal processing: graph filtering of random signals, and random sampling
of bandlimited graph signals. We prove that our method, with a gain in
computation time that can reach several orders of magnitude, is in fact an
approximation of spectral clustering, for which we are able to control the
error. We test the performance of our method on artificial and real-world
network data.
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02018</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02022</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Preoperative Volume Determination for Pituitary Adenoma</dc:title>
 <dc:creator>Zukic, Dzenan</dc:creator>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:creator>Bauer, Miriam H. A.</dc:creator>
 <dc:creator>Kuhnt, Daniela</dc:creator>
 <dc:creator>Carl, Barbara</dc:creator>
 <dc:creator>Freisleben, Bernd</dc:creator>
 <dc:creator>Kolb, Andreas</dc:creator>
 <dc:creator>Nimsky, Christopher</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  The most common sellar lesion is the pituitary adenoma, and sellar tumors are
approximately 10-15% of all intracranial neoplasms. Manual slice-by-slice
segmentation takes quite some time that can be reduced by using the appropriate
algorithms. In this contribution, we present a segmentation method for
pituitary adenoma. The method is based on an algorithm that we have applied
recently to segmenting glioblastoma multiforme. A modification of this scheme
is used for adenoma segmentation that is much harder to perform, due to lack of
contrast-enhanced boundaries. In our experimental evaluation, neurosurgeons
performed manual slice-by-slice segmentation of ten magnetic resonance imaging
(MRI) cases. The segmentations were compared to the segmentation results of the
proposed method using the Dice Similarity Coefficient (DSC). The average DSC
for all datasets was 75.92% +/- 7.24%. A manual segmentation took about four
minutes and our algorithm required about one second.
</dc:description>
 <dc:description>Comment: 7 pages, 6 figures, 1 table, 16 references in Proc. SPIE 7963,
  Medical Imaging 2011: Computer-Aided Diagnosis, 79632T (9 March 2011). arXiv
  admin note: text overlap with arXiv:1103.1778</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02022</dc:identifier>
 <dc:identifier>doi:10.1117/12.877660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02023</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Multi-view Performance Capture of Fine-Scale Surface Detail</dc:title>
 <dc:creator>Robertini, Nadia</dc:creator>
 <dc:creator>De Aguiar, Edilson</dc:creator>
 <dc:creator>Helten, Thomas</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We present a new effective way for performance capture of deforming meshes
with fine-scale time-varying surface detail from multi-view video. Our method
builds up on coarse 4D surface reconstructions, as obtained with commonly used
template-based methods. As they only capture models of coarse-to-medium scale
detail, fine scale deformation detail is often done in a second pass by using
stereo constraints, features, or shading-based refinement. In this paper, we
propose a new effective and stable solution to this second step. Our framework
creates an implicit representation of the deformable mesh using a dense
collection of 3D Gaussian functions on the surface, and a set of 2D Gaussians
for the images. The fine scale deformation of all mesh vertices that maximizes
photo-consistency can be efficiently found by densely optimizing a new
model-to-image consistency energy on all vertex positions. A principal
advantage is that our problem formulation yields a smooth closed form energy
with implicit occlusion handling and analytic derivatives. Error-prone
correspondence finding, or discrete sampling of surface displacement values are
also not needed. We show several reconstructions of human subjects wearing
loose clothing, and we qualitatively and quantitatively show that we robustly
capture more detail than related methods.
</dc:description>
 <dc:description>Comment: 3D Vision (3DV), 2014 2nd International Conference on</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02023</dc:identifier>
 <dc:identifier>doi:10.1109/3DV.2014.46</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02026</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph parameters from symplectic group invariants</dc:title>
 <dc:creator>Regts, Guus</dc:creator>
 <dc:creator>Sevenster, Bart</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>05C45, 15A72, Secondary 05C25, 05C31</dc:subject>
 <dc:description>  In this paper we introduce, and characterize, a class of graph parameters
obtained from tensor invariants of the symplectic group. These parameters are
similar to partition functions of vertex models, as introduced by de la Harpe
and Jones, [P. de la Harpe, V.F.R. Jones, Graph invariants related to
statistical mechanical models: examples and problems, Journal of Combinatorial
Theory, Series B 57 (1993) 207-227]. Yet they give a completely different class
of graph invariants. We moreover show that certain evaluations of the cycle
partition polynomial, as defined by Martin [P. Martin, Enum\'erations
eul\'eriennes dans les multigraphes et invariants de Tutte-Grothendieck, Diss.
Institut National Polytechnique de Grenoble-INPG; Universit\'e
Joseph-Fourier-Grenoble I, 1977], give examples of graph parameters that can be
obtained this way.
</dc:description>
 <dc:description>Comment: Some corrections have been made on the basis of referee comments. 21
  pages, 1 figure. Accepted in JCTB</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02030</identifier>
 <datestamp>2017-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptation Logic for HTTP Dynamic Adaptive Streaming using
  Geo-Predictive Crowdsourcing</dc:title>
 <dc:creator>Dubin, Ran</dc:creator>
 <dc:creator>Dvir, Amit</dc:creator>
 <dc:creator>Pele, Ofir</dc:creator>
 <dc:creator>Hadar, Ofer</dc:creator>
 <dc:creator>Katz, Itay</dc:creator>
 <dc:creator>Mashiach, Ori</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The increasing demand for video streaming services with high Quality of
Experience (QoE) has prompted a lot of research on client-side adaptation logic
approaches. However, most algorithms use the client's previous download
experience and do not use a crowd knowledge database generated by users of a
professional service. We propose a new crowd algorithm that maximizes the QoE.
Additionally, we show how crowd information can be integrated into existing
algorithms and illustrate this with two state-of-the-art algorithms. We
evaluate our algorithm and state-of-the-art algorithms (including our modified
algorithms) on a large, real-life crowdsourcing dataset that contains 336,551
samples on network performance. The dataset was provided by WeFi LTD. Our new
algorithm outperforms all other methods in terms of QoS (eMOS).
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02030</dc:identifier>
 <dc:identifier>doi:10.1007/s00530-016-0525-6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02032</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Track selection in Multifunction Radars for Multi-target tracking: an
  Anti-Coordination game</dc:title>
 <dc:creator>Bogdanovi&#x107;, Nikola</dc:creator>
 <dc:creator>Driessen, Hans</dc:creator>
 <dc:creator>Yarovoy, Alexander</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, a track selection problem for multi-target tracking in a
multifunction radar network is studied using the concepts from game theory. The
problem is formulated as a non-cooperative game, and specifically as an
anti-coordination game, where each player aims to differ from what other
players do. The players' utilities are modeled using a proper tracking accuracy
criterion and, under different assumptions on the structure of these utilities,
the corresponding Nash equilibria are characterized. To find an equilibrium, a
distributed algorithm based on the best-response dynamics is proposed. Finally,
computer simulations are carried out to verify the effectiveness of the
proposed algorithm in a multi-target tracking scenario.
</dc:description>
 <dc:description>Comment: Accepted for ICASSP 2016 conference</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02036</identifier>
 <datestamp>2016-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classical capacities of quantum channels with environment assistance</dc:title>
 <dc:creator>Karumanchi, Siddharth</dc:creator>
 <dc:creator>Mancini, Stefano</dc:creator>
 <dc:creator>Winter, Andreas</dc:creator>
 <dc:creator>Yang, Dong</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A quantum channel physically is a unitary interaction between the information
carrying system and an environment, which is initialized in a pure state before
the interaction. Conventionally, this state, as also the parameters of the
interaction, is assumed to be fixed and known to the sender and receiver. Here,
following the model introduced by us earlier [Karumanchi et al.,
arXiv[quant-ph]:1407.8160], we consider a benevolent third party, i.e. a
helper, controlling the environment state, and how the helper's presence
changes the communication game. In particular, we define and study the
classical capacity of a unitary interaction with helper, indeed two variants,
one where the helper can only prepare separable states across many channel
uses, and one without this restriction. Furthermore, the two even more powerful
scenarios of pre-shared entanglement between helper and receiver, and of
classical communication between sender and helper (making them conferencing
encoders) are considered.
</dc:description>
 <dc:description>Comment: 28 pages, 9 figures. To appear in &quot;Problems of Information
  Transmission&quot;</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-06-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02036</dc:identifier>
 <dc:identifier>Problems of Information Transmission, vol. 52, no. 3, pp. 214-238
  (2016)</dc:identifier>
 <dc:identifier>doi:10.1134/S0032946016030029</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02040</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient and Scalable Distributed Autonomous Spatial Aloha Networks via
  Local Leader Election</dc:title>
 <dc:creator>Lyu, Jiangbin</dc:creator>
 <dc:creator>Chew, Yong Huat</dc:creator>
 <dc:creator>Wong, Wai-Choong</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper uses a spatial Aloha model to describe a distributed autonomous
wireless network in which a group of transmit-receive pairs (users) shares a
common collision channel via slotted-Aloha-like random access. The objective of
this study is to develop an intelligent algorithm to be embedded into the
transceivers so that all users know how to self-tune their medium access
probability (MAP) to achieve overall Pareto optimality in terms of network
throughput under spatial reuse while maintaining network stability. While the
optimal solution requires each user to have complete information about the
network, our proposed algorithm only requires users to have local information.
The fundamental of our algorithm is that the users will first self-organize
into a number of non-overlapping neighborhoods, and the user with the maximum
node degree in each neighborhood is elected as the local leader (LL). Each LL
then adjusts its MAP according to a parameter R which indicates the radio
intensity level in its neighboring region, whereas the remaining users in the
neighborhood simply follow the same MAP value. We show that by ensuring R less
than or equal to 2 at the LLs, the stability of the entire network can be
assured even when each user only has partial network information. For practical
implementation, we propose each LL to use R=2 as the constant reference signal
to its built-in proportional and integral controller. The settings of the
control parameters are discussed and we validate through simulations that the
proposed method is able to achieve close-to-Pareto-front throughput.
</dc:description>
 <dc:description>Comment: 32 pages, 10 figures, accepted for publication in IEEE Transactions
  on Vehicular Technology</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02040</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2527058</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02041</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Network Coding in a Slotted ALOHA-based Two-Way Relay
  Network</dc:title>
 <dc:creator>Javid, Alireza Mahdavi</dc:creator>
 <dc:creator>Setayesh, Mehdi</dc:creator>
 <dc:creator>Farhadi, Farzaneh</dc:creator>
 <dc:creator>Ashtiani, Farid</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper deals with a two-way relay network (TWRN) based on a slotted ALOHA
protocol which utilizes network coding to exchange the packets. We proposed an
analytical approach to study the behavior of such networks and the effects of
network coding on the throughput, power, and queueing delay of the relay node.
In addition, when end nodes are not saturated, our approach enables us to
achieve the stability region of the network in different situations. Finally,
we carry out some simulation to confirm the validity of the proposed analytical
approach.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02041</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02045</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Logic Control of a Hybrid Energy Storage Module for Naval Pulsed
  Power Applications</dc:title>
 <dc:creator>Cohen, Isaac J.</dc:creator>
 <dc:creator>Wetz, David A.</dc:creator>
 <dc:creator>Veiga, Stepfanie</dc:creator>
 <dc:creator>Dong, Qing</dc:creator>
 <dc:creator>Heinzel, John</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  There is need for an energy storage device capable of transferring high power
in transient situations aboard naval vessels. Currently, batteries are used to
accomplish this task, but previous research has shown that when utilized at
high power rates, these devices deteriorate over time causing a loss in
lifespan. It has been shown that a hybrid energy storage configuration is
capable of meeting such a demand while reducing the strain placed on individual
components. While designing a custom converter capable of controlling the power
to and from a battery would be ideal for this application, it can be costly to
develop when compared to purchasing commercially available products.
Commercially available products offer limited controllability in exchange for
their proven performance and lower cost point - often times only allowing a
system level control input without any way to interface with low level controls
that are frequently used in controller design. This paper proposes the use of
fuzzy logic control in order to provide a system level control to the
converters responsible for limiting power to and from the battery. A system
will be described mathematically, modeled in MATLAB/Simulink, and a fuzzy logic
controller will be compared with a typical controller.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02045</dc:identifier>
 <dc:identifier>International Journal of Fuzzy Logic Systems, vol. 6, no. 1, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02046</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MyAdChoices: Bringing Transparency and Control to Online Advertising</dc:title>
 <dc:creator>Parra-Arnau, Javier</dc:creator>
 <dc:creator>Achara, Jagdish Prasad</dc:creator>
 <dc:creator>Castelluccia, Claude</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  The intrusiveness and the increasing invasiveness of online advertising have,
in the last few years, raised serious concerns regarding user privacy and Web
usability. As a reaction to these concerns, we have witnessed the emergence of
a myriad of ad-blocking and anti-tracking tools, whose aim is to return control
to users over advertising. The problem with these technologies, however, is
that they are extremely limited and radical in their approach: users can only
choose either to block or allow all ads. With around 200 million people
regularly using these tools, the economic model of the Web ---in which users
get content free in return for allowing advertisers to show them ads--- is at
serious peril. In this paper, we propose a smart Web technology that aims at
bringing transparency to online advertising, so that users can make an informed
and equitable decision regarding ad blocking. The proposed technology is
implemented as a Web-browser extension and enables users to exert fine-grained
control over advertising, thus providing them with certain guarantees in terms
of privacy and browsing experience, while preserving the Internet economic
model. Experimental results in a real environment demonstrate the suitability
and feasibility of our approach, and provide preliminary findings on behavioral
targeting from real user browsing profiles.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02046</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02047</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Utiliza\c{c}\~ao de Grafos e Matriz de Similaridade na Sumariza\c{c}\~ao
  Autom\'atica de Documentos Baseada em Extra\c{c}\~ao de Frases</dc:title>
 <dc:creator>Pontes, Elvys Linhares</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  The internet increased the amount of information available. However, the
reading and understanding of this information are costly tasks. In this
scenario, the Natural Language Processing (NLP) applications enable very
important solutions, highlighting the Automatic Text Summarization (ATS), which
produce a summary from one or more source texts. Automatically summarizing one
or more texts, however, is a complex task because of the difficulties inherent
to the analysis and generation of this summary. This master's thesis describes
the main techniques and methodologies (NLP and heuristics) to generate
summaries. We have also addressed and proposed some heuristics based on graphs
and similarity matrix to measure the relevance of judgments and to generate
summaries by extracting sentences. We used the multiple languages (English,
French and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA
(French) corpus to evaluate the developped systems. The results obtained were
quite interesting.
</dc:description>
 <dc:description>Comment: Dissertation, 83 pages, in Portuguese. in Disserta\c{c}\~ao de
  Mestrado, Universidade Federal do Cear\'a, 2015</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02047</dc:identifier>
 <dc:language>pt</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02049</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A fast, deterministic algorithm for computing a Hermite Normal Form of a
  polynomial matrix</dc:title>
 <dc:creator>Labahn, George</dc:creator>
 <dc:creator>Zhou, Wei</dc:creator>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:description>  Given a square, nonsingular matrix of univariate polynomials $\mathbf{F} \in
\mathbb{K}[x]^{n \times n}$ over a field $\mathbb{K}$, we give a fast,
deterministic algorithm for finding the Hermite normal form of $\mathbf{F}$
with complexity $O^{\sim}\left(n^{\omega}d\right)$ where $d$ is the degree of
$\mathbf{F}$. Here soft-$O$ notation is Big-$O$ with log factors removed and
$\omega$ is the exponent of matrix multiplication. The method relies of a fast
algorithm for determining the diagonal entries of its Hermite normal form,
having as cost $O^{\sim}\left(n^{\omega}s\right)$ operations with $s$ the
average of the column degrees of $\mathbf{F}$.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02049</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02052</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Comparison of 10 Sampling Algorithms for Configurable Systems</dc:title>
 <dc:creator>Medeiros, Fl&#xe1;vio</dc:creator>
 <dc:creator>K&#xe4;stner, Christian</dc:creator>
 <dc:creator>Ribeiro, M&#xe1;rcio</dc:creator>
 <dc:creator>Gheyi, Rohit</dc:creator>
 <dc:creator>Apel, Sven</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Almost every software system provides configuration options to tailor the
system to the target platform and application scenario. Often, this
configurability renders the analysis of every individual system configuration
infeasible. To address this problem, researchers have proposed a diverse set of
sampling algorithms. We present a comparative study of 10 state-of-the-art
sampling algorithms regarding their fault-detection capability and size of
sample sets. The former is important to improve software quality and the latter
to reduce the time of analysis. In a nutshell, we found that sampling
algorithms with larger sample sets are able to detect higher numbers of faults,
but simple algorithms with small sample sets, such as most-enabled-disabled,
are the most efficient in most contexts. Furthermore, we observed that the
limiting assumptions made in previous work influence the number of detected
faults, the size of sample sets, and the ranking of algorithms. Finally, we
have identified a number of technical challenges when trying to avoid the
limiting assumptions, which questions the practicality of certain sampling
algorithms.
</dc:description>
 <dc:description>Comment: An extended version of our ICSE 2016 paper, entitled: A Comparison of
  10 Sampling Algorithms for Configurable Systems</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02052</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02057</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Generalised Differential Framework for Measuring Signal Sparsity</dc:title>
 <dc:creator>Maronidis, Anastasios</dc:creator>
 <dc:creator>Chatzilari, Elisavet</dc:creator>
 <dc:creator>Nikolopoulos, Spiros</dc:creator>
 <dc:creator>Kompatsiaris, Ioannis</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The notion of signal sparsity has been gaining increasing interest in
information theory and signal processing communities. As a consequence, a
plethora of sparsity metrics has been presented in the literature. The
appropriateness of these metrics is typically evaluated against a set of
objective criteria that has been proposed for assessing the credibility of any
sparsity metric. In this paper, we propose a Generalised Differential Sparsity
(GDS) framework for generating novel sparsity metrics whose functionality is
based on the concept that sparsity is encoded in the differences among the
signal coefficients. We rigorously prove that every metric generated using GDS
satisfies all the aforementioned criteria and we provide a computationally
efficient formula that makes GDS suitable for high-dimensional signals. The
great advantage of GDS is its flexibility to offer sparsity metrics that can be
well-tailored to certain requirements stemming from the nature of the data and
the problem to be solved. This is in contrast to current state-of-the-art
sparsity metrics like Gini Index (GI), which is actually proven to be only a
specific instance of GDS, demonstrating the generalisation power of our
framework. In verifying our claims, we have incorporated GDS in a stochastic
signal recovery algorithm and experimentally investigated its efficacy in
reconstructing randomly projected sparse signals. As a result, it is proven
that GDS, in comparison to GI, both loosens the bounds of the assumed sparsity
of the original signals and reduces the minimum number of projected dimensions,
required to guarantee an almost perfect reconstruction of heavily compressed
signals. The superiority of GDS over GI in conjunction with the fact that the
latter is considered as a standard in numerous scientific domains, prove the
great potential of GDS as a general purpose framework for measuring sparsity.
</dc:description>
 <dc:description>Comment: 14 pages, 4 figures, The abstract field cannot be longer than 1,920
  characters: The abstract appearing here is slightly shorter than the one in
  the pdf</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02057</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02063</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the power of dominated players in team competitions</dc:title>
 <dc:creator>Jin, Kai</dc:creator>
 <dc:creator>Tang, Pingzhong</dc:creator>
 <dc:creator>Chen, Shiteng</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>91A06</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  We investigate multi-round team competitions between two teams, where each
team selects one of its players simultaneously in each round and each player
can play at most once. The competition defines an extensive-form game with
perfect recall and can be solved efficiently by standard methods. We are
interested in the properties of the subgame perfect equilibria of this game.
  We first show that uniformly random strategy is a subgame perfect equilibrium
strategy for both teams when there are no redundant players (i.e., the number
of players in each team equals to the number of rounds of the competition).
Secondly, a team can safely abandon its weak players if it has redundant
players and the strength of players is transitive.
  We then focus on the more interesting case where there are redundant players
and the strength of players is not transitive. In this case, we obtain several
counterintuitive results. First of all, a player might help improve the payoff
of its team, even if it is dominated by the entire other team. We give a
necessary condition for a dominated player to be useful. We also study the
extent to which the dominated players can increase the payoff.
  These results bring insights into playing and designing general team
competitions.
</dc:description>
 <dc:description>Comment: 8pages, AAMAS2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02063</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02066</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Fictitious Play for Optimal Behavior of Multi-Agent Systems
  with Incomplete Information</dc:title>
 <dc:creator>Eksin, Ceyhun</dc:creator>
 <dc:creator>Ribeiro, Alejandro</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  A multi-agent system operates in an uncertain environment about which agents
have different and time varying beliefs that, as time progresses, converge to a
common belief. A global utility function that depends on the realized state of
the environment and actions of all the agents determines the system's optimal
behavior. We define the asymptotically optimal action profile as an equilibrium
of the potential game defined by considering the expected utility with respect
to the asymptotic belief. At finite time, however, agents have not entirely
congruous beliefs about the state of the environment and may select conflicting
actions. This paper proposes a variation of the fictitious play algorithm which
is proven to converge to equilibrium actions if the state beliefs converge to a
common distribution at a rate that is at least linear. In conventional
fictitious play, agents build beliefs on others' future behavior by computing
histograms of past actions and best respond to their expected payoffs
integrated with respect to these histograms. In the variations developed here
histograms are built using knowledge of actions taken by nearby nodes and best
responses are further integrated with respect to the local beliefs on the state
of the environment. We exemplify the use of the algorithm in coordination and
target covering games.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02066</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02068</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label
  Classification</dc:title>
 <dc:creator>Martins, Andr&#xe9; F. T.</dc:creator>
 <dc:creator>Astudillo, Ram&#xf3;n Fernandez</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose sparsemax, a new activation function similar to the traditional
softmax, but able to output sparse probabilities. After deriving its
properties, we show how its Jacobian can be efficiently computed, enabling its
use in a network trained with backpropagation. Then, we propose a new smooth
and convex loss function which is the sparsemax analogue of the logistic loss.
We reveal an unexpected connection between this new loss and the Huber
classification loss. We obtain promising empirical results in multi-label
classification problems and in attention-based neural networks for natural
language inference. For the latter, we achieve a similar performance as the
traditional softmax, but with a selective, more compact, attention focus.
</dc:description>
 <dc:description>Comment: Minor corrections</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02068</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02070</identifier>
 <datestamp>2016-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressive PCA for Low-Rank Matrices on Graphs</dc:title>
 <dc:creator>Shahid, Nauman</dc:creator>
 <dc:creator>Perraudin, Nathanael</dc:creator>
 <dc:creator>Puy, Gilles</dc:creator>
 <dc:creator>Vandergheynst, Pierre</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a novel framework for an approxi- mate recovery of data matrices
which are low-rank on graphs, from sampled measurements. The rows and columns
of such matrices belong to the span of the first few eigenvectors of the graphs
constructed between their rows and columns. We leverage this property to
recover the non-linear low-rank structures efficiently from sampled data
measurements, with a low cost (linear in n). First, a Resrtricted Isometry
Property (RIP) condition is introduced for efficient uniform sampling of the
rows and columns of such matrices based on the cumulative coherence of graph
eigenvectors. Secondly, a state-of-the-art fast low-rank recovery method is
suggested for the sampled data. Finally, several efficient, parallel and
parameter-free decoders are presented along with their theoretical analysis for
decoding the low-rank and cluster indicators for the full data matrix. Thus, we
overcome the computational limitations of the standard linear low-rank recovery
methods for big datasets. Our method can also be seen as a major step towards
efficient recovery of non- linear low-rank structures. For a matrix of size n X
p, on a single core machine, our method gains a speed up of $p^2/k$ over Robust
Principal Component Analysis (RPCA), where k &lt;&lt; p is the subspace dimension.
Numerically, we can recover a low-rank matrix of size 10304 X 1000, 100 times
faster than Robust PCA.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-10-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02070</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02086</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Region Based Approximation for High Dimensional Bayesian Network Models</dc:title>
 <dc:creator>Lin, Peng</dc:creator>
 <dc:creator>Neil, Martin</dc:creator>
 <dc:creator>Fenton, Norman</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Performing efficient inference on Bayesian Networks (BNs), with large numbers
of densely connected variables is challenging. With exact inference methods,
such as the Junction Tree algorithm, clustering complexity can grow
exponentially with the number of nodes and so computation becomes intractable.
This paper presents a general purpose approximate inference algorithm called
Triplet Region Construction (TRC) that reduces the clustering complexity for
factorized models from worst case exponential to polynomial. We employ graph
factorization to reduce connection complexity and produce clusters of limited
size. Unlike MCMC algorithms TRC is guaranteed to converge and we present
experiments that show that TRC achieves accurate results when compared with
exact solutions.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02086</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02089</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Harmonic Grammar in a DisCo Model of Meaning</dc:title>
 <dc:creator>Lewis, Martha</dc:creator>
 <dc:creator>Coecke, Bob</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The model of cognition developed in (Smolensky and Legendre, 2006) seeks to
unify two levels of description of the cognitive process: the connectionist and
the symbolic. The theory developed brings together these two levels into the
Integrated Connectionist/Symbolic Cognitive architecture (ICS). Clark and
Pulman (2007) draw a parallel with semantics where meaning may be modelled on
both distributional and symbolic levels, developed by Coecke et al, 2010 into
the Distributional Compositional (DisCo) model of meaning. In the current work,
we revisit Smolensky and Legendre (S&amp;L)'s model. We describe the DisCo
framework, summarise the key ideas in S&amp;L's architecture, and describe how
their description of harmony as a graded measure of grammaticality may be
applied in the DisCo model.
</dc:description>
 <dc:description>Comment: Abstract, Advances in Distributional Semantics, IWCS</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02089</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02091</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Innovative Physical Layer Design for Mobile WSN Platforms</dc:title>
 <dc:creator>Tripathy, Malay Ranjan</dc:creator>
 <dc:creator>Ranjan, Priya</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  We today live in the era of dynamic and mobile wireless enabled platforms.
This kind of stringent communication capability in the face of volatile and
turbulent mobility demands a fresh look at physical layer in general and
antenna design in particular. The dimension of the antenna is 30x35x1.6 mm^3.
Multiplicity of bands is very useful for compatibility purposes where legacy
robotic platforms generally operate in MHz range while latest robotic platforms
are capable to handle GHz communication regimes and can pump data very at much
greater speeds. Seven frequency bands are obtained at 700 MHz, 2.4 GHz, 3.6
GHz, 4.37 GHz, 5.8 GHz, 6.93 GHz and 7.7 GHz with bandwidth of 1.1 GHz, 0.7
GHz, 0.8 GHz, 0.23 GHz, 0.90 GHz, 0.19 GHz and 0.12 GHz respectively.
</dc:description>
 <dc:description>Comment: Accepted for Publication at International Conference on IoT and Cloud
  Computing (ICC 2016)-http://icc-conference.org/</dc:description>
 <dc:date>2016-02-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02098</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Continuous opinions and discrete actions in social networks: a
  multi-agent system approach</dc:title>
 <dc:creator>Chowdhury, N. R.</dc:creator>
 <dc:creator>Morarescu, I. -C.</dc:creator>
 <dc:creator>Martin, S.</dc:creator>
 <dc:creator>Srikant, S.</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper proposes and analyzes a novel multi-agent opinion dynamics model
in which agents have access to actions which are quantized version of the
opinions of their neighbors. The model produces different behaviors observed in
social networks such as disensus, clustering, oscillations, opinion
propagation, even when the communication network is connected. The main results
of the paper provides the characterization of preservation and diffusion of
actions under general communication topologies. A complete analysis allowing
the opinion forecasting is given in the particular cases of complete and ring
communication graphs. Numerical examples illustrate the main features of this
model.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02098</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02101</identifier>
 <datestamp>2017-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variance-Reduced and Projection-Free Stochastic Optimization</dc:title>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:creator>Luo, Haipeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The Frank-Wolfe optimization algorithm has recently regained popularity for
machine learning applications due to its projection-free property and its
ability to handle structured constraints. However, in the stochastic learning
setting, it is still relatively understudied compared to the gradient descent
counterpart. In this work, leveraging a recent variance reduction technique, we
propose two stochastic Frank-Wolfe variants which substantially improve
previous results in terms of the number of stochastic gradient evaluations
needed to achieve $1-\epsilon$ accuracy. For example, we improve from
$O(\frac{1}{\epsilon})$ to $O(\ln\frac{1}{\epsilon})$ if the objective function
is smooth and strongly convex, and from $O(\frac{1}{\epsilon^2})$ to
$O(\frac{1}{\epsilon^{1.5}})$ if the objective function is smooth and
Lipschitz. The theoretical improvement is also observed in experiments on
real-world datasets for a multiclass classification application.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2017-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02102</identifier>
 <datestamp>2018-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Spacey Random Walk: a Stochastic Process for Higher-order Data</dc:title>
 <dc:creator>Benson, Austin R.</dc:creator>
 <dc:creator>Gleich, David F.</dc:creator>
 <dc:creator>Lim, Lek-Heng</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:description>  Random walks are a fundamental model in applied mathematics and are a common
example of a Markov chain. The limiting stationary distribution of the Markov
chain represents the fraction of the time spent in each state during the
stochastic process. A standard way to compute this distribution for a random
walk on a finite set of states is to compute the Perron vector of the
associated transition matrix. There are algebraic analogues of this Perron
vector in terms of transition probability tensors of higher-order Markov
chains. These vectors are nonnegative, have dimension equal to the dimension of
the state space, and sum to one and are derived by making an algebraic
substitution in the equation for the joint-stationary distribution of a
higher-order Markov chains. Here, we present the spacey random walk, a
non-Markovian stochastic process whose stationary distribution is given by the
tensor eigenvector. The process itself is a vertex-reinforced random walk, and
its discrete dynamics are related to a continuous dynamical system. We analyze
the convergence properties of these dynamics and discuss numerical methods for
computing the stationary distribution. Finally, we provide several applications
of the spacey random walk model in population genetics, ranking, and clustering
data, and we use the process to analyze taxi trajectory data in New York. This
example shows definite non-Markovian structure.
</dc:description>
 <dc:description>Comment: Updated from V1: Expanded introduction; minor revisions; typos</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-12-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02102</dc:identifier>
 <dc:identifier>SIAM Review, 59(2). 2017</dc:identifier>
 <dc:identifier>doi:10.1137/16M1074023</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02114</identifier>
 <datestamp>2017-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exchangeable Random Measures for Sparse and Modular Graphs with
  Overlapping Communities</dc:title>
 <dc:creator>Todeschini, Adrien</dc:creator>
 <dc:creator>Miscouridou, Xenia</dc:creator>
 <dc:creator>Caron, Fran&#xe7;ois</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a novel statistical model for sparse networks with overlapping
community structure. The model is based on representing the graph as an
exchangeable point process, and naturally generalizes existing probabilistic
models with overlapping block-structure to the sparse regime. Our construction
builds on vectors of completely random measures, and has interpretable
parameters, each node being assigned a vector representing its level of
affiliation to some latent communities. We develop methods for simulating this
class of random graphs, as well as to perform posterior inference. We show that
the proposed approach can recover interpretable structure from two real-world
networks and can handle graphs with thousands of nodes and tens of thousands of
edges.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2017-08-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02120</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Ordered Sets Using Join</dc:title>
 <dc:creator>Blelloch, Guy</dc:creator>
 <dc:creator>Ferizovic, Daniel</dc:creator>
 <dc:creator>Sun, Yihan</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The ordered set is one of the most important data type in both theoretical
algorithm design and analysis and practical programming. In this paper we study
the set operations on two ordered sets, including Union, Intersect and
Difference, based on four types of balanced Binary Search Trees (BST) including
AVL trees, red-black trees, weight balanced trees and treaps. We introduced
only one subroutine Join that needs to be implemented differently for each
balanced BST, and on top of which we can implement generic, simple and
efficient parallel functions for ordered sets. We first prove the
work-efficiency of these Join-based set functions using a generic proof working
for all the four types of balanced BSTs.
  We also implemented and tested our algorithm on all the four balancing
schemes. Interestingly the implementations on all four data structures and
three set functions perform similarly in time and speedup (more than 45x on 64
cores). We also compare the performance of our implementation to other existing
libraries and algorithms.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-11-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02120</dc:identifier>
 <dc:identifier>doi:10.1145/2935764.2935768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02123</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequence Classification with Neural Conditional Random Fields</dc:title>
 <dc:creator>Abramson, Myriam</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The proliferation of sensor devices monitoring human activity generates
voluminous amount of temporal sequences needing to be interpreted and
categorized. Moreover, complex behavior detection requires the personalization
of multi-sensor fusion algorithms. Conditional random fields (CRFs) are
commonly used in structured prediction tasks such as part-of-speech tagging in
natural language processing. Conditional probabilities guide the choice of each
tag/label in the sequence conflating the structured prediction task with the
sequence classification task where different models provide different
categorization of the same sequence. The claim of this paper is that CRF models
also provide discriminative models to distinguish between types of sequence
regardless of the accuracy of the labels obtained if we calibrate the class
membership estimate of the sequence. We introduce and compare different neural
network based linear-chain CRFs and we present experiments on two complex
sequence classification and structured prediction tasks to support this claim.
</dc:description>
 <dc:description>Comment: 14th International Conference on Machine Learning and Applications
  (ICMLA) 2015</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02123</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02125</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tuner control system of spoke012 SRF cavity for C-ADS injector I at IHEP</dc:title>
 <dc:creator>Liu, Na</dc:creator>
 <dc:creator>Sun, Yi</dc:creator>
 <dc:creator>Wang, Guang-Wei</dc:creator>
 <dc:creator>Mi, Zheng-Hui</dc:creator>
 <dc:creator>Lin, Hai-Ying</dc:creator>
 <dc:creator>Wang, Qun-Yao</dc:creator>
 <dc:creator>Liu, Rong</dc:creator>
 <dc:creator>Ma, Xin-Peng</dc:creator>
 <dc:subject>Physics - Accelerator Physics</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>High Energy Physics - Experiment</dc:subject>
 <dc:description>  A new tuner control system of spoke superconducting radio frequency (SRF)
cavity has been developed and applied to cryomodule I (CM1) of C-ADS injector I
at IHEP. We have successfully implemented the tuner controllerfor the first
time and achieved a cavity tuning phase error of 0.7degrees (about 4 Hz peak to
peak) in the presence of electromechanical coupled resonance. This paper will
present the preliminary experimental results based on the new tuner controller
under proton beam commissioning.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02125</dc:identifier>
 <dc:identifier>doi:10.1088/1674-1137/40/9/097001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02129</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on the Complexity of Computing the Number of Reachable Vertices
  in a Digraph</dc:title>
 <dc:creator>Borassi, Michele</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this work, we consider the following problem: given a digraph $G=(V,E)$,
for each vertex $v$, we want to compute the number of vertices reachable from
$v$. In other words, we want to compute the out-degree of each vertex in the
transitive closure of $G$. We show that this problem is not solvable in time
$\mathcal{O}\left(|E|^{2-\epsilon}\right)$ for any $\epsilon&gt;0$, unless the
Strong Exponential Time Hypothesis is false. This result still holds if $G$ is
assumed to be acyclic.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02129</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02130</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sub-cortical brain structure segmentation using F-CNN's</dc:title>
 <dc:creator>Shakeri, Mahsa</dc:creator>
 <dc:creator>Tsogkas, Stavros</dc:creator>
 <dc:creator>Ferrante, Enzo</dc:creator>
 <dc:creator>Lippe, Sarah</dc:creator>
 <dc:creator>Kadoury, Samuel</dc:creator>
 <dc:creator>Paragios, Nikos</dc:creator>
 <dc:creator>Kokkinos, Iasonas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a deep learning approach for segmenting sub-cortical
structures of the human brain in Magnetic Resonance (MR) image data. We draw
inspiration from a state-of-the-art Fully-Convolutional Neural Network (F-CNN)
architecture for semantic segmentation of objects in natural images, and adapt
it to our task. Unlike previous CNN-based methods that operate on image
patches, our model is applied on a full blown 2D image, without any alignment
or registration steps at testing time. We further improve segmentation results
by interpreting the CNN output as potentials of a Markov Random Field (MRF),
whose topology corresponds to a volumetric grid. Alpha-expansion is used to
perform approximate inference imposing spatial volumetric homogeneity to the
CNN priors. We compare the performance of the proposed pipeline with a similar
system using Random Forest-based priors, as well as state-of-art segmentation
algorithms, and show promising results on two different brain MRI datasets.
</dc:description>
 <dc:description>Comment: ISBI 2016: International Symposium on Biomedical Imaging, Apr 2016,
  Prague, Czech Republic</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02130</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02133</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mining Software Quality from Software Reviews: Research Trends and Open
  Issues</dc:title>
 <dc:creator>Atoum, Issa</dc:creator>
 <dc:creator>Otoom, Ahmed</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Software review text fragments have considerably valuable information about
users experience. It includes a huge set of properties including the software
quality. Opinion mining or sentiment analysis is concerned with analyzing
textual user judgments. The application of sentiment analysis on software
reviews can find a quantitative value that represents software quality.
Although many software quality methods are proposed they are considered
difficult to customize and many of them are limited. This article investigates
the application of opinion mining as an approach to extract software quality
properties. We found that the major issues of software reviews mining using
sentiment analysis are due to software lifecycle and the diverse users and
teams.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02133</dc:identifier>
 <dc:identifier>International Journal of Computer Trends and Technology,Vol. 31,
  No. 2, Jan 2016</dc:identifier>
 <dc:identifier>doi:10.14445/22312803/IJCTT-V31P114</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02136</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing Runtime by Recycling Samples</dc:title>
 <dc:creator>Wang, Jialei</dc:creator>
 <dc:creator>Wang, Hai</dc:creator>
 <dc:creator>Srebro, Nathan</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Contrary to the situation with stochastic gradient descent, we argue that
when using stochastic methods with variance reduction, such as SDCA, SAG or
SVRG, as well as their variants, it could be beneficial to reuse previously
used samples instead of fresh samples, even when fresh samples are available.
We demonstrate this empirically for SDCA, SAG and SVRG, studying the optimal
sample size one should use, and also uncover be-havior that suggests running
SDCA for an integer number of epochs could be wasteful.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02136</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02139</identifier>
 <datestamp>2016-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A simple method for estimating the fractal dimension from digital
  images: The compression dimension</dc:title>
 <dc:creator>Chamorro-Posada, P.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Physics - Data Analysis, Statistics and Probability</dc:subject>
 <dc:description>  The fractal structure of real world objects is often analyzed using digital
images. In this context, the compression fractal dimension is put forward. It
provides a simple method for the direct estimation of the dimension of fractals
stored as digital image files. The computational scheme can be implemented
using readily available free software. Its simplicity also makes it very
interesting for introductory elaborations of basic concepts of fractal
geometry, complexity, and information theory. A test of the computational
scheme using limited-quality images of well-defined fractal sets obtained from
the Internet and free software has been performed. Also, a systematic
evaluation of the proposed method using computer generated images of the
Weierstrass cosine function shows an accuracy comparable to those of the
methods most commonly used to estimate the dimension of fractal data sequences
applied to the same test problem.
</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-08-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02139</dc:identifier>
 <dc:identifier>Chaos Solitons Fract 91 (2016) 562-572</dc:identifier>
 <dc:identifier>doi:10.1016/j.chaos.2016.08.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02144</identifier>
 <datestamp>2016-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Access of Mobile Flows to Heterogeneous Networks under Flash
  Crowds</dc:title>
 <dc:creator>Moura, Jose</dc:creator>
 <dc:creator>Edwards, Christopher</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>C.2.1</dc:subject>
 <dc:subject>C.2.3</dc:subject>
 <dc:subject>I.6.4</dc:subject>
 <dc:description>  Future wireless networks need to offer orders of magnitude more capacity to
address the predicted growth in mobile traffic demand. Operators to enhance the
capacity of cellular networks are increasingly using WiFi to offload traffic
from their core networks. This paper deals with the efficient and flexible
management of a heterogeneous networking environment offering wireless access
to multimode terminals. This wireless access is evaluated under disruptive
usage scenarios, such as flash crowds, which can mean unwanted severe
congestion on a specific operator network whilst the remaining available
capacity from other access technologies is not being used. To address these
issues, we propose a scalable network assisted distributed solution that is
administered by centralized policies, and an embedded reputation system, by
which initially selfish operators are encouraged to cooperate under the threat
of churn. Our solution after detecting a congested technology, including within
its wired backhaul, automatically offloads and balances the flows amongst the
access resources from all the existing technologies, following some quality
metrics. Our results show that the smart integration of access networks can
yield an additional wireless quality for mobile flows up to thirty eight
percent beyond that feasible from the best effort standalone operation of each
wireless access technology. It is also evidenced that backhaul constraints are
conveniently reflected on the way the flow access to wireless media is granted.
Finally, we have analyzed the sensitivity of the handover decision algorithm
running in each terminal agent to consecutive flash crowds, as well as its
centralized feature that controls the connection quality offered by a
heterogeneous access infrastructure owned by distinct operators.
</dc:description>
 <dc:description>Comment: Hi, my article has free access until November 19, 2016. Please refer
  to the following journal reference:
  http://authors.elsevier.com/a/1TojL4xsUrkD8U. Cheers,Jose Moura</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-10-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02144</dc:identifier>
 <dc:identifier>Computer Networks, Vol. 107, Part 2, 2016, 163-177</dc:identifier>
 <dc:identifier>doi:10.1016/j.comnet.2016.04.010</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02148</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A replay-attack resistant message authentication scheme using time-based
  keying hash functions and unique message identifiers</dc:title>
 <dc:creator>Gupta, Boudhayan</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Hash-based message authentication codes are an extremely simple yet hugely
effective construction for producing keyed message digests using shared
secrets. HMACs have seen widespread use as ad-hoc digital signatures in many
Internet applications. While messages signed with an HMAC are secure against
sender impersonation and tampering in transit, if used alone they are
susceptible to replay attacks. We propose a construction that extends HMACs to
produce a keyed message digest that has a finite validity period. We then
propose a message signature scheme that uses this time-dependent MAC along with
an unique message identifier to calculate a set of authentication factors using
which a recipient can readily detect and ignore replayed messages, thus
providing perfect resistance against replay attacks. We further analyse
time-based message authentication codes and show that they provide stronger
security guarantees than plain HMACs, even when used independently of the
aforementioned replay attack resistant message signature scheme.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02148</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02151</identifier>
 <datestamp>2016-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters</dc:title>
 <dc:creator>Allen-Zhu, Zeyuan</dc:creator>
 <dc:creator>Yuan, Yang</dc:creator>
 <dc:creator>Sridharan, Karthik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The amount of data available in the world is growing faster than our ability
to deal with it. However, if we take advantage of the internal
\emph{structure}, data may become much smaller for machine learning purposes.
In this paper we focus on one of the fundamental machine learning tasks,
empirical risk minimization (ERM), and provide faster algorithms with the help
from the clustering structure of the data.
  We introduce a simple notion of raw clustering that can be efficiently
computed from the data, and propose two algorithms based on clustering
information. Our accelerated algorithm ClusterACDM is built on a novel Haar
transformation applied to the dual space of the ERM problem, and our
variance-reduction based algorithm ClusterSVRG introduces a new gradient
estimator using clustering. Our algorithms outperform their classical
counterparts ACDM and SVRG respectively.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-11-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02159</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Daleel: Simplifying Cloud Instance Selection Using Machine Learning</dc:title>
 <dc:creator>Samreen, Faiza</dc:creator>
 <dc:creator>Elkhatib, Yehia</dc:creator>
 <dc:creator>Rowe, Matthew</dc:creator>
 <dc:creator>Blair, Gordon S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  Decision making in cloud environments is quite challenging due to the
diversity in service offerings and pricing models, especially considering that
the cloud market is an incredibly fast moving one. In addition, there are no
hard and fast rules, each customer has a specific set of constraints (e.g.
budget) and application requirements (e.g. minimum computational resources).
Machine learning can help address some of the complicated decisions by carrying
out customer-specific analytics to determine the most suitable instance type(s)
and the most opportune time for starting or migrating instances. We employ
machine learning techniques to develop an adaptive deployment policy, providing
an optimal match between the customer demands and the available cloud service
offerings. We provide an experimental study based on extensive set of job
executions over a major public cloud infrastructure.
</dc:description>
 <dc:description>Comment: In the IEEE/IFIP Network Operations and Management Symposium (NOMS),
  April 2016</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02159</dc:identifier>
 <dc:identifier>doi:10.1109/NOMS.2016.7502858</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02164</identifier>
 <datestamp>2016-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Note on Alternating Minimization Algorithm for the Matrix Completion
  Problem</dc:title>
 <dc:creator>Gamarnik, David</dc:creator>
 <dc:creator>Misra, Sidhant</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  We consider the problem of reconstructing a low rank matrix from a subset of
its entries and analyze two variants of the so-called Alternating Minimization
algorithm, which has been proposed in the past. We establish that when the
underlying matrix has rank $r=1$, has positive bounded entries, and the graph
$\mathcal{G}$ underlying the revealed entries has bounded degree and diameter
which is at most logarithmic in the size of the matrix, both algorithms succeed
in reconstructing the matrix approximately in polynomial time starting from an
arbitrary initialization. We further provide simulation results which suggest
that the second algorithm which is based on the message passing type updates,
performs significantly better.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02164</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2576979</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02169</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Probabilistic Extension to the Concurrent Constraint Factor Oracle Model
  for Music Improvisation</dc:title>
 <dc:creator>Toro, Mauricio</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We can program a Real-Time (RT) music improvisation system in C++ without a
formal semantic or we can model it with process calculi such as the
Non-deterministic Timed Concurrent Constraint (ntcc) calculus. &quot;A Concurrent
Constraints Factor Oracle (FO) model for Music Improvisation&quot; (Ccfomi) is an
improvisation model specified on ntcc. Since Ccfomi improvises
non-deterministically, there is no control on choices and therefore little
control over the sequence variation during the improvisation. To avoid this, we
extended Ccfomi using the Probabilistic Non-deterministic Timed Concurrent
Constraint calculus. Our extension to Ccfomi does not change the time and space
complexity of building the FO, thus making our extension compatible with RT.
However, there was not a ntcc interpreter capable of RT to execute Ccfomi. We
developed Ntccrt --a RT capable interpreter for ntcc-- and we executed Ccfomi
on Ntccrt. In the future, we plan to extend Ntccrt to execute our extension to
Ccfomi.
</dc:description>
 <dc:description>Comment: 70 pages</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02169</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02172</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Column Selection in Approximate Kernel Canonical Correlation Analysis</dc:title>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We study the problem of column selection in large-scale kernel canonical
correlation analysis (KCCA) using the Nystr\&quot;om approximation, where one
approximates two positive semi-definite kernel matrices using &quot;landmark&quot; points
from the training set. When building low-rank kernel approximations in KCCA,
previous work mostly samples the landmarks uniformly at random from the
training set. We propose novel strategies for sampling the landmarks
non-uniformly based on a version of statistical leverage scores recently
developed for kernel ridge regression. We study the approximation accuracy of
the proposed non-uniform sampling strategy, develop an incremental algorithm
that explores the path of approximation ranks and facilitates efficient model
selection, and derive the kernel stability of out-of-sample mapping for our
method. Experimental results on both synthetic and real-world datasets
demonstrate the promise of our method.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02172</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02174</identifier>
 <datestamp>2016-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Participation Incentives in Randomized Social Choice</dc:title>
 <dc:creator>Aziz, Haris</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>91A12, 68Q15</dc:subject>
 <dc:subject>F.2</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  When aggregating preferences of agents via voting, two desirable goals are to
identify outcomes that are Pareto optimal and to incentivize agents to
participate in the voting process. We consider participation notions as
formalized by Brandl, Brandt, and Hofbauer (2015) and study how far efficiency
and participation are achievable by randomized social choice functions in
particular when agents' preferences are downward lexicographic (DL) or satisfy
stochastic dominance (SD). Our results include the followings ones: we prove
formal relations between the participation notions with respect to SD and DL
and we show that the maximal recursive rule satisfies very strong participation
with respect to both SD and DL.
</dc:description>
 <dc:description>Comment: corrected one proposition from previous version</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-11-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02174</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02178</identifier>
 <datestamp>2017-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative Hierarchical Caching in 5G Cloud Radio Access Networks
  (C-RANs)</dc:title>
 <dc:creator>Tran, Tuyen X.</dc:creator>
 <dc:creator>Hajisami, Abolfazl</dc:creator>
 <dc:creator>Pompili, Dario</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Over the last few years, Cloud Radio Access Network (C-RAN) has arisen as a
transformative architecture for 5G cellular networks that brings the
flexibility and agility of cloud computing to wireless communications. At the
same time, content caching in wireless networks has become an essential
solution to lower the content-access latency and backhaul traffic loading,
which translate into user Quality of Experience (QoE) improvement and network
cost reduction. In this article, a novel Cooperative Hierarchical Caching (CHC)
framework in C-RAN is introduced where contents are jointly cached at the
BaseBand Unit (BBU) and at the Radio Remote Heads (RRHs). Unlike in traditional
approaches, the cache at the BBU, cloud cache, presents a new layer in the
cache hierarchy, bridging the latency/capacity gap between the traditional
edge-based and core-based caching schemes. Trace-driven simulations reveal that
CHC yields up to 80% improvement in cache hit ratio, 21% decrease in average
content-access latency, and 20% reduction in backhaul traffic load compared to
the edge-only caching scheme with the same total cache capacity. Before closing
the article, several challenges and promising opportunities for deploying
content caching in C-RAN are highlighted towards a content-centric mobile
wireless network.
</dc:description>
 <dc:description>Comment: to appear on IEEE Network, July 2017</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2017-04-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02178</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02181</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Active Information Acquisition</dc:title>
 <dc:creator>He, He</dc:creator>
 <dc:creator>Mineiro, Paul</dc:creator>
 <dc:creator>Karampatziakis, Nikos</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a general framework for sequential and dynamic acquisition of
useful information in order to solve a particular task. While our goal could in
principle be tackled by general reinforcement learning, our particular setting
is constrained enough to allow more efficient algorithms. In this paper, we
work under the Learning to Search framework and show how to formulate the goal
of finding a dynamic information acquisition policy in that framework. We apply
our formulation on two tasks, sentiment analysis and image recognition, and
show that the learned policies exhibit good statistical performance. As an
emergent byproduct, the learned policies show a tendency to focus on the most
prominent parts of each instance and give harder instances more attention
without explicitly being trained to do so.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02181</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02191</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Convex Relaxation Regression: Black-Box Optimization of Smooth Functions
  by Learning Their Convex Envelopes</dc:title>
 <dc:creator>Azar, Mohammad Gheshlaghi</dc:creator>
 <dc:creator>Dyer, Eva</dc:creator>
 <dc:creator>Kording, Konrad</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Finding efficient and provable methods to solve non-convex optimization
problems is an outstanding challenge in machine learning and optimization
theory. A popular approach used to tackle non-convex problems is to use convex
relaxation techniques to find a convex surrogate for the problem.
Unfortunately, convex relaxations typically must be found on a
problem-by-problem basis. Thus, providing a general-purpose strategy to
estimate a convex relaxation would have a wide reaching impact. Here, we
introduce Convex Relaxation Regression (CoRR), an approach for learning convex
relaxations for a class of smooth functions. The main idea behind our approach
is to estimate the convex envelope of a function $f$ by evaluating $f$ at a set
of $T$ random points and then fitting a convex function to these function
evaluations. We prove that with probability greater than $1-\delta$, the
solution of our algorithm converges to the global optimizer of $f$ with error
$\mathcal{O} \Big( \big(\frac{\log(1/\delta) }{T} \big)^{\alpha} \Big)$ for
some $\alpha&gt; 0$. Our approach enables the use of convex optimization tools to
solve a class of non-convex optimization problems.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-03-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02191</dc:identifier>
 <dc:identifier>Proc. of the Conference on Uncertainty in Artificial Intelligence,
  pg. 22-31, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02196</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits</dc:title>
 <dc:creator>Rakhlin, Alexander</dc:creator>
 <dc:creator>Sridharan, Karthik</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We present efficient algorithms for the problem of contextual bandits with
i.i.d. covariates, an arbitrary sequence of rewards, and an arbitrary class of
policies. Our algorithm BISTRO requires d calls to the empirical risk
minimization (ERM) oracle per round, where d is the number of actions. The
method uses unlabeled data to make the problem computationally simple. When the
ERM problem itself is computationally hard, we extend the approach by employing
multiplicative approximation algorithms for the ERM. The integrality gap of the
relaxation only enters in the regret bound rather than the benchmark. Finally,
we show that the adversarial version of the contextual bandit problem is
learnable (and efficient) whenever the full-information supervised online
learning problem has a non-trivial regret guarantee (and efficient).
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02196</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02201</identifier>
 <datestamp>2017-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compress and Estimate in Multiterminal Source Coding</dc:title>
 <dc:creator>Kipnis, Alon</dc:creator>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:creator>Goldsmith, Andrea J.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We consider a multiterminal remote source coding problem in which a source
sequence is estimated from the output of multiple source encoders, each having
access only to a noisy observation of the source realization. Each remote
encoder compresses its noisy observation sequence so as to minimize a local
distortion measure which depends only on the distribution of its observed
sequence, and is otherwise independent from the distribution of the underlying
source. The latter is estimated at a central location from the output of each
of the remote encoders. This source compression and estimation scenario leads
to an achievable scheme for the remote multiterminal source coding problem
which we term the &quot;compress-and-estimate&quot; (CE) scheme. For the case of a source
with independently and identically distributed (i.i.d) elements observed
through multiple memoryless channels, we derive a single-letter expression for
the distortion in the CE scheme, which we refer to as the CE distortion-rate
function (CE-DRF). We prove that the CE-DRF can be achieved by estimating the
source realization from the output of any set of encoders, as long as each
encoder attains its local rate-distortion function. We prove in addition a
converse result saying that, for large enough blocklength, the distortion in
estimating a finite sub-block of the source from the output of such encoders,
averaged over all sub-blocks, does not exceed the CE-DRF. Finally, we derive
closed-form expressions for the CE-DRF in the case of a Gaussian source
observed through multiple AWGN channels under quadratic distortion, and for the
case of a binary source observed through multiple biflip channels under Hamming
distortion.
</dc:description>
 <dc:description>Comment: Submitted to ITT for review</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2017-05-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02201</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02202</identifier>
 <datestamp>2017-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Second Order Online Learning by Sketching</dc:title>
 <dc:creator>Luo, Haipeng</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Cesa-Bianchi, Nicolo</dc:creator>
 <dc:creator>Langford, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose Sketched Online Newton (SON), an online second order learning
algorithm that enjoys substantially improved regret guarantees for
ill-conditioned data. SON is an enhanced version of the Online Newton Step,
which, via sketching techniques enjoys a running time linear in the dimension
and sketch size. We further develop sparse forms of the sketching methods (such
as Oja's rule), making the computation linear in the sparsity of features.
Together, the algorithm eliminates all computational obstacles in previous
second order online learning approaches.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2017-10-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02202</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02203</identifier>
 <datestamp>2016-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GDoF of the MISO BC: Bridging the Gap between Finite Precision and
  Perfect CSIT</dc:title>
 <dc:creator>Davoodi, Arash Gholami</dc:creator>
 <dc:creator>Yuan, Bofeng</dc:creator>
 <dc:creator>Jafar, Syed A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For the $K=2$ user MISO BC, i.e., the wireless broadcast channel where a
transmitter equipped with $K=2$ antennas sends independent messages to $K=2$
receivers each of which is equipped with a single antenna, the sum generalized
degrees of freedom (GDoF) are characterized for arbitrary channel strength and
channel uncertainty levels for each of the channel coefficients. The result is
extended to $K&gt;2$ users under additional restrictions which include the
assumption of symmetry.
</dc:description>
 <dc:description>Comment: 19 pages, 2 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-08-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02205</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Capacity of the Dirty Paper Channel with Fast Fading and Discrete
  Channel States</dc:title>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:creator>Shitz, Shlomo Shamai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The &quot;writing dirty paper&quot; capacity result crucially dependents on the perfect
channel knowledge at the transmitter as the presence of even a small
uncertainty in the channel realization gravely hampers the ability of the
transmitter to pre-code its transmission against the channel state. This is
particularly disappointing as it implies that interference pre-coding in
practical systems is effective only when the channel estimates at the users
have very high precision, a condition which is generally unattainable in
wireless environments. In this paper we show that substantial improvements are
possible when the state sequence is drawn from a discrete distribution, such as
a constrained input constellation, for which state decoding can be
approximately optimal. We consider the &quot;writing on dirty paper&quot; channel in
which the state sequence is multiplied by a fast fading process and derive
conditions on the fading and state distributions for which state decoding
closely approaches capacity. These conditions intuitively relate to the ability
of the receiver to correctly identify both the input and the state realization
despite of the uncertainty introduced by fading.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02205</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02206</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Carbon Copy onto Dirty Paper Channel with Statistically Equivalent
  States</dc:title>
 <dc:creator>Rini, Stefano</dc:creator>
 <dc:creator>Shitz, Shlomo Shamai</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Costa's &quot;writing on dirty paper&quot; capacity result establishes that full state
pre-cancellation can be attained in Gelfand-Pinsker channel with additive state
and additive Gaussian noise. The &quot;carbon copy onto dirty paper&quot; channel is the
extension of Costa's model to the compound setting: M receivers each observe
the sum of the channel input, Gaussian noise and one of M Gaussian state
sequences and attempt to decode the same common message. The state sequences
are all non-causally known at the transmitter which attempts to simultaneously
pre-code its transmission against the channel state affecting each output. In
this correspondence we derive the capacity to within 2.25 bits-per-channel-use
of the carbon copying onto dirty paper channel in which the state sequences are
statistically equivalent, having the same variance and the same pairwise
correlation. For this channel capacity is approached by letting the channel
input be the superposition of two codewords: a base codeword, simultaneously
decoded at each user, and a top codeword which is pre-coded against the state
realization at each user for a portion 1/M of the time. The outer bound relies
on a recursive bounding in which incremental side information is provided at
each receiver. This result represents a significant first step toward
determining the capacity of the most general &quot;carbon copy onto dirty paper&quot;
channel in which state sequences appearing in the different channel outputs
have any jointly Gaussian distribution.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02210</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification Accuracy as a Proxy for Two Sample Testing</dc:title>
 <dc:creator>Ramdas, Aaditya</dc:creator>
 <dc:creator>Singh, Aarti</dc:creator>
 <dc:creator>Wasserman, Larry</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  When data analysts train a classifier and check if its accuracy is
significantly different from random guessing, they are implicitly and
indirectly performing a hypothesis test (two sample testing) and it is of
importance to ask whether this indirect method for testing is statistically
optimal or not. Given that hypothesis tests attempt to maximize statistical
power subject to a bound on the allowable false positive rate, while prediction
attempts to minimize statistical risk on future predictions on unseen data, we
wish to study whether a predictive approach for an ultimate aim of testing is
prudent. We formalize this problem by considering the two-sample mean-testing
setting where one must determine if the means of two Gaussians (with known and
equal covariance) are the same or not, but the analyst indirectly does so by
checking whether the accuracy achieved by Fisher's LDA classifier is
significantly different from chance or not. Unexpectedly, we find that the
asymptotic power of LDA's sample-splitting classification accuracy is actually
minimax rate-optimal in terms of problem-dependent parameters. Since prediction
is commonly thought to be harder than testing, it might come as a surprise to
some that solving a harder problem does not create a information-theoretic
bottleneck for the easier one. On the flip side, even though the power is
rate-optimal, our derivation suggests that it may be worse by a small constant
factor; hence practitioners must be wary of using (admittedly flexible)
prediction methods on disguised testing problems.
</dc:description>
 <dc:description>Comment: 15 pages, 2 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02210</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02211</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fuzzy Maximum Satisfiability</dc:title>
 <dc:creator>Halaby, Mohamed El</dc:creator>
 <dc:creator>Abdalla, Areeg</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  In this paper, we extend the Maximum Satisfiability (MaxSAT) problem to
{\L}ukasiewicz logic. The MaxSAT problem for a set of formulae {\Phi} is the
problem of finding an assignment to the variables in {\Phi} that satisfies the
maximum number of formulae. Three possible solutions (encodings) are proposed
to the new problem: (1) Disjunctive Linear Relations (DLRs), (2) Mixed Integer
Linear Programming (MILP) and (3) Weighted Constraint Satisfaction Problem
(WCSP). Like its Boolean counterpart, the extended fuzzy MaxSAT will have
numerous applications in optimization problems that involve vagueness.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02211</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02215</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Swivel: Improving Embeddings by Noticing What's Missing</dc:title>
 <dc:creator>Shazeer, Noam</dc:creator>
 <dc:creator>Doherty, Ryan</dc:creator>
 <dc:creator>Evans, Colin</dc:creator>
 <dc:creator>Waterson, Chris</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We present Submatrix-wise Vector Embedding Learner (Swivel), a method for
generating low-dimensional feature embeddings from a feature co-occurrence
matrix. Swivel performs approximate factorization of the point-wise mutual
information matrix via stochastic gradient descent. It uses a piecewise loss
with special handling for unobserved co-occurrences, and thus makes use of all
the information in the matrix. While this requires computation proportional to
the size of the entire matrix, we make use of vectorized multiplication to
process thousands of rows and columns at once to compute millions of predicted
values. Furthermore, we partition the matrix into shards in order to
parallelize the computation across many nodes. This approach results in more
accurate embeddings than can be achieved with methods that consider only
observed co-occurrences, and can scale to much larger corpora than can be
handled with sampling methods.
</dc:description>
 <dc:description>Comment: 9 pages, 4 figures</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02215</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02216</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Smoothing Brascamp-Lieb Inequalities and Strong Converses for Common
  Randomness Generation</dc:title>
 <dc:creator>Liu, Jingbo</dc:creator>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:creator>Cuff, Paul</dc:creator>
 <dc:creator>Verdu, Sergio</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the infimum of the best constant in a functional inequality, the
Brascamp-Lieb-like inequality, over auxiliary measures within a neighborhood of
a product distribution. In the finite alphabet and the Gaussian cases, such an
infimum converges to the best constant in a mutual information inequality.
Implications for strong converse properties of two common randomness (CR)
generation problems are discussed. In particular, we prove the strong converse
property of the rate region for the omniscient helper CR generation problem in
the discrete and the Gaussian cases. The latter case is perhaps the first
instance of a strong converse for a continuous source when the rate region
involves auxiliary random variables.
</dc:description>
 <dc:description>Comment: 7 pages; first 5 pages submitted to ISIT 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02216</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02218</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strongly-Typed Recurrent Neural Networks</dc:title>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:creator>Ghifary, Muhammad</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recurrent neural networks are increasing popular models for sequential
learning. Unfortunately, although the most effective RNN architectures are
perhaps excessively complicated, extensive searches have not found simpler
alternatives. This paper imports ideas from physics and functional programming
into RNN design to provide guiding principles. From physics, we introduce type
constraints, analogous to the constraints that forbids adding meters to
seconds. From functional programming, we require that strongly-typed
architectures factorize into stateless learnware and state-dependent firmware,
reducing the impact of side-effects. The features learned by strongly-typed
nets have a simple semantic interpretation via dynamic average-pooling on
one-dimensional convolutions. We also show that strongly-typed gradients are
better behaved than in classical architectures, and characterize the
representational power of strongly-typed nets. Finally, experiments show that,
despite being more constrained, strongly-typed architectures achieve lower
training and comparable generalization error to classical architectures.
</dc:description>
 <dc:description>Comment: 10 pages, final version, ICML 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02220</identifier>
 <datestamp>2016-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Dropout for Shallow and Deep Learning</dc:title>
 <dc:creator>Li, Zhe</dc:creator>
 <dc:creator>Gong, Boqing</dc:creator>
 <dc:creator>Yang, Tianbao</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Dropout has been witnessed with great success in training deep neural
networks by independently zeroing out the outputs of neurons at random. It has
also received a surge of interest for shallow learning, e.g., logistic
regression. However, the independent sampling for dropout could be suboptimal
for the sake of convergence. In this paper, we propose to use multinomial
sampling for dropout, i.e., sampling features or neurons according to a
multinomial distribution with different probabilities for different
features/neurons. To exhibit the optimal dropout probabilities, we analyze the
shallow learning with multinomial dropout and establish the risk bound for
stochastic optimization. By minimizing a sampling dependent factor in the risk
bound, we obtain a distribution-dependent dropout with sampling probabilities
dependent on the second order statistics of the data distribution. To tackle
the issue of evolving distribution of neurons in deep learning, we propose an
efficient adaptive dropout (named \textbf{evolutional dropout}) that computes
the sampling probabilities on-the-fly from a mini-batch of examples. Empirical
studies on several benchmark datasets demonstrate that the proposed dropouts
achieve not only much faster convergence and but also a smaller testing error
than the standard dropout. For example, on the CIFAR-100 data, the evolutional
dropout achieves relative improvements over 10\% on the prediction performance
and over 50\% on the convergence speed compared to the standard dropout.
</dc:description>
 <dc:description>Comment: In NIPS 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-12-04</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02235</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Constructions of q-ary entanglement-assisted quantum MDS codes with
  minimum distance greater than q + 1</dc:title>
 <dc:creator>Fan, Jihao</dc:creator>
 <dc:creator>Chen, Hanwu</dc:creator>
 <dc:creator>Xu, Juan</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The entanglement-assisted stabilizer formalism provides a useful framework
for constructing quantum error-correcting codes (QECC), which can transform
arbitrary classical linear codes into entanglement-assisted quantum error
correcting codes (EAQECCs) by using pre-shared entanglement between the sender
and the receiver. In this paper, we construct five classes of
entanglement-assisted quantum MDS (EAQMDS) codes based on classical MDS codes
by exploiting one or more pre-shared maximally entangled states. We show that
these EAQMDS codes have much larger minimum distance than the standard quantum
MDS (QMDS) codes of the same length, and three classes of these EAQMDS codes
consume only one pair of maximally entangled states.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02235</dc:identifier>
 <dc:identifier>Quantum Information and Computation, vol. 16, no. 5&amp;6, pp.
  0423-0434, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02237</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reducing training requirements through evolutionary based dimension
  reduction and subject transfer</dc:title>
 <dc:creator>Atyabi, Adham</dc:creator>
 <dc:creator>Luerssena, Martin</dc:creator>
 <dc:creator>Fitzgibbon, Sean P.</dc:creator>
 <dc:creator>Lewis, Trent</dc:creator>
 <dc:creator>Powersa, David M. W.</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Training Brain Computer Interface (BCI) systems to understand the intention
of a subject through Electroencephalogram (EEG) data currently requires
multiple training sessions with a subject in order to develop the necessary
expertise to distinguish signals for different tasks. Conventionally the task
of training the subject is done by introducing a training and calibration stage
during which some feedback is presented to the subject. This training session
can take several hours which is not appropriate for on-line EEG-based BCI
systems. An alternative approach is to use previous recording sessions of the
same person or some other subjects that performed the same tasks (subject
transfer) for training the classifiers. The main aim of this study is to
generate a methodology that allows the use of data from other subjects while
reducing the dimensions of the data. The study investigates several
possibilities for reducing the necessary training and calibration period in
subjects and the classifiers and addresses the impact of i) evolutionary
subject transfer and ii) adapting previously trained methods (retraining) using
other subjects data. Our results suggest reduction to 40% of target subject
data is sufficient for training the classifier. Our results also indicate the
superiority of the approaches that incorporated evolutionary subject transfer
and highlights the feasibility of adapting a system trained on other subjects.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02237</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02238</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Who Benefits from the &quot;Sharing&quot; Economy of Airbnb?</dc:title>
 <dc:creator>Quattrone, Giovanni</dc:creator>
 <dc:creator>Proserpio, Davide</dc:creator>
 <dc:creator>Quercia, Daniele</dc:creator>
 <dc:creator>Capra, Licia</dc:creator>
 <dc:creator>Musolesi, Mirco</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Sharing economy platforms have become extremely popular in the last few
years, and they have changed the way in which we commute, travel, and borrow
among many other activities. Despite their popularity among consumers, such
companies are poorly regulated. For example, Airbnb, one of the most successful
examples of sharing economy platform, is often criticized by regulators and
policy makers. While, in theory, municipalities should regulate the emergence
of Airbnb through evidence-based policy making, in practice, they engage in a
false dichotomy: some municipalities allow the business without imposing any
regulation, while others ban it altogether. That is because there is no
evidence upon which to draft policies. Here we propose to gather evidence from
the Web. After crawling Airbnb data for the entire city of London, we find out
where and when Airbnb listings are offered and, by matching such listing
information with census and hotel data, we determine the socio-economic
conditions of the areas that actually benefit from the hospitality platform.
The reality is more nuanced than one would expect, and it has changed over the
years. Airbnb demand and offering have changed over time, and traditional
regulations have not been able to respond to those changes. That is why,
finally, we rely on our data analysis to envision regulations that are
responsive to real-time demands, contributing to the emerging idea of
&quot;algorithmic regulation&quot;.
</dc:description>
 <dc:description>Comment: In Proceedings of the 26th International ACM Conference on World Wide
  Web (WWW), 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02238</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02241</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Mean Queue Size and Its Rate of Change: Queue Management with
  Random Dropping</dc:title>
 <dc:creator>Karmeshu</dc:creator>
 <dc:creator>Patel, Sanjeev</dc:creator>
 <dc:creator>Bhatnagar, Shalabh</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  The Random early detection (RED) active queue management (AQM) scheme uses
the average queue size to calculate the dropping probability in terms of
minimum and maximum thresholds. The effect of heavy load enhances the frequency
of crossing the maximum threshold value resulting in frequent dropping of the
packets. An adaptive queue management with random dropping (AQMRD) algorithm is
proposed which incorporates information not just about the average queue size
but also the rate of change of the same. Introducing an adaptively changing
threshold level that falls in between lower and upper thresholds, our algorithm
demonstrates that these additional features significantly improve the system
performance in terms of throughput, average queue size, utilization and queuing
delay in relation to the existing AQM algorithms.
</dc:description>
 <dc:description>Comment: 17 pages, 19 figures, and submitted to Telecommunication Systems,
  Springer</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02241</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02244</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Multipole Method as a Matrix-Free Hierarchical Low-Rank
  Approximation</dc:title>
 <dc:creator>Yokota, Rio</dc:creator>
 <dc:creator>Ibeid, Huda</dc:creator>
 <dc:creator>Keyes, David</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>65Y20, 68Q25</dc:subject>
 <dc:subject>D.1.3</dc:subject>
 <dc:subject>G.1.0</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>G.1.3</dc:subject>
 <dc:subject>G.1.4</dc:subject>
 <dc:subject>G.1.8</dc:subject>
 <dc:subject>G.1.9</dc:subject>
 <dc:subject>G.4</dc:subject>
 <dc:description>  There has been a large increase in the amount of work on hierarchical
low-rank approximation methods, where the interest is shared by multiple
communities that previously did not intersect. This objective of this article
is two-fold; to provide a thorough review of the recent advancements in this
field from both analytical and algebraic perspectives, and to present a
comparative benchmark of two highly optimized implementations of contrasting
methods for some simple yet representative test cases. We categorize the recent
advances in this field from the perspective of compute-memory tradeoff, which
has not been considered in much detail in this area. Benchmark tests reveal
that there is a large difference in the memory consumption and performance
between the different methods.
</dc:description>
 <dc:description>Comment: 19 pages, 6 figures</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02249</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Processing In-Memory Realization Using QCA: Proposal and
  Implementation</dc:title>
 <dc:creator>Chougule, P. P.</dc:creator>
 <dc:creator>Sen, B.</dc:creator>
 <dc:creator>Mukherjee, R.</dc:creator>
 <dc:creator>Karade, V. C.</dc:creator>
 <dc:creator>Patil, P. S.</dc:creator>
 <dc:creator>Dongale, T. D.</dc:creator>
 <dc:creator>Kamat, R. K.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>81P45</dc:subject>
 <dc:description>  Processing in Memory (PIM) is a computing paradigm that promises enormous
gain in processing speed by eradicating latencies in the typical von Neumann
architecture. It has gained popularity owing to its throughput by embedding
storage and computation of data in a single unit. We portray implementation of
Akers array architecture endowed with PIM computation using Quantum-dot
Cellular Automata (QCA). We present the proof of concept of PIM with its
realization in the QCA designer paradigm. We illustrate implementation of Ex-OR
gate with the help of QCA based Akers Array and put forth many interesting
potential possibilities.
</dc:description>
 <dc:description>Comment: 4 pages, 3 figures, 3 tables, 1 equation</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02249</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02250</identifier>
 <datestamp>2016-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Limits of Coexisting Coverage and Capacity in Multi-RAT
  Heterogeneous Networks</dc:title>
 <dc:creator>Liu, Chun-Hung</dc:creator>
 <dc:creator>Tsai, Hong-Cheng</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper devises a general modeling and analyzing framework for a
heterogeneous wireless network (HetNet) in which several wireless subnetworks
coexist and use multiple radio access technologies (multi-RATs). The coexisting
coverage and network capacity in such a multi-RAT HetNet are hardly
investigated in prior works. To characterize the coexisting interactions in a
multi-RAT HetNet, in this paper we consider a HetNet consisting of K-tier APs
and two different RATs, RAT-L and RAT-U, are adopted in the HetNet. RAT-L is
adopted by the access points (APs) in the first K-1 tiers and APs in the Kth
tier only use RAT-U. Both noncrossing-RAT and crossing-RAT user association
scenarios are considered. In each scenario, the void probability and channel
access probability of the APs in each tier are first found and then the tight
lower bounds and their lowest limits on the proposed coexisting coverage and
network capacity are derived. We show that multi-RAT networks in general can
achieve higher link coverage and capacity by using opportunistic CSMA/CA that
avoids/alleviates severe interfering between all coexisting APs. Also,
crossing-RAT user association is shown to achieve much higher coexisting
coverage and network capacity than noncrossing-RAT user association. Finally,
numerical simulations for the LTE-U and WiFi networks coexisting in the HetNet
validate our findings.
</dc:description>
 <dc:description>Comment: 31 pages, 6 figures, journal</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02250</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02255</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Cross-Modal Hashing</dc:title>
 <dc:creator>Jiang, Qing-Yuan</dc:creator>
 <dc:creator>Li, Wu-Jun</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Due to its low storage cost and fast query speed, cross-modal hashing (CMH)
has been widely used for similarity search in multimedia retrieval
applications. However, almost all existing CMH methods are based on
hand-crafted features which might not be optimally compatible with the
hash-code learning procedure. As a result, existing CMH methods with
handcrafted features may not achieve satisfactory performance. In this paper,
we propose a novel cross-modal hashing method, called deep crossmodal hashing
(DCMH), by integrating feature learning and hash-code learning into the same
framework. DCMH is an end-to-end learning framework with deep neural networks,
one for each modality, to perform feature learning from scratch. Experiments on
two real datasets with text-image modalities show that DCMH can outperform
other baselines to achieve the state-of-the-art performance in cross-modal
retrieval applications.
</dc:description>
 <dc:description>Comment: 12 pages</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02255</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02256</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Tractable Fully Bayesian Method for the Stochastic Block Model</dc:title>
 <dc:creator>Hayashi, Kohei</dc:creator>
 <dc:creator>Konishi, Takuya</dc:creator>
 <dc:creator>Kawamoto, Tatsuro</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The stochastic block model (SBM) is a generative model revealing macroscopic
structures in graphs. Bayesian methods are used for (i) cluster assignment
inference and (ii) model selection for the number of clusters. In this paper,
we study the behavior of Bayesian inference in the SBM in the large sample
limit. Combining variational approximation and Laplace's method, a consistent
criterion of the fully marginalized log-likelihood is established. Based on
that, we derive a tractable algorithm that solves tasks (i) and (ii)
concurrently, obviating the need for an outer loop to check all model
candidates. Our empirical and theoretical results demonstrate that our method
is scalable in computation, accurate in approximation, and concise in model
selection.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02261</identifier>
 <datestamp>2016-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>End-to-End Goal-Driven Web Navigation</dc:title>
 <dc:creator>Nogueira, Rodrigo</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We propose a goal-driven web navigation as a benchmark task for evaluating an
agent with abilities to understand natural language and plan on partially
observed environments. In this challenging task, an agent navigates through a
website, which is represented as a graph consisting of web pages as nodes and
hyperlinks as directed edges, to find a web page in which a query appears. The
agent is required to have sophisticated high-level reasoning based on natural
languages and efficient sequential decision-making capability to succeed. We
release a software tool, called WebNav, that automatically transforms a website
into this goal-driven web navigation task, and as an example, we make WikiNav,
a dataset constructed from the English Wikipedia. We extensively evaluate
different variants of neural net based artificial agents on WikiNav and observe
that the proposed goal-driven web navigation well reflects the advances in
models, making it a suitable benchmark for evaluating future progress.
Furthermore, we extend the WikiNav with question-answer pairs from Jeopardy!
and test the proposed agent based on recurrent neural networks against strong
inverted index based search engines. The artificial agents trained on WikiNav
outperforms the engined based approaches, demonstrating the capability of the
proposed goal-driven navigation as a good proxy for measuring the progress in
real-world tasks such as focused crawling and question-answering.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-05-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02261</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02262</identifier>
 <datestamp>2016-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Recovery guarantee of weighted low-rank approximation via alternating
  minimization</dc:title>
 <dc:creator>Li, Yuanzhi</dc:creator>
 <dc:creator>Liang, Yingyu</dc:creator>
 <dc:creator>Risteski, Andrej</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Many applications require recovering a ground truth low-rank matrix from
noisy observations of the entries, which in practice is typically formulated as
a weighted low-rank approximation problem and solved by non-convex optimization
heuristics such as alternating minimization. In this paper, we provide provable
recovery guarantee of weighted low-rank via a simple alternating minimization
algorithm. In particular, for a natural class of matrices and weights and
without any assumption on the noise, we bound the spectral norm of the
difference between the recovered matrix and the ground truth, by the spectral
norm of the weighted noise plus an additive error that decreases exponentially
with the number of rounds of alternating minimization, from either
initialization by SVD or, more importantly, random initialization. These
provide the first theoretical results for weighted low-rank via alternating
minimization with non-binary deterministic weights, significantly generalizing
those for matrix completion, the special case with binary weights, since our
assumptions are similar or weaker than those made in existing works.
Furthermore, this is achieved by a very simple algorithm that improves the
vanilla alternating minimization with a simple clipping step.
  The key technical challenge is that under non-binary deterministic weights,
na\&quot;ive alternating steps will destroy the incoherence and spectral properties
of the intermediate solutions, which are needed for making progress towards the
ground truth. We show that the properties only need to hold in an average sense
and can be achieved by the clipping step.
  We further provide an alternating algorithm that uses a whitening step that
keeps the properties via SDP and Rademacher rounding and thus requires weaker
assumptions. This technique can potentially be applied in some other
applications and is of independent interest.
</dc:description>
 <dc:description>Comment: 40 pages. Updated with the ICML 2016 camera ready version, together
  with an additional algorithm which needs less assumptions in Appendix C</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-12-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02262</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02263</identifier>
 <datestamp>2016-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DOLPHIn - Dictionary Learning for Phase Retrieval</dc:title>
 <dc:creator>Tillmann, Andreas M.</dc:creator>
 <dc:creator>Eldar, Yonina C.</dc:creator>
 <dc:creator>Mairal, Julien</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose a new algorithm to learn a dictionary for reconstructing and
sparsely encoding signals from measurements without phase. Specifically, we
consider the task of estimating a two-dimensional image from squared-magnitude
measurements of a complex-valued linear transformation of the original image.
Several recent phase retrieval algorithms exploit underlying sparsity of the
unknown signal in order to improve recovery performance. In this work, we
consider such a sparse signal prior in the context of phase retrieval, when the
sparsifying dictionary is not known in advance. Our algorithm jointly
reconstructs the unknown signal - possibly corrupted by noise - and learns a
dictionary such that each patch of the estimated image can be sparsely
represented. Numerical experiments demonstrate that our approach can obtain
significantly better reconstructions for phase retrieval problems with noise
than methods that cannot exploit such &quot;hidden&quot; sparsity. Moreover, on the
theoretical side, we provide a convergence result for our method.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-08-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02263</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2607180</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02265</identifier>
 <datestamp>2016-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving the Dispatchability of Distribution Feeders through Prosumers
  Data Driven Forecasting and Model Predictive Control of Electrochemical
  Storage</dc:title>
 <dc:creator>Sossan, Fabrizio</dc:creator>
 <dc:creator>Namor, Emil</dc:creator>
 <dc:creator>Cherkaoui, Rachid</dc:creator>
 <dc:creator>Paolone, Mario</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We propose and experimentally validate a control strategy to dispatch the
operation of a distribution feeder interfacing heterogeneous prosumers by using
a grid-connected battery energy storage system (BESS) as a controllable element
coupled with a minimally invasive monitoring infrastructure. It consists in a
two-stage procedure: day-ahead dispatch planning, where the feeder 5-minute
average power consumption trajectory for the next day of operation (called
\emph{dispatch plan}) is determined, and intra-day/real-time operation, where
the mismatch with respect to the \emph{dispatch plan} is corrected by applying
receding horizon model predictive control (MPC) to decide the BESS
charging/discharging profile while accounting for operational constraints. The
consumption forecast necessary to compute the \emph{dispatch plan} and the
battery model for the MPC algorithm are built by applying adaptive data driven
methodologies. The discussed control framework currently operates on a daily
basis to dispatch the operation of a 20~kV feeder of the EPFL university campus
using a 750~kW/500~kWh lithium titanate BESS.
</dc:description>
 <dc:description>Comment: Submitted for publication, 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-08-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02265</dc:identifier>
 <dc:identifier>IEEE Transactions on Sustainable Energy, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TSTE.2016.2600103</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02268</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure and Dependable Virtual Network Embedding</dc:title>
 <dc:creator>Ferrolho, Lu&#xed;s</dc:creator>
 <dc:creator>Alaluna, Max</dc:creator>
 <dc:creator>Neves, Nuno</dc:creator>
 <dc:creator>Ramos, Fernando M. V.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  One of the fundamental problems in network virtualization is Virtual Network
Embedding (VNE). The VNE problem deals with finding an effective mapping of the
virtual nodes &amp; links onto the substrate network. The recent advances in
network virtualization gave cloud operators the ability to extend their cloud
computing offerings with virtual networks. This trend, jointly with the
increasing evidence of incidents in cloud facilities demonstrate that security
and dependability is becoming a critical factor that should be considered by
VNE algorithms. In this abstract we propose a VNE solution that considers
security and dependability as first class citizens. The resiliency properties
of our solution are enhanced by assuming a multiple cloud provider model.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02268</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02282</identifier>
 <datestamp>2016-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ladder Variational Autoencoders</dc:title>
 <dc:creator>S&#xf8;nderby, Casper Kaae</dc:creator>
 <dc:creator>Raiko, Tapani</dc:creator>
 <dc:creator>Maal&#xf8;e, Lars</dc:creator>
 <dc:creator>S&#xf8;nderby, S&#xf8;ren Kaae</dc:creator>
 <dc:creator>Winther, Ole</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Variational Autoencoders are powerful models for unsupervised learning.
However deep models with several layers of dependent stochastic variables are
difficult to train which limits the improvements obtained using these highly
expressive models. We propose a new inference model, the Ladder Variational
Autoencoder, that recursively corrects the generative distribution by a data
dependent approximate likelihood in a process resembling the recently proposed
Ladder Network. We show that this model provides state of the art predictive
log-likelihood and tighter log-likelihood lower bound compared to the purely
bottom-up inference in layered Variational Autoencoders and other generative
models. We provide a detailed analysis of the learned hierarchical latent
representation and show that our new inference model is qualitatively different
and utilizes a deeper more distributed hierarchy of latent variables. Finally,
we observe that batch normalization and deterministic warm-up (gradually
turning on the KL-term) are crucial for training variational models with many
stochastic layers.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02282</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02283</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Importance Sampling for Minibatches</dc:title>
 <dc:creator>Csiba, Dominik</dc:creator>
 <dc:creator>Richt&#xe1;rik, Peter</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Minibatching is a very well studied and highly popular technique in
supervised learning, used by practitioners due to its ability to accelerate
training through better utilization of parallel processing power and reduction
of stochastic variance. Another popular technique is importance sampling -- a
strategy for preferential sampling of more important examples also capable of
accelerating the training process. However, despite considerable effort by the
community in these areas, and due to the inherent technical difficulty of the
problem, there is no existing work combining the power of importance sampling
with the strength of minibatching. In this paper we propose the first {\em
importance sampling for minibatches} and give simple and rigorous complexity
analysis of its performance. We illustrate on synthetic problems that for
training data of certain properties, our sampling can lead to several orders of
magnitude improvement in training time. We then test the new sampling on
several popular datasets, and show that the improvement can reach an order of
magnitude.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02285</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Deep Learning Approach to Unsupervised Ensemble Learning</dc:title>
 <dc:creator>Shaham, Uri</dc:creator>
 <dc:creator>Cheng, Xiuyuan</dc:creator>
 <dc:creator>Dror, Omer</dc:creator>
 <dc:creator>Jaffe, Ariel</dc:creator>
 <dc:creator>Nadler, Boaz</dc:creator>
 <dc:creator>Chang, Joseph</dc:creator>
 <dc:creator>Kluger, Yuval</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show how deep learning methods can be applied in the context of
crowdsourcing and unsupervised ensemble learning. First, we prove that the
popular model of Dawid and Skene, which assumes that all classifiers are
conditionally independent, is {\em equivalent} to a Restricted Boltzmann
Machine (RBM) with a single hidden node. Hence, under this model, the posterior
probabilities of the true labels can be instead estimated via a trained RBM.
Next, to address the more general case, where classifiers may strongly violate
the conditional independence assumption, we propose to apply RBM-based Deep
Neural Net (DNN). Experimental results on various simulated and real-world
datasets demonstrate that our proposed DNN approach outperforms other
state-of-the-art methods, in particular when the data violates the conditional
independence assumption.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02285</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02293</identifier>
 <datestamp>2016-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Efficient Distributed Construction of Near Optimal Routing Schemes</dc:title>
 <dc:creator>Elkin, Michael</dc:creator>
 <dc:creator>Neiman, Ofer</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Given a distributed network represented by a weighted undirected graph
$G=(V,E)$ on $n$ vertices, and a parameter $k$, we devise a distributed
algorithm that computes a routing scheme in $(n^{1/2+1/k}+D)\cdot n^{o(1)}$
rounds, where $D$ is the hop-diameter of the network. The running time matches
the lower bound of $\tilde{\Omega}(n^{1/2}+D)$ rounds (which holds for any
scheme with polynomial stretch), up to lower order terms. The routing tables
are of size $\tilde{O}(n^{1/k})$, the labels are of size $O(k\log^2n)$, and
every packet is routed on a path suffering stretch at most $4k-5+o(1)$. Our
construction nearly matches the state-of-the-art for routing schemes built in a
centralized sequential manner. The previous best algorithms for building
routing tables in a distributed small messages model were by \cite[STOC
2013]{LP13} and \cite[PODC 2015]{LP15}. The former has similar properties but
suffers from substantially larger routing tables of size $O(n^{1/2+1/k})$,
while the latter has sub-optimal running time of
$\tilde{O}(\min\{(nD)^{1/2}\cdot n^{1/k},n^{2/3+2/(3k)}+D\})$.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-11-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02293</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02294</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Source-Channel Separation Theorem with Application to the Source
  Broadcast Problem</dc:title>
 <dc:creator>Khezeli, Kia</dc:creator>
 <dc:creator>Chen, Jun</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  A converse method is developed for the source broadcast problem.
Specifically, it is shown that the separation architecture is optimal for a
variant of the source broadcast problem and the associated source-channel
separation theorem can be leveraged, via a reduction argument, to establish a
necessary condition for the original problem, which unifies several existing
results in the literature. Somewhat surprisingly, this method, albeit based on
the source-channel separation theorem, can be used to prove the optimality of
non-separation based schemes and determine the performance limits in certain
scenarios where the separation architecture is suboptimal.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02294</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02296</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Report on the Third Workshop on Sustainable Software for Science:
  Practice and Experiences (WSSSPE3)</dc:title>
 <dc:creator>Katz, Daniel S.</dc:creator>
 <dc:creator>Choi, Sou-Cheng T.</dc:creator>
 <dc:creator>Niemeyer, Kyle E.</dc:creator>
 <dc:creator>Hetherington, James</dc:creator>
 <dc:creator>L&#xf6;ffler, Frank</dc:creator>
 <dc:creator>Gunter, Dan</dc:creator>
 <dc:creator>Idaszak, Ray</dc:creator>
 <dc:creator>Brandt, Steven R.</dc:creator>
 <dc:creator>Miller, Mark A.</dc:creator>
 <dc:creator>Gesing, Sandra</dc:creator>
 <dc:creator>Jones, Nick D.</dc:creator>
 <dc:creator>Weber, Nic</dc:creator>
 <dc:creator>Marru, Suresh</dc:creator>
 <dc:creator>Allen, Gabrielle</dc:creator>
 <dc:creator>Penzenstadler, Birgit</dc:creator>
 <dc:creator>Venters, Colin C.</dc:creator>
 <dc:creator>Davis, Ethan</dc:creator>
 <dc:creator>Hwang, Lorraine</dc:creator>
 <dc:creator>Todorov, Ilian</dc:creator>
 <dc:creator>Patra, Abani</dc:creator>
 <dc:creator>de Val-Borro, Miguel</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  This report records and discusses the Third Workshop on Sustainable Software
for Science: Practice and Experiences (WSSSPE3). The report includes a
description of the keynote presentation of the workshop, which served as an
overview of sustainable scientific software. It also summarizes a set of
lightning talks in which speakers highlighted to-the-point lessons and
challenges pertaining to sustaining scientific software. The final and main
contribution of the report is a summary of the discussions, future steps, and
future organization for a set of self-organized working groups on topics
including developing pathways to funding scientific software; constructing
useful common metrics for crediting software stakeholders; identifying
principles for sustainable software engineering design; reaching out to
research software organizations around the world; and building communities for
software sustainability. For each group, we include a point of contact and a
landing page that can be used by those who want to join that group's future
activities. The main challenge left by the workshop is to see if the groups
will execute these activities that they have scheduled, and how the WSSSPE
community can encourage this to happen.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02296</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02311</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>R\'enyi Divergence Variational Inference</dc:title>
 <dc:creator>Li, Yingzhen</dc:creator>
 <dc:creator>Turner, Richard E.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  This paper introduces the variational R\'enyi bound (VR) that extends
traditional variational inference to R\'enyi's alpha-divergences. This new
family of variational methods unifies a number of existing approaches, and
enables a smooth interpolation from the evidence lower-bound to the log
(marginal) likelihood that is controlled by the value of alpha that
parametrises the divergence. The reparameterization trick, Monte Carlo
approximation and stochastic optimisation methods are deployed to obtain a
tractable and unified framework for optimisation. We further consider negative
alpha values and propose a novel variational inference method as a new special
case in the proposed framework. Experiments on Bayesian neural networks and
variational auto-encoders demonstrate the wide applicability of the VR bound.
</dc:description>
 <dc:description>Comment: NIPS 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02311</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02332</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalable Text Mining with Sparse Generative Models</dc:title>
 <dc:creator>Puurula, Antti</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The information age has brought a deluge of data. Much of this is in text
form, insurmountable in scope for humans and incomprehensible in structure for
computers. Text mining is an expanding field of research that seeks to utilize
the information contained in vast document collections. General data mining
methods based on machine learning face challenges with the scale of text data,
posing a need for scalable text mining methods.
  This thesis proposes a solution to scalable text mining: generative models
combined with sparse computation. A unifying formalization for generative text
models is defined, bringing together research traditions that have used
formally equivalent models, but ignored parallel developments. This framework
allows the use of methods developed in different processing tasks such as
retrieval and classification, yielding effective solutions across different
text mining tasks. Sparse computation using inverted indices is proposed for
inference on probabilistic models. This reduces the computational complexity of
the common text mining operations according to sparsity, yielding probabilistic
models with the scalability of modern search engines.
  The proposed combination provides sparse generative models: a solution for
text mining that is general, effective, and scalable. Extensive experimentation
on text classification and ranked retrieval datasets are conducted, showing
that the proposed solution matches or outperforms the leading task-specific
methods in effectiveness, with a order of magnitude decrease in classification
times for Wikipedia article categorization with a million classes. The
developed methods were further applied in two 2014 Kaggle data mining prize
competitions with over a hundred competing teams, earning first and second
places.
</dc:description>
 <dc:description>Comment: PhD Thesis, Computer Science, University of Waikato, 2016</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02334</identifier>
 <datestamp>2017-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>ERBlox: Combining Matching Dependencies with Machine Learning for Entity
  Resolution</dc:title>
 <dc:creator>Bahmani, Zeinab</dc:creator>
 <dc:creator>Bertossi, Leopoldo</dc:creator>
 <dc:creator>Vasiloglou, Nikolaos</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Entity resolution (ER), an important and common data cleaning problem, is
about detecting data duplicate representations for the same external entities,
and merging them into single representations. Relatively recently, declarative
rules called &quot;matching dependencies&quot; (MDs) have been proposed for specifying
similarity conditions under which attribute values in database records are
merged. In this work we show the process and the benefits of integrating four
components of ER: (a) Building a classifier for duplicate/non-duplicate record
pairs built using machine learning (ML) techniques; (b) Use of MDs for
supporting the blocking phase of ML; (c) Record merging on the basis of the
classifier results; and (d) The use of the declarative language &quot;LogiQL&quot; -an
extended form of Datalog supported by the &quot;LogicBlox&quot; platform- for all
activities related to data processing, and the specification and enforcement of
MDs.
</dc:description>
 <dc:description>Comment: Final journal version, with some minor technical corrections.
  Extended version of arXiv:1508.06013</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2017-01-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02334</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02338</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Stratified Bayesian Optimization</dc:title>
 <dc:creator>Toscano-Palmerin, Saul</dc:creator>
 <dc:creator>Frazier, Peter I.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We consider derivative-free black-box global optimization of expensive noisy
functions, when most of the randomness in the objective is produced by a few
influential scalar random inputs. We present a new Bayesian global optimization
algorithm, called Stratified Bayesian Optimization (SBO), which uses this
strong dependence to improve performance. Our algorithm is similar in spirit to
stratification, a technique from simulation, which uses strong dependence on a
categorical representation of the random input to reduce variance. We
demonstrate in numerical experiments that SBO outperforms state-of-the-art
Bayesian optimization benchmarks that do not leverage this dependence.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-02-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02338</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02339</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Selection of Virtual Machines for Application Servers in Cloud
  Environments</dc:title>
 <dc:creator>Grozev, Nikolay</dc:creator>
 <dc:creator>Buyya, Rajkumar</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Autoscaling is a hallmark of cloud computing as it allows flexible
just-in-time allocation and release of computational resources in response to
dynamic and often unpredictable workloads. This is especially important for web
applications whose workload is time dependent and prone to flash crowds. Most
of them follow the 3-tier architectural pattern, and are divided into
presentation, application/domain and data layers. In this work we focus on the
application layer. Reactive autoscaling policies of the type &quot;Instantiate a new
Virtual Machine (VM) when the average server CPU utilisation reaches X%&quot; have
been used successfully since the dawn of cloud computing. But which VM type is
the most suitable for the specific application at the moment remains an open
question. In this work, we propose an approach for dynamic VM type selection.
It uses a combination of online machine learning techniques, works in real time
and adapts to changes in the users' workload patterns, application changes as
well as middleware upgrades and reconfigurations. We have developed a
prototype, which we tested with the CloudStone benchmark deployed on AWS EC2.
Results show that our method quickly adapts to workload changes and reduces the
total cost compared to the industry standard approach.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02339</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02343</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Eye-CU: Sleep Pose Classification for Healthcare using Multimodal
  Multiview Data</dc:title>
 <dc:creator>Torres, Carlos</dc:creator>
 <dc:creator>Fragoso, Victor</dc:creator>
 <dc:creator>Hammond, Scott D.</dc:creator>
 <dc:creator>Fried, Jeffrey C.</dc:creator>
 <dc:creator>Manjunath, B. S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Manual analysis of body poses of bed-ridden patients requires staff to
continuously track and record patient poses. Two limitations in the
dissemination of pose-related therapies are scarce human resources and
unreliable automated systems. This work addresses these issues by introducing a
new method and a new system for robust automated classification of sleep poses
in an Intensive Care Unit (ICU) environment. The new method,
coupled-constrained Least-Squares (cc-LS), uses multimodal and multiview (MM)
data and finds the set of modality trust values that minimizes the difference
between expected and estimated labels. The new system, Eye-CU, is an affordable
multi-sensor modular system for unobtrusive data collection and analysis in
healthcare. Experimental results indicate that the performance of cc-LS matches
the performance of existing methods in ideal scenarios. This method outperforms
the latest techniques in challenging scenarios by 13% for those with poor
illumination and by 70% for those with both poor illumination and occlusions.
Results also show that a reduced Eye-CU configuration can classify poses
without pressure information with only a slight drop in its performance.
</dc:description>
 <dc:description>Comment: Ten-page manuscript including references and ten figures</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-22</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02343</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02348</identifier>
 <datestamp>2016-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Economic and Technological Complexity: A Model Study of Indicators of
  Knowledge-based Innovation Systems</dc:title>
 <dc:creator>Ivanova, Inga</dc:creator>
 <dc:creator>Strand, Oivind</dc:creator>
 <dc:creator>Kushnir, Duncan</dc:creator>
 <dc:creator>Leydesdorff, Loet</dc:creator>
 <dc:subject>Quantitative Finance - Economics</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  The Economic Complexity Index (ECI; Hidalgo &amp; Hausmann, 2009) measures the
complexity of national economies in terms of product groups. Analogously to
ECI, a Patent Complexity Index (PatCI) can be developed on the basis of a
matrix of nations versus patent classes. Using linear algebra, the three
dimensions: countries, product groups, and patent classes can be combined into
a measure of &quot;Triple Helix&quot; complexity (THCI) including the trilateral
interaction terms between knowledge production, wealth generation, and
(national) control. THCI can be expected to capture the extent of systems
integration between the global dynamics of markets (ECI) and technologies
(PatCI) in each national system of innovation. We measure ECI, PatCI, and THCI
during the period 2000-2014 for the 34 OECD member states, the BRICS countries,
and a group of emerging and affiliated economies (Argentina, Hong Kong,
Indonesia, Malaysia, Romania, and Singapore). The three complexity indicators
are correlated between themselves; but the correlations with GDP per capita are
virtually absent. Of the world's major economies, Japan scores highest on all
three indicators, while China has been increasingly successful in combining
economic and technological complexity. We could not reproduce the correlation
between ECI and average income that has been central to the argument about the
fruitfulness of the economic complexity approach.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-12-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02350</identifier>
 <datestamp>2016-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Solving Ridge Regression using Sketched Preconditioned SVRG</dc:title>
 <dc:creator>Gonen, Alon</dc:creator>
 <dc:creator>Orabona, Francesco</dc:creator>
 <dc:creator>Shalev-Shwartz, Shai</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We develop a novel preconditioning method for ridge regression, based on
recent linear sketching methods. By equipping Stochastic Variance Reduced
Gradient (SVRG) with this preconditioning process, we obtain a significant
speed-up relative to fast stochastic methods such as SVRG, SDCA and SAG.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02355</identifier>
 <datestamp>2016-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hyperparameter optimization with approximate gradient</dc:title>
 <dc:creator>Pedregosa, Fabian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Most models in machine learning contain at least one hyperparameter to
control for model complexity. Choosing an appropriate set of hyperparameters is
both crucial in terms of model accuracy and computationally challenging. In
this work we propose an algorithm for the optimization of continuous
hyperparameters using inexact gradient information. An advantage of this method
is that hyperparameters can be updated before model parameters have fully
converged. We also give sufficient conditions for the global convergence of
this method, based on regularity conditions of the involved functions and
summability of errors. Finally, we validate the empirical performance of this
method on the estimation of regularization constants of L2-regularized logistic
regression and kernel Ridge regression. Empirical benchmarks indicate that our
approach is highly competitive with respect to state of the art methods.
</dc:description>
 <dc:description>Comment: Proceedings of the International conference on Machine Learning
  (ICML)</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-06-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02355</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02358</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>NED: An Inter-Graph Node Metric Based On Edit Distance</dc:title>
 <dc:creator>Zhu, Haohan</dc:creator>
 <dc:creator>Meng, Xianrui</dc:creator>
 <dc:creator>Kollios, George</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Node similarity is a fundamental problem in graph analytics. However, node
similarity between nodes in different graphs (inter-graph nodes) has not
received a lot of attention yet. The inter-graph node similarity is important
in learning a new graph based on the knowledge of an existing graph (transfer
learning on graphs) and has applications in biological, communication, and
social networks. In this paper, we propose a novel distance function for
measuring inter-graph node similarity with edit distance, called NED. In NED,
two nodes are compared according to their local neighborhood structures which
are represented as unordered k-adjacent trees, without relying on labels or
other assumptions. Since the computation problem of tree edit distance on
unordered trees is NP-Complete, we propose a modified tree edit distance,
called TED*, for comparing neighborhood trees. TED* is a metric distance, as
the original tree edit distance, but more importantly, TED* is polynomially
computable. As a metric distance, NED admits efficient indexing, provides
interpretable results, and shows to perform better than existing approaches on
a number of data analysis tasks, including graph de-anonymization. Finally, the
efficiency and effectiveness of NED are empirically demonstrated using
real-world graphs.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02358</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02362</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the circuit complexity of the standard and the Karatsuba methods of
  multiplying integers</dc:title>
 <dc:creator>Sergeev, Igor S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We provide accurate upper bounds on the Boolean circuit complexity of the
standard and the Karatsuba methods of integer multiplication
</dc:description>
 <dc:description>Comment: 6 pages, published in Russian in Proc. XXII Conf. &quot;Information means
  and technology&quot; (Moscow, November 18--20, 2014). Vol. 3. Moscow, MPEI, 2014,
  180--187</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02362</dc:identifier>
 <dc:language>ru</dc:language>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02366</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Degrees-of-Freedom of the Large-Scale Interfering Two-Way Relay
  Network</dc:title>
 <dc:creator>Yang, Hyun Jong</dc:creator>
 <dc:creator>Shin, Won-Yong</dc:creator>
 <dc:creator>Jung, Bang Chul</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Achievable degrees-of-freedom (DoF) of the large-scale interfering two-way
relay network is investigated. The network consists of $K$ pairs of
communication nodes (CNs) and $N$ relay nodes (RNs). It is assumed that $K\ll
N$ and each pair of CNs communicates with each other through one of the $N$
relay nodes without a direct link between them. Interference among RNs is also
considered. Assuming local channel state information (CSI) at each RN, a
distributed and opportunistic RN selection technique is proposed for the
following three promising relaying protocols: amplify--forward,
decode--forward, and compute--forward. As a main result, the asymptotically
achievable DoF is characterized as $N$ increases for the three relaying
protocols. In particular, a sufficient condition on $N$ required to achieve the
certain DoF of the network is analyzed. Through extensive simulations, it is
shown that the proposed RN selection techniques outperform conventional schemes
in terms of achievable rate even in practical communication scenarios. Note
that the proposed technique operates with a distributed manner and requires
only local CSI, leading to easy implementation for practical wireless systems.
</dc:description>
 <dc:description>Comment: 18 pages, 5 figures, To appear in IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02366</dc:identifier>
 <dc:identifier>doi:10.1109/TVT.2016.2519379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02367</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Diffusion Kernel LMS algorithm for nonlinear adaptive networks</dc:title>
 <dc:creator>Chouvardas, Symeon</dc:creator>
 <dc:creator>Draief, Moez</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This work presents a distributed algorithm for nonlinear adaptive learning.
In particular, a set of nodes obtain measurements, sequentially one per time
step, which are related via a nonlinear function; their goal is to collectively
minimize a cost function by employing a diffusion based Kernel Least Mean
Squares (KLMS). The algorithm follows the Adapt Then Combine mode of
cooperation. Moreover, the theoretical properties of the algorithm are studied
and it is proved that under certain assumptions the algorithm suffers a no
regret bound. Finally, comparative experiments verify that the proposed scheme
outperforms other variants of the LMS.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02367</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02373</identifier>
 <datestamp>2016-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Supervised and Semi-Supervised Text Categorization using LSTM for Region
  Embeddings</dc:title>
 <dc:creator>Johnson, Rie</dc:creator>
 <dc:creator>Zhang, Tong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  One-hot CNN (convolutional neural network) has been shown to be effective for
text categorization (Johnson &amp; Zhang, 2015). We view it as a special case of a
general framework which jointly trains a linear model with a non-linear feature
generator consisting of `text region embedding + pooling'. Under this
framework, we explore a more sophisticated region embedding method using Long
Short-Term Memory (LSTM). LSTM can embed text regions of variable (and possibly
large) sizes, whereas the region size needs to be fixed in a CNN. We seek
effective and efficient use of LSTM for this purpose in the supervised and
semi-supervised settings. The best results were obtained by combining region
embeddings in the form of LSTM and convolution layers trained on unlabeled
data. The results indicate that on this task, embeddings of text regions, which
can convey complex concepts, are more useful than embeddings of single words in
isolation. We report performances exceeding the previous best results on four
benchmark datasets.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02373</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02377</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Find an Optimal Path in Static System and Dynamical System within
  Polynomial Runtime</dc:title>
 <dc:creator>Tan, Yong</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>37HXX, 70Q05, 70G60, 93C85, 91B06,</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>J.7</dc:subject>
 <dc:description>  We study an ancient problem that in a static or dynamical system, sought an
optimal path, which the context always means within an extremal condition. In
fact, through those discussions about this theme, we established a universal
essential calculated model to serve for these complex systems. Meanwhile we
utilize the sample space to character the system. These contents in this paper
would involve in several major areas including the geometry, probability, graph
algorithms and some prior approaches, which stands the ultimately subtle linear
algorithm to solve this class problem. Along with our progress, our discussion
would demonstrate more general meaning and robust character, which provides
clear ideas or notion to support our concrete applications, who work in a more
popular complex system.
</dc:description>
 <dc:description>Comment: 27 pages, 9720 words,10 figures,5 trials</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02377</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02383</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Disentangled Representations in Neural Models</dc:title>
 <dc:creator>Whitney, William</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Representation learning is the foundation for the recent success of neural
network models. However, the distributed representations generated by neural
networks are far from ideal. Due to their highly entangled nature, they are di
cult to reuse and interpret, and they do a poor job of capturing the sparsity
which is present in real- world transformations. In this paper, I describe
methods for learning disentangled representations in the two domains of
graphics and computation. These methods allow neural methods to learn
representations which are easy to interpret and reuse, yet they incur little or
no penalty to performance. In the Graphics section, I demonstrate the ability
of these methods to infer the generating parameters of images and rerender
those images under novel conditions. In the Computation section, I describe a
model which is able to factorize a multitask learning problem into subtasks and
which experiences no catastrophic forgetting. Together these techniques provide
the tools to design a wide range of models that learn disentangled
representations and better model the factors of variation in the real world.
</dc:description>
 <dc:description>Comment: MIT Master's of Engineering thesis</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02383</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02384</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The benefit of a 1-bit jump-start, and the necessity of stochastic
  encoding, in jamming channels</dc:title>
 <dc:creator>Dey, Bikash Kumar</dc:creator>
 <dc:creator>Jaggi, Sidharth</dc:creator>
 <dc:creator>Langberg, Michael</dc:creator>
 <dc:creator>Sarwate, Anand D.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We consider the problem of communicating a message $m$ in the presence of a
malicious jamming adversary (Calvin), who can erase an arbitrary set of up to
$pn$ bits, out of $n$ transmitted bits $(x_1,\ldots,x_n)$. The capacity of such
a channel when Calvin is exactly causal, i.e. Calvin's decision of whether or
not to erase bit $x_i$ depends on his observations $(x_1,\ldots,x_i)$ was
recently characterized to be $1-2p$. In this work we show two (perhaps)
surprising phenomena. Firstly, we demonstrate via a novel code construction
that if Calvin is delayed by even a single bit, i.e. Calvin's decision of
whether or not to erase bit $x_i$ depends only on $(x_1,\ldots,x_{i-1})$ (and
is independent of the &quot;current bit&quot; $x_i$) then the capacity increases to $1-p$
when the encoder is allowed to be stochastic. Secondly, we show via a novel
jamming strategy for Calvin that, in the single-bit-delay setting, if the
encoding is deterministic (i.e. the transmitted codeword is a deterministic
function of the message $m$) then no rate asymptotically larger than $1-2p$ is
possible with vanishing probability of error, hence stochastic encoding (using
private randomness at the encoder) is essential to achieve the capacity of
$1-p$ against a one-bit-delayed Calvin.
</dc:description>
 <dc:description>Comment: 21 pages, 4 figures, extended draft of submission to ISIT 2016</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02384</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02386</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network Inference by Learned Node-Specific Degree Prior</dc:title>
 <dc:creator>Tang, Qingming</dc:creator>
 <dc:creator>Tu, Lifu</dc:creator>
 <dc:creator>Wang, Weiran</dc:creator>
 <dc:creator>Xu, Jinbo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel method for network inference from partially observed edges
using a node-specific degree prior. The degree prior is derived from observed
edges in the network to be inferred, and its hyper-parameters are determined by
cross validation. Then we formulate network inference as a matrix completion
problem regularized by our degree prior. Our theoretical analysis indicates
that this prior favors a network following the learned degree distribution, and
may lead to improved network recovery error bound than previous work.
Experimental results on both simulated and real biological networks demonstrate
the superior performance of our method in various settings.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02386</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02387</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Monitoring Temporal Properties using Interval Analysis</dc:title>
 <dc:creator>Ishii, Daisuke</dc:creator>
 <dc:creator>Yonezaki, Naoki</dc:creator>
 <dc:creator>Goldsztejn, Alexandre</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Verification of temporal logic properties plays a crucial role in proving the
desired behaviors of continuous systems. In this paper, we propose an interval
method that verifies the properties described by a bounded signal temporal
logic. We relax the problem so that if the verification process cannot succeed
at the prescribed precision, it outputs an inconclusive result. The problem is
solved by an efficient and rigorous monitoring algorithm. This algorithm
performs a forward simulation of a continuous-time dynamical system, detects a
set of time intervals in which the atomic propositions hold, and validates the
property by propagating the time intervals. In each step, the continuous state
at a certain time is enclosed by an interval vector that is proven to contain a
unique solution. We experimentally demonstrate the utility of the proposed
method in formal analysis of nonlinear and complex continuous systems.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1506.01762</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02387</dc:identifier>
 <dc:identifier>IEICE Trans. Fundamentals, vol. E99-A, no. 2, pp. 442-453, Feb.
  2016</dc:identifier>
 <dc:identifier>doi:10.1587/transfun.E99.A.442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02389</identifier>
 <datestamp>2017-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Ensemble Robustness and Generalization of Stochastic Deep Learning
  Algorithms</dc:title>
 <dc:creator>Zahavy, Tom</dc:creator>
 <dc:creator>Kang, Bingyi</dc:creator>
 <dc:creator>Sivak, Alex</dc:creator>
 <dc:creator>Feng, Jiashi</dc:creator>
 <dc:creator>Xu, Huan</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The question why deep learning algorithms generalize so well has attracted
increasing research interest. However, most of the well-established approaches,
such as hypothesis capacity, stability or sparseness, have not provided
complete explanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this
work, we focus on the robustness approach (Xu &amp; Mannor, 2012), i.e., if the
error of a hypothesis will not change much due to perturbations of its training
examples, then it will also generalize well. As most deep learning algorithms
are stochastic (e.g., Stochastic Gradient Descent, Dropout, and
Bayes-by-backprop), we revisit the robustness arguments of Xu &amp; Mannor, and
introduce a new approach, ensemble robustness, that concerns the robustness of
a population of hypotheses. Through the lens of ensemble robustness, we reveal
that a stochastic learning algorithm can generalize well as long as its
sensitiveness to adversarial perturbations is bounded in average over training
examples. Moreover, an algorithm may be sensitive to some adversarial examples
(Goodfellow et al., 2015) but still generalize well. To support our claims, we
provide extensive simulations for different deep learning algorithms and
different network architectures exhibiting a strong correlation between
ensemble robustness and the ability to generalize.
</dc:description>
 <dc:description>Comment: 16 pages, 2 figures</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2017-11-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02389</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02390</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Lower Bounds for Interactive Function Computation via Wyner Common
  Information</dc:title>
 <dc:creator>Rajakrishnan, Shijin</dc:creator>
 <dc:creator>S, Sundara Rajan</dc:creator>
 <dc:creator>Prabhakaran, Vinod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The question of how much communication is required between collaborating
parties to compute a function of their data is of fundamental importance in the
fields of theoretical computer science and information theory. In this work,
the focus is on coming up with lower bounds on this. The information cost of a
protocol is the amount of information the protocol reveals to Alice and Bob
about each others inputs, and the information complexity of a function is the
infimum of information costs over all valid protocols. For the amortized case,
it is known that the optimal rate for the computation is equal to the
information complexity. Exactly computing this information complexity is not
straight forward however. In this work we lower bound information complexity
for independent inputs in terms of the Wyner common information of a certain
pair of random variables. We show a structural property for the optimal
auxiliary random variable of Wyner common information and exploit this to
exactly compute the Wyner common information in certain cases. The lower bound
obtained through this technique is shown to be tight for a non-trivial example
- equality (EQ) for the ternary alphabet. We also give an example to show that
the lower bound may, in general, not be tight.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures, accepted in NCC 2016</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02390</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02396</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The problem of popular primes: Logjam</dc:title>
 <dc:creator>Bokslag, Wouter</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>94A60</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>K.6.5</dc:subject>
 <dc:description>  This paper will discuss the Logjam attack on TLS. The Logjam attack allows,
under certain conditions, to defeat the security provided by TLS. This is done
by manipulating server and client into using weak and deprecated export grade
crypto, and subsequently breaking the Diffie-Hellman key exchange. We explore
how the attack works conceptually and how exactly TLS is vulnerable to this
attack. Also, the conditions under which the attack can be mounted are
discussed, and an estimate of the impact of the attack is presented. Lastly,
several mitigations are presented.
</dc:description>
 <dc:description>Comment: 9 pages, 1 figures</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02396</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02409</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A mathematical formalization of data parallel operations</dc:title>
 <dc:creator>Eijkhout, Victor</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  We give a mathematical formalization of `generalized data parallel'
operations, a concept that covers such common scientific kernels as
matrix-vector multiplication, multi-grid coarsening, load distribution, and
many more. We show that from a compact specification such computational aspects
as MPI messages or task dependencies can be automatically derived.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02410</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring the Limits of Language Modeling</dc:title>
 <dc:creator>Jozefowicz, Rafal</dc:creator>
 <dc:creator>Vinyals, Oriol</dc:creator>
 <dc:creator>Schuster, Mike</dc:creator>
 <dc:creator>Shazeer, Noam</dc:creator>
 <dc:creator>Wu, Yonghui</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  In this work we explore recent advances in Recurrent Neural Networks for
large scale Language Modeling, a task central to language understanding. We
extend current models to deal with two key challenges present in this task:
corpora and vocabulary sizes, and complex, long term structure of language. We
perform an exhaustive study on techniques such as character Convolutional
Neural Networks or Long-Short Term Memory, on the One Billion Word Benchmark.
Our best single model significantly improves state-of-the-art perplexity from
51.3 down to 30.0 (whilst reducing the number of parameters by a factor of 20),
while an ensemble of models sets a new record by improving perplexity from 41.0
down to 23.7. We also release these models for the NLP and ML community to
study and improve upon.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02410</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02412</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The counting house: measuring those who count. Presence of
  Bibliometrics, Scientometrics, Informetrics, Webometrics and Altmetrics in
  the Google Scholar Citations, ResearcherID, ResearchGate, Mendeley &amp; Twitter</dc:title>
 <dc:creator>Martin-Martin, Alberto</dc:creator>
 <dc:creator>Orduna-Malea, Enrique</dc:creator>
 <dc:creator>Ayllon, Juan M.</dc:creator>
 <dc:creator>Lopez-Cozar, Emilio Delgado</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  Following in the footsteps of the model of scientific communication, which
has recently gone through a metamorphosis (from the Gutenberg galaxy to the Web
galaxy), a change in the model and methods of scientific evaluation is also
taking place. A set of new scientific tools are now providing a variety of
indicators which measure all actions and interactions among scientists in the
digital space, making new aspects of scientific communication emerge. In this
work we present a method for capturing the structure of an entire scientific
community (the Bibliometrics, Scientometrics, Informetrics, Webometrics, and
Altmetrics community) and the main agents that are part of it (scientists,
documents, and sources) through the lens of Google Scholar Citations.
  Additionally, we compare these author portraits to the ones offered by other
profile or social platforms currently used by academics (ResearcherID,
ResearchGate, Mendeley, and Twitter), in order to test their degree of use,
completeness, reliability, and the validity of the information they provide. A
sample of 814 authors (researchers in Bibliometrics with a public profile
created in Google Scholar Citations was subsequently searched in the other
platforms, collecting the main indicators computed by each of them. The data
collection was carried out on September, 2015. The Spearman correlation was
applied to these indicators (a total of 31) , and a Principal Component
Analysis was carried out in order to reveal the relationships among metrics and
platforms as well as the possible existence of metric clusters
</dc:description>
 <dc:description>Comment: 60 pages, 12 tables, 35 figures</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02412</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02415</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Cartesian line sampling with anisotropic total variation
  regularization</dc:title>
 <dc:creator>Poon, Clarice</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper considers the use of the anisotropic total variation seminorm to
recover a two dimensional vector $x\in \mathbb{C}^{N\times N}$ from its partial
Fourier coefficients, sampled along Cartesian lines. We prove that if $(x_{k,j}
- x_{k-1,j})_{k,j}$ has at most $s_1$ nonzero coefficients in each column and
$(x_{k,j} - x_{k,j-1})_{k,j}$ has at most $s_2$ nonzero coefficients in each
row, then, up to multiplication by $\log$ factors, one can exactly recover $x$
by sampling along $s_1$ horizontal lines of its Fourier coefficients and along
$s_2$ vertical lines of its Fourier coefficients. Finally, unlike standard
compressed sensing estimates, the $\log$ factors involved are dependent on the
separation distance between the nonzero entries in each row/column of the
gradient of $x$ and not on $N^2$, the ambient dimension of $x$.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02415</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02422</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Approximate Capacity of Index Coding for Some Classes of Graphs</dc:title>
 <dc:creator>Arbabjolfaei, Fatemeh</dc:creator>
 <dc:creator>Kim, Young-Han</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  For a class of graphs for which the Ramsey number $R(i,j)$ is upper bounded
by $ci^aj^b$, for some constants $a,b,$ and $c$, it is shown that the clique
covering scheme approximates the broadcast rate of every $n$-node index coding
problem in the class within a multiplicative factor of $c^{\frac{1}{a+b+1}}
n^{\frac{a+b}{a+b+1}}$ for every $n$. Using this theorem and some graph
theoretic arguments, it is demonstrated that the broadcast rate of planar
graphs, line graphs and fuzzy circular interval graphs is approximated by the
clique covering scheme within a factor of $n^{\frac{2}{3}}$.
</dc:description>
 <dc:description>Comment: 5 pages</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02422</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02426</identifier>
 <datestamp>2016-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Atlas: A Tool for Mapping Social Networks</dc:title>
 <dc:creator>Saveski, Martin</dc:creator>
 <dc:creator>Chu, Eric</dc:creator>
 <dc:creator>Vosoughi, Soroush</dc:creator>
 <dc:creator>Roy, Deb</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>H.5.2, H.3.4</dc:subject>
 <dc:description>  Most social network analyses focus on online social networks. While these
networks encode important aspects of our lives they fail to capture many
real-world connections. Most of these connections are, in fact, public and
known to the members of the community. Mapping them is a task very suitable for
crowdsourcing: it is easily broken down in many simple and independent
subtasks. Due to the nature of social networks -- presence of highly connected
nodes and tightly knit groups -- if we allow users to map their immediate
connections and the connections between them, we will need few participants to
map most connections within a community. To this end, we built the Human Atlas,
a web-based tool for mapping social networks. To test it, we partially mapped
the social network of the MIT Media Lab. We ran a user study and invited
members of the community to use the tool. In 4.6 man-hours, 22 participants
mapped 984 connections within the lab, demonstrating the potential of the tool.
</dc:description>
 <dc:description>Comment: WWW'16 Demonstration, WWW'16 Companion, April 11-15, 2016, Montreal,
  Quebec, Canada</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02426</dc:identifier>
 <dc:identifier>doi:10.1145/2872518.2890552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02432</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Finitely presented group whose word problem has sampleable hard
  instances</dc:title>
 <dc:creator>Gilman, Robert H</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>68A20</dc:subject>
 <dc:description>  Hard instances of natural computational problems are often elusive. In this
note we present an example of a natural decision problem, the word problem for
a certain finitely presented group, whose hard instances are easy to find. More
precisely the problem has a complexity core sampleable in linear time.
</dc:description>
 <dc:description>Comment: 3 pages</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02432</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02434</identifier>
 <datestamp>2016-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Screen Content Image Segmentation Using Sparse Decomposition and Total
  Variation Minimization</dc:title>
 <dc:creator>Minaee, Shervin</dc:creator>
 <dc:creator>Wang, Yao</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse decomposition has been widely used for different applications, such as
source separation, image classification, image denoising and more. This paper
presents a new algorithm for segmentation of an image into background and
foreground text and graphics using sparse decomposition and total variation
minimization. The proposed method is designed based on the assumption that the
background part of the image is smoothly varying and can be represented by a
linear combination of a few smoothly varying basis functions, while the
foreground text and graphics can be modeled with a sparse component overlaid on
the smooth background. The background and foreground are separated using a
sparse decomposition framework regularized with a few suitable regularization
terms which promotes the sparsity and connectivity of foreground pixels. This
algorithm has been tested on a dataset of images extracted from HEVC standard
test sequences for screen content coding, and is shown to have superior
performance over some prior methods, including least absolute deviation
fitting, k-means clustering based segmentation in DjVu and shape primitive
extraction and coding (SPEC) algorithm.
</dc:description>
 <dc:description>Comment: 5 pages in IEEE, International Conference on Image Processing, 2016</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-07-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02439</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Assessments, Matching and Allocation of Tasks</dc:title>
 <dc:creator>Ahuja, Kartik</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In many two-sided markets, each side has incomplete information about the
other but has an opportunity to learn (some) relevant information before final
matches are made. For instance, clients seeking workers to perform tasks often
conduct interviews that require the workers to perform some tasks and thereby
provide information to both sides. The performance of a worker in such an
interview/assessment - and hence the information revealed - depends both on the
inherent characteristics of the worker and the task and also on the actions
taken by the worker (e.g. the effort expended); thus there is both adverse
selection (on both sides) and moral hazard (on one side). When interactions are
ongoing, incentives for workers to expend effort in the current assessment can
be provided by the payment rule used and also by the matching rule that
assesses and determines the tasks to which the worker is assigned in the
future; thus workers have career concerns. We derive mechanisms - payment,
assessment and matching rules - that lead to final matchings that are stable in
the long run and achieve close to the optimal performance (profit or social
welfare maximizing) in equilibrium (unique) thus mitigating both adverse
selection and moral hazard (in many settings).
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-09-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02439</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02442</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Simple Practical Accelerated Method for Finite Sums</dc:title>
 <dc:creator>Defazio, Aaron</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We describe a novel optimization method for finite sums (such as empirical
risk minimization problems) building on the recently introduced SAGA method.
Our method achieves an accelerated convergence rate on strongly convex smooth
problems. Our method has only one parameter (a step size), and is radically
simpler than other accelerated methods for finite sums. Additionally it can be
applied when the terms are non-smooth, yielding a method applicable in many
areas where operator splitting methods would traditionally be applied.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-10-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02442</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02443</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy and Spectral Efficiency Gains From Multi-User MIMO-based Small
  Cell Reassignments</dc:title>
 <dc:creator>Finn, Danny</dc:creator>
 <dc:creator>Ahmadi, Hamed</dc:creator>
 <dc:creator>Razavi, Rouzbeh</dc:creator>
 <dc:creator>Claussen, Holger</dc:creator>
 <dc:creator>DaSilva, Luiz</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this work we investigate the reassignment of User Equipments (UEs) between
adjacent small cells to concurrently enable spatial multiplexing gains through
Multi-User MIMO (MU-MIMO) and reductions in energy consumption though switching
emptied small cells to a sleep state. We consider a case where UEs can be
reassigned between adjacent small cells provided that the targeted neighbouring
cell contains a UE with which the reassigned UE can perform MU-MIMO without
experiencing excessive multi-user interference, and whilst achieving a minimum
expected gain in spectral efficiency over the previous original cell
transmissions as a result. We formulate the selection decision of which UEs to
reassign as a set covering problem with the objective of maximising the number
of small cell base stations to switch to a sleep state. Our results show that,
for both indoor and outdoor LTE small cell scenarios, the proposed
MU-MIMO-based reassignments achieve significant reductions in the required
number of active small cell base stations, whilst simultaneously achieving
increases in spectral efficiency.
</dc:description>
 <dc:description>Comment: The paper is presented in IEEE Globecom 2015</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02443</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02445</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Logspace Solution to the Word and Conjugacy problem of Generalized
  Baumslag-Solitar Groups</dc:title>
 <dc:creator>Wei&#xdf;, Armin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Group Theory</dc:subject>
 <dc:subject>20F10, 68Q25</dc:subject>
 <dc:subject>F.2.1</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Baumslag-Solitar groups were introduced in 1962 by Baumslag and Solitar as
examples for finitely presented non-Hopfian two-generator groups. Since then,
they served as examples for a wide range of purposes. As Baumslag-Solitar
groups are HNN extensions, there is a natural generalization in terms of graph
of groups.
  Concerning algorithmic aspects of generalized Baumslag-Solitar groups,
several decidability results are known. Indeed, a straightforward application
of standard algorithms leads to a polynomial time solution of the word problem
(the question whether some word over the generators represents the identity of
the group). The conjugacy problem (the question whether two given words
represent conjugate group elements) is more complicated; still decidability has
been established by Anshel and Stebe for ordinary Baumslag-Solitar groups and
for generalized Baumslag-Solitar groups independently by Lockhart and Beeker.
However, up to now no precise complexity estimates have been given.
  In this work, we give a LOGSPACE algorithm for both problems. More precisely,
we describe a uniform TC^0 many-one reduction of the word problem to the word
problem of the free group. Then we refine the known techniques for the
conjugacy problem and show that it can be solved in LOGSPACE. Moreover, for
ordinary Baumslag-Solitar groups also conjugacy is AC^0-Turing-reducible to the
word problem of the free group.
  Finally, we consider uniform versions (where also the graph of groups is part
of the input) of both word and conjugacy problem: while the word problem still
is solvable in LOGSPACE, the conjugacy problem becomes EXPSPACE-complete.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02445</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02450</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Loss factorization, weakly supervised learning and label noise
  robustness</dc:title>
 <dc:creator>Patrini, Giorgio</dc:creator>
 <dc:creator>Nielsen, Frank</dc:creator>
 <dc:creator>Nock, Richard</dc:creator>
 <dc:creator>Carioni, Marcello</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We prove that the empirical risk of most well-known loss functions factors
into a linear term aggregating all labels with a term that is label free, and
can further be expressed by sums of the loss. This holds true even for
non-smooth, non-convex losses and in any RKHS. The first term is a (kernel)
mean operator --the focal quantity of this work-- which we characterize as the
sufficient statistic for the labels. The result tightens known generalization
bounds and sheds new light on their interpretation.
  Factorization has a direct application on weakly supervised learning. In
particular, we demonstrate that algorithms like SGD and proximal methods can be
adapted with minimal effort to handle weak supervision, once the mean operator
has been estimated. We apply this idea to learning with asymmetric noisy
labels, connecting and extending prior work. Furthermore, we show that most
losses enjoy a data-dependent (by the mean operator) form of noise robustness,
in contrast with known negative results.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02450</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02452</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Privacy Preserving Architectures for Collaborative Intrusion Detection</dc:title>
 <dc:creator>Dara, Sashank</dc:creator>
 <dc:creator>Muralidhara, V. N.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Collaboration among multiple organizations is imperative for contemporary
intrusion detection. As modern threats become well sophisticated it is
difficult for organizations to defend with threat context local to their
networks alone. Availability of global \emph{threat intelligence} is must for
organizations to defend against modern advanced persistent threats (APTs). In
order to benefit from such global context of attacks, privacy concerns continue
to be of major hindrance. In this position paper we identify real world privacy
problems as precise use cases, relevant cryptographic technologies and discuss
privacy preserving architectures for collaborative intrusion detection.
</dc:description>
 <dc:description>Comment: 9 Pages, 2 figures, Position paper</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02452</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02454</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Algorithms for Adversarial Contextual Learning</dc:title>
 <dc:creator>Syrgkanis, Vasilis</dc:creator>
 <dc:creator>Krishnamurthy, Akshay</dc:creator>
 <dc:creator>Schapire, Robert E.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We provide the first oracle efficient sublinear regret algorithms for
adversarial versions of the contextual bandit problem. In this problem, the
learner repeatedly makes an action on the basis of a context and receives
reward for the chosen action, with the goal of achieving reward competitive
with a large class of policies. We analyze two settings: i) in the transductive
setting the learner knows the set of contexts a priori, ii) in the small
separator setting, there exists a small set of contexts such that any two
policies behave differently in one of the contexts in the set. Our algorithms
fall into the follow the perturbed leader family \cite{Kalai2005} and achieve
regret $O(T^{3/4}\sqrt{K\log(N)})$ in the transductive setting and $O(T^{2/3}
d^{3/4} K\sqrt{\log(N)})$ in the separator setting, where $K$ is the number of
actions, $N$ is the number of baseline policies, and $d$ is the size of the
separator. We actually solve the more general adversarial contextual
semi-bandit linear optimization problem, whilst in the full information setting
we address the even more general contextual combinatorial optimization. We
provide several extensions and implications of our algorithms, such as
switching regret and efficient learning with predictable sequences.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02454</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02473</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Particle Swarm Optimized Power Consumption of Trilateration</dc:title>
 <dc:creator>Al-Olimat, Hussein S.</dc:creator>
 <dc:creator>Green II, Robert C.</dc:creator>
 <dc:creator>Alam, Mansoor</dc:creator>
 <dc:creator>Devabhaktuni, Vijay</dc:creator>
 <dc:creator>Cheng, Wei</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  Trilateration-based localization (TBL) has become a corner stone of modern
technology. This study formulates the concern on how wireless sensor networks
can take advantage of the computational intelligent techniques using both
single- and multi-objective particle swarm optimization (PSO) with an overall
aim of concurrently minimizing the required time for localization, minimizing
energy consumed during localization, and maximizing the number of nodes fully
localized through the adjustment of wireless sensor transmission ranges while
using TBL process. A parameter-study of the applied PSO variants is performed,
leading to results that show algorithmic improvements of up to 32% in the
evaluated objectives.
</dc:description>
 <dc:description>Comment: 19 Pages, 13 Figures, 10 Tables, Journal</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02473</dc:identifier>
 <dc:identifier>International Journal in Foundations of Computer Science &amp;
  Technology (IJFCST), Vol.4, No.4, July 2014</dc:identifier>
 <dc:identifier>doi:10.5121/ijfcst.2014.4401</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02481</identifier>
 <datestamp>2016-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Large Dataset of Object Scans</dc:title>
 <dc:creator>Choi, Sungjoon</dc:creator>
 <dc:creator>Zhou, Qian-Yi</dc:creator>
 <dc:creator>Miller, Stephen</dc:creator>
 <dc:creator>Koltun, Vladlen</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We have created a dataset of more than ten thousand 3D scans of real objects.
To create the dataset, we recruited 70 operators, equipped them with
consumer-grade mobile 3D scanning setups, and paid them to scan objects in
their environments. The operators scanned objects of their choosing, outside
the laboratory and without direct supervision by computer vision professionals.
The result is a large and diverse collection of object scans: from shoes, mugs,
and toys to grand pianos, construction vehicles, and large outdoor sculptures.
We worked with an attorney to ensure that data acquisition did not violate
privacy constraints. The acquired data was irrevocably placed in the public
domain and is available freely at http://redwood-data.org/3dscan .
</dc:description>
 <dc:description>Comment: Technical report</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-05-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02490</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simulation of bifurcated stent grafts to treat abdominal aortic
  aneurysms (AAA)</dc:title>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:creator>Gro&#xdf;kopf, Stefan</dc:creator>
 <dc:creator>Freisleben, Bernd</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Physics - Medical Physics</dc:subject>
 <dc:subject>Quantitative Biology - Tissues and Organs</dc:subject>
 <dc:description>  In this paper a method is introduced, to visualize bifurcated stent grafts in
CT-Data. The aim is to improve therapy planning for minimal invasive treatment
of abdominal aortic aneurysms (AAA). Due to precise measurement of the
abdominal aortic aneurysm and exact simulation of the bifurcated stent graft,
physicians are supported in choosing a suitable stent prior to an intervention.
The presented method can be used to measure the dimensions of the abdominal
aortic aneurysm as well as simulate a bifurcated stent graft. Both of these
procedures are based on a preceding segmentation and skeletonization of the
aortic, right and left iliac. Using these centerlines (aortic, right and left
iliac) a bifurcated initial stent is constructed. Through the implementation of
an ACM method the initial stent is fit iteratively to the vessel walls - due to
the influence of external forces (distance- as well as balloonforce). Following
the fitting process, the crucial values for choosing a bifurcated stent graft
are measured, e.g. aortic diameter, right and left common iliac diameter,
minimum diameter of distal neck. The selected stent is then simulated to the
CT-Data - starting with the initial stent. It hereby becomes apparent if the
dimensions of the bifurcated stent graft are exact, i.e. the fitting to the
arteries was done properly and no ostium was covered.
</dc:description>
 <dc:description>Comment: 6 pages, 5 figures, 5 equations, 9 references in Proc. SPIE 6509,
  Medical Imaging 2007: Visualization and Image-Guided Procedures, 65091N (22
  March 2007)</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02490</dc:identifier>
 <dc:identifier>doi:10.1117/12.709260</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02493</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of Location Management Schemes for MANET using Synthetic
  Mobility Models</dc:title>
 <dc:creator>Bhute, Harsha</dc:creator>
 <dc:creator>Chavan, G. T.</dc:creator>
 <dc:creator>Bhute, Avinash</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In the performance evaluation of a protocol for an ad hoc network, the
protocol should be tested under realistic conditions including, but not limited
to, a sensible transmission range, limited buffer space for the storage of
messages, representative data traffic models, and realistic movements of the
mobile users and several mobility models that represent mobile nodes whose
movements are dependent on each other (i.e., group mobility models ).The goal
of this paper is to simulate the movements of mobile nodes within a network and
present a number of mobility models in order to demonstrate its effect on
Location management scheme for mobile ad hoc network or personal communication
services networks. Specifically, to illustrate how the performance results of
an ad hoc network protocol drastically change as a result of changing the
mobility model simulated. Location management is a fundamental problem in
personal communication services network. The current standard of location
management is HLR/VLR scheme. It has been observed that the performance of any
location management scheme depends on space requirements, bandwidth
requirements and time requirements. To avoid certain drawbacks in HLR/VLR
scheme, many approaches including hierarchical approaches have been suggested.
Working set idea is chosen to analyze its performance for location management
in PCS networks. Due to inadequacy of standard network simulators to provide
the output in the format desired, a new location management simulator can be
built. Two variants of working set idea viz. Working set scheme for HLR/VLR
approach and working set scheme for hierarchical approach can be used and then
compare the performance of HLR/VLR scheme and working set scheme using the
results obtained by the simulator with respect to already available mobile
activity traces.
</dc:description>
 <dc:description>Comment: 7 pages, 2 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02493</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02499</identifier>
 <datestamp>2016-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The &quot;Sprekend Nederland&quot; project and its application to accent location</dc:title>
 <dc:creator>van Leeuwen, David A.</dc:creator>
 <dc:creator>Orr, Rosemary</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  This paper describes the data collection effort that is part of the project
Sprekend Nederland (The Netherlands Talking), and discusses its potential use
in Automatic Accent Location. We define Automatic Accent Location as the task
to describe the accent of a speaker in terms of the location of the speaker and
its history. We discuss possible ways of describing accent location, the
consequence these have for the task of automatic accent location, and potential
evaluation metrics.
</dc:description>
 <dc:description>Comment: Accepted to Speaker and Language Recognition Odyssey 2016</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02499</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02504</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Requirement verification in simulation-based automation testing</dc:title>
 <dc:creator>Siivola, Eero</dc:creator>
 <dc:creator>Sierla, Seppo</dc:creator>
 <dc:creator>Niemist&#xf6;, Hannu</dc:creator>
 <dc:creator>Karhela, Tommi</dc:creator>
 <dc:creator>Vyatkin, Valeriy</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  The emergence of the Industrial Internet results in an increasing number of
complicated temporal interdependencies between automation systems and the
processes to be controlled. There is a need for verification methods that scale
better than formal verification methods and which are more exact than testing.
Simulation-based runtime verification is proposed as such a method, and an
application of Metric temporal logic is presented as a contribution. The
practical scalability of the proposed approach is validated against a
production process designed by an industrial partner, resulting in the
discovery of requirement violations.
</dc:description>
 <dc:description>Comment: 4 pages, 2 figures. Added IEEE copyright notice</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2017-04-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02504</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02505</identifier>
 <datestamp>2016-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binarized Neural Networks</dc:title>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:creator>Soudry, Daniel</dc:creator>
 <dc:creator>Yaniv, Ran El</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We introduce a method to train Binarized Neural Networks (BNNs) - neural
networks with binary weights and activations at run-time and when computing the
parameters' gradient at train-time. We conduct two sets of experiments, each
based on a different framework, namely Torch7 and Theano, where we train BNNs
on MNIST, CIFAR-10 and SVHN, and achieve nearly state-of-the-art results.
During the forward pass, BNNs drastically reduce memory size and accesses, and
replace most arithmetic operations with bit-wise operations, which might lead
to a great increase in power-efficiency. Last but not least, we wrote a binary
matrix multiplication GPU kernel with which it is possible to run our MNIST BNN
7 times faster than with an unoptimized GPU kernel, without suffering any loss
in classification accuracy. The code for training and running our BNNs is
available.
</dc:description>
 <dc:description>Comment: This is an obsolete version, up to date version is available here:
  arXiv:1602.02830</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-03-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02505</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02506</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wikipedia Tools for Google Spreadsheets</dc:title>
 <dc:creator>Steiner, Thomas</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.5</dc:subject>
 <dc:description>  In this paper, we introduce the Wikipedia Tools for Google Spreadsheets.
Google Spreadsheets is part of a free, Web-based software office suite offered
by Google within its Google Docs service. It allows users to create and edit
spreadsheets online, while collaborating with other users in realtime.
Wikipedia is a free-access, free-content Internet encyclopedia, whose content
and data is available, among other means, through an API. With the Wikipedia
Tools for Google Spreadsheets, we have created a toolkit that facilitates
working with Wikipedia data from within a spreadsheet context. We make these
tools available as open-source on GitHub
[https://github.com/tomayac/wikipedia-tools-for-google-spreadsheets], released
under the permissive Apache 2.0 license.
</dc:description>
 <dc:description>Comment: 4 pages, 3 Listings, 4 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02506</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02509</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Evaluating e-voting: theory and practice</dc:title>
 <dc:creator>Bokslag, Wouter</dc:creator>
 <dc:creator>de Vries, Manon</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>91B12, 94A60</dc:subject>
 <dc:subject>K.4.1</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  In the Netherlands as well as many other countries, the use of electronic
voting solutions is a recurrent topic of discussion. While electronic voting
certainly has advantages over paper voting, there are also important risks
involved. This paper presents an analysis of benefits and risks of electronic
voting, and shows the relevance of these issues by means of three case studies
of real-world implementations. Additionally, techniques that may be employed to
improve upon many of the current systems are presented. We conclude that the
advantages of E-voting do not outweigh the disadvantages, as the resulting
reduced verifiability and transparency seem hard to overcome.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02514</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast K-Means with Accurate Bounds</dc:title>
 <dc:creator>Newling, James</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose a novel accelerated exact k-means algorithm, which performs better
than the current state-of-the-art low-dimensional algorithm in 18 of 22
experiments, running up to 3 times faster. We also propose a general
improvement of existing state-of-the-art accelerated exact k-means algorithms
through better estimates of the distance bounds used to reduce the number of
distance calculations, and get a speedup in 36 of 44 experiments, up to 1.8
times faster.
  We have conducted experiments with our own implementations of existing
methods to ensure homogeneous evaluation of performance, and we show that our
implementations perform as well or better than existing available
implementations. Finally, we propose simplified variants of standard approaches
and show that they are faster than their fully-fledged counterparts in 59 of 62
experiments.
</dc:description>
 <dc:description>Comment: 8 pages + supplementary material v2: mlpack installed with
  optimisation (previously installed in DEBUG) v3: Annulus -&gt; Annular v4:
  Author affiliation update v5: Synced with version at ICML, now including
  Suppl. Mat</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-09-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02514</dc:identifier>
 <dc:identifier>Proceedings of the International Conference on Machine Learning
  (ICML) pp. 936-944, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02517</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Efficient Video Fusion with Heterogeneous CPU-FPGA Devices</dc:title>
 <dc:creator>Nunez-Yanez, Jose</dc:creator>
 <dc:creator>Sun, Tom</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Computer Science - Performance</dc:subject>
 <dc:description>  This paper presents a complete video fusion system with hardware acceleration
and investigates the energy trade-offs between computing in the CPU or the FPGA
device. The video fusion application is based on the Dual-Tree Complex Wavelet
Transforms (DT-CWT). In this work the transforms are mapped to a hardware
accelerator using high-level synthesis tools for the FPGA and also vectorized
code for the single instruction multiple data (SIMD) engine available in the
CPU. The accelerated system reduces computation time and energy by a factor of
2. Moreover, the results show a key finding that the FPGA is not always the
best choice for acceleration, and the SIMD engine should be selected when the
wavelet decomposition reduces the frame size below a certain threshold. This
dependency on workload size means that an adaptive system that intelligently
selects between the SIMD engine and the FPGA achieves the most energy and
performance efficiency point.
</dc:description>
 <dc:description>Comment: Presented at HIP3ES, 2016</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02517</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02518</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-view Kernel Completion</dc:title>
 <dc:creator>Bhadra, Sahely</dc:creator>
 <dc:creator>Kaski, Samuel</dc:creator>
 <dc:creator>Rousu, Juho</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we introduce the first method that (1) can complete kernel
matrices with completely missing rows and columns as opposed to individual
missing kernel values, (2) does not require any of the kernels to be complete a
priori, and (3) can tackle non-linear kernels. These aspects are necessary in
practical applications such as integrating legacy data sets, learning under
sensor failures and learning when measurements are costly for some of the
views. The proposed approach predicts missing rows by modelling both
within-view and between-view relationships among kernel values. We show, both
on simulated data and real world data, that the proposed method outperforms
existing techniques in the restricted settings where they are available, and
extends applicability to new settings.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02518</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02522</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Semi-Automated Method for Object Segmentation in Infant's Egocentric
  Videos to Study Object Perception</dc:title>
 <dc:creator>Mirsharif, Qazaleh</dc:creator>
 <dc:creator>Sadani, Sidharth</dc:creator>
 <dc:creator>Shah, Shishir</dc:creator>
 <dc:creator>Yoshida, Hanako</dc:creator>
 <dc:creator>Burling, Joseph</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Object segmentation in infant's egocentric videos is a fundamental step in
studying how children perceive objects in early stages of development. From the
computer vision perspective, object segmentation in such videos pose quite a
few challenges because the child's view is unfocused, often with large head
movements, effecting in sudden changes in the child's point of view which leads
to frequent change in object properties such as size, shape and illumination.
In this paper, we develop a semi-automated, domain specific, method to address
these concerns and facilitate the object annotation process for cognitive
scientists allowing them to select and monitor the object under segmentation.
The method starts with an annotation from the user of the desired object and
employs graph cut segmentation and optical flow computation to predict the
object mask for subsequent video frames automatically. To maintain accuracy, we
use domain specific heuristic rules to re-initialize the program with new user
input whenever object properties change dramatically. The evaluations
demonstrate the high speed and accuracy of the presented method for object
segmentation in voluminous egocentric videos. We apply the proposed method to
investigate potential patterns in object distribution in child's view at
progressive ages.
</dc:description>
 <dc:description>Comment: Accepted at CVIP 2016</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02522</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02523</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Efficient Reinforcement Learning in Continuous-State POMDPs</dc:title>
 <dc:creator>McAllister, Rowan</dc:creator>
 <dc:creator>Rasmussen, Carl Edward</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a data-efficient reinforcement learning algorithm resistant to
observation noise. Our method extends the highly data-efficient PILCO algorithm
(Deisenroth &amp; Rasmussen, 2011) into partially observed Markov decision
processes (POMDPs) by considering the filtering process during policy
evaluation. PILCO conducts policy search, evaluating each policy by first
predicting an analytic distribution of possible system trajectories. We
additionally predict trajectories w.r.t. a filtering process, achieving
significantly higher performance than combining a filter with a policy
optimised by the original (unfiltered) framework. Our test setup is the
cartpole swing-up task with sensor noise, which involves nonlinear dynamics and
requires nonlinear control.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02523</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02524</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean and variance of the LQG cost function</dc:title>
 <dc:creator>Bijl, Hildo</dc:creator>
 <dc:creator>van Wingerden, Jan Willem</dc:creator>
 <dc:creator>Sch&#xf6;n, Thomas B.</dc:creator>
 <dc:creator>Verhaegen, Michel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Linear Quadratic Gaussian (LQG) systems are well-understood and methods to
minimize the expected cost are readily available. Less is known about the
statistical properties of the resulting cost function. The contribution of this
paper is a set of analytic expressions for the mean and variance of the LQG
cost function. These expressions are derived using two different methods, one
using solutions to Lyapunov equations and the other using only matrix
exponentials. Both the discounted and the non-discounted cost function are
considered, as well as the finite-time and the infinite-time cost function. The
derived expressions are successfully applied to an example system to reduce the
probability of the cost exceeding a given threshold.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02524</dc:identifier>
 <dc:identifier>Automatica, Volume 67, May 2016, Pages 216-223</dc:identifier>
 <dc:identifier>doi:10.1016/j.automatica.2016.01.030</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02527</identifier>
 <datestamp>2016-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on the Price of Anarchy for a More General Class of Directed
  Graphs in Opinion Formation Games</dc:title>
 <dc:creator>Chen, Po-An</dc:creator>
 <dc:creator>Chen, Yi-Le</dc:creator>
 <dc:creator>Lu, Chi-Jen</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  In opinion formation games with directed graphs, a bounded price of anarchy
is only known for weighted Eulerian graphs. Thus, we bound the price of anarchy
for a more general class of directed graphs with conditions intuitively meaning
that each node does not influence the others more than she is influenced, where
the bounds depend on such difference (in a ratio). We also show that there
exists an example just slightly violating the conditions with an unbounded
price of anarchy.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-10-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02527</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02543</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homogeneity of Cluster Ensembles</dc:title>
 <dc:creator>Jain, Brijnesh J.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The expectation and the mean of partitions generated by a cluster ensemble
are not unique in general. This issue poses challenges in statistical inference
and cluster stability. In this contribution, we state sufficient conditions for
uniqueness of expectation and mean. The proposed conditions show that a unique
mean is neither exceptional nor generic. To cope with this issue, we introduce
homogeneity as a measure of how likely is a unique mean for a sample of
partitions. We show that homogeneity is related to cluster stability. This
result points to a possible conflict between cluster stability and diversity in
consensus clustering. To assess homogeneity in a practical setting, we propose
an efficient way to compute a lower bound of homogeneity. Empirical results
using the k-means algorithm suggest that uniqueness of the mean partition is
not exceptional for real-world data. Moreover, for samples of high homogeneity,
uniqueness can be enforced by increasing the number of data points or by
removing outlier partitions. In a broader context, this contribution can be
placed as a further step towards a statistical theory of partitions.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02543</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02574</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterization of a Multi-User Indoor Positioning System Based on Low
  Cost Depth Vision (Kinect) for Monitoring Human Activity in a Smart Home</dc:title>
 <dc:creator>Sevrin, Lo&#xef;c</dc:creator>
 <dc:creator>Noury, Norbert</dc:creator>
 <dc:creator>Abouchi, Nacer</dc:creator>
 <dc:creator>Jumel, Fabrice</dc:creator>
 <dc:creator>Massot, Bertrand</dc:creator>
 <dc:creator>Saraydaryan, Jacques</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  An increasing number of systems use indoor positioning for many scenarios
such as asset tracking, health care, games, manufacturing, logistics, shopping,
and security. Many technologies are available and the use of depth cameras is
becoming more and more attractive as this kind of device becomes affordable and
easy to handle. This paper contributes to the effort of creating an indoor
positioning system based on low cost depth cameras (Kinect). A method is
proposed to optimize the calibration of the depth cameras, to describe the
multi-camera data fusion and to specify a global positioning projection to
maintain the compatibility with outdoor positioning systems.
  The monitoring of the people trajectories at home is intended for the early
detection of a shift in daily activities which highlights disabilities and loss
of autonomy. This system is meant to improve homecare health management at home
for a better end of life at a sustainable cost for the community.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02574</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02575</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DECOrrelated feature space partitioning for distributed sparse
  regression</dc:title>
 <dc:creator>Wang, Xiangyu</dc:creator>
 <dc:creator>Dunson, David</dc:creator>
 <dc:creator>Leng, Chenlei</dc:creator>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Fitting statistical models is computationally challenging when the sample
size or the dimension of the dataset is huge. An attractive approach for
down-scaling the problem size is to first partition the dataset into subsets
and then fit using distributed algorithms. The dataset can be partitioned
either horizontally (in the sample space) or vertically (in the feature space).
While the majority of the literature focuses on sample space partitioning,
feature space partitioning is more effective when $p\gg n$. Existing methods
for partitioning features, however, are either vulnerable to high correlations
or inefficient in reducing the model dimension. In this paper, we solve these
problems through a new embarrassingly parallel framework named DECO for
distributed variable selection and parameter estimation. In DECO, variables are
first partitioned and allocated to $m$ distributed workers. The decorrelated
subset data within each worker are then fitted via any algorithm designed for
high-dimensional problems. We show that by incorporating the decorrelation
step, DECO can achieve consistent variable selection and parameter estimation
on each subset with (almost) no assumptions. In addition, the convergence rate
is nearly minimax optimal for both sparse and weakly sparse models and does NOT
depend on the partition number $m$. Extensive numerical experiments are
provided to illustrate the performance of the new framework.
</dc:description>
 <dc:description>Comment: Correct legend errors in Figure 3</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02575</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02576</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Progress Towards the Conjecture on APN Functions and Absolutely
  Irreducible Polynomials</dc:title>
 <dc:creator>Delgado, Moises</dc:creator>
 <dc:creator>Janwa, Heeralal</dc:creator>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Algebraic Geometry</dc:subject>
 <dc:subject>94A60, 20C05, 05B10, 11T71, 11G20, 11G25, 12E20, 14E15, 14G15,
  14G20, 14H25</dc:subject>
 <dc:subject>E.4</dc:subject>
 <dc:subject>D.4.6</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  Almost Perfect Nonlinear (APN) functions are very useful in cryptography,
when they are used as S-Boxes, because of their good resistance to differential
cryptanalysis. An APN function $f:\mathbb{F}_{2^n}\rightarrow\mathbb{F}_{2^n}$
is called exceptional APN if it is APN on infinitely many extensions of
$\mathbb{F}_{2^n}$. Aubry, McGuire and Rodier conjectured that the only
exceptional APN functions are the Gold and the Kasami-Welch monomial functions.
They established that a polynomial function of odd degree is not exceptional
APN provided the degree is not a Gold number $(2^k+1)$ or a Kasami-Welch number
$(2^{2k}-2^k+1)$. When the degree of the polynomial function is a Gold number,
several partial results have been obtained [1, 7, 8, 10, 17]. One of the
results in this article is a proof of the relatively primeness of the
multivariate APN polynomial conjecture, in the Gold degree case. This helps us
extend substantially previous results. We prove that Gold degree polynomials of
the form $x^{2^k+1}+h(x)$, where $deg(h)$ is any odd integer (with the natural
exceptions), can not be exceptional APN.
  We also show absolute irreducibility of several classes of multivariate
polynomials over finite fields and discuss their applications.
</dc:description>
 <dc:date>2016-01-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02576</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02586</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tumour ROI Estimation in Ultrasound Images via Radon Barcodes in
  Patients with Locally Advanced Breast Cancer</dc:title>
 <dc:creator>Tizhoosh, Hamid R.</dc:creator>
 <dc:creator>Gangeh, Mehrdad J.</dc:creator>
 <dc:creator>Tadayyon, Hadi</dc:creator>
 <dc:creator>Czarnota, Gregory J.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Quantitative ultrasound (QUS) methods provide a promising framework that can
non-invasively and inexpensively be used to predict or assess the tumour
response to cancer treatment. The first step in using the QUS methods is to
select a region of interest (ROI) inside the tumour in ultrasound images.
Manual segmentation, however, is very time consuming and tedious. In this
paper, a semi-automated approach will be proposed to roughly localize an ROI
for a tumour in ultrasound images of patients with locally advanced breast
cancer (LABC). Content-based barcodes, a recently introduced binary descriptor
based on Radon transform, were used in order to find similar cases and estimate
a bounding box surrounding the tumour. Experiments with 33 B-scan images
resulted in promising results with an accuracy of $81\%$.
</dc:description>
 <dc:description>Comment: To appear in proceedings of The International Symposium on Biomedical
  Imaging (ISBI), April 13-16, 2016, Prague, Czech Republic</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02594</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>GitHub open source project recommendation system</dc:title>
 <dc:creator>Matek, Tadej</dc:creator>
 <dc:creator>Zebec, Svit Timej</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Hosting platforms for software projects can form collaborative social
networks and a prime example of this is GitHub which is arguably the most
popular platform of this kind. An open source project recommendation system
could be a major feature for a platform like GitHub, enabling its users to find
relevant projects in a fast and simple manner. We perform network analysis on a
constructed graph based on GitHub data and present a recommendation system that
uses link prediction.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02594</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02598</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Cooperative output regulation of multi-agent network systems with
  dynamic edges</dc:title>
 <dc:creator>Xiang, Ji</dc:creator>
 <dc:creator>Li, Yanjun</dc:creator>
 <dc:creator>Hill, David J.</dc:creator>
 <dc:subject>Mathematics - Dynamical Systems</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper investigates a new class of linear multi-agent network systems, in
which nodes are coupled by dynamic edges in the sense that each edge has a
dynamic system attached as well. The outputs of the edge dynamic systems form
the external inputs of the node dynamic systems, which are termed &quot;neighboring
inputs&quot; representing the coupling actions between nodes. The outputs of the
node dynamic systems are the inputs of the edge dynamic systems. Several
cooperative output regulation problems are posed, including output
synchronization, output cooperation and master-slave output cooperation. Output
cooperation is specified as making the neighboring input, a weighted sum of
edge outputs, track a predefined trajectory by cooperation of node outputs.
Distributed cooperative output regulation controllers depending on local state
and neighboring inputs are presented, which are designed by combining feedback
passivity theories and the internal model principle. A simulation example on
the cooperative current control of an electrical network illustrates the
potential applications of the analytical results.
</dc:description>
 <dc:description>Comment: 17 pages, 5 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02601</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>What We Don't Know About Spreadsheet Errors Today: The Facts, Why We
  Don't Believe Them, and What We Need to Do</dc:title>
 <dc:creator>Panko, Ray</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Research on spreadsheet errors is substantial, compelling, and unanimous. It
has three simple conclusions. The first is that spreadsheet errors are rare on
a per-cell basis, but in large programs, at least one incorrect bottom-line
value is very likely to be present. The second is that errors are extremely
difficult to detect and correct. The third is that spreadsheet developers and
corporations are highly overconfident in the accuracy of their spreadsheets.
The disconnect between the first two conclusions and the third appears to be
due to the way human cognition works. Most importantly, we are aware of very
few of the errors we make. In addition, while we are proudly aware of errors
that we fix, we have no idea of how many remain, but like Little Jack Horner we
are impressed with our ability to ferret out errors. This paper reviews human
cognition processes and shows first that humans cannot be error free no matter
how hard they try, and second that our intuition about errors and how we can
reduce them is based on appallingly bad knowledge. This paper argues that we
should reject any prescription for reducing errors that has not been rigorously
proven safe and effective. This paper also argues that our biggest need, based
on empirical data, is to do massively more testing than we do now. It suggests
that the code inspection methodology developed in software development is
likely to apply very well to spreadsheet inspection.
</dc:description>
 <dc:description>Comment: 15 Pages, 5 Figures, 3 Tables, some in colour</dc:description>
 <dc:date>2016-02-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02601</dc:identifier>
 <dc:identifier>Proc. 16th EuSpRIG Conf. &quot;Spreadsheet Risk Management&quot; (2015)
  pp79-93 ISBN: 978-1-905404-52-0</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02610</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Metric Dimension of Bounded Tree-length Graphs</dc:title>
 <dc:creator>Belmonte, R&#xe9;my</dc:creator>
 <dc:creator>Fomin, Fedor V.</dc:creator>
 <dc:creator>Golovach, Petr A.</dc:creator>
 <dc:creator>Ramanujan, M. S.</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The notion of resolving sets in a graph was introduced by Slater (1975) and
Harary and Melter (1976) as a way of uniquely identifying every vertex in a
graph. A set of vertices in a graph is a resolving set if for any pair of
vertices x and y there is a vertex in the set which has distinct distances to x
and y. A smallest resolving set in a graph is called a metric basis and its
size, the metric dimension of the graph. The problem of computing the metric
dimension of a graph is a well-known NP-hard problem and while it was known to
be polynomial time solvable on trees, it is only recently that efforts have
been made to understand its computational complexity on various restricted
graph classes. In recent work, Foucaud et al. (2015) showed that this problem
is NP-complete even on interval graphs. They complemented this result by also
showing that it is fixed-parameter tractable (FPT) parameterized by the metric
dimension of the graph. In this work, we show that this FPT result can in fact
be extended to all graphs of bounded tree-length. This includes well-known
classes like chordal graphs, AT-free graphs and permutation graphs. We also
show that this problem is FPT parameterized by the modular-width of the input
graph.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02610</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02612</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sign-Compute-Resolve for Tree Splitting Random Access</dc:title>
 <dc:creator>Goseling, Jasper</dc:creator>
 <dc:creator>Stefanovic, Cedomir</dc:creator>
 <dc:creator>Popovski, Petar</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We present an approach to random access that is based on three elements:
physical-layer network coding (PLNC), signature codes and tree splitting. In
presence of a collision, physical-layer network coding enables the receiver to
decode, i.e. compute the sum of the packets that were transmitted by the
individual users. For each user, the packet consists of the user's signature,
as well as the data that the user wants to communicate. As long as no more than
K users collide, their identities can be recovered from the sum of their
signatures. A tree-splitting algorithm is used to deal with the case that more
than K users collide. We demonstrate that our approach achieves throughput that
tends to 1 rapidly as K increases. We also present results on net data-rate of
the system, showing the impact of the overheads of the constituent elements of
the proposed protocol. We compare the performance of our scheme with an upper
bound that is obtained under the assumption that the active users are a priori
known. Also, we consider an upper bound on the net data-rate for any PLNC based
strategy in which one linear equation per slot is decoded. We show that already
at modest packet lengths, the net data-rate of our scheme becomes close to the
second upper bound, i.e. the overhead of the contention resolution algorithm
and the signature codes vanishes.
</dc:description>
 <dc:description>Comment: This is an extended version of arXiv:1409.6902</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02612</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02617</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive imputation of missing values for incomplete pattern
  classification</dc:title>
 <dc:creator>Liu, Zhun-Ga</dc:creator>
 <dc:creator>Pan, Quan</dc:creator>
 <dc:creator>Dezert, Jean</dc:creator>
 <dc:creator>Martin, Arnaud</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  In classification of incomplete pattern, the missing values can either play a
crucial role in the class determination, or have only little influence (or
eventually none) on the classification results according to the context. We
propose a credal classification method for incomplete pattern with adaptive
imputation of missing values based on belief function theory. At first, we try
to classify the object (incomplete pattern) based only on the available
attribute values. As underlying principle, we assume that the missing
information is not crucial for the classification if a specific class for the
object can be found using only the available information. In this case, the
object is committed to this particular class. However, if the object cannot be
classified without ambiguity, it means that the missing values play a main role
for achieving an accurate classification. In this case, the missing values will
be imputed based on the K-nearest neighbor (K-NN) and self-organizing map (SOM)
techniques, and the edited pattern with the imputation is then classified. The
(original or edited) pattern is respectively classified according to each
training class, and the classification results represented by basic belief
assignments are fused with proper combination rules for making the credal
classification. The object is allowed to belong with different masses of belief
to the specific classes and meta-classes (which are particular disjunctions of
several single classes). The credal classification captures well the
uncertainty and imprecision of classification, and reduces effectively the rate
of misclassifications thanks to the introduction of meta-classes. The
effectiveness of the proposed method with respect to other classical methods is
demonstrated based on several experiments using artificial and real data sets.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02617</dc:identifier>
 <dc:identifier>Pattern Recognition, Elsevier, 2016, 52</dc:identifier>
 <dc:identifier>doi:10.1016/j.patcog.2015.10.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02620</identifier>
 <datestamp>2016-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Scalability and Total Recall with Fast CoveringLSH</dc:title>
 <dc:creator>Pham, Ninh</dc:creator>
 <dc:creator>Pagh, Rasmus</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:description>  Locality-sensitive hashing (LSH) has emerged as the dominant algorithmic
technique for similarity search with strong performance guarantees in
high-dimensional spaces. A drawback of traditional LSH schemes is that they may
have \emph{false negatives}, i.e., the recall is less than 100\%. This limits
the applicability of LSH in settings requiring precise performance guarantees.
Building on the recent theoretical &quot;CoveringLSH&quot; construction that eliminates
false negatives, we propose a fast and practical covering LSH scheme for
Hamming space called \emph{Fast CoveringLSH (fcLSH)}. Inheriting the design
benefits of CoveringLSH our method avoids false negatives and always reports
all near neighbors. Compared to CoveringLSH we achieve an asymptotic
improvement to the hash function computation time from $\mathcal{O}(dL)$ to
$\mathcal{O}(d + L\log{L})$, where $d$ is the dimensionality of data and $L$ is
the number of hash tables. Our experiments on synthetic and real-world data
sets demonstrate that \emph{fcLSH} is comparable (and often superior) to
traditional hashing-based approaches for search radius up to 20 in
high-dimensional Hamming space.
</dc:description>
 <dc:description>Comment: Short version appears in Proceedings of CIKM 2016</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-08-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02620</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02622</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Review of Control Algorithms for Autonomous Quadrotors</dc:title>
 <dc:creator>Zulu, Andrew</dc:creator>
 <dc:creator>John, Samuel</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The quadrotor unmanned aerial vehicle is a great platform for control systems
research as its nonlinear nature and under-actuated configuration make it ideal
to synthesize and analyze control algorithms. After a brief explanation of the
system, several algorithms have been analyzed including their advantages and
disadvantages: PID, Linear Quadratic Regulator (LQR), Sliding mode,
Backstepping, Feedback linearization, Adaptive, Robust, Optimal, L1,
H-infinity, Fuzzy logic and Artificial neutral networks. The conclusion of this
work is a proposal of hybrid systems to be considered as they combine
advantages from more than one control philosophy.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, 1 table</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02622</dc:identifier>
 <dc:identifier>Open Journal of Applied Sciences, 2014, 4, 547-556</dc:identifier>
 <dc:identifier>doi:10.4236/ojapps.2014.414053</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02627</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal and asymptotically optimal NCT reversible circuits by the gate
  types</dc:title>
 <dc:creator>Maslov, Dmitri</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We report optimal and asymptotically optimal reversible circuits composed of
NOT, CNOT, and Toffoli (NCT) gates, keeping the count by the subsets of the
gate types used. This study fine tunes the circuit complexity figures for the
realization of reversible functions via reversible NCT circuits. An important
consequence is a result on the limitation of the use of the $T$-count quantum
circuit metric popular in applications.
</dc:description>
 <dc:description>Comment: 14 pages</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-12-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02627</dc:identifier>
 <dc:identifier>Quantum Information &amp; Computation, 16(13&amp;14):1096-1112, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02629</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Bounds for the Excluded Grid Theorem</dc:title>
 <dc:creator>Chuzhoy, Julia</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>05C83</dc:subject>
 <dc:description>  We study the Excluded Grid Theorem of Robertson and Seymour. This is a
fundamental result in graph theory, that states that there is some function $f:
Z^+\rightarrow Z^+$, such that for all integers $g&gt;0$, every graph of treewidth
at least $f(g)$ contains the $(g\times g)$-grid as a minor. Until recently, the
best known upper bounds on $f$ were super-exponential in $g$. A recent work of
Chekuri and Chuzhoy provided the first polynomial bound, by showing that
treewidth $f(g)=O(g^{98}\operatorname{poly}\log g)$ is sufficient to ensure the
existence of the $(g\times g)$-grid minor in any graph. In this paper we
improve this bound to $f(g)=O(g^{19}\operatorname{poly}\log g)$. We introduce a
number of new techniques, including a conceptually simple and almost entirely
self-contained proof of the theorem that achieves a polynomial bound on $f(g)$.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02629</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02630</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An efficient null space inexact Newton method for hydraulic simulation
  of water distribution networks</dc:title>
 <dc:creator>Abraham, Edo</dc:creator>
 <dc:creator>Stoianov, Ivan</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  Null space Newton algorithms are efficient in solving the nonlinear equations
arising in hydraulic analysis of water distribution networks. In this article,
we propose and evaluate an inexact Newton method that relies on partial updates
of the network pipes' frictional headloss computations to solve the linear
systems more efficiently and with numerical reliability. The update set
parameters are studied to propose appropriate values. Different null space
basis generation schemes are analysed to choose methods for sparse and
well-conditioned null space bases resulting in a smaller update set. The Newton
steps are computed in the null space by solving sparse, symmetric positive
definite systems with sparse Cholesky factorizations. By using the constant
structure of the null space system matrices, a single symbolic factorization in
the Cholesky decomposition is used multiple times, reducing the computational
cost of linear solves. The algorithms and analyses are validated using medium
to large-scale water network models.
</dc:description>
 <dc:description>Comment: 15 pages, 9 figures, Preprint extension of Abraham and Stoianov, 2015
  (https://dx.doi.org/10.1061/(ASCE)HY.1943-7900.0001089), September 2015.
  Includes extended exposition, additional case studies and new simulations and
  analysis</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02630</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02638</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Response to &quot;Comment on 'Zero and negative energy dissipation at
  information-theoretic erasure'&quot;</dc:title>
 <dc:creator>Kish, Laszlo B.</dc:creator>
 <dc:creator>Granqvist, Claes-G.</dc:creator>
 <dc:creator>Khatri, Sunil P.</dc:creator>
 <dc:creator>Peper, Ferdinand</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  We prove that statistical information theoretic quantities, such as
information entropy, cannot generally be interrelated with the lower limit of
energy dissipation during information erasure. We also point out that, in
deterministic and error-free computers, the information entropy of memories
does not change during erasure because its value is always zero. On the other
hand, for information-theoretic erasure - i.e., &quot;thermalization&quot; /
randomization of the memory - the originally zero information entropy (with
deterministic data in the memory) changes after erasure to its maximum value, 1
bit / memory bit, while the energy dissipation is still positive, even at
parameters for which the thermodynamic entropy within the memory cell does not
change. Information entropy does not convert to thermodynamic entropy and to
the related energy dissipation; they are quantities of different physical
nature. Possible specific observations (if any) indicating convertibility are
at most fortuitous and due to the disregard of additional processes that are
present.
</dc:description>
 <dc:description>Comment: Journal of Computational Electronics (Springer), in press (currently
  web-published)</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02638</dc:identifier>
 <dc:identifier>doi:10.1007/s10825-015-0788-8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02644</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Images with Perceptual Similarity Metrics based on Deep
  Networks</dc:title>
 <dc:creator>Dosovitskiy, Alexey</dc:creator>
 <dc:creator>Brox, Thomas</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Image-generating machine learning models are typically trained with loss
functions based on distance in the image space. This often leads to
over-smoothed results. We propose a class of loss functions, which we call deep
perceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of
computing distances in the image space, we compute distances between image
features extracted by deep neural networks. This metric better reflects
perceptually similarity of images and thus leads to better results. We show
three applications: autoencoder training, a modification of a variational
autoencoder, and inversion of deep convolutional networks. In all cases, the
generated images look sharp and resemble natural images.
</dc:description>
 <dc:description>Comment: minor corrections</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02648</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coding in the fork network in the framework of Kolmogorov complexity</dc:title>
 <dc:creator>Romashchenko, Andrei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Many statements from the classic information theory (the theory of Shannon's
entropy) have natural counterparts in the algorithmic information theory (in
the framework of Kolmogorov complexity). In this paper we discuss one simple
instance of the parallelism between Shannon's and Kolmogorov's theories: we
prove in the setting of Kolmogorov complexity a version of Wolf's
characterization of admissible rates for the fork network.
</dc:description>
 <dc:description>Comment: v2: fixed a mistake in the proof of theorem 4</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02648</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02651</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Face Reenactment</dc:title>
 <dc:creator>Garrido, Pablo</dc:creator>
 <dc:creator>Valgaerts, Levi</dc:creator>
 <dc:creator>Rehmsen, Ole</dc:creator>
 <dc:creator>Thormaehlen, Thorsten</dc:creator>
 <dc:creator>Perez, Patrick</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  We propose an image-based, facial reenactment system that replaces the face
of an actor in an existing target video with the face of a user from a source
video, while preserving the original target performance. Our system is fully
automatic and does not require a database of source expressions. Instead, it is
able to produce convincing reenactment results from a short source video
captured with an off-the-shelf camera, such as a webcam, where the user
performs arbitrary facial gestures. Our reenactment pipeline is conceived as
part image retrieval and part face transfer: The image retrieval is based on
temporal clustering of target frames and a novel image matching metric that
combines appearance and motion to select candidate frames from the source
video, while the face transfer uses a 2D warping strategy that preserves the
user's identity. Our system excels in simplicity as it does not rely on a 3D
face model, it is robust under head motion and does not require the source and
target performance to be similar. We show convincing reenactment results for
videos that we recorded ourselves and for low-quality footage taken from the
Internet.
</dc:description>
 <dc:description>Comment: Proceedings of the 2014 IEEE Conference on Computer Vision and
  Pattern Recognition (8 pages)</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02651</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2014.537</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02656</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>LSTM Deep Neural Networks Postfiltering for Improving the Quality of
  Synthetic Voices</dc:title>
 <dc:creator>Coto-Jim&#xe9;nez, Marvin</dc:creator>
 <dc:creator>Goddard-Close, John</dc:creator>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Recent developments in speech synthesis have produced systems capable of
outcome intelligible speech, but now researchers strive to create models that
more accurately mimic human voices. One such development is the incorporation
of multiple linguistic styles in various languages and accents.
  HMM-based Speech Synthesis is of great interest to many researchers, due to
its ability to produce sophisticated features with small footprint. Despite
such progress, its quality has not yet reached the level of the predominant
unit-selection approaches that choose and concatenate recordings of real
speech. Recent efforts have been made in the direction of improving these
systems.
  In this paper we present the application of Long-Short Term Memory Deep
Neural Networks as a Postfiltering step of HMM-based speech synthesis, in order
to obtain closer spectral characteristics to those of natural speech. The
results show how HMM-voices could be improved using this approach.
</dc:description>
 <dc:description>Comment: 5 pages, 5 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02656</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02658</identifier>
 <datestamp>2017-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graying the black box: Understanding DQNs</dc:title>
 <dc:creator>Zahavy, Tom</dc:creator>
 <dc:creator>Zrihem, Nir Ben</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In recent years there is a growing interest in using deep representations for
reinforcement learning. In this paper, we present a methodology and tools to
analyze Deep Q-networks (DQNs) in a non-blind matter. Moreover, we propose a
new model, the Semi Aggregated Markov Decision Process (SAMDP), and an
algorithm that learns it automatically. The SAMDP model allows us to identify
spatio-temporal abstractions directly from features and may be used as a
sub-goal detector in future work. Using our tools we reveal that the features
learned by DQNs aggregate the state space in a hierarchical fashion, explaining
its success. Moreover, we are able to understand and describe the policies
learned by DQNs for three different Atari2600 games and suggest ways to
interpret, debug and optimize deep neural networks in reinforcement learning.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2017-04-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02658</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02660</identifier>
 <datestamp>2016-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploiting Cyclic Symmetry in Convolutional Neural Networks</dc:title>
 <dc:creator>Dieleman, Sander</dc:creator>
 <dc:creator>De Fauw, Jeffrey</dc:creator>
 <dc:creator>Kavukcuoglu, Koray</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Many classes of images exhibit rotational symmetry. Convolutional neural
networks are sometimes trained using data augmentation to exploit this, but
they are still required to learn the rotation equivariance properties from the
data. Encoding these properties into the network architecture, as we are
already used to doing for translation equivariance by using convolutional
layers, could result in a more efficient use of the parameter budget by
relieving the model from learning them. We introduce four operations which can
be inserted into neural network models as layers, and which can be combined to
make these models partially equivariant to rotations. They also enable
parameter sharing across different orientations. We evaluate the effect of
these architectural modifications on three datasets which exhibit rotational
symmetry and demonstrate improved performance with smaller models.
</dc:description>
 <dc:description>Comment: 10 pages, 6 figures, accepted for publication at ICML 2016</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02660</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02665</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The happiness paradox: your friends are happier than you</dc:title>
 <dc:creator>Bollen, Johan</dc:creator>
 <dc:creator>Gon&#xe7;alves, Bruno</dc:creator>
 <dc:creator>van de Leemput, Ingrid</dc:creator>
 <dc:creator>Ruan, Guangchen</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Most individuals in social networks experience a so-called Friendship
Paradox: they are less popular than their friends on average. This effect may
explain recent findings that widespread social network media use leads to
reduced happiness. However the relation between popularity and happiness is
poorly understood. A Friendship paradox does not necessarily imply a Happiness
paradox where most individuals are less happy than their friends. Here we
report the first direct observation of a significant Happiness Paradox in a
large-scale online social network of $39,110$ Twitter users. Our results reveal
that popular individuals are indeed happier and that a majority of individuals
experience a significant Happiness paradox. The magnitude of the latter effect
is shaped by complex interactions between individual popularity, happiness, and
the fact that users cluster assortatively by level of happiness. Our results
indicate that the topology of online social networks and the distribution of
happiness in some populations can cause widespread psycho-social effects that
affect the well-being of billions of individuals.
</dc:description>
 <dc:description>Comment: 15 pages, 3 figures, 2 tables</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02665</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02666</identifier>
 <datestamp>2017-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Variational Analysis of Stochastic Gradient Algorithms</dc:title>
 <dc:creator>Mandt, Stephan</dc:creator>
 <dc:creator>Hoffman, Matthew D.</dc:creator>
 <dc:creator>Blei, David M.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Stochastic Gradient Descent (SGD) is an important algorithm in machine
learning. With constant learning rates, it is a stochastic process that, after
an initial phase of convergence, generates samples from a stationary
distribution. We show that SGD with constant rates can be effectively used as
an approximate posterior inference algorithm for probabilistic modeling.
Specifically, we show how to adjust the tuning parameters of SGD such as to
match the resulting stationary distribution to the posterior. This analysis
rests on interpreting SGD as a continuous-time stochastic process and then
minimizing the Kullback-Leibler divergence between its stationary distribution
and the target posterior. (This is in the spirit of variational inference.) In
more detail, we model SGD as a multivariate Ornstein-Uhlenbeck process and then
use properties of this process to derive the optimal parameters. This
theoretical framework also connects SGD to modern scalable inference
algorithms; we analyze the recently proposed stochastic gradient Fisher scoring
under this perspective. We demonstrate that SGD with properly chosen constant
rates gives a new way to optimize hyperparameters in probabilistic models.
</dc:description>
 <dc:description>Comment: 8 pages, 3 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02666</dc:identifier>
 <dc:identifier>International Conference on Machine Learning (ICML 2016), p.
  354--363</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02670</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Model and Objective Separation with Conditional Lower Bounds:
  Disjunction is Harder than Conjunction</dc:title>
 <dc:creator>Chatterjee, Krishnendu</dc:creator>
 <dc:creator>Dvo&#x159;&#xe1;k, Wolfgang</dc:creator>
 <dc:creator>Henzinger, Monika</dc:creator>
 <dc:creator>Loitzenbauer, Veronika</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Given a model of a system and an objective, the model-checking question asks
whether the model satisfies the objective. We study polynomial-time problems in
two classical models, graphs and Markov Decision Processes (MDPs), with respect
to several fundamental $\omega$-regular objectives, e.g., Rabin and Streett
objectives. For many of these problems the best-known upper bounds are
quadratic or cubic, yet no super-linear lower bounds are known. In this work
our contributions are two-fold: First, we present several improved algorithms,
and second, we present the first conditional super-linear lower bounds based on
widely believed assumptions about the complexity of CNF-SAT and combinatorial
Boolean matrix multiplication. A separation result for two models with respect
to an objective means a conditional lower bound for one model that is strictly
higher than the existing upper bound for the other model, and similarly for two
objectives with respect to a model. Our results establish the following
separation results: (1) A separation of models (graphs and MDPs) for
disjunctive queries of reachability and B\&quot;uchi objectives. (2) Two kinds of
separations of objectives, both for graphs and MDPs, namely, (2a) the
separation of dual objectives such as reachability/safety (for disjunctive
questions) and Streett/Rabin objectives, and (2b) the separation of conjunction
and disjunction of multiple objectives of the same type such as safety,
B\&quot;uchi, and coB\&quot;uchi. In summary, our results establish the first model and
objective separation results for graphs and MDPs for various classical
$\omega$-regular objectives. Quite strikingly, we establish conditional lower
bounds for the disjunction of objectives that are strictly higher than the
existing upper bounds for the conjunction of the same objectives.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02670</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02672</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning to Communicate to Solve Riddles with Deep Distributed Recurrent
  Q-Networks</dc:title>
 <dc:creator>Foerster, Jakob N.</dc:creator>
 <dc:creator>Assael, Yannis M.</dc:creator>
 <dc:creator>de Freitas, Nando</dc:creator>
 <dc:creator>Whiteson, Shimon</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We propose deep distributed recurrent Q-networks (DDRQN), which enable teams
of agents to learn to solve communication-based coordination tasks. In these
tasks, the agents are not given any pre-designed communication protocol.
Therefore, in order to successfully communicate, they must first automatically
develop and agree upon their own communication protocol. We present empirical
results on two multi-agent learning problems based on well-known riddles,
demonstrating that DDRQN can successfully solve such tasks and discover elegant
communication protocols to do so. To our knowledge, this is the first time deep
reinforcement learning has succeeded in learning communication protocols. In
addition, we present ablation experiments that confirm that each of the main
components of the DDRQN architecture are critical to its success.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02672</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02673</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Sparsity by NUV-EM, Gaussian Message Passing, and Kalman Smoothing</dc:title>
 <dc:creator>Loeliger, Hans-Andrea</dc:creator>
 <dc:creator>Bruderer, Lukas</dc:creator>
 <dc:creator>Malmberg, Hampus</dc:creator>
 <dc:creator>Wadehn, Federico</dc:creator>
 <dc:creator>Zalmai, Nour</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Normal priors with unknown variance (NUV) have long been known to promote
sparsity and to blend well with parameter learning by expectation maximization
(EM). In this paper, we advocate this approach for linear state space models
for applications such as the estimation of impulsive signals, the detection of
localized events, smoothing with occasional jumps in the state space, and the
detection and removal of outliers. The actual computations boil down to
multivariate-Gaussian message passing algorithms that are closely related to
Kalman smoothing. We give improved tables of Gaussian-message computations from
which such algorithms are easily synthesized, and we point out two preferred
such algorithms.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02673</dc:identifier>
 <dc:identifier>2016 Information Theory &amp; Applications Workshop (ITA), La Jolla,
  CA, Jan. 31 - Feb. 5, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02675</identifier>
 <datestamp>2016-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance of 1-D and 2-D Lattice Boltzmann (LB) in Solution of the
  Shock Tube Problem</dc:title>
 <dc:creator>Komeili, M.</dc:creator>
 <dc:creator>Mirzaei, M.</dc:creator>
 <dc:creator>Shabouei, M.</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  In this paper we presented a lattice Boltzmann with square grid for
compressible flow problems. Triple level velocity is considered for each cell.
Migration step use discrete velocity but continuous parameters are utilized to
calculate density, velocity, and energy. So, we called this semi-discrete
method. To evaluate the performance of the method the well-known shock tube
problem is solved, using 1-D and 2-D version of the lattice Boltzmann method.
The results of these versions are compared with each other and with the results
of the analytical solution.
</dc:description>
 <dc:description>Comment: in International Conference on Fascinating Advancement in Mechanical
  Engineering (FAME2008), India, 2008</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-09-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02675</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02680</identifier>
 <datestamp>2016-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Numerical Solution of Cylindrically Converging Shock Waves</dc:title>
 <dc:creator>Shabouei, M.</dc:creator>
 <dc:creator>Ebrahimi, R.</dc:creator>
 <dc:creator>Body, K. Mazaheri</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  The cylindrically converging shock wave was numerically simulated by solving
the Euler equations in cylindrical coordinates with TVD scheme and MUSCL
approach, using Roe's approximate Riemann solver and super-bee nonlinear
limiter. The present study used the in house code developed for this purpose.
The behavior of the solution in the vicinity of axis is investigated and the
results of the numerical solution are compared with the computed data given by
Payne, Lapidus, Abarbanel, and Goldberg, Sod, and Leutioff et al.
</dc:description>
 <dc:description>Comment: International Conference on Fascinating Advancement in Mechanical
  Engineering (FAME08), India, 2008</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02680</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02685</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Predicting Clinical Events by Combining Static and Dynamic Information
  Using Recurrent Neural Networks</dc:title>
 <dc:creator>Esteban, Crist&#xf3;bal</dc:creator>
 <dc:creator>Staeck, Oliver</dc:creator>
 <dc:creator>Yang, Yinchong</dc:creator>
 <dc:creator>Tresp, Volker</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  In clinical data sets we often find static information (e.g. patient gender,
blood type, etc.) combined with sequences of data that are recorded during
multiple hospital visits (e.g. medications prescribed, tests performed, etc.).
Recurrent Neural Networks (RNNs) have proven to be very successful for
modelling sequences of data in many areas of Machine Learning. In this work we
present an approach based on RNNs, specifically designed for the clinical
domain, that combines static and dynamic information in order to predict future
events. We work with a database collected in the Charit\'{e} Hospital in Berlin
that contains complete information concerning patients that underwent a kidney
transplantation. After the transplantation three main endpoints can occur:
rejection of the kidney, loss of the kidney and death of the patient. Our goal
is to predict, based on information recorded in the Electronic Health Record of
each patient, whether any of those endpoints will occur within the next six or
twelve months after each visit to the clinic. We compared different types of
RNNs that we developed for this work, with a model based on a Feedforward
Neural Network and a Logistic Regression model. We found that the RNN that we
developed based on Gated Recurrent Units provides the best performance for this
task. We also used the same models for a second task, i.e., next event
prediction, and found that here the model based on a Feedforward Neural Network
outperformed the other models. Our hypothesis is that long-term dependencies
are not as relevant in this task.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02685</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02690</identifier>
 <datestamp>2016-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Beamforming Against Direction-of-Arrival Mismatch Using
  Subspace-Constrained Diagonal Loading</dc:title>
 <dc:creator>Tsai, Yueh-Ting</dc:creator>
 <dc:creator>Su, Borching</dc:creator>
 <dc:creator>Tsao, Yu</dc:creator>
 <dc:creator>Wang, Syu-Siang</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this study, a new subspace-constrained diagonal loading (SSC-DL) method is
presented for robust beamforming against the issue of a mismatched direction of
arrival (DoA), based on an extension to the well known diagonal loading (DL)
technique. One important difference of the proposed SSC-DL from conventional DL
is that it imposes an additional constraint to restrict the optimal weight
vector within a subspace whose basis vectors are determined by a number of
angles neighboring to the estimated DoA. Unlike many existing methods which
resort to a beamwidth expansion, the weight vector produced by SSC-DL has a
relatively small beamwidth around the DoA of the target signal. Yet, the SSC-DL
beamformer has a great interference suppression level, thereby achieving an
improved overall SINR performance. Simulation results suggest the proposed
method has a near-to-optimal SINR performance.
</dc:description>
 <dc:description>Comment: 9 pages, 14 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02690</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02692</identifier>
 <datestamp>2016-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Science on YouTube: What users find when they search for climate science
  and climate manipulation</dc:title>
 <dc:creator>Allgaier, Joachim</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  Online video-sharing sites such as YouTube are very popular and also used by
a lot of people to obtain knowledge and information, also on science, health
and technology. Technically they could be valuable tools for the public
communication of science and technology, but the users of YouTube are also
confronted with conspiracy theories and erroneous and misleading information
that deviates from scientific consensus views. This contribution details the
results of a study that investigates what kind of information users find when
they are searching for climate science and climate manipulation topics on
YouTube and whether this information corresponds with or challenges scientific
consensus views. An innovative methodological approach using the anonymization
network Tor is introduced for drawing randomized samples of YouTube videos.
This approach was used to select and examine a sample of 140 YouTube videos on
climate topics.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02692</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02695</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-Bit Messages are Sufficient to Implement Atomic Read/Write Registers
  in Crash-prone Systems</dc:title>
 <dc:creator>Most&#xe9;faoui, Achour</dc:creator>
 <dc:creator>Raynal, Michel</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Atomic registers are certainly the most basic objects of computing science.
Their implementation on top of an n-process asynchronous message-passing system
has received a lot of attention. It has been shown that t \textless{} n/2
(where t is the maximal number of processes that may crash) is a necessary and
sufficient requirement to build an atomic register on top of a crash-prone
asynchronous message-passing system. Considering such a context, this paper
presents an algorithm which implements a single-writer multi-reader atomic
register with four message types only, and where no message needs to carry
control information in addition to its type. Hence, two bits are sufficient to
capture all the control information carried by all the implementation messages.
Moreover, the messages of two types need to carry a data value while the
messages of the two other types carry no value at all. As far as we know, this
algorithm is the first with such an optimality property on the size of control
information carried by messages. It is also particularly efficient from a time
complexity point of view.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02695</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02697</identifier>
 <datestamp>2017-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Practical Black-Box Attacks against Machine Learning</dc:title>
 <dc:creator>Papernot, Nicolas</dc:creator>
 <dc:creator>McDaniel, Patrick</dc:creator>
 <dc:creator>Goodfellow, Ian</dc:creator>
 <dc:creator>Jha, Somesh</dc:creator>
 <dc:creator>Celik, Z. Berkay</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning (ML) models, e.g., deep neural networks (DNNs), are
vulnerable to adversarial examples: malicious inputs modified to yield
erroneous model outputs, while appearing unmodified to human observers.
Potential attacks include having malicious content like malware identified as
legitimate or controlling vehicle behavior. Yet, all existing adversarial
example attacks require knowledge of either the model internals or its training
data. We introduce the first practical demonstration of an attacker controlling
a remotely hosted DNN with no such knowledge. Indeed, the only capability of
our black-box adversary is to observe labels given by the DNN to chosen inputs.
Our attack strategy consists in training a local model to substitute for the
target DNN, using inputs synthetically generated by an adversary and labeled by
the target DNN. We use the local substitute to craft adversarial examples, and
find that they are misclassified by the targeted DNN. To perform a real-world
and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online
deep learning API. We find that their DNN misclassifies 84.24% of the
adversarial examples crafted with our substitute. We demonstrate the general
applicability of our strategy to many ML techniques by conducting the same
attack against models hosted by Amazon and Google, using logistic regression
substitutes. They yield adversarial examples misclassified by Amazon and Google
at rates of 96.19% and 88.94%. We also find that this black-box attack strategy
is capable of evading defense strategies previously found to make adversarial
example crafting harder.
</dc:description>
 <dc:description>Comment: Proceedings of the 2017 ACM Asia Conference on Computer and
  Communications Security, Abu Dhabi, UAE</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2017-03-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02697</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02698</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Defining Cross-Cloud Systems</dc:title>
 <dc:creator>Elkhatib, Yehia</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recent years have seen an increasing number of cross-cloud architectures,
i.e. systems that span across cloud provisioning boundaries. However, the cloud
computing world still lacks any standards in terms of programming interfaces,
which has a knock-on effect on the costs associated with interoperability and
severely limits the flexibility and portability of applications and virtual
infrastructures. This paper outlines the different types of cross-cloud
systems, and the associated design decisions.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02698</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02701</identifier>
 <datestamp>2017-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compressed Online Dictionary Learning for Fast fMRI Decomposition</dc:title>
 <dc:creator>Mensch, Arthur</dc:creator>
 <dc:creator>Varoquaux, Ga&#xeb;l</dc:creator>
 <dc:creator>Thirion, Bertrand</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present a method for fast resting-state fMRI spatial decomposi-tions of
very large datasets, based on the reduction of the temporal dimension before
applying dictionary learning on concatenated individual records from groups of
subjects. Introducing a measure of correspondence between spatial
decompositions of rest fMRI, we demonstrates that time-reduced dictionary
learning produces result as reliable as non-reduced decompositions. We also
show that this reduction significantly improves computational scalability.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02701</dc:identifier>
 <dc:identifier>doi:10.1109/ISBI.2016.7493501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02704</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrated Interleaved Codes as Locally Recoverable Codes: Properties
  and Performance</dc:title>
 <dc:creator>Blaum, Mario</dc:creator>
 <dc:creator>Hetzler, Steven R.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Considerable interest has been paid in recent literature to codes combining
local and global properties for erasure correction. Applications are in cloud
type of implementations, in which fast recovery of a failed storage device is
important, but additional protection is required in order to avoid data loss,
and in RAID type of architectures, in which total device failures coexist with
silent failures at the page or sector level in each device. Existing solutions
to these problems require in general relatively large finite fields. The
techniques of Integrated Interleaved Codes (which are closely related to
Generalized Concatenated Codes) are proposed to reduce significantly the size
of the finite field, and it is shown that when the parameters of these codes
are judiciously chosen, their performance may be competitive with the one of
codes optimizing the minimum distance.
</dc:description>
 <dc:description>Comment: 24 pages, 5 figures and 3 tables</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02704</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02706</identifier>
 <datestamp>2016-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Decoy Bandits Dueling on a Poset</dc:title>
 <dc:creator>Audiffren, Julien</dc:creator>
 <dc:creator>Liva, Ralaivola</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We adress the problem of dueling bandits defined on partially ordered sets,
or posets. In this setting, arms may not be comparable, and there may be
several (incomparable) optimal arms. We propose an algorithm, UnchainedBandits,
that efficiently finds the set of optimal arms of any poset even when pairs of
comparable arms cannot be distinguished from pairs of incomparable arms, with a
set of minimal assumptions. This algorithm relies on the concept of decoys,
which stems from social psychology. For the easier case where the
incomparability information may be accessible, we propose a second algorithm,
SlicingBandits, which takes advantage of this information and achieves a very
significant gain of performance compared to UnchainedBandits. We provide
theoretical guarantees and experimental evaluation for both algorithms.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-06-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02710</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strategic disclosure of opinions on a social network</dc:title>
 <dc:creator>Grandi, Umberto</dc:creator>
 <dc:creator>Lorini, Emiliano</dc:creator>
 <dc:creator>Perrussel, Laurent</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  We study the strategic aspects of social influence in a society of agents
linked by a trust network, introducing a new class of games called games of
influence. A game of influence is an infinite repeated game with incomplete
information in which, at each stage of interaction, an agent can make her
opinions visible (public) or invisible (private) in order to influence other
agents' opinions. The influence process is mediated by a trust network, as we
assume that the opinion of a given agent is only affected by the opinions of
those agents that she considers trustworthy (i.e., the agents in the trust
network that are directly linked to her). Each agent is endowed with a goal,
expressed in a suitable temporal language inspired from linear temporal logic
(LTL). We show that games of influence provide a simple abstraction to explore
the effects of the trust network structure on the agents' behaviour, by
considering solution concepts from game-theory such as Nash equilibrium, weak
dominance and winning strategies.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02710</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02715</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the notion of &quot;von Neumann vicious circle&quot; coined by John Backus</dc:title>
 <dc:creator>Ambroszkiewicz, Stanislaw</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>03D</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  &quot;The von Neumann vicious circle&quot; means that non-von Neumann computer
architectures cannot be developed because of the lack of widely available and
effective non-von Neumann languages. New languages cannot be created because of
lack of conceptual foundations for non-von Neumann architectures. The reason is
that programming languages are high-level abstract isomorphic copies of von
Neumann computer architectures. This constitutes the current paradigm in
Computer Science. The paradigm is equivalent to the predominant view that
computations on higher order objects (functionals) can be done only
symbolically, i.e. by term rewriting. The paper is a short introduction to the
papers arXiv:1501.03043 and arXiv:1510.02787 trying to break the paradigm by
introducing a framework that may be seen as a higher order functional HDL
(Hardware Description Language).
</dc:description>
 <dc:description>Comment: In this version (March 7, 2016) only small error in Fig. 3 was
  removed. Keywords: von Neumann bottleneck, von Neumann vicious circle,
  non-von Neumann computer architectures, lazy evaluation, higher order
  functionals, functional programming languages, higher order HDL (Hardware
  Description Language)</dc:description>
 <dc:date>2016-02-03</dc:date>
 <dc:date>2016-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02715</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02718</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of Directionality on Interference Mitigation in Full-Duplex
  Cellular Network</dc:title>
 <dc:creator>Psomas, Constantinos</dc:creator>
 <dc:creator>Mohammadi, Mohammadali</dc:creator>
 <dc:creator>Krikidis, Ioannis</dc:creator>
 <dc:creator>Suraweera, Himal A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider two fundamental full-duplex (FD) architectures,
two-node and three-node, in the context of cellular networks where the
terminals employ directional antennas. The simultaneous transmission and
reception of data in non-orthogonal channels makes FD radio a potential
solution for the currently limited spectrum. However, its implementation
generates high levels of interference either in the form of loopback
interference (LI) from the output to the input antenna of a transceiver or in
the form of co-channel interference in large-scale multicell networks due to
the large number of active links. Using a stochastic geometry model, we
investigate how directional antennas can control and mitigate the co-channel
interference. Furthermore, we provide a model which characterizes the way
directional antennas manage the LI in order to passively suppress it. Our
results show that both architectures can benefit significantly by the
employment of directional antennas. Finally, we consider the case where both
architectures are employed in the network and derive the optimal values for the
density fraction of each architecture which maximize the success probability
and the network throughput.
</dc:description>
 <dc:description>Comment: to appear in IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-11-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02720</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multimodal Remote Sensing Image Registration with Accuracy Estimation at
  Local and Global Scales</dc:title>
 <dc:creator>Uss, M. L.</dc:creator>
 <dc:creator>Vozel, B.</dc:creator>
 <dc:creator>Lukin, V. V.</dc:creator>
 <dc:creator>Chehdi, K.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  This paper focuses on potential accuracy of remote sensing images
registration. We investigate how this accuracy can be estimated without ground
truth available and used to improve registration quality of mono- and
multi-modal pair of images. At the local scale of image fragments, the
Cramer-Rao lower bound (CRLB) on registration error is estimated for each local
correspondence between coarsely registered pair of images. This CRLB is defined
by local image texture and noise properties. Opposite to the standard approach,
where registration accuracy is only evaluated at the output of the registration
process, such valuable information is used by us as an additional input
knowledge. It greatly helps detecting and discarding outliers and refining the
estimation of geometrical transformation model parameters. Based on these
ideas, a new area-based registration method called RAE (Registration with
Accuracy Estimation) is proposed. In addition to its ability to automatically
register very complex multimodal image pairs with high accuracy, the RAE method
provides registration accuracy at the global scale as covariance matrix of
estimation error of geometrical transformation model parameters or as
point-wise registration Standard Deviation. This accuracy does not depend on
any ground truth availability and characterizes each pair of registered images
individually. Thus, the RAE method can identify image areas for which a
predefined registration accuracy is guaranteed. The RAE method is proved
successful with reaching subpixel accuracy while registering eight complex
mono/multimodal and multitemporal image pairs including optical to optical,
optical to radar, optical to Digital Elevation Model (DEM) images and DEM to
radar cases. Other methods employed in comparisons fail to provide in a stable
manner accurate results on the same test cases.
</dc:description>
 <dc:description>Comment: 48 pages, 8 figures, 5 tables, 51 references Revised arguments in
  sections 2 and 3. Additional test cases added in Section 4; comparison with
  the state-of-the-art improved. References added. Conclusions unchanged.
  Proofread</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02720</dc:identifier>
 <dc:identifier>doi:10.1109/TGRS.2016.2587321</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02722</identifier>
 <datestamp>2016-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>PAC Reinforcement Learning with Rich Observations</dc:title>
 <dc:creator>Krishnamurthy, Akshay</dc:creator>
 <dc:creator>Agarwal, Alekh</dc:creator>
 <dc:creator>Langford, John</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We propose and study a new model for reinforcement learning with rich
observations, generalizing contextual bandits to sequential decision making.
These models require an agent to take actions based on observations (features)
with the goal of achieving long-term performance competitive with a large set
of policies. To avoid barriers to sample-efficient learning associated with
large observation spaces and general POMDPs, we focus on problems that can be
summarized by a small number of hidden states and have long-term rewards that
are predictable by a reactive function class. In this setting, we design and
analyze a new reinforcement learning algorithm, Least Squares Value Elimination
by Exploration. We prove that the algorithm learns near optimal behavior after
a number of episodes that is polynomial in all relevant parameters, logarithmic
in the number of policies, and independent of the size of the observation
space. Our result provides theoretical justification for reinforcement learning
with function approximation.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-10-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02722</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02726</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local and Global Convergence of a General Inertial Proximal Splitting
  Scheme</dc:title>
 <dc:creator>Johnstone, Patrick R.</dc:creator>
 <dc:creator>Moulin, Pierre</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:description>  This paper is concerned with convex composite minimization problems in a
Hilbert space. In these problems, the objective is the sum of two closed,
proper, and convex functions where one is smooth and the other admits a
computationally inexpensive proximal operator. We analyze a general family of
inertial proximal splitting algorithms (GIPSA) for solving such problems. We
establish finiteness of the sum of squared increments of the iterates and
optimality of the accumulation points. Weak convergence of the entire sequence
then follows if the minimum is attained. Our analysis unifies and extends
several previous results.
  We then focus on $\ell_1$-regularized optimization, which is the ubiquitous
special case where the nonsmooth term is the $\ell_1$-norm. For certain
parameter choices, GIPSA is amenable to a local analysis for this problem. For
these choices we show that GIPSA achieves finite &quot;active manifold
identification&quot;, i.e. convergence in a finite number of iterations to the
optimal support and sign, after which GIPSA reduces to minimizing a local
smooth function. Local linear convergence then holds under certain conditions.
We determine the rate in terms of the inertia, stepsize, and local curvature.
Our local analysis is applicable to certain recent variants of the Fast
Iterative Shrinkage-Thresholding Algorithm (FISTA), for which we establish
active manifold identification and local linear convergence. Our analysis
motivates the use of a momentum restart scheme in these FISTA variants to
obtain the optimal local linear convergence rate.
</dc:description>
 <dc:description>Comment: 33 pages 1 figure</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02726</dc:identifier>
 <dc:identifier>doi:10.1007/s10589-017-9896-7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02737</identifier>
 <datestamp>2016-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Low-Rank Positive Semidefinite Matrix Recovery from Corrupted Rank-One
  Measurements</dc:title>
 <dc:creator>Li, Yuanxin</dc:creator>
 <dc:creator>Sun, Yue</dc:creator>
 <dc:creator>Chi, Yuejie</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We study the problem of estimating a low-rank positive semidefinite (PSD)
matrix from a set of rank-one measurements using sensing vectors composed of
i.i.d. standard Gaussian entries, which are possibly corrupted by arbitrary
outliers. This problem arises from applications such as phase retrieval,
covariance sketching, quantum space tomography, and power spectrum estimation.
We first propose a convex optimization algorithm that seeks the PSD matrix with
the minimum $\ell_1$-norm of the observation residual. The advantage of our
algorithm is that it is free of parameters, therefore eliminating the need for
tuning parameters and allowing easy implementations. We establish that with
high probability, a low-rank PSD matrix can be exactly recovered as soon as the
number of measurements is large enough, even when a fraction of the
measurements are corrupted by outliers with arbitrary magnitudes. Moreover, the
recovery is also stable against bounded noise. With the additional information
of an upper bound of the rank of the PSD matrix, we propose another non-convex
algorithm based on subgradient descent that demonstrates excellent empirical
performance in terms of computational efficiency and accuracy.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-08-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02737</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2620109</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02739</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Determining if Tree-based Networks Contain Fixed Trees</dc:title>
 <dc:creator>Anaya, Maria</dc:creator>
 <dc:creator>Anipchenko-Ulaj, Olga</dc:creator>
 <dc:creator>Ashfaq, Aisha</dc:creator>
 <dc:creator>Chiu, Joyce</dc:creator>
 <dc:creator>Kaiser, Mahedi</dc:creator>
 <dc:creator>Ohsawa, Max Shoji</dc:creator>
 <dc:creator>Owen, Megan</dc:creator>
 <dc:creator>Pavlechko, Ella</dc:creator>
 <dc:creator>John, Katherine St.</dc:creator>
 <dc:creator>Suleria, Shivam</dc:creator>
 <dc:creator>Thompson, Keith</dc:creator>
 <dc:creator>Yap, Corrine</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We address an open question of Francis and Steel about phylogenetic networks
and trees. They give a polynomial time algorithm to decide if a phylogenetic
network, N, is tree-based and pose the problem: given a fixed tree T and
network N, is N based on T? We show that it is NP-hard to decide, by reduction
from 3-Dimensional Matching (3DM), and further, that the problem is fixed
parameter tractable.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02739</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02740</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toom-Cook Multiplication: Some Theoretical and Practical Aspects</dc:title>
 <dc:creator>Kronenburg, M. J.</dc:creator>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Toom-Cook multiprecision multiplication is a well-known multiprecision
multiplication method, which can make use of multiprocessor systems. In this
paper the Toom-Cook complexity is derived, some explicit proofs of the
Toom-Cook interpolation method are given, the even-odd method for interpolation
is explained, and certain aspects of a 32-bit C++ and assembler implementation,
which is in development, are discussed. A performance graph of this
implementation is provided. The Toom-Cook method can also be used to
multithread other types of multiplication, which is demonstrated for 32-bit GMP
FFT multiplication.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02740</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02743</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The IMP game: Learnability, approximability and adversarial learning
  beyond $\Sigma^0_1$</dc:title>
 <dc:creator>Brand, Michael</dc:creator>
 <dc:creator>Dowe, David L.</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>68Q32 (Primary) 68Q05, 68T42, 68T05</dc:subject>
 <dc:subject>F.1.1</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  We introduce a problem set-up we call the Iterated Matching Pennies (IMP)
game and show that it is a powerful framework for the study of three problems:
adversarial learnability, conventional (i.e., non-adversarial) learnability and
approximability. Using it, we are able to derive the following theorems. (1) It
is possible to learn by example all of $\Sigma^0_1 \cup \Pi^0_1$ as well as
some supersets; (2) in adversarial learning (which we describe as a
pursuit-evasion game), the pursuer has a winning strategy (in other words,
$\Sigma^0_1$ can be learned adversarially, but $\Pi^0_1$ not); (3) some
languages in $\Pi^0_1$ cannot be approximated by any language in $\Sigma^0_1$.
  We show corresponding results also for $\Sigma^0_i$ and $\Pi^0_i$ for
arbitrary $i$.
</dc:description>
 <dc:description>Comment: 23 pages</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02743</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02744</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The physical and circuit-theoretic significance of the Memristor : Full
  version</dc:title>
 <dc:creator>Gluskin, Emanuel</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:description>  It is observed that the inductive and capacitive features of the memristor
reflect (and are a quintessence of) such features of any resistor. The very
presence of the voltage and current state variables, associated by their
electrodynamics sense with electrical and magnetic fields, in the resistive
characteristic v = f(i), forces any resister to accumulate some magnetic and
electrostatic fields and energies around itself, i.e. L and C elements are
always present. From the circuit-theoretic point of view, the role of the
memristor is seen, first of all, in the elimination of the use of a unique
v(i). This makes circuits with hysteresis characteristics relevant, and also
suggests that the concept of memristor should influence the basic problem of
definition of nonlinearity. Since the memristor mainly originates from the
resistor, it was found necessary to overview some unusual cases of resistive
circuits. The present opinion is that the framework of basic circuit theory and
its connection with applications should be logically expanded in order to
naturally include the new element.
</dc:description>
 <dc:description>Comment: 23 pages, 6 figures</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02744</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02747</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Independent sets and cuts in large-girth regular graphs</dc:title>
 <dc:creator>Cs&#xf3;ka, Endre</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a local algorithm producing an independent set of expected size
$0.44533n$ on large-girth 3-regular graphs and $0.40407n$ on large-girth
4-regular graphs. We also construct a cut (or bisection or bipartite subgraph)
with $1.34105n$ edges on large-girth 3-regular graphs. These decrease the gaps
between the best known upper and lower bounds from $0.0178$ to $0.01$, from
$0.0242$ to $0.0123$ and from $0.0724$ to $0.0616$, respectively. We are using
local algorithms, therefore, the method also provides upper bounds for the
fractional coloring numbers of $1 / 0.44533 \approx 2.24554$ and $1 / 0.40407
\approx 2.4748$ and fractional edge coloring number $1.5 / 1.34105 \approx
1.1185$. Our algorithms are applications of the technique introduced by Hoppen
and Wormald.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02747</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02788</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Revisiting the Sanders-Freiman-Ruzsa Theorem in $\mathbb{F}_p^n$ and its
  Application to Non-malleable Codes</dc:title>
 <dc:creator>Aggarwal, Divesh</dc:creator>
 <dc:creator>Bri&#xeb;t, Jop</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Non-malleable codes (NMCs) protect sensitive data against degrees of
corruption that prohibit error detection, ensuring instead that a corrupted
codeword decodes correctly or to something that bears little relation to the
original message. The split-state model, in which codewords consist of two
blocks, considers adversaries who tamper with either block arbitrarily but
independently of the other. The simplest construction in this model, due to
Aggarwal, Dodis, and Lovett (STOC'14), was shown to give NMCs sending k-bit
messages to $O(k^7)$-bit codewords. It is conjectured, however, that the
construction allows linear-length codewords. Towards resolving this conjecture,
we show that the construction allows for code-length $O(k^5)$. This is achieved
by analysing a special case of Sanders's Bogolyubov-Ruzsa theorem for general
Abelian groups. Closely following the excellent exposition of this result for
the group $\mathbb{F}_2^n$ by Lovett, we expose its dependence on $p$ for the
group $\mathbb{F}_p^n$, where $p$ is a prime.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02788</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02794</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comments on &quot;On Clock Synchronization Algorithms for Wireless Sensor
  Networks Under Unknown Delay&quot;</dc:title>
 <dc:creator>Kim, Kyeong Soo</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The generalization of the maximum-likelihood-like estimator for clock skew by
Leng and Wu in the above paper is erroneous because the correlation of the
noise components in the model is not taken into account in the derivation of
the maximum likelihood estimator, its performance bound, and the optimal
selection of the gap between two subtracting time stamps. This comment
investigates the issue of noise correlation in the model and provides the range
of the gap for which the maximum likelihood estimator and its performance bound
are valid and corrects the optimal selection of the gap based on the provided
range.
</dc:description>
 <dc:description>Comment: 2 pages, 1 figure, submitted to IEEE Transactions on Vehicular
  Technology</dc:description>
 <dc:date>2016-02-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02794</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02800</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Primary frequency regulation with load-side participation: stability and
  optimality</dc:title>
 <dc:creator>Kasis, Andreas</dc:creator>
 <dc:creator>Devane, Eoin</dc:creator>
 <dc:creator>Lestas, Ioannis</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  We present a method to design distributed generation and demand control
schemes for primary frequency regulation in power networks that guarantee
asymptotic stability and ensure fairness of allocation. We impose a passivity
condition on net power supply variables and provide explicit steady state
conditions on a general class of generation and demand control dynamics that
ensure convergence of solutions to equilibria that solve an appropriately
constructed network optimization problem. We also show that the inclusion of
controllable demand results in a drop in steady state frequency deviations. We
discuss how various classes of dynamics used in recent studies fit within our
framework and show that this allows for less conservative stability and
optimality conditions. We illustrate our results with simulations on the IEEE
68 bus system and observe that both static and dynamic demand response schemes
that fit within our framework offer improved transient and steady state
behavior compared with control of generation alone. The dynamic scheme is also
seen to enhance the robustness of the system to time-delays.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02800</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02801</identifier>
 <datestamp>2016-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The algebra of Kleene stars of the plane and polylogarithms</dc:title>
 <dc:creator>Hoang, Ngoc</dc:creator>
 <dc:creator>Duchamp, G&#xe9;rard</dc:creator>
 <dc:creator>Minh, Hoang Ngoc</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Symbolic Computation</dc:subject>
 <dc:subject>Mathematics - Commutative Algebra</dc:subject>
 <dc:description>  We extend the definition and study the algebraic properties of the
polylogarithm Li(T), where T is rational series over the alphabet X = {x 0, x
1} belonging to suitable subalgebras of rational series.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02801</dc:identifier>
 <dc:identifier>doi:10.1145/1235</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02822</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parameterizing Region Covariance: An Efficient Way To Apply Sparse Codes
  On Second Order Statistics</dc:title>
 <dc:creator>Dai, Xiyang</dc:creator>
 <dc:creator>Khamis, Sameh</dc:creator>
 <dc:creator>Zhang, Yangmuzi</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Sparse representations have been successfully applied to signal processing,
computer vision and machine learning. Currently there is a trend to learn
sparse models directly on structure data, such as region covariance. However,
such methods when combined with region covariance often require complex
computation. We present an approach to transform a structured sparse model
learning problem to a traditional vectorized sparse modeling problem by
constructing a Euclidean space representation for region covariance matrices.
Our new representation has multiple advantages. Experiments on several vision
tasks demonstrate competitive performance with the state-of-the-art methods.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02823</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Poor starting points in machine learning</dc:title>
 <dc:creator>Tygert, Mark</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Poor (even random) starting points for learning/training/optimization are
common in machine learning. In many settings, the method of Robbins and Monro
(online stochastic gradient descent) is known to be optimal for good starting
points, but may not be optimal for poor starting points -- indeed, for poor
starting points Nesterov acceleration can help during the initial iterations,
even though Nesterov methods not designed for stochastic approximation could
hurt during later iterations. The common practice of training with nontrivial
minibatches enhances the advantage of Nesterov acceleration.
</dc:description>
 <dc:description>Comment: 11 pages, 3 figures, 1 table; this initial version is literally
  identical to that circulated among a restricted audience over a month ago</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02823</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02830</identifier>
 <datestamp>2016-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Binarized Neural Networks: Training Deep Neural Networks with Weights
  and Activations Constrained to +1 or -1</dc:title>
 <dc:creator>Courbariaux, Matthieu</dc:creator>
 <dc:creator>Hubara, Itay</dc:creator>
 <dc:creator>Soudry, Daniel</dc:creator>
 <dc:creator>El-Yaniv, Ran</dc:creator>
 <dc:creator>Bengio, Yoshua</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We introduce a method to train Binarized Neural Networks (BNNs) - neural
networks with binary weights and activations at run-time. At training-time the
binary weights and activations are used for computing the parameters gradients.
During the forward pass, BNNs drastically reduce memory size and accesses, and
replace most arithmetic operations with bit-wise operations, which is expected
to substantially improve power-efficiency. To validate the effectiveness of
BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On
both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10
and SVHN datasets. Last but not least, we wrote a binary matrix multiplication
GPU kernel with which it is possible to run our MNIST BNN 7 times faster than
with an unoptimized GPU kernel, without suffering any loss in classification
accuracy. The code for training and running our BNNs is available on-line.
</dc:description>
 <dc:description>Comment: 11 pages and 3 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-03-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02830</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02831</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Distances of the QC-LDPC Codes in IEEE 802 Communication
  Standards</dc:title>
 <dc:creator>Butler, Brian K.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This work applies earlier results on Quasi-Cyclic (QC) LDPC codes to the
codes specified in six separate IEEE 802 standards, specifying wireless
communications from 54 MHz to 60 GHz. First, we examine the weight matrices
specified to upper bound the codes' minimum distance independent of block
length. Next, we search for the minimum distance achieved for the parity check
matrices selected at each block length. Finally, solutions to the computational
challenges encountered are addressed.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ISIT 2016. 5 pages, 2 figures, and 7 tables</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02834</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Data Detection and Phase Noise Mitigation for Light Field Video
  Transmission in MIMO-OFDM Systems</dc:title>
 <dc:creator>Salim, Omar H.</dc:creator>
 <dc:creator>Xiang, Wei</dc:creator>
 <dc:creator>Nasi, Ali A.</dc:creator>
 <dc:creator>Wang, Gengkun</dc:creator>
 <dc:creator>Mehrpouyan, Hani</dc:creator>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Previous studies in the literature for video transmission over wireless
communication systems focused on combating the effects of additive channel
noise and fading channels without taking the impairments in the physical layer
such as phase noise (PHN) into account. Oscillator phase noise impairs the
performance of multi-input multi-output- orthogonal frequency division
multiplexing (MIMO-OFDM) systems in providing high data rates for video
applications and may lead to decoding failure. In this paper, we propose a
light field (LF) video transmission system in wireless channels, and analyze
joint data detection and phase mitigation in MIMO-OFDM systems for LF video
transmission. The signal model and rate-distortion (RD) model for LF video
transmission in the presence of multiple PHNs are discussed. Moreover, we
propose an iterative algorithm based on the extended Kalman filter for joint
data detection and PHN tracking. Numerical results show that the proposed
detector can significantly improve the average bit-error rate (BER) and
peak-to-noise ratio (PSNR) performance for LF video transmission compared to
existing algorithms. Moreover, the BER and PSNR performance of the proposed
system is closer to that of the ideal case of perfect PHN estimation. Finally,
it is demonstrated that the proposed system model and algorithm are well suited
for LF video transmission in wireless channels.
</dc:description>
 <dc:description>Comment: Submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02834</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02841</identifier>
 <datestamp>2016-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Combinatorial Scoring of Phylogenetic Networks</dc:title>
 <dc:creator>Alexeev, Nikita</dc:creator>
 <dc:creator>Alekseyev, Max A.</dc:creator>
 <dc:subject>Quantitative Biology - Populations and Evolution</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  Construction of phylogenetic trees and networks for extant species from their
characters represents one of the key problems in phylogenomics. While solution
to this problem is not always uniquely defined and there exist multiple methods
for tree/network construction, it becomes important to measure how well the
constructed networks capture the given character relationship across the
species.
  In the current study, we propose a novel method for measuring the specificity
of a given phylogenetic network in terms of the total number of distributions
of character states at the leaves that the network may impose. While for binary
phylogenetic trees, this number has an exact formula and depends only on the
number of leaves and character states but not on the tree topology, the
situation is much more complicated for non-binary trees or networks.
Nevertheless, we develop an algorithm for combinatorial enumeration of such
distributions, which is applicable for arbitrary trees and networks under some
reasonable assumptions.
</dc:description>
 <dc:description>Comment: 12 pages; 3 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-08-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02841</dc:identifier>
 <dc:identifier>Lecture Notes in Computer Science 9797 (2016), 560-572</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-42634-1_45</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02842</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Collaborative filtering via sparse Markov random fields</dc:title>
 <dc:creator>Tran, Truyen</dc:creator>
 <dc:creator>Phung, Dinh</dc:creator>
 <dc:creator>Venkatesh, Svetha</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Recommender systems play a central role in providing individualized access to
information and services. This paper focuses on collaborative filtering, an
approach that exploits the shared structure among mind-liked users and similar
items. In particular, we focus on a formal probabilistic framework known as
Markov random fields (MRF). We address the open problem of structure learning
and introduce a sparsity-inducing algorithm to automatically estimate the
interaction structures between users and between items. Item-item and user-user
correlation networks are obtained as a by-product. Large-scale experiments on
movie recommendation and date matching datasets demonstrate the power of the
proposed method.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02842</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02845</identifier>
 <datestamp>2016-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Online Active Linear Regression via Thresholding</dc:title>
 <dc:creator>Riquelme, Carlos</dc:creator>
 <dc:creator>Johari, Ramesh</dc:creator>
 <dc:creator>Zhang, Baosen</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We consider the problem of online active learning to collect data for
regression modeling. Specifically, we consider a decision maker with a limited
experimentation budget who must efficiently learn an underlying linear
population model. Our main contribution is a novel threshold-based algorithm
for selection of most informative observations; we characterize its performance
and fundamental lower bounds. We extend the algorithm and its guarantees to
sparse linear regression in high-dimensional settings. Simulations suggest the
algorithm is remarkably robust: it provides significant benefits over passive
random sampling in real-world datasets that exhibit high nonlinearity and high
dimensionality --- significantly reducing both the mean and variance of the
squared error.
</dc:description>
 <dc:description>Comment: Published in AAAI 2017</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-12-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02845</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02847</identifier>
 <datestamp>2017-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Refined Multiscale Fuzzy Entropy based on Standard Deviation for
  Biomedical Signal Analysis</dc:title>
 <dc:creator>Azami, Hamed</dc:creator>
 <dc:creator>Fernandez, Alberto</dc:creator>
 <dc:creator>Escudero, Javier</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Multiscale entropy (MSE) has been a prevalent algorithm to quantify the
complexity of fluctuations in the local mean value of biomedical time series.
Recent developments in the field have tried to improve the MSE by reducing its
variability in large scale factors. On the other hand, there has been recent
interest in using other statistical moments than the mean, i.e. variance, in
the coarse-graining step of the MSE. Building on these trends, here we
introduce the so-called refined composite multiscale fuzzy entropy based on the
standard deviation (RCMFE{\sigma}) to quantify the dynamical properties of
spread over multiple time scales. We demonstrate the dependency of the
RCMFE{\sigma}, in comparison with other multiscale approaches, on several
straightforward signal processing concepts using a set of synthetic signals. We
also investigate the complementarity of using the standard deviation instead of
the mean in the coarse-graining process using magnetoencephalograms in
Alzheimer disease and publicly available electroencephalograms recorded from
focal and non-focal areas in epilepsy. Our results indicate that RCMFE{\sigma}
offers complementary information to that revealed by classical coarse-graining
approaches and that it has superior performance to distinguish different types
of physiological activity.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2017-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02847</dc:identifier>
 <dc:identifier>doi:10.1007/s11517-017-1647-5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02850</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Toward Optimal Feature Selection in Naive Bayes for Text Categorization</dc:title>
 <dc:creator>Tang, Bo</dc:creator>
 <dc:creator>Kay, Steven</dc:creator>
 <dc:creator>He, Haibo</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Automated feature selection is important for text categorization to reduce
the feature size and to speed up the learning process of classifiers. In this
paper, we present a novel and efficient feature selection framework based on
the Information Theory, which aims to rank the features with their
discriminative capacity for classification. We first revisit two information
measures: Kullback-Leibler divergence and Jeffreys divergence for binary
hypothesis testing, and analyze their asymptotic properties relating to type I
and type II errors of a Bayesian classifier. We then introduce a new divergence
measure, called Jeffreys-Multi-Hypothesis (JMH) divergence, to measure
multi-distribution divergence for multi-class classification. Based on the
JMH-divergence, we develop two efficient feature selection methods, termed
maximum discrimination ($MD$) and $MD-\chi^2$ methods, for text categorization.
The promising results of extensive experiments demonstrate the effectiveness of
the proposed approaches.
</dc:description>
 <dc:description>Comment: This paper has been submitted to the IEEE Trans. Knowledge and Data
  Engineering. 14 pages, 5 figures</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02850</dc:identifier>
 <dc:identifier>doi:10.1109/TKDE.2016.2563436</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02852</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Compliance-Aware Bandits</dc:title>
 <dc:creator>Della Penna, Nicol&#xe1;s</dc:creator>
 <dc:creator>Reid, Mark D.</dc:creator>
 <dc:creator>Balduzzi, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Motivated by clinical trials, we study bandits with observable
non-compliance. At each step, the learner chooses an arm, after, instead of
observing only the reward, it also observes the action that took place. We show
that such noncompliance can be helpful or hurtful to the learner in general.
Unfortunately, naively incorporating compliance information into bandit
algorithms loses guarantees on sublinear regret. We present hybrid algorithms
that maintain regret bounds up to a multiplicative factor and can incorporate
compliance information. Simulations based on real data from the International
Stoke Trial show the practical potential of these algorithms.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02852</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02857</identifier>
 <datestamp>2017-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Mean Square Stability Analysis and Synthesis of Stochastic
  Continuous-time Linear Networked Systems</dc:title>
 <dc:creator>Pushpak, Sai</dc:creator>
 <dc:creator>Diwadkar, Amit</dc:creator>
 <dc:creator>Vaidya, Umesh</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  In this work, we study the mean square stability-based analysis and
controller synthesis of stochastic continuous-time linear networked systems.
The stochastic uncertainty is assumed to enter multiplicatively in system
dynamics through input and output channels of the plant. Necessary and
sufficient conditions for mean square exponential stability are expressed in
terms of the input-output property of deterministic or nominal system dynamics
captured by the {\it mean square} system norm and variance of channel
uncertainty. The stability results can also be interpreted as small gain
theorem for continuous-time stochastic systems. Linear Matrix Inequalities
(LMI)-based optimization formulation is provided for the computation of mean
square system norm for stability analysis and controller synthesis. For a
special case of single input channel uncertainty, we also prove a fundamental
limitation result that arise in the mean square exponential stabilization of
continuous-time linear system. Overall, the contributions in this work
generalize the existing results on stability analysis and controller synthesis
from discrete-time linear systems to continuous-time linear systems with
multiplicative uncertainty. Simulation results are presented for WSCC 9 bus
power system to demonstrate the application of developed framework.
</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2017-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02857</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02860</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of integrity attacks on real-time pricing in smart grids</dc:title>
 <dc:creator>Tan, Rui</dc:creator>
 <dc:creator>Krishna, Varun Badrinath</dc:creator>
 <dc:creator>Yau, David K. Y.</dc:creator>
 <dc:creator>Kalbarczyk, Zbigniew</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Modern information and communication technologies used by smart grids are
subject to cybersecurity threats. This paper studies the impact of integrity
attacks on real-time pricing (RTP), a key feature of smart grids that uses such
technologies to improve system efficiency. Recent studies have shown that RTP
creates a closed loop formed by the mutually dependent real-time price signals
and price-taking demand. Such a closed loop can be exploited by an adversary
whose objective is to destabilize the pricing system. Specifically, small
malicious modifications to the price signals can be iteratively amplified by
the closed loop, causing inefficiency and even severe failures such as
blackouts. This paper adopts a control-theoretic approach to deriving the
fundamental conditions of RTP stability under two broad classes of integrity
attacks, namely, the scaling and delay attacks. We show that the RTP system is
at risk of being destabilized only if the adversary can compromise the price
signals advertised to smart meters by reducing their values in the scaling
attack, or by providing old prices to over half of all consumers in the delay
attack. The results provide useful guidelines for system operators to analyze
the impact of various attack parameters on system stability, so that they may
take adequate measures to secure RTP systems.
</dc:description>
 <dc:description>Comment: Proceedings of the 2013 ACM SIGSAC conference on Computer &amp;
  communications security</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02860</dc:identifier>
 <dc:identifier>doi:10.1145/2508859.2516705</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02862</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Feature-Based Prediction Model of Algorithm Selection for Constrained
  Continuous Optimisation</dc:title>
 <dc:creator>Poursoltan, Shayan</dc:creator>
 <dc:creator>Neumann, Frank</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  With this paper, we contribute to the growing research area of feature-based
analysis of bio-inspired computing. In this research area, problem instances
are classified according to different features of the underlying problem in
terms of their difficulty of being solved by a particular algorithm. We
investigate the impact of different sets of evolved instances for building
prediction models in the area of algorithm selection. Building on the work of
Poursoltan and Neumann [11,10], we consider how evolved instances can be used
to predict the best performing algorithm for constrained continuous
optimisation from a set of bio-inspired computing methods, namely high
performing variants of differential evolution, particle swarm optimization, and
evolution strategies. Our experimental results show that instances evolved with
a multi-objective approach in combination with random instances of the
underlying problem allow to build a model that accurately predicts the best
performing algorithm for a wide range of problem instances.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02862</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02863</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Reassembling of Graphs, Part 2: The Balanced Case</dc:title>
 <dc:creator>Mirzaei, Saber</dc:creator>
 <dc:creator>Kfoury, Assaf</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:description>  The reassembling of a simple connected graph G = (V,E) is an abstraction of a
problem arising in earlier studies of network analysis. The reassembling
process has a simple formulation (there are several equivalent formulations)
relative to a binary tree B (reassembling tree), with root node at the top and
$n$ leaf nodes at the bottom, where every cross-section corresponds to a
partition of V such that:
  - the bottom (or first) cross-section (all the leaves) is the finest
partition of V with n one-vertex blocks,
  - the top (or last) cross-section (the root) is the coarsest partition with a
single block, the entire set V,
  - a node (or block) in an intermediate cross-section (or partition) is the
result of merging its two children nodes (or blocks) in the cross-section (or
partition) below it.
  The maximum edge-boundary degree encountered during the reassembling process
is what we call the alpha-measure of the reassembling, and the sum of all
edge-boundary degrees is its beta-measure. The alpha-optimization (resp.
beta-optimization) of the reassembling of G is to determine a reassembling tree
B that minimizes its alpha-measure (resp. beta-measure).
  There are different forms of reassembling. In an earlier report, we studied
linear reassembling, which is the case when the height of B is (n-1). In this
report, we study balanced reassembling, when B has height [log n].
  The two main results in this report are the NP-hardness of alpha-optimization
and beta-optimization of balanced reassembling. The first result is obtained by
a sequence of polynomial-time reductions from minimum bisection of graphs
(known to be NP-hard), and the second by a sequence of polynomial-time
reductions from clique cover of graphs (known to be NP-hard).
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02863</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02864</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-External Memory Sparse Matrix Multiplication for Billion-Node
  Graphs</dc:title>
 <dc:creator>Zheng, Da</dc:creator>
 <dc:creator>Mhembere, Disa</dc:creator>
 <dc:creator>Lyzinski, Vince</dc:creator>
 <dc:creator>Vogelstein, Joshua</dc:creator>
 <dc:creator>Priebe, Carey E.</dc:creator>
 <dc:creator>Burns, Randal</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Sparse matrix multiplication is traditionally performed in memory and scales
to large matrices using the distributed memory of multiple nodes. In contrast,
we scale sparse matrix multiplication beyond memory capacity by implementing
sparse matrix dense matrix multiplication (SpMM) in a semi-external memory
(SEM) fashion; i.e., we keep the sparse matrix on commodity SSDs and dense
matrices in memory. Our SEM-SpMM incorporates many in-memory optimizations for
large power-law graphs. It outperforms the in-memory implementations of
Trilinos and Intel MKL and scales to billion-node graphs, far beyond the
limitations of memory. Furthermore, on a single large parallel machine, our
SEM-SpMM operates as fast as the distributed implementations of Trilinos using
five times as much processing power. We also run our implementation in memory
(IM-SpMM) to quantify the overhead of keeping data on SSDs. SEM-SpMM achieves
almost 100% performance of IM-SpMM on graphs when the dense matrix has more
than four columns; it achieves at least 65% performance of IM-SpMM on all
inputs. We apply our SpMM to three important data analysis tasks--PageRank,
eigensolving, and non-negative matrix factorization--and show that our SEM
implementations significantly advance the state of the art.
</dc:description>
 <dc:description>Comment: published in IEEE Transactions on Parallel and Distributed Systems</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-10-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02864</dc:identifier>
 <dc:identifier>doi:10.1109/TPDS.2016.2618791</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02865</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Role of Typicality in Object Classification: Improving The
  Generalization Capacity of Convolutional Neural Networks</dc:title>
 <dc:creator>Saleh, Babak</dc:creator>
 <dc:creator>Elgammal, Ahmed</dc:creator>
 <dc:creator>Feldman, Jacob</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Deep artificial neural networks have made remarkable progress in different
tasks in the field of computer vision. However, the empirical analysis of these
models and investigation of their failure cases has received attention
recently. In this work, we show that deep learning models cannot generalize to
atypical images that are substantially different from training images. This is
in contrast to the superior generalization ability of the visual system in the
human brain. We focus on Convolutional Neural Networks (CNN) as the
state-of-the-art models in object recognition and classification; investigate
this problem in more detail, and hypothesize that training CNN models suffer
from unstructured loss minimization. We propose computational models to improve
the generalization capacity of CNNs by considering how typical a training image
looks like. By conducting an extensive set of experiments we show that
involving a typicality measure can improve the classification results on a new
set of images by a large margin. More importantly, this significant improvement
is achieved without fine-tuning the CNN model on the target image set.
</dc:description>
 <dc:description>Comment: In Submission</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02867</identifier>
 <datestamp>2017-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Value Iteration Networks</dc:title>
 <dc:creator>Tamar, Aviv</dc:creator>
 <dc:creator>Wu, Yi</dc:creator>
 <dc:creator>Thomas, Garrett</dc:creator>
 <dc:creator>Levine, Sergey</dc:creator>
 <dc:creator>Abbeel, Pieter</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce the value iteration network (VIN): a fully differentiable neural
network with a `planning module' embedded within. VINs can learn to plan, and
are suitable for predicting outcomes that involve planning-based reasoning,
such as policies for reinforcement learning. Key to our approach is a novel
differentiable approximation of the value-iteration algorithm, which can be
represented as a convolutional neural network, and trained end-to-end using
standard backpropagation. We evaluate VIN based policies on discrete and
continuous path-planning domains, and on a natural-language based search task.
We show that by learning an explicit planning computation, VIN policies
generalize better to new, unseen domains.
</dc:description>
 <dc:description>Comment: Fixed missing table values</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2017-03-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02867</dc:identifier>
 <dc:identifier>Advances in Neural Information Processing Systems 29 pages
  2154--2162, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02868</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Evaluation of Building Demand Response Capacity</dc:title>
 <dc:creator>Jung, Deokwoo</dc:creator>
 <dc:creator>Krishna, Varun Badrinath</dc:creator>
 <dc:creator>Temple, William</dc:creator>
 <dc:creator>Yau, David K. Y.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Before a building can participate in a demand response program, its facility
managers must characterize the site's ability to reduce load. Today, this is
often done through manual audit processes and prototypical control strategies.
In this paper, we propose a new approach to estimate a building's demand
response capacity using detailed data from various sensors installed in a
building. We derive a formula for a probabilistic measure that characterizes
various tradeoffs between the available demand response capacity and the
confidence level associated with that curtailment under the constraints of
building occupant comfort level (or utility). Then, we develop a data-driven
framework to associate observed or projected building energy consumption with a
particular set of rules learned from a large sensor dataset. We apply this
methodology using testbeds in two buildings in Singapore: a unique net-zero
energy building and a modern commercial office building. Our experimental
results identify key control parameters and provide insight into the available
demand response strategies at each site.
</dc:description>
 <dc:description>Comment: In proceedings of the 2014 IEEE International Conference on Smart
  Grid Communications (IEEE SmartGridComm 2014)</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02868</dc:identifier>
 <dc:identifier>doi:10.1109/SmartGridComm.2014.7007703</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02881</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and Visualization of Endoleaks in CT Data for Monitoring of
  Thoracic and Abdominal Aortic Aneurysm Stents</dc:title>
 <dc:creator>Lu, Jing</dc:creator>
 <dc:creator>Egger, Jan</dc:creator>
 <dc:creator>Wimmer, Andreas</dc:creator>
 <dc:creator>Gro&#xdf;kopf, Stefan</dc:creator>
 <dc:creator>Freisleben, Bernd</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:description>  In this paper we present an efficient algorithm for the segmentation of the
inner and outer boundary of thoratic and abdominal aortic aneurysms (TAA &amp; AAA)
in computed tomography angiography (CTA) acquisitions. The aneurysm
segmentation includes two steps: first, the inner boundary is segmented based
on a grey level model with two thresholds; then, an adapted active contour
model approach is applied to the more complicated outer boundary segmentation,
with its initialization based on the available inner boundary segmentation. An
opacity image, which aims at enhancing important features while reducing
spurious structures, is calculated from the CTA images and employed to guide
the deformation of the model. In addition, the active contour model is extended
by a constraint force that prevents intersections of the inner and outer
boundary and keeps the outer boundary at a distance, given by the thrombus
thickness, to the inner boundary. Based upon the segmentation results, we can
measure the aneurysm size at each centerline point on the centerline orthogonal
multiplanar reformatting (MPR) plane. Furthermore, a 3D TAA or AAA model is
reconstructed from the set of segmented contours, and the presence of endoleaks
is detected and highlighted. The implemented method has been evaluated on nine
clinical CTA data sets with variations in anatomy and location of the pathology
and has shown promising results.
</dc:description>
 <dc:description>Comment: 7 pages, 7 figures, 1 table, 12 references, Proc. SPIE 6918, Medical
  Imaging 2008: Visualization, Image-Guided Procedures, and Modeling, 69181F
  (17 March 2008)</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02881</dc:identifier>
 <dc:identifier>doi:10.1117/12.769414</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02885</identifier>
 <datestamp>2017-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Defogging and Demosaicking</dc:title>
 <dc:creator>Lee, Y. J.</dc:creator>
 <dc:creator>Hirakawa, K.</dc:creator>
 <dc:creator>Nguyen, T. Q.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Image defogging is a technique used extensively for enhancing visual quality
of images in bad weather condition. Even though defogging algorithms have been
well studied, defogging performance is degraded by demosaicking artifacts and
sensor noise amplification in distant scenes. In order to improve visual
quality of restored images, we propose a novel approach to perform defogging
and demosaicking simultaneously. We conclude that better defogging performance
with fewer artifacts can be achieved when a defogging algorithm is combined
with a demosaicking algorithm simultaneously. We also demonstrate that the
proposed joint algorithm has the benefit of suppressing noise amplification in
distant scene. In addition, we validate our theoretical analysis and
observations for both synthesized datasets with ground truth fog-free images
and natural scene datasets captured in a raw format.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02885</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2631880</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02886</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optilization of the gyroaverage operator based on hermite interpolation</dc:title>
 <dc:creator>Rozar, F</dc:creator>
 <dc:creator>Steiner, C</dc:creator>
 <dc:creator>Latu, G</dc:creator>
 <dc:creator>Mehrenberger, M</dc:creator>
 <dc:creator>Grandgirard, V</dc:creator>
 <dc:creator>Bigot, Julien</dc:creator>
 <dc:creator>Cartier-Michaud, T</dc:creator>
 <dc:creator>Roman, Jean</dc:creator>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:description>  Gyrokinetic modeling is appropriate for describing Tokamak plasma turbulence,
and the gyroaverage operator is a cornerstone of this approach. In a
gyrokinetic code, the gyroaveraging scheme needs to be accurate enough to avoid
spoiling the data but also requires a low computation cost because it is
applied often on the main unknown, the 5D guiding-center distribution function,
and on the 3D electric potentials. In the present paper, we improve a
gyroaverage scheme based on Hermite interpolation used in the Gysela code. This
initial implementation represents a too large fraction of the total execution
time. The gyroaverage operator has been reformulated and is now expressed as a
matrix-vector product and a cache-friendly algorithm has been setup. Different
techniques have been investigated to quicken the computations by more than a
factor two. Description of the algorithms is given, together with an analysis
of the achieved performance.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02886</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02887</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Classification with Boosting of Extreme Learning Machine Over
  Arbitrarily Partitioned Data</dc:title>
 <dc:creator>&#xc7;atak, Ferhat &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Machine learning based computational intelligence methods are widely used to
analyze large scale data sets in this age of big data. Extracting useful
predictive modeling from these types of data sets is a challenging problem due
to their high complexity. Analyzing large amount of streaming data that can be
leveraged to derive business value is another complex problem to solve. With
high levels of data availability (\textit{i.e. Big Data}) automatic
classification of them has become an important and complex task. Hence, we
explore the power of applying MapReduce based Distributed AdaBoosting of
Extreme Learning Machine (ELM) to build a predictive bag of classification
models. Accordingly, (i) data set ensembles are created; (ii) ELM algorithm is
used to build weak learners (classifier functions); and (iii) builds a strong
learner from a set of weak learners. We applied this training model to the
benchmark knowledge discovery and data mining data sets.
</dc:description>
 <dc:description>Comment: Springer Soft Computing</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02887</dc:identifier>
 <dc:identifier>doi:10.1007/s00500-015-1938-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02888</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Robust Ensemble Classifier Combination Based on Noise Removal with
  One-Class SVM</dc:title>
 <dc:creator>&#xc7;atak, Ferhat &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In machine learning area, as the number of labeled input samples becomes very
large, it is very difficult to build a classification model because of input
data set is not fit in a memory in training phase of the algorithm, therefore,
it is necessary to utilize data partitioning to handle overall data set.
Bagging and boosting based data partitioning methods have been broadly used in
data mining and pattern recognition area. Both of these methods have shown a
great possibility for improving classification model performance. This study is
concerned with the analysis of data set partitioning with noise removal and its
impact on the performance of multiple classifier models. In this study, we
propose noise filtering preprocessing at each data set partition to increment
classifier model performance. We applied Gini impurity approach to find the
best split percentage of noise filter ratio. The filtered sub data set is then
used to train individual ensemble models.
</dc:description>
 <dc:description>Comment: 22nd International Conference, ICONIP 2015</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02888</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02899</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Secure Multi-Party Computation Based Privacy Preserving Extreme Learning
  Machine Algorithm Over Vertically Distributed Data</dc:title>
 <dc:creator>&#xc7;atak, Ferhat &#xd6;zg&#xfc;r</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Especially in the Big Data era, the usage of different classification methods
is increasing day by day. The success of these classification methods depends
on the effectiveness of learning methods. Extreme learning machine (ELM)
classification algorithm is a relatively new learning method built on
feed-forward neural-network. ELM classification algorithm is a simple and fast
method that can create a model from high-dimensional data sets. Traditional ELM
learning algorithm implicitly assumes complete access to whole data set. This
is a major privacy concern in most of cases. Sharing of private data (i.e.
medical records) is prevented because of security concerns. In this research,
we propose an efficient and secure privacy-preserving learning algorithm for
ELM classification over data that is vertically partitioned among several
parties. The new learning method preserves the privacy on numerical attributes,
builds a classification model without sharing private data without disclosing
the data of each party to others.
</dc:description>
 <dc:description>Comment: 22nd International Conference, ICONIP 2015</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02899</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-26535-3_39</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02911</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Searching PubMed for articles relevant to clinical interpretation of
  rare human genetic variants</dc:title>
 <dc:creator>McMurry, Andrew J.</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:description>  Numerous challenges persist that delay clinical interpretation of human
genetic variants, to name a few: (1) un- structured PubMed articles are the
most abundant source of evidence, yet their variant annotations are difficult
to query uniformly, (2) variants can be reported many different ways, for
example as DNA sequence change or protein modification, (3) historical drift in
annotations over time between various genome reference assemblies and
transcript alignments, (4) no single laboratory has sufficient numbers of human
samples, necessitating precompetitive efforts to share evidence for clinical
interpretation.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02911</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02923</identifier>
 <datestamp>2017-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Globally Optimal Energy-Efficient Power Control and Receiver Design in
  Wireless Networks</dc:title>
 <dc:creator>Zappone, Alessio</dc:creator>
 <dc:creator>Bj&#xf6;rnson, Emil</dc:creator>
 <dc:creator>Sanguinetti, Luca</dc:creator>
 <dc:creator>Jorswieck, Eduard</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The characterization of the global maximum of energy efficiency (EE) problems
in wireless networks is a challenging problem due to the non-convex nature of
investigated problems in interference channels. The aim of this work is to
develop a new and general framework to achieve globally optimal solutions.
First, the hidden monotonic structure of the most common EE maximization
problems is exploited jointly with fractional programming theory to obtain
globally optimal solutions with exponential complexity in the number of network
links. To overcome this issue, we also propose a framework to compute
suboptimal power control strategies characterized by affordable complexity.
This is achieved by merging fractional programming and sequential optimization.
The proposed monotonic framework is used to shed light on the ultimate
performance of wireless networks in terms of EE and also to benchmark the
performance of the lower-complexity framework based on sequential programming.
Numerical evidence is provided to show that the sequential fractional
programming framework achieves global optimality in several practical
communication scenarios.
</dc:description>
 <dc:description>Comment: Accepted for publication in the IEEE Transactions on Signal
  Processing</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2017-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02923</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2017.2673813</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02924</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Blocklength-Limited Performance of Relaying under Quasi-Static Rayleigh
  Channels</dc:title>
 <dc:creator>Hu, Yulin</dc:creator>
 <dc:creator>Schmeink, Anke</dc:creator>
 <dc:creator>Gross, James</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the blocklength-limited performance of a relaying system is
studied, where channels are assumed to experience quasi-static Rayleigh fading
while at the same time only the average channel state information (CSI) is
available at the source. Both the physical-layer performance
(blocklength-limited throughput) and the link-layer performance (effective
capacity) of the relaying system are investigated. We propose a simple system
operation by introducing a factor based on which we weight the average CSI and
let the source determine the coding rate accordingly. In particular, we prove
that both the blocklength-limited throughput and the effective capacity are
quasi-concave in the weight factor. Through numerical investigations, we show
the appropriateness of our theoretical model. In addition, we observe that
relaying is more efficient than direct transmission. Moreover, this performance
advantage of relaying under the average CSI scenario is more significant than
under the perfect CSI scenario. Finally, the speed of convergence (between the
blocklength-limited performance and the performance in the Shannon capacity
regime) in relaying system is faster in comparison to the direct transmission
under both the average CSI scenario and the perfect CSI scenario.
</dc:description>
 <dc:description>Comment: 12 figures, submitted to IEEE Transactions on Wireless Communications</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02924</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2542245</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02934</identifier>
 <datestamp>2016-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Nested Mini-Batch K-Means</dc:title>
 <dc:creator>Newling, James</dc:creator>
 <dc:creator>Fleuret, Fran&#xe7;ois</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  A new algorithm is proposed which accelerates the mini-batch k-means
algorithm of Sculley (2010) by using the distance bounding approach of Elkan
(2003). We argue that, when incorporating distance bounds into a mini-batch
algorithm, already used data should preferentially be reused. To this end we
propose using nested mini-batches, whereby data in a mini-batch at iteration t
is automatically reused at iteration t+1.
  Using nested mini-batches presents two difficulties. The first is that
unbalanced use of data can bias estimates, which we resolve by ensuring that
each data sample contributes exactly once to centroids. The second is in
choosing mini-batch sizes, which we address by balancing premature fine-tuning
of centroids with redundancy induced slow-down. Experiments show that the
resulting nmbatch algorithm is very effective, often arriving within 1% of the
empirical minimum 100 times earlier than the standard mini-batch algorithm.
</dc:description>
 <dc:description>Comment: 8 pages + Supplementary Material. Version 2 : new experiments added.
  Version 3 : Add acknowledgments, upper case in title. Version 4 : Correct
  spelling of Acknowledgements, change title. Version 5: camera ready NIPS</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-09-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02934</dc:identifier>
 <dc:identifier>Nested Mini-Batch K-Means, Proceedings of the International
  Conference on Neural Information Processing Systems (NIPS), 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02938</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Challenges of Integrating A Priori Information Efficiently in the
  Discovery of Spatio-Temporal Objects in Large Databases</dc:title>
 <dc:creator>Schott, Benjamin</dc:creator>
 <dc:creator>Stegmaier, Johannes</dc:creator>
 <dc:creator>Takamiya, Masanari</dc:creator>
 <dc:creator>Mikut, Ralf</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>92-08, 92C37, 92C55, 68U10</dc:subject>
 <dc:description>  Using the knowledge discovery framework, it is possible to explore object
databases and extract groups of objects with highly heterogeneous movement
behavior by efficiently integrating a priori knowledge through interacting with
the framework. The whole process is modular expandable and is therefore
adaptive to any problem formulation. Further, the flexible use of different
information allocation processes reveal a great potential to efficiently
incorporate the a priori knowledge of different users in different ways.
Therefore, the stepwise knowledge discovery process embedded in the knowledge
discovery framework is described in detail to point out the flexibility of such
a system incorporating object databases from different applications. The
described framework can be used to gain knowledge out of object databases in
many different fields. This knowledge can be used to gain further insights and
improve the understanding of underlying phenomena. The functionality of the
proposed framework is exemplarily demonstrated using a benchmark database based
on real biological object data.
</dc:description>
 <dc:description>Comment: Proc., 25. Workshop Computational Intelligence, Dortmund, 2015</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02938</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02943</identifier>
 <datestamp>2016-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Evaluation of Plug-in Electric Vehicle Data of a Campus Charging
  Network</dc:title>
 <dc:creator>Bayram, Islam Safak</dc:creator>
 <dc:creator>Zamani, Vahraz</dc:creator>
 <dc:creator>Hanna, Ryan</dc:creator>
 <dc:creator>Kleissl, Jan</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  The mass adoption of plug-in electric vehicles (PEVs) requires the deployment
of public charging stations. Such facilities are expected to employ distributed
generation and storage units to reduce the stress on the grid and boost
sustainable transportation. While prior work has made considerable progress in
deriving insights for understanding the adverse impacts of PEV chargings and
how to alleviate them, a critical issue that affects the accuracy is the lack
of real world PEV data. As the dynamics and pertinent design of such charging
stations heavily depend on actual customer demand profile, in this paper we
present and evaluate the data obtained from a $17$ node charging network
equipped with Level $2$ chargers at a major North American University campus.
The data is recorded for $166$ weeks starting from late $2011$. The result
indicates that the majority of the customers use charging lots to extend their
driving ranges. Also, the demand profile shows that there is a tremendous
opportunity to employ solar generation to fuel the vehicles as there is a
correlation between the peak customer demand and solar irradiation. Also, we
provided a more detailed data analysis and show how to use this information in
designing future sustainable charging facilities.
</dc:description>
 <dc:description>Comment: Accepted by IEEE Energycon 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02943</dc:identifier>
 <dc:identifier>doi:10.1109/ENERGYCON.2016.7514026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02944</identifier>
 <datestamp>2016-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast phase retrieval for high dimensions: A block-based approach</dc:title>
 <dc:creator>Rajaei, Boshra</dc:creator>
 <dc:creator>Gigan, Sylvain</dc:creator>
 <dc:creator>Krzakala, Florent</dc:creator>
 <dc:creator>Daudet, Laurent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This paper addresses fundamental scaling issues that hinder phase retrieval
(PR) in high dimensions. We show that, if the measurement matrix can be put
into a generalized block-diagonal form, a large PR problem can be solved on
separate blocks, at the cost of a few extra global measurements to merge the
partial results. We illustrate this principle using two distinct PR methods,
and discuss different design trade-offs. Experimental results indicate that
this block-based PR framework can reduce computational cost and memory
requirements by several orders of magnitude.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-06-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02944</dc:identifier>
 <dc:identifier>IEEE Signal Processing Letters Year: 2016, Volume: 23, Issue: 9
  Pages: 1179 - 1182</dc:identifier>
 <dc:identifier>doi:10.1109/LSP.2016.2587618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02949</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Weak oddness as an approximation of oddness and resistance in cubic
  graphs</dc:title>
 <dc:creator>Luko&#x165;ka, Robert</dc:creator>
 <dc:creator>Maz&#xe1;k, J&#xe1;n</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  We introduce weak oddness $\omega_{\textrm w}$, a new measure of
uncolourability of cubic graphs, defined as the least number of odd components
in an even factor. For every bridgeless cubic graph $G$,
$\rho(G)\le\omega_{\textrm w}(G)\le\omega(G)$, where $\rho(G)$ denotes the
resistance of $G$ and $\omega(G)$ denotes the oddness of $G$, so this new
measure is an approximation of both oddness and resistance. We demonstrate that
there are graphs $G$ satisfying $\rho(G) &lt; \omega_{\textrm w}(G) &lt; \omega(G)$,
and that the difference between any two of those three measures can be
arbitrarily large. The construction implies that if we replace a vertex of a
cubic graph with a triangle, then its oddness can decrease by an arbitrarily
large amount.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02949</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02950</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Spoofing detection under noisy conditions: a preliminary investigation
  and an initial database</dc:title>
 <dc:creator>Tian, Xiaohai</dc:creator>
 <dc:creator>Wu, Zhizheng</dc:creator>
 <dc:creator>Xiao, Xiong</dc:creator>
 <dc:creator>Chng, Eng Siong</dc:creator>
 <dc:creator>Li, Haizhou</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Sound</dc:subject>
 <dc:description>  Spoofing detection for automatic speaker verification (ASV), which is to
discriminate between live speech and attacks, has received increasing
attentions recently. However, all the previous studies have been done on the
clean data without significant additive noise. To simulate the real-life
scenarios, we perform a preliminary investigation of spoofing detection under
additive noisy conditions, and also describe an initial database for this task.
The noisy database is based on the ASVspoof challenge 2015 database and
generated by artificially adding background noises at different signal-to-noise
ratios (SNRs). Five different additive noises are included. Our preliminary
results show that using the model trained from clean data, the system
performance degrades significantly in noisy conditions. Phase-based feature is
more noise robust than magnitude-based features. And the systems perform
significantly differ under different noise scenarios.
</dc:description>
 <dc:description>Comment: Submitted to Odyssey: The Speaker and Language Recognition Workshop
  2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02982</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variable Transmission Voltage for Loss Minimization in Long Offshore
  Wind Farm AC Export Cables</dc:title>
 <dc:creator>Gustavsen, Bjorn</dc:creator>
 <dc:creator>Mo, Olve</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Connection of offshore wind farms to shore requires the use of submarine
cables. In the case of long HVAC connections, the capacitive charging currents
limit the transfer capability and lead to high losses. This paper shows that
the losses can be substantially reduced by continuously adjusting the cable
operating voltage according to the instantaneous wind farm power
production.Calculations for a 320 MW windfarm connected to shore via a 200 km
cable at 220 kV nominal voltage shows that an annual loss reduction of 9
percent is achievable by simply using a 15 percent tap changer voltage
regulation on the two transformers. Allowing a larger voltage regulation range
leads to further loss reduction (13 percent for 0.4-1.0 p.u. voltage range). If
the windfarm has a low utilization factor, the loss reduction potential is
demonstrated to be as high as 21 percent . The methodology can be applied
without introducing new technology that needs to be developed or qualified.
</dc:description>
 <dc:description>Comment: To be submitted to IEEE Transactions on Power Delivery</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02982</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02990</identifier>
 <datestamp>2016-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Self-organized control for musculoskeletal robots</dc:title>
 <dc:creator>Der, Ralf</dc:creator>
 <dc:creator>Martius, Georg</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>37N35, 68T05, 68T40, 93C40</dc:subject>
 <dc:subject>I.2.9</dc:subject>
 <dc:subject>I.2.6</dc:subject>
 <dc:description>  With the accelerated development of robot technologies, optimal control
becomes one of the central themes of research. In traditional approaches, the
controller, by its internal functionality, finds appropriate actions on the
basis of the history of sensor values, guided by the goals, intentions,
objectives, learning schemes, and so on planted into it. The idea is that the
controller controls the world---the body plus its environment---as reliably as
possible. However, in elastically actuated robots this approach faces severe
difficulties. This paper advocates for a new paradigm of self-organized
control. The paper presents a solution with a controller that is devoid of any
functionalities of its own, given by a fixed, explicit and context-free
function of the recent history of the sensor values. When applying this
controller to a muscle-tendon driven arm-shoulder system from the Myorobotics
toolkit, we observe a vast variety of self-organized behavior patterns: when
left alone, the arm realizes pseudo-random sequences of different poses but one
can also manipulate the system into definite motion patterns. But most
interestingly, after attaching an object, the controller gets in a functional
resonance with the object's internal dynamics: when given a half-filled bottle,
the system spontaneously starts shaking the bottle so that maximum response
from the dynamics of the water is being generated. After attaching a pendulum
to the arm, the controller drives the pendulum into a circular mode. In this
way, the robot discovers dynamical affordances of objects its body is
interacting with. We also discuss perspectives for using this controller
paradigm for intention driven behavior generation.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures, 1 table</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-06-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02990</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02991</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A local constant factor approximation for the minimum dominating set
  problem on bounded genus graphs</dc:title>
 <dc:creator>Amiri, Saeed Akhoondian</dc:creator>
 <dc:creator>Schmid, Stefan</dc:creator>
 <dc:creator>Siebertz, Sebastian</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The Minimum Dominating Set (MDS) problem is not only one of the most
fundamental problems in distributed computing, it is also one of the most
challenging ones. While it is well-known that minimum dominating sets cannot be
approximated locally on general graphs, over the last years, several
breakthroughs have been made on computing local approximations on sparse
graphs.
  This paper presents a deterministic and local constant factor approximation
for minimum dominating sets on bounded genus graphs, a very large family of
sparse graphs. Our main technical contribution is a new analysis of a slightly
modified, first-order definable variant of an existing algorithm by Lenzen et
al. Interestingly, unlike existing proofs for planar graphs, our analysis does
not rely on any topological arguments. We believe that our techniques can be
useful for the study of local problems on sparse graphs beyond the scope of
this paper.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02991</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02992</identifier>
 <datestamp>2017-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection and Quantification of Flow Consistency in Business Process
  Models</dc:title>
 <dc:creator>Burattin, Andrea</dc:creator>
 <dc:creator>Bernstein, Vered</dc:creator>
 <dc:creator>Neurauter, Manuel</dc:creator>
 <dc:creator>Soffer, Pnina</dc:creator>
 <dc:creator>Weber, Barbara</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Business process models abstract complex business processes by representing
them as graphical models. Their layout, solely determined by the modeler,
affects their understandability. To support the construction of understandable
models it would be beneficial to systematically study this effect. However,
this requires a basic set of measurable key visual features, depicting the
layout properties that are meaningful to the human user. The aim of this
research is thus twofold. First, to empirically identify key visual features of
business process models which are perceived as meaningful to the user. Second,
to show how such features can be quantified into computational metrics, which
are applicable to business process models. We focus on one particular feature,
consistency of flow direction, and show the challenges that arise when
transforming it into a precise metric. We propose three different metrics
addressing these challenges, each following a different view of flow
consistency. We then report the results of an empirical evaluation, which
indicates which metric is more effective in predicting the human perception of
this feature. Moreover, two other automatic evaluations describing the
performance and the computational capabilities of our metrics are reported as
well.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02992</dc:identifier>
 <dc:identifier>doi:10.1007/s10270-017-0576-y</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02995</identifier>
 <datestamp>2016-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Segmental Spatiotemporal CNNs for Fine-grained Action Segmentation</dc:title>
 <dc:creator>Lea, Colin</dc:creator>
 <dc:creator>Reiter, Austin</dc:creator>
 <dc:creator>Vidal, Rene</dc:creator>
 <dc:creator>Hager, Gregory D.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  Joint segmentation and classification of fine-grained actions is important
for applications of human-robot interaction, video surveillance, and human
skill evaluation. However, despite substantial recent progress in large-scale
action classification, the performance of state-of-the-art fine-grained action
recognition approaches remains low. We propose a model for action segmentation
which combines low-level spatiotemporal features with a high-level segmental
classifier. Our spatiotemporal CNN is comprised of a spatial component that
uses convolutional filters to capture information about objects and their
relationships, and a temporal component that uses large 1D convolutional
filters to capture information about how object relationships change across
time. These features are used in tandem with a semi-Markov model that models
transitions from one action to another. We introduce an efficient constrained
segmental inference algorithm for this model that is orders of magnitude faster
than the current approach. We highlight the effectiveness of our Segmental
Spatiotemporal CNN on cooking and surgical action datasets for which we observe
substantially improved performance relative to recent baseline methods.
</dc:description>
 <dc:description>Comment: Updated from the ECCV 2016 version. We fixed an important
  mathematical error and made the section on segmental inference clearer</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-09-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02995</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.02999</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Recognition: Perspectives from the Real-World</dc:title>
 <dc:creator>Mandal, Bappaditya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper, we analyze some of our real-world deployment of face
recognition (FR) systems for various applications and discuss the gaps between
expectations of the user and what the system can deliver. We evaluate some of
our proposed algorithms with ad-hoc modifications for applications such as FR
on wearable devices (like Google Glass), monitoring of elderly people in senior
citizens centers, FR of children in child care centers and face matching
between a scanned IC/passport face image and a few live webcam images for
automatic hotel/resort checkouts. We describe each of these applications, the
challenges involved and proposed solutions. Since FR is intuitive in nature and
we human beings use it for interactions with the outside world, people have
high expectations of its performance in real-world scenarios. However, we
analyze and discuss here that it is not the case, machine recognition of faces
for each of these applications poses unique challenges and demands specific
research components so as to adapt in the actual sites.
</dc:description>
 <dc:description>Comment: 11 pages, 4 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.02999</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03001</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Convolutional Attention Network for Extreme Summarization of Source
  Code</dc:title>
 <dc:creator>Allamanis, Miltiadis</dc:creator>
 <dc:creator>Peng, Hao</dc:creator>
 <dc:creator>Sutton, Charles</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Attention mechanisms in neural networks have proved useful for problems in
which the input and output do not have fixed dimension. Often there exist
features that are locally translation invariant and would be valuable for
directing the model's attention, but previous attentional architectures are not
constructed to learn such features specifically. We introduce an attentional
neural network that employs convolution on the input tokens to detect local
time-invariant and long-range topical attention features in a context-dependent
way. We apply this architecture to the problem of extreme summarization of
source code snippets into short, descriptive function name-like summaries.
Using those features, the model sequentially generates a summary by
marginalizing over two attention mechanisms: one that predicts the next summary
token based on the attention weights of the input tokens and another that is
able to copy a code token as-is directly into the summary. We demonstrate our
convolutional attention neural network's performance on 10 popular Java
projects showing that it achieves better performance compared to previous
attentional mechanisms.
</dc:description>
 <dc:description>Comment: Code, data and visualization at
  http://groups.inf.ed.ac.uk/cup/codeattention/</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03012</identifier>
 <datestamp>2016-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic
  Videos</dc:title>
 <dc:creator>Twinanda, Andru P.</dc:creator>
 <dc:creator>Shehata, Sherif</dc:creator>
 <dc:creator>Mutter, Didier</dc:creator>
 <dc:creator>Marescaux, Jacques</dc:creator>
 <dc:creator>de Mathelin, Michel</dc:creator>
 <dc:creator>Padoy, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Surgical workflow recognition has numerous potential medical applications,
such as the automatic indexing of surgical video databases and the optimization
of real-time operating room scheduling, among others. As a result, phase
recognition has been studied in the context of several kinds of surgeries, such
as cataract, neurological, and laparoscopic surgeries. In the literature, two
types of features are typically used to perform this task: visual features and
tool usage signals. However, the visual features used are mostly handcrafted.
Furthermore, the tool usage signals are usually collected via a manual
annotation process or by using additional equipment. In this paper, we propose
a novel method for phase recognition that uses a convolutional neural network
(CNN) to automatically learn features from cholecystectomy videos and that
relies uniquely on visual information. In previous studies, it has been shown
that the tool signals can provide valuable information in performing the phase
recognition task. Thus, we present a novel CNN architecture, called EndoNet,
that is designed to carry out the phase recognition and tool presence detection
tasks in a multi-task manner. To the best of our knowledge, this is the first
work proposing to use a CNN for multiple recognition tasks on laparoscopic
videos. Extensive experimental comparisons to other methods show that EndoNet
yields state-of-the-art results for both tasks.
</dc:description>
 <dc:description>Comment: Video: https://www.youtube.com/watch?v=6v0NWrFOUUM</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03012</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03014</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Herding as a Learning System with Edge-of-Chaos Dynamics</dc:title>
 <dc:creator>Chen, Yutian</dc:creator>
 <dc:creator>Welling, Max</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Herding defines a deterministic dynamical system at the edge of chaos. It
generates a sequence of model states and parameters by alternating parameter
perturbations with state maximizations, where the sequence of states can be
interpreted as &quot;samples&quot; from an associated MRF model. Herding differs from
maximum likelihood estimation in that the sequence of parameters does not
converge to a fixed point and differs from an MCMC posterior sampling approach
in that the sequence of states is generated deterministically. Herding may be
interpreted as a&quot;perturb and map&quot; method where the parameter perturbations are
generated using a deterministic nonlinear dynamical system rather than randomly
from a Gumbel distribution. This chapter studies the distinct statistical
characteristics of the herding algorithm and shows that the fast convergence
rate of the controlled moments may be attributed to edge of chaos dynamics. The
herding algorithm can also be generalized to models with latent variables and
to a discriminative learning setting. The perceptron cycling theorem ensures
that the fast moment matching property is preserved in the more general
framework.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03014</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03016</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>FPGA Hardware Acceleration of Monte Carlo Simulations for the Ising
  Model</dc:title>
 <dc:creator>Ortega-Zamorano, Francisco</dc:creator>
 <dc:creator>Montemurro, Marcelo A.</dc:creator>
 <dc:creator>Cannas, Sergio A.</dc:creator>
 <dc:creator>Jerez, Jos&#xe9; M.</dc:creator>
 <dc:creator>Franco, Leonardo</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:subject>Physics - Computational Physics</dc:subject>
 <dc:description>  A two-dimensional Ising model with nearest-neighbors ferromagnetic
interactions is implemented in a Field Programmable Gate Array (FPGA)
board.Extensive Monte Carlo simulations were carried out using an efficient
hardware representation of individual spins and a combined global-local LFSR
random number generator. Consistent results regarding the descriptive
properties of magnetic systems, like energy, magnetization and susceptibility
are obtained while a speed-up factor of approximately 6 times is achieved in
comparison to previous FPGA-based published works and almost $10^4$ times in
comparison to a standard CPU simulation. A detailed description of the logic
design used is given together with a careful analysis of the quality of the
random number generator used. The obtained results confirm the potential of
FPGAs for analyzing the statistical mechanics of magnetic systems.
</dc:description>
 <dc:description>Comment: 19 pages, 10 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03016</dc:identifier>
 <dc:identifier>doi:10.1109/TPDS.2015.2505725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03027</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimax Lower Bounds for Realizable Transductive Classification</dc:title>
 <dc:creator>Tolstikhin, Ilya</dc:creator>
 <dc:creator>Lopez-Paz, David</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Transductive learning considers a training set of $m$ labeled samples and a
test set of $u$ unlabeled samples, with the goal of best labeling that
particular test set. Conversely, inductive learning considers a training set of
$m$ labeled samples drawn iid from $P(X,Y)$, with the goal of best labeling any
future samples drawn iid from $P(X)$. This comparison suggests that
transduction is a much easier type of inference than induction, but is this
really the case? This paper provides a negative answer to this question, by
proving the first known minimax lower bounds for transductive, realizable,
binary classification. Our lower bounds show that $m$ should be at least
$\Omega(d/\epsilon + \log(1/\delta)/\epsilon)$ when $\epsilon$-learning a
concept class $\mathcal{H}$ of finite VC-dimension $d&lt;\infty$ with confidence
$1-\delta$, for all $m \leq u$. This result draws three important conclusions.
First, general transduction is as hard as general induction, since both
problems have $\Omega(d/m)$ minimax values. Second, the use of unlabeled data
does not help general transduction, since supervised learning algorithms such
as ERM and (Hanneke, 2015) match our transductive lower bounds while ignoring
the unlabeled test set. Third, our transductive lower bounds imply lower bounds
for semi-supervised learning, which add to the important discussion about the
role of unlabeled data in machine learning.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03027</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03031</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coinami: A Cryptocurrency with DNA Sequence Alignment as Proof-of-work</dc:title>
 <dc:creator>Ileri, Atalay M.</dc:creator>
 <dc:creator>Ozercan, Halil I.</dc:creator>
 <dc:creator>Gundogdu, Alper</dc:creator>
 <dc:creator>Senol, Ahmet K.</dc:creator>
 <dc:creator>Ozkaya, M. Yusuf</dc:creator>
 <dc:creator>Alkan, Can</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  Rate of growth of the amount of data generated using the high throughput
sequencing (HTS) platforms now exceeds the growth stipulated by Moore's Law.
The HTS data is expected to surpass those of other &quot;big data&quot; domains such as
astronomy, before the year 2025. In addition to sequencing genomes for research
purposes, genome and exome sequencing in clinical settings will be a routine
part of health care. The analysis of such large amounts of data, however, is
not without computational challenges. This burden is even more increased due to
the periodic updates to reference genomes, which typically require re-analysis
of existing data. Here we propose Coin-Application Mediator Interface (Coinami)
to distribute the workload for mapping reads to reference genomes using a
volunteer grid computer approach similar to Berkeley Open Infrastructure for
Network Computing (BOINC). However, since HTS read mapping requires substantial
computational resources and fast analysis turnout is desired, Coinami uses the
HTS read mapping as proof-of-work to generate valid blocks to main its own
cryptocurrency system, which may help motivate volunteers to dedicate more
resources. The Coinami protocol includes mechanisms to ensure that jobs
performed by volunteers are correct, and provides genomic data privacy. The
prototype implementation of Coinami is available at http://coinami.github.io/.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03031</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03032</identifier>
 <datestamp>2016-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Associative Long Short-Term Memory</dc:title>
 <dc:creator>Danihelka, Ivo</dc:creator>
 <dc:creator>Wayne, Greg</dc:creator>
 <dc:creator>Uria, Benigno</dc:creator>
 <dc:creator>Kalchbrenner, Nal</dc:creator>
 <dc:creator>Graves, Alex</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  We investigate a new method to augment recurrent neural networks with extra
memory without increasing the number of network parameters. The system has an
associative memory based on complex-valued vectors and is closely related to
Holographic Reduced Representations and Long Short-Term Memory networks.
Holographic Reduced Representations have limited capacity: as they store more
information, each retrieval becomes noisier due to interference. Our system in
contrast creates redundant copies of stored information, which enables
retrieval with reduced noise. Experiments demonstrate faster learning on
multiple memorization tasks.
</dc:description>
 <dc:description>Comment: ICML-2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-19</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03032</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03033</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Strengthening the Entropy Power Inequality</dc:title>
 <dc:creator>Courtade, Thomas A.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We tighten the Entropy Power Inequality (EPI) when one of the random summands
is Gaussian. Our strengthening is closely connected to the concept of strong
data processing for Gaussian channels and generalizes the (vector extension of)
Costa's EPI. This leads to a new reverse entropy power inequality and, as a
corollary, sharpens Stam's inequality relating entropy power and Fisher
information. Applications to network information theory are given, including a
short self-contained proof of the rate region for the two-encoder quadratic
Gaussian source coding problem.
  Our argument is based on weak convergence and a technique employed by Geng
and Nair for establishing Gaussian optimality via rotational-invariance, which
traces its roots to a `doubling trick' that has been successfully used in the
study of functional inequalities.
</dc:description>
 <dc:description>Comment: 23 pages. Full version of submission to 2016 International Symposium
  on Information Theory. Presented in part at Institut Henri Poincar\'{e} Feb
  10, 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03033</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03040</identifier>
 <datestamp>2016-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Structured Weighted Violations Perceptron Algorithm</dc:title>
 <dc:creator>Dror, Rotem</dc:creator>
 <dc:creator>Reichart, Roi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We present the Structured Weighted Violations Perceptron (SWVP) algorithm, a
new structured prediction algorithm that generalizes the Collins Structured
Perceptron (CSP). Unlike CSP, the update rule of SWVP explicitly exploits the
internal structure of the predicted labels. We prove the convergence of SWVP
for linearly separable training sets, provide mistake and generalization
bounds, and show that in the general case these bounds are tighter than those
of the CSP special case. In synthetic data experiments with data drawn from an
HMM, various variants of SWVP substantially outperform its CSP special case.
SWVP also provides encouraging initial dependency parsing results.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-09-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03040</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03050</identifier>
 <datestamp>2016-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete Problems of Propositional Logic for the Exponential Hierarchy</dc:title>
 <dc:creator>L&#xfc;ck, Martin</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q15</dc:subject>
 <dc:subject>F.1.3</dc:subject>
 <dc:subject>F.4.1</dc:subject>
 <dc:description>  Large complexity classes, like the exponential time hierarchy, received
little attention in terms of finding complete problems. In this work a
generalization of propositional logic is investigated which fills this gap with
the introduction of Boolean higher-order quantifiers or equivalently Boolean
Skolem functions. This builds on the important results of Wrathall and
Stockmeyer regarding complete problems, namely QBF and QBF-k, for the
polynomial hierarchy. Furthermore it generalizes the Dependency QBF problem
introduced by Peterson, Reif and Azhar which is complete for NEXP, the first
level of the exponential hierarchy. Also it turns out that the hardness results
do not collapse at the consideration of conjunctive and disjunctive normal
forms, in contrast to plain QBF.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03050</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03061</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Minimum Conditional Description Length Estimation for Markov Random
  Fields</dc:title>
 <dc:creator>Reyes, Matthew G.</dc:creator>
 <dc:creator>Neuhoff, David L.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  In this paper we discuss a method, which we call Minimum Conditional
Description Length (MCDL), for estimating the parameters of a subset of sites
within a Markov random field. We assume that the edges are known for the entire
graph $G=(V,E)$. Then, for a subset $U\subset V$, we estimate the parameters
for nodes and edges in $U$ as well as for edges incident to a node in $U$, by
finding the exponential parameter for that subset that yields the best
compression conditioned on the values on the boundary $\partial U$. Our
estimate is derived from a temporally stationary sequence of observations on
the set $U$. We discuss how this method can also be applied to estimate a
spatially invariant parameter from a single configuration, and in so doing,
derive the Maximum Pseudo-Likelihood (MPL) estimate.
</dc:description>
 <dc:description>Comment: Information Theory and Applications (ITA) workshop, February 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03061</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03072</identifier>
 <datestamp>2016-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Big Graph Mining: Frameworks and Techniques</dc:title>
 <dc:creator>Aridhi, Sabeur</dc:creator>
 <dc:creator>Nguifo, Engelbert Mephu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Big graph mining is an important research area and it has attracted
considerable attention. It allows to process, analyze, and extract meaningful
information from large amounts of graph data. Big graph mining has been highly
motivated not only by the tremendously increasing size of graphs but also by
its huge number of applications. Such applications include bioinformatics,
chemoinformatics and social networks. One of the most challenging tasks in big
graph mining is pattern mining in big graphs. This task consists on using data
mining algorithms to discover interesting, unexpected and useful patterns in
large amounts of graph data. It aims also to provide deeper understanding of
graph data. In this context, several graph processing frameworks and scaling
data mining/pattern mining techniques have been proposed to deal with very big
graphs. This paper gives an overview of existing data mining and graph
processing frameworks that deal with very big graphs. Then it presents a survey
of current researches in the field of data mining / pattern mining in big
graphs and discusses the main research issues related to this field. It also
gives a categorization of both distributed data mining and machine learning
techniques, graph processing frameworks and large scale pattern mining
approaches.
</dc:description>
 <dc:description>Comment: Submitted to Big Data Research, Elsevier</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03072</dc:identifier>
 <dc:identifier>doi:10.1016/j.bdr.2016.07.002</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03084</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local Codes with Cooperative Repair in Distributed Storage System</dc:title>
 <dc:creator>Wang, Jing</dc:creator>
 <dc:creator>Yan, Zhiyuan</dc:creator>
 <dc:creator>Xie, Hongmei</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Recently, the research on local repair codes is mainly confined to repair the
failed nodes within each repair group. But if the extreme cases occur that the
entire repair group has failed, the local code stored in the failed group need
to be recovered as a whole. In this paper, local codes with cooperative repair,
in which the local codes are constructed based on minimum storage regeneration
(MSR) codes, is proposed to achieve repairing the failed groups. Specifically,
the proposed local codes with cooperative repair construct a kind of mutual
interleaving structure among the parity symbols, that the parity symbols of
each local code, named as distributed local parity, can be generated by the
parity symbols of the MSR codes in its two adjacent local codes. Taking
advantage of the structure given, the failed local groups can be repaired
cooperatively by their adjacent local groups with lower repair locality, and
meanwhile the minimum distance of local codes with cooperative repair is
derived. Theoretical analysis and simulation experiments show that, compared
with codes with local regeneration (such as MSR-local codes and MBR-local
codes), the proposed local codes with cooperative repair have benefits in
bandwidth overhead and repair locality for the case of local groups failure.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03084</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03086</identifier>
 <datestamp>2017-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>RECKONER: Read Error Corrector Based on KMC</dc:title>
 <dc:creator>Dlugosz, Maciej</dc:creator>
 <dc:creator>Deorowicz, Sebastian</dc:creator>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Motivation: Next-generation sequencing tools have enabled producing of huge
amount of genomic information at low cost. Unfortunately, presence of
sequencing errors in such data affects quality of downstream analyzes. Accuracy
of them can be improved by performing error correction. Because of huge amount
of such data correction algorithms have to: be fast, memory-frugal, and provide
high accuracy of error detection and elimination for variously-sized organisms.
  Results: We introduce a new algorithm for genomic data correction, capable of
processing eucaryotic 300 Mbp-genome-size, high error-rated data using less
than 4 GB of RAM in less than 40 minutes on 16-core CPU. The algorithm allows
to correct sequencing data at better or comparable level than competitors. This
was achieved by using very robust KMC~2 $k$-mer counter, new method of
erroneous regions correction based on both $k$-mer counts and FASTQ quality
indicators as well as careful optimization. Availability: Program is freely
available at http://sun.aei.posl.pl/REFRESH/reckoner. Contact:
sebastian.deorowicz@polsl.pl
</dc:description>
 <dc:description>Comment: 7 pages + 24 pages of supplementary material</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03086</dc:identifier>
 <dc:identifier>doi:10.1093/bioinformatics/btw746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03090</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Differentially Private Chi-Squared Hypothesis Testing: Goodness of Fit
  and Independence Testing</dc:title>
 <dc:creator>Gaboardi, Marco</dc:creator>
 <dc:creator>Lim, Hyun woo</dc:creator>
 <dc:creator>Rogers, Ryan</dc:creator>
 <dc:creator>Vadhan, Salil</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Hypothesis testing is a useful statistical tool in determining whether a
given model should be rejected based on a sample from the population. Sample
data may contain sensitive information about individuals, such as medical
information. Thus it is important to design statistical tests that guarantee
the privacy of subjects in the data. In this work, we study hypothesis testing
subject to differential privacy, specifically chi-squared tests for goodness of
fit for multinomial data and independence between two categorical variables.
  We propose new tests for goodness of fit and independence testing that like
the classical versions can be used to determine whether a given model should be
rejected or not, and that additionally can ensure differential privacy. We give
both Monte Carlo based hypothesis tests as well as hypothesis tests that more
closely follow the classical chi-squared goodness of fit test and the Pearson
chi-squared test for independence. Crucially, our tests account for the
distribution of the noise that is injected to ensure privacy in determining
significance.
  We show that these tests can be used to achieve desired significance levels,
in sharp contrast to direct applications of classical tests to differentially
private contingency tables which can result in wildly varying significance
levels. Moreover, we study the statistical power of these tests. We empirically
show that to achieve the same level of power as the classical non-private tests
our new tests need only a relatively modest increase in sample size.
</dc:description>
 <dc:date>2016-02-07</dc:date>
 <dc:date>2016-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03090</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03091</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing the Estimation of mm-Wave Large Array Channels by Exploiting
  Spatio-Temporal Correlation and Sparse Scattering</dc:title>
 <dc:creator>Haghighatshoar, Saeid</dc:creator>
 <dc:creator>Caire, Giuseppe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In order to cope with the large path-loss exponent of mm-Wave channels, a
high beamforming gain is needed. This can be achieved with small hardware
complexity and high hardware power efficiency by Hybrid Digital-Analog (HDA)
beamforming, where a very large number $M\gg 1$ of antenna array elements
requires only a relatively small $m\ll M$ number of A/D converters and
modulators/demodulators. As such, the estimation of mm-Wave MIMO channels must
deal with two specific problems: 1) high Doppler, due to the large carrier
frequency; 2) impossibility of observing directly the M-dimensional channel
vector at the antenna array elements, due to the mentioned HDA implementation.
In this paper, we consider a novel scheme inspired by recent results on
gridless multiple measurement vectors problem in compressed sensing, that is
able to exploit the inherent mm-Wave channel sparsity in the angular domain in
order to cope with both the above problems simultaneously. Our scheme uses past
pilot-symbol observations in a window of length $T$ in order to estimate a
low-dimensional subspace that approximately contains the channel vector at the
current time. This subspace information can be used directly, in order to
separate users in the spatial domain, or indirectly, in order to improve the
estimate of the user channel vector from the current pilot-symbol observation.
</dc:description>
 <dc:description>Comment: 7 pages, 4 figures. Accepted for presentation at WSA 2016, Munich,
  Germany</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03091</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03095</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>OpenRISC System-on-Chip Design Emulation</dc:title>
 <dc:creator>Cong, Kai</dc:creator>
 <dc:creator>Lei, Li</dc:creator>
 <dc:creator>Yang, Zhenkun</dc:creator>
 <dc:creator>Xie, Fei</dc:creator>
 <dc:subject>Computer Science - Hardware Architecture</dc:subject>
 <dc:description>  Recently the hardware emulation technique has emerged as a promising approach
to accelerating hardware verification/debugging process. To fully evaluate the
powerfulness of the emulation approach and demonstrate its potential impact, we
propose to emulate a system-on-chip (SoC) design using Mentor Graphics Veloce
emulation platform. This article presents our project setup and the results we
have achieved. The results are encouraging. ORPSoC emulation with Veloce has
more than ten times faster than hardware simulation. Our experimental results
demonstrate that Mentor Graphics Veloce has major advantages in emulation,
verification, and debugging of complicated real hardware designs, especially in
the context of SoC complexity. Through our three major tasks, we will
demonstrate that (1) Veloce can successfully emulate large-scale SoC designs;
(2) it has much better performance comparing to the state-of-the-art simulation
tools; (3) it can significantly accelerate the process of hardware verification
and debugging while maintaining full signal visibility.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03095</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03097</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Open Sesame: The Password Hashing Competition and Argon2</dc:title>
 <dc:creator>Wetzels, Jos</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>E.3</dc:subject>
 <dc:description>  In this document we present an overview of the background to and goals of the
Password Hashing Competition (PHC) as well as the design of its winner, Argon2,
and its security requirements and properties.
</dc:description>
 <dc:description>Comment: 17 pages</dc:description>
 <dc:date>2016-02-08</dc:date>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03097</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03100</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improving Data Quality in Intelligent Transportation Systems</dc:title>
 <dc:creator>Megler, V. M.</dc:creator>
 <dc:creator>Tufte, Kristin</dc:creator>
 <dc:creator>Maier, David</dc:creator>
 <dc:subject>Computer Science - Other Computer Science</dc:subject>
 <dc:description>  Intelligent Transportation Systems (ITS) use data and information technology
to improve the operation of our transportation network. ITS contributes to
sustainable development by using technology to make the transportation system
more efficient; improving our environment by reducing emissions, reducing the
need for new construction and improving our daily lives through reduced
congestion. A key component of ITS is traveler information. The Oregon
Department of Transportation (ODOT) recently implemented a new traveler
information system on selected freeways to provide drivers with travel time
estimates that allow them to make more informed decisions about routing to
their destinations. The ODOT project aims to improve traffic flow and promote
efficient traffic movement, which can reduce emissions rates and improve air
quality. The new ODOT system is based on travel data collected from a
recently-increased set of sensors installed on its freeways. Our current
project investigates novel data cleaning methodologies and the integration of
those methodologies into the prediction of travel times. We use machine
learning techniques on our archive to identify suspect data, and calculate
revised travel times excluding this suspect data. We compare the resulting
travel time predictions to ground-truth data, and to predictions based on
simple, rule-based data cleaning. We report on the results of our study using
qualitative and quantitative methods.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03100</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03101</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Barbara Made the News: Mining the Behavior of Crowds for Time-Aware
  Learning to Rank</dc:title>
 <dc:creator>Martins, Fl&#xe1;vio</dc:creator>
 <dc:creator>Magalh&#xe3;es, Jo&#xe3;o</dc:creator>
 <dc:creator>Callan, Jamie</dc:creator>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>H.3.3</dc:subject>
 <dc:description>  In Twitter, and other microblogging services, the generation of new content
by the crowd is often biased towards immediacy: what is happening now. Prompted
by the propagation of commentary and information through multiple mediums,
users on the Web interact with and produce new posts about newsworthy topics
and give rise to trending topics. This paper proposes to leverage on the
behavioral dynamics of users to estimate the most relevant time periods for a
topic. Our hypothesis stems from the fact that when a real-world event occurs
it usually has peak times on the Web: a higher volume of tweets, new visits and
edits to related Wikipedia articles, and news published about the event. In
this paper, we propose a novel time-aware ranking model that leverages on
multiple sources of crowd signals. Our approach builds on two major novelties.
First, a unifying approach that given query q, mines and represents temporal
evidence from multiple sources of crowd signals. This allows us to predict the
temporal relevance of documents for query q. Second, a principled retrieval
model that integrates temporal signals in a learning to rank framework, to rank
results according to the predicted temporal relevance. Evaluation on the TREC
2013 and 2014 Microblog track datasets demonstrates that the proposed model
achieves a relative improvement of 13.2% over lexical retrieval models and 6.2%
over a learning to rank baseline.
</dc:description>
 <dc:description>Comment: To appear in WSDM 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03101</dc:identifier>
 <dc:identifier>doi:10.1145/2835776.2835825</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03103</identifier>
 <datestamp>2017-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Embedding Graphs in Lorentzian Spacetime</dc:title>
 <dc:creator>Clough, James R.</dc:creator>
 <dc:creator>Evans, Tim S.</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Geometric approaches to network analysis combine simply defined models with
great descriptive power. In this work we provide a method for embedding
directed acyclic graphs into Minkowski spacetime using Multidimensional scaling
(MDS). First we generalise the classical MDS algorithm, defined only for
metrics with a Euclidean signature, to manifolds of any metric signature. We
then use this general method to develop an algorithm to be used on networks
which have causal structure allowing them to be embedded in Lorentzian
manifolds. The method is demonstrated by calculating embeddings for both causal
sets and citation networks in Minkowski spacetime. We finally suggest a number
of applications in citation analysis such as paper recommendation, identifying
missing citations and fitting citation models to data using this geometric
approach.
</dc:description>
 <dc:description>Comment: 15 pages, 6 figure, 2 page appendix</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03103</dc:identifier>
 <dc:identifier>PLoS ONE 12 (2017) e0187301</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0187301</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03104</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Graph Isomorphism-based Decentralized Algorithm for Modular Robot
  Configuration Formation</dc:title>
 <dc:creator>Dutta, Ayan</dc:creator>
 <dc:creator>Dasgupta, Prithviraj</dc:creator>
 <dc:creator>Nelson, Carl</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  We consider the problem of configuration formation in modular robot systems
where a set of modules that are initially in different configurations and
located at different locations are required to assume appropriate positions so
that they can get into a new, user-specified, target configuration. We propose
a novel algorithm based on graph isomorphism, where the modules select
locations or spots in the target configuration using a utility-based framework,
while retaining their original configuration to the greatest extent possible,
to reduce the time and energy required by the modules to assume the target
configuration. We have shown analytically that our proposed algorithm is
complete and guarantees a Pareto-optimal allocation. Experimental simulations
of our algorithm with different number of modules in different initial
configurations and located initially at different locations, show that the
planning time of our algorithm is nominal (order of msec. for 100 modules). We
have also compared our algorithm against a market-based allocation algorithm
and shown that our proposed algorithm performs better in terms of time and
number of messages exchanged.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03104</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03105</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graphical Model Sketch</dc:title>
 <dc:creator>Kveton, Branislav</dc:creator>
 <dc:creator>Bui, Hung</dc:creator>
 <dc:creator>Ghavamzadeh, Mohammad</dc:creator>
 <dc:creator>Theocharous, Georgios</dc:creator>
 <dc:creator>Muthukrishnan, S.</dc:creator>
 <dc:creator>Sun, Siqi</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Structured high-cardinality data arises in many domains, and poses a major
challenge for both modeling and inference. Graphical models are a popular
approach to modeling structured data but they are unsuitable for
high-cardinality variables. The count-min (CM) sketch is a popular approach to
estimating probabilities in high-cardinality data but it does not scale well
beyond a few variables. In this work, we bring together the ideas of graphical
models and count sketches; and propose and analyze several approaches to
estimating probabilities in structured high-cardinality streams of data. The
key idea of our approximations is to use the structure of a graphical model and
approximately estimate its factors by &quot;sketches&quot;, which hash high-cardinality
variables using random projections. Our approximations are computationally
efficient and their space complexity is independent of the cardinality of
variables. Our error bounds are multiplicative and significantly improve upon
those of the CM sketch, a state-of-the-art approach to estimating probabilities
in streams. We evaluate our approximations on synthetic and real-world
problems, and report an order of magnitude improvements over the CM sketch.
</dc:description>
 <dc:description>Comment: Proceedings of the European Conference on Machine Learning and
  Knowledge Discovery in Databases</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03105</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03109</identifier>
 <datestamp>2017-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Number of fixed points and disjoint cycles in monotone Boolean networks</dc:title>
 <dc:creator>Aracena, Julio</dc:creator>
 <dc:creator>Richard, Adrien</dc:creator>
 <dc:creator>Salinas, Lilian</dc:creator>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Quantitative Biology - Molecular Networks</dc:subject>
 <dc:description>  Given a digraph $G$, a lot of attention has been deserved on the maximum
number $\phi(G)$ of fixed points in a Boolean network $f:\{0,1\}^n\to\{0,1\}^n$
with $G$ as interaction graph. In particular, a central problem in network
coding consists in studying the optimality of the classical upper bound
$\phi(G)\leq 2^{\tau}$, where $\tau$ is the minimum size of a feedback vertex
set of $G$. In this paper, we study the maximum number $\phi_m(G)$ of fixed
points in a {\em monotone} Boolean network with interaction graph $G$. We
establish new upper and lower bounds on $\phi_m(G)$ that depends on the cycle
structure of $G$. In addition to $\tau$, the involved parameters are the
maximum number $\nu$ of vertex-disjoint cycles, and the maximum number
$\nu^{*}$ of vertex-disjoint cycles verifying some additional technical
conditions. We improve the classical upper bound $2^\tau$ by proving that
$\phi_m(G)$ is at most the largest sub-lattice of $\{0,1\}^\tau$ without chain
of size $\nu+1$, and without another forbidden-pattern of size $2\nu^{*}$.
Then, we prove two optimal lower bounds: $\phi_m(G)\geq \nu+1$ and
$\phi_m(G)\geq 2^{\nu^{*}}$. As a consequence, we get the following
characterization: $\phi_m(G)=2^\tau$ if and only if $\nu^{*}=\tau$. As another
consequence, we get that if $c$ is the maximum length of a chordless cycle of
$G$ then $2^{\nu/3^c}\leq\phi_m(G)\leq 2^{c\nu}$. Finally, with the technics
introduced, we establish an upper bound on the number of fixed points of any
Boolean network according to its signed interaction graph.
</dc:description>
 <dc:description>Comment: 24 pages</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2017-11-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03109</dc:identifier>
 <dc:identifier>SIAM Journal on Discrete Mathematics, 31(3):1702-1725, 2017</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03110</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Holistic Influence Maximization: Combining Scalability and Efficiency
  with Opinion-Aware Models</dc:title>
 <dc:creator>Galhotra, Sainyam</dc:creator>
 <dc:creator>Arora, Akhil</dc:creator>
 <dc:creator>Roy, Shourya</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>H.2.8</dc:subject>
 <dc:description>  The steady growth of graph data from social networks has resulted in
wide-spread research in finding solutions to the influence maximization
problem. In this paper, we propose a holistic solution to the influence
maximization (IM) problem. (1) We introduce an opinion-cum-interaction (OI)
model that closely mirrors the real-world scenarios. Under the OI model, we
introduce a novel problem of Maximizing the Effective Opinion (MEO) of
influenced users. We prove that the MEO problem is NP-hard and cannot be
approximated within a constant ratio unless P=NP. (2) We propose a heuristic
algorithm OSIM to efficiently solve the MEO problem. To better explain the OSIM
heuristic, we first introduce EaSyIM - the opinion-oblivious version of OSIM, a
scalable algorithm capable of running within practical compute times on
commodity hardware. In addition to serving as a fundamental building block for
OSIM, EaSyIM is capable of addressing the scalability aspect - memory
consumption and running time, of the IM problem as well.
  Empirically, our algorithms are capable of maintaining the deviation in the
spread always within 5% of the best known methods in the literature. In
addition, our experiments show that both OSIM and EaSyIM are effective,
efficient, scalable and significantly enhance the ability to analyze real
datasets.
</dc:description>
 <dc:description>Comment: ACM SIGMOD Conference 2016, 18 pages, 29 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03110</dc:identifier>
 <dc:identifier>doi:10.1145/2882903.2882929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03111</identifier>
 <datestamp>2017-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Boosting Information Spread: An Algorithmic Approach</dc:title>
 <dc:creator>Lin, Yishi</dc:creator>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  The majority of influence maximization (IM) studies focus on targeting
influential seeders to trigger substantial information spread in social
networks. In this paper, we consider a new and complementary problem of how to
further increase the influence spread of given seeders. Our study is motivated
by the observation that direct incentives could &quot;boost&quot; users so that they are
more likely to be influenced by friends. We study the $k$-boosting problem
which aims to find $k$ users to boost so that the final &quot;boosted&quot; influence
spread is maximized. The $k$-boosting problem is different from the IM problem
because boosted users behave differently from seeders: boosted users are
initially uninfluenced and we only increase their probability to be influenced.
Our work also complements the IM studies because we focus on triggering larger
influence spread on the basis of given seeders. Both the NP-hardness of the
problem and the non-submodularity of the objective function pose challenges to
the $k$-boosting problem. To tackle the problem on general graphs, we devise
two efficient algorithms with the data-dependent approximation ratio. For the
$k$-boosting problem on bidirected trees, we present an efficient greedy
algorithm and a rounded dynamic programming that is a fully polynomial-time
approximation scheme. We conduct extensive experiments using real social
networks and synthetic bidirected trees. We show that boosting solutions
returned by our algorithms achieves boosts of influence that are up to several
times higher than those achieved by boosting solutions returned by intuitive
baselines, which have no guarantee of solution quality. We also explore the
&quot;budget allocation&quot; problem in our experiments. Compared with targeting seeders
with all budget, larger influence spread is achieved when we allocation the
budget to both seeders and boosted users.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2017-06-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03111</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03115</identifier>
 <datestamp>2017-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Towards Robustness in Residue Number Systems</dc:title>
 <dc:creator>Xiao, Li</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:creator>Huo, Haiye</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Number Theory</dc:subject>
 <dc:description>  The problem of robustly reconstructing a large number from its erroneous
remainders with respect to several moduli, namely the robust remaindering
problem, may occur in many applications including phase unwrapping, frequency
detection from several undersampled waveforms, wireless sensor networks, etc.
Assuming that the dynamic range of the large number is the maximal possible
one, i.e., the least common multiple (lcm) of all the moduli, a method called
robust Chinese remainder theorem (CRT) for solving the robust remaindering
problem has been recently proposed. In this paper, by relaxing the assumption
that the dynamic range is fixed to be the lcm of all the moduli, a trade-off
between the dynamic range and the robustness bound for two-modular systems is
studied. It basically says that a decrease in the dynamic range may lead to an
increase of the robustness bound. We first obtain a general condition on the
remainder errors and derive the exact dynamic range with a closed-form formula
for the robustness to hold. We then propose simple closed-form reconstruction
algorithms. Furthermore, the newly obtained two-modular results are applied to
the robust reconstruction for multi-modular systems and generalized to real
numbers. Finally, some simulations are carried out to verify our proposed
theoretical results.
</dc:description>
 <dc:description>Comment: 32 pages, 5 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03115</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2641398</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03117</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Layering of Communication Networks and a Forward-Backward Duality</dc:title>
 <dc:creator>Cyran, Michael</dc:creator>
 <dc:creator>Schotsch, Birgit</dc:creator>
 <dc:creator>Huber, Johannes B.</dc:creator>
 <dc:creator>Fischer, Robert F. H.</dc:creator>
 <dc:creator>Forutan, Vahid</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In layered communication networks there are only connections between
intermediate nodes in adjacent layers. Applying network coding to such networks
provides a number of benefits in theory as well as in practice. We propose a
&quot;layering procedure&quot; to transform an arbitrary network into a layered
structure. Furthermore, we derive a &quot;forward-backward duality&quot; for linear
network codes, which can be seen as an analogon to the &quot;uplink-downlink
duality&quot; in MIMO communication systems.
</dc:description>
 <dc:description>Comment: 5 pages, 6 figures, submitted to ISIT 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03117</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03124</identifier>
 <datestamp>2017-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Even Delta-Matroids and the Complexity of Planar Boolean CSPs</dc:title>
 <dc:creator>Kazda, Alexandr</dc:creator>
 <dc:creator>Kolmogorov, Vladimir</dc:creator>
 <dc:creator>Rol&#xed;nek, Michal</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>68Q25</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.2</dc:subject>
 <dc:description>  The main result of this paper is a generalization of the classical blossom
algorithm for finding perfect matchings. Our algorithm can efficiently solve
Boolean CSPs where each variable appears in exactly two constraints (we call it
edge CSP) and all constraints are even $\Delta$-matroid relations (represented
by lists of tuples). As a consequence of this, we settle the complexity
classification of planar Boolean CSPs started by Dvorak and Kupec.
  Knowing that edge CSP is tractable for even $\Delta$-matroid constraints
allows us to extend the tractability result to a larger class of
$\Delta$-matroids that includes many classes that were known to be tractable
before, namely co-independent, compact, local and binary.
</dc:description>
 <dc:description>Comment: 40 pages, 9 figures; stabilizable delta-matroids generalized to
  effectively coverable delta-matroids</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2017-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03124</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03139</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hazard analysis of human--robot interactions with HAZOP--UML</dc:title>
 <dc:creator>Guiochet, J&#xe9;r&#xe9;mie</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  New safety critical systems are about to appear in our everyday life:
advanced robots able to interact with humans and perform tasks at home, in
hospitals , or at work. A hazardous behavior of those systems, induced by
failures or extreme environment conditions, may lead to catastrophic
consequences. Well-known risk analysis methods used in other critical domains
(e.g., avion-ics, nuclear, medical, transportation), have to be extended or
adapted due to the non-deterministic behavior of those systems, evolving in
unstructured environments. One major challenge is thus to develop methods that
can be applied at the very beginning of the development process, to identify
hazards induced by robot tasks and their interactions with humans. In this
paper we present a method which is based on an adaptation of a hazard
identification technique, HAZOP (Hazard Operability), coupled with a system
description notation, UML (Unified Modeling Language). This systematic approach
has been applied successfully in research projects, and is now applied by robot
manufacturers. Some results of those studies are presented and discussed to
explain the benefits and limits of our method.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03139</dc:identifier>
 <dc:identifier>Safety Science, Elsevier, 2016, 84</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03145</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A New Spatio-Spectral Morphological Segmentation For Multi-Spectral
  Remote-Sensing Images</dc:title>
 <dc:creator>Noyel, Guillaume</dc:creator>
 <dc:creator>Angulo, Jesus</dc:creator>
 <dc:creator>Jeulin, Dominique</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A general framework of spatio-spectral segmentation for multi-spectral images
is introduced in this paper. The method is based on classification-driven
stochastic watershed (WS) by Monte Carlo simulations, and it gives more regular
and reliable contours than standard WS. The present approach is decomposed into
several sequential steps. First, a dimensionality-reduction stage is performed
using the factor-correspondence analysis method. In this context, a new way to
select the factor axes (eigenvectors) according to their spatial information is
introduced. Then, a spectral classification produces a spectral
pre-segmentation of the image. Subsequently, a probability density function
(pdf) of contours containing spatial and spectral information is estimated by
simulation using a stochastic WS approach driven by the spectral
classification. The pdf of the contours is finally segmented by a WS controlled
by markers from a regularization of the initial classification.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03145</dc:identifier>
 <dc:identifier>International Journal of Remote Sensing, Taylor \&amp; Francis, 2010,
  31 (22), pp.5895-5920</dc:identifier>
 <dc:identifier>doi:10.1080/01431161.2010.512314</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03146</identifier>
 <datestamp>2016-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DCM Bandits: Learning to Rank with Multiple Clicks</dc:title>
 <dc:creator>Katariya, Sumeet</dc:creator>
 <dc:creator>Kveton, Branislav</dc:creator>
 <dc:creator>Szepesv&#xe1;ri, Csaba</dc:creator>
 <dc:creator>Wen, Zheng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  A search engine recommends to the user a list of web pages. The user examines
this list, from the first page to the last, and clicks on all attractive pages
until the user is satisfied. This behavior of the user can be described by the
dependent click model (DCM). We propose DCM bandits, an online learning variant
of the DCM where the goal is to maximize the probability of recommending
satisfactory items, such as web pages. The main challenge of our learning
problem is that we do not observe which attractive item is satisfactory. We
propose a computationally-efficient learning algorithm for solving our problem,
dcmKL-UCB; derive gap-dependent upper bounds on its regret under reasonable
assumptions; and also prove a matching lower bound up to logarithmic factors.
We evaluate our algorithm on synthetic and real-world problems, and show that
it performs well even when our model is misspecified. This work presents the
first practical and regret-optimal online algorithm for learning to rank with
multiple clicks in a cascade-like click model.
</dc:description>
 <dc:description>Comment: Proceedings of the 33rd International Conference on Machine Learning</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03146</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03153</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Limiting Self-Propagating Malware Based on Connection Failure Behavior
  through Hyper-Compact Estimators</dc:title>
 <dc:creator>Zhou, You</dc:creator>
 <dc:creator>Zhou, Yian</dc:creator>
 <dc:creator>Chen, Shigang</dc:creator>
 <dc:creator>Kreidl, O. Patrick</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Self-propagating malware (e.g., an Internet worm) exploits security loopholes
in software to infect servers and then use them to scan the Internet for more
vulnerable servers. While the mechanisms of worm infection and their
propagation models are well understood, defense against worms remains an open
problem. One branch of defense research investigates the behavioral difference
between worm-infected hosts and normal hosts to set them apart. One particular
observation is that a worm-infected host, which scans the Internet with
randomly selected addresses, has a much higher connection-failure rate than a
normal host. Rate-limit algorithms have been proposed to control the spread of
worms by traffic shaping based on connection failure rate. However, these
rate-limit algorithms can work properly only if it is possible to measure
failure rates of individual hosts efficiently and accurately. This paper points
out a serious problem in the prior method. To address this problem, we first
propose a solution based on a highly efficient double-bitmap data structure,
which places only a small memory footprint on the routers, while providing good
measurement of connection failure rates whose accuracy can be tuned by system
parameters. Furthermore, we propose another solution based on shared register
array data structure, achieving better memory efficiency and much larger
estimation range than our double-bitmap solution.
</dc:description>
 <dc:description>Comment: International Journal of Network Security &amp; Its Applications (IJNSA)
  Vol.8, No.1, January 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03153</dc:identifier>
 <dc:identifier>doi:10.5121/ijnsa.2016.8101</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03199</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Instability of Sensor Orientation in Gait Verification on Mobile
  Phone</dc:title>
 <dc:creator>Hoang, Thang</dc:creator>
 <dc:creator>Choi, Deokjai</dc:creator>
 <dc:creator>Nguyen, Thuc</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Authentication schemes using tokens or biometric modalities have been
proposed to ameliorate the security strength on mobile devices. However, the
existing approaches are obtrusive since the user is required to perform
explicit gestures in order to be authenticated. While the gait signal captured
by inertial sensors is understood to be a reliable profile for effective
implicit authentication, recent studies have been conducted in ideal conditions
and might therefore be inapplicable in the real mobile context. Particularly,
the acquiring sensor is always fixed to a specific position and orientation.
This paper mainly focuses on addressing the instability of sensor's orientation
which mostly happens in the reality. A flexible solution taking advantages of
available sensors on mobile devices which can help to handle this problem is
presented. Moreover, a novel gait recognition method utilizes statistical
analysis and supervised learning to adapt itself to the instability of the
biometric gait under various circumstances is also proposed. By adopting
PCA+SVM to construct the gait model, the proposed method outperformed other
state-of-the-art studies, with an equal error rate of 2.45\% and accuracy rate
of 99.14\% in terms of the verification and identification aspects being
achieved, respectively.
</dc:description>
 <dc:description>Comment: 12 pages, 7 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03199</dc:identifier>
 <dc:identifier>SECRYPT 2015, pp. 148-159</dc:identifier>
 <dc:identifier>doi:10.5220/0005572001480159</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03202</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Market Model and Optimal Pricing Scheme of Big Data and Internet of
  Things (IoT)</dc:title>
 <dc:creator>Niyato, Dusit</dc:creator>
 <dc:creator>Alsheikh, Mohammad Abu</dc:creator>
 <dc:creator>Wang, Ping</dc:creator>
 <dc:creator>Kim, Dong In</dc:creator>
 <dc:creator>Han, Zhu</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Big data has been emerging as a new approach in utilizing large datasets to
optimize complex system operations. Big data is fueled with Internet-of-Things
(IoT) services that generate immense sensory data from numerous sensors and
devices. While most current research focus of big data is on machine learning
and resource management design, the economic modeling and analysis have been
largely overlooked. This paper thus investigates the big data market model and
optimal pricing scheme. We first study the utility of data from the data
science perspective, i.e., using the machine learning methods. We then
introduce the market model and develop an optimal pricing scheme afterward. The
case study shows clearly the suitability of the proposed data utility
functions. The numerical examples demonstrate that big data and IoT service
provider can achieve the maximum profit through the proposed market model.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03202</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7510922</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03203</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time Resource Networks</dc:title>
 <dc:creator>Sidor, Szymon</dc:creator>
 <dc:creator>Yu, Peng</dc:creator>
 <dc:creator>Fang, Cheng</dc:creator>
 <dc:creator>Williams, Brian</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  The problem of scheduling under resource constraints is widely applicable.
One prominent example is power management, in which we have a limited
continuous supply of power but must schedule a number of power-consuming tasks.
Such problems feature tightly coupled continuous resource constraints and
continuous temporal constraints.
  We address such problems by introducing the Time Resource Network (TRN), an
encoding for resource-constrained scheduling problems. The definition allows
temporal specifications using a general family of representations derived from
the Simple Temporal network, including the Simple Temporal Network with
Uncertainty, and the probabilistic Simple Temporal Network (Fang et al.
(2014)).
  We propose two algorithms for determining the consistency of a TRN: one based
on Mixed Integer Programing and the other one based on Constraint Programming,
which we evaluate on scheduling problems with Simple Temporal Constraints and
Probabilistic Temporal Constraints.
</dc:description>
 <dc:description>Comment: 7 pages, submitted for review to IJCAI16</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03205</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Image encryption with dynamic chaotic Look-Up Table</dc:title>
 <dc:creator>Abdmouleh, Med Karim</dc:creator>
 <dc:creator>Khalfallah, Ali</dc:creator>
 <dc:creator>Bouhlel, Med Salim</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this paper we propose a novel image encryption scheme. The proposed method
is based on the chaos theory. Our cryptosystem uses the chaos theory to define
a dynamic chaotic Look-Up Table (LUT) to compute the new value of the current
pixel to cipher. Applying this process on each pixel of the plain image, we
generate the encrypted image. The results of different experimental tests, such
as Key space analysis, Information Entropy and Histogram analysis, show that
the proposed encryption image scheme seems to be protected against various
attacks. A comparison between the plain and encrypted image, in terms of
correlation coefficient, proves that the plain image is very different from the
encrypted one.
</dc:description>
 <dc:description>Comment: 7 pages, 12 figures, 6th International Conference on Sciences of
  Electronics, Technologies of Information and Telecommunications (SETIT), 2012</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03205</dc:identifier>
 <dc:identifier>doi:10.1109/SETIT.2012.6481937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03206</identifier>
 <datestamp>2016-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Design of false color palettes for grayscale reproduction</dc:title>
 <dc:creator>Sala, Filip A.</dc:creator>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Design of false color palette is quite easy but some effort has to be done to
achieve good dynamic range, contrast and overall appearance of the palette.
Such palettes, for instance, are commonly used in scientific papers for
presenting the data. However, to lower the cost of the paper most scientists
decide to let the data to be printed in grayscale. The same applies to e-book
readers based on e-ink where most of them are still grayscale. For majority of
false color palettes reproducing them in grayscale results in ambiguous mapping
of the colors and may be misleading for the reader. In this article design of
false color palettes suitable for grayscale reproduction is described. Due to
the monotonic change of luminance of these palettes grayscale representation is
very similar to the data directly presented with a grayscale palette. Some
suggestions and examples how to design such palettes are provided.
</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2016-03-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03206</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03208</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal asymptotic bounds on the oracle use in computations from
  Chaitin's Omega</dc:title>
 <dc:creator>Barmpalias, George</dc:creator>
 <dc:creator>Fang, Nan</dc:creator>
 <dc:creator>Lewis-Pye, Andrew</dc:creator>
 <dc:subject>Mathematics - Logic</dc:subject>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Chaitin's number Omega is the halting probability of a universal prefix-free
machine, and although it depends on the underlying enumeration of prefix-free
machines, it is always Turing-complete. It can be observed, in fact, that for
every computably enumerable (c.e.) real, there exists a Turing functional via
which Omega computes it, and such that the number of bits of omega that are
needed for the computation of the first n bits of the given number (i.e. the
use on argument n) is bounded above by a computable function h(n) = n+o(n). We
characterise the asymptotic upper bounds on the use of Chaitin's omega in
oracle computations of halting probabilities (i.e. c.e. reals). We show that
the following two conditions are equivalent for any computable function h such
that h(n)-n is non-decreasing: (1) h(n)-n is an information content measure,
(2) for every c.e. real there exists a Turing functional via which omega
computes the real with use bounded by h. We also give a similar
characterisation with respect to computations of c.e. sets from Omega, by
showing that the following are equivalent for any computable non-decreasing
function g: (1) g is an information-content measure, (2) for every c.e. set A,
Omega computes A with use bounded by g. Further results and some connections
with Solovay functions are given.
</dc:description>
 <dc:date>2016-02-05</dc:date>
 <dc:date>2016-05-03</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03208</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03218</identifier>
 <datestamp>2016-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Efficient Algorithms with Hierarchical Attentive Memory</dc:title>
 <dc:creator>Andrychowicz, Marcin</dc:creator>
 <dc:creator>Kurach, Karol</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this paper, we propose and investigate a novel memory architecture for
neural networks called Hierarchical Attentive Memory (HAM). It is based on a
binary tree with leaves corresponding to memory cells. This allows HAM to
perform memory access in O(log n) complexity, which is a significant
improvement over the standard attention mechanism that requires O(n)
operations, where n is the size of the memory.
  We show that an LSTM network augmented with HAM can learn algorithms for
problems like merging, sorting or binary searching from pure input-output
examples. In particular, it learns to sort n numbers in time O(n log n) and
generalizes well to input sequences much longer than the ones seen during the
training. We also show that HAM can be trained to act like classic data
structures: a stack, a FIFO queue and a priority queue.
</dc:description>
 <dc:description>Comment: Added soft attention appendix</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-23</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03218</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03220</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discriminative Regularization for Generative Models</dc:title>
 <dc:creator>Lamb, Alex</dc:creator>
 <dc:creator>Dumoulin, Vincent</dc:creator>
 <dc:creator>Courville, Aaron</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We explore the question of whether the representations learned by classifiers
can be used to enhance the quality of generative models. Our conjecture is that
labels correspond to characteristics of natural data which are most salient to
humans: identity in faces, objects in images, and utterances in speech. We
propose to take advantage of this by using the representations from
discriminative classifiers to augment the objective function corresponding to a
generative model. In particular we enhance the objective function of the
variational autoencoder, a popular generative model, with a discriminative
regularization term. We show that enhancing the objective function in this way
leads to samples that are clearer and have higher visual quality than the
samples from the standard variational autoencoders.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03220</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03228</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Busy Beaver Machines and the Observant Otter Heuristic (or How to Tame
  Dreadful Dragons)</dc:title>
 <dc:creator>Harland, James</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:description>  The busy beaver is a well-known specific example of a non-computable
function. Whilst many aspect of this problem have been investigated, it is not
always easy to find thorough and convincing evidence for the claims made about
the maximality of particular machines, and the phenomenal size of some of the
numbers involved means that it is not obvious that the problem can be feasibly
addressed at all. In this paper we address both of these issues. We discuss a
framework in which the busy beaver problem and similar problems may be
addressed, and the appropriate processes for providing evidence of claims made.
We also show how a simple heuristic, which we call the observant otter, can be
used to evaluate machines with an extremely large number of execution steps
required to terminate. We also show empirical results for an implementation of
this heuristic which show how this heuristic is effective for all known
`monster' machines.
</dc:description>
 <dc:description>Comment: This has been submitted to the Theoretical Computer Science journal</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03228</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03231</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Christoffel and standard words and their derivatives</dc:title>
 <dc:creator>D'Aniello, Alma</dc:creator>
 <dc:creator>de Luca, Aldo</dc:creator>
 <dc:creator>De Luca, Alessandro</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We introduce and study natural derivatives for Christoffel and finite
standard words, as well as for characteristic Sturmian words. These
derivatives, which are realized as inverse images under suitable morphisms,
preserve the aforementioned classes of words. In the case of Christoffel words,
the morphisms involved map $a$ to $a^{k+1}b$ (resp.,~$ab^{k}$) and $b$ to
$a^{k}b$ (resp.,~$ab^{k+1}$) for a suitable $k&gt;0$. As long as derivatives are
longer than one letter, higher-order derivatives are naturally obtained. We
define the depth of a Christoffel or standard word as the smallest order for
which the derivative is a single letter. We give several combinatorial and
arithmetic descriptions of the depth, and (tight) lower and upper bounds for
it.
</dc:description>
 <dc:description>Comment: 28 pages. Final version, to appear in TCS</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03231</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03247</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Exploring Dynamic Environments Using Stochastic Search Strategies</dc:title>
 <dc:creator>Pi&#xf1;a-Garc&#xed;a, C. A.</dc:creator>
 <dc:creator>Gu, Dongbing</dc:creator>
 <dc:creator>Siqueiros-Garc&#xed;a, J. Mario</dc:creator>
 <dc:creator>Carre&#xf3;n, Gustavo</dc:creator>
 <dc:creator>Gershenson, Carlos</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  In this paper, we conduct a literature review of laws of motion based on
stochastic search strategies which are mainly focused on exploring highly
dynamic environments. In this regard, stochastic search strategies represent an
interesting alternative to cope with uncertainty and reduced perceptual
capabilities. This study aims to present an introductory overview of research
in terms of directional rules and searching methods mainly based on
bio-inspired approaches. This study critically examines the role of animal
searching behavior applied to random walk models using stochastic rules and
kinesis or taxis. The aim of this study is to examine existing techniques and
to select relevant work on random walks and analyze their actual contributions.
In this regard, we cover a wide range of displacement events with an
orientation mechanism given by a reactive behavior or a source-seeking
behavior. Finally, we conclude with a discussion concerning the usefulness of
using optimal foraging strategies as a reliable methodology.
</dc:description>
 <dc:description>Comment: 8 pages, 11 figures</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03247</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03254</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings Eighth International Workshop on Programming Language
  Approaches to Concurrency- and Communication-cEntric Software</dc:title>
 <dc:creator>Gay, Simon</dc:creator>
 <dc:creator>Alglave, Jade</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  PLACES 2015 (full title: Programming Language Approaches to Concurrency- and
Communication-Centric Software) is the eighth edition of the PLACES workshop
series. After the first PLACES, which was affiliated to DisCoTec in 2008, the
workshop has been part of ETAPS every year since 2009 and is now an established
part of the ETAPS satellite events. PLACES 2015 was held on 18th April in
London, UK.
  The workshop series was started in order to promote the application of novel
programming language ideas to the increasingly important problem of developing
software for systems in which concurrency and communication are intrinsic
aspects. This includes software for both multi-core systems and large-scale
distributed and/or service-oriented systems. The scope of PLACES includes new
programming language features, whole new programming language designs, new type
systems, new semantic approaches, new program analysis techniques, and new
implementation mechanisms.
  This volume consists of revised versions of the papers that were presented at
the workshop.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03254</dc:identifier>
 <dc:identifier>EPTCS 203, 2016</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03256</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved Eigenfeature Regularization for Face Identification</dc:title>
 <dc:creator>Mandal, Bappaditya</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we propose to divide each class (a person) into subclasses
using spatial partition trees which helps in better capturing the
intra-personal variances arising from the appearances of the same individual.
We perform a comprehensive analysis on within-class and within-subclass
eigenspectrums of face images and propose a novel method of eigenspectrum
modeling which extracts discriminative features of faces from both
within-subclass and total or between-subclass scatter matrices. Effective
low-dimensional face discriminative features are extracted for face recognition
(FR) after performing discriminant evaluation in the entire eigenspace.
Experimental results on popular face databases (AR, FERET) and the challenging
unconstrained YouTube Face database show the superiority of our proposed
approach on all three databases.
</dc:description>
 <dc:description>Comment: 6 pages, 4 figures, ICIP 2015</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03256</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03258</identifier>
 <datestamp>2016-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interactive Bayesian Hierarchical Clustering</dc:title>
 <dc:creator>Vikram, Sharad</dc:creator>
 <dc:creator>Dasgupta, Sanjoy</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Clustering is a powerful tool in data analysis, but it is often difficult to
find a grouping that aligns with a user's needs. To address this, several
methods incorporate constraints obtained from users into clustering algorithms,
but unfortunately do not apply to hierarchical clustering. We design an
interactive Bayesian algorithm that incorporates user interaction into
hierarchical clustering while still utilizing the geometry of the data by
sampling a constrained posterior distribution over hierarchies. We also suggest
several ways to intelligently query a user. The algorithm, along with the
querying schemes, shows promising results on real data.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-04-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03258</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03264</identifier>
 <datestamp>2016-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Theory of Generative ConvNet</dc:title>
 <dc:creator>Xie, Jianwen</dc:creator>
 <dc:creator>Lu, Yang</dc:creator>
 <dc:creator>Zhu, Song-Chun</dc:creator>
 <dc:creator>Wu, Ying Nian</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  We show that a generative random field model, which we call generative
ConvNet, can be derived from the commonly used discriminative ConvNet, by
assuming a ConvNet for multi-category classification and assuming one of the
categories is a base category generated by a reference distribution. If we
further assume that the non-linearity in the ConvNet is Rectified Linear Unit
(ReLU) and the reference distribution is Gaussian white noise, then we obtain a
generative ConvNet model that is unique among energy-based models: The model is
piecewise Gaussian, and the means of the Gaussian pieces are defined by an
auto-encoder, where the filters in the bottom-up encoding become the basis
functions in the top-down decoding, and the binary activation variables
detected by the filters in the bottom-up convolution process become the
coefficients of the basis functions in the top-down deconvolution process. The
Langevin dynamics for sampling the generative ConvNet is driven by the
reconstruction error of this auto-encoder. The contrastive divergence learning
of the generative ConvNet reconstructs the training images by the auto-encoder.
The maximum likelihood learning algorithm can synthesize realistic natural
image patterns.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-05-31</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03264</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03265</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Simple Search Algorithms on Semantic Networks Learned from Language Use</dc:title>
 <dc:creator>Nematzadeh, Aida</dc:creator>
 <dc:creator>Miscevic, Filip</dc:creator>
 <dc:creator>Stevenson, Suzanne</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recent empirical and modeling research has focused on the semantic fluency
task because it is informative about semantic memory. An interesting interplay
arises between the richness of representations in semantic memory and the
complexity of algorithms required to process it. It has remained an open
question whether representations of words and their relations learned from
language use can enable a simple search algorithm to mimic the observed
behavior in the fluency task. Here we show that it is plausible to learn rich
representations from naturalistic data for which a very simple search algorithm
(a random walk) can replicate the human patterns. We suggest that explicitly
structuring knowledge about words into a semantic network plays a crucial role
in modeling human behavior in memory search and retrieval; moreover, this is
the case across a range of semantic information sources.
</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03265</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03266</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Computing Distances between Reach Flowpipes</dc:title>
 <dc:creator>Majumdar, Rupak</dc:creator>
 <dc:creator>Prabhu, Vinayak S.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  We investigate quantifying the difference between two hybrid dynamical
systems under noise and initial-state uncertainty. While the set of traces for
these systems is infinite, it is possible to symbolically approximate trace
sets using \emph{reachpipes} that compute upper and lower bounds on the
evolution of the reachable sets with time. We estimate distances between
corresponding sets of trajectories of two systems in terms of distances between
the reachpipes.
  In case of two individual traces, the Skorokhod distance has been proposed as
a robust and efficient notion of distance which captures both value and timing
distortions. In this paper, we extend the computation of the Skorokhod distance
to reachpipes, and provide algorithms to compute upper and lower bounds on the
distance between two sets of traces. Our algorithms use new geometric insights
that are used to compute the worst-case and best-case distances between two
polyhedral sets evolving with time.
</dc:description>
 <dc:description>Comment: Full version of paper accepted at HSCC 2016</dc:description>
 <dc:date>2016-02-09</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03266</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03273</identifier>
 <datestamp>2016-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>YTrace: End-to-end Performance Diagnosis in Large Cloud and Content
  Providers</dc:title>
 <dc:creator>Kanuparthy, Partha</dc:creator>
 <dc:creator>Dai, Yuchen</dc:creator>
 <dc:creator>Pathak, Sudhir</dc:creator>
 <dc:creator>Samal, Sambit</dc:creator>
 <dc:creator>Benson, Theophilus</dc:creator>
 <dc:creator>Ghasemi, Mojgan</dc:creator>
 <dc:creator>Narayan, P. P. S.</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>B.8.2</dc:subject>
 <dc:subject>C.2.4</dc:subject>
 <dc:subject>C.4</dc:subject>
 <dc:description>  Content providers build serving stacks to deliver content to users. An
important goal of a content provider is to ensure good user experience, since
user experience has an impact on revenue. In this paper, we describe a system
at Yahoo called YTrace that diagnoses bad user experience in near real time. We
present the different components of YTrace for end-to-end multi-layer diagnosis
(instrumentation, methods and backend system), and the system architecture for
delivering diagnosis in near real time across all user sessions at Yahoo.
YTrace diagnoses problems across service and network layers in the end-to-end
path spanning user host, Internet, CDN and the datacenters, and has three
diagnosis goals: detection, localization and root cause analysis (including
cascading problems) of performance problems in user sessions with the cloud.
The key component of the methods in YTrace is capturing and discovering
causality, which we design based on a mix of instrumentation API, domain
knowledge and blackbox methods. We show three case studies from production that
span a large-scale distributed storage system, a datacenter-wide network, and
an end-to-end video serving stack at Yahoo. We end by listing a number of open
directions for performance diagnosis in cloud and content providers.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-05-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03273</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03275</identifier>
 <datestamp>2017-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Infinite Horizon Average Optimality of the N-network Queueing Model in
  the Halfin-Whitt Regime</dc:title>
 <dc:creator>Arapostathis, Ari</dc:creator>
 <dc:creator>Pang, Guodong</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>60K25, 68M20, 90B22, 90B36</dc:subject>
 <dc:description>  We study the infinite horizon optimal control problem for N-network queueing
systems, which consist of two customer classes and two server pools, under
average (ergodic) criteria in the Halfin-Whitt regime. We consider three
control objectives: 1) minimizing the queueing (and idleness) cost, 2)
minimizing the queueing cost while imposing a constraint on idleness at each
server pool, and 3) minimizing the queueing cost while requiring fairness on
idleness. The running costs can be any nonnegative convex functions having at
most polynomial growth.
  For all three problems we establish asymptotic optimality, namely, the
convergence of the value functions of the diffusion-scaled state process to the
corresponding values of the controlled diffusion limit. We also present a
simple state-dependent priority scheduling policy under which the
diffusion-scaled state process is geometrically ergodic in the Halfin-Whitt
regime, and some results on convergence of mean empirical measures which
facilitate the proofs.
</dc:description>
 <dc:description>Comment: 35 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-08-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03275</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03277</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Survey of Incentives and Mechanism Design for Human Computation
  Systems</dc:title>
 <dc:creator>Liu, Yuan</dc:creator>
 <dc:creator>Miao, Chunyan</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Human computation systems (HCSs) have been widely adopted in various domains.
Their goal is to harness human intelligence to solve computational problems
that are beyond the capability of modern computers. One of the most challenging
problems in HCSs is how to incentivize a broad range of users to participate in
the system and make high efforts. This article surveys the field of HCSs from
the perspective of incentives and mechanism design. We first review
state-of-the-art HCSs, focusing on how incentives are provided to users. We
then use mechanism design to theoretically analyze different incentives. We
survey the mechanisms derived from state-of-the-art HCSs as well as classic
mechanisms that have been used in HCSs. Finally, we discuss eight promising
research directions for designing incentives in HCSs.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03277</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03283</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Performance Analysis of $l_0$ Norm Constrained Recursive Least Squares
  Algorithm</dc:title>
 <dc:creator>Mukhopadhyay, Samrat</dc:creator>
 <dc:creator>Das, Bijit Kumar</dc:creator>
 <dc:creator>Chakraborty, Mrityunjoy</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Nonlinear Sciences - Adaptation and Self-Organizing Systems</dc:subject>
 <dc:subject>Statistics - Methodology</dc:subject>
 <dc:description>  Performance analysis of $l_0$ norm constrained Recursive least Squares (RLS)
algorithm is attempted in this paper. Though the performance pretty attractive
compared to its various alternatives, no thorough study of theoretical analysis
has been performed. Like the popular $l_0$ Least Mean Squares (LMS) algorithm,
in $l_0$ RLS, a $l_0$ norm penalty is added to provide zero tap attractions on
the instantaneous filter taps. A thorough theoretical performance analysis has
been conducted in this paper with white Gaussian input data under assumptions
suitable for many practical scenarios. An expression for steady state MSD is
derived and analyzed for variations of different sets of predefined variables.
Also a Taylor series expansion based approximate linear evolution of the
instantaneous MSD has been performed. Finally numerical simulations are carried
out to corroborate the theoretical analysis and are shown to match well for a
wide range of parameters.
</dc:description>
 <dc:description>Comment: 15 pages, 5 figures</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03283</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03291</identifier>
 <datestamp>2016-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feature Based Task Recommendation in Crowdsourcing with Implicit
  Observations</dc:title>
 <dc:creator>Rahman, Habibur</dc:creator>
 <dc:creator>Joppa, Lucas</dc:creator>
 <dc:creator>Roy, Senjuti Basu</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Existing research in crowdsourcing has investigated how to recommend tasks to
workers based on which task the workers have already completed, referred to as
{\em implicit feedback}. We, on the other hand, investigate the task
recommendation problem, where we leverage both implicit feedback and explicit
features of the task. We assume that we are given a set of workers, a set of
tasks, interactions (such as the number of times a worker has completed a
particular task), and the presence of explicit features of each task (such as,
task location). We intend to recommend tasks to the workers by exploiting the
implicit interactions, and the presence or absence of explicit features in the
tasks. We formalize the problem as an optimization problem, propose two
alternative problem formulations and respective solutions that exploit implicit
feedback, explicit features, as well as similarity between the tasks. We
compare the efficacy of our proposed solutions against multiple
state-of-the-art techniques using two large scale real world datasets.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-09-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03291</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03297</identifier>
 <datestamp>2016-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Concavity of Auxiliary Function in Classical-Quantum Channels</dc:title>
 <dc:creator>Cheng, Hao-Chung</dc:creator>
 <dc:creator>Hsieh, Min-Hsiu</dc:creator>
 <dc:subject>Quantum Physics</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The auxiliary function of a classical channel appears in two fundamental
quantities that upper and lower bound the error probability, respectively. A
crucial property of the auxiliary function is its concavity, which leads to
several important results in finite block length analysis. In this paper, we
prove that the auxiliary function of a classical-quantum channel also enjoys
the same concave property, extending an earlier partial result to its full
generality. The key component in our proof is a beautiful result of geometric
means of operators.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03297</dc:identifier>
 <dc:identifier>IEEE Trans. Inf. Theory, 62(10), 5960 - 5965, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2598835</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03303</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Asymptotically Optimal Gathering on a Grid</dc:title>
 <dc:creator>Cord-Landwehr, Andreas</dc:creator>
 <dc:creator>Fischer, Matthias</dc:creator>
 <dc:creator>Jung, Daniel</dc:creator>
 <dc:creator>der Heide, Friedhelm Meyer auf</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>F.1.2</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:description>  In this paper, we solve the local gathering problem of a swarm of $n$
indistinguishable, point-shaped robots on a two dimensional grid in
asymptotically optimal time $\mathcal{O}(n)$ in the fully synchronous
$\mathcal{FSYNC}$ time model. Given an arbitrarily distributed (yet connected)
swarm of robots, the gathering problem on the grid is to locate all robots
within a $2\times 2$-sized area that is not known beforehand. Two robots are
connected if they are vertical or horizontal neighbors on the grid. The
locality constraint means that no global control, no compass, no global
communication and only local vision is available; hence, a robot can only see
its grid neighbors up to a constant $L_1$-distance, which also limits its
movements. A robot can move to one of its eight neighboring grid cells and if
two or more robots move to the same location they are \emph{merged} to be only
one robot. The locality constraint is the significant challenging issue here,
since robot movements must not harm the (only globally checkable) swarm
connectivity. For solving the gathering problem, we provide a synchronous
algorithm -- executed by every robot -- which ensures that robots merge without
breaking the swarm connectivity. In our model, robots can obtain a special
state, which marks such a robot to be performing specific connectivity
preserving movements in order to allow later merge operations of the swarm.
Compared to the grid, for gathering in the Euclidean plane for the same robot
and time model the best known upper bound is $\mathcal{O}(n^2)$.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1510.05454</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03303</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03305</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Coverage and capacity scaling laws in downlink ultra-dense cellular
  networks</dc:title>
 <dc:creator>Nguyen, Van Minh</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Driven by new types of wireless devices and the proliferation of
bandwidth-intensive applications, data traffic and the corresponding network
load are increasing dramatically. Network densification has been recognized as
a promising and efficient way to provide higher network capacity and enhanced
coverage. Most prior work on performance analysis of ultra-dense networks
(UDNs) has focused on random spatial deployment with idealized singular path
loss models and Rayleigh fading. In this paper, we consider a more precise and
general model, which incorporates multi-slope path loss and general fading
distributions. We derive the tail behavior and scaling laws for the coverage
probability and the capacity considering strongest base station association in
a Poisson field network. Our analytical results identify the regimes in which
the signal-to-interference-plus-noise ratio (SINR) either asymptotically grows,
saturates, or decreases with increasing network density. We establish general
results on when UDNs lead to worse or even zero SINR coverage and capacity, and
we provide crisp insights on the fundamental limits of wireless network
densification.
</dc:description>
 <dc:description>Comment: Accepted for IEEE ICC 2016 - revised version. 7 pages, 7 figures</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-02-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03305</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03308</identifier>
 <datestamp>2016-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Gabor Wavelets in Image Processing</dc:title>
 <dc:creator>Barina, David</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Graphics</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  This work shows the use of a two-dimensional Gabor wavelets in image
processing. Convolution with such a two-dimensional wavelet can be separated
into two series of one-dimensional ones. The key idea of this work is to
utilize a Gabor wavelet as a multiscale partial differential operator of a
given order. Gabor wavelets are used here to detect edges, corners and blobs. A
performance of such an interest point detector is compared to detectors
utilizing a Haar wavelet and a derivative of a Gaussian function. The proposed
approach may be useful when a fast implementation of the Gabor transform is
available or when the transform is already precomputed.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03308</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03313</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Remark on Channels with Transceiver Distortion</dc:title>
 <dc:creator>Zhang, Wenyi</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Information transmission over channels with transceiver distortion is
investigated via generalized mutual information (GMI) under Gaussian input
distribution and nearest-neighbor decoding. A canonical transceiver structure
in which the channel output is processed by a minimum mean-squared error
estimator before decoding is established to maximize the GMI, and the
well-known Bussgang's decomposition is shown to be a heuristic that is
consistent with the GMI under linear output processing.
</dc:description>
 <dc:description>Comment: 2016 Information Theory and Applications (ITA) Workshop, La Jolla,
  CA, USA, Jan.-Feb. 2016</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03313</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03316</identifier>
 <datestamp>2017-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Safety in Numbers: Anonymization Makes Centralized Systems Trustworthy</dc:title>
 <dc:creator>Gunn, Lachlan J.</dc:creator>
 <dc:creator>Allison, Andrew</dc:creator>
 <dc:creator>Abbott, Derek</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Decentralized systems can be more resistant to operator mischief than
centralized ones, but they are substantially harder to develop, deploy, and
maintain. This cost is dramatically reduced if the decentralized part of the
system can be made highly generic, and thus incorporated into many different
applications. We show how existing anonymization systems can serve this
purpose, securing a public database against equivocation by its operator
without the need for cooperation by the database owner. We derive bounds on the
probability of successful equivocation, and in doing so, we demonstrate that
anonymization systems are not only important for user privacy, but that by
providing privacy to machines they have a wider value within the internet
infrastructure
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03316</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03320</identifier>
 <datestamp>2016-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Graph Wavelets via Sparse Cuts: Extended Version</dc:title>
 <dc:creator>Silva, Arlei</dc:creator>
 <dc:creator>Dang, Xuan-Hong</dc:creator>
 <dc:creator>Basu, Prithwish</dc:creator>
 <dc:creator>Singh, Ambuj K</dc:creator>
 <dc:creator>Swami, Ananthram</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Modeling information that resides on vertices of large graphs is a key
problem in several real-life applications, ranging from social networks to the
Internet-of-things. Signal Processing on Graphs and, in particular, graph
wavelets can exploit the intrinsic smoothness of these datasets in order to
represent them in a both compact and accurate manner. However, how to discover
wavelet bases that capture the geometry of the data with respect to the signal
as well as the graph structure remains an open question. In this paper, we
study the problem of computing graph wavelet bases via sparse cuts in order to
produce low-dimensional encodings of data-driven bases. This problem is
connected to known hard problems in graph theory (e.g. multiway cuts) and thus
requires an efficient heuristic. We formulate the basis discovery task as a
relaxation of a vector optimization problem, which leads to an elegant solution
as a regularized eigenvalue computation. Moreover, we propose several
strategies in order to scale our algorithm to large graphs. Experimental
results show that the proposed algorithm can effectively encode both the graph
structure and signal, producing compressed and accurate representations for
vertex values in a wide range of datasets (e.g. sensor and gene networks) and
significantly outperforming the best baseline.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-06-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03320</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03328</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Degrees of Freedom Rate Region of the $K$-user Interference Channel with
  Blind CSIT Using Staggered Antenna Switching</dc:title>
 <dc:creator>Johnny, Milad</dc:creator>
 <dc:creator>Aref, Mohammad Reza</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we consider the problem of the interference alignment for the
$K$-user SISO interference channel with blind channel state information at
transmitters (CSIT). Our achievement in contrast to popular $K-$user
interference alignment (IA) scheme has more practical notions. In this case
every receiver is equipped with one reconfigurable antenna which tries to place
its desired signal in a subspace which is linearly independent from
interference signals. We show that if the channel values are known to the
receivers only, the sum degrees-of-freedom (DOF) rate region of the linear BIA
with staggered antenna switching is $\frac{Kr}{r^2-r+K}$, where $r = \left
\lceil{\frac{\sqrt{1+4K}-1}{2}} \right \rceil$. The result indicates that the
optimum DoF rate region of the $K-$user interference channel is to achieve the
DoF of $\frac{\sqrt{K}}{2}$ for an asymptotically large network. Thus, the DoF
of the $K$-user interference channel using staggered antenna switching grows
sub-linearly with the number of the users, whereas it grows linearly in the
case where transmitters access the CSI. In addition we propose both
achievability and converse proof so as to show that this is the DoF rate region
of blind interference alignment (BIA) with staggered antenna switching.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures, This paper submitted to IEEE Transactions on
  Wireless Communications and partially IWCIT 2016. arXiv admin note: text
  overlap with arXiv:1408.6427 by other authors</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03328</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03332</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Polynomial Depth, Highness and Lowness for E</dc:title>
 <dc:creator>Moser, Philippe</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:description>  We study the relations between the notions of highness, lowness and logical
depth in the setting of complexity theory. We introduce a new notion of
polynomial depth based on time bounded Kolmogorov complexity. We show our
polynomial depth notion satisfies all basic logical depth properties, namely
neither sets in P nor sets random for EXP are polynomial deep, and only
polynomial deep sets can polynomially Turing compute a polynomial deep set. We
prove all EXP- complete sets are poly-deep, and under the assumption that NP
does not have p-measure zero, then NP contains a polynomial deep set. We show
that every high set for E contains a polynomial deep set in its polynomial
Turing degree, and that there exists low for E polynomial deep sets.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03332</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03333</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A representation of a compressed de Bruijn graph for pan-genome analysis
  that enables search</dc:title>
 <dc:creator>Beller, Timo</dc:creator>
 <dc:creator>Ohlebusch, Enno</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Recently, Marcus et al. (Bioinformatics 2014) proposed to use a compressed de
Bruijn graph to describe the relationship between the genomes of many
individuals/strains of the same or closely related species. They devised an
$O(n \log g)$ time algorithm called splitMEM that constructs this graph
directly (i.e., without using the uncompressed de Bruijn graph) based on a
suffix tree, where $n$ is the total length of the genomes and $g$ is the length
of the longest genome. In this paper, we present a construction algorithm that
outperforms their algorithm in theory and in practice. Moreover, we propose a
new space-efficient representation of the compressed de Bruijn graph that adds
the possibility to search for a pattern (e.g. an allele - a variant form of a
gene) within the pan-genome.
</dc:description>
 <dc:description>Comment: Submitted to Algorithmica special issue of CPM2015</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03333</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03337</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enhancing Patient Appointments Scheduling that Uses Mobile Technology</dc:title>
 <dc:creator>Kyambille, Godphrey G</dc:creator>
 <dc:creator>Kalegele, Khamisi</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:description>  Appointment scheduling systems are utilized mainly by specialty care clinics
to manage access to service providers as well as by hospitals to schedule
patient appointments. When attending hospitals in Tanzania, patients experience
challenges to see an appropriate specialist doctor because of service interval
inconsistency. Timely availability of doctors is critical whenever a patient
needs to see a specialist doctor for treatment and a serious bottleneck lies in
the application of appropriate technology techniques to enhance appointment
scheduling. In this paper, we present a mobile based application scheduling
system for managing patient appointments. Furthermore, forthcoming
opportunities for the innovative use of the mobile based application scheduling
system are identified.
</dc:description>
 <dc:description>Comment: 7 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03337</dc:identifier>
 <dc:identifier>International Journal of Computer Science and Information
  Security, 13(11), 21 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03342</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>The Case for Data Plane Timestamping in SDN</dc:title>
 <dc:creator>Mizrahi, Tal</dc:creator>
 <dc:creator>Moses, Yoram</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  This paper presents the case for Data Plane Timestamping (DPT). We argue that
in the unique environment of Software-Defined Networks (SDN), attaching a
timestamp to the header of all packets is a powerful feature that can be
leveraged by various diverse SDN applications. We analyze three key use cases
that demonstrate the advantages of using DPT, and show that SDN applications
can benefit even from using as little as one bit for the timestamp field.
</dc:description>
 <dc:description>Comment: This technical report is an extended version of &quot;The Case for Data
  Plane Timestamping in SDN&quot;, which was accepted to the IEEE INFOCOM Workshop
  on Software-Driven Flexible and Agile Networking (SWFAN), 2016</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03342</dc:identifier>
 <dc:identifier>doi:10.1109/INFCOMW.2016.7562197</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03346</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>DAP3D-Net: Where, What and How Actions Occur in Videos?</dc:title>
 <dc:creator>Liu, Li</dc:creator>
 <dc:creator>Zhou, Yi</dc:creator>
 <dc:creator>Shao, Ling</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Action parsing in videos with complex scenes is an interesting but
challenging task in computer vision. In this paper, we propose a generic 3D
convolutional neural network in a multi-task learning manner for effective Deep
Action Parsing (DAP3D-Net) in videos. Particularly, in the training phase,
action localization, classification and attributes learning can be jointly
optimized on our appearancemotion data via DAP3D-Net. For an upcoming test
video, we can describe each individual action in the video simultaneously as:
Where the action occurs, What the action is and How the action is performed. To
well demonstrate the effectiveness of the proposed DAP3D-Net, we also
contribute a new Numerous-category Aligned Synthetic Action dataset, i.e.,
NASA, which consists of 200; 000 action clips of more than 300 categories and
with 33 pre-defined action attributes in two hierarchical levels (i.e.,
low-level attributes of basic body part movements and high-level attributes
related to action motion). We learn DAP3D-Net using the NASA dataset and then
evaluate it on our collected Human Action Understanding (HAU) dataset.
Experimental results show that our approach can accurately localize, categorize
and describe multiple actions in realistic videos.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03346</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03348</identifier>
 <datestamp>2016-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Iterative Hierarchical Optimization for Misspecified Problems (IHOMP)</dc:title>
 <dc:creator>Mankowitz, Daniel J.</dc:creator>
 <dc:creator>Mann, Timothy A.</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  For complex, high-dimensional Markov Decision Processes (MDPs), it may be
necessary to represent the policy with function approximation. A problem is
misspecified whenever, the representation cannot express any policy with
acceptable performance. We introduce IHOMP : an approach for solving
misspecified problems. IHOMP iteratively learns a set of context specialized
options and combines these options to solve an otherwise misspecified problem.
Our main contribution is proving that IHOMP enjoys theoretical convergence
guarantees. In addition, we extend IHOMP to exploit Option Interruption (OI)
enabling it to decide where the learned options can be reused. Our experiments
demonstrate that IHOMP can find near-optimal solutions to otherwise
misspecified problems and that OI can further improve the solutions.
</dc:description>
 <dc:description>Comment: arXiv admin note: text overlap with arXiv:1506.03624</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03348</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03350</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query Processing For The Internet-of-Things: Coupling Of Device Energy
  Consumption And Cloud Infrastructure Billing</dc:title>
 <dc:creator>Renna, Francesco</dc:creator>
 <dc:creator>Doyle, Joseph</dc:creator>
 <dc:creator>Giotsas, Vasileios</dc:creator>
 <dc:creator>Andreopoulos, Yiannis</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Audio/visual recognition and retrieval applications have recently garnered
significant attention within Internet-of-Things (IoT) oriented services, given
that video cameras and audio processing chipsets are now ubiquitous even in
low-end embedded systems. In the most typical scenario for such services, each
device extracts audio/visual features and compacts them into feature
descriptors, which comprise media queries. These queries are uploaded to a
remote cloud computing service that performs content matching for
classification or retrieval applications. Two of the most crucial aspects for
such services are: (i) controlling the device energy consumption when using the
service; (ii) reducing the billing cost incurred from the cloud infrastructure
provider. In this paper we derive analytic conditions for the optimal coupling
between the device energy consumption and the incurred cloud infrastructure
billing. Our framework encapsulates: the energy consumption to produce and
transmit audio/visual queries, the billing rates of the cloud infrastructure,
the number of devices concurrently connected to the same cloud server, and the
statistics of the query data production volume per device. Our analytic results
are validated via a deployment with: (i) the device side comprising compact
image descriptors (queries) computed on Beaglebone Linux embedded platforms and
transmitted to Amazon Web Services (AWS) Simple Storage Service; (ii) the cloud
side carrying out image similarity detection via AWS Elastic Compute Cloud
(EC2) spot instances, with the AWS Auto Scaling being used to control the
number of instances according to the demand.
</dc:description>
 <dc:description>Comment: To be presented at the 1st IEEE International Conference on
  Internet-of-Things Design and Implementation (IoTDI 2016)</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03350</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03351</identifier>
 <datestamp>2016-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive Skills, Adaptive Partitions (ASAP)</dc:title>
 <dc:creator>Mankowitz, Daniel J.</dc:creator>
 <dc:creator>Mann, Timothy A.</dc:creator>
 <dc:creator>Mannor, Shie</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We introduce the Adaptive Skills, Adaptive Partitions (ASAP) framework that
(1) learns skills (i.e., temporally extended actions or options) as well as (2)
where to apply them. We believe that both (1) and (2) are necessary for a truly
general skill learning framework, which is a key building block needed to scale
up to lifelong learning agents. The ASAP framework can also solve related new
tasks simply by adapting where it applies its existing learned skills. We prove
that ASAP converges to a local optimum under natural conditions. Finally, our
experimental results, which include a RoboCup domain, demonstrate the ability
of ASAP to learn where to reuse skills as well as solve multiple tasks with
considerably less experience than solving each task from scratch.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03351</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03364</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Relations on words</dc:title>
 <dc:creator>Rigo, Michel</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68R15</dc:subject>
 <dc:description>  In the first part of this survey, we present classical notions arising in
combinatorics on words: growth function of a language, complexity function of
an infinite word, pattern avoidance, periodicity and uniform recurrence. Our
presentation tries to set up a unified framework with respect to a given binary
relation.
  In the second part, we mainly focus on abelian equivalence, $k$-abelian
equivalence, combinatorial coefficients and associated relations, Parikh
matrices and $M$-equivalence. In particular, some new refinements of abelian
equivalence are introduced.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03364</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03368</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast model selection by limiting SVM training times</dc:title>
 <dc:creator>Demircioglu, Aydin</dc:creator>
 <dc:creator>Horn, Daniel</dc:creator>
 <dc:creator>Glasmachers, Tobias</dc:creator>
 <dc:creator>Bischl, Bernd</dc:creator>
 <dc:creator>Weihs, Claus</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Kernelized Support Vector Machines (SVMs) are among the best performing
supervised learning methods. But for optimal predictive performance,
time-consuming parameter tuning is crucial, which impedes application. To
tackle this problem, the classic model selection procedure based on grid-search
and cross-validation was refined, e.g. by data subsampling and direct search
heuristics. Here we focus on a different aspect, the stopping criterion for SVM
training. We show that by limiting the training time given to the SVM solver
during parameter tuning we can reduce model selection times by an order of
magnitude.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03368</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03379</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Comparison of feature extraction and dimensionality reduction methods
  for single channel extracellular spike sorting</dc:title>
 <dc:creator>Mitra, Anupam</dc:creator>
 <dc:creator>Pathak, Anagh</dc:creator>
 <dc:creator>Majumdar, Kaushik</dc:creator>
 <dc:subject>Quantitative Biology - Quantitative Methods</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Quantitative Biology - Neurons and Cognition</dc:subject>
 <dc:description>  Spikes in the membrane electrical potentials of neurons play a major role in
the functioning of nervous systems of animals. Obtaining the spikes from
different neurons has been a challenging problem for decades. Several schemes
have been proposed for spike sorting to isolate the spikes of individual
neurons from electrical recordings in extracellular media. However, there is
much scope for improvement in the accuracies obtained using the prevailing
methods of spike sorting. To determine more effective spike sorting strategies
using well known methods, we compared different types of signal features and
techniques for dimensionality reduction in feature space. We tried to determine
an optimum or near optimum feature extraction and dimensionality reduction
methods and an optimum or near optimum number of features for spike sorting. We
assessed relative performance of well known methods on simulated recordings
specially designed for development and benchmarking of spike sorting schemes,
with varying number of spike classes and the well established method of
$k$-means clustering of selected features. We found that almost all well known
methods performed quite well. Nevertheless, from spike waveforms of 64 samples,
sampled at 24 kHz, using principal component analysis (PCA) to select around 46
to 55 features led to the better spike sorting performance than most other
methods (Wilcoxon signed rank sum test, $p &lt; 0.001$).
</dc:description>
 <dc:description>Comment: 12 pages, 2 figures</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03379</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03400</identifier>
 <datestamp>2017-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Noise Robustness of Simultaneous Orthogonal Matching Pursuit</dc:title>
 <dc:creator>Determe, Jean-Fran&#xe7;ois</dc:creator>
 <dc:creator>Louveaux, J&#xe9;r&#xf4;me</dc:creator>
 <dc:creator>Jacques, Laurent</dc:creator>
 <dc:creator>Horlin, Fran&#xe7;ois</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, the joint support recovery of several sparse signals whose
supports present similarities is examined. Each sparse signal is acquired using
the same noisy linear measurement process, which returns fewer observations
than the dimension of the sparse signals. The measurement noise is assumed
additive, Gaussian, and admits different variances for each sparse signal that
is measured. Using the theory of compressed sensing, the performance of
simultaneous orthogonal matching pursuit (SOMP) is analysed for the envisioned
signal model. The cornerstone of this paper is a novel analysis method upper
bounding the probability that SOMP recovers at least one incorrect entry of the
joint support during a prescribed number of iterations. Furthermore, the
probability of SOMP failing is investigated whenever the number of sparse
signals being recovered simultaneously increases and tends to infinity. In
particular, convincing observations and theoretical results suggest that SOMP
committing no mistake in the noiseless case does not guarantee the absence of
error in the noisy case whenever the number of acquired sparse signals scales
to infinity. Finally, simulation results confirm the validity of the
theoretical results.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-02-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03400</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2626244</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03404</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Proceedings of the Workshop on High Performance Energy Efficient
  Embedded Systems (HIP3ES) 2016</dc:title>
 <dc:creator>Castells-Rufas, David</dc:creator>
 <dc:creator>Bastoul, C&#xe9;dric</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Proceedings of the Workshop on High Performance Energy Efficient Embedded
Systems (HIP3ES) 2016. Prague, January 18th. Collocated with HIPEAC 2016
Conference.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03404</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03407</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Random Distances Associated with Arbitrary Polygons: An Algorithmic
  Approach between Two Random Points</dc:title>
 <dc:creator>Tong, Fei</dc:creator>
 <dc:creator>Pan, Jianping</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:description>  This report presents a new, algorithmic approach to the distributions of the
distance between two points distributed uniformly at random in various
polygons, based on the extended Kinematic Measure (KM) from integral geometry.
We first obtain such random Point Distance Distributions (PDDs) associated with
arbitrary triangles (i.e., triangle-PDDs), including the PDD within a triangle,
and that between two triangles sharing either a common side or a common vertex.
For each case, we provide an algorithmic procedure showing the mathematical
derivation process, based on which either the closed-form expressions or the
algorithmic results can be obtained. The obtained triangle-PDDs can be utilized
for modeling and analyzing the wireless communication networks associated with
triangle geometries, such as sensor networks with triangle-shaped clusters and
triangle-shaped cellular systems with highly directional antennas. Furthermore,
based on the obtained triangle-PDDs, we then show how to obtain the PDDs
associated with arbitrary polygons through the decomposition and recursion
approach, since any polygons can be triangulated, and any geometry shapes can
be approximated by polygons with a needed precision. Finally, we give the PDDs
associated with ring geometries. The results shown in this report can enrich
and expand the theory and application of the probabilistic distance models for
the analysis of wireless communication networks.
</dc:description>
 <dc:description>Comment: 16 pages, 14 figures</dc:description>
 <dc:date>2016-01-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03407</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03409</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Deep Convolutional Neural Networks for Computer-Aided Detection: CNN
  Architectures, Dataset Characteristics and Transfer Learning</dc:title>
 <dc:creator>Shin, Hoo-Chang</dc:creator>
 <dc:creator>Roth, Holger R.</dc:creator>
 <dc:creator>Gao, Mingchen</dc:creator>
 <dc:creator>Lu, Le</dc:creator>
 <dc:creator>Xu, Ziyue</dc:creator>
 <dc:creator>Nogues, Isabella</dc:creator>
 <dc:creator>Yao, Jianhua</dc:creator>
 <dc:creator>Mollura, Daniel</dc:creator>
 <dc:creator>Summers, Ronald M.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Remarkable progress has been made in image recognition, primarily due to the
availability of large-scale annotated datasets and the revival of deep CNN.
CNNs enable learning data-driven, highly representative, layered hierarchical
image features from sufficient training data. However, obtaining datasets as
comprehensively annotated as ImageNet in the medical imaging domain remains a
challenge. There are currently three major techniques that successfully employ
CNNs to medical image classification: training the CNN from scratch, using
off-the-shelf pre-trained CNN features, and conducting unsupervised CNN
pre-training with supervised fine-tuning. Another effective method is transfer
learning, i.e., fine-tuning CNN models pre-trained from natural image dataset
to medical image tasks. In this paper, we exploit three important, but
previously understudied factors of employing deep convolutional neural networks
to computer-aided detection problems. We first explore and evaluate different
CNN architectures. The studied models contain 5 thousand to 160 million
parameters, and vary in numbers of layers. We then evaluate the influence of
dataset scale and spatial image context on performance. Finally, we examine
when and why transfer learning from pre-trained ImageNet (via fine-tuning) can
be useful. We study two specific computer-aided detection (CADe) problems,
namely thoraco-abdominal lymph node (LN) detection and interstitial lung
disease (ILD) classification. We achieve the state-of-the-art performance on
the mediastinal LN detection, with 85% sensitivity at 3 false positive per
patient, and report the first five-fold cross-validation classification results
on predicting axial CT slices with ILD categories. Our extensive empirical
evaluation, CNN model analysis and valuable insights can be extended to the
design of high performance CAD systems for other medical imaging tasks.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03409</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03418</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Triplet Similarity Embedding for Face Verification</dc:title>
 <dc:creator>Sankaranarayanan, Swami</dc:creator>
 <dc:creator>Alavi, Azadeh</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  In this work, we present an unconstrained face verification algorithm and
evaluate it on the recently released IJB-A dataset that aims to push the
boundaries of face verification methods. The proposed algorithm couples a deep
CNN-based approach with a low-dimensional discriminative embedding learnt using
triplet similarity constraints in a large margin fashion. Aside from yielding
performance improvement, this embedding provides significant advantages in
terms of memory and post-processing operations like hashing and visualization.
Experiments on the IJB-A dataset show that the proposed algorithm outperforms
state of the art methods in verification and identification metrics, while
requiring less training time.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03418</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03419</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complexity of regular abstractions of one-counter languages</dc:title>
 <dc:creator>Atig, Mohamed Faouzi</dc:creator>
 <dc:creator>Chistikov, Dmitry</dc:creator>
 <dc:creator>Hofman, Piotr</dc:creator>
 <dc:creator>Kumar, K Narayan</dc:creator>
 <dc:creator>Saivasan, Prakash</dc:creator>
 <dc:creator>Zetzsche, Georg</dc:creator>
 <dc:subject>Computer Science - Formal Languages and Automata Theory</dc:subject>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  We study the computational and descriptional complexity of the following
transformation: Given a one-counter automaton (OCA) A, construct a
nondeterministic finite automaton (NFA) B that recognizes an abstraction of the
language L(A): its (1) downward closure, (2) upward closure, or (3) Parikh
image.
  For the Parikh image over a fixed alphabet and for the upward and downward
closures, we find polynomial-time algorithms that compute such an NFA. For the
Parikh image with the alphabet as part of the input, we find a quasi-polynomial
time algorithm and prove a completeness result: we construct a sequence of OCA
that admits a polynomial-time algorithm iff there is one for all OCA.
  For all three abstractions, it was previously unknown if appropriate NFA of
sub-exponential size exist.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03419</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03426</identifier>
 <datestamp>2016-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Automatic Sarcasm Detection: A Survey</dc:title>
 <dc:creator>Joshi, Aditya</dc:creator>
 <dc:creator>Bhattacharyya, Pushpak</dc:creator>
 <dc:creator>Carman, Mark James</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Automatic sarcasm detection is the task of predicting sarcasm in text. This
is a crucial step to sentiment analysis, considering prevalence and challenges
of sarcasm in sentiment-bearing text. Beginning with an approach that used
speech-based features, sarcasm detection has witnessed great interest from the
sentiment analysis community. This paper is the first known compilation of past
work in automatic sarcasm detection. We observe three milestones in the
research so far: semi-supervised pattern extraction to identify implicit
sentiment, use of hashtag-based supervision, and use of context beyond target
text. In this paper, we describe datasets, approaches, trends and issues in
sarcasm detection. We also discuss representative performance values, shared
tasks and pointers to future work, as given in prior works. In terms of
resources that could be useful for understanding state-of-the-art, the survey
presents several useful illustrations - most prominently, a table that
summarizes past papers along different dimensions such as features, annotation
techniques, data forms, etc.
</dc:description>
 <dc:description>Comment: This paper is likely to be submitted to ACM CSUR. This copy on arXiv
  is to obtain feedback from stakeholders</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-09-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03426</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03434</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of degree truncation on the spread of a contagious process on
  networks</dc:title>
 <dc:creator>Harling, Guy</dc:creator>
 <dc:creator>Onnela, Jukka-Pekka</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:description>  Understanding how person-to-person contagious processes spread through a
population requires accurate information on connections between population
members. However, such connectivity data, when collected via interview, is
often incomplete due to partial recall, respondent fatigue or study design,
e.g., fixed choice designs (FCD) truncate out-degree by limiting the number of
contacts each respondent can report. Past research has shown how FCD truncation
affects network properties, but its implications for predicted speed and size
of spreading processes remain largely unexplored. To study the impact of degree
truncation on spreading processes, we generated collections of synthetic
networks containing specific properties (degree distribution,
degree-assortativity, clustering), and also used empirical social network data
from 75 villages in Karnataka, India. We simulated FCD using various truncation
thresholds and ran a susceptible-infectious-recovered (SIR) process on each
network. We found that spreading processes propagated on truncated networks
resulted in slower and smaller epidemics, with a sudden decrease in prediction
accuracy at a level of truncation that varied by network type. Our results have
implications beyond FCD to truncation due to any limited sampling from a larger
network. We conclude that knowledge of network structure is important for
understanding the accuracy of predictions of process spread on degree truncated
networks.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03434</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03436</identifier>
 <datestamp>2017-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High-Dimensional Estimation of Structured Signals from Non-Linear
  Observations with General Convex Loss Functions</dc:title>
 <dc:creator>Genzel, Martin</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we study the issue of estimating a structured signal $x_0 \in
\mathbb{R}^n$ from non-linear and noisy Gaussian observations. Supposing that
$x_0$ is contained in a certain convex subset $K \subset \mathbb{R}^n$, we
prove that accurate recovery is already feasible if the number of observations
exceeds the effective dimension of $K$, which is a common measure for the
complexity of signal classes. It will turn out that the possibly unknown
non-linearity of our model affects the error rate only by a multiplicative
constant. This achievement is based on recent works by Plan and Vershynin, who
have suggested to treat the non-linearity rather as noise which perturbs a
linear measurement process. Using the concept of restricted strong convexity,
we show that their results for the generalized Lasso can be extended to a
fairly large class of convex loss functions. Moreover, we shall allow for the
presence of adversarial noise so that even deterministic model inaccuracies can
be coped with. These generalizations particularly give further evidence of why
many standard estimators perform surprisingly well in practice, although they
do not rely on any knowledge of the underlying output rule. To this end, our
results provide a unified and general framework for signal reconstruction in
high dimensions, covering various challenges from the fields of compressed
sensing, signal processing, and statistical learning.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-08-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03436</dc:identifier>
 <dc:identifier>IEEE Trans. Inf. Theory 64.3 (2017), 1601-1619</dc:identifier>
 <dc:identifier>doi:10.1109/TIT.2016.2642993</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03458</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Super-Resolved Retinal Image Mosaicing</dc:title>
 <dc:creator>K&#xf6;hler, Thomas</dc:creator>
 <dc:creator>Heinrich, Axel</dc:creator>
 <dc:creator>Maier, Andreas</dc:creator>
 <dc:creator>Hornegger, Joachim</dc:creator>
 <dc:creator>Tornow, Ralf P.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The acquisition of high-resolution retinal fundus images with a large field
of view (FOV) is challenging due to technological, physiological and economic
reasons. This paper proposes a fully automatic framework to reconstruct retinal
images of high spatial resolution and increased FOV from multiple
low-resolution images captured with non-mydriatic, mobile and video-capable but
low-cost cameras. Within the scope of one examination, we scan different
regions on the retina by exploiting eye motion conducted by a patient guidance.
Appropriate views for our mosaicing method are selected based on optic disk
tracking to trace eye movements. For each view, one super-resolved image is
reconstructed by fusion of multiple video frames. Finally, all super-resolved
views are registered to a common reference using a novel polynomial
registration scheme and combined by means of image mosaicing. We evaluated our
framework for a mobile and low-cost video fundus camera. In our experiments, we
reconstructed retinal images of up to 30{\deg} FOV from 10 complementary views
of 15{\deg} FOV. An evaluation of the mosaics by human experts as well as a
quantitative comparison to conventional color fundus images encourage the
clinical usability of our framework.
</dc:description>
 <dc:description>Comment: accepted for 2016 IEEE 13th International Symposium on Biomedical
  Imaging (ISBI 2016)</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03458</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03468</identifier>
 <datestamp>2017-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Articulated Clinician Detection Using 3D Pictorial Structures on RGB-D
  Data</dc:title>
 <dc:creator>Kadkhodamohammadi, Abdolrahim</dc:creator>
 <dc:creator>Gangi, Afshin</dc:creator>
 <dc:creator>de Mathelin, Michel</dc:creator>
 <dc:creator>Padoy, Nicolas</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Reliable human pose estimation (HPE) is essential to many clinical
applications, such as surgical workflow analysis, radiation safety monitoring
and human-robot cooperation. Proposed methods for the operating room (OR) rely
either on foreground estimation using a multi-camera system, which is a
challenge in real ORs due to color similarities and frequent illumination
changes, or on wearable sensors or markers, which are invasive and therefore
difficult to introduce in the room. Instead, we propose a novel approach based
on Pictorial Structures (PS) and on RGB-D data, which can be easily deployed in
real ORs. We extend the PS framework in two ways. First, we build robust and
discriminative part detectors using both color and depth images. We also
present a novel descriptor for depth images, called histogram of depth
differences (HDD). Second, we extend PS to 3D by proposing 3D pairwise
constraints and a new method that makes exact inference tractable. Our approach
is evaluated for pose estimation and clinician detection on a challenging RGB-D
dataset recorded in a busy operating room during live surgeries. We conduct
series of experiments to study the different part detectors in conjunction with
the various 2D or 3D pairwise constraints. Our comparisons demonstrate that 3D
PS with RGB-D part detectors significantly improves the results in a visually
challenging operating environment.
</dc:description>
 <dc:description>Comment: The supplementary video is available at https://youtu.be/iabbGSqRSgE</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03468</dc:identifier>
 <dc:identifier>doi:10.1016/j.media.2016.07.001</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03471</identifier>
 <datestamp>2016-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Improved group testing rates with constant column weight designs</dc:title>
 <dc:creator>Aldridge, Matthew</dc:creator>
 <dc:creator>Johnson, Oliver</dc:creator>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We consider nonadaptive group testing where each item is placed in a constant
number of tests. The tests are chosen uniformly at random with replacement, so
the testing matrix has (almost) constant column weights. We show that
performance is improved compared to Bernoulli designs, where each item is
placed in each test independently with a fixed probability. In particular, we
show that the rate of the practical COMP detection algorithm is increased by
31% in all sparsity regimes. In dense cases, this beats the best possible
algorithm with Bernoulli tests, and in sparse cases is the best proven
performance of any practical algorithm. We also give an algorithm-independent
upper bound for the constant column weight case; for dense cases this is again
a 31% increase over the analogous Bernoulli result.
</dc:description>
 <dc:description>Comment: 5 pages, 2 figures; to be presented at ISIT 2016</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03471</dc:identifier>
 <dc:identifier>Proceedings of the International Symposium on Information Theory
  (ISIT 2016), p1381-1385</dc:identifier>
 <dc:identifier>doi:10.1109/ISIT.2016.7541525</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03476</identifier>
 <datestamp>2016-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Conditional Dependence via Shannon Capacity: Axioms, Estimators and
  Applications</dc:title>
 <dc:creator>Gao, Weihao</dc:creator>
 <dc:creator>Kannan, Sreeram</dc:creator>
 <dc:creator>Oh, Sewoong</dc:creator>
 <dc:creator>Viswanath, Pramod</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  We conduct an axiomatic study of the problem of estimating the strength of a
known causal relationship between a pair of variables. We propose that an
estimate of causal strength should be based on the conditional distribution of
the effect given the cause (and not on the driving distribution of the cause),
and study dependence measures on conditional distributions. Shannon capacity,
appropriately regularized, emerges as a natural measure under these axioms. We
examine the problem of calculating Shannon capacity from the observed samples
and propose a novel fixed-$k$ nearest neighbor estimator, and demonstrate its
consistency. Finally, we demonstrate an application to single-cell
flow-cytometry, where the proposed estimators significantly reduce sample
complexity.
</dc:description>
 <dc:description>Comment: 43 pages, 3 figures</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-06-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03476</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03481</identifier>
 <datestamp>2017-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Achieving Budget-optimality with Adaptive Schemes in Crowdsourcing</dc:title>
 <dc:creator>Khetan, Ashish</dc:creator>
 <dc:creator>Oh, Sewoong</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Crowdsourcing platforms provide marketplaces where task requesters can pay to
get labels on their data. Such markets have emerged recently as popular venues
for collecting annotations that are crucial in training machine learning models
in various applications. However, as jobs are tedious and payments are low,
errors are common in such crowdsourced labels. A common strategy to overcome
such noise in the answers is to add redundancy by getting multiple answers for
each task and aggregating them using some methods such as majority voting. For
such a system, there is a fundamental question of interest: how can we maximize
the accuracy given a fixed budget on how many responses we can collect on the
crowdsourcing system. We characterize this fundamental trade-off between the
budget (how many answers the requester can collect in total) and the accuracy
in the estimated labels. In particular, we ask whether adaptive task assignment
schemes lead to a more efficient trade-off between the accuracy and the budget.
  Adaptive schemes, where tasks are assigned adaptively based on the data
collected thus far, are widely used in practical crowdsourcing systems to
efficiently use a given fixed budget. However, existing theoretical analyses of
crowdsourcing systems suggest that the gain of adaptive task assignments is
minimal. To bridge this gap, we investigate this question under a strictly more
general probabilistic model, which has been recently introduced to model
practical crowdsourced annotations. Under this generalized Dawid-Skene model,
we characterize the fundamental trade-off between budget and accuracy. We
introduce a novel adaptive scheme that matches this fundamental limit. We
further quantify the fundamental gap between adaptive and non-adaptive schemes,
by comparing the trade-off with the one for non-adaptive schemes. Our analyses
confirm that the gap is significant.
</dc:description>
 <dc:description>Comment: 32 pages, 4 figures</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-08-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03481</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03483</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Distributed Representations of Sentences from Unlabelled Data</dc:title>
 <dc:creator>Hill, Felix</dc:creator>
 <dc:creator>Cho, Kyunghyun</dc:creator>
 <dc:creator>Korhonen, Anna</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Unsupervised methods for learning distributed representations of words are
ubiquitous in today's NLP research, but far less is known about the best ways
to learn distributed phrase or sentence representations from unlabelled data.
This paper is a systematic comparison of models that learn such
representations. We find that the optimal approach depends critically on the
intended application. Deeper, more complex models are preferable for
representations to be used in supervised systems, but shallow log-linear models
work best for building representation spaces that can be decoded with simple
spatial distance metrics. We also propose two new unsupervised
representation-learning objectives designed to optimise the trade-off between
training time, domain portability and performance.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03483</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03490</identifier>
 <datestamp>2017-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Tremain equiangular tight frames</dc:title>
 <dc:creator>Fickus, Matthew</dc:creator>
 <dc:creator>Jasper, John</dc:creator>
 <dc:creator>Mixon, Dustin G.</dc:creator>
 <dc:creator>Peterson, Jesse</dc:creator>
 <dc:subject>Mathematics - Functional Analysis</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>Primary: 42C15, Secondary: 51E10, 05B20, 05C12</dc:subject>
 <dc:description>  Equiangular tight frames provide optimal packings of lines through the
origin. We combine Steiner triple systems with Hadamard matrices to produce a
new infinite family of equiangular tight frames. This in turn leads to new
constructions of strongly regular graphs and distance-regular antipodal covers
of the complete graph.
</dc:description>
 <dc:description>Comment: 11 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-06-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03490</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03494</identifier>
 <datestamp>2017-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Time and Frequency Domain Investigation of Selected Memristor based
  Analog Circuits</dc:title>
 <dc:creator>Patil, G. S.</dc:creator>
 <dc:creator>Ghatage, S. R.</dc:creator>
 <dc:creator>Gaikwad, P. K.</dc:creator>
 <dc:creator>Kamat, R. K.</dc:creator>
 <dc:creator>Dongale, T. D.</dc:creator>
 <dc:subject>Computer Science - Emerging Technologies</dc:subject>
 <dc:subject>94C05, 00A72</dc:subject>
 <dc:subject>J.2</dc:subject>
 <dc:description>  In this paper, we investigate few memristor-based analog circuits namely the
phase shift oscillator, integrator, and differentiator which have been explored
numerously using the traditional lumped components. We use LTspice-IV platform
for simulation of the above-said circuits. The investigation resorts to the
nonlinear dopant drift model of memristor and the window function portrayed in
the literature for nonlinearity realization. The results of our investigations
depict good agreement with the conventional lumped component based phase shift
oscillator, integrator, and differentiator circuits. The results are evident to
showcase the potential of the memristor as a promising candidate for the next
generation analog circuits.
</dc:description>
 <dc:description>Comment: 11 Pages, 9 Figures</dc:description>
 <dc:date>2016-02-06</dc:date>
 <dc:date>2017-03-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03494</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03498</identifier>
 <datestamp>2016-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analog Coding of a Source with Erasures</dc:title>
 <dc:creator>Haikin, Marina</dc:creator>
 <dc:creator>Zamir, Ram</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Analog coding decouples the tasks of protecting against erasures and noise.
For erasure correction, it creates an &quot;analog redundancy&quot; by means of
band-limited discrete Fourier transform (DFT) interpolation, or more generally,
by an over-complete expansion based on a frame. We examine the analog coding
paradigm for the dual setup of a source with &quot;erasure&quot; side-information (SI) at
the encoder. The excess rate of analog coding above the rate-distortion
function (RDF) is associated with the energy of the inverse of submatrices of
the frame, where each submatrix corresponds to a possible erasure pattern. We
give a partial theoretical as well as numerical evidence that a variety of
structured frames, in particular DFT frames with difference-set spectrum and
more general equiangular tight frames (ETFs), with a common MANOVA limiting
spectrum, minimize the excess rate over all possible frames. However, they do
not achieve the RDF even in the limit as the dimension goes to infinity.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-05-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03498</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03501</identifier>
 <datestamp>2016-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Algebraic Databases</dc:title>
 <dc:creator>Schultz, Patrick</dc:creator>
 <dc:creator>Spivak, David I.</dc:creator>
 <dc:creator>Vasilakopoulou, Christina</dc:creator>
 <dc:creator>Wisnesky, Ryan</dc:creator>
 <dc:subject>Mathematics - Category Theory</dc:subject>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:subject>18C10, 18D05, 68P15</dc:subject>
 <dc:description>  Databases have been studied category-theoretically for decades. The database
schema---whose purpose is to arrange high-level conceptual entities---is
generally modeled as a category or sketch. The data itself, often called an
instance, is generally modeled as a set-valued functor, assigning to each
conceptual entity a set of examples. While mathematically elegant, these
categorical models have typically struggled with representing concrete data
such as integers or strings.
  In the present work, we propose an extension of the set-valued functor model,
making use of multisorted algebraic theories (a.k.a. Lawvere theories) to
incorporate concrete data in a principled way. This also allows constraints and
queries to make use of operations on data, such as multiplication or comparison
of numbers, helping to bridge the gap between traditional databases and
programming languages.
  We also show how all of the components of our model---including schemas,
instances, change-of-schema functors, and queries - fit into a single double
categorical structure called a proarrow equipment (a.k.a. framed bicategory).
</dc:description>
 <dc:description>Comment: 80 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-11-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03501</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03506</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Research Priorities for Robust and Beneficial Artificial Intelligence</dc:title>
 <dc:creator>Russell, Stuart</dc:creator>
 <dc:creator>Dewey, Daniel</dc:creator>
 <dc:creator>Tegmark, Max</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Success in the quest for artificial intelligence has the potential to bring
unprecedented benefits to humanity, and it is therefore worthwhile to
investigate how to maximize these benefits while avoiding potential pitfalls.
This article gives numerous examples (which should by no means be construed as
an exhaustive list) of such worthwhile research aimed at ensuring that AI
remains robust and beneficial.
</dc:description>
 <dc:description>Comment: This article gives examples of the type of research advocated by the
  open letter for robust &amp; beneficial AI at
  http://futureoflife.org/ai-open-letter</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03506</dc:identifier>
 <dc:identifier>AI Magazine 36:4 (2015)</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03508</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Energy Management in Heterogeneous Networks with Cell Activation, User
  Association and Interference Coordination</dc:title>
 <dc:creator>Kuang, Quan</dc:creator>
 <dc:creator>Utschick, Wolfgang</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The densification and expansion of wireless network pose new challenges on
interference management and reducing energy consumption. This paper studies
energy-efficient resource management in heterogeneous networks by jointly
optimizing cell activation, user association and multicell multiuser channel
assignment, according to the long-term average traffic and channel conditions.
The proposed framework is built on characterizing the interference coupling by
pre-defined interference patterns, and performing resource allocation among
these patterns. In this way, the interference fluctuation caused by
(de)activating cells is explicitly taken into account when calculating the user
achievable rates. A tailored algorithm is developed to solve the formulated
problem in the dual domain by exploiting the problem structure, which gives a
significant complexity saving. Numerical results show a huge improvement in
energy saving achieved by the proposed scheme. The user association derived
from the proposed joint resource optimization is mapped to standard-compliant
cell selection biasing. This mapping reveals that the cell-specific biasing for
energy saving is quite different from that for load balancing investigated in
the literature.
</dc:description>
 <dc:description>Comment: This is an extended version of a paper to appear in IEEE Transactions
  on Wireless Communications with the same title, containing all detailed
  proofs</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03508</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03534</identifier>
 <datestamp>2016-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Unsupervised Transductive Domain Adaptation</dc:title>
 <dc:creator>Sener, Ozan</dc:creator>
 <dc:creator>Song, Hyun Oh</dc:creator>
 <dc:creator>Saxena, Ashutosh</dc:creator>
 <dc:creator>Savarese, Silvio</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Supervised learning with large scale labeled datasets and deep layered models
has made a paradigm shift in diverse areas in learning and recognition.
However, this approach still suffers generalization issues under the presence
of a domain shift between the training and the test data distribution. In this
regard, unsupervised domain adaptation algorithms have been proposed to
directly address the domain shift problem. In this paper, we approach the
problem from a transductive perspective. We incorporate the domain shift and
the transductive target inference into our framework by jointly solving for an
asymmetric similarity metric and the optimal transductive target label
assignment. We also show that our model can easily be extended for deep feature
learning in order to learn features which are discriminative in the target
domain. Our experiments show that the proposed method significantly outperforms
state-of-the-art algorithms in both object recognition and digit classification
experiments by a large margin.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03534</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03536</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Duality between erasures and defects</dc:title>
 <dc:creator>Kim, Yongjune</dc:creator>
 <dc:creator>Kumar, B. V. K. Vijaya</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We investigate the duality of the binary erasure channel (BEC) and the binary
defect channel (BDC). This duality holds for channel capacities, capacity
achieving schemes, minimum distances, and upper bounds on the probability of
failure to retrieve the original message. In addition, the relations between
BEC, BDC, binary erasure quantization (BEQ), and write-once memory (WOM) are
described. From these relations we claim that the capacity of the BDC can be
achieved by Reed-Muller (RM) codes under maximum a posterior (MAP) decoding.
Also, polar codes with a successive cancellation encoder achieve the capacity
of the BDC.
  Inspired by the duality between the BEC and the BDC, we introduce locally
rewritable codes (LWC) for resistive memories, which are the counterparts of
locally repairable codes (LRC) for distributed storage systems. The proposed
LWC can improve endurance limit and power efficiency of resistive memories.
</dc:description>
 <dc:description>Comment: Presented at Information Theory and Applications (ITA) Workshop 2016.
  arXiv admin note: text overlap with arXiv:1602.01202</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03536</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03540</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Homonym Population Protocols</dc:title>
 <dc:creator>Bournez, Olivier</dc:creator>
 <dc:creator>Cohen, Johanne</dc:creator>
 <dc:creator>Rabie, Mika&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  The population protocol model was introduced by Angluin \emph{et al.} as a
model of passively mobile anonymous finite-state agents. This model computes a
predicate on the multiset of their inputs via interactions by pairs. The
original population protocol model has been proved to compute only semi-linear
predicates and has been recently extended in various ways. In the community
protocol model by Guerraoui and Ruppert, agents have unique identifiers but may
only store a finite number of the identifiers they already heard about. The
community protocol model provides the power of a Turing machine with a $O(n\log
n)$ space. We consider variations on the two above models and we obtain a whole
landscape that covers and extends already known results. Namely, by considering
the case of homonyms, that is to say the case when several agents may share the
same identifier, we provide a hierarchy that goes from the case of no
identifier (population protocol model) to the case of unique identifiers
(community protocol model). We obtain in particular that any Turing Machine on
space $O(\log^{O(1)} n)$ can be simulated with at least $O(\log^{O(1)} n)$
identifiers, a result filling a gap left open in all previous studies. Our
results also extend and revisit in particular the hierarchy provided by
Chatzigiannakis \emph{et al.} on population protocols carrying Turing Machines
on limited space, solving the problem of the gap left by this work between
per-agent space $o(\log \log n)$ (proved to be equivalent to population
protocols) and $O(\log n)$ (proved to be equivalent to Turing machines).
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1412.2497</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03540</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03551</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Knowledge Transfer with Medical Language Embeddings</dc:title>
 <dc:creator>Hyland, Stephanie L.</dc:creator>
 <dc:creator>Karaletsos, Theofanis</dc:creator>
 <dc:creator>R&#xe4;tsch, Gunnar</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  Identifying relationships between concepts is a key aspect of scientific
knowledge synthesis. Finding these links often requires a researcher to
laboriously search through scien- tific papers and databases, as the size of
these resources grows ever larger. In this paper we describe how distributional
semantics can be used to unify structured knowledge graphs with unstructured
text to predict new relationships between medical concepts, using a
probabilistic generative model. Our approach is also designed to ameliorate
data sparsity and scarcity issues in the medical domain, which make language
modelling more challenging. Specifically, we integrate the medical relational
database (SemMedDB) with text from electronic health records (EHRs) to perform
knowledge graph completion. We further demonstrate the ability of our model to
predict relationships between tokens not appearing in the relational database.
</dc:description>
 <dc:description>Comment: 6 pages, 2 figures, to appear at SDM-DMMH 2016</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03551</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03552</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Learning Privately from Multiparty Data</dc:title>
 <dc:creator>Hamm, Jihun</dc:creator>
 <dc:creator>Cao, Paul</dc:creator>
 <dc:creator>Belkin, Mikhail</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  Learning a classifier from private data collected by multiple parties is an
important problem that has many potential applications. How can we build an
accurate and differentially private global classifier by combining
locally-trained classifiers from different parties, without access to any
party's private data? We propose to transfer the `knowledge' of the local
classifier ensemble by first creating labeled data from auxiliary unlabeled
data, and then train a global $\epsilon$-differentially private classifier. We
show that majority voting is too sensitive and therefore propose a new risk
weighted by class probabilities estimated from the ensemble. Relative to a
non-private solution, our private solution has a generalization error bounded
by $O(\epsilon^{-2}M^{-2})$ where $M$ is the number of parties. This allows
strong privacy without performance loss when $M$ is large, such as in
crowdsensing applications. We demonstrate the performance of our method with
realistic tasks of activity recognition, network intrusion detection, and
malicious URL detection.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03552</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03557</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Old Techniques for New Join Algorithms: A Case Study in RDF Processing</dc:title>
 <dc:creator>Aberger, Christopher R.</dc:creator>
 <dc:creator>Tu, Susan</dc:creator>
 <dc:creator>Olukotun, Kunle</dc:creator>
 <dc:creator>R&#xe9;, Christopher</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Recently there has been significant interest around designing specialized RDF
engines, as traditional query processing mechanisms incur orders of magnitude
performance gaps on many RDF workloads. At the same time researchers have
released new worst-case optimal join algorithms which can be asymptotically
better than the join algorithms in traditional engines. In this paper we apply
worst-case optimal join algorithms to a standard RDF workload, the LUBM
benchmark, for the first time. We do so using two worst-case optimal engines:
(1) LogicBlox, a commercial database engine, and (2) EmptyHeaded, our prototype
research engine with enhanced worst-case optimal join algorithms. We show that
without any added optimizations both LogicBlox and EmptyHeaded outperform two
state-of-the-art specialized RDF engines, RDF-3X and TripleBit, by up to 6x on
cyclic join queries-the queries where traditional optimizers are suboptimal. On
the remaining, less complex queries in the LUBM benchmark, we show that three
classic query optimization techniques enable EmptyHeaded to compete with RDF
engines, even when there is no asymptotic advantage to the worst-case optimal
approach. We validate that our design has merit as EmptyHeaded outperforms
MonetDB by three orders of magnitude and LogicBlox by two orders of magnitude,
while remaining within an order of magnitude of RDF-3X and TripleBit.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03557</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03563</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>QoS Evaluation of Heterogeneous Networks: Application-based Approach</dc:title>
 <dc:creator>Farid, Farnaz</dc:creator>
 <dc:creator>Shahrestani, Seyed</dc:creator>
 <dc:creator>Ruan, Chun</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  In this paper, an application-based QoS evaluation approach for heterogeneous
networks is proposed.It is possible to expand the network capacity and coverage
in a dynamic fashion by applying heterogeneous wireless network architecture.
However, the Quality of Service (QoS) evaluation of this type of network
architecture is very challenging due to the presence of different communication
technologies. Different communication technologies have different
characteristics and the applications that utilize them have unique QoS
requirements. Although, the communication technologies have different
performance measurement parameters, the applications using these radio access
networks have the same QoS requirements. As a result, it would be easier to
evaluate the QoS of the access networks and the overall network configuration
based on the performance of applications running on them. Using such
application-based QoS evaluation approach, the heterogeneous nature of the
underlying networks and the diversity of their traffic can be adequately taken
into account. Through simulation studies, we show that the application
performance based assessment approach facilitates better QoS management and
monitoring of heterogeneous network configurations.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03563</dc:identifier>
 <dc:identifier>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.8, No.1, January 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03570</identifier>
 <datestamp>2016-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimized Kernel-based Projection Space of Riemannian Manifolds</dc:title>
 <dc:creator>Alavi, Azadeh</dc:creator>
 <dc:creator>Patel, Vishal M</dc:creator>
 <dc:creator>Chellappa, Rama</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  It is proven that encoding images and videos through Symmetric Positive
Definite (SPD) matrices, and considering the Riemannian geometry of the
resulting space, can lead to increased classification performance. Taking into
account manifold geometry is typically done via embedding the manifolds in
tangent spaces, or Reproducing Kernel Hilbert Spaces (RKHS). Recently, it was
shown that embedding such manifolds into a Random Projection Spaces (RPS),
rather than RKHS or tangent space, leads to higher classification and
clustering performance. However, based on structure and dimensionality of the
randomly generated hyperplanes, the classification performance over RPS may
vary significantly. In addition, fine-tuning RPS is data expensive (as it
requires validation-data), time consuming, and resource demanding. In this
paper, we introduce an approach to learn an optimized kernel-based projection
(with fixed dimensionality), by employing the concept of subspace clustering.
As such, we encode the association of data points to the underlying subspace of
each point, to generate meaningful hyperplanes. Further, we adopt the concept
of dictionary learning and sparse coding, and discriminative analysis, for the
optimized kernel-based projection space (OPS) on SPD manifolds. We validate our
algorithm on several classification tasks. The experiment results also
demonstrate that the proposed method outperforms state-of-the-art methods on
such manifolds.
</dc:description>
 <dc:description>Comment: 14 pages, 6 figures, conference</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-03-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03570</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03571</identifier>
 <datestamp>2017-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High Dimensional Inference with Random Maximum A-Posteriori
  Perturbations</dc:title>
 <dc:creator>Hazan, Tamir</dc:creator>
 <dc:creator>Orabona, Francesco</dc:creator>
 <dc:creator>Sarwate, Anand D.</dc:creator>
 <dc:creator>Maji, Subhransu</dc:creator>
 <dc:creator>Jaakkola, Tommi</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  This paper presents a new approach, called perturb-max, for high-dimensional
statistical inference that is based on applying random perturbations followed
by optimization. This framework injects randomness to maximum a-posteriori
(MAP) predictors by randomly perturbing the potential function for the input. A
classic result from extreme value statistics asserts that perturb-max
operations generate unbiased samples from the Gibbs distribution using
high-dimensional perturbations. Unfortunately, the computational cost of
generating so many high-dimensional random variables can be prohibitive.
However, when the perturbations are of low dimension, sampling the perturb-max
prediction is as efficient as MAP optimization. This paper shows that the
expected value of perturb-max inference with low dimensional perturbations can
be used sequentially to generate unbiased samples from the Gibbs distribution.
Furthermore the expected value of the maximal perturbations is a natural bound
on the entropy of such perturb-max models. A measure concentration result for
perturb-max values shows that the deviation of their sampled average from its
expectation decays exponentially in the number of samples, allowing effective
approximation of the expectation.
</dc:description>
 <dc:description>Comment: 47 pages, 10 figures, under review</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-05-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03571</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03573</identifier>
 <datestamp>2016-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Space CoBot: a collaborative aerial robot for indoor microgravity
  environments</dc:title>
 <dc:creator>Roque, Pedro</dc:creator>
 <dc:creator>Ventura, Rodrigo</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:description>  This paper presents a first contribution to the design of a small aerial
robot for inhabited microgravity environments, such as orbiting space stations.
In particular, we target a fleet of robots for collaborative tasks with humans,
such as telepresence and cooperative mobile manipulation. We explore a
propeller based propulsion system, arranged in such a way that the
translational and the rotational components can be decoupled, resulting in an
holonomic hexarotor. Since propellers have limited thrust, we employ an
optimization approach to select the geometric configuration given a criteria of
uniform maximum thrust across all directions in the body reference frame. We
also tackle the problem of motion control: due to the decoupling of
translational and rotational modes we use separate converging controllers for
each one of these modes. In addition, we present preliminary simulation results
in a realistic simulator, in closed loop with the proposed controller, thus
providing a first validation of the followed methodology.
</dc:description>
 <dc:description>Comment: 21 pages, 13 figures. Previously at arXiv:1603.07545</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2016-04-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03573</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03585</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Generating Discriminative Object Proposals via Submodular Ranking</dc:title>
 <dc:creator>Zhang, Yangmuzi</dc:creator>
 <dc:creator>Jiang, Zhuolin</dc:creator>
 <dc:creator>Chen, Xi</dc:creator>
 <dc:creator>Davis, Larry S.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  A multi-scale greedy-based object proposal generation approach is presented.
Based on the multi-scale nature of objects in images, our approach is built on
top of a hierarchical segmentation. We first identify the representative and
diverse exemplar clusters within each scale by using a diversity ranking
algorithm. Object proposals are obtained by selecting a subset from the
multi-scale segment pool via maximizing a submodular objective function, which
consists of a weighted coverage term, a single-scale diversity term and a
multi-scale reward term. The weighted coverage term forces the selected set of
object proposals to be representative and compact; the single-scale diversity
term encourages choosing segments from different exemplar clusters so that they
will cover as many object patterns as possible; the multi-scale reward term
encourages the selected proposals to be discriminative and selected from
multiple layers generated by the hierarchical image segmentation. The
experimental results on the Berkeley Segmentation Dataset and PASCAL VOC2012
segmentation dataset demonstrate the accuracy and efficiency of our object
proposal model. Additionally, we validate our object proposals in simultaneous
segmentation and detection and outperform the state-of-art performance.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03585</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03586</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Guessing Numbers of Odd Cycles</dc:title>
 <dc:creator>Atkins, Ross</dc:creator>
 <dc:creator>Rombach, Puck</dc:creator>
 <dc:creator>Skerman, Fiona</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  For a given number of colours, $s$, the guessing number of a graph is the
base $s$ logarithm of the size of the largest family of colourings of the
vertex set of the graph such that the colour of each vertex can be determined
from the colours of the vertices in its neighbourhood. An upper bound for the
guessing number of the $n$-vertex cycle graph $C_n$ is $n/2$. It is known that
the guessing number equals $n/2$ whenever $n$ is even or $s$ is a perfect
square \cite{Christofides2011guessing}. We show that, for any given integer
$s\geq 2$, if $a$ is the largest factor of $s$ less than or equal to
$\sqrt{s}$, for sufficiently large odd $n$, the guessing number of $C_n$ with
$s$ colours is $(n-1)/2 + \log_s(a)$. This answers a question posed by
Christofides and Markstr\&quot;{o}m in 2011 \cite{Christofides2011guessing}. We also
present an explicit protocol which achieves this bound for every $n$. Linking
this to index coding with side information, we deduce that the information
defect of $C_n$ with $s$ colours is $(n+1)/2 - \log_s(a)$ for sufficiently
large odd $n$. Our results are a generalisation of the $s=2$ case which was
proven in \cite{bar2011index}.
</dc:description>
 <dc:description>Comment: 16 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03586</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03591</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Using session types as an effect system</dc:title>
 <dc:creator>Orchard, Dominic</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>F.3.3</dc:subject>
 <dc:subject>D.3.2</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  Side effects are a core part of practical programming. However, they are
often hard to reason about, particularly in a concurrent setting. We propose a
foundation for reasoning about concurrent side effects using sessions.
Primarily, we show that session types are expressive enough to encode an effect
system for stateful processes. This is formalised via an effect-preserving
encoding of a simple imperative language with an effect system into the
pi-calculus with session primitives and session types (into which we encode
effect specifications). This result goes towards showing a connection between
the expressivity of session types and effect systems. We briefly discuss how
the encoding could be extended and applied to reason about and control
concurrent side effects.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03591</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 1-13</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03592</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Broadcast and aggregation in BBC</dc:title>
 <dc:creator>H&#xfc;ttel, Hans</dc:creator>
 <dc:creator>Pratas, Nuno</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  In distributed systems, where multi-party communication is essential, two
communication paradigms are ever present: (1) one-to-many, commonly denoted as
broadcast; and (2) many-to-one denoted as aggregation or collection.
  In this paper we present the BBC process calculus, which inherently models
the broadcast and aggregation communication modes. We then apply this process
calculus to reason on hierarchical network structure and provide examples on
its expressive power.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03592</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 15-28</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.2</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03593</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Precise subtyping for synchronous multiparty sessions</dc:title>
 <dc:creator>Dezani-Ciancaglini, Mariangiola</dc:creator>
 <dc:creator>Ghilezan, Silvia</dc:creator>
 <dc:creator>Jak&#x161;i&#x107;, Svetlana</dc:creator>
 <dc:creator>Pantovi&#x107;, Jovanka</dc:creator>
 <dc:creator>Yoshida, Nobuko</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>D.3.3</dc:subject>
 <dc:subject>F.3.2</dc:subject>
 <dc:description>  The notion of subtyping has gained an important role both in theoretical and
applicative domains: in lambda and concurrent calculi as well as in programming
languages. The soundness and the completeness, together referred to as the
preciseness of subtyping, can be considered from two different points of view:
operational and denotational. The former preciseness has been recently
developed with respect to type safety, i.e. the safe replacement of a term of a
smaller type when a term of a bigger type is expected. The latter preciseness
is based on the denotation of a type which is a mathematical object that
describes the meaning of the type in accordance with the denotations of other
expressions from the language. The result of this paper is the operational and
denotational preciseness of the subtyping for a synchronous multiparty session
calculus. The novelty of this paper is the introduction of characteristic
global types to prove the operational completeness.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03593</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 29-43</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.3</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03594</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reversible Communicating Processes</dc:title>
 <dc:creator>Brown, Geoffrey</dc:creator>
 <dc:creator>Sabry, Amr</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Reversible distributed programs have the ability to abort unproductive
computation paths and backtrack, while unwinding communication that occurred in
the aborted paths. While it is natural to assume that reversibility implies
full state recovery (as with traditional roll-back recovery protocols), an
interesting alternative is to separate backtracking from local state recovery.
For example, such a model could be used to create complex transactions out of
nested compensable transactions where a programmer-supplied compensation
defines the work required to &quot;unwind&quot; a transaction.
  Reversible distributed computing has received considerable theoretical
attention, but little reduction to practice; the few published implementations
of languages supporting reversibility depend upon a high degree of central
control. The objective of this paper is to demonstrate that a practical
reversible distributed language can be efficiently implemented in a fully
distributed manner.
  We discuss such a language, supporting CSP-style synchronous communication,
embedded in Scala. While this language provided the motivation for the work
described in this paper, our focus is upon the distributed implementation. In
particular, we demonstrate that a &quot;high-level&quot; semantic model can be
implemented using a simple point-to-point protocol.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03594</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 45-59</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03595</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Retractable Contracts</dc:title>
 <dc:creator>Barbanera, Franco</dc:creator>
 <dc:creator>Dezani-Ciancaglini, Mariangiola</dc:creator>
 <dc:creator>Lanese, Ivan</dc:creator>
 <dc:creator>de'Liguoro, Ugo</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  In calculi for modelling communication protocols, internal and external
choices play dual roles. Two external choices can be viewed naturally as dual
too, as they represent an agreement between the communicating parties. If the
interaction fails, the past agreements are good candidates as points where to
roll back, in order to take a different agreement. We propose a variant of
contracts with synchronous rollbacks to agreement points in case of deadlock.
The new calculus is equipped with a compliance relation which is shown to be
decidable.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03595</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 61-72</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.5</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03596</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Typed Model for Dynamic Authorizations</dc:title>
 <dc:creator>Ghilezan, Silvia</dc:creator>
 <dc:creator>Jak&#x161;i&#x107;, Svetlana</dc:creator>
 <dc:creator>Pantovi&#x107;, Jovanka</dc:creator>
 <dc:creator>P&#xe9;rez, Jorge A.</dc:creator>
 <dc:creator>Vieira, Hugo Torres</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Security requirements in distributed software systems are inherently dynamic.
In the case of authorization policies, resources are meant to be accessed only
by authorized parties, but the authorization to access a resource may be
dynamically granted/yielded. We describe ongoing work on a model for specifying
communication and dynamic authorization handling. We build upon the pi-calculus
so as to enrich communication-based systems with authorization specification
and delegation; here authorizations regard channel usage and delegation refers
to the act of yielding an authorization to another party. Our model includes:
(i) a novel scoping construct for authorization, which allows to specify
authorization boundaries, and (ii) communication primitives for authorizations,
which allow to pass around authorizations to act on a given channel. An
authorization error may consist in, e.g., performing an action along a name
which is not under an appropriate authorization scope. We introduce a typing
discipline that ensures that processes never reduce to authorization errors,
even when authorizations are dynamically delegated.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03596</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 73-84</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.6</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03597</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Communicating machines as a dynamic binding mechanism of services</dc:title>
 <dc:creator>Vissani, Ignacio</dc:creator>
 <dc:creator>Pombo, Carlos Gustavo Lopez</dc:creator>
 <dc:creator>Tuosto, Emilio</dc:creator>
 <dc:subject>Computer Science - Logic in Computer Science</dc:subject>
 <dc:description>  Distributed software is becoming more and more dynamic to support
applications able to respond and adapt to the changes of their execution
environment. For instance, service-oriented computing (SOC) envisages
applications as services running over globally available computational
resources where discovery and binding between them is transparently performed
by a middleware. Asynchronous Relational Networks (ARNs) is a well-known formal
orchestration model, based on hypergraphs, for the description of
service-oriented software artefacts. Choreography and orchestration are the two
main design principles for the development of distributed software. In this
work, we propose Communicating Relational Networks (CRNs), which is a variant
of ARNs, but relies on choreographies for the characterisation of the
communicational aspects of a software artefact, and for making their automated
analysis more efficient.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03597</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 85-98</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03598</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Distributed Programming via Safe Closure Passing</dc:title>
 <dc:creator>Haller, Philipp</dc:creator>
 <dc:creator>Miller, Heather</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Programming systems incorporating aspects of functional programming, e.g.,
higher-order functions, are becoming increasingly popular for large-scale
distributed programming. New frameworks such as Apache Spark leverage
functional techniques to provide high-level, declarative APIs for in-memory
data analytics, often outperforming traditional &quot;big data&quot; frameworks like
Hadoop MapReduce. However, widely-used programming models remain rather ad-hoc;
aspects such as implementation trade-offs, static typing, and semantics are not
yet well-understood. We present a new asynchronous programming model that has
at its core several principles facilitating functional processing of
distributed data. The emphasis of our model is on simplicity, performance, and
expressiveness. The primary means of communication is by passing functions
(closures) to distributed, immutable data. To ensure safe and efficient
distribution of closures, our model leverages both syntactic and type-based
restrictions. We report on a prototype implementation in Scala. Finally, we
present preliminary experimental results evaluating the performance impact of a
static, type-based optimization of serialization.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03598</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 99-107</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.8</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03599</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Behavioural types for non-uniform memory accesses</dc:title>
 <dc:creator>Franco, Juliana</dc:creator>
 <dc:creator>Drossopoulou, Sophia</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  Concurrent programs executing on NUMA architectures consist of concurrent
entities (e.g. threads, actors) and data placed on different nodes. Execution
of these concurrent entities often reads or updates states from remote nodes.
The performance of such systems depends on the extent to which the concurrent
entities can be executing in parallel, and on the amount of the remote reads
and writes.
  We consider an actor-based object oriented language, and propose a type
system which expresses the topology of the program (the placement of the actors
and data on the nodes), and an effect system which characterises remote reads
and writes (in terms of which node reads/writes from which other nodes). We use
a variant of ownership types for the topology, and a combination of behavioural
and ownership types for the effect system.
</dc:description>
 <dc:description>Comment: In Proceedings PLACES 2015, arXiv:1602.03254</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03599</dc:identifier>
 <dc:identifier>EPTCS 203, 2016, pp. 109-120</dc:identifier>
 <dc:identifier>doi:10.4204/EPTCS.203.9</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03600</identifier>
 <datestamp>2017-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Data-Driven Online Decision Making with Costly Information Acquisition</dc:title>
 <dc:creator>Atan, Onur</dc:creator>
 <dc:creator>van der Schaar, Mihaela</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In most real-world settings such as recommender systems, finance, and
healthcare, collecting useful information is costly and requires an active
choice on the part of the decision maker. The decision-maker needs to learn
simultaneously what observations to make and what actions to take. This paper
incorporates the information acquisition decision into an online learning
framework. We propose two different algorithms for this dual learning problem:
Sim-OOS and Seq-OOS where observations are made simultaneously and
sequentially, respectively. We prove that both algorithms achieve a regret that
is sublinear in time. The developed framework and algorithms can be used in
many applications including medical informatics, recommender systems and
actionable intelligence in transportation, finance, cyber-security etc., in
which collecting information prior to making decisions is costly. We validate
our algorithms in a breast cancer example setting in which we show substantial
performance gains for our proposed algorithms.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:date>2017-10-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03600</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03602</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wireless Communications with Unmanned Aerial Vehicles: Opportunities and
  Challenges</dc:title>
 <dc:creator>Zeng, Yong</dc:creator>
 <dc:creator>Zhang, Rui</dc:creator>
 <dc:creator>Lim, Teng Joon</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Wireless communication systems that include unmanned aerial vehicles (UAVs)
promise to provide cost-effective wireless connectivity for devices without
infrastructure coverage. Compared to terrestrial communications or those based
on high-altitude platforms (HAPs), on-demand wireless systems with low-altitude
UAVs are in general faster to deploy, more flexibly re-configured, and are
likely to have better communication channels due to the presence of short-range
line-of-sight (LoS) links. However, the utilization of highly mobile and
energy-constrained UAVs for wireless communications also introduces many new
challenges. In this article, we provide an overview of UAV-aided wireless
communications, by introducing the basic networking architecture and main
channel characteristics, highlighting the key design considerations as well as
the new opportunities to be exploited.
</dc:description>
 <dc:description>Comment: To appear in IEEE Communications Magazine</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03602</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2016.7470933</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03606</identifier>
 <datestamp>2017-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Variations of the Similarity Function of TextRank for Automated
  Summarization</dc:title>
 <dc:creator>Barrios, Federico</dc:creator>
 <dc:creator>L&#xf3;pez, Federico</dc:creator>
 <dc:creator>Argerich, Luis</dc:creator>
 <dc:creator>Wachenchauzer, Rosa</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Information Retrieval</dc:subject>
 <dc:subject>I.2.7</dc:subject>
 <dc:description>  This article presents new alternatives to the similarity function for the
TextRank algorithm for automatic summarization of texts. We describe the
generalities of the algorithm and the different functions we propose. Some of
these variants achieve a significative improvement using the same metrics and
dataset as the original publication.
</dc:description>
 <dc:description>Comment: 8 pages, 2 figures. Presented at the Argentine Symposium on
  Artificial Intelligence (ASAI) 2015 - 44 JAIIO (September 2015)</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03606</dc:identifier>
 <dc:identifier>44 JAIIO - ASAI 2015 - ISSN: 2451-7585, pages 65-72</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03609</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Attentive Pooling Networks</dc:title>
 <dc:creator>Santos, Cicero dos</dc:creator>
 <dc:creator>Tan, Ming</dc:creator>
 <dc:creator>Xiang, Bing</dc:creator>
 <dc:creator>Zhou, Bowen</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In this work, we propose Attentive Pooling (AP), a two-way attention
mechanism for discriminative model training. In the context of pair-wise
ranking or classification with neural networks, AP enables the pooling layer to
be aware of the current input pair, in a way that information from the two
input items can directly influence the computation of each other's
representations. Along with such representations of the paired inputs, AP
jointly learns a similarity measure over projected segments (e.g. trigrams) of
the pair, and subsequently, derives the corresponding attention vector for each
input to guide the pooling. Our two-way attention mechanism is a general
framework independent of the underlying representation learning, and it has
been applied to both convolutional neural networks (CNNs) and recurrent neural
networks (RNNs) in our studies. The empirical results, from three very
different benchmark tasks of question answering/answer selection, demonstrate
that our proposed models outperform a variety of strong baselines and achieve
state-of-the-art performance in all the benchmarks.
</dc:description>
 <dc:description>Comment: 10 pages</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03609</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03616</identifier>
 <datestamp>2016-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multifaceted Feature Visualization: Uncovering the Different Types of
  Features Learned By Each Neuron in Deep Neural Networks</dc:title>
 <dc:creator>Nguyen, Anh</dc:creator>
 <dc:creator>Yosinski, Jason</dc:creator>
 <dc:creator>Clune, Jeff</dc:creator>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  We can better understand deep neural networks by identifying which features
each of their neurons have learned to detect. To do so, researchers have
created Deep Visualization techniques including activation maximization, which
synthetically generates inputs (e.g. images) that maximally activate each
neuron. A limitation of current techniques is that they assume each neuron
detects only one type of feature, but we know that neurons can be multifaceted,
in that they fire in response to many different types of features: for example,
a grocery store class neuron must activate either for rows of produce or for a
storefront. Previous activation maximization techniques constructed images
without regard for the multiple different facets of a neuron, creating
inappropriate mixes of colors, parts of objects, scales, orientations, etc.
Here, we introduce an algorithm that explicitly uncovers the multiple facets of
each neuron by producing a synthetic visualization of each of the types of
images that activate a neuron. We also introduce regularization methods that
produce state-of-the-art results in terms of the interpretability of images
obtained by activation maximization. By separately synthesizing each type of
image a neuron fires in response to, the visualizations have more appropriate
colors and coherent global structure. Multifaceted feature visualization thus
provides a clearer and more comprehensive description of the role of each
neuron.
</dc:description>
 <dc:description>Comment: 23 pages (including SI), 24 figures</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-05-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03616</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03617</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Two-hop Power-Relaying for Linear Wireless Sensor Networks</dc:title>
 <dc:creator>Bengua, Johann A.</dc:creator>
 <dc:creator>Tuan, Hoang D.</dc:creator>
 <dc:creator>Phien, Ho N.</dc:creator>
 <dc:creator>Kha, Ha H.</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This paper presents two-hop relay gain-scheduling control in a Wireless
Sensor Network to estimate a static target prior characterized by Gaussian
probability distribution. The target is observed by a network of linear
sensors, whose observations are transmitted to a fusion center for carrying out
final estimation via a amplify-and-forward relay node. We are concerned with
the joint transmission power allocation for sensors and relay to optimize the
minimum mean square error (MMSE) estimator, which is deployed at the fusion
center. Particularly, such highly nonlinear optimization problems are solved by
an iterative procedure of very low computational complexity. Simulations are
provided to support the efficiency of our proposed power allocation.
</dc:description>
 <dc:description>Comment: Submitted to IEEE ICCE 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03617</dc:identifier>
 <dc:identifier>doi:10.1109/CCE.2016.7562622</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03618</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Characterising Probability Distributions via Entropies</dc:title>
 <dc:creator>Thakor, Satyajit</dc:creator>
 <dc:creator>Chan, Terence</dc:creator>
 <dc:creator>Grant, Alex</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Characterising the capacity region for a network can be extremely difficult,
especially when the sources are dependent. Most existing computable outer
bounds are relaxations of the Linear Programming bound. One main challenge to
extend linear program bounds to the case of correlated sources is the
difficulty (or impossibility) of characterising arbitrary dependencies via
entropy functions. This paper tackles the problem by addressing how to use
entropy functions to characterise correlation among sources.
</dc:description>
 <dc:description>Comment: 5 pages, 1 figure</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03618</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03619</identifier>
 <datestamp>2017-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimal Inference in Crowdsourced Classification via Belief Propagation</dc:title>
 <dc:creator>Ok, Jungseul</dc:creator>
 <dc:creator>Oh, Sewoong</dc:creator>
 <dc:creator>Shin, Jinwoo</dc:creator>
 <dc:creator>Yi, Yung</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  Crowdsourcing systems are popular for solving large-scale labelling tasks
with low-paid workers. We study the problem of recovering the true labels from
the possibly erroneous crowdsourced labels under the popular Dawid-Skene model.
To address this inference problem, several algorithms have recently been
proposed, but the best known guarantee is still significantly larger than the
fundamental limit. We close this gap by introducing a tighter lower bound on
the fundamental limit and proving that Belief Propagation (BP) exactly matches
this lower bound. The guaranteed optimality of BP is the strongest in the sense
that it is information-theoretically impossible for any other algorithm to
correctly label a larger fraction of the tasks. Experimental results suggest
that BP is close to optimal for all regimes considered and improves upon
competing state-of-the-art algorithms.
</dc:description>
 <dc:description>Comment: This article is partially based on preliminary results published in
  the proceeding of the 33rd International Conference on Machine Learning (ICML
  2016)</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-01-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03619</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03623</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Dynamic Group Behaviors for Interactive Crowd Simulation</dc:title>
 <dc:creator>He, Liang</dc:creator>
 <dc:creator>Pan, Jia</dc:creator>
 <dc:creator>Narang, Sahil</dc:creator>
 <dc:creator>Wang, Wenping</dc:creator>
 <dc:creator>Manocha, Dinesh</dc:creator>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:description>  We present a new algorithm to simulate dynamic group behaviors for
interactive multi-agent crowd simulation. Our approach is general and makes no
assumption about the environment, shape, or size of the groups. We use the
least effort principle to perform coherent group navigation and present
efficient inter-group and intra-group maintenance techniques. We extend the
reciprocal collision avoidance scheme to perform agent-group and group-group
collision avoidance that can generate collision-free as well as coherent and
trajectories. The additional overhead of dynamic group simulation is relatively
small. We highlight its interactive performance on complex scenarios with
hundreds of agents and compare the trajectory behaviors with real-world videos.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03623</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03635</identifier>
 <datestamp>2017-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Optimization of Caching Devices with Geometric Constraints</dc:title>
 <dc:creator>Avrachenkov, Konstantin</dc:creator>
 <dc:creator>Bai, Xinwei</dc:creator>
 <dc:creator>Goseling, Jasper</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  It has been recently advocated that in large communication systems it is
beneficial both for the users and for the network as a whole to store content
closer to users. One particular implementation of such an approach is to
co-locate caches with wireless base stations. In this paper we study
geographically distributed caching of a fixed collection of files. We model
cache placement with the help of stochastic geometry and optimize the
allocation of storage capacity among files in order to minimize the cache miss
probability. We consider both per cache capacity constraints as well as an
average capacity constraint over all caches. The case of per cache capacity
constraints can be efficiently solved using dynamic programming, whereas the
case of the average constraint leads to a convex optimization problem. We
demonstrate that the average constraint leads to significantly smaller cache
miss probability. Finally, we suggest a simple LRU-based policy for
geographically distributed caching and show that its performance is close to
the optimal.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-01-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03635</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03636</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Link prediction in Foursquare network</dc:title>
 <dc:creator>Fortuna, Rok</dc:creator>
 <dc:creator>Marovt, Urban</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Foursquare is an online social network and can be represented with a
bipartite network of users and venues. A user-venue pair is connected if a user
has checked-in at that venue. In the case of Foursquare, network analysis
techniques can be used to enhance the user experience. One such technique is
link prediction, which can be used to build a personalized recommendation
system of venues. Recommendation systems in bipartite networks are very often
designed using the global ranking method and collaborative filtering. A less
known method- network based inference is also a feasible choice for link
prediction in bipartite networks and sometimes performs better than the
previous two. In this paper we test these techniques on the Foursquare network.
The best technique proves to be the network based inference. We also show that
taking into account the available metadata can be beneficial.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03636</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03638</identifier>
 <datestamp>2016-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>High performance Python for direct numerical simulations of turbulent
  flows</dc:title>
 <dc:creator>Mortensen, Mikael</dc:creator>
 <dc:creator>Langtangen, Hans Petter</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Direct Numerical Simulations (DNS) of the Navier Stokes equations is an
invaluable research tool in fluid dynamics. Still, there are few publicly
available research codes and, due to the heavy number crunching implied,
available codes are usually written in low-level languages such as C/C++ or
Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS
code that nearly matches the performance of C++ for thousands of processors and
billions of unknowns. We also describe a version optimized through Cython, that
is found to match the speed of C++. The solvers are written from scratch in
Python, both the mesh, the MPI domain decomposition, and the temporal
integrators. The solvers have been verified and benchmarked on the Shaheen
supercomputer at the KAUST supercomputing laboratory, and we are able to show
very good scaling up to several thousand cores.
  A very important part of the implementation is the mesh decomposition (we
implement both slab and pencil decompositions) and 3D parallel Fast Fourier
Transforms (FFT). The mesh decomposition and FFT routines have been implemented
in Python using serial FFT routines (either NumPy, pyFFTW or any other serial
FFT module), NumPy array manipulations and with MPI communications handled by
MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT
in Python for a slab mesh decomposition using 4 lines of compact Python code,
for which the parallel performance on Shaheen is found to be slightly better
than similar routines provided through the FFTW library. For a pencil mesh
decomposition 7 lines of code is required to execute a transform.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03638</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2016.02.005</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03641</identifier>
 <datestamp>2016-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Vertex Approximate Gradient discretization of hybrid
  dimensional Darcy flow and transport in discrete fracture networks</dc:title>
 <dc:creator>Xing, Feng</dc:creator>
 <dc:creator>Masson, Roland</dc:creator>
 <dc:creator>Lopez, Simon</dc:creator>
 <dc:subject>Mathematics - Numerical Analysis</dc:subject>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:subject>Computer Science - Numerical Analysis</dc:subject>
 <dc:subject>Mathematics - Analysis of PDEs</dc:subject>
 <dc:description>  This paper proposes a parallel numerical algorithm to simulate the flow and
the transport in a discrete fracture network taking into account the mass
exchanges with the surrounding matrix. The discretization of the Darcy fluxes
is based on the Vertex Approximate Gradient finite volume scheme adapted to
polyhedral meshes and to heterogeneous anisotropic media, and the transport
equation is discretized by a first order upwind scheme combined with an Euler
explicit integration in time. The parallelization is based on the SPMD (Single
Program, Multiple Data) paradigm and relies on a distribution of the mesh on
the processes with one layer of ghost cells in order to allow for a local
assembly of the discrete systems. The linear system for the Darcy flow is
solved using different linear solvers and preconditioners implemented in the
PETSc and Trilinos libraries. The convergence of the scheme is validated on two
original analytical solutions with one and four intersecting fractures. Then,
the parallel efficiency of the algorithm is assessed on up to 512 processes
with different types of meshes, different matrix fracture permeability ratios,
and different levels of complexity of the fracture network.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-11-17</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03641</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03642</identifier>
 <datestamp>2016-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Access Control Encryption: Enforcing Information Flow with Cryptography</dc:title>
 <dc:creator>Damg&#xe5;rd, Ivan</dc:creator>
 <dc:creator>Haagh, Helene</dc:creator>
 <dc:creator>Orlandi, Claudio</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We initiate the study of Access Control Encryption (ACE), a novel
cryptographic primitive that allows fine-grained access control, by giving
different rights to different users not only in terms of which messages they
are allowed to receive, but also which messages they are allowed to send.
  Classical examples of security policies for information flow are the well
known Bell-Lapadula [BL73] or Biba [Bib75] model: in a nutshell, the
Bell-Lapadula model assigns roles to every user in the system (e.g., public,
secret and top-secret). A users' role specifies which messages the user is
allowed to receive (i.e., the no read-up rule, meaning that users with public
clearance should not be able to read messages marked as secret or top-secret)
but also which messages the user is allowed to send (i.e., the no write-down
rule, meaning that a user with top-secret clearance should not be able to write
messages marked as secret or public).
  To the best of our knowledge, no existing cryptographic primitive allows for
even this simple form of access control, since no existing cryptographic
primitive enforces any restriction on what kind of messages one should be able
to encrypt.
  Our contributions are: - Introducing and formally defining access control
encryption (ACE); - A construction of ACE with complexity linear in the number
of the roles based on classic number theoretic assumptions (DDH, Paillier); - A
construction of ACE with complexity polylogarithmic in the number of roles
based on recent results on cryptographic obfuscation;
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-12-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03642</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03643</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Oasis: a high-level/high-performance open source Navier-Stokes solver</dc:title>
 <dc:creator>Mortensen, Mikael</dc:creator>
 <dc:creator>Valen-Sendstad, Kristian</dc:creator>
 <dc:subject>Computer Science - Mathematical Software</dc:subject>
 <dc:description>  Oasis is a high-level/high-performance finite element Navier-Stokes solver
written from scratch in Python using building blocks from the FEniCS project
(fenicsproject.org). The solver is unstructured and targets large-scale
applications in complex geometries on massively parallel clusters. Oasis
utilizes MPI and interfaces, through FEniCS, to the linear algebra backend
PETSc. Oasis advocates a high-level, programmable user interface through the
creation of highly flexible Python modules for new problems. Through the
high-level Python interface the user is placed in complete control of every
aspect of the solver. A version of the solver, that is using piecewise linear
elements for both velocity and pressure, is shown reproduce very well the
classical, spectral, turbulent channel simulations of Moser, Kim and Mansour at
$Re_{\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is
strongly dominated by the iterative solvers provided by the linear algebra
backend, which is arguably the best performance any similar implicit solver
using PETSc may hope for. Higher order accuracy is also demonstrated and new
solvers may be easily added within the same framework.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03643</dc:identifier>
 <dc:identifier>Computer Physics Communications, Volume 188, p 177-188, 2015</dc:identifier>
 <dc:identifier>doi:10.1016/j.cpc.2014.10.026</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03644</identifier>
 <datestamp>2016-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Impact of LOS/NLOS Propagation and Path Loss in Ultra-Dense Cellular
  Networks</dc:title>
 <dc:creator>Arnau, Jes&#xfa;s</dc:creator>
 <dc:creator>Atzeni, Italo</dc:creator>
 <dc:creator>Kountouris, Marios</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Most prior work on performance analysis of ultra-dense cellular networks
(UDNs) has considered standard power-law path loss models and non-line-of-sight
(NLOS) propagation modeled by Rayleigh fading. The effect of line-of-sight
(LOS) on coverage and throughput and its implication on network densification
are still not fully understood. In this paper, we investigate the performance
of UDNs when the signal propagation includes both LOS and NLOS components.
Using a stochastic geometry based cellular network model, we derive expressions
for the coverage probability, as well as tight approximations and upper bounds
for both closest and strongest base station (BS) association. Our results show
that under standard singular path loss model, LOS propagation increases the
coverage, especially with nearest BS association. On the contrary, using dual
slope path loss, LOS propagation is beneficial with closest BS association and
detrimental for strongest BS association.
</dc:description>
 <dc:description>Comment: Paper presented at IEEE ICC 2016 - Wireless Communications Symposium</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-09-28</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03644</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03647</identifier>
 <datestamp>2016-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the Difficulty of Selecting Ising Models with Approximate Recovery</dc:title>
 <dc:creator>Scarlett, Jonathan</dc:creator>
 <dc:creator>Cevher, Volkan</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In this paper, we consider the problem of estimating the underlying graph
associated with an Ising model given a number of independent and identically
distributed samples. We adopt an \emph{approximate recovery} criterion that
allows for a number of missed edges or incorrectly-included edges, in contrast
with the widely-studied exact recovery problem. Our main results provide
information-theoretic lower bounds on the sample complexity for graph classes
imposing constraints on the number of edges, maximal degree, and other
properties. We identify a broad range of scenarios where, either up to constant
factors or logarithmic factors, our lower bounds match the best known lower
bounds for the exact recovery criterion, several of which are known to be tight
or near-tight. Hence, in these cases, approximate recovery has a similar
difficulty to exact recovery in the minimax sense.
  Our bounds are obtained via a modification of Fano's inequality for handling
the approximate recovery criterion, along with suitably-designed ensembles of
graphs that can broadly be classed into two categories: (i) Those containing
graphs that contain several isolated edges or cliques and are thus difficult to
distinguish from the empty graph; (ii) Those containing graphs for which
certain groups of nodes are highly correlated, thus making it difficult to
determine precisely which edges connect them. We support our theoretical
results on these ensembles with numerical experiments.
</dc:description>
 <dc:description>Comment: Accepted to IEEE Transactions on Signal and Information Processing
  over Networks (TSIPN)</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-07-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03647</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03648</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Joint Beamforming and Broadcasting in Massive MIMO</dc:title>
 <dc:creator>Larsson, Erik G.</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  The downlink of a massive MIMO system is considered for the case in which the
base station must concurrently serve two categories of terminals: one group to
which imperfect instantaneous channel state information (CSI) is available, and
one group to which no CSI is available. Motivating applications include
broadcasting of public channels and control information in wireless networks.
  A new technique is developed and analyzed: joint beamforming and broadcasting
(JBB), by which the base station beamforms to the group of terminals to which
CSI is available, and broadcasts to the other group of terminals, to which no
CSI is available. The broadcast information does not interfere with the
beamforming as it is placed in the nullspace of the channel matrix collectively
seen by the terminals targeted by the beamforming. JBB is compared to
orthogonal access (OA), by which the base station partitions the time-frequency
resources into two disjunct parts, one for each group of terminals.
  It is shown that JBB can substantially outperform OA in terms of required
total radiated power for given rate targets.
</dc:description>
 <dc:description>Comment: with minor correction</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-03-14</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03648</dc:identifier>
 <dc:identifier>IEEE Trans. Wireless Communications, 2016</dc:identifier>
 <dc:identifier>doi:10.1109/TWC.2016.2515598</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03650</identifier>
 <datestamp>2017-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher order assortativity in complex networks</dc:title>
 <dc:creator>Arcagni, Alberto</dc:creator>
 <dc:creator>Grassi, Rosanna</dc:creator>
 <dc:creator>Stefani, Silvana</dc:creator>
 <dc:creator>Torriero, Anna</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  Assortativity was first introduced by Newman and has been extensively studied
and applied to many real world networked systems since then. Assortativity is a
graph metrics and describes the tendency of high degree nodes to be directly
connected to high degree nodes and low degree nodes to low degree nodes. It can
be interpreted as a first order measure of the connection between nodes, i.e.
the first autocorrelation of the degree-degree vector. Even though
assortativity has been used so extensively, to the author's knowledge, no
attempt has been made to extend it theoretically. This is the scope of our
paper. We will introduce higher order assortativity by extending the Newman
index based on a suitable choice of the matrix driving the connections. Higher
order assortativity will be defined for paths, shortest paths, random walks of
a given time length, connecting any couple of nodes. The Newman assortativity
is achieved for each of these measures when the matrix is the adjacency matrix,
or, in other words, the correlation is of order 1. Our higher order
assortativity indexes can be used for describing a variety of real networks,
help discriminating networks having the same Newman index and may reveal new
topological network features.
</dc:description>
 <dc:description>Comment: 24 pages, 16 figures</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03650</dc:identifier>
 <dc:identifier>Eur.J.Oper.Res. 262 (2017) 708-719</dc:identifier>
 <dc:identifier>doi:10.1016/j.ejor.2017.04.028</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03654</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling UAV Cellular with Millimeter-Wave Communication: Potentials and
  Approaches</dc:title>
 <dc:creator>Xiao, Zhenyu</dc:creator>
 <dc:creator>Xia, Pengfei</dc:creator>
 <dc:creator>Xia, Xiang-Gen</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  To support high data rate urgent or ad hoc communications, we consider mmWave
UAV cellular networks and the associated challenges and solutions. To enable
fast beamforming training and tracking, we first investigate a hierarchical
structure of beamforming codebooks and design of hierarchical codebooks with
different beam widths via the sub-array techniques. We next examine the Doppler
effect as a result of UAV movement and find that the Doppler effect may not be
catastrophic when high gain directional transmission is used. We further
explore the use of millimeter wave spatial division multiple access and
demonstrate its clear advantage in improving the cellular network capacity. We
also explore different ways of dealing with signal blockage and point out that
possible adaptive UAV cruising algorithms would be necessary to counteract
signal blockage. Finally, we identify a close relationship between UAV
positioning and directional millimeter wave user discovery, where update of the
former may directly impact the latter and vice versa.
</dc:description>
 <dc:description>Comment: This paper explores the potentials and approaches to exploit mmWave
  communication to establish a UAV cellular. It is to appear in IEEE
  Communications Magazine</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03654</dc:identifier>
 <dc:identifier>doi:10.1109/MCOM.2016.7470937</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03655</identifier>
 <datestamp>2017-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Multi-Unit Facility Location Games</dc:title>
 <dc:creator>Ben-Porat, Omer</dc:creator>
 <dc:creator>Tennenholtz, Moshe</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  Motivated by applications in clustering and information retrieval, we extend
the classical Hotelling setting to deal with multi-facility location duels. In
the classical Hotelling setting, customers' locations are taken from the
uniform distribution on the $[0,1]$ segment, and there are two facility owners,
each needs to decide on the location of her (single) facility, aiming to
maximize the proportion of customers closer to it. We extend the Hotelling
setting to multi-unit facility location games, where there are $n$ players,
where player $i$ may control ${\bf several}$ facilities. We first analyze
competition among the owner of $k$ facilities to the owner of $l$ facilities,
for arbitrary $(l,k)$, where $l\leq k$. Our message for this extended Hotelling
duel is quite striking: in no equilibrium of any such $(l,k)$ facility location
duel a facility will materialize in a location which is not part of the social
welfare maximizing locations of the player who has $k$ facilities, if she were
to locate her facilities under no competition. This is obtained despite the
lack of pure strategy equilibrium in any $(l,k)$ duel whenever $l \neq k$.
Moreover, for the $n$-player setting, we provide sufficient and necessary
conditions for a pure strategy profile to be an equilibrium in such game. We
then show that a pure-strategy equilibrium exist if and only if there is no
dominant player who controls more than half of the facilities; in the latter
case, under some conditions, a mixed strategy equilibrium of the form obtained
in the $(l,k)$ duel does exist.
</dc:description>
 <dc:description>Comment: Accepted to 12th Conference on Web and Internet Economics (WINE 2016)</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-10-15</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03655</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-662-54110-4</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03661</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the emergence of syntactic structures: quantifying and modelling
  duality of patterning</dc:title>
 <dc:creator>Loreto, Vittorio</dc:creator>
 <dc:creator>Gravino, Pietro</dc:creator>
 <dc:creator>Servedio, Vito D. P.</dc:creator>
 <dc:creator>Tria, Francesca</dc:creator>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  The complex organization of syntax in hierarchical structures is one of the
core design features of human language. Duality of patterning refers for
instance to the organization of the meaningful elements in a language at two
distinct levels: a combinatorial level where meaningless forms are combined
into meaningful forms and a compositional level where meaningful forms are
composed into larger lexical units. The question remains wide open regarding
how such a structure could have emerged. Furthermore a clear mathematical
framework to quantify this phenomenon is still lacking. The aim of this paper
is that of addressing these two aspects in a self-consistent way. First, we
introduce suitable measures to quantify the level of combinatoriality and
compositionality in a language, and present a framework to estimate these
observables in human natural languages. Second, we show that the theoretical
predictions of a multi-agents modeling scheme, namely the Blending Game, are in
surprisingly good agreement with empirical data. In the Blending Game a
population of individuals plays language games aiming at success in
communication. It is remarkable that the two sides of duality of patterning
emerge simultaneously as a consequence of a pure cultural dynamics in a
simulated environment that contains meaningful relations, provided a simple
constraint on message transmission fidelity is also considered.
</dc:description>
 <dc:description>Comment: 11 pages, to appear in the Proceedings of the Workshop on Origins of
  Communication Systems: Modeling and Ethologically-based Theory, Konrad Lorenz
  Institute for Evolution and Cognition Research, Altenberg, Austria (2013).
  Special Issue of topiCS on New frontiers in language evolution and
  development</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03661</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03664</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Identifying top football players and springboard clubs from a football
  player collaboration and club transfer networks</dc:title>
 <dc:creator>Tribu&#x161;on, Matic</dc:creator>
 <dc:creator>Leni&#x10d;, Matev&#x17e;</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  We consider all players and clubs in top twenty world football leagues in the
last fifteen seasons. The purpose of this paper is to reveal top football
players and identify springboard clubs. To do that, we construct two separate
weighted networks. Player collaboration network consists of players, that are
connected to each other if they ever played together at the same club. In
directed club transfer network, clubs are connected if players were ever
transferred from one club to another. To get meaningful results, we perform
different network analysis methods on our networks. Our approach based on
PageRank reveals Christiano Ronaldo as the top player. Using a variation of
betweenness centrality, we identify Standard Liege as the best springboard
club.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03664</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03674</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analysis of friendship network from MMORPG based data</dc:title>
 <dc:creator>&#x10c;rnigoj, Dean</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  This work analyzes friendship network from a Massively Multiplayer Online
Role-Playing Game (MMORPG). The network is based on data from a private server
that was active from 2007 until 2011. The work conducts a standard analysis of
the network and then divides players according to different groups based on
their activity. Work checks how friendship network can be correlated to the
clan (a self-organized group of players who often form a league and play on the
same side in a match) network. Main part of the work is the recommendation
method for players that are not part of any clan and it is based on communities
of friendship network.
</dc:description>
 <dc:description>Comment: 6 pages</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03674</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03676</identifier>
 <datestamp>2016-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Cellular Networks in Fading Environments with Dominant Specular
  Components</dc:title>
 <dc:creator>AlAmmouri, Ahmad</dc:creator>
 <dc:creator>ElSawy, Hesham</dc:creator>
 <dc:creator>Sultan-Salem, Ahmed</dc:creator>
 <dc:creator>Di Renzo, Marco</dc:creator>
 <dc:creator>Alouini, Mohamed-Slim</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Stochastic geometry (SG) has been widely accepted as a fundamental tool for
modeling and analyzing cellular networks. However, the fading models used with
SG analysis are mainly confined to the simplistic Rayleigh fading, which is
extended to the Nakagami-m fading in some special cases. However, neither the
Rayleigh nor the Nakagami-m accounts for dominant specular components (DSCs)
which may appear in realistic fading channels. In this paper, we present a
tractable model for cellular networks with generalized two-ray (GTR) fading
channel. The GTR fading explicitly accounts for two DSCs in addition to the
diffuse components and offers high flexibility to capture diverse fading
channels that appear in realistic outdoor/indoor wireless communication
scenarios. It also encompasses the famous Rayleigh and Rician fading as special
cases. To this end, the prominent effect of DSCs is highlighted in terms of
average spectral efficiency.
</dc:description>
 <dc:description>Comment: IEEE ICC16</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03676</dc:identifier>
 <dc:identifier>doi:10.1109/ICC.2016.7510903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03681</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Package equivalence in complex software network</dc:title>
 <dc:creator>Slijep&#x10d;evi&#x107;, Tomislav</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  The public package registry npm is one of the biggest software registry. With
its 216 911 software packages, it forms a big network of software dependencies.
In this paper we evaluate various methods for finding similar packages in the
npm network, using only the structure of the graph. Namely, we want to find a
way of categorizing similar packages, which would be useful for recommendation
systems. This size enables us to compute meaningful results, as it softened the
particularities of the graph. Npm is also quite famous as it is the default
package repository of Node.js. We believe that it will make our results
interesting for more people than a less used package repository. This makes it
a good subject of analysis of software networks.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03681</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03686</identifier>
 <datestamp>2017-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Medical Concept Representation Learning from Electronic Health Records
  and its Application on Heart Failure Prediction</dc:title>
 <dc:creator>Choi, Edward</dc:creator>
 <dc:creator>Schuetz, Andy</dc:creator>
 <dc:creator>Stewart, Walter F.</dc:creator>
 <dc:creator>Sun, Jimeng</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Neural and Evolutionary Computing</dc:subject>
 <dc:description>  Objective: To transform heterogeneous clinical data from electronic health
records into clinically meaningful constructed features using data driven
method that rely, in part, on temporal relations among data. Materials and
Methods: The clinically meaningful representations of medical concepts and
patients are the key for health analytic applications. Most of existing
approaches directly construct features mapped to raw data (e.g., ICD or CPT
codes), or utilize some ontology mapping such as SNOMED codes. However, none of
the existing approaches leverage EHR data directly for learning such concept
representation. We propose a new way to represent heterogeneous medical
concepts (e.g., diagnoses, medications and procedures) based on co-occurrence
patterns in longitudinal electronic health records. The intuition behind the
method is to map medical concepts that are co-occuring closely in time to
similar concept vectors so that their distance will be small. We also derive a
simple method to construct patient vectors from the related medical concept
vectors. Results: For qualitative evaluation, we study similar medical concepts
across diagnosis, medication and procedure. In quantitative evaluation, our
proposed representation significantly improves the predictive modeling
performance for onset of heart failure (HF), where classification methods (e.g.
logistic regression, neural network, support vector machine and K-nearest
neighbors) achieve up to 23% improvement in area under the ROC curve (AUC)
using this proposed representation. Conclusion: We proposed an effective method
for patient and medical concept representation learning. The resulting
representation can map relevant concepts together and also improves predictive
modeling performance.
</dc:description>
 <dc:description>Comment: 45 pages</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-06-20</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03686</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03689</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Analytic Methods to Calculate Fault Trees with Loops - Restrictions of
  Application and Solution Uniqueness</dc:title>
 <dc:creator>Porotsky, Sergey</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  One of the important tasks of the Reliability Estimation is Analysis of the
Fault Tree. A problem of Fault Trees analysis is considered one of the most
complex ones, since structure of such trees is characterized by a considerable
number of interconnections. Usually analytical methods are used and most
applicable method is Minimal Cut Sets building and calculation. Classical Fault
Tree Analysis methods are applicable only for Fault Trees without loops. Loops
can appear in Fault Tree, when a TOP or some intermediate gates appear as input
to another gate at a lower level of the model. An occurrence of a Loop has been
a problematic issue in a Fault Tree calculation. The article relates to the
uniqueness of the solution for the Fault Trees with arbitrary Loops. There are
assumed, that failures of the Basic Events are non-repairable and Fault Tree
gates may be expressed by two main logic gates.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03689</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03699</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Adaptive TXOP Assignment for QoS Support of Video Traffic in IEEE
  802.11e Networks</dc:title>
 <dc:creator>Al-Maqri, Mohammed A.</dc:creator>
 <dc:creator>Othman, Mohamed</dc:creator>
 <dc:creator>Ali, Borhanuddin Mohd</dc:creator>
 <dc:creator>Hanapi, Zurina Mohd</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  Quality of Service (QoS) is provided in IEEE 802.11e protocol by means of HCF
Controlled Channel Access (HCCA) scheduler which is efficient for supporting
Constant Bit Rate (CBR) applications. Numerous researches have been carried out
to enhance the HCCA scheduler attempting to accommodate the needs of Variable
Bit Rate (VBR) video traffics which probably demonstrates a non-deterministic
profile during the time. This paper presents an adaptive TXOP assignment
mechanism for supporting the transmission of the prerecorded video traffics
over IEEE 802.11e wireless networks. The proposed mechanism uses a feedback
about the size of the subsequent video frames of the uplink traffic to assist
the Hybrid Coordinator (HC) accurately assign TXOP according to the fast
changes in the VBR profile. The simulation results show that our mechanism
reduces the delay experienced by VBR traffic streams comparable to HCCA
scheduler due to the accurate assignment of the TXOP which preserve the channel
time for data transmission.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03699</dc:identifier>
 <dc:identifier>doi:10.1109/RFM.2013.6757236</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03706</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>SDxVPN: A Software-Defined Solution for VPN Service Providers</dc:title>
 <dc:creator>Mirkhanzadeh, Behzad</dc:creator>
 <dc:creator>Taheri, Naeim</dc:creator>
 <dc:creator>Khorsandi, Siyavash</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:description>  BGP/MPLS IP VPN and VPLS services are considered to be widely used in IP/MPLS
networks for connecting customers' remote sites. However, service providers
struggle with many challenges to provide these services. Management complexity,
equipment costs, and last but not least, scalability issues emerging as the
customers increase in number, are just some of these problems. Software-defined
networking (SDN) is an emerging paradigm that can solve aforementioned issues
using a logically centralized controller for network devices. In this paper, we
propose a SDN-based solution called SDxVPN which considerably lowers the
complexity of VPN service definition and management. Our method eliminates
complex and costly device interactions that used to be done through several
control plane protocols and enables customers to determine their service
specifications, define restriction policies and even interconnect with other
customers automatically without operator's intervention. We describe our
prototype implementation of SDxVPN and its scalability evaluations under
several representative scenarios. The results indicate the effectiveness of the
proposed solution for deployment to provide large scale VPN services.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03706</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03713</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Distributed $(2+\epsilon)$-Approximation for Vertex Cover in
  $O(\log{\Delta}/\epsilon\log\log{\Delta})$ Rounds</dc:title>
 <dc:creator>Bar-Yehuda, Reuven</dc:creator>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Schwartzman, Gregory</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We present a simple deterministic distributed $(2+\epsilon)$-approximation
algorithm for minimum weight vertex cover, which completes in
$O(\log{\Delta}/\epsilon\log\log{\Delta})$ rounds, where $\Delta$ is the
maximum degree in the graph, for any $\epsilon&gt;0$ which is at most $O(1)$. For
a constant $\epsilon$, this implies a constant approximation in
$O(\log{\Delta}/\log\log{\Delta})$ rounds, which contradicts the lower bound of
[KMW10].
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03713</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03716</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Feasible HCCA Polling Mechanism for Video Transmission in IEEE 802.11e
  WLANs</dc:title>
 <dc:creator>Al-Maqri, Mohammed A.</dc:creator>
 <dc:creator>Othman, Mohamed</dc:creator>
 <dc:creator>Ali, Borhanuddin Mohd</dc:creator>
 <dc:creator>Hanapi, Zurina Mohd</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  IEEE 802.11e standard defines two Medium Access Control (MAC) functions to
support Quality of Service (QoS) for wireless local area networks: Enhanced
Distributed Channel Access (EDCA) and HCF Controlled Channel Access (HCCA).
EDCA provides fair prioritized QoS support while HCCA guarantees parameterized
QoS for the traffics with rigid QoS requirements. The latter shows higher QoS
provisioning with Constant Bit Rate (CBR) traffics. However, it does not
efficiently cope with the fluctuation of the Variable Bit Rate (VBR) video
streams since its reference scheduler generates a schedule based on the mean
characteristics of the traffic. Scheduling based on theses characteristics is
not always accurate as these tra_cs show high irregularity over the time. In
this paper, we propose an enhancement on the HCCA polling mechanism to address
the problem of scheduling pre-recorded VBR video streams. Our approach enhances
the polling mechanism by feed-backing the arrival time of the subsequent video
frame of the uplink traffic obtained through cross-layering approach.
Simulation experiments have been conducted on several publicly available video
traces in order to show the efficiency of our mechanism. The simulation results
reveal the efficiency of the proposed mechanism in providing less delay and
high throughput with conserving medium channel through minimizing the number of
Null-Frames caused by wasted polls
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03716</dc:identifier>
 <dc:identifier>doi:10.1007/s11277-015-2816-1</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03718</identifier>
 <datestamp>2016-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Distributed Algorithms for Testing Graph Properties</dc:title>
 <dc:creator>Censor-Hillel, Keren</dc:creator>
 <dc:creator>Fischer, Eldar</dc:creator>
 <dc:creator>Schwartzman, Gregory</dc:creator>
 <dc:creator>Vasudev, Yadu</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  We initiate a thorough study of \emph{distributed property testing} --
producing algorithms for the approximation problems of property testing in the
CONGEST model. In particular, for the so-called \emph{dense} testing model we
emulate sequential tests for nearly all graph properties having $1$-sided
tests, while in the \emph{sparse} and \emph{general} models we obtain faster
tests for triangle-freeness and bipartiteness respectively.
  In most cases, aided by parallelism, the distributed algorithms have a much
shorter running time as compared to their counterparts from the sequential
querying model of traditional property testing. The simplest property testing
algorithms allow a relatively smooth transitioning to the distributed model.
For the more complex tasks we develop new machinery that is of independent
interest. This includes a method for distributed maintenance of multiple random
walks.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-05-02</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03718</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03719</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Discovering novel ingredient pairings in molecular gastronomy using
  network analysis</dc:title>
 <dc:creator>Klju&#x10d;ev&#x161;ek, Aleksander</dc:creator>
 <dc:creator>Krapi&#x107;, Luka</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  Molecular gastronomy is a distinct sub-discipline of food science that takes
an active role in examining chemical and physical properties of ingredients and
as such lends itself to more scientific approaches to finding novel ingredient
pairings. With thousands of ingredients and molecules, which participate in the
creation of each ingredient's flavour, it can be difficult to find compatible
flavours in an efficient manner. Existing literature is focused mainly on
analysis of already established cuisine based on the flavour profile of its
ingredients, but fails to consider the potential in finding flavour
compatibility for use in creation of completely new recipes. Expressing
relationships between ingredients and their molecular structure as a bipartite
network opens up this problem to effective analysis with methods from network
science. We describe a series of experiments on a database of food using
network analysis, which produce a set of compatible ingredients that can be
used in creation of new recipes. We expect this approach and its results to
dramatically simplify the creation of new recipes with previously unseen and
fresh combinations of ingredients.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03719</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03722</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Sequences with small correlation</dc:title>
 <dc:creator>Schmidt, Kai-Uwe</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:description>  The extent to which a sequence of finite length differs from a shifted
version of itself is measured by its aperiodic autocorrelations. Of particular
interest are sequences whose entries are 1 or -1, called binary sequences, and
sequences whose entries are complex numbers of unit magnitude, called
unimodular sequences. Since the 1950s, there is sustained interest in sequences
with small aperiodic autocorrelations relative to the sequence length. One of
the main motivations is that a sequence with small aperiodic autocorrelations
is intrinsically suited for the separation of signals from noise, and therefore
has natural applications in digital communications. This survey reviews the
state of knowledge concerning the two central problems in this area: How small
can the aperiodic autocorrelations of a binary or a unimodular sequence
collectively be and how can we efficiently find the best such sequences? Since
the analysis and construction of sequences with small aperiodic
autocorrelations is closely tied to the (often much easier) analysis of
periodic autocorrelation properties, several fundamental results on
corresponding problems in the periodic setting are also reviewed.
</dc:description>
 <dc:description>Comment: Survey paper, 32 pages</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03722</dc:identifier>
 <dc:identifier>Des. Codes Cryptogr. 78(1), 237-267, 2016</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03725</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Versatile Scene Model with Differentiable Visibility Applied to
  Generative Pose Estimation</dc:title>
 <dc:creator>Rhodin, Helge</dc:creator>
 <dc:creator>Robertini, Nadia</dc:creator>
 <dc:creator>Richardt, Christian</dc:creator>
 <dc:creator>Seidel, Hans-Peter</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Generative reconstruction methods compute the 3D configuration (such as pose
and/or geometry) of a shape by optimizing the overlap of the projected 3D shape
model with images. Proper handling of occlusions is a big challenge, since the
visibility function that indicates if a surface point is seen from a camera can
often not be formulated in closed form, and is in general discrete and
non-differentiable at occlusion boundaries. We present a new scene
representation that enables an analytically differentiable closed-form
formulation of surface visibility. In contrast to previous methods, this yields
smooth, analytically differentiable, and efficient to optimize pose similarity
energies with rigorous occlusion handling, fewer local minima, and
experimentally verified improved convergence of numerical optimization. The
underlying idea is a new image formation model that represents opaque objects
by a translucent medium with a smooth Gaussian density distribution which turns
visibility into a smooth phenomenon. We demonstrate the advantages of our
versatile scene model in several generative pose estimation problems, namely
marker-less multi-object pose estimation, marker-less human motion capture with
few cameras, and image-based 3D geometry estimation.
</dc:description>
 <dc:description>Comment: 9 pages, In proceedings of ICCV 2015</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03725</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03729</identifier>
 <datestamp>2017-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A Language for the Declarative Composition of Concurrent Protocols</dc:title>
 <dc:creator>Cruz-Filipe, Lu&#xed;s</dc:creator>
 <dc:creator>Montesi, Fabrizio</dc:creator>
 <dc:subject>Computer Science - Programming Languages</dc:subject>
 <dc:description>  A recent study of bugs in real-world concurrent and distributed systems found
that, while implementations of individual protocols tend to be robust, the
composition of multiple protocols and its interplay with internal computation
is the culprit for most errors. Multiparty Session Types and Choreographic
Programming are methodologies for developing correct-by-construction concurrent
and distributed software, based on global descriptions of communication flows.
However, protocol composition is either limited or left unchecked. Inspired by
these two methodologies, in this work we present a new language model for the
safe composition of protocols, called Procedural Choreographies (PC). Protocols
in PC are procedures, parameterised on the processes that enact them.
Procedures define communications declaratively using global descriptions, and
programs are written by invoking and composing these procedures. An
implementation in terms of a process model is then mechanically synthesised,
guaranteeing correctness and deadlock-freedom. We study PC in the settings of
synchronous and asynchronous communications, and illustrate its expressivity
with some representative examples.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-10-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03729</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-60225-7_7</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03730</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HDBSCAN: Density based Clustering over Location Based Services</dc:title>
 <dc:creator>Rahman, Md Farhadur</dc:creator>
 <dc:creator>Liu, Weimo</dc:creator>
 <dc:creator>Suhaim, Saad Bin</dc:creator>
 <dc:creator>Thirumuruganathan, Saravanan</dc:creator>
 <dc:creator>Zhang, Nan</dc:creator>
 <dc:creator>Das, Gautam</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  Location Based Services (LBS) have become extremely popular and used by
millions of users. Popular LBS run the entire gamut from mapping services (such
as Google Maps) to restaurants (such as Yelp) and real-estate (such as Redfin).
The public query interfaces of LBS can be abstractly modeled as a kNN interface
over a database of two dimensional points: given an arbitrary query point, the
system returns the k points in the database that are nearest to the query
point. Often, k is set to a small value such as 20 or 50. In this paper, we
consider the novel problem of enabling density based clustering over an LBS
with only a limited, kNN query interface. Due to the query rate limits imposed
by LBS, even retrieving every tuple once is infeasible. Hence, we seek to
construct a cluster assignment function f(.) by issuing a small number of kNN
queries, such that for any given tuple t in the database which may or may not
have been accessed, f(.) outputs the cluster assignment of t with high
accuracy. We conduct a comprehensive set of experiments over benchmark datasets
and popular real-world LBS such as Yahoo! Flickr, Zillow, Redfin and Google
Maps.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-02-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03730</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03739</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Qualities and Inequalities in Online Social Networks through the Lens of
  the Generalized Friendship Paradox</dc:title>
 <dc:creator>Momeni, Naghmeh</dc:creator>
 <dc:creator>Rabbat, Michael</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  The friendship paradox is the phenomenon that in social networks, people on
average have fewer friends than their friends do. The generalized friendship
paradox is an extension to attributes other than the number of friends. The
friendship paradox and its generalized version have gathered recent attention
due to the information they provide about network structure and local
inequalities. In this paper, we propose several measures of nodal qualities
which capture different aspects of their activities and influence in online
social networks. Using these measures we analyse the prevalence of the
generalized friendship paradox over Twitter and we report high levels of
prevalence (up to over 90\% of nodes). We contend that this prevalence of the
friendship paradox and its generalized version arise because of the
hierarchical nature of the connections in the network. This hierarchy is nested
as opposed to being star-like. We conclude that these paradoxes are collective
phenomena not created merely by a minority of well-connected or high-attribute
nodes. Moreover, our results show that a large fraction of individuals can
experience the generalized friendship paradox even in the absence of a
significant correlation between degrees and attributes.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03739</dc:identifier>
 <dc:identifier>PLoS ONE 11(2): e0143633 (2016)</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0143633</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03742</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>HMM and DTW for evaluation of therapeutical gestures using kinect</dc:title>
 <dc:creator>Palma, Carlos</dc:creator>
 <dc:creator>Salazar, Augusto</dc:creator>
 <dc:creator>Vargas, Francisco</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Automatic recognition of the quality of movement in human beings is a
challenging task, given the difficulty both in defining the constraints that
make a movement correct, and the difficulty in using noisy data to determine if
these constraints were satisfied. This paper presents a method for the
detection of deviations from the correct form in movements from physical
therapy routines based on Hidden Markov Models, which is compared to Dynamic
Time Warping. The activities studied include upper an lower limbs movements,
the data used comes from a Kinect sensor. Correct repetitions of the activities
of interest were recorded, as well as deviations from these correct forms. The
ability of the proposed approach to detect these deviations was studied.
Results show that a system based on HMM is much more likely to determine if a
certain movement has deviated from the specification.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03742</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03746</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Finding overlapping communities in multiplex networks</dc:title>
 <dc:creator>Afsarmanesh, Nazanin</dc:creator>
 <dc:creator>Magnani, Matteo</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We define an approach to identify overlapping communities in multiplex
networks, extending the popular clique percolation method for simple graphs.
The extension requires to rethink the basic concepts on which the clique
percolation algorithm is based, including cliques and clique adjacency, to
allow the presence of multiple types of edges.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-03-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03746</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03755</identifier>
 <datestamp>2016-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Hitting Families of Schedules for Asynchronous Programs</dc:title>
 <dc:creator>Chistikov, Dmitry</dc:creator>
 <dc:creator>Majumdar, Rupak</dc:creator>
 <dc:creator>Niksic, Filip</dc:creator>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  We consider the following basic task in the testing of concurrent systems.
The input to the task is a partial order of events, which models actions
performed on or by the system and specifies ordering constraints between them.
The task is to determine if some scheduling of these events can result in a
bug. The number of schedules to be explored can, in general, be exponential.
  Empirically, many bugs in concurrent programs have been observed to have
small bug depth; that is, these bugs are exposed by every schedule that orders
$d$ specific events in a particular way, irrespective of how the other events
are ordered, and $d$ is small compared to the total number of events. To find
all bugs of depth $d$, one needs to only test a $d$-hitting family of
schedules: we call a set of schedules a $d$-hitting family if for each set of
$d$ events, and for each allowed ordering of these events, there is some
schedule in the family that executes these events in this ordering. The size of
a $d$-hitting family may be much smaller than the number of all possible
schedules, and a natural question is whether one can find $d$-hitting families
of schedules that have small size.
  In general, finding the size of optimal $d$-hitting families is hard, even
for $d=2$. We show, however, that when the partial order is a tree, one can
explicitly construct $d$-hitting families of schedules of small size. When the
tree is balanced, our constructions are polylogarithmic in the number of
events.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-07-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03755</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03757</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Human Machine Epistemology Survey</dc:title>
 <dc:creator>Nazin, R&#xe9;mi</dc:creator>
 <dc:creator>Fass, Didier</dc:creator>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Pluridisciplinar convergence is a major problem that had emerged with
Human-Artefact Systems and so-called &quot; Augmented Humanity &quot; as academical
fields and even more as technical fields. Problems come mainly from the
juxtaposition of two very different types of system, a biological one and an
artificial one. Thus, conceiving and designing the multiple couplings between
them has become a major difficulty. Some came with reductionnist solutions to
answer these problems but since we know that a biological system and a
technical system are different, this approach is limited from its beginning.
Using a specifically designed questionnaire and statistical analysis we
determined how specialists (medical practitioners, ergonomists and engineers)
in the domain conceive themselves what is a Human-Artifact System and how they
relate to existent traditions and showed that some of them relate to the
integrativist views.
</dc:description>
 <dc:date>2016-02-10</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03757</dc:identifier>
 <dc:identifier>Vincent G. Duffy. HCI Interantional 2016, Aug 2015, Los Angeles,
  United States. Springer, LNCS 9184, pp.12, 2015, Digital Human Modeling.
  Applications in Health, Safety, Ergonomics and Risk Management: Human
  Modeling</dc:identifier>
 <dc:identifier>doi:10.1007/978-3-319-21073-5_35</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03768</identifier>
 <datestamp>2016-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>MISO Networks with Imperfect CSIT: A Topological Rate-Splitting Approach</dc:title>
 <dc:creator>Hao, Chenxi</dc:creator>
 <dc:creator>Clerckx, Bruno</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  Recently, the Degrees-of-Freedom (DoF) region of multiple-input-single-output
(MISO) networks with imperfect channel state information at the transmitter
(CSIT) has attracted significant attentions. An achievable scheme is known as
rate-splitting (RS) that integrates common-message-multicasting and
private-message-unicasting. In this paper, focusing on the general $K$-cell
MISO IC where the CSIT of each interference link has an arbitrary quality of
imperfectness, we firstly identify the DoF region achieved by RS. Secondly, we
introduce a novel scheme, so called Topological RS (TRS), whose novelties
compared to RS lie in a multi-layer structure and transmitting multiple common
messages to be decoded by groups of users rather than all users. The design of
TRS is motivated by a novel interpretation of the $K$-cell IC with imperfect
CSIT as a weighted-sum of a series of partially connected networks. We show
that the DoF region achieved by TRS covers that achieved by RS. Also, we find
the maximal sum DoF achieved by TRS via hypergraph fractional packing, which
yields the best sum DoF so far. Lastly, for a realistic scenario where each
user is connected to three dominant transmitters, we identify the sufficient
condition where TRS strictly outperforms conventional schemes.
</dc:description>
 <dc:description>Comment: submitted for publication</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-03-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03768</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03770</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Integrative Dynamic Reconfiguration in a Parallel Stream Processing
  Engine</dc:title>
 <dc:creator>Madsen, Kasper Grud Skat</dc:creator>
 <dc:creator>Zhou, Yongluan</dc:creator>
 <dc:creator>Cao, Jianneng</dc:creator>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:description>  Load balancing, operator instance collocations and horizontal scaling are
critical issues in Parallel Stream Processing Engines to achieve low data
processing latency, optimized cluster utilization and minimized communication
cost respectively. In previous work, these issues are typically tackled
separately and independently. We argue that these problems are tightly coupled
in the sense that they all need to determine the allocations of workloads and
migrate computational states at runtime. Optimizing them independently would
result in suboptimal solutions. Therefore, in this paper, we investigate how
these three issues can be modeled as one integrated optimization problem. In
particular, we first consider jobs where workload allocations have little
effect on the communication cost, and model the problem of load balance as a
Mixed-Integer Linear Program. Afterwards, we present an extended solution
called ALBIC, which support general jobs. We implement the proposed techniques
on top of Apache Storm, an open-source Parallel Stream Processing Engine. The
extensive experimental results over both synthetic and real datasets show that
our techniques clearly outperform existing approaches.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03770</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03779</identifier>
 <datestamp>2017-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Network of Bandits insure Privacy of end-users</dc:title>
 <dc:creator>F&#xe9;raud, Rapha&#xeb;l</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Distributed, Parallel, and Cluster Computing</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In order to distribute the best arm identification task as close as possible
to the user's devices, on the edge of the Radio Access Network, we propose a
new problem setting, where distributed players collaborate to find the best
arm. This architecture guarantees privacy to end-users since no events are
stored. The only thing that can be observed by an adversary through the core
network is aggregated information across users. We provide a first algorithm,
Distributed Median Elimination, which is optimal in term of number of
transmitted bits and near optimal in term of speed-up factor with respect to an
optimal algorithm run independently on each player. In practice, this first
algorithm cannot handle the trade-off between the communication cost and the
speed-up factor, and requires some knowledge about the distribution of players.
Extended Distributed Median Elimination overcomes these limitations, by playing
in parallel different instances of Distributed Median Elimination and selecting
the best one. Experiments illustrate and complete the analysis. According to
the analysis, in comparison to Median Elimination performed on each player, the
proposed algorithm shows significant practical improvements.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-03-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03779</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03780</identifier>
 <datestamp>2017-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Interplay between Social Influence and Network Centrality: A Comparative
  Study on Shapley Centrality and Single-Node-Influence Centrality</dc:title>
 <dc:creator>Chen, Wei</dc:creator>
 <dc:creator>Teng, Shang-Hua</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Physics - Physics and Society</dc:subject>
 <dc:description>  We study network centrality based on dynamic influence propagation models in
social networks. To illustrate our integrated mathematical-algorithmic approach
for understanding the fundamental interplay between dynamic influence processes
and static network structures, we focus on two basic centrality measures: (a)
Single Node Influence (SNI) centrality, which measures each node's significance
by its influence spread; and (b) Shapley Centrality, which uses the Shapley
value of the influence spread function --- formulated based on a fundamental
cooperative-game-theoretical concept --- to measure the significance of nodes.
We present a comprehensive comparative study of these two centrality measures.
Mathematically, we present axiomatic characterizations, which precisely capture
the essence of these two centrality measures and their fundamental differences.
Algorithmically, we provide scalable algorithms for approximating them for a
large family of social-influence instances. Empirically, we demonstrate their
similarity and differences in a number of real-world social networks, as well
as the efficiency of our scalable algorithms. Our results shed light on their
applicability: SNI centrality is suitable for assessing individual influence in
isolation while Shapley centrality assesses individuals' performance in group
influence settings.
</dc:description>
 <dc:description>Comment: The 10-page extended abstract version appears in WWW'2017</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-03-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03780</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03796</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On Repetitive Scenario Design</dc:title>
 <dc:creator>Calafiore, Giuseppe C.</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  Repetitive Scenario Design (RSD) is a randomized approach to robust design
based on iterating two phases: a standard scenario design phase that uses $N$
scenarios (design samples), followed by randomized feasibility phase that uses
$N_o$ test samples on the scenario solution. We give a full and exact
probabilistic characterization of the number of iterations required by the RSD
approach for returning a solution, as a function of $N$, $N_o$, and of the
desired levels of probabilistic robustness in the solution. This novel approach
broadens the applicability of the scenario technology, since the user is now
presented with a clear tradeoff between the number $N$ of design samples and
the ensuing expected number of repetitions required by the RSD algorithm. The
plain (one-shot) scenario design becomes just one of the possibilities, sitting
at one extreme of the tradeoff curve, in which one insists in finding a
solution in a single repetition: this comes at the cost of possibly high $N$.
Other possibilities along the tradeoff curve use lower $N$ values, but possibly
require more than one repetition.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03796</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03805</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Local High-order Regularization on Data Manifolds</dc:title>
 <dc:creator>Kim, Kwang In</dc:creator>
 <dc:creator>Tompkin, James</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  The common graph Laplacian regularizer is well-established in semi-supervised
learning and spectral dimensionality reduction. However, as a first-order
regularizer, it can lead to degenerate functions in high-dimensional manifolds.
The iterated graph Laplacian enables high-order regularization, but it has a
high computational complexity and so cannot be applied to large problems. We
introduce a new regularizer which is globally high order and so does not suffer
from the degeneracy of the graph Laplacian regularizer, but is also sparse for
efficient computation in semi-supervised learning applications. We reduce
computational complexity by building a local first-order approximation of the
manifold as a surrogate geometry, and construct our high-order regularizer
based on local derivative evaluations therein. Experiments on human body shape
and pose analysis demonstrate the effectiveness and efficiency of our method.
</dc:description>
 <dc:description>Comment: Accepted version of paper published at CVPR 2015,
  http://dx.doi.org/10.1109/CVPR.2015.7299186</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03805</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7299186</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03808</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Semi-supervised Learning with Explicit Relationship Regularization</dc:title>
 <dc:creator>Kim, Kwang In</dc:creator>
 <dc:creator>Tompkin, James</dc:creator>
 <dc:creator>Pfister, Hanspeter</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  In many learning tasks, the structure of the target space of a function holds
rich information about the relationships between evaluations of functions on
different data points. Existing approaches attempt to exploit this relationship
information implicitly by enforcing smoothness on function evaluations only.
However, what happens if we explicitly regularize the relationships between
function evaluations? Inspired by homophily, we regularize based on a smooth
relationship function, either defined from the data or with labels. In
experiments, we demonstrate that this significantly improves the performance of
state-of-the-art algorithms in semi-supervised classification and in spectral
data embedding for constrained clustering and dimensionality reduction.
</dc:description>
 <dc:description>Comment: Accepted version of paper published at CVPR 2015,
  http://dx.doi.org/10.1109/CVPR.2015.7298831</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03808</dc:identifier>
 <dc:identifier>doi:10.1109/CVPR.2015.7298831</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03814</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Enabling Basic Normative HRI in a Cognitive Robotic Architecture</dc:title>
 <dc:creator>Sarathy, Vasanth</dc:creator>
 <dc:creator>Wilson, Jason R.</dc:creator>
 <dc:creator>Arnold, Thomas</dc:creator>
 <dc:creator>Scheutz, Matthias</dc:creator>
 <dc:subject>Computer Science - Robotics</dc:subject>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  Collaborative human activities are grounded in social and moral norms, which
humans consciously and subconsciously use to guide and constrain their
decision-making and behavior, thereby strengthening their interactions and
preventing emotional and physical harm. This type of norm-based processing is
also critical for robots in many human-robot interaction scenarios (e.g., when
helping elderly and disabled persons in assisted living facilities, or
assisting humans in assembly tasks in factories or even the space station). In
this position paper, we will briefly describe how several components in an
integrated cognitive architecture can be used to implement processes that are
required for normative human-robot interactions, especially in collaborative
tasks where actions and situations could potentially be perceived as
threatening and thus need a change in course of action to mitigate the
perceived threats.
</dc:description>
 <dc:description>Comment: Presented at &quot;2nd Workshop on Cognitive Architectures for Social
  Human-Robot Interaction 2016 (arXiv:1602.01868)&quot;</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03814</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03819</identifier>
 <datestamp>2016-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Query By Provenance</dc:title>
 <dc:creator>Deutch, Daniel</dc:creator>
 <dc:creator>Gilad, Amir</dc:creator>
 <dc:subject>Computer Science - Databases</dc:subject>
 <dc:description>  To assist non-specialists in formulating database queries, multiple
frameworks that automatically infer queries from a set of examples have been
proposed. While highly useful, a shortcoming of the approach is that if users
can only provide a small set of examples, many inherently different queries may
qualify, and only some of these actually match the user intentions. Our main
observation is that if users further explain their examples, the set of
qualifying queries may be significantly more focused. We develop a novel
framework where users explain example tuples by choosing input tuples that are
intuitively the &quot;cause&quot; for their examples. Their explanations are
automatically &quot;compiled&quot; into a formal model for explanations, based on
previously developed models of data provenance. Then, our novel algorithms
infer conjunctive queries from the examples and their explanations. We prove
the computational efficiency of the algorithms and favorable properties of
inferred queries. We have further implemented our solution in a system
prototype with an interface that assists users in formulating explanations in
an intuitive way. Our experimental results, including a user study as well as
experiments using the TPC-H benchmark, indicate the effectiveness of our
solution.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-05-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03819</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03822</identifier>
 <datestamp>2016-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Neural Network Support Vector Detection via a Soft-Label, Hybrid K-Means
  Classifier</dc:title>
 <dc:creator>Murphy, Robert A.</dc:creator>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>60D05, 62C99</dc:subject>
 <dc:description>  We use random geometric graphs to describe clusters of higher dimensional
data points which are bijectively mapped to a (possibly) lower dimensional
space where an equivalent random cluster model is used to calculate the
expected number of modes to be found when separating the data of a multi-modal
data set into distinct clusters. Furthermore, as a function of the expected
number of modes and the number of data points in the sample, an upper bound on
a given distance measure is found such that data points have the greatest
correlation if their mutual distances from a common center is less than or
equal to the calculated bound. Anomalies are exposed, which lie outside of the
union of all regularized clusters of data points.
  Similar to finding a hyperplane which can be shifted along its normal to
expose the maximal distance between binary classes, it is shown that the union
of regularized clusters can be used to define a hyperplane which can be shifted
by a certain amount to separate the data into binary classes and that the
shifted hyperplane defines the activation function for a two-class
discriminating neural network. Lastly, this neural network is used to detect
the set of support vectors which determines the maximally-separating region
between the binary classes.
</dc:description>
 <dc:description>Comment: This paper is a combined replacement for the papers &quot;A Neural Network
  Anomaly Detector using the Random Cluster Model&quot; (arXiv:1501.07227), &quot;On the
  Sharp Threshold Interval Length of Partially Connected Random Geometric
  Graphs During K-Means Classification&quot; (arXiv:1412.4178) and &quot;Estimating the
  Mean Number of K-Means Clusters to Form&quot; (arXiv:1503.03488), which have all
  been withdrawn</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-04-18</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03822</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03828</identifier>
 <datestamp>2016-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Community Recovery in Graphs with Locality</dc:title>
 <dc:creator>Chen, Yuxin</dc:creator>
 <dc:creator>Kamath, Govinda</dc:creator>
 <dc:creator>Suh, Changho</dc:creator>
 <dc:creator>Tse, David</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:subject>Quantitative Biology - Genomics</dc:subject>
 <dc:description>  Motivated by applications in domains such as social networks and
computational biology, we study the problem of community recovery in graphs
with locality. In this problem, pairwise noisy measurements of whether two
nodes are in the same community or different communities come mainly or
exclusively from nearby nodes rather than uniformly sampled between all nodes
pairs, as in most existing models. We present an algorithm that runs nearly
linearly in the number of measurements and which achieves the information
theoretic limit for exact recovery.
</dc:description>
 <dc:description>Comment: accepted in part to International Conference on Machine Learning
  (ICML), 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-06-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03828</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03834</identifier>
 <datestamp>2016-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Climate Change Research in View of Bibliometrics</dc:title>
 <dc:creator>Haunschild, Robin</dc:creator>
 <dc:creator>Bornmann, Lutz</dc:creator>
 <dc:creator>Marx, Werner</dc:creator>
 <dc:subject>Computer Science - Digital Libraries</dc:subject>
 <dc:description>  This bibliometric study of a large publication set dealing with research on
climate change aims at mapping the relevant literature from a bibliometric
perspective and presents a multitude of quantitative data: (1) The growth of
the overall publication output as well as (2) of some major subfields, (3) the
contributing journals and countries as well as their citation impact, and (4) a
title word analysis aiming to illustrate the time evolution and relative
importance of specific research topics. The study is based on 222,060 papers
published between 1980 and 2014. The total number of papers shows a strong
increase with a doubling every 5-6 years. Continental biomass related research
is the major subfield, closely followed by climate modeling. Research dealing
with adaptation, mitigation, risks, and vulnerability of global warming is
comparatively small, but their share of papers increased exponentially since
2005. Research on vulnerability and on adaptation published the largest
proportion of very important papers. Research on climate change is
quantitatively dominated by the USA, followed by the UK, Germany, and Canada.
The citation-based indicators exhibit consistently that the UK has produced the
largest proportion of high impact papers compared to the other countries
(having published more than 10,000 papers). The title word analysis shows that
the term climate change comes forward with time. Furthermore, the term impact
arises and points to research dealing with the various effects of climate
change. Finally, the term model and related terms prominently appear
independent of time, indicating the high relevance of climate modeling.
</dc:description>
 <dc:description>Comment: 40 pages, 6 figures, and 4 tables</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-07-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03834</dc:identifier>
 <dc:identifier>PLoS ONE 11(7): e0160393, 2016</dc:identifier>
 <dc:identifier>doi:10.1371/journal.pone.0160393</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03854</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Estimating the unconfined compressive strength of carbonate rocks using
  gene expression programming</dc:title>
 <dc:creator>Dindarloo, Saeid R.</dc:creator>
 <dc:creator>Siami-Irdemoosa, Elnaz</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  Conventionally, many researchers have used both regression and black box
techniques to estimate the unconfined compressive strength (UCS) of different
rocks. The advantage of the regression approach is that it can be used to
render a functional relationship between the predictive rock indices and its
UCS. The advantage of the black box techniques is in rendering more accurate
predictions. Gene expression programming (GEP) is proposed, in this study, as a
robust mathematical alternative for predicting the UCS of carbonate rocks. The
two parameters of total porosity and P-wave speed were selected as predictive
indices. The proposed GEP model had the advantage of the both traditionally
used approaches by proposing a mathematical model, similar to a regression,
while keeping the prediction errors as low as the black box methods. The GEP
outperformed both artificial neural networks and support vector machines in
terms of yielding more accurate estimates of UCS. Both the porosity and the
P-wave velocity were sufficient predictive indices for estimating the UCS of
the carbonate rocks in this study. Nearly, 95% of the observed variation in the
UCS values was explained by these two parameters (i.e., R2 =95%).
</dc:description>
 <dc:date>2016-01-25</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03854</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03860</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Real-Time Hand Tracking Using a Sum of Anisotropic Gaussians Model</dc:title>
 <dc:creator>Sridhar, Srinath</dc:creator>
 <dc:creator>Rhodin, Helge</dc:creator>
 <dc:creator>Seidel, Hans-Peter</dc:creator>
 <dc:creator>Oulasvirta, Antti</dc:creator>
 <dc:creator>Theobalt, Christian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Real-time marker-less hand tracking is of increasing importance in
human-computer interaction. Robust and accurate tracking of arbitrary hand
motion is a challenging problem due to the many degrees of freedom, frequent
self-occlusions, fast motions, and uniform skin color. In this paper, we
propose a new approach that tracks the full skeleton motion of the hand from
multiple RGB cameras in real-time. The main contributions include a new
generative tracking method which employs an implicit hand shape representation
based on Sum of Anisotropic Gaussians (SAG), and a pose fitting energy that is
smooth and analytically differentiable making fast gradient based pose
optimization possible. This shape representation, together with a full
perspective projection model, enables more accurate hand modeling than a
related baseline method from literature. Our method achieves better accuracy
than previous methods and runs at 25 fps. We show these improvements both
qualitatively and quantitatively on publicly available datasets.
</dc:description>
 <dc:description>Comment: 8 pages, Accepted version of paper published at 3DV 2014</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03860</dc:identifier>
 <dc:identifier>2nd International Conference on , vol.1, no., pp.319-326, 8-11
  Dec. 2014</dc:identifier>
 <dc:identifier>doi:10.1109/3DV.2014.37</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03865</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Higher signature Delaunay decompositions</dc:title>
 <dc:creator>Danciger, Jeffrey</dc:creator>
 <dc:creator>Maloni, Sara</dc:creator>
 <dc:creator>Schlenker, Jean-Marc</dc:creator>
 <dc:subject>Computer Science - Computational Geometry</dc:subject>
 <dc:subject>Computer Science - Discrete Mathematics</dc:subject>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:description>  A Delaunay decomposition is a cell decomposition in R^d for which each cell
is inscribed in a Euclidean ball which is empty of all other vertices. This
article introduces a generalization of the Delaunay decomposition in which the
Euclidean balls in the empty ball condition are replaced by other families of
regions bounded by certain quadratic hypersurfaces. This generalized notion is
adaptable to geometric contexts in which the natural space from which the point
set is sampled is not Euclidean, but rather some other flat semi-Riemannian
geometry, possibly with degenerate directions. We prove the existence and
uniqueness of the decomposition and discuss some of its basic properties. In
the case of dimension d = 2, we study the extent to which some of the
well-known optimality properties of the Euclidean Delaunay triangulation
generalize to the higher signature setting. In particular, we describe a higher
signature generalization of a well-known description of Delaunay decompositions
in terms of the intersection angles between the circumscribed circles.
</dc:description>
 <dc:description>Comment: 25 pages, 6 figures</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03865</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03881</identifier>
 <datestamp>2016-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parallel Shortest-Paths Using Radius Stepping</dc:title>
 <dc:creator>Blelloch, Guy E.</dc:creator>
 <dc:creator>Gu, Yan</dc:creator>
 <dc:creator>Sun, Yihan</dc:creator>
 <dc:creator>Tangwongsan, Kanat</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  The single-source shortest path problem (SSSP) with nonnegative edge weights
is a notoriously difficult problem to solve efficiently in parallel---it is one
of the graph problems said to suffer from the transitive-closure bottleneck. In
practice, the $\Delta$-stepping algorithm of Meyer and Sanders (J. Algorithms,
2003) often works efficiently but has no known theoretical bounds on general
graphs. The algorithm takes a sequence of steps, each increasing the radius by
a user-specified value $\Delta$. Each step settles the vertices in its annulus
but can take $\Theta(n)$ substeps, each requiring $\Theta(m)$ work ($n$
vertices and $m$ edges).
  In this paper, we describe Radius-Stepping, an algorithm with the best-known
tradeoff between work and depth bounds for SSSP with nearly-linear
($\otilde(m)$) work. The algorithm is a $\Delta$-stepping-like algorithm but
uses a variable instead of fixed-size increase in radii, allowing us to prove a
bound on the number of steps. In particular, by using what we define as a
vertex $k$-radius, each step takes at most $k+2$ substeps. Furthermore, we
define a $(k, \rho)$-graph property and show that if an undirected graph has
this property, then the number of steps can be bounded by $O(\frac{n}{\rho}
\log \rho L)$, for a total of $O(\frac{kn}{\rho} \log \rho L)$ substeps, each
parallel. We describe how to preprocess a graph to have this property.
Altogether, Radius-Stepping takes $O((m+n\log n)\log \frac{n}{\rho})$ work and
$O(\frac{n}{\rho}\log n \log (\rho{}L))$ depth per source after preprocessing.
The preprocessing step can be done in $O(m\log n + n\rho^2)$ work and
$O(\rho^2)$ depth or in $O(m\log n + n\rho^2\log n)$ work and $O(\rho\log
\rho)$ depth, and adds no more than $O(n\rho)$ edges.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-03-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03881</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03885</identifier>
 <datestamp>2016-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Accountability in Dynamic Networks</dc:title>
 <dc:creator>Vila&#xe7;a, Xavier</dc:creator>
 <dc:creator>Rodrigues, Lu&#xed;s</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  We take a game theoretical approach to determine necessary and sufficient
conditions under which we can persuade rational agents to exchange messages in
pairwise exchanges over links of a dynamic network, by holding them accountable
for deviations with punishments. We make three contributions: (1) we provide a
new game theoretical model of repeated interactions in dynamic networks, where
agents have incomplete information of the topology, (2) we define a new
solution concept for this model, and (3) we identify necessary and sufficient
conditions for enforcing accountability, i.e., for persuading agents to
exchange messages in the aforementioned model.
  Our results are of technical interest but also of practical relevance. We
show that we cannot enforce accountability if the dynamic network does not
allow for \emph{timely punishments}. In practice, this means for instance that
we cannot enforce accountability in some networks formed in file-sharing
applications such as Bittorrent\,\cite{Cohen:03}. We also show that for
applications such as secret exchange, where the benefits of the exchanges
significantly surpass the communication costs, timely punishments are enough to
enforce accountability. However, we cannot in general enforce accountability if
agents do not possess enough information about the network topology.
Nevertheless, we can enforce accountability in a wide variety of networks that
satisfy 1-connectivity\,\cite{Kuhn:10} with minimal knowledge about the network
topology, including overlays for gossip dissemination such as
\cite{Li:06,Li:08}.
</dc:description>
 <dc:description>Comment: 32 pages, 3 figures, 7 main theorems, 1 algorithm, to be submitted to
  a conference; improved presentation; added generalisation to non-bounded
  protocols</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-05-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03885</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03886</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Providing Dynamic TXOP for QoS Support of Video Transmission in IEEE
  802.11e WLANs</dc:title>
 <dc:creator>Al-Maqri, Mohammed A.</dc:creator>
 <dc:creator>Othman, Mohamed</dc:creator>
 <dc:creator>Ali, Borhanuddin Mohd</dc:creator>
 <dc:creator>Hanapi, Zurina Mohd</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Multimedia</dc:subject>
 <dc:description>  The IEEE 802.11e standard introduced by IEEE 802.11 Task Group E (TGe)
enhances the Quality of Service (QoS) by means of HCF Controlled Channel Access
(HCCA). The scheduler of HCCA allocates Transmission Opportunities (TXOPs) to
QoS-enabled Station (QSTA) based on their TS Specifications (TSPECs) negotiated
at the traffic setup time so that it is only efficient for Constant Bit Rate
(CBR) applications. However, Variable Bit Rate (VBR) traffics are not
efficiently supported as they exhibit nondeterministic profile during the time.
In this paper, we present a dynamic TXOP assignment Scheduling Algorithm for
supporting the video traffics transmission over IEEE 802.11e wireless networks.
This algorithm uses a piggybacked information about the size of the subsequent
video frames of the uplink traffic to assist the Hybrid Coordinator accurately
assign the TXOP according to the fast changes in the VBR profile. The proposed
scheduling algorithm has been evaluated using simulation with different
variability level video streams. The simulation results show that the proposed
algorithm reduces the delay experienced by VBR traffic streams comparable to
HCCA scheduler due to the accurate assignment of the TXOP which preserve the
channel time for transmission.
</dc:description>
 <dc:description>Comment: arXiv admin note: substantial text overlap with arXiv:1602.03699</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03886</dc:identifier>
 <dc:identifier>doi:10.4304/jnw.10.9.501-511</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03903</identifier>
 <datestamp>2016-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Wavelet-Based Semantic Features for Hyperspectral Signature
  Discrimination</dc:title>
 <dc:creator>Feng, Siwei</dc:creator>
 <dc:creator>Itoh, Yuki</dc:creator>
 <dc:creator>Parente, Mario</dc:creator>
 <dc:creator>Duarte, Marco F.</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  Hyperspectral signature classification is a quantitative analysis approach
for hyperspectral imagery which performs detection and classification of the
constituent materials at the pixel level in the scene. The classification
procedure can be operated directly on hyperspectral data or performed by using
some features extracted from the corresponding hyperspectral signatures
containing information like the signature's energy or shape. In this paper, we
describe a technique that applies non-homogeneous hidden Markov chain (NHMC)
models to hyperspectral signature classification. The basic idea is to use
statistical models (such as NHMC) to characterize wavelet coefficients which
capture the spectrum semantics (i.e., structural information) at multiple
levels. Experimental results show that the approach based on NHMC models can
outperform existing approaches relevant in classification tasks.
</dc:description>
 <dc:description>Comment: 21 pages, 8 figures, 4 tables, preprint, revised April 8 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-04-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03903</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03906</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>How to group wireless nodes together?</dc:title>
 <dc:creator>Giovanidis, Anastasios</dc:creator>
 <dc:subject>Computer Science - Networking and Internet Architecture</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  This report presents a survey on how to group together in a static way planar
nodes, that may belong to a wireless network (ad hoc or cellular). The aim is
to identify appropriate methods that could also be applied for Point Processes.
Specifically matching pairs and algorithms are initially discussed. Next,
specifically for Point Processes, the Nearest Neighbour and Lilypond models are
presented. Properties and results for the two models are stated. Original
bounds are given for the value of the so-called generation number, which is
related to the size of the nearest neighbour cluster. Finally, a variation of
the nearest neighbour grouping is proposed and an original metric is
introduced, named here the ancestor number. This is used to facilitate the
analysis of the distribution of cluster size. Based on this certain related
bounds are derived. The report and the analysis included show clearly the
difficulty of working in point processes with static clusters of size greater
than two, when these are defined by proximity criteria.
</dc:description>
 <dc:description>Comment: 35 pages, 14 figures, 3 tables, Report</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03906</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03924</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modeling Human Ad Hoc Coordination</dc:title>
 <dc:creator>Krafft, Peter M.</dc:creator>
 <dc:creator>Baker, Chris L.</dc:creator>
 <dc:creator>Pentland, Alex</dc:creator>
 <dc:creator>Tenenbaum, Joshua B.</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:subject>Computer Science - Multiagent Systems</dc:subject>
 <dc:subject>I.2.0</dc:subject>
 <dc:subject>I.2.11</dc:subject>
 <dc:subject>J.4</dc:subject>
 <dc:description>  Whether in groups of humans or groups of computer agents, collaboration is
most effective between individuals who have the ability to coordinate on a
joint strategy for collective action. However, in general a rational actor will
only intend to coordinate if that actor believes the other group members have
the same intention. This circular dependence makes rational coordination
difficult in uncertain environments if communication between actors is
unreliable and no prior agreements have been made. An important normative
question with regard to coordination in these ad hoc settings is therefore how
one can come to believe that other actors will coordinate, and with regard to
systems involving humans, an important empirical question is how humans arrive
at these expectations. We introduce an exact algorithm for computing the
infinitely recursive hierarchy of graded beliefs required for rational
coordination in uncertain environments, and we introduce a novel mechanism for
multiagent coordination that uses it. Our algorithm is valid in any environment
with a finite state space, and extensions to certain countably infinite state
spaces are likely possible. We test our mechanism for multiagent coordination
as a model for human decisions in a simple coordination game using existing
experimental data. We then explore via simulations whether modeling humans in
this way may improve human-agent collaboration.
</dc:description>
 <dc:description>Comment: AAAI 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03924</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03926</identifier>
 <datestamp>2016-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Modelling the level of adoption of analytical tools; An implementation
  of multi-criteria evidential reasoning</dc:title>
 <dc:creator>Barahona, Igor</dc:creator>
 <dc:creator>Cavazos, Judith</dc:creator>
 <dc:creator>Yang, Jian-Bo</dc:creator>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Statistics - Other Statistics</dc:subject>
 <dc:description>  In the future, competitive advantages will be given to organisations that can
extract valuable information from massive data and make better decisions. In
most cases, this data comes from multiple sources. Therefore, the challenge is
to aggregate them into a common framework in order to make them meaningful and
useful. This paper will first review the most important multi-criteria decision
analysis methods (MCDA) existing in current literature. We will offer a novel,
practical and consistent methodology based on a type of MCDA, to aggregate data
from two different sources into a common framework. Two datasets that are
different in nature but related to the same topic are aggregated to a common
scale by implementing a set of transformation rules. This allows us to generate
appropriate evidence for assessing and finally prioritising the level of
adoption of analytical tools in four types of companies. A numerical example is
provided to clarify the form for implementing this methodology. A six-step
process is offered as a guideline to assist engineers, researchers or
practitioners interested in replicating this methodology in any situation where
there is a need to aggregate and transform multiple source data.
</dc:description>
 <dc:description>Comment: Keywords: MCDA methods; evidential reasoning; analytical tools;
  multiple source data</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03926</dc:identifier>
 <dc:identifier>International Journal of Supply and Operations Management. (2014)
  Vol.1, Issue 2, pp 129-151</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03929</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Designing a Mobile Game for Home Computer Users to Protect Against
  Phishing Attacks</dc:title>
 <dc:creator>Arachchilage, Nalin Asanka Gamagedara</dc:creator>
 <dc:creator>Cole, Melissa</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  This research aims to design an educational mobile game for home computer
users to prevent from phishing attacks. Phishing is an online identity theft
which aims to steal sensitive information such as username, password and online
banking details from victims. To prevent this, phishing education needs to be
considered. Mobile games could facilitate to embed learning in a natural
environment. The paper introduces a mobile game design based on a story which
is simplifying and exaggerating real life. We use a theoretical model derived
from Technology Threat Avoidance Theory (TTAT) to address the game design
issues and game design principles were used as a set of guidelines for
structuring and presenting information. The overall mobile game design was
aimed to enhance avoidance behaviour through motivation of home computer users
to protect against phishing threats. The prototype game design is presented on
Google App Inventor Emulator. We believe by training home computer users to
protect against phishing attacks, would be an aid to enable the cyberspace as a
secure environment.
</dc:description>
 <dc:description>Comment: 8 in International Journal for e-Learning Security (IJeLS), Volume 1,
  Issue 1/2, March/June 2011. arXiv admin note: substantial text overlap with
  arXiv:1511.07093</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03929</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03930</identifier>
 <datestamp>2016-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Global Deconvolutional Networks for Semantic Segmentation</dc:title>
 <dc:creator>Nekrasov, Vladimir</dc:creator>
 <dc:creator>Ju, Janghoon</dc:creator>
 <dc:creator>Choi, Jaesik</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Semantic image segmentation is a principal problem in computer vision, where
the aim is to correctly classify each individual pixel of an image into a
semantic label. Its widespread use in many areas, including medical imaging and
autonomous driving, has fostered extensive research in recent years. Empirical
improvements in tackling this task have primarily been motivated by successful
exploitation of Convolutional Neural Networks (CNNs) pre-trained for image
classification and object recognition. However, the pixel-wise labelling with
CNNs has its own unique challenges: (1) an accurate deconvolution, or
upsampling, of low-resolution output into a higher-resolution segmentation mask
and (2) an inclusion of global information, or context, within locally
extracted features. To address these issues, we propose a novel architecture to
conduct the equivalent of the deconvolution operation globally and acquire
dense predictions. We demonstrate that it leads to improved performance of
state-of-the-art semantic segmentation models on the PASCAL VOC 2012 benchmark,
reaching 74.0% mean IU accuracy on the test set.
</dc:description>
 <dc:description>Comment: BMVC 2016 Conference</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-08-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03930</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03934</identifier>
 <datestamp>2016-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bouncing Towers move faster than Hanoi Towers, but still require
  exponential time</dc:title>
 <dc:creator>Barbay, J&#xe9;r&#xe9;my</dc:creator>
 <dc:subject>Computer Science - General Literature</dc:subject>
 <dc:description>  The problem of the Hanoi Tower is a classic exercise in recursive
programming: the solution has a simple recursive definition, and its complexity
and the matching lower bound are the solution of a simple recursive function
(the solution is so easy that most students memorize it and regurgitate it at
exams without truly understanding it). We describe how some very minor changes
in the rules of the Hanoi Tower yield various increases of complexity in the
solution, so that they require a deeper analysis than the classical Hanoi Tower
problem while still yielding exponential solutions. In particular, we analyze
the problem fo the Bouncing Tower, where just changing the insertion and
extraction position from the top to the middle of the tower results in a
surprising increase of complexity in the solution: such a tower of $n$ disks
can be optimally moved in $\sqrt{3}^n$ moves for $n$ even (i.e. less than a
Hanoi Tower of same height), via $5$ recursive functions (or, equivalently, one
recursion function with $5$ states).
</dc:description>
 <dc:description>Comment: 18 pages and many figures, one appendix with the disk pile problem,
  code in Python</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-03-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03934</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03935</identifier>
 <datestamp>2016-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Face Attribute Prediction Using Off-the-Shelf CNN Features</dc:title>
 <dc:creator>Zhong, Yang</dc:creator>
 <dc:creator>Sullivan, Josephine</dc:creator>
 <dc:creator>Li, Haibo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Predicting attributes from face images in the wild is a challenging computer
vision problem. To automatically describe face attributes from face containing
images, traditionally one needs to cascade three technical blocks --- face
localization, facial descriptor construction, and attribute classification ---
in a pipeline. As a typical classification problem, face attribute prediction
has been addressed using deep learning. Current state-of-the-art performance
was achieved by using two cascaded Convolutional Neural Networks (CNNs), which
were specifically trained to learn face localization and attribute description.
In this paper, we experiment with an alternative way of employing the power of
deep representations from CNNs. Combining with conventional face localization
techniques, we use off-the-shelf architectures trained for face recognition to
build facial descriptors. Recognizing that the describable face attributes are
diverse, our face descriptors are constructed from different levels of the CNNs
for different attributes to best facilitate face attribute prediction.
Experiments on two large datasets, LFWA and CelebA, show that our approach is
entirely comparable to the state-of-the-art. Our findings not only demonstrate
an efficient face attribute prediction approach, but also raise an important
question: how to leverage the power of off-the-shelf CNN representations for
novel tasks.
</dc:description>
 <dc:description>Comment: In proceeding of 2016 International Conference on Biometrics (ICB)</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-06-21</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03935</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03936</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Study of Interference Cancellation and Relay Selection Algorithms Using
  Greedy Techniques for Cooperative DS-CDMA Systems</dc:title>
 <dc:creator>Gu, J.</dc:creator>
 <dc:creator>de Lamare, R. C.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this work, we study interference cancellation techniques and a multi-relay
selection algorithm based on greedy methods for the uplink of cooperative
direct-sequence code-division multiple access (DS-CDMA) systems. We first
devise low-cost list-based successive interference cancellation (GL-SIC) and
parallel interference cancellation (GL-PIC) algorithms with RAKE receivers as
the front-end that can approach the maximum likelihood detector performance and
be used at both the relays and the destination of cooperative systems. Unlike
prior art, the proposed GL-SIC and GL-PIC algorithms exploit the Euclidean
distance between users of interest and the potential nearest constellation
point with a chosen threshold in order to build an effective list of detection
candidates. A low-complexity multi-relay selection algorithm based on greedy
techniques that can approach the performance of an exhaustive search is also
proposed. A cross-layer design strategy that brings together the proposed
multiuser detection algorithms and the greedy relay selection is then developed
along with an analysis of the proposed techniques. Simulations show an
excellent bit error rate performance of the proposed detection and relay
selection algorithms as compared to existing techniques.
</dc:description>
 <dc:description>Comment: 6 figures in Eurasip Journal on Wireless Communications and
  Networking, 2016. arXiv admin note: text overlap with arXiv:1410.0444,
  arXiv:1406.0234</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03936</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03942</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Efficient Call Path Detection for Android-OS Size of Huge Source Code</dc:title>
 <dc:creator>Yamamoto, Koji</dc:creator>
 <dc:creator>Matsutsuka, Taka</dc:creator>
 <dc:subject>Computer Science - Data Structures and Algorithms</dc:subject>
 <dc:description>  Today most developers utilize source code written by other parties. Because
the code is modified frequently, the developers need to grasp the impact of the
modification repeatedly. A call graph and especially its special type, a call
path, help the developers comprehend the modification. Source code written by
other parties, however, becomes too huge to be held in memory in the form of
parsed data for a call graph or path. This paper offers a bidirectional search
algorithm for a call graph of too huge amount of source code to store all parse
results of the code in memory. It refers to a method definition in source code
corresponding to the visited node in the call graph. The significant feature of
the algorithm is the referenced information is used not in order to select a
prioritized node to visit next but in order to select a node to postpone
visiting. It reduces path extraction time by 8% for a case in which ordinary
path search algorithms do not reduce the time.
</dc:description>
 <dc:description>Comment: in Sixth International Conference on Computer Science, Engineering
  and Applications (CCSEA 2016), Dubai, UAE, January 23~24, 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03942</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03943</identifier>
 <datestamp>2017-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Second-Order Stochastic Optimization for Machine Learning in Linear Time</dc:title>
 <dc:creator>Agarwal, Naman</dc:creator>
 <dc:creator>Bullins, Brian</dc:creator>
 <dc:creator>Hazan, Elad</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  First-order stochastic methods are the state-of-the-art in large-scale
machine learning optimization owing to efficient per-iteration complexity.
Second-order methods, while able to provide faster convergence, have been much
less explored due to the high cost of computing the second-order information.
In this paper we develop second-order stochastic methods for optimization
problems in machine learning that match the per-iteration cost of gradient
based methods, and in certain settings improve upon the overall running time
over popular first-order methods. Furthermore, our algorithm has the desirable
property of being implementable in time linear in the sparsity of the input
data.
</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2017-11-30</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03943</dc:identifier>
 <dc:identifier>Journal of Machine Learning Research 18(116) (2017) 1-40</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03945</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An Overview of Particle Methods for Random Finite Set Models</dc:title>
 <dc:creator>Ristic, Branko</dc:creator>
 <dc:creator>Beard, Michael</dc:creator>
 <dc:creator>Fantacci, Claudio</dc:creator>
 <dc:subject>Computer Science - Systems and Control</dc:subject>
 <dc:description>  This overview paper describes the particle methods developed for the
implementation of the a class of Bayes filters formulated using the random
finite set formalism. It is primarily intended for the readership already
familiar with the particle methods in the context of the standard Bayes filter.
The focus in on the Bernoulli particle filter, the probability hypothesis
density (PHD) particle filter and the generalised labelled multi-Bernoulli
(GLMB) particle filter. The performance of the described filters is
demonstrated in the context of bearings-only target tracking application.
</dc:description>
 <dc:description>Comment: 50 pages including 6 figures in Information Fusion, 2016</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03945</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03950</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>General Vector Machine</dc:title>
 <dc:creator>Zhao, Hong</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:description>  The support vector machine (SVM) is an important class of learning machines
for function approach, pattern recognition, and time-serious prediction, etc.
It maps samples into the feature space by so-called support vectors of selected
samples, and then feature vectors are separated by maximum margin hyperplane.
The present paper presents the general vector machine (GVM) to replace the SVM.
The support vectors are replaced by general project vectors selected from the
usual vector space, and a Monte Carlo (MC) algorithm is developed to find the
general vectors. The general project vectors improves the feature-extraction
ability, and the MC algorithm can control the width of the separation margin of
the hyperplane. By controlling the separation margin, we show that the maximum
margin hyperplane can usually induce the overlearning, and the best learning
machine is achieved with a proper separation margin. Applications in function
approach, pattern recognition, and classification indicate that the developed
method is very successful, particularly for small-set training problems.
Additionally, our algorithm may induce some particular applications, such as
for the transductive inference.
</dc:description>
 <dc:description>Comment: 57pages, 20 figures</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03950</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03954</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Linear Degrees of Freedom for $K $-user MISO Interference Channels with
  Blind Interference Alignment</dc:title>
 <dc:creator>Yang, Heecheol</dc:creator>
 <dc:creator>Shin, Wonjae</dc:creator>
 <dc:creator>Lee, Jungwoo</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  In this paper, we characterize the degrees of freedom (DoF) for $K $-user $M
\times 1 $ multiple-input single-output interference channels with
reconfigurable antennas which have multiple preset modes at the receivers,
assuming linear coding strategies in the absence of channel state information
at the transmitters, i.e., blind interference alignment. Our linear DoF
converse builds on the lemma that if a set of transmit symbols is aligned at
their common unintended receivers, those symbols must have independent signal
subspace at their corresponding receivers. This lemma arises from the inherent
feature that channel state's changing patterns of the links towards the same
receiver are always identical, assuming that the coherence time of the channel
is long enough. We derive an upper bound for the linear sum DoF, and propose an
achievable scheme that exactly achieves the linear sum DoF upper-bound when
both of the $\frac{n^{*}}{M}=R_{1} $ and $\frac{MK}{n^{*}}=R_{2} $ are
integers. For the other cases, where either $R_1 $ or $R_2 $ is not an integer,
we only give some guidelines how the interfering signals are aligned at the
receivers to achieve the upper-bound. As an extension, we also show the linear
sum DoF upper-bound for downlink/uplink cellular networks.
</dc:description>
 <dc:description>Comment: 25 pages, 6 figures, submitted to IEEE Transactions on Wireless
  Communications</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03954</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03956</identifier>
 <datestamp>2016-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Grokya: a Privacy-Friendly Framework for Ubiquitous Computing</dc:title>
 <dc:creator>Farinha, Daniel Filipe G.</dc:creator>
 <dc:subject>Computer Science - Computers and Society</dc:subject>
 <dc:subject>Computer Science - Human-Computer Interaction</dc:subject>
 <dc:description>  In a world where for-profit enterprises are increasingly looking to maximize
profits by engaging in privacy invading consumer-profiling techniques, the rise
of ubiquitous computing and the Internet of Things (IoT) poses a major problem.
If not acted upon quickly, the combination of Big Data with IoT will explode
into a dystopian world that even George Orwell could not have predicted. The
proposed project aims to fill a gap that no other solution is addressing, which
is to reach a win-win scenario that works for both the enterprises and the
consumers. It aims to do this by creating the building blocks for a consumer
owned infrastructure that can provide both privacy for the user, and still
enable the enterprises to achieve their high-level goals.
</dc:description>
 <dc:description>Comment: Master thesis</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:date>2016-06-29</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03956</dc:identifier>
 <dc:identifier>doi:10.13140/RG.2.1.2452.3281</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03960</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>TabMCQ: A Dataset of General Knowledge Tables and Multiple-choice
  Questions</dc:title>
 <dc:creator>Jauhar, Sujay Kumar</dc:creator>
 <dc:creator>Turney, Peter</dc:creator>
 <dc:creator>Hovy, Eduard</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  We describe two new related resources that facilitate modelling of general
knowledge reasoning in 4th grade science exams. The first is a collection of
curated facts in the form of tables, and the second is a large set of
crowd-sourced multiple-choice questions covering the facts in the tables.
Through the setup of the crowd-sourced annotation task we obtain implicit
alignment information between questions and tables. We envisage that the
resources will be useful not only to researchers working on question answering,
but also to people investigating a diverse range of other applications such as
information extraction, question parsing, answer type identification, and
lexical semantic modelling.
</dc:description>
 <dc:description>Comment: Keywords: Data, General Knowledge, Tables, Question Answering, MCQ,
  Crowd-sourcing, Mechanical Turk</dc:description>
 <dc:date>2016-02-11</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03960</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03963</identifier>
 <datestamp>2016-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Detection of Cooperative Interactions in Logistic Regression Models</dc:title>
 <dc:creator>Xu, Easton Li</dc:creator>
 <dc:creator>Qian, Xiaoning</dc:creator>
 <dc:creator>Liu, Tie</dc:creator>
 <dc:creator>Cui, Shuguang</dc:creator>
 <dc:subject>Computer Science - Artificial Intelligence</dc:subject>
 <dc:description>  An important problem in the field of bioinformatics is to identify
interactive effects among profiled variables for outcome prediction. In this
paper, a logistic regression model with pairwise interactions among a set of
binary covariates is considered. Modeling the structure of the interactions by
a graph, our goal is to recover the interaction graph from independently
identically distributed (i.i.d.) samples of the covariates and the outcome.
  When viewed as a feature selection problem, a simple quantity called
influence is proposed as a measure of the marginal effects of the interaction
terms on the outcome. For the case when the underlying interaction graph is
known to be acyclic, it is shown that a simple algorithm that is based on a
maximum-weight spanning tree with respect to the plug-in estimates of the
influences not only has strong theoretical performance guarantees, but can also
outperform generic feature selection algorithms for recovering the interaction
graph from i.i.d. samples of the covariates and the outcome. Our results can
also be extended to the model that includes both individual effects and
pairwise interactions via the help of an auxiliary covariate.
</dc:description>
 <dc:description>Comment: 15 pages, 4 figures</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:date>2016-12-27</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03963</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03966</identifier>
 <datestamp>2017-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Measuring and Maximizing Influence via Random Walk in Social Activity
  Networks</dc:title>
 <dc:creator>Zhao, Pengpeng</dc:creator>
 <dc:creator>Li, Yongkun</dc:creator>
 <dc:creator>Xie, Hong</dc:creator>
 <dc:creator>Wu, Zhiyong</dc:creator>
 <dc:creator>Xu, Yinlong</dc:creator>
 <dc:creator>Lui, John C. S.</dc:creator>
 <dc:subject>Computer Science - Social and Information Networks</dc:subject>
 <dc:description>  With the popularity of OSNs, finding a set of most influential users (or
nodes) so as to trigger the largest influence cascade is of significance. For
example, companies may take advantage of the &quot;word-of-mouth&quot; effect to trigger
a large cascade of purchases by offering free samples/discounts to those most
influential users. This task is usually modeled as an influence maximization
problem, and it has been widely studied in the past decade. However,
considering that users in OSNs may participate in various kinds of online
activities, e.g., giving ratings to products, joining discussion groups, etc.,
influence diffusion through online activities becomes even more significant.
  In this paper, we study the impact of online activities by formulating the
influence maximization problem for social-activity networks (SANs) containing
both users and online activities. To address the computation challenge, we
define an influence centrality via random walks to measure influence, then use
the Monte Carlo framework to efficiently estimate the centrality in SANs.
Furthermore, we develop a greedy-based algorithm with two novel optimization
techniques to find the most influential users. By conducting extensive
experiments with real-world datasets, we show our approach is more efficient
than the state-of-the-art algorithm IMM[17] when we needs to handle large
amount of online activities.
</dc:description>
 <dc:description>Comment: 19 pages</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:date>2017-01-09</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03966</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03969</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Opportunistic Detection Rules: Finite and Asymptotic Analysis</dc:title>
 <dc:creator>Zhang, Wenyi</dc:creator>
 <dc:creator>Moustakides, George V.</dc:creator>
 <dc:creator>Poor, H. Vincent</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  Opportunistic detection rules (ODRs) are variants of fixed-sample-size
detection rules in which the statistician is allowed to make an early decision
on the alternative hypothesis opportunistically based on the sequentially
observed samples. From a sequential decision perspective, ODRs are also
mixtures of one-sided and truncated sequential detection rules. Several results
regarding ODRs are established in this paper. In the finite regime, the maximum
sample size is modeled either as a fixed finite number, or a geometric random
variable with a fixed finite mean. For both cases, the corresponding Bayesian
formulations are investigated. The former case is a slight variation of the
well-known finite-length sequential hypothesis testing procedure in the
literature, whereas the latter case is new, for which the Bayesian optimal ODR
is shown to be a sequence of likelihood ratio threshold tests with two
different thresholds: a running threshold, which is determined by solving a
stationary state equation, is used when future samples are still available, and
a terminal threshold (simply the ratio between the priors scaled by costs) is
used when the statistician reaches the final sample and thus has to make a
decision immediately. In the asymptotic regime, the tradeoff among the
exponents of the (false alarm and miss) error probabilities and the normalized
expected stopping time under the alternative hypothesis is completely
characterized and proved to be tight, via an information-theoretic argument.
Within the tradeoff region, one noteworthy fact is that the performance of the
Stein-Chernoff Lemma is attainable by ODRs.
</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03969</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03979</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Signal periodic decomposition with conjugate subspaces</dc:title>
 <dc:creator>Deng, Shi-Wen</dc:creator>
 <dc:creator>Han, Ji-Qing</dc:creator>
 <dc:subject>Computer Science - Computational Engineering, Finance, and Science</dc:subject>
 <dc:description>  In this paper, we focus on hidden period identification and the periodic
decomposition of signals. Based on recent results on the Ramanujan subspace, we
reveal the conjugate symmetry of the Ramanujan subspace with a set of complex
exponential basis functions and represent the subspace as the union of a series
of conjugate subspaces. With these conjugate subspaces, the signal periodic
model is introduced to characterize the periodic structure of a signal. To
achieve the decomposition of the proposed model, the conjugate subspace
matching pursuit (CSMP) algorithm is proposed based on two different greedy
strategies. The CSMP is performed iteratively in two stages. In the first
stage, the dominant hidden period is chosen with the periodicity strategy.
Then, the dominant conjugate subspace is chosen with the energy strategy in the
second stage. Compared with the current state-of-the-art methods for hidden
period identification, the main advantages provided by the CSMP are the
following: (i) the capability of identifying all the hidden periods in the
range from $1$ to the maximum hidden period $Q$ of a signal of any length,
without truncating the signal; (ii) the ability to identify the time-varying
hidden period with its shifted version; and (iii) the low computational cost,
without generating and using a large over-complete dictionary. Moreover, we
provide examples and applications to demonstrate the abilities of the proposed
two-stage CSMP algorithm, which include hidden period identification, signal
approximation, time-varying period detection, and pitch detection of speech.
</dc:description>
 <dc:description>Comment: 11 pages, 9 figures</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03979</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2600509</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03985</identifier>
 <datestamp>2017-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>A complexity trichotomy for approximately counting list H-colourings</dc:title>
 <dc:creator>Galanis, Andreas</dc:creator>
 <dc:creator>Goldberg, Leslie Ann</dc:creator>
 <dc:creator>Jerrum, Mark</dc:creator>
 <dc:subject>Computer Science - Computational Complexity</dc:subject>
 <dc:subject>Mathematics - Combinatorics</dc:subject>
 <dc:subject>68Q17, 05C15, 05C75, 68Q25</dc:subject>
 <dc:subject>F.2.2</dc:subject>
 <dc:subject>G.2.1</dc:subject>
 <dc:description>  We examine the computational complexity of approximately counting the list
H-colourings of a graph. We discover a natural graph-theoretic trichotomy based
on the structure of the graph H. If H is an irreflexive bipartite graph or a
reflexive complete graph then counting list H-colourings is trivially in
polynomial time. Otherwise, if H is an irreflexive bipartite permutation graph
or a reflexive proper interval graph then approximately counting list
H-colourings is equivalent to #BIS, the problem of approximately counting
independent sets in a bipartite graph. This is a well-studied problem which is
believed to be of intermediate complexity -- it is believed that it does not
have an FPRAS, but that it is not as difficult as approximating the most
difficult counting problems in #P. For every other graph H, approximately
counting list H-colourings is complete for #P with respect to
approximation-preserving reductions (so there is no FPRAS unless NP=RP). Two
pleasing features of the trichotomy are (i) it has a natural formulation in
terms of hereditary graph classes, and (ii) the proof is largely self-contained
and does not require any universal algebra (unlike similar dichotomies in the
weighted case). We are able to extend the hardness results to the
bounded-degree setting, showing that all hardness results apply to input graphs
with maximum degree at most 6.
</dc:description>
 <dc:description>Comment: To appear in ACM Transactions on Computation Theory</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:date>2017-01-05</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03985</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03992</identifier>
 <datestamp>2016-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Orthogonal Sparse PCA and Covariance Estimation via Procrustes
  Reformulation</dc:title>
 <dc:creator>Benidis, Konstantinos</dc:creator>
 <dc:creator>Sun, Ying</dc:creator>
 <dc:creator>Babu, Prabhu</dc:creator>
 <dc:creator>Palomar, Daniel P.</dc:creator>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:subject>Statistics - Applications</dc:subject>
 <dc:description>  The problem of estimating sparse eigenvectors of a symmetric matrix attracts
a lot of attention in many applications, especially those with high dimensional
data set. While classical eigenvectors can be obtained as the solution of a
maximization problem, existing approaches formulate this problem by adding a
penalty term into the objective function that encourages a sparse solution.
However, the resulting methods achieve sparsity at the expense of sacrificing
the orthogonality property. In this paper, we develop a new method to estimate
dominant sparse eigenvectors without trading off their orthogonality. The
problem is highly non-convex and hard to handle. We apply the MM framework
where we iteratively maximize a tight lower bound (surrogate function) of the
objective function over the Stiefel manifold. The inner maximization problem
turns out to be a rectangular Procrustes problem, which has a closed form
solution. In addition, we propose a method to improve the covariance estimation
problem when its underlying eigenvectors are known to be sparse. We use the
eigenvalue decomposition of the covariance matrix to formulate an optimization
problem where we impose sparsity on the corresponding eigenvectors. Numerical
experiments show that the proposed eigenvector extraction algorithm matches or
outperforms existing algorithms in terms of support recovery and explained
variance, while the covariance estimation algorithms improve significantly the
sample covariance estimator.
</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03992</dc:identifier>
 <dc:identifier>doi:10.1109/TSP.2016.2605073</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.03995</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>An automatic method for segmentation of fission tracks in epidote
  crystal photomicrographs</dc:title>
 <dc:creator>de Siqueira, Alexandre Fioravante</dc:creator>
 <dc:creator>Nakasuga, Wagner Massayuki</dc:creator>
 <dc:creator>Pagamisse, Aylton</dc:creator>
 <dc:creator>Saenz, Carlos Alberto Tello</dc:creator>
 <dc:creator>Job, Aldo Eloizo</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:subject>65T60</dc:subject>
 <dc:subject>G.1.2</dc:subject>
 <dc:subject>I.4.0</dc:subject>
 <dc:subject>I.4.6</dc:subject>
 <dc:subject>I.5.4</dc:subject>
 <dc:description>  Manual identification of fission tracks has practical problems, such as
variation due to observer-observation efficiency. An automatic processing
method that could identify fission tracks in a photomicrograph could solve this
problem and improve the speed of track counting. However, separation of
non-trivial images is one of the most difficult tasks in image processing.
Several commercial and free softwares are available, but these softwares are
meant to be used in specific images. In this paper, an automatic method based
on starlet wavelets is presented in order to separate fission tracks in mineral
photomicrographs. Automatization is obtained by Matthews correlation
coefficient, and results are evaluated by precision, recall and accuracy. This
technique is an improvement of a method aimed at segmentation of scanning
electron microscopy images. This method is applied in photomicrographs of
epidote phenocrystals, in which accuracy higher than 89% was obtained in
fission track segmentation, even for difficult images. Algorithms corresponding
to the proposed method are available for download. Using the method presented
here, an user could easily determine fission tracks in photomicrographs of
mineral samples.
</dc:description>
 <dc:description>Comment: 16 pages, 5 figures</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.03995</dc:identifier>
 <dc:identifier>Computers &amp; Geosciences, v. 69, pp. 55-61, aug 2014</dc:identifier>
 <dc:identifier>doi:10.1016/j.cageo.2014.04.008</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.04000</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Budget-Constrained Multi-Battle Contests: A New Perspective and Analysis</dc:title>
 <dc:creator>Cheng, Chu-Han</dc:creator>
 <dc:creator>Chen, Po-An</dc:creator>
 <dc:creator>Hon, Wing-Kai</dc:creator>
 <dc:subject>Computer Science - Computer Science and Game Theory</dc:subject>
 <dc:description>  In a multi-battle contest, each time a player competes by investing some of
her budgets or resources in a component battle to collect a value if winning
the battle. There are multiple battles to fight, and the budgets get consumed
over time. The final winner in the overall contest is the one who first reaches
some amount of total value. Examples include R &amp; D races, sports competition,
elections, and many more. A player needs to make adequate sequential actions to
win the contest against dynamic competition over time from the others. We are
interested in how much budgets the players would need and what actions they
should take in order to perform well.
  We model and study such budget-constrained multi-battle contests where each
component battle is a first-price or all-pay auction. We focus on analyzing the
2-player budget ratio that guarantees a player's winning (or falling behind in
just a bounded amount of collected value) against the other omnipotent player.
In the settings considered, we give efficient dynamic programs to find the
optimal budget ratios and the corresponding bidding strategies. Our definition
of game, budget constraints, and emphasis on budget analyses provide a new
perspective and analysis in the related context.
</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.04000</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1602.04007</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Complete contracts through specification drivers</dc:title>
 <dc:creator>Naumchev, Alexandr</dc:creator>
 <dc:creator>Meyer, Bertrand</dc:creator>
 <dc:subject>Computer Science - Software Engineering</dc:subject>
 <dc:description>  Existing techniques of Design by Contract do not allow software developers to
specify complete contracts in many cases. Incomplete contracts leave room for
malicious implementations. This article complements Design by Contract with a
simple yet powerful technique that removes the problem without adding
syntactical mechanisms. The proposed technique makes it possible not only to
derive complete contracts, but also to rigorously check and improve
completeness of existing contracts without instrumenting them.
</dc:description>
 <dc:description>Comment: 8 pages; 11 figures; submitted to TASE 2016; pending for acceptance
  decision</dc:description>
 <dc:date>2016-02-12</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1602.04007</dc:identifier>
 </oai_dc:dc>
</metadata>
</record>
<resumptionToken cursor="91000" completeListSize="155308">2369777|92001</resumptionToken>
</ListRecords>
</OAI-PMH>
